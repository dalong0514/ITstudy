## GPT-4 的黑箱运作方式引科学家不满

环球科学 2023-03-23 21:30 发表于北京

以下文章来源于 Nature Portfolio ，作者 Nature Portfolio

科研人员对这项 AI 技术充满期待，但对其底层技术的秘而不宣感到不满。

文章来源｜公众号「Nature Portfolio」

原文作者｜Katharine Sanderson

上周，人工智能公司 OpenAI 推出了 GPT-4 —— 驱动其热门对话机器人 ChatGPT 的大型语言模型的最新版本。这个语言模型能根据几乎任何提示创作有人类文笔的文本并生成图像和程序代码，而且表现十分惊艳。该公司表示，GPT-4 在此基础上又有了很大的提升。研究人员认为这些能力有望推动科研变革，但也有人感到不满，因为他们还没有使用权限，也不了解它的底层代码或是训练方式。科学家认为，这种情况下，人们对该技术的安全性会有顾虑，其对科研的帮助也不如预想的这么大。

3 月 14 日公布的 GPT-4 有一个全新升级：它现在不仅可以处理文本，还可以处理图像。作为对其语言能力的演示，位于加州旧金山的 OpenAI 表示，GPT-4 已经能通过美国律师资格考试，成绩位于第 90 百分位，而之前的 ChatGPT 版本只能进入第 10 百分位。不过，这项技术尚未向所有人开放，目前只有 ChatGPT 的付费用户可以使用。

「现在需要在等位名单上排队，还不能立刻就用上。」阿姆斯特丹大学心理学家 Evi-Anne van Dis 说。不过，她已经见过 GPT-4 的 demo。她说：「我们在视频里看过他们演示 GPT-4 的一些能力，简直超乎想象。」她记得，有一次演示用了一个网站的手绘插画，GPT-4 能根据这些插画生成构建该网站的代码，证明它能将图像转化为输入信息的能力。

不过，OpenAI 对它的模型使用哪些数据训练、如何训练，以及它的运作方式讳莫如深，这令科研人员感到不满。「所有这些闭源模型可以说是科学界的死胡同，」开源 AI 社区 HuggingFace 的气候科学家 Sasha Luccioni 说，「他们【OpenAI】可以在他们的研究基础上越攀越高，但对整个科学界来说，这就是条死路。」

###「红队」测试

美国罗切斯特大学的化学工程师 Andrew White 以「红队队员」（red-teamer）的身份优先体验了 GPT-4。OpenAI 付费邀请这些红队队员测试该平台，他们会尝试让 GPT-4 做些不好的事情。他说，他在过去 6 个月都可以使用 GPT-4。「与之前几代相比，一开始它好像也没什么特别之处。」

图片来源：OpenAI 推特

他会询问这个机器人合成某个化合物需要哪些反应步骤，让它预测反应产物并选择催化剂。「起初我没觉得它有多强大，」White 说，「令人惊讶的是它看起来特别像回事，但它会在这里幻想出一个原子，在那里跳过一个步骤。」不过，就在他按照他们红队的任务给 GPT-4 开放科研论文的权限后，情况急剧变化。「我们发现，这类模型独立存在时可能没什么厉害之处，但当你把它和互联网和逆合成设计功能（retrosynthesis planner）等工具，或是和计算器相连，突然之间，新的能力全部出现了。」

当然，这些能力也伴随着隐忧。比如，GPT-4 会允许合成危险化学品吗？利用 White 等人的输入信息，OpenAI 的工程师再把这些信息「投喂」给他们的模型，让 GPT-4 避免生成危险、非法、有害的内容，White 说道。

### 捏造事实

不实信息是另一个问题。Luccioni 表示，GPT-4 一类模型的功能是预测一句话的下一个词，所以无法完全摆脱胡编乱造的问题，这种现象也成为「幻觉」（hallucinating）。她说：「你不能全信这些模型，因为它的幻觉太多了。」即使是最新版本也仍有这个问题，她说，尽管 OpenAI 表示已经提升了 GPT-4 的安全性。

如果不公开训练所使用的数据，OpenAI 关于安全性的担保在 Luccioni 看来是不够的。她说：「你不知道它用了哪些数据，你就无法优化它。我的意思是，把科研工作教给这样一个模型肯定是不现实的。」

围绕 GPT-4 训练方式的谜团对 van Dis 在阿姆斯特丹大学的同事、心理学家 Claudi Bockting 来说也是一个担忧。「让人类对他无法监督的东西负责是很难的，」她说，「一个担忧是它们的偏见可能远远超过人类自己的偏见。」Luccioni 解释道，如果无法获得 GPT-4 的底层代码，你就无法判断偏见是来自哪里，自然也就没法纠正了。

### 伦理探讨

Bockting 和 van Dis 还担心这些 AI 系统今后都会被大型科技公司收入麾下。他们希望这项技术能得到科学家的严格测试和验证。她说：「这里也有机遇，因为与科技巨头的合作能加快前进速度。」

van Dis、Bockting 和同事在今年更早时指出，亟需建立一套「活」指南，指导 AI 和 GPT-4 等工具的使用和开发。他们担心关于 AI 技术的任何法规很难跟上 AI 发展的步伐。Bockting 和 van Dis 已经组织 4 月 11 日在阿姆斯特丹大学召开研讨会，探讨上述问题，与会代表来自联合国教科文组织的科学伦理委员会、经济合作与发展组织、世界经济论坛等组织。

White 认为，抛开种种顾虑，GPT-4 及其未来迭代势必会重塑科学。他说：「我相信这将是科研基础架构的一次重大变革，堪比当初互联网带来的巨大震动。」它不会取代科学家，他说，但能协助科学家开展某些工作。「我认为我们将慢慢意识到，我们能把论文、数据程序、我们用的图书库与计算工作，甚至是机器人实验全部互联。

原文以 GPT-4 is here: what scientists think 标题发表在 2023 年 3 月 16 日《自然》的新闻版块上。
