

## How do I list all files of a directory?

duhhunjonn

[How do I list all files of a directory?](https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory)

How can I list all files of a directory in Python and add them to a list?

2010-07-08 19:31:22Z

How can I list all files of a directory in Python and add them to a list?os.listdir() will get you everything that's in a directory - files and directories.If you want just files, you could either filter this down using os.path:or you could use os.walk() which will yield two lists for each directory it visits - splitting into files and dirs for you. If you only want the top directory you can just break the first time it yieldsI prefer using the glob module, as it does pattern matching and expansion.It will return a list with the queried files:will return a list of all files and directories in "somedirectory".How to get all the files (and directories) in the current directory (Python 3)Following, are simple methods to retrieve only files in the current directory, using os  and the listdir() function, in Python 3.  Further exploration, will demonstrate how to return folders in the directory, but you will not have the file in the subdirectory, for that you can use walk - discussed later).I found glob easier to select the file of the same type or with something in common. Look at the following example:The function returns a list of the given extension (.txt, .docx ecc.) in the argumentThe function now returns a list of file that matched with the string you pass as argumentoutputAs you noticed, you don't have the full path of the file in the code above. If you need to have the absolute path, you can use another function of the os.path module called _getfullpathname, putting the file that you get from os.listdir() as an argument. There are other ways to have the full path, as we will check later (I replaced, as suggested by mexmex, _getfullpathname with abspath).I find this very useful to find stuff in many directories, and it helped me find a file about which I didn't remember the name:In Python 2, if you want the list of the files in the current directory, you have to give the argument as '.' or os.getcwd() in the os.listdir method.If I should need the absolute path of the files:With list comprehension:Alternatively, use pathlib.Path() instead of pathlib.Path(".")In this example, we look for the number of files that are included in all the directory and its subdirectories.A script to make order in your computer finding all files of a type (default: pptx) and copying them in a new folder.In case you want to create a txt file with all the file names:With this function you can create a txt file that will have the name of a type of file that you look for (ex. pngfile.txt) with all the full path of all the files of that type. It can be useful sometimes, I think.A one-line solution to get only list of files (no subdirectories):or absolute pathnames:Getting Full File Paths From a Directory and All Its SubdirectoriesIf you'd like, you can open and read the contents, or focus only on files with the extension ".dat" like in the code below:/Users/johnny/Desktop/TEST/SUBFOLDER/file3.datSince version 3.4 there are builtin iterators for this which are a lot more efficient than os.listdir():pathlib: New in version 3.4.According to PEP 428, the aim of the pathlib library is to provide a simple hierarchy of classes to handle filesystem paths and the common operations users do over them.os.scandir(): New in version 3.5.Note that os.walk() uses os.scandir() instead of os.listdir() from version 3.5, and its speed got increased by 2-20 times according to PEP 471.Let me also recommend reading ShadowRanger's comment below.Notes:I really liked adamk's answer, suggesting that you use glob(), from the module of the same name. This allows you to have pattern matching with *s.But as other people pointed out in the comments, glob() can get tripped up over inconsistent slash directions. To help with that, I suggest you use the join() and expanduser() functions in the os.path module, and perhaps the getcwd() function in the os module, as well.As examples:The above is terrible - the path has been hardcoded and will only ever work on Windows between the drive name and the \s being hardcoded into the path.The above works better, but it relies on the folder name Users which is often found on Windows and not so often found on other OSs. It also relies on the user having a specific name, admin.This works perfectly across all platforms.Another great example that works perfectly across platforms and does something a bit different:Hope these examples help you see the power of a few of the functions you can find in the standard Python library modules.If you are looking for a Python implementation of find, this is a recipe I use rather frequently:So I made a PyPI package out of it and there is also a GitHub repository. I hope that someone finds it potentially useful for this code.For greater results, you can use listdir() method of the os module along with a generator (a generator is a powerful iterator that keeps its state, remember?). The following code works fine with both versions: Python 2 and Python 3.Here's a code:The listdir() method returns the list of entries for the given directory. The method os.path.isfile() returns True if the given entry is a file. And the yield operator quits the func but keeps its current state, and it returns only the name of the entry detected as a file. All the above allows us to loop over the generator function.Returning a list of absolute filepaths, does not recurse into subdirectoriesHere I use a recursive structure.A wise teacher told me once that:I will thus add a solution for a subset of the problem: quite often, we only want to check whether a file matches a start string and an end string, without going into subdirectories. We would thus like a function that returns a list of filenames, like:If you care to first declare two functions, this can be done:This solution could be easily generalized with regular expressions (and you might want to add a pattern argument, if you do not want your patterns to always stick to the start or end of the filename).Using generatorsAnother very readable variant for Python 3.4+ is using pathlib.Path.glob:It is simple to make more specific, e.g. only look for Python source files which are not symbolic links, also in all subdirectories:Here's my general-purpose function for this.  It returns a list of file paths rather than filenames since I found that to be more useful.  It has a few optional arguments that make it versatile.  For instance, I often use it with arguments like pattern='*.txt' or subfolders=True.I will provide a sample one liner where sourcepath and file type can be provided as input. The code returns a list of filenames with csv extension. Use . in case all files needs to be returned. This will also recursively scans the subdirectories. [y for x in os.walk(sourcePath) for y in glob(os.path.join(x[0], '*.csv'))]Modify file extensions and source path as needed. For python2:

pip install rglobdircache is  "Deprecated since version 2.6: The dircache module has been removed in Python 3.0."

## Accessing the index in 'for' loops?

Joan Venge

[Accessing the index in 'for' loops?](https://stackoverflow.com/questions/522563/accessing-the-index-in-for-loops)

How do I access the index in a for loop like the following?I want to get this output:When I loop through it using a for loop, how do I access the loop index, from 1 to 5 in this case?

2009-02-06 22:47:54Z

How do I access the index in a for loop like the following?I want to get this output:When I loop through it using a for loop, how do I access the loop index, from 1 to 5 in this case?Using an additional state variable, such as an index variable (which you would normally use in languages such as C or PHP), is considered non-pythonic.The better option is to use the built-in function enumerate(), available in both Python 2 and 3:Check out PEP 279 for more.Use enumerate to get the index with the element as you iterate:And note that Python's indexes start at zero, so you would get 0 to 4 with the above. If you want the count, 1 to 5, do this:What you are asking for is the Pythonic equivalent of the following, which is the algorithm most programmers of lower-level languages would use:Or in languages that do not have a for-each loop:or sometimes more commonly (but unidiomatically) found in Python:Python's enumerate function reduces the visual clutter by hiding the accounting for the indexes, and encapsulating the iterable into another iterable (an enumerate object) that yields a two-item tuple of the index and the item that the original iterable would provide. That looks like this:This code sample is fairly well the canonical example of the difference between code that is idiomatic of Python and code that is not. Idiomatic code is sophisticated (but not complicated) Python, written in the way that it was intended to be used. Idiomatic code is expected by the designers of the language, which means that usually this code is not just more readable, but also more efficient.Even if you don't need indexes as you go, but you need a count of the iterations (sometimes desirable) you can start with 1 and the final number will be your count.The count seems to be more what you intend to ask for (as opposed to index) when you said you wanted from 1 to 5.To break these examples down, say we have a list of items that we want to iterate over with an index:Now we pass this iterable to enumerate, creating an enumerate object:We can pull the first item out of this iterable that we would get in a loop with the next function:And we see we get a tuple of 0, the first index, and 'a', the first item:we can use what is referred to as "sequence unpacking" to extract the elements from this two-tuple:and when we inspect index, we find it refers to the first index, 0, and item refers to the first item, 'a'.So do this:It's pretty simple to start it from 1 other than 0:Important hint, though a little misleading since index will be a tuple (idx, item) here.

Good to go.As is the norm in Python there are several ways to do this. In all examples assume: lst = [1, 2, 3, 4, 5]This is also the safest option in my opinion because the chance of going into infinite recursion has been eliminated. Both the item and its index are held in variables and there is no need to write any further code

to access the item.As explained before, there are other ways to do this that have not been explained here and they may even apply more in other situations. e.g using itertools.chain with for. It handles nested loops better than the other examples.Old fashioned way:List comprehension:The fastest way to access indexes of list within loop in Python 2.7 is to use the range method for small lists and enumerate method for medium and huge size lists.Please see different approaches which can be used to iterate over list and access index value and their performance metrics (which I suppose would be useful for you) in code samples below:See performance metrics for each method below:As the result, using range method is the fastest one up to list with 1000 items. For list with size > 10 000 items enumerate is the winner.Adding some useful links below:First of all, the indexes will be from 0 to 4. Programming languages start counting from 0; don't forget that or you will come across an index out of bounds exception. All you need in the for loop is a variable counting from 0 to 4 like so:Keep in mind that I wrote 0 to 5 because the loop stops one number before the max. :)To get the value of an index useAccording to this discussion: http://bytes.com/topic/python/answers/464012-objects-list-indexLoop counter iterationThe current idiom for looping over the indices makes use of the built-in range function:Looping over both elements and indices can be achieved either by the old idiom or by using the new zip built-in function:orvia http://www.python.org/dev/peps/pep-0212/You can do it with this code:Use this code if you need to reset the index value at the end of the loop:Best solution for this problem is use enumerate in-build python function. 

enumerate return tuple 

first value is index 

second value is element of array at that indexResult:Result:Result:If I were to iterate nums = [1, 2, 3, 4, 5] I would doOr get the length as l = len(nums)If there is no duplicate value in the list:In your question, you write "how do I access the loop index, from 1 to 5 in this case?"However, the index for a list runs from zero.  So, then we need to know if what you actually want is the index and item for each item in a list, or whether you really want numbers starting from 1.  Fortunately, in Python, it is easy to do either or both.First, to clarify, the enumerate function iteratively returns the index and corresponding item for each item in a list.The output for the above is then,Notice that the index runs from 0. This kind of indexing is common among modern programming languages including Python and C.If you want your loop to span a part of the list, you can use the standard Python syntax for a part of the list. For example, to loop from the second item in a list up to but not including the last item, you could useNote that once again, the output index runs from 0,That brings us to the start=n switch for enumerate().  This simply offsets the index, you can equivalently simply add a number to the index inside the loop.for which the output isYou can also try this:The output is You can use the index methodEDIT

Highlighted in the comment that this method doesn’t work if there are duplicates in ints, the method below should work for any values in ints:Or alternativelyif you want to get both the index and the value in ints as a list of tuples.It uses the method of enumerate in the selected answer to this question, but with list comprehension, making it faster with less code.To print tuple of (index, value) in list comprehension using a for loop:Output:This serves the purpose well enough:

## How do I sort a dictionary by value?

Gern Blanston

[How do I sort a dictionary by value?](https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value)

I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.I can sort on the keys, but how can I sort based on the values?Note: I have read Stack Overflow question here How do I sort a list of dictionaries by a value of the dictionary? and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution to sort either in ascending or descending order.

2009-03-05 00:49:05Z

I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.I can sort on the keys, but how can I sort based on the values?Note: I have read Stack Overflow question here How do I sort a list of dictionaries by a value of the dictionary? and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution to sort either in ascending or descending order.It is not possible to sort a dictionary, only to get a representation of a dictionary that is sorted. Dictionaries are inherently orderless, but other types, such as lists and tuples, are not. So you need an ordered data type to represent sorted values, which will be a list—probably a list of tuples.For instance,sorted_x will be a list of tuples sorted by the second element in each tuple. dict(sorted_x) == x.And for those wishing to sort on keys instead of values:In Python3 since unpacking is not allowed [1] we can use If you want the output as a dict, you can use collections.OrderedDict:Well, it is actually possible to do a "sort by dictionary values". Recently I had to do that in a Code Golf (Stack Overflow question Code golf: Word frequency chart). Abridged, the problem was of the kind: given a text, count how often each word is encountered and display a list of the top words, sorted by decreasing frequency. If you construct a dictionary with the words as keys and the number of occurrences of each word as value, simplified here as:then you can get a list of the words, ordered by frequency of use with sorted(d, key=d.get) - the sort iterates over the dictionary keys, using the number of word occurrences as a sort key . I am writing this detailed explanation to illustrate what people often mean by "I can easily sort a dictionary by key, but how do I sort by value" - and I think the original post was trying to address such an issue. And the solution is to do sort of list of the keys, based on the values, as shown above.You could use:This will sort the dictionary by the values of each entry within the dictionary from smallest to largest.To sort it in descending order just add reverse=True:Input:Output:Dicts can't be sorted, but you can build a sorted list from them.A sorted list of dict values:A list of (key, value) pairs, sorted by value:In recent Python 2.7, we have the new OrderedDict type, which remembers the order in which the items were added.To make a new ordered dictionary from the original, sorting by the values:The OrderedDict behaves like a normal dict:UPDATE: 5 DECEMBER 2015 using Python 3.5Whilst I found the accepted answer useful, I was also surprised that it hasn't been updated to reference OrderedDict from the standard library collections module as a viable, modern alternative - designed to solve exactly this type of problem.The official OrderedDict documentation offers a very similar example too, but using a lambda for the sort function:Pretty much the same as Hank Gay's answer:Or optimized slightly as suggested by John Fouhy:It can often be very handy to use namedtuple. For example, you have a dictionary of 'name' as keys and 'score' as values and you want to sort on 'score':sorting with lowest score first:sorting with highest score first:Now you can get the name and score of, let's say the second-best player (index=1) very Pythonically like this:Good news, so the OP's original use case of mapping pairs retrieved from a database with unique string ids as keys and numeric values as values into a built-in Python v3.6+ dict, should now respect the insert order.If say the resulting two column table expressions from a database query like:would be stored in two Python tuples, k_seq and v_seq (aligned by numerical index and with the same length of course), then:Allow to output later as:yielding in this case (for the new Python 3.6+ built-in dict!):in the same ordering per value of v.Where in the Python 3.5 install on my machine it currently yields:As proposed in 2012 by Raymond Hettinger (cf. mail on python-dev with subject "More compact dictionaries with faster iteration") and now (in 2016) announced in a mail by Victor Stinner to python-dev with subject "Python 3.6 dict becomes compact and gets a private version; and keywords become ordered" due to the fix/implementation of issue 27350 "Compact and ordered dict" in Python 3.6 we will now be able, to use a built-in dict to maintain insert order!!Hopefully this will lead to a thin layer OrderedDict implementation as a first step. As @JimFasarakis-Hilliard indicated, some see use cases for the OrderedDict type also in the future. I think the Python community at large will carefully inspect, if this will stand the test of time, and what the next steps will be.Time to rethink our coding habits to not miss the possibilities opened by stable ordering of:The first because it eases dispatch in the implementation of functions and methods in some cases.The second as it encourages to more easily use dicts as intermediate storage in processing pipelines.Raymond Hettinger kindly provided documentation explaining "The Tech Behind Python 3.6 Dictionaries" - from his San Francisco Python Meetup Group presentation 2016-DEC-08.And maybe quite some Stack Overflow high decorated question and answer pages will receive variants of this information and many high quality answers will require a per version update too.As @ajcr rightfully notes: "The order-preserving aspect of this new implementation is considered an implementation detail and should not be relied upon." (from the whatsnew36) not nit picking, but the citation was cut a bit pessimistic ;-). It continues as " (this may change in the future, but it is desired to have this new dict implementation in the language for a few releases before changing the language spec to mandate order-preserving semantics for all current and future Python implementations; this also helps preserve backwards-compatibility with older versions of the language where random iteration order is still in effect, e.g. Python 3.5)."So as in some human languages (e.g. German), usage shapes the language, and the will now has been declared ... in whatsnew36.In a mail to the python-dev list, Guido van Rossum declared:So, the version 3.6 CPython side-effect of dict insertion ordering is now becoming part of the language spec (and not anymore only an implementation detail). That mail thread also surfaced some distinguishing design goals for collections.OrderedDict as reminded by Raymond Hettinger during discussion.I had the same problem, and I solved it like this:(People who answer "It is not possible to sort a dict" did not read the question! In fact, "I can sort on the keys, but how can I sort based on the values?" clearly means that he wants a list of the keys sorted according to the value of their values.)Please notice that the order is not well defined (keys with the same value will be in an arbitrary order in the output list).In Python 2.7, simply do:copy-paste from : http://docs.python.org/dev/library/collections.html#ordereddict-examples-and-recipesEnjoy ;-)If values are numeric you may also use Counter from collections.This is the code:Here are the results:OriginalRoflRank Try the following approach. Let us define a dictionary called mydict with the following data:If one wanted to sort the dictionary by keys, one could do something like:This should return the following output:On the other hand, if one wanted to sort a dictionary by value (as is asked in the question), one could do the following:The result of this command (sorting the dictionary by value) should return the following:You can create an "inverted index", alsoNow your inverse has the values; each value has a list of applicable keys.You can use the collections.Counter. Note, this will work for both numeric and non-numeric values.Starting from Python 3.6, dict objects are now ordered by insertion order. It's officially in the specs of Python 3.7.Before that, you had to use OrderedDict.Python 3.7 documentation says:You can use a skip dict which is a dictionary that's permanently sorted by value.If you use keys(), values() or items() then you'll iterate in sorted order by value.It's implemented using the skip list datastructure.You can also use custom function that can be passed to key.Here is a solution using zip on d.values() and d.keys().  A few lines down this link (on Dictionary view objects) is:So we can do the following:As pointed out by Dilettant, Python 3.6 will now keep the order! I thought I'd share a function I wrote that eases the sorting of an iterable (tuple, list, dict). In the latter case, you can sort either on keys or values, and it can take numeric comparison into account. Only for >= 3.6!When you try using sorted on an iterable that holds e.g. strings as well as ints, sorted() will fail. Of course you can force string comparison with str(). However, in some cases you want to do actual numeric comparison where 12 is smaller than 20 (which is not the case in string comparison). So I came up with the following. When you want explicit numeric comparison you can use the flag num_as_num which will try to do explicit numeric sorting by trying to convert all values to floats. If that succeeds, it will do numeric sorting, otherwise it'll resort to string comparison.Comments for improvement or push requests welcome.Of course, remember, you need to use OrderedDict because regular Python dictionaries don't keep the original order. If you do not have Python 2.7 or higher, the best you can do is iterate over the values in a generator function. (There is an OrderedDict for 2.4 and 2.6  here, but a) I don't know about how well it works and b) You have to download and install it of course. If you do not have administrative access, then I'm afraid the option's out.)You can also print out every valuePlease remember to remove the parentheses after print if not using Python 3.0 or aboveUse ValueSortedDict from dicts:Iterate through a dict and sort it by its values in descending order:If your values are integers, and you use Python 2.7 or newer, you can use collections.Counter instead of dict. The most_common method will give you all items, sorted by the value.Just learned relevant skill from Python for Everybody.You may use a temporary list to help you to sort the dictionary:If you want to sort the list in descending order, simply change the original sorting line to:Using list comprehension, the one liner would be:Sample Output:This works in 3.1.x:For the sake of completeness, I am posting a solution using heapq. Note, this method will work for both numeric and non-numeric valuesBecause of requirements to retain backward compatability with older versions of Python I think the OrderedDict solution is very unwise. You want something that works with Python 2.7 and older versions.But the collections solution mentioned in another answer is absolutely superb, because you retrain a connection between the key and value which in the case of dictionaries is extremely important.I don't agree with the number one choice presented in another answer, because it throws away the keys.I used the solution mentioned above (code shown below) and retained access to both keys and values and in my case the ordering was on the values, but the importance was the ordering of the keys after ordering the values.

## How do I check if a list is empty?

Ray Vega

[How do I check if a list is empty?](https://stackoverflow.com/questions/53513/how-do-i-check-if-a-list-is-empty)

For example, if passed the following:How do I check to see if a is empty?

2008-09-10 06:20:11Z

For example, if passed the following:How do I check to see if a is empty?Using the implicit booleanness of the empty list is quite pythonic.The pythonic way to do it is from the PEP 8 style guide (where Yes means「recommended」and No means「not recommended」):I prefer it explicitly:This way it's 100% clear that li is a sequence (list) and we want to test its size. My problem with if not li: ... is that it gives the false impression that li is a boolean variable.This is the first google hit for "python test empty array" and similar queries, plus other people seem to be generalizing the question beyond just lists, so I thought I'd add a caveat for a different type of sequence that a lot of people might use.You need to be careful with NumPy arrays, because other methods that work fine for lists or other standard containers fail for NumPy arrays.  I explain why below, but in short, the preferred method is to use size.The "pythonic" way fails with NumPy arrays because NumPy tries to cast the array to an array of bools, and if x tries to evaluate all of those bools at once for some kind of aggregate truth value.  But this doesn't make any sense, so you get a ValueError:But at least the case above tells you that it failed.  If you happen to have a NumPy array with exactly one element, the if statement will "work", in the sense that you don't get an error.  However, if that one element happens to be 0 (or 0.0, or False, ...), the if statement will incorrectly result in False:But clearly x exists and is not empty!  This result is not what you wanted.For example,returns 1, even though the array has zero elements.As explained in the SciPy FAQ, the correct method in all cases where you know you have a NumPy array is to use if x.size:If you're not sure whether it might be a list, a NumPy array, or something else, you could combine this approach with the answer @dubiousjim gives to make sure the right test is used for each type.  Not very "pythonic", but it turns out that NumPy intentionally broke pythonicity in at least this sense.If you need to do more than just check if the input is empty, and you're using other NumPy features like indexing or math operations, it's probably more efficient (and certainly more common) to force the input to be a NumPy array.  There are a few nice functions for doing this quickly — most importantly numpy.asarray.  This takes your input, does nothing if it's already an array, or wraps your input into an array if it's a list, tuple, etc., and optionally converts it to your chosen dtype.  So it's very quick whenever it can be, and it ensures that you just get to assume the input is a NumPy array.  We usually even just use the same name, as the conversion to an array won't make it back outside of the current scope:This will make the x.size check work in all cases I see on this page.Place the list in a boolean context (for example, with an if or while statement). It will test False if it is empty, and True otherwise. For example:PEP 8, the official Python style guide for Python code in Python's standard library, asserts:We should expect that standard library code should be as performant and correct as possible. But why is that the case, and why do we need this guidance?I frequently see code like this from experienced programmers new to Python:And users of lazy languages may be tempted to do this:These are correct in their respective other languages. And this is even semantically correct in Python. But we consider it un-Pythonic because Python supports these semantics directly in the list object's interface via boolean coercion.From the docs (and note specifically the inclusion of the empty list, []):And the datamodel documentation:and So instead of this:or this:Do this:Does it pay off? (Note that less time to perform an equivalent operation is better:)For scale, here's the cost of calling the function and constructing and returning an empty list, which you might subtract from the costs of the emptiness checks used above:We see that either checking for length with the builtin function len compared to 0 or checking against an empty list is much less performant than using the builtin syntax of the language as documented.Why?For the len(a) == 0 check:First Python has to check the globals to see if len is shadowed. Then it must call the function, load 0, and do the equality comparison in Python (instead of with C):And for the [] == [] it has to build an unnecessary list and then, again, do the comparison operation in Python's virtual machine (as opposed to C)The "Pythonic" way is a much simpler and faster check since the length of the list is cached in the object instance header:From the c source in Include/listobject.h:IPython magic, %timeit, is not entirely useless here:We can see there's a bit of linear cost for each additional not here. We want to see the costs, ceteris paribus, that is, all else equal - where all else is minimized as far as possible:Now let's look at the case for an unempty list:What we can see here is that it makes little difference whether you pass in an actual bool to the condition check or the list itself, and if anything, giving the list, as is, is faster.Python is written in C; it uses its logic at the C level. Anything you write in Python will be slower. And it will likely be orders of magnitude slower unless you're using the mechanisms built into Python directly.An empty list is itself considered false in true value testing (see python documentation):@Daren ThomasYour duckCollection should implement __nonzero__ or __len__ so the if a: will work without problems.Patrick's (accepted) answer is right: if not a: is the right way to do it. Harley Holcombe's answer is right that this is in the PEP 8 style guide. But what none of the answers explain is why it's a good idea to follow the idiom—even if you personally find it's not explicit enough or confusing to Ruby users or whatever.Python code, and the Python community, has very strong idioms. Following those idioms makes your code easier to read for anyone experienced in Python. And when you violate those idioms, that's a strong signal.It's true that if not a: doesn't distinguish empty lists from None, or numeric 0, or empty tuples, or empty user-created collection types, or empty user-created not-quite-collection types, or single-element NumPy array acting as scalars with falsey values, etc. And sometimes it's important to be explicit about that. And in that case, you know what you want to be explicit about, so you can test for exactly that. For example, if not a and a is not None: means "anything falsey except None", while if len(a) != 0: means "only empty sequences—and anything besides a sequence is an error here", and so on. Besides testing for exactly what you want to test, this also signals to the reader that this test is important.But when you don't have anything to be explicit about, anything other than if not a: is misleading the reader. You're signaling something as important when it isn't. (You may also be making the code less flexible, or slower, or whatever, but that's all less important.) And if you habitually mislead the reader like this, then when you do need to make a distinction, it's going to pass unnoticed because you've been "crying wolf" all over your code.No one seems to have addressed questioning your need to test the list in the first place.  Because you provided no additional context, I can imagine that you may not need to do this check in the first place, but are unfamiliar with list processing in Python.I would argue that the most pythonic way is to not check at all, but rather to just process the list.  That way it will do the right thing whether empty or full.This has the benefit of handling any contents of a, while not requiring a specific check for emptiness.  If a is empty, the dependent block will not execute and the interpreter will fall through to the next line.If you do actually need to check the array for emptiness, the other answers are sufficient.len() is an O(1) operation for Python lists, strings, dicts, and sets. Python internally keeps track of the number of elements in these containers.JavaScript has a similar notion of truthy/falsy.I had written:which was voted -1. I'm not sure if that's because readers objected to the strategy or thought the answer wasn't helpful as presented. I'll pretend it was the latter, since---whatever counts as "pythonic"---this is the correct strategy. Unless you've already ruled out, or are prepared to handle cases where a is, for example, False, you need a test more restrictive than just if not a:. You could use something like this:the first test is in response to @Mike's answer, above. The third line could also be replaced with:if you only want to accept instances of particular types (and their subtypes), or with:You can get away without the explicit type check, but only if the surrounding context already assures you that a is a value of the types you're prepared to handle, or if you're sure that types you're not prepared to handle are going to raise errors (e.g., a TypeError if you call len on a value for which it's undefined) that you're prepared to handle. In general, the "pythonic" conventions seem to go this last way. Squeeze it like a duck and let it raise a DuckError if it doesn't know how to quack. You still have to think about what type assumptions you're making, though, and whether the cases you're not prepared to handle properly really are going to error out in the right places. The Numpy arrays are a good example where just blindly relying on len or the boolean typecast may not do precisely what you're expecting.From documentation on truth value testing:All values other than what is listed here are considered TrueAs can be seen, empty list [] is falsy, so doing what would be done to a boolean value sounds most efficient:Here are a few ways you can check if a list is empty:1) The pretty simple pythonic way:In Python, empty containers such as lists,tuples,sets,dicts,variables etc are seen as False. One could simply treat the list as a predicate (returning a Boolean value). And  a True value would indicate that it's non-empty.2) A much explicit way: using the len() to find the length and check if it equals to 0:3) Or comparing it to an anonymous empty list:4) Another yet silly way to do is using exception and iter():I prefer the following:Method 1 (Preferred):Method 2 :Method 3: It is sometimes good to test for None and for emptiness separately as those are two different states. The code above produces the following output:Although it's worth nothing that None is falsy. So if you don't want to separate test for None-ness, you don't have to do that. produces expectedMany answers have been given, and a lot of them are pretty good. I just wanted to add that the checkwill also pass for None and other types of empty structures. If you truly want to check for an empty list, you can do this:we could use a simple if else:Being inspired by @dubiousjim's solution, I propose to use an additional general check of whether is it something iterableNote: a string is considered to be iterable. - add and not isinstance(a,(str,unicode)) if you want the empty string to be excludedTest:If you want to check if a list is empty:If you want to check whether all the values in list is empty. However it will be True for an empty list:If you want to use both cases together:Now you can use:You can even try using bool() like thisI love this way for checking list is empty or not. Very handy and useful.From python3 onwards you can useto check if the list is emptyEDIT : This works with python2.7 too.. I am not sure why there are so many complicated answers.

It's pretty clear and straightforwarda little more practical:and shertest version:Simple way is checking the length is equal zero.Simply use is_empty() or make function like:- It can be used for any data_structure like a list,tuples, dictionary and many more. By these, you can call it many times using just is_empty(any_structure). The truth value of an empty list is False whereas for a non-empty list it is True.What brought me here is a special use-case: I actually wanted a function to tell me if a list is empty or not. I wanted to avoid writing my own function or using a lambda-expression here (because it seemed like it should be simple enough):And, of course, there is a very natural way to do it:Of course, do not use bool in if (i.e., if bool(L):) because it's implied. But, for the cases when "is not empty" is explicitly needed as a function, bool is the best choice.Hope this helps.

## How to make a flat list out of list of lists?

Emma

[How to make a flat list out of list of lists?](https://stackoverflow.com/questions/952914/how-to-make-a-flat-list-out-of-list-of-lists)

I wonder whether there is a shortcut to make a simple list out of list of lists in Python.I can do that in a for loop, but maybe there is some cool "one-liner"? I tried it with reduce(), but I get an error.CodeError message

2009-06-04 20:30:05Z

I wonder whether there is a shortcut to make a simple list out of list of lists in Python.I can do that in a for loop, but maybe there is some cool "one-liner"? I tried it with reduce(), but I get an error.CodeError messageGiven a list of lists l,flat_list = [item for sublist in l for item in sublist]which means:is faster than the shortcuts posted so far. (l is the list to flatten.)Here is the corresponding function:As evidence, you can use the timeit module in the standard library:Explanation: the shortcuts based on + (including the implied use in sum) are, of necessity, O(L**2) when there are L sublists -- as the intermediate result list keeps getting longer, at each step a new intermediate result list object gets allocated, and all the items in the previous intermediate result must be copied over (as well as a few new ones added at the end). So, for simplicity and without actual loss of generality, say you have L sublists of I items each: the first I items are copied back and forth L-1 times, the second I items L-2 times, and so on; total number of copies is I times the sum of x for x from 1 to L excluded, i.e., I * (L**2)/2.The list comprehension just generates one list, once, and copies each item over (from its original place of residence to the result list) also exactly once.You can use itertools.chain():Or you can use itertools.chain.from_iterable() which doesn't require unpacking the list with the * operator:This approach is arguably more readable than [item for sublist in l for item in sublist] and appears to be faster too:Note from the author: This is inefficient. But fun, because monoids are awesome. It's not appropriate for production Python code.This just sums the elements of iterable passed in the first argument, treating second argument as the initial value of the sum (if not given, 0 is used instead and this case will give you an error).Because you are summing nested lists, you actually get [1,3]+[2,4] as a result of sum([[1,3],[2,4]],[]), which is equal to [1,3,2,4].Note that only works on lists of lists. For lists of lists of lists, you'll need another solution.I tested most suggested solutions with perfplot (a pet project of mine, essentially a wrapper around timeit), and foundto be the fastest solution. (operator.iadd is equally fast.)Code to reproduce the plot:The extend() method in your example modifies x instead of returning a useful value (which reduce() expects).A faster way to do the reduce version would beHere is a general approach that applies to numbers, strings, nested lists and mixed containers.CodeNotes: DemoReference...Pandas:...Itertools:...Matplotlib...Unipath:...Setuptools:If you want to flatten a data-structure where you don't know how deep it's nested you could use iteration_utilities.deepflatten1It's a generator so you need to cast the result to a list or explicitly iterate over it.To flatten only one level and if each of the items is itself iterable you can also use iteration_utilities.flatten which itself is just a thin wrapper around itertools.chain.from_iterable:Just to add some timings (based on Nico Schlömer answer that didn't include the function presented in this answer):It's a log-log plot to accommodate for the huge range of values spanned. For qualitative reasoning: Lower is better.The results show that if the iterable contains only a few inner iterables then sum will be fastest, however for long iterables only the itertools.chain.from_iterable, iteration_utilities.deepflatten or the nested comprehension have reasonable performance with itertools.chain.from_iterable being the fastest (as already noticed by Nico Schlömer).1 Disclaimer: I'm the author of that libraryI take my statement back. sum is not the winner. Although it is faster when the list is small. But the performance degrades significantly with larger lists. The sum version is still running for more than a minute and it hasn't done processing yet!For medium lists:Using small lists and timeit: number=1000000There seems to be a confusion with operator.add! When you add two lists together, the correct term for that is concat, not add. operator.concat is what you need to use.If you're thinking functional, it is as easy as this::You see reduce respects the sequence type, so when you supply a tuple, you get back a tuple. Let's try with a list::Aha, you get back a list.How about performance::from_iterable is pretty fast! But it's no comparison to reduce with concat.Why do you use extend?This should work fine.Consider installing the more_itertools package.It ships with an implementation for flatten (source, from the itertools recipes):As of version 2.4, you can flatten more complicated, nested iterables with more_itertools.collapse (source, contributed by  abarnet).The reason your function didn't work is because the extend extends an array in-place and doesn't return it. You can still return x from lambda, using something like this:Note: extend is more efficient than + on lists.matplotlib.cbook.flatten() will work for nested lists even if they nest more deeply than the example.Result:This is 18x faster than underscore._.flatten:Recursive versionThe accepted answer did not work for me when dealing with text-based lists of variable lengths. Here is an alternate approach that did work for me.An bad feature of Anil's function above is that it requires the user to always manually specify the second argument to be an empty list []. This should instead be a default. Due to the way Python objects work, these should be set inside the function, not in the arguments.Here's a working function:Testing:Following seem simplest to me:One can also use NumPy's flat:Edit 11/02/2016: Only works when sublists have identical dimensions.You can use numpy :

flat_list = list(np.concatenate(list_of_list))If you are willing to give up a tiny amount of speed for a cleaner look, then you could use numpy.concatenate().tolist() or numpy.concatenate().ravel().tolist():You can find out more here in the docs numpy.concatenate and numpy.ravelSimple code for underscore.py package fanIt solves all flatten problems (none list item or complex nesting)You can install underscore.py with pipNote: Below applies to Python 3.3+ because it uses yield_from.  six is also a third-party package, though it is stable.  Alternately, you could use sys.version.In the case of obj = [[1, 2,], [3, 4], [5, 6]], all of the solutions here are good, including list comprehension and itertools.chain.from_iterable.However, consider this slightly more complex case:There are several problems here:You can remedy this as follows:Here, you check that the sub-element (1) is iterable with Iterable, an ABC from itertools, but also want to ensure that (2) the element is not "string-like."This Code also works fine as it just extend the list all the way. Although it is much similar but only have one for loop. So It have less complexity than adding 2 for loops.The advantage of this solution over most others here is that if you have a list like:while most other solutions throw an error this solution handles them.Fastest solution I have found (for large list anyway):Done! You can of course turn it back into a list by executing list(l)This may not be the most efficient way but I thought to put a one-liner (actually a two-liner). Both versions will work on arbitrary hierarchy nested lists, and exploits language features (Python3.5) and recursion.The output isThis works in a depth first manner. The recursion goes down until it finds a non-list element, then extends the local variable flist and then rolls back it to the parent. Whenever flist is returned, it is extended to the parent's flist in the list comprehension. Therefore, at the root, a flat list is returned.The above one creates several local lists and returns them which are used to extend the parent's list. I think the way around for this may be creating a gloabl flist, like below.The output is againAlthough I am not sure at this time about the efficiency.another fun way to do this:

## Catch multiple exceptions in one line (except block)

inspectorG4dget

[Catch multiple exceptions in one line (except block)](https://stackoverflow.com/questions/6470428/catch-multiple-exceptions-in-one-line-except-block)

I know that I can do:I can also do this:But if I want to do the same thing inside two different exceptions, the best I can think of right now is to do this:Is there any way that I can do something like this (since the action to take in both exceptions is to say please):Now this really won't work, as it matches the syntax for:So, my effort to catch the two distinct exceptions doesn't exactly come through.Is there a way to do this?

2011-06-24 15:55:08Z

I know that I can do:I can also do this:But if I want to do the same thing inside two different exceptions, the best I can think of right now is to do this:Is there any way that I can do something like this (since the action to take in both exceptions is to say please):Now this really won't work, as it matches the syntax for:So, my effort to catch the two distinct exceptions doesn't exactly come through.Is there a way to do this?From Python Documentation:Or, for Python 2 only:Separating the exception from the variable with a comma will still work in Python 2.6 and 2.7, but is now deprecated and does not work in Python 3; now you should be using as.Do this:The parentheses are required due to older syntax that used the commas to assign the error object to a name. The as keyword is used for the assignment. You can use any name for the error object, I prefer error personally.To do this in a manner currently and forward compatible with Python, you need to separate the Exceptions with commas and wrap them with parentheses to differentiate from earlier syntax that assigned the exception instance to a variable name by following the Exception type to be caught with a comma. Here's an example of simple usage:I'm specifying only these exceptions to avoid hiding bugs, which if I encounter I expect the full stack trace from.This is documented here: https://docs.python.org/tutorial/errors.htmlYou can assign the exception to a variable, (e is common, but you might prefer a more verbose variable if you have long exception handling or your IDE only highlights selections larger than that, as mine does.) The instance has an args attribute. Here is an example:Note that in Python 3, the err object falls out of scope when the except block is concluded.You may see code that assigns the error with a comma. This usage, the only form available in Python 2.5 and earlier, is deprecated, and if you wish your code to be forward compatible in Python 3, you should update the syntax to use the new form:If you see the comma name assignment in your codebase, and you're using Python 2.5 or higher, switch to the new way of doing it so your code remains compatible when you upgrade.The accepted answer is really 4 lines of code, minimum:The try, except, pass lines can be handled in a single line with the suppress context manager, available in Python 3.4:So when you want to pass on certain exceptions, use suppress.From Python documentation -> 8.3 Handling Exceptions:If you frequently use a large number of exceptions, you can pre-define a tuple, so you don't have to re-type them many times. NOTES: One of the way to do this is..and another way is to create method which performs task executed by except block and call it through all of the except block that you write..I know that second one is not the best way to do this, but i'm just showing number of ways to do this thing.

## How do I pass a variable by reference?

David Sykes

[How do I pass a variable by reference?](https://stackoverflow.com/questions/986006/how-do-i-pass-a-variable-by-reference)

The Python documentation seems unclear about whether parameters are passed by reference or value, and the following code produces the unchanged value 'Original'Is there something I can do to pass the variable by actual reference?

2009-06-12 10:23:51Z

The Python documentation seems unclear about whether parameters are passed by reference or value, and the following code produces the unchanged value 'Original'Is there something I can do to pass the variable by actual reference?Arguments are passed by assignment. The rationale behind this is twofold:So:To make it even more clear, let's have some examples. Let's try to modify the list that was passed to a method:Output:Since the parameter passed in is a reference to outer_list, not a copy of it, we can use the mutating list methods to change it and have the changes reflected in the outer scope.Now let's see what happens when we try to change the reference that was passed in as a parameter:Output:Since the the_list parameter was passed by value, assigning a new list to it had no effect that the code outside the method could see. The the_list was a copy of the outer_list reference, and we had the_list point to a new list, but there was no way to change where outer_list pointed.It's immutable, so there's nothing we can do to change the contents of the stringNow, let's try to change the referenceOutput:Again, since the the_string parameter was passed by value, assigning a new string to it had no effect that the code outside the method could see. The the_string was a copy of the outer_string reference, and we had the_string point to a new string, but there was no way to change where outer_string pointed.I hope this clears things up a little.EDIT: It's been noted that this doesn't answer the question that @David originally asked, "Is there something I can do to pass the variable by actual reference?". Let's work on that.As @Andrea's answer shows, you could return the new value. This doesn't change the way things are passed in, but does let you get the information you want back out:If you really wanted to avoid using a return value, you could create a class to hold your value and pass it into the function or use an existing class, like a list:Although this seems a little cumbersome.The problem comes from a misunderstanding of what variables are in Python. If you're used to most traditional languages, you have a mental model of what happens in the following sequence:You believe that a is a memory location that stores the value 1, then is updated to store the value 2. That's not how things work in Python. Rather, a starts as a reference to an object with the value 1, then gets reassigned as a reference to an object with the value 2. Those two objects may continue to coexist even though a doesn't refer to the first one anymore; in fact they may be shared by any number of other references within the program.When you call a function with a parameter, a new reference is created that refers to the object passed in. This is separate from the reference that was used in the function call, so there's no way to update that reference and make it refer to a new object. In your example:self.variable is a reference to the string object 'Original'. When you call Change you create a second reference var to the object. Inside the function you reassign the reference var to a different string object 'Changed', but the reference self.variable is separate and does not change.The only way around this is to pass a mutable object. Because both references refer to the same object, any changes to the object are reflected in both places.I found the other answers rather long and complicated, so I created this simple diagram to explain the way Python treats variables and parameters.

It is neither pass-by-value or pass-by-reference - it is call-by-object. See this, by Fredrik Lundh: http://effbot.org/zone/call-by-object.htmHere is a significant quote:In your example, when the Change method is called--a namespace is created for it; and var becomes a name, within that namespace, for the string object 'Original'. That object then has a name in two namespaces. Next, var = 'Changed' binds var to a new string object, and thus the method's namespace forgets about 'Original'. Finally, that namespace is forgotten, and the string 'Changed' along with it.Think of stuff being passed by assignment instead of by reference/by value. That way, it is always clear, what is happening as long as you understand what happens during the normal assignment.So, when passing a list to a function/method, the list is assigned to the parameter name. Appending to the list will result in the list being modified. Reassigning the list inside the function will not change the original list, since:Since immutable types cannot be modified, they seem like being passed by value - passing an int into a function means assigning the int to the function's parameter. You can only ever reassign that, but it won't change the original variables value.Effbot (aka Fredrik Lundh) has described Python's variable passing style as call-by-object:  http://effbot.org/zone/call-by-object.htmObjects are allocated on the heap and pointers to them can be passed around anywhere.  Hope that clarifies the issue for you. Technically, Python always uses pass by reference values. I am going to repeat my other answer to support my statement.Python always uses pass-by-reference values. There isn't any exception. Any variable assignment means copying the reference value. No exception. Any variable is the name bound to the reference value. Always.You can think about a reference value as the address of the target object. The address is automatically dereferenced when used. This way, working with the reference value, it seems you work directly with the target object. But there always is a reference in between, one step more to jump to the target.Here is the example that proves that Python uses passing by reference:If the argument was passed by value, the outer lst could not be modified. The green are the target objects (the black is the value stored inside, the red is the object type), the yellow is the memory with the reference value inside -- drawn as the arrow. The blue solid arrow is the reference value that was passed to the function (via the dashed blue arrow path). The ugly dark yellow is the internal dictionary. (It actually could be drawn also as a green ellipse. The colour and the shape only says it is internal.)You can use the id() built-in function to learn what the reference value is (that is, the address of the target object).In compiled languages, a variable is a memory space that is able to capture the value of the type. In Python, a variable is a name (captured internally as a string) bound to the reference variable that holds the reference value to the target object. The name of the variable is the key in the internal dictionary, the value part of that dictionary item stores the reference value to the target.Reference values are hidden in Python. There isn't any explicit user type for storing the reference value. However, you can use a list element (or element in any other suitable container type) as the reference variable, because all containers do store the elements also as references to the target objects. In other words, elements are actually not contained inside the container -- only the references to elements are.The key to understanding parameter passing is to stop thinking about "variables". There are names and objects in Python and together they

appear like variables, but it is useful to always distinguish the three.That is all there is to it. Mutability is irrelevant for this question.Example: This binds the name a to an object of type integer that holds the value 1.This binds the name b to the same object that the name x is currently bound to.

Afterwards, the name b has nothing to do with the name x any more.See sections 3.1 and 4.2 in the Python 3 language reference.In the code shown in the question, the statement self.Change(self.variable) binds the name var (in the scope of function Change) to the object that holds the value 'Original' and the assignment var = 'Changed' (in the body of function Change) assigns that same name again: to some other object (that happens to hold a string as well but could have been something else entirely).(edit 2019-04-28)So if the thing you want to change is a mutable object, there is no problem, as everything is effectively passed by reference.If it is an immutable object (e.g. a bool, number, string), the way to go is to wrap it in a mutable object.

The quick-and-dirty solution for this is a one-element list (instead of self.variable, pass [self.variable] and in the function modify var[0]).

The more pythonic approach would be to introduce a trivial, one-attribute class. The function receives an instance of the class and manipulates the attribute.A simple trick I normally use is to just wrap it in a list:(Yeah I know this can be inconvenient, but sometimes it is simple enough to do this.)(edit - Blair has updated his enormously popular answer so that it is now accurate)I think it is important to note that the current post with the most votes (by Blair Conrad), while being correct with respect to its result, is misleading and is borderline incorrect based on its definitions.  While there are many languages (like C) that allow the user to either pass by reference or pass by value, Python is not one of them.David Cournapeau's answer points to the real answer and explains why the behavior in Blair Conrad's post seems to be correct while the definitions are not.To the extent that Python is pass by value, all languages are pass by value since some piece of data (be it a "value" or a "reference") must be sent. However, that does not mean that Python is pass by value in the sense that a C programmer would think of it.If you want the behavior, Blair Conrad's answer is fine.  But if you want to know the nuts and bolts of why Python is neither pass by value or pass by reference, read David Cournapeau's answer.You got some really good answers here.In this case the variable titled var in the method Change is assigned a reference to self.variable, and you immediately assign a string to var. It's no longer pointing to self.variable. The following code snippet shows what would happen if you modify the data structure pointed to by var and self.variable, in this case a list:I'm sure someone else could clarify this further.Python’s pass-by-assignment scheme isn’t quite the same as C++’s reference parameters option, but it turns out to be very similar to the argument-passing model of the C language (and others) in practice:As you can state you need to have a mutable object, but let me suggest you to check over the global variables as they can help you or even solve this kind of issue!http://docs.python.org/3/faq/programming.html#what-are-the-rules-for-local-and-global-variables-in-pythonexample:A lot of insights in answers here, but i think an additional point is not clearly mentioned here explicitly.   Quoting from python documentation https://docs.python.org/2/faq/programming.html#what-are-the-rules-for-local-and-global-variables-in-python  "In Python, variables that are only referenced inside a function are implicitly global. If a variable is assigned a new value anywhere within the function’s body, it’s assumed to be a local. If a variable is ever assigned a new value inside the function, the variable is implicitly local, and you need to explicitly declare it as ‘global’.

Though a bit surprising at first, a moment’s consideration explains this. On one hand, requiring global for assigned variables provides a bar against unintended side-effects. On the other hand, if global was required for all global references, you’d be using global all the time. You’d have to declare as global every reference to a built-in function or to a component of an imported module. This clutter would defeat the usefulness of the global declaration for identifying side-effects."Even when passing a mutable object to a function this still applies. And to me clearly explains the reason for the difference in behavior between assigning to the object and operating on the object in the function.gives:The assignment to an global variable that is not declared global therefore creates a new local object and breaks the link to the original object.Here is the simple (I hope) explanation of the concept pass by object used in Python.

Whenever you pass an object to the function, the object itself is passed (object in Python is actually what you'd call a value in other programming languages) not the reference to this object. In other words, when you call:The actual object - [0, 1] (which would be called a value in other programming languages) is being passed. So in fact the function change_me will try to do something like:which obviously will not change the object passed to the function. If the function looked like this:Then the call would result in:which obviously will change the object. This answer explains it well.Aside from all the great explanations on how this stuff works in Python, I don't see a simple suggestion for the problem. As you seem to do create objects and instances, the pythonic way of handling instance variables and changing them is the following:In instance methods, you normally refer to self to access instance attributes. It is normal to set instance attributes in __init__ and read or change them in instance methods. That is also why you pass self als the first argument to def Change.Another solution would be to create a static method like this:There is a little trick to pass an object by reference, even though the language doesn't make it possible. It works in Java too, it's the list with one item. ;-)It's an ugly hack, but it works. ;-PI used the following method to quickly convert a couple of Fortran codes to Python.  True, it's not pass by reference as the original question was posed, but is a simple work around in some cases.While pass by reference is nothing that fits well into python and should be rarely used there are some workarounds that actually can work to get the object currently assigned to a local variable or even reassign a local variable from inside of a called function.The basic idea is to have a function that can do that access and can be passed as object into other functions or stored in a class.One way is to use global (for global variables) or nonlocal (for local variables in a function) in a wrapper function.The same idea works for reading and deleting a variable.For just reading there is even a shorter way of just using lambda: x which returns a callable that when called returns the current value of x. This is somewhat like "call by name" used in languages in the distant past.Passing 3 wrappers to access a variable is a bit unwieldy so those can be wrapped into a class that has a proxy attribute:Pythons "reflection" support makes it possible to get a object that is capable of reassigning a name/variable in a given scope without defining functions explicitly in that scope:Here the ByRef class wraps a dictionary access. So attribute access to wrapped is translated to a item access in the passed dictionary. By passing the result of the builtin locals and the name of a local variable this ends up accessing a local variable. The python documentation as of 3.5 advises that changing the dictionary might not work but it seems to work for me.given the way python handles values and references to them, the only way you can reference an arbitrary instance attribute is by name:in real code you would, of course, add error checking on the dict lookup.Pass-By-Reference in Python is quite different from the concept of pass by reference in C++/Java. Since your example happens to be object-oriented, you could make the following change to achieve a similar result:Since dictionaries are passed by reference, you can use a dict variable to store any referenced values inside it.Since it seems to be nowhere mentioned an approach to simulate references as known from e.g. C++ is to use an "update" function and pass that instead of the actual variable (or rather, "name"):This is mostly useful for "out-only references" or in a situation with multiple threads / processes (by making the update function thread / multiprocessing safe).Obviously the above does not allow reading the value, only updating it.You can merely use an empty class as an instance to store reference objects because internally object attributes are stored in an instance dictionary. See the example.

## 「Least Astonishment」and the Mutable Default Argument

Stefano Borini

[「Least Astonishment」and the Mutable Default Argument](https://stackoverflow.com/questions/1132941/least-astonishment-and-the-mutable-default-argument)

Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:Python novices would expect this function to always return a list with only one element: [5]. The result is instead very different, and very astonishing (for a novice):A manager of mine once had his first encounter with this feature, and called it "a dramatic design flaw" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?)Edit: Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function or "together" with it?Doing the binding inside the function would mean that x is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the def line would be "hybrid" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.

2009-07-15 18:00:37Z

Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:Python novices would expect this function to always return a list with only one element: [5]. The result is instead very different, and very astonishing (for a novice):A manager of mine once had his first encounter with this feature, and called it "a dramatic design flaw" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?)Edit: Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function or "together" with it?Doing the binding inside the function would mean that x is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the def line would be "hybrid" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.Actually, this is not a design flaw, and it is not because of internals, or performance.

It comes simply from the fact that functions in Python are first-class objects, and not only a piece of code.As soon as you get to think into this way, then it completely makes sense: a function is an object being evaluated on its definition; default parameters are kind of "member data" and therefore their state may change from one call to the other - exactly as in any other object.In any case, Effbot has a very nice explanation of the reasons for this behavior in Default Parameter Values in Python.

I found it very clear, and I really suggest reading it for a better knowledge of how function objects work.Suppose you have the following codeWhen I see the declaration of eat, the least astonishing thing is to think that if the first parameter is not given, that it will be equal to the tuple ("apples", "bananas", "loganberries")However, supposed later on in the code, I do something likethen if default parameters were bound at function execution rather than function declaration then I would be astonished (in a very bad way) to discover that fruits had been changed.  This would be more astonishing IMO than discovering that your foo function above was mutating the list.The real problem lies with mutable variables, and all languages have this problem to some extent. Here's a question: suppose in Java I have the following code:Now, does my map use the value of the StringBuffer key when it was placed into the map, or does it store the key by reference?  Either way, someone is astonished; either the person who tried to get the object out of the Map using a value identical to the one they put it in with, or the person who can't seem to retrieve their object even though the key they're using is literally the same object that was used to put it into the map (this is actually why Python doesn't allow its mutable built-in data types to be used as dictionary keys).Your example is a good one of a case where Python newcomers will be surprised and bitten.  But I'd argue that if we "fixed" this, then that would only create a different situation where they'd be bitten instead, and that one would be even less intuitive. Moreover, this is always the case when dealing with mutable variables; you always run into cases where someone could intuitively expect one or the opposite behavior depending on what code they're writing.I personally like Python's current approach: default function arguments are evaluated when the function is defined and that object is always the default. I suppose they could special-case using an empty list, but that kind of special casing would cause even more astonishment, not to mention be backwards incompatible.The relevant part of the documentation:I know nothing about the Python interpreter inner workings (and I'm not an expert in compilers and interpreters either) so don't blame me if I propose anything unsensible or impossible.Provided that python objects are mutable I think that this should be taken into account when designing the default arguments stuff.

When you instantiate a list:you expect to get a new list referenced by a.Why should the a=[] ininstantiate a new list on function definition and not on invocation?

It's just like you're asking "if the user doesn't provide the argument then instantiate a new list and use it as if it was produced by the caller".

I think this is ambiguous instead:user, do you want a to default to the datetime corresponding to when you're defining or executing x?

In this case, as in the previous one, I'll keep the same behaviour as if the default argument "assignment" was the first instruction of the function (datetime.now() called on function invocation).

On the other hand, if the user wanted the definition-time mapping he could write:I know, I know: that's a closure. Alternatively Python might provide a keyword to force definition-time binding:Well, the reason is quite simply that bindings are done when code is executed, and the function definition is executed, well... when the functions is defined.Compare this:This code suffers from the exact same unexpected happenstance. bananas is a class attribute, and hence, when you add things to it, it's added to all instances of that class. The reason is exactly the same.It's just "How It Works", and making it work differently in the function case would probably be complicated, and in the class case likely impossible, or at least slow down object instantiation a lot, as you would have to keep the class code around and execute it when objects are created.Yes, it is unexpected. But once the penny drops, it fits in perfectly with how Python works in general. In fact, it's a good teaching aid, and once you understand why this happens, you'll grok python much better.That said it should feature prominently in any good Python tutorial. Because as you mention, everyone runs into this problem sooner or later.I'm really surprised no one has performed the insightful introspection offered by Python (2 and 3 apply) on callables. Given a simple little function func defined as:When Python encounters it, the first thing it will do is compile it in order to create a code object for this function. While this compilation step is done, Python evaluates* and then stores the default arguments (an empty list [] here) in the function object itself. As the top answer mentioned: the list a can now be considered a member of the function func.So, let's do some introspection, a before and after to examine how the list gets expanded inside the function object. I'm using Python 3.x for this, for Python 2 the same applies (use __defaults__ or func_defaults in Python 2; yes, two names for the same thing).After Python executes this definition it will take any default parameters specified (a = [] here) and cram them in the __defaults__ attribute for the function object (relevant section: Callables):     O.k, so an empty list as the single entry in __defaults__, just as expected. Let's now execute this function:Now, let's see those __defaults__ again: Astonished? The value inside the object changes! Consecutive calls to the function will now simply append to that embedded list object:So, there you have it, the reason why this 'flaw' happens, is because default arguments are part of the function object. There's nothing weird going on here, it's all just a bit surprising.The common solution to combat this is to use None as the default and then initialize in the function body:Since the function body is executed anew each time, you always get a fresh new empty list if no argument was passed for a.To further verify that the list in __defaults__ is the same as that used in the function func you can just change your function to return the id of the list a used inside the function body. Then, compare it to the list in __defaults__ (position [0] in __defaults__) and you'll see how these are indeed refering to the same list instance:All with the power of introspection! * To verify that Python evaluates the default arguments during compilation of the function, try executing the following:as you'll notice, input() is called before the process of building the function and binding it to the name bar is made.I used to think that creating the objects at runtime would be the better approach.  I'm less certain now, since you do lose some useful features, though it may be worth it regardless simply to prevent newbie confusion.  The disadvantages of doing so are:1. PerformanceIf call-time evaluation is used, then the expensive function is called every time your function is used without an argument.  You'd either pay an expensive price on each call, or need to manually cache the value externally, polluting your namespace and adding verbosity.2. Forcing bound parametersA useful trick is to bind parameters of a lambda to the current binding of a variable when the lambda is created.  For example:This returns a list of functions that return 0,1,2,3... respectively.  If the behaviour is changed, they will instead bind i to the call-time value of i, so you would get a list of functions that all returned 9.The only way to implement this otherwise would be to create a further closure with the i bound, ie:3. IntrospectionConsider the code:We can get information about the arguments and defaults using the inspect module, which This information is very useful for things like document generation, metaprogramming, decorators etc.Now, suppose the behaviour of defaults could be changed so that this is the equivalent of:However, we've lost the ability to introspect, and see what the default arguments are.  Because the objects haven't been constructed, we can't ever get hold of them without actually calling the function.  The best we could do is to store off the source code and return that as a string.This behavior is easy explained by:So:What you're asking is why this:isn't internally equivalent to this:except for the case of explicitly calling func(None, None), which we'll ignore.In other words, instead of evaluating default parameters, why not store each of them, and evaluate them when the function is called?One answer is probably right there--it would effectively turn every function with default parameters into a closure.  Even if it's all hidden away in the interpreter and not a full-blown closure, the data's got to be stored somewhere.  It'd be slower and use more memory.1)  The so-called problem of "Mutable Default Argument" is in general a special example demonstrating that:

"All functions with this problem suffer also from similar side effect problem on the actual parameter,"

That is against the rules of functional programming, usually undesiderable and should be fixed both together.Example:Solution:  a copy

An absolutely safe solution is to copy or deepcopy the input object first and then to do whatever with the copy.Many builtin mutable types have a copy method like some_dict.copy() or some_set.copy() or can be copied easy like somelist[:] or list(some_list). Every object can be also copied by copy.copy(any_object) or more thorough by copy.deepcopy() (the latter useful if the mutable object is composed from mutable objects). Some objects are fundamentally based on side effects like "file" object and can not be meaningfully reproduced by copy. copyingExample problem for a similar SO questionIt shouldn't be neither saved in any public attribute of an instance returned by this function. (Assuming that private attributes of instance should not be modified from outside of this class or subclasses by convention. i.e. _var1 is a private attribute )Conclusion:

Input parameters objects shouldn't be modified in place (mutated) nor they should not be binded into an object returned by the function. (If we prefere programming without side effects which is strongly recommended. see Wiki about "side effect" (The first two paragraphs are relevent in this context.)

.)2)

Only if the side effect on the actual parameter is required but unwanted on the default parameter then the useful solution is def ...(var1=None): if var1 is None: var1 = [] More..3) In some cases is the mutable behavior of default parameters useful.This actually has nothing to do with default values, other than that it often comes up as an unexpected behaviour when you write functions with mutable default values.No default values in sight in this code, but you get exactly the same problem.The problem is that foo is modifying a mutable variable passed in from the caller, when the caller doesn't expect this. Code like this would be fine if the function was called something like append_5; then the caller would be calling the function in order to modify the value they pass in, and the behaviour would be expected. But such a function would be very unlikely to take a default argument, and probably wouldn't return the list (since the caller already has a reference to that list; the one it just passed in).Your original foo, with a default argument, shouldn't be modifying a whether it was explicitly passed in or got the default value. Your code should leave mutable arguments alone unless it is clear from the context/name/documentation that the arguments are supposed to be modified. Using mutable values passed in as arguments as local temporaries is an extremely bad idea, whether we're in Python or not and whether there are default arguments involved or not.If you need to destructively manipulate a local temporary in the course of computing something, and you need to start your manipulation from an argument value, you need to make a copy.Already busy topic, but from what I read here, the following helped me realizing how it's working internally:It's a performance optimization.  As a result of this functionality, which of these two function calls do you think is faster?I'll give you a hint.  Here's the disassembly (see http://docs.python.org/library/dis.html):As you can see, there is a performance benefit when using immutable default arguments.  This can make a difference if it's a frequently called function or the default argument takes a long time to construct.  Also, bear in mind that Python isn't C.  In C you have constants that are pretty much free.  In Python you don't have this benefit.Default arguments get evaluated at the time the function is compiled into a function object. When used by the function, multiple times by that function, they are and remain the same object. When they are mutable, when mutated (for example, by adding an element to it) they remain mutated on consecutive calls.They stay mutated because they are the same object each time.Since the list is bound to the function when the function object is compiled and instantiated, this:is almost exactly equivalent to this:Here's a demonstration - you can verify that they are the same object each time they are referenced by example.pyand running it with python example.py:This order of execution is frequently confusing to new users of Python. If you understand the Python execution model, then it becomes quite expected. But this is why the usual instruction to new users is to create their default arguments like this instead:This uses the None singleton as a sentinel object to tell the function whether or not we've gotten an argument other than the default. If we get no argument, then we actually want to use a new empty list, [], as the default.As the tutorial section on control flow says:The shortest answer would probably be "definition is execution", therefore the whole argument makes no strict sense. As a more contrived example, you may cite this:Hopefully it's enough to show that not executing the default argument expressions at the execution time of the def statement isn't easy or doesn't make sense, or both.I agree it's a gotcha when you try to use default constructors, though.A simple workaround using NoneThis behavior is not surprising if you take the following into consideration:The role of (2) has been covered extensively in this thread. (1) is likely the astonishment causing factor, as this behavior is not "intuitive" when coming from other languages.(1) is described in the Python tutorial on classes. In an attempt to assign a value to a read-only class attribute:Look back to the original example and consider the above points:Here foo is an object and a is an attribute of foo (available at foo.func_defs[0]). Since a is a list, a is mutable and is thus a read-write attribute of foo. It is initialized to the empty list as specified by the signature when the function is instantiated, and is available for reading and writing as long as the function object exists. Calling foo without overriding a default uses that default's value from foo.func_defs. In this case, foo.func_defs[0] is used for a within function object's code scope. Changes to a change foo.func_defs[0], which is part of the foo object and persists between execution of the code in foo.Now, compare this to the example from the documentation on emulating the default argument behavior of other languages, such that the function signature defaults are used every time the function is executed:Taking (1) and (2) into account, one can see why this accomplishes the the desired behavior: I am going to demonstrate an alternative structure to pass a default list value to a function (it works equally well with dictionaries).  As others have extensively commented, the list parameter is bound to the function when it is defined as opposed to when it is executed.  Because lists and dictionaries are mutable, any alteration to this parameter will affect other calls to this function.  As a result, subsequent calls to the function will receive this shared list which may have been altered by any other calls to the function.  Worse yet, two parameters are using this function's shared parameter at the same time oblivious to the changes made by the other.Wrong Method (probably...):You can verify that they are one and the same object by using id:Per Brett Slatkin's "Effective Python: 59 Specific Ways to Write Better Python", Item 20: Use None and Docstrings to specify dynamic default arguments (p. 48)This implementation ensures that each call to the function either receives the default list or else the list passed to the function.Preferred Method:There may be legitimate use cases for the 'Wrong Method' whereby the programmer intended the default list parameter to be shared, but this is more likely the exception than the rule.The solutions here are:The second option is nice because users of the function can pass in a callable, which may be already existing (such as a type)When we do this:... we assign the argument a to an unnamed list, if the caller does not pass the value of a.To make things simpler for this discussion, let's temporarily give the unnamed list a name. How about pavlo ?At any time, if the caller doesn't tell us what a is, we reuse pavlo.If pavlo is mutable (modifiable), and foo ends up modifying it, an effect we notice the next time foo is called without specifying a.So this is what you see (Remember, pavlo is initialized to []):Now, pavlo is [5].Calling foo() again modifies pavlo again:Specifying a when calling foo() ensures pavlo is not touched.So, pavlo is still [5, 5].I sometimes exploit this behavior as an alternative to the following pattern:If singleton is only used by use_singleton, I like the following pattern as a replacement:I've used this for instantiating client classes that access external resources, and also for creating dicts or lists for memoization.Since I don't think this pattern is well known, I do put a short comment in to guard against future misunderstandings.You can get round this by replacing the object (and therefore the tie with the scope):Ugly, but it works.It may be true that:it is entirely consistent to hold to both of the features above and still make another point:The other answers, or at least some of them either make points 1 and 2 but not 3, or make point 3 and downplay points 1 and 2. But all three are true.It may be true that switching horses in midstream here would be asking for significant breakage, and that there could be more problems created by changing Python to intuitively handle Stefano's opening snippet. And it may be true that someone who knew Python internals well could explain a minefield of consequences. However,The existing behavior is not Pythonic, and Python is successful because very little about the language violates the principle of least astonishment anywhere near this badly. It is a real problem, whether or not it would be wise to uproot it. It is a design flaw. If you understand the language much better by trying to trace out the behavior, I can say that C++ does all of this and more; you learn a lot by navigating, for instance, subtle pointer errors. But this is not Pythonic: people who care about Python enough to persevere in the face of this behavior are people who are drawn to the language because Python has far fewer surprises than other language. Dabblers and the curious become Pythonistas when they are astonished at how little time it takes to get something working--not because of a design fl--I mean, hidden logic puzzle--that cuts against the intuitions of programmers who are drawn to Python because it Just Works.This is not a design flaw. Anyone who trips over this is doing something wrong.There are 3 cases I see where you might run into this problem:The example in the question could fall into category 1 or 3. It's odd that it both modifies the passed list and returns it; you should pick one or the other.This "bug" gave me a lot of overtime work hours! But I'm beginning to see a potential use of it (but I would have liked it to be at the execution time, still)I'm gonna give you what I see as a useful example.prints the followingJust change the function to be:I think the answer to this question lies in how python pass data to parameter (pass by value or by reference), not mutability or how python handle the "def" statement.A brief introduction. First, there are two type of data types in python, one is simple elementary data type, like numbers, and another data type is objects. Second, when passing data to parameters, python pass elementary data type by value, i.e., make a local copy of the value to a local variable, but pass object by reference, i.e., pointers to the object.Admitting the above two points, let's explain what happened to the python code. It's only because of passing by reference for objects, but has nothing to do with mutable/immutable, or arguably the fact that "def" statement is executed only once when it is defined.[] is an object, so python pass the reference of [] to a, i.e., a is only a pointer to [] which lies in memory as an object. There is only one copy of [] with, however, many references to it. For the first foo(), the list [] is changed to 1 by append method. But Note that there is only one copy of the list object and this object now becomes 1. When running the second foo(), what effbot webpage says (items is not evaluated any more) is wrong. a is evaluated to be the list object, although now the content of the object is 1. This is the effect of passing by reference! The result of foo(3) can be easily derived in the same way.To further validate my answer, let's take a look at two additional codes.====== No. 2 ========[] is an object, so is None (the former is mutable while the latter is immutable. But the mutability has nothing to do with the question). None is somewhere in the space but we know it's there and there is only one copy of None there. So every time foo is invoked, items is evaluated (as opposed to some answer that it is only evaluated once) to be None, to be clear, the reference (or the address) of None. Then in the foo, item is changed to [], i.e., points to another object which has a different address. ====== No. 3 =======The invocation of foo(1) make items point to a list object [] with an address, say, 11111111. the content of the list is changed to 1 in the foo function in the sequel, but the address is not changed, still 11111111. Then foo(2,[]) is coming. Although the [] in foo(2,[]) has the same content as the default parameter [] when calling foo(1), their address are different! Since we provide the parameter explicitly, items has to take the address of this new [], say 2222222, and return it after making some change. Now foo(3) is executed. since only x is provided, items has to take its default value again. What's the default value? It is set when defining the foo function: the list object located in 11111111. So the items is evaluated to be the address 11111111 having an element 1. The list located at 2222222 also contains one element 2, but it is not pointed by items any more. Consequently, An append of 3 will make items [1,3]. From the above explanations, we can see that the effbot webpage recommended in the accepted answer failed to give a relevant answer to this question. What is more, I think a point in the effbot webpage is wrong. I think the code regarding the UI.Button is correct:Each button can hold a distinct callback function which will display different value of i. I can provide an example to show this:If we execute x[7]() we'll get 7 as expected, and x[9]() will gives 9, another value of i.TLDR: Define-time defaults are consistent and strictly more expressive.Defining a function affects two scopes: the defining scope containing the function, and the execution  scope contained by the function. While it is pretty clear how blocks map to scopes, the question is where def <name>(<args=defaults>): belongs to:The def name part must evaluate in the defining scope - we want name to be available there, after all. Evaluating the function only inside itself would make it inaccessible.Since parameter is a constant name, we can "evaluate" it at the same time as def name. This also has the advantage it produces the function with a known signature as name(parameter=...):, instead of a bare name(...):.Now, when to evaluate default?Consistency already says "at definition": everything else of def <name>(<args=defaults>): is best evaluated at definition as well. Delaying parts of it would be the astonishing choice.The two choices are not equivalent, either: If default is evaluated at definition time, it can still affect execution time. If default is evaluated at execution time, it cannot affect definition time. Choosing "at definition" allows expressing both cases, while choosing "at execution" can express only one:Every other answer explains why this is actually a nice and desired behavior, or why you shouldn't be needing this anyway. Mine is for those stubborn ones who want to exercise their right to bend the language to their will, not the other way around.We will "fix" this behavior with a decorator that will copy the default value instead of reusing the same instance for each positional argument left at its default value.Now let's redefine our function using this decorator:This is particularly neat for functions that take multiple arguments. Compare:withIt's important to note that the above solution breaks if you try to use keyword args, like so:The decorator could be adjusted to allow for that, but we leave this as an exercise for the reader ;)
