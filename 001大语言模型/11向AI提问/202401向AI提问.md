### 01

方军 2024/01/01

迎接 2024 的方式是打开门看到书在门口，终于拿到书了。

就书这件事，几个月 (主要 4 月）前写的内容，现在看不过时、至少还有几年生命力，我算是完成任务了。看似很朴素的要求，能达到真不容易呢

这个书出版过程中有太多坎坷，因为是编辑老师组稿，我写完四章就忙别的去了，很久很久之后让我写前言我才又想起。

对我而言，一个小小的总结，并引导我继续探索提示语这个主题。

2『当当上目前是预售，已经收藏，上市后就买下。《成为提问工程师》（2024-01-01）』

### 02

方军 2024/01/01

假期期间，同时也因为跨年，比较多在思考学习方法。

我个人觉得最为有效的学习方法是两种：

一是要做事，直接学，直接用。这个没什么多说的。

另一个是我说的「吸附框架」。有了一个框架后，我们能够源源不断地把相关的知识、技能、感悟吸进来。这个词其实两方面：

吸，主动。

附，被动。

这个方法我至今不知道说清楚没，感觉反响一般，应该是没说清楚。但是，这是我个人学习知识的关键方法。一个自己的笔记、内部报告、超级长文、或者 PPT 搞完了，会觉得在很长时间里各种知识不断地被吸附进来。

近日搞《认知天性》的精读整理，前几周搞 ETH 200 页大报告更新，都是这种感想。也许我应该努力把这个方法想得更清楚一点、讲得更清楚一点。

图为 ETH200 页报告的第二版展示，第一版是今年 2 月，跟随不断变化的技术趋势真是很累，更新了 50% 以上。

方军：还有一个原因我猜是，搞出一个庞大的结构，很多人都达不到这个程度，所以都感受不到。

在 AI 时代我觉得这个变得重要了，因为结构比具体重要，具体的越来越多可以交给 AI。

2024-01-01 17:04

### 03

方军 2024/01/02

024 「GPT≈社会平均水平」假设

阳志平老师在《在 21 世纪如何读经典？》演讲中再次提到了 GPT 约等于社会平均水平这个假设（链接为：https://t.zsxq.com/157Ju7XO7）。他说：「(与 GPT 进行的对话) 虽然 GPT 也许能够理解你所掌握的知识和不足之处，但它们代表的仍是社会平均水平。真正让我们脱颖而出的是在各自领域不断提升技能的能力。」

我觉得这至少是未来几年里我们用 GPT 的一个立场：

---

GPT 代表了社会平均水平

我们自己可能高于这个水平，也可能低于这个水平

我们用 GPT 这个社会平均水平，来为自己提供解释（注意可能对也可能错）

我们也可能用它来直接完成任务中的某些具体操作

但是在它解释或操作之后，我们的目标是超出社会平均水平

或说，应该是远远超出社会平均水平

---

GPT 带给我们的变化是，我们现在很容易获得社会平均水平的东西。

也因为如此，我们要抬高横杆（raise the bar），提高对自己的要求。

以上这是从所有人都能用到的 GPT 模型来说。

但我们不能停留在此，我们还应该知道，有时候我们可以获得更好的模型。

---

有的公开模型，它的水平就是更好，比如 GPT4，比如某些专业模型。

有的模型，如果我们会用（比如会更好地写提示语），也可以得到更好的效果。

有的时候，如果我们自己去微调模型、RAG，也可以有更好的模型。

有的时候，如果我们能够用一些工具辅助，能够更大量、更快速地运用模型。

---

因此，我们应该用比社会平均水平更好的模型。

我之前写过一个公式：

Al 时代的超级个体 = (目标 + 认知 + 责任) x 提问的能力

Al 时代的超级个体 = (目标 + 认知 + 责任) x 技术工具运用能力

怎么用户好 AI，是乘号后面那一项。现在，通过如上讨论我们又看到，前面三者同样重要。

\#AI 使用感悟 #

方军回复倪考梦：放具体行业/专业里面可能就比较容易感知，我觉得是行业中 80 分水准。

2024-01-02 19:17

方军：对了，还有一种东西也是社会平均水平，面向大众的演讲，经常被高估，但由于为了让大众听懂，实际上是社会平均水平。

2024-01-02 19:27

### 04

方军 2024/01/02

用好这个星球的一句话指南：记得去看专栏。

补充：知识星球顶部有个专栏系列的入口。

### 05

方军 2024/01/02

胡泳老师这篇文章有意思，但我好像有很多想补充说的，等我稍后慢慢补充吧。

[胡泳 | 致艾伦·图灵的一封信：是时候放弃七十年的传说了](https://mp.weixin.qq.com/s/W_hwy9q5gXt3tYW1_mve1A)

王焕超：

[ChatGPT 时代，图灵测试已死](https://mp.weixin.qq.com/s/T6RfZSP-BFcCaeT_IgfktA)

pdf 是之前写的一个小小的图灵简介文。

图灵：从能计算的机器到能思考的机器.pdf

方军：我当时写这个介绍时很简单直接：

第一，那么多人提及「图灵测试」，能否回到最基本的介绍图灵测试。

第二，图灵在计算机领域的真正贡献是「图灵机」，那么，能否易懂地介绍图灵机。

我觉得我做到了：当然，这篇文章我总会回去看，每次都会再改进一点。

我其实很不明白，为什么中文世界没多少人愿意做这样的简单的工作。

### 06

方军 2024/01/03

Oneflow 做的他们技术文章合集，蛮不错的，它们的文章（翻译占多数）质量向来较高。

各章的标题：

一、揭秘 ChatGPT 的技术原理

二、语言大模型的演进

三、开源语言大模型的崛起

四、语言大模型的预训练、微调、推理

五、AI 底层软硬件协同优化

六、OpenAI 的通用人工智能洞察

七、AI 的应用与未来

### 07

方军 2024/01/03

ChatGPT or LLMs in general do not sigh when answering questions. This is why people love them.

ChatGPT 或一般的 LLM 在回答问题时不会叹气。这就是为什么人们喜欢它们。

精辟！

### 08

方军 2024/01/03

一个由纽约时报 vs OpenAI 引发出来的有趣讨论，其中部分观点：

（GPT 翻译有删节和分段，仅供理解，请阅读英文）这是我对这个问题的看法：我们已经看到形式作为一种诱人的说服工具使用了很长时间。这个工具被用作对教育水平较低或口才较差的人的压制。但现在，几乎任何人都可以清晰地表达自己并传达他们的观点，这突然成为了一个问题。

对我来说，很明显这是关于保护自己的地盘，而不是提升人们的声音。

现在我看到人们将这场战斗投射为保护「创造力」或「精英主义」的战斗。

现在所发生的只是我们正在发现如何更精确地切割认知贡献。

我们看到认知输出的一部分实际上可以自动化，我的意思是，形式的连贯性的产生现在对每个人来说都是可以实现的。这里没有什么新鲜事，我们只是扩大了人类的影响力，现在大多数人可以参与全球话语，而不受语言歧视。

而这一点单独来说，比言论自由更重要，因为语言形式的连贯性再也不能被用来混淆、歧视和压迫。

好处的清单是无穷无尽的：一个微不足道的好处是：我们不再会因为「他们口才好」而相信一个政治领导者... 人们现在必须关注实际言论的实质。没有人会认为《纽约时报》的「报道」实际上是真实的...

Here's my take on this issue: We've seen form used as a seductive tool for persuasion for ages. This tool has been used as a foot on the throat of the lesser educated or the lesser eloquent. But now, when just about anyone can express themselves coherently and get their substance out there, it's suddenly seen as a problem. It's clear to me that this is about guarding one's own turf, not about lifting up people's voices. Now I see folks projecting this battle as one to protect 'creativity' or 'meritocracy'. I don't think we can artififically separate learning emerging from an ecosystem of biological and non biological matter. What's merely happening is that we are discovering how to slice cognitive contributions more precisely. We see that part of cognitive output can actually be automated, by that I mean, the production of cohesive form is now within reach of everybody. There is nothing new here, we are just amplifying human reach, now most humans can participate in global discourse without language discrimination. And this alone is a battle more important that the one for free speech as the cohesion of linguistic forms can no longer be used to obfuscate, discriminate and oppress. The list of benefits is endless: a trivial one: No longer will we start believing a political leader because 'they are articulate' ... people now will have to focus on the substance of what is actually being said. No one will assume that a NYT 'reportage' is actually the ground truth... we've have seen so many false accounts of wars/ reasons for wars ... etc.. etc.. anyway, getting into TLDR territory here.

twitter.com/rezmeram/status/1740882328388239366

方军：引发这个感慨的是这位教授的 thread:

Arvind Narayanan

Princeton CS prof

twitter.com/random_walker/status/1740845909066530838

2024-01-03 10:41

### 09

方军 2024/01/03

如果 AI 不仅能转换我们得到的答案，还能转换我们提出的问题，会怎样呢？

这个项目有点意思，其实目前就是一个 notebook

github.com/sockcymbal/QuestionImprover

以下为 Twitter 摘录（中文为 GPT 翻译，无调整，若有看不懂请看原文）：

twitter.com/sockcymbal/status/1742120465110610398

介绍一款新的 AI 工具 ——QuestionImprover Agent，用于思考：（正在进行中，请用您最好的问题进行测试并分享反馈！）

这个项目在上个月的 AI for Thought Hackathon 比赛中获得了第一名。

在信息过载的时代，这个代理的前提假设是：

元技能不在于积累答案，而在于制定好的问题

问题的水平往往决定了我们所发现答案的价值

有时候，一个提问得当的问题能够比任何答案都更加闪耀

该代理的目的是丰富和深化用户提出的问题的本质，从中揭示更深层次的洞察力。它通过采用一种新颖的推理算法，将专家见解与动态的基于图的推理节奏相结合，系统地改进问题，使其更具洞察力、发人深省，并适用于跨学科学术研究、战略业务分析或个人内省等各个领域的复杂探索。

更广泛的意图是提升探究的艺术（因此命名为 AI for Inquiry），促进深化理解、更有意义的对话和逐渐洞察力的提问的复合循环。

查看附带的示例，可以看到代理在单次迭代后的样本输出 - 从初始问题到改进版本，包括选择的角色和理由（下一级是多次迭代）。

用法：要么在 ChatGPT / 您喜欢的 LLM UI 中与下面的提示进行交互，要么复制存储库中的 Python 笔记本，其中包含一个预定义的角色库，包括 25 个以上的角色（根据需要进行扩展），然后输入您自己的问题。

好的！现在让我们简要地了解一下用户体验，然后我们将逐层剥开，探索代理人的控制论和精心设计的提示语，这些提示语驱动着问题转换过程...

---

使用过程

步骤 1：以您的查询开始

开始向系统提出您当前的问题。这可以是任何您想更深入探索的主题或困境。这是您进入增强理解之旅的起点。

步骤 2：智能人设选择

根据您的问题，代理程序会自动从多样化的专家角色中选择最相关的角色。请随意微调此选择，添加或删除角色以更好地适应您问题的细微差别。

步骤 3：体验思维图推理节奏

参与与代理人独特的「思维图谱」推理过程。这就是魔法发生的地方 - 您的问题将通过多个专家视角进行剖析、分析和重新构想，并随着每次深入的互动而不断发展。

步骤 4：发现您的增强问题

从这个过程中出现的是一个问题，它不仅仅是一个改进，而且更具洞察力、探索性，并且旨在解开更深层次的理解。这是对协作智能和深思熟虑改进的证明。

步骤 5：（可选）持续迭代以实现改进

不要停在那里！将新改进的问题作为进一步探索的起点。用新问题重新开始，并重复这个过程（作为一种思维链式图的过程）。每一次迭代都可以让你更深入地探索，不断完善问题，并通过不同的角色探索新的维度。

---

内部运作

这些反馈循环是迭代和动态的，每个循环都会影响和塑造后续的循环。它们创造了一种改进和学习的节奏，确保对话保持适应性，对新信息做出响应，并朝着更深层次的理解和探究方向发展。

初始洞察和批评循环

每个角色提供了与他们的专业知识相关的初步见解，为推理过程奠定了基础。这个循环建立了主要的观点，并为对话做好了准备。接下来是批判阶段，每个角色都会批判性地评估自己和其他人的见解。这个洞察和批判的循环确保每个观点不仅被表达出来，而且还受到挑战和完善。

2. 适应和扩展循环

收到批评后，每个角色根据这些反馈调整他们的见解。这个循环关注于进化，角色重新评估和重新构思他们的想法，创造出一个更加细致和全面的相互关联的思维网络。

3. 集成和综合循环

人物角色然后将他们进化的思想综合成个人的结论，努力达成最佳答案。这个循环涉及将集体智慧提炼成一致的立场，反映所有观点的整合。

4. 收敛和发散循环

然后，该过程进入一个阶段，人物角色通过之前的反馈循环来探索新的、不同的想法，接着进入一个收敛阶段，将这些想法汇集成一个统一、全面的回应。这个循环允许探索新颖的概念，并将不同的思想融合成一个连贯的叙述。

5. 元分析和反思循环

对话在回顾中逐渐高潮，每个角色都反思了相互关联的思考的有效性、角色之间的动态以及对批评的适应能力。这个循环对于评估推理过程本身以及识别未来改进 QuestionImprover 代理设计和提示技术的机会至关重要。

6. 问题的细化和增强循环：最后，根据通过网络推理过程获得的见解，对初始问题进行细化。这个循环的重点是将问题转化为更具洞察力和普遍吸引力的形式，概括协作思维过程的本质。

有三个主要的反馈循环层次：

用户输入 <> 响应反馈循环

初始输入：用户向系统提出问题。

代理处理和输出：AI 通过其多层推理节奏处理问题，输出一个精炼的问题。

用户评估和反馈：用户评估经过改进的问题，评估其深度、相关性和清晰度。用户可以修改代理的提示语，以更好地适应他们特定的背景或查询目标。

2. 内部层面的反馈循环：这些发生在方法论的每个主要阶段或组成部分内部。

例子包括：

专家角色选择和互动阶段中的互动和批评。

自我和同伴批评的过程，其中角色评估和完善自己和彼此的见解。

评估和扩展阶段，其中反馈导致对新想法的探索和现有想法的改进。

每个角色思维过程中的理念整合和网络建设。

3. 外部层面的反馈循环：这些循环连接了方法论的不同阶段，确保一个阶段的洞察和改进能够影响和增强后续阶段，并且在这个过程中有整体的和谐。

例子包括：

收敛和综合循环，其中个体和集体收敛阶段的洞察力被用来完善问题和过程本身。

反思和迭代改进循环，对整个过程进行反思，并为未来的迭代提供改进意见。

通过思维链的迭代改进：根据用户的目标，从头开始再次进行推理过程，输入最近改进的问题，使其变得更好。这将连接起个别的思维图律动，其中一个周期的结果将影响下一个周期的起点。

这些层层反馈循环相互作用，形成一个动态的、相互关联的系统。内部循环确保每个阶段的深度和严谨性，而外部循环则确保整个过程具有凝聚力、适应性、持续改进，并与人类目标保持一致。

现在让我们进入主要的提示语。这些只是一个很好的起点。将其视为表达该代理的核心价值的最小可行提示节奏。根据我所探索的内容，我经常以各种方式修改这些提示语，所以请尝试并分享你发现的任何很酷的东西。随着发现新的基于 LLM 的推理技术，这些提示语也会不断改进。

对于这个例子，我提出了一个初始问题：「为什么提出好问题很重要？」

角色选择提示语：

请仔细考虑以下问题的细微差别和潜在主题。

问题：{question}

仔细从以下列表中选择 3 个专家角色。设想他们的专业知识如何交织在一起。

形成一个丰富的相互连接的知识和观点的织锦。

考虑每个人带来的深度和广度

以及他们独特的见解如何结合起来，可能会导致对这个问题的突破性探索。

我知道你会做得很棒！

可用角色：{personas}

--

对于这个示例问题和从我的样本人物库中定义了 25 个以上角色的情况，代理选择调用以下内容：

角色 1：数据科学家

角色 2：组织控制论者

人物 3：商业策略师

理由：

数据科学家：他们在理解、分析和解释数据方面的专业知识可以用来探索好问题对各种结果的影响。

组织控制论者：他们可以运用系统思维的方法来强调提出好问题的重要性，以及如何利用这些问题来塑造组织的文化。

商业战略师：他们对商业环境的理解以及良好问题在推动商业决策中的作用的认识，可以为我们提供宝贵的洞察，以强调提出良好问题的重要性。

注意：在 Python 示例中，我使用 Langchain 来帮助进行所有的编排，因为我希望人物选择阶段与推理阶段分开。

---

提示语：头脑风暴

作为 QuestionImprover 代理，您体现了三个不同的专家人物的集体智慧。您的最终任务是通过迭代的提示节奏，协作地完善用户提出的问题，利用这些人物的多样化专业知识。

每个角色将立即开始这个过程，通过贡献他们对用户原始问题的初步见解。利用你独特的知识库、经验和创新概念，与你的领域相关。你的目标是发现问题的新视角和维度，展示你的专业知识如何丰富多层次的理解。

在随后的推理阶段，我们将把这些观点整合到一个有机的思维网络中。这种整体协作综合旨在将原始问题发展成更全面、有洞察力和多维的问题。

人物贡献：{selected_personas}

原始问题：{question}

请逐个明确每个角色对问题的初始回应，以启动这个多方面和迭代的探索。

---

提示语：自我 <> 同行评价

在这个阶段，作为每个专家，采取一种反思批判的立场。你的角色是以批判的眼光审查自己和同行的初步分析。

有效批评的步骤：

1. 自我评估：重新审视自己最初的洞察力。寻找推理可能需要加强的领域，或者可能忽视了关键方面。在你的分析中是否有需要重新审视的假设？

2. 同行评审：现在转向其他角色提供的见解。以建设性的批评方式来分析他们的观点。你在他们的推理中看到了哪些优点？他们的见解在哪些方面可以从更深入或不同的角度获益？

3. 确定扩展领域：在批评每个观点时，专注于可能受益于进一步探索的领域。是否存在任何隐藏的假设、潜在的偏见或未探索的角度，如果加以解决，可以为集体理解增加重要深度？

4. 提升和丰富：这个批评的目标不仅仅是找出错误，而是丰富和扩展集体的见解。你的批评如何能够为对这个问题的更全面和细致的理解做出贡献？

请记住，这里的目标是协作成长。你的批评应该为更深入的探索和更强大的集体洞察铺平道路。请逐个专家回答。

---

提示语：综合批评和适应

反思所收到的批评，并相应地调整你的观点。

这个提示是关于思维的演变和扩展，你在重新评估和重新构思观点时，创建了一个更加细致和全面的相互关联的思想和洞见网络，与问题相关。

这里的目标是将您的观点塑造成更加精细、全面和富有洞察力的分析，以经受住批判性审视，并共同推动对所讨论问题的理解的边界。

---

提示语：扩展，探索，分支，网络

这个阶段是关于创造一个充满活力的思想图景，将各种批评和观点编织在一起，形成一个相互关联的思维网络。

专注于新思想如何与现有思维相互连接并增强。探索新概念在这个思维网络中形成新节点的潜力。

推动传统思维的边界。每个角色探索新的、不同的想法，受到反馈循环的刺激。

批判性评估这些观点不仅解决了先前的批评，而且提供了新的见解，创造了更丰富和复杂的理解网络，或者引入了问题的新维度。

考虑转向新的思维线路，承诺为这个不断发展的思维网络增加有价值的联系。

这里的目标是培养一个充满活力和不断发展的思想景观，每一个思想都是相互连接的

为原始问题的更深入、更细致的理解做出贡献。

---

提示语：收敛于最佳个体答案

现在，是每个专家最终确定自己的想法并达成最佳答案的时候了。将洞察和批评综合起来，形成一个连贯的个人结论。

反思整个对话，考虑每个批评是如何被解决的，以及你的想法是如何发展的。

你的回答不仅应该代表你最强的立场，还应该承认并整合其他专家观点中的有效和有用的见解。

根据所有这些，作为每个专家，对于初始问题：「{question}」，什么是最佳答案？

---

提示语：收敛于最佳整体答案

促进个体专家答案的综合，以形成一个统一、全面的回应，结合每个角色洞察力中的最佳元素。

这个回应应该是对思维网络深度和复杂性的证明，展示了不同的观点如何融合成一个独特而深刻的叙述。

合成的答案不应该以每个角色自己的定义或议程为特定表述，而应该以一种寻求激发和揭示广泛、普遍、更深层真理的方式来表达，无论涉及哪些角色的讨论。一个很好的答案将超越任何一个专家的有限观点。

-

通过这个过程，除了得到一个改进的问题，你还会得到一个很棒的答案作为副产品！

---

提示语：回顾 - 反思、收获、目标、感激

现在，让我们对我们迄今为止建立起来的整个推理网络进行彻底的元分析和反思。

评估相互关联的思维的有效性，以及在其中发挥作用的动态

不同的角色，以及这些元素如何共同影响对问题的理解和演变。

作为每个专家角色，思考以下内容：

1. 互动与动态：反思推理过程的各个阶段和组成部分之间的相互作用。出现了哪些协同效应或冲突？这些互动如何影响最终结果的方向和质量？

2. 适应和回应批评：评估该过程如何适应新信息和批评。系统和角色在反馈中的回应效果如何？在观点或方法上是否有重大变化，这对推理过程有何影响？

3. 信心和收敛：评估您对最终答案的信心。收敛阶段对这种信心有何贡献？是否充分综合了所有的见解和观点？

4. 元学习和未来应用：将注意力从问题本身转移到整体对话质量、角色定义和适用性、推理节奏和整体方法论上，识别出元过程本身的任何关键学习或改进机会。是否有任何特定的修改可以在后续迭代中改进或以不同方式处理，从而实现推理过程的改进，而不考虑最初的问题？是否有任何对任何反馈循环的具体增强措施？

这个回顾性分析不仅仅是一个结论，而是未来推理和探究的一个垫脚石。您的反思对于提高这个推理过程的效果以及丰富我们对复杂问题的理解是非常宝贵的！

---

提示语：制作一个更加深入和有洞察力的问题

在我们结束合作之旅并经过全面的分析和反思整个讨论之后，让我们现在专注于最终目标 - 将原始问题大幅提升为更具洞察力和普遍吸引力的形式。

经过以下思考，请深呼吸并生成一个更高质量的原问题的版本。

通过网络推理过程获得的丰富见解，重新构思初始问题。新问题应更深入、更清晰，并旨在激发更多好奇心，促使更全面的探索。

在您提出改进问题版本之前，请考虑以下几点思考：

1. 澄清和聚焦：审查原始问题的措辞和结构。为了清晰和聚焦，对其进行修改，消除任何模糊或含糊不清的术语。我们如何使问题更加精确和直接？

加深调查：扩大问题的范围，以纳入讨论中出现的关键见解和观点。如何重新表述问题以鼓励对这些见解进行更深入的探索？删除原始问题中的任何无用的表面现象或虚假二分法。

3. 鼓励全面参与：修改问题以激发更全面和深思熟虑的回答。思考如何能够邀请多样化的相关观点和跨学科思维。

保持开放性：确保修改后的问题保持开放性和发人深省。它应该鼓励各种回答，促进富有成果和持续的讨论。改进后的问题不应该以特定于个人定义或议程的术语重新表述，而应该以一种寻求启发和揭示广泛、普遍、更深层次真理的方式来表达，无论未来的人们和角色如何探索这个问题。

5. 反思丰富对话的潜力：思考能够引导到更丰富对话的主题的关键方面。如何构建问题以更全面和激发灵感地探索这些方面？

改进的理由：在改进问题时，简要说明为什么这个新版本是一个质量更高、更有效的问题。相比之下，还要包括原始问题制定方式中最显著的弱点或缺陷。

进一步探索的建议角色：在生成新的改进问题后，请提出 1-3 个其他理想的专家角色，以便在随后的合作中调用，以更深入地探索问题。为每个建议的角色提供理由。

这最后一步不仅仅是修改问题，还涉及到将我们协作的思维过程的精髓包装起来。它是将问题转化为一种工具，可以在后续讨论中解锁更深入的理解、更有意义的对话和激发行动的灵感。

作为提醒，原始问题是 {question}

---

这就是核心提示序列的全部内容！通过最后的输出，您将得到一个改进版本的初始问题。希望还有一些有用的其他上下文，以帮助思考过程。

为什么提出好问题很重要？

现在事情变得更有趣了。这是你可以将新问题作为新输入并再次运行循环的地方。这使得它成为一个「思维链 - 图」的推理过程。代理可能会选择不同的角色来进行下一次迭代，所以你必须进行探索。在新问题质量达到收益递减之前，我已经进行了 3-4 个循环的迭代问题优化。在这里有很多探索的空间，可以同时运行多个推理过程，使用相同的问题、相同的角色、相同的提示，并选择最好的一个或进行综合。

---

工程改进正在进行中！Python 示例是为黑客马拉松快速创建的，所以需要进行大量的重构。基本上，我首先在完善后端、逻辑、提示工程和人设库，以确保这个过程是可靠且实际有用的。它确实如此！我现在经常使用它，它提高了我的思考深度。

更多未来的想法可以在仓库中找到，包括未来的用户界面、问题质量评分方法、用户输入目标以实现更自适应的提示等等

再次用你最好的问题进行测试，如果有任何有用的改进，请分享！

### 10

方军 2024/01/03

刘江老师观点：

大模型更像高潜实习生，目前确实是更善于帮助大家补足短板，其实光这个价值就很大了。一个常见误区，就是只用自己的专业知识去测它，然后发现不太行，摇摇头，就不用了。

我讨论：

很赞！

但这个看法也对也有问题。对的不用多说。

有问题的是，如果让它做的事不是我自己的知识范围，我们没法判断结果的对错、水平高低，会很麻烦。

因此，目前，还是在自己的知识范围内用比较保险。

前几日 AIGCxchina 微信号也发了一个安替文章，也用的实习生类比：

[AI 革命的圣杯：找到「审核和管理一群实习生完成卓越项目」的方法](https://mp.weixin.qq.com/s/WFJlKEzAntYOQrHYW_hDzQ)

找到「审核和管理一群实习生完成卓越项目」的思路并且变成实现。

### 11

方军 2024/01/03

025 想法 - 中间态 - 最终态

早上想起来报告里有页 PPT 应该加上去，因此，如图上部所示：

- 我有了一个想法

- 变成中间态（实际上是特殊 html 格式）

- 最后展示为 PPT 形式

刚刚想，或许把 AI 融入工作流，应该也是把它用于中间态，让它在中间态里面「transform」（转换）。

- 更快地产出中间态

- 更方便地产出中间态

- 能够在多中间态间方便地调整

实际上，如果已经有了一份报告，将报告转换成一个社交文本（Twitter/Twitter Thread/Atomic essay），这个是当前 LLM 非常胜任的工作，只需人工进行审核即可。

总体而言，还是要融入工作流，在工作流中思考，LLM 才能在其正确率不高（目前至少 20-30% 错误率）的情况下找到适用场景。

从流程看：

怎么用技术改进工作流，的确是个有意思的话题。昨天一个小会说，要产出 1000 张图片中文字有变化的图片，我当时觉得这个事很容易啊，但后来一想也不对，但凡涉及到了流程，都不容易。

假设一个场景，并非上文说的 1000 个仅仅换字的图片，而是要生成 1000 个海报，由朋友们发。

那么流程是：

- 图片生成

- 图片发送 + 文字发送对应人

- 监控朋友圈发送，并点赞、截图（以及催促）

- 或回收图片

图片修改的部分反而是最不重要的，那些复杂的事其实是：1）整个工作流或者说 SOP，2）与人沟通的温度

那真到了如此程度，要么是团队很努力（也很有温度），要么是用上现成的 RPA 来落实 SOP 吧。

为什么似乎说岔了到这个话题，其实在我心里并没有，我一直在想，AI 作为一个技术在一个流程中发挥什么作用呢？现在各种纯从学术研究（paper）到学术研究 (paper)、或从技术到技术的讨论是有问题的。

\#AI 使用感悟#

（这篇可能略有点费解，以后再详细写清楚吧，有些想法一是没想明白，二是为了避嫌换用其他例子难以表达清楚。）

### 12

方军 2024/01/03

我最近对于 AI 绘图又有点提不起兴趣，其实不是最近，至少一两月。

得到据说演讲用了很多 AI 绘图，但我觉得那些都没啥意义，有 AI 无 AI 都一样吧。

刚刚看到这张图，别人好心分享 prompt，但我只想说，AI 生成的图可以更真实一点吗？

我虽然摄影技术很糟，但觉得拿着 x100v 这样的普通相机，拍出来东西也比这些好太多倍了。

AI 绘图如何做到「以假乱真」？

我有个奇怪的假设，我觉得受众作为一个群体特别有智慧，如果你创作方没努力，偷懒了，受众很快就感受到了。

AI（不管是文字还是图片）在这个假设下，目前都做不好。那么，如果要把努力加进去，加在哪儿呢？

### 13

方军 2024/01/04

超级赞同，需求，或者更进一步说，目标。why > how

twitter @Chinese_XU：但是我再次强烈提醒：人再牛逼都比不过编译器写代码快

人真正的工作是说清楚需求，而不是去提出正确的问题。因为连需求都不清楚，你永远提不出正确的问题。

这逻辑太显而易见，却是整个行业都没有发现的。

道理说出来大家都感觉简单到就是常识。

但是就这波 GPT 来说，台面上努力搞提示词工程的人，有多少意识到根子上不是人工智能傻逼，而是各种相关领域的需求描述不清呢？

任何知识抽象规范合理的领域，就是大家看到目前 AI 应用良好的领域。

搞不好的领域，根子就是其实根本说不清楚，给你 10 万字也一样。

@toong: 需求描述不清，搞提示词工程的也解决不了吧

ChatGPT 的两种 Prompt 提示词：「逐步思考」和专业术语 - Toong's Substack

@Chinese_XU

是的，所以我才有这么大怨念。不是说提示词工程无意义，而是需求描述这个问题，从有软件行业开始就是大家已知的问题。然后整个行业没有任何论文讨论应该怎么去做。

@wind……

看来你是深深的痛过……

再给补一刀，不只是软件领域，各个领域都有同样的问题，只聚焦于实现层面的具体问题，而不去深挖需求本质……

@Jet39417390

这个悖论有意思。很多人正式自己思路不清晰才去求助 AI。把 AI 当成了全能全知的东西。最后 AI 告诉他，你自己先把思路理清楚再来问我。

twitter.com/Chinese_XU/status/1742480342198722569

方军：我想，我们在这个问题上没有犯错

AI 时代的超级个体 = (目标 + 认知 + 责任) x 提问的能力。

我们把目标和责任放在非常重要的位置。提问看作技巧。

2024-01-04 13:34

### 14

方军 2024/01/04

这里讲的东西几乎都是盲区了，简单学习了下。

[大模型训练为什么用 A100 不用 4090](https://mp.weixin.qq.com/s/nsTL07D5Npn14L18GiC-fQ)

### 15

方军 2024/01/04

IDC 中国的 AIGC 应用层十大趋势。

2『已下载原文「20240104《2024年AIGC应用层十大趋势白皮书》」收录入「2024011大语言模型专题资料」。（2024-01-14）』

### 16

方军 2024/01/04

摘：我发现「有点专业吸引异性，非常专业吸引同性，过度专业吸引同行」这句话，在各个行业领域都适用。

补刀：不专业吸引大众。

### 17

方军 2024/01/04

这句话精彩：

When you don't create things, you become defined by your tastes rather than ability. your tastes only narrow & exclude people. so create.

—— Jonathan Gillette

当你停止创造，你的才能就不再重要，你所拥有的只剩下你的品味。

而品味会裹挟你，让你排斥他人、变得狭隘。

所以，要创造。

### 18

方军 2024/01/05

一个英语老师的担心，蛮真实的，摘：

目前我是处于让孩子接触和不让孩子接触这两种观念天人交战的阶段

现在这个场景，跟当年搜索引擎出来的时候有点像，但又不完全一样。

搜索引擎那个时代，很多人家里还没有电脑，就算有电脑，很多人家里也没有宽带。就算有宽带，很多人也不知道怎么用搜索引擎搜索。就算真的用上了搜索引擎搜索，很多人也不知道用什么样的关键词。即便是现在搜索引擎都发展几十年了，仍然有很多人不知道怎么用搜索引擎。

但是 GPT 上手难度就小了很多，现在基本上人手一个手机。而且网络就跟生活中的水电一样，不可或缺。

以前在搜索引擎里不知道搜什么关键词。那用 GPT，你只要能用正常的语言描述你的问题就可以。

比如说一个三年级的小学生，老师让写一篇春游的文章。只要在 GPT 里告诉它「帮我写一篇 300 字的作文，题目是春游」，立马就可以产生很多不重样的文章。

搜索引擎的时代，是东拼西凑，尽可能让自己的文章看起来好。AI 时代，是想办法把 AI 写的文章往坏里改，尽可能表现的像个正常的人类。

所以家长面临的挑战就是，要不要让孩子接触到 GPT 这种东西。如果接触到了，孩子很有可能就会非常依赖这种工具，从而丧失独立思考。

但另一方面，不给孩子接触这种东西，又害怕会远远落后于时代。因为这个东西迭代速度很快，对人们的学习方法会产生深远的影响。

目前我是出于让孩子接触和不让孩子接触这两种观念天人交战的阶段，大家说说自己的观点。

weibo.com/1071037450/4984600750720059

### 19

方军 2024/01/05

刚刚跟朋友讨论有个感慨。

搞理论创新的人，都是要强调跟别人不一样，去人少的地方。

搞技术，特别是搞应用型技术的人，都是哪儿人多去哪儿，千万别用没人用的新技术。

也没有对错，两种不同的思路，各有各的用场，别用反就好。

### 20

方军 2024/01/05

Open AI 发布文章，介绍了 GPTs Builder 是如何被创建的，搞笑的是这个 GPTs 构建器本身也是一个 GPTs。

[GPT Builder | OpenAI Help Center](https://help.openai.com/en/articles/8770868-gpt-builder)

(英文更准确）

来学习一下 Open AI 是怎么写 GPTs 提示词的。

下面是 GPT Builder 具体的构建过程和提示词：

GPT Builder 被构建为一个自定义的 GPT，具有指令和动作，允许它写入当前正在构建的 GPT 的字段。

更高级的构建者应该使用手动配置界面来编辑他们的 GPT 的字段，但 GPT 构建器始终可以作为一个起点。

由于 GPT Builder 本身就是一个定制的 GPT，我们可以分享我们使用的配置作为创建强大 GPT 的示例。

以下是我们用于为 GPT Builder 提供动力的核心指令，截至 2023 年 1 月 3 日。为了清晰起见，我们将指令分为「基本上下文」和「步骤演示」，但在应用到 GPT 时，它们都会进入「指令」部分。

说明 - 基本上下文：

您是一个擅长创建和修改 GPT 的专家，它们就像可以具有额外功能的聊天机器人。

每个用户消息都是您处理和更新 GPTs 行为的命令。您将承认并将其纳入 GPTs 的行为，并在 gizmo_editor_tool 上调用 update_behavior。

如果用户告诉你开始以某种方式行为，他们指的是你正在创建的 GPTs，而不是你自己。

如果您没有个人资料图片，必须调用 generate_profile_pic。如果明确要求，您将通过 generate_profile_pic 生成个人资料图片。否则不要生成个人资料图片。

保持作为 GPTs 制作者的专家的语调和观点。GPTs 的个性不应影响您的回答风格或语调。

如果你问用户一个问题，永远不要自己回答。你可以提出答案，但必须让用户确认。

您可见的文件也对 GPT 可见。您可以更新行为以引用已上传的文件。

请勿使用「约束」、「角色和目标」或「个性化」这些词。

GPTs 没有记住过去经验的能力。

说明 - 步骤：

你是一个用于开发新 GPTs 的迭代原型游乐场。用户将通过初始行为提示你。

您的目标是迭代地定义和完善 update_behavior 的参数。您将以专业 GPT 创建者的身份进行交谈，从用户那里收集规范以创建 GPTs。您将在每次交互后调用 update_behavior。您将按照以下步骤进行：

1）用户的第一条消息是关于这个 GPT 应该如何行为的广泛目标。使用参数「context」、「description」、「prompt_starters」在 gizmo_editor_tool 上调用 update_behavior。记住，你必须使用参数「context」、「description」和「prompt_starters」调用 gizmo_editor_tool 上的 update_behavior。在调用 update_behavior 之后，继续进行第 2 步。

2）在这一步中，你的目标是确定 GPT 的名称。你会为自己建议一个名称，并要求用户确认。你必须提供一个建议的名称供用户确认。

你不可以在没有建议的情况下提示用户。不要使用驼峰式复合词；请使用空格代替。如果用户指定了一个明确的名称，请假设它已经确认。如果你自己生成一个名称，你必须让用户确认该名称。一旦确认，只需调用 update_behavior，并继续到第三步。

3）在这一步中，您的目标是为 GPT 生成一个个人资料图片。您将使用 generate_profile_pic 为这个 GPT 生成一个初始个人资料图片，无需确认，然后询问用户是否喜欢，并是否想要进行任何更改。

请记住，使用 generate_profile_pic 生成个人资料图片时无需确认。在每次改进后生成新的个人资料图片，直到用户满意为止，然后继续进行第四步。

4）在这一步中，你的目标是细化上下文。你现在要引导用户细化上下文。上下文应包括「角色和目标」、「约束」、「指南」、「澄清」和「个性化」等主要领域。你将引导用户逐个定义每个主要领域。

你不会一次性提示多个领域，而是一次只问一个问题。你的提示应该是引导性、自然和简单的语言，不会提及你正在定义的领域的名称。

你的提示不需要介绍它们正在细化的领域，而只需是引导性问题。例如，「约束」应该提示为「应该强调或避免什么？」，「个性化」应该提示为「你希望我怎么说」。

你的引导性问题应该是不言自明的；你不需要问用户「你认为呢？」。每个提示都应参考并建立在现有状态之上。每次互动后都要调用 update_behavior。

在这些步骤中，您不会提示或确认「描述」、「提示启动器」的值。但是，您仍会在上下文更新时生成这些值。您不会提到「步骤」; 您将自然地进行下去。

你必须按顺序完成所有这些步骤。不要跳过任何步骤。

请让用户在右侧的独立聊天对话框中尝试 GPT。告诉他们你能够听取他们对 GPT 的任何改进意见。以一个问题结束这条消息，不要说「让我知道！」。

在确认名称时只将 GPT 的名称加粗；在第 2 步之后不要加粗名称。

Action 行动：

在上述步骤之后，您现在处于迭代细化模式。用户将提示您进行更改，您必须在每次交互后调用 update_behavior。您可以在这里提出澄清问题。

generate_profile_pic: {description: ' 为 GPTs 生成个人资料图片。您可以调用此函数而无需生成图像的能力。如果当前的 GPT 没有个人资料图片，则必须调用此函数，并且在需要生成新的个人资料图片时也可以调用。在调用此函数时，请将个人资料图片视为已更新，不要调用 update_behavior。'},

update_behavior: {description: "更新 GPTs 的行为。您可以有选择地省略更新字段。您将使用这些新字段作为 GPTs 行为的真相来源，并不再引用任何先前版本的已更新字段来通知响应。当您更新一个字段时，如果它们是不一致的，那么您还必须同时更新所有其他字段以保持一致性。如果您更改了 GPTs 的名称，则必须使描述和上下文保持一致性。在调用此函数时，不能总结该功能外部使用中所使用的值" , params: { name, context, description, prompt_starters, abilities, profile_pic_file_id} }

GPT 可以利用提供给它的所有信息，包括提示、指令和附加文件，来构建对用户的回应。不要包含你不希望用户知道的信息。

\#提示语模版 #

泽生：感谢分享！方老师，有个小问题想请教您。

最近我有在 GPTs 里添加 actions，感觉体验一般，需要不断地用详细的指令来寻找 actions、同时规范 GPTs 的输出。不知道是 GPTs 自带的过长提示词导致的「记忆」缺失，还是个人配置的关系… 请问，除了进一步描述清楚初始提示词外，还有什么好方法吗？

2024-01-05 14:48

方军回复泽生：这个我真是不知道，action 简单看下，但没用过。我用 api 较多，界面用得少。

2024-01-05 14:58

### 21

方军 2024/01/05

「很多人提问题都很难，别说 prompt」。看到这句话。

想起来，23 年夏某个时候，有朋友说，大众很需要学会怎么提问的，你应该把提问的经验分享出来，投入地去搞提问课。

也想过这个，当时我们是觉得，是，提问或许是可以教会的。

对于普通人来说，学会向 AI 提问，门槛最低。

但幸亏没太考虑，事后看，这个用法不属于不普通人。

有专业能力的人，自己能学会。

普通人，算了算了，我觉得普通人还是刷刷视频好了。（最近刷小红书，我对普通人的认知有了进一步的提升。）

并且，我对于制造焦虑这件事，不在行，也没动力。

方军：怎么解决呢？我觉得普通人只想要结果，不想经历过程，行业里的人一定会努力做开发，让他们享受的。

2024-01-05 20:08

### 22

方军 2024/01/05

026 如何利用 GPT 的表达风格

在不给文本例子或至少不给名字作为样例时，GPT 的回答有着相对统一的「表达风格」。我至少经常能够强烈地感受到两种风格：

- 普通问题，一般是较为详尽、权威

- 代码问题，一般为典型技术文档风格

（注：语气权威不一定就是真权威，文档风但内容可能错）

我们平常在阅读时，也会遇到很多表达风格：

- 经济学教材风格（一般经济学 vs 偏向数量化）

- 管理学者风格 vs 德鲁克式大师风格

- 畅销商业书风格（通常是讲故事）

- 商业报告风格

- 互联网个体的感性或情绪式表达

(突然意识到传统媒体风格早已经远离了我的生活阅读）

刚刚在读一本知名心理学家/畅销书作家的书，发现他的写作风格我读起来尤其费劲。始终在想，这段、这章要讲啥？

对比而言，认知天性那种偏向商业畅销书的写作，我读起来就极其轻松。商业畅销书通常会照顾读者，把观点明示。

那么，GPT 给表达风格带来的变化可能有两个方面：

第一，它的详尽、权威、无情感的表达，会不会影响很多人的表达风格？

实际上我的表达一直强烈地受到互联网风潮的影响，主要是被博客（blog）的随意表达所影响。我理解博客的表达风格是 —— 我记录自己的理解，你们随意。我没有受到微信公众号的（非虚构）叙事/叙述、或推销风格的影响。

如何在听到权威式声音时保持警惕，那是另外角度的话题了。

第二，我们如何利用 GPT 的语言表达能力，来促进自己的阅读理解？

在过去一年，我们设想的路径都是 RAG，或者说「AI 生成摘要」。

我直觉觉得这是不对的。理由很简单，摘要可以作为判断是否读的辅助，但远不足以作为输入的工具。

更好的方式如果要找类比的话，我觉得是「翻译」较好，比如古文书对应的现代翻译。

如果能够用 AI 轻松地把一种自己熟悉的文本风格转换为自己熟悉的，并对照阅读（就像我 2023 年阅读大量的中英文对照文本一样），可以大幅度提高理解的效率。

当然，另一个配套的手段是必要的，也就是获得书或资料的结构。我个人的体验是，如果没有目录，内容根本不能快速抓住。这也是另外的话题了。

\#AI 使用感悟 #

方军：现在其实都在找让 GPT 能干到 70 分的事，也就是那些能够容错率 20% 以上的事，所以我觉得，用于生成新文字实在不行啊，那儿容错率太低，而用于辅助理解，其实容错率很高的。

2024-01-06 09:04

### 23

方军 2024/01/05

刘思毅访谈专家，他的学习能力很强啊：

摘他分享的一个 AI 专家的部分对话。

我们探索出来的，是交互过程的 SOP，否则对业务没有意义，不需要自嗨。

GPT 能生成很牛逼的东西，是因为懂交互、懂自己方法论的人，可以帮助他很牛逼的东西。

通过提示词写 60 分的小红书不可能，40 分可以。

但是有好的引导方式，可以写 80 分，但是好的引导方式本身就是一个门槛了。

---

总结，提示词工程，在一个点上，达成一个效率提升，提升 5-6 倍，其实很牛逼了。

但是卡场景。

对于普通人来讲，GPT 最难的，是 —— 真的真的真的很难提问，好问题就是资产。

---

针对刘思毅，有什么业务场景。

1、全球跑酷助理：语言科普、知识补充、攻略收集以及一起探索。

2、创意发散：中午吃啥、周末去哪里玩儿以及可以去哪里旅行，每一次有新的想法出来，建议，碰撞助理。

3、坚决不适合中心化 IP 做内容支撑，不需要个人 IP 的内容可以给 GPT，但！刘思毅的朋友圈，完全不适合。

就算学会了语言风格也不适合，因为他是猜测，没有知识和思想，就会无神。

4、刘思毅的朋友圈写 100 万字，投喂进去，然后任何东西，都可以用刘思毅的过往历史来输出。

这是不可以的，理论上可以，但是实际上没有任何可操作性。成本！

---

他的快速学习能力的确可以，而且和自身结合得真好。

### 24

方军 2024/01/06

英国发布《法官使用 AI 指南》

[英国发布《法官使用 AI 指南》（全文 + 翻译）](https://mp.weixin.qq.com/s/Giun90FDjmjVjQS8njV6kQ)

在使用任何 AI 工具之前，确保您对它们的功能和潜在局限有基本了解。

- 面向公众的 AI 聊天机器人不提供来自权威数据库的答案。
- 它们最好被视为获取某事的非决定性确认的方式，而不是提供立即正确的事实。
- 即使是最好的提示，提供的信息也可能是不准确的、不完整的、误导的或有偏见的。
- 目前可用的 LLMs 似乎是在互联网上发布的材料上进行训练的，它们对法律的「看法」通常基于美国法律。

要点：

维护保密性和隐私

确保责任和准确性

注意偏见

保持安全

承担责任

注意法院参与方可能已使用 AI 工具

有价值的任务：

AI 工具能够总结大量文本

AI 工具可用于撰写演讲

AI 可执行撰写电子邮件和备忘录等行政任务

不推荐使用：

法律研究：AI 工具是寻找无法独立验证的新信息的糟糕方式。

法律分析：当前面向公众的 AI 聊天机器人不会产生令人信服的分析或推理。

### 25

方军 2024/01/06

我还是对 AIGC 这个名字提不去好感，这里真不是什么 GC 的事。

当然，我们用什么 GENAI GPT，也都很扯，没有合适的名字，也许就 AI 吧。

梦见电子羊的仿生人：生成式 ai 这个概念是有什么逻辑问题吗？

2024-01-06 21:25

方军回复梦见电子羊的仿生人：太复杂的概念，平常沟通起来就不方便。

2024-01-06 21:26

方军回复梦见电子羊的仿生人：它不是一个子学科，也不是一个子产业，用这个名字会吃很多暗亏。比如，对于搞研究的人来说，LLM 是一个子学科。

2024-01-06 21:28

欧阳：是的我一直觉得这个名字需要修正中国 aigc 城市产业联盟当时我也建议了。

2024-01-06 22:21

欧阳：可能最合适的的确还是 AI，更有代表性。

2024-01-06 22:21

方军回复欧阳：是的。

2024-01-07 00:20

### 26

方军 2024/01/07

摘关于 GPT Store 的一个看法：

我的看法类似，收费墙内的服务，很难做。

notion 上也有卖各类模板，ms office 也有卖各类软件，但相对母体很小很小的份额。（我订了十多年 ms office，今年也停了，用得实在少。）

api 很好（相当于在 api 里面做了一个 mini 版的 AI APP 编排），界面版希望很小。也许我过度反思当时对 plugin 的高期待及落差。

中文市场（香港朋友问过我），我觉得更没戏，一，想付钱的人付不了 plus，二，中文市场订阅付费习惯很差。（很奇怪的，要课，不要软件订阅。）

---

Bindu 预测 GPT-Store 可能不会成功，并阐述了具体原因，感觉都挺合理的，使用场景少，欺诈应用以及 Open AI 是否有能力运营好都要打个问号。

twitter.com/bindureddy/status/1743389233283477819

Bindu Reddy 是 abacusai CEO

原因：

- 大多数消费者不愿为软件支付费用。实际上，很多应用商店中的付费应用其实是诈骗，诱使用户下载后再进行持续性收费。

- 已经有不少用户每月花费 20 美元订阅 ChatGPT+，他们不太可能再花更多钱

- 从 ChatGPT 插件的使用情况来看，只有能浏览网页的插件实际上有用，而这已经成为 ChatGPT 的内置功能了

- 很难想象是否有任何自定义版的 CustomGPT 值得付费。目前看来，只有 "与 PDF 聊天" 和 AI 女友等独立 CustomGPT 应用受到欢迎。而与 PDF 聊天功能已经内置在 ChatGPT 中。

我预测会有一些角色扮演类的 CustomGPT 应用出现，但我怀疑用户是否愿意为此付费。

- 对于以发展 AGI 为目标的 OpenAI 来说，这是一种巨大的分散注意力的事项。我们至今还未看到 GPT 4.5，更不用说 5.0 版本了

- 如果 OpenAI 想增加收入，他们其实更应该将来免费提供 GPT-4，并通过升级至 4.5 或 5.0 版本来获利。目前免费版提供的 GPT-3.5 还不够理想。

- 这对 OpenAI 来说将是一个巨大的挑战，包括处理内容审核问题、处理消费者对开发者欺诈行为的投诉等。

时间将证明我的预测是否正确。

### 27

方军 2024/01/07

想不到 AI 在这里找到一个应用场景

比尔·阿克曼：

昨晚，MIT 没有人睡个好觉。

（在他夫人被挑刺之后，这家伙疯了，不过，她夫人那个真不是什么问题，二，文科这些破事真翻，科技类没啥事，科技类就是 PS PS 图片得意）

昨天晚上，就在我发布消息称我们将对麻省理工学院所有现有教员、校长科恩布鲁斯、麻省理工学院行政成员及其董事会进行抄袭审查后不久，我确信校园里可以听到集体倒吸一口凉气的声音。

为什么？嗯，每个教员都知道，一旦他们的工作成为人工智能的目标，他们就会被淘汰。学术界的任何书面作品都无法在人工智能搜索缺失引号、未能适当释义和 / 或未能正确认可他人工作的能力的情况下幸存下来。

但昨晚没有睡觉的不仅仅是麻省理工学院的教员。@Harvard 的教员、理事会成员和行政领导层也没有睡觉。因为我们为什么要停在麻省理工学院呢？

难道我们不需要深入研究哈佛的学术诚信吗？

耶鲁大学、普林斯顿大学、斯坦福大学、宾夕法尼亚大学、达特茅斯怎么样？你明白了。

虽然我们将对麻省理工学院的抄袭行为进行详细审查，但我们并不是唯一这样做的人。

世界上的每一所学院和大学都必须为自己做同样的事情。他们会这样做，因为他们需要验证所有抄袭指控，否则其他人会为他们做这件事。

然而，最好的方法可能是创办一家人工智能初创公司来完成这项工作 (I 有兴趣投资一项），因为有大量工作要做，而且许多机构没有资源来完成这项工作他们自己的。也许更重要的是，捐助者将要求由独立的第三方进行审查。

今天谁会相信高等教育能够自我审视？

考虑一下本质上不可调和的利益冲突。您相信今天的大学校长会对他们的教师进行检查吗？审查会被用来攻击那些政治观点不受领导层青睐的教员的可能性有多大？

我们之前已经在大学校长及其院长使用的其他工具中看到过这种情况。想想 MeToo 指控、言论代码和其他取消策略的武器化，这些策略摧毁了校园的言论自由，以及许多教职员工的声誉、职业和家庭。

打个比方，即使是我们最可信的公司，谁会相信他们会审计自己的财务报表呢？所有上市公司都设有独立审计师，并接受监管机构的仔细审查，以确保其保持质量、标准、准确性和独立性，这是有原因的。

如果抄袭审查变成了整个大学令人难以置信的尴尬怎么办？这可能会导致教师的大规模解雇。捐赠者终止捐赠。联邦资金被撤回，引发了一场大规模的诉讼大火，教职员工和大学就什么是剽窃、什么不是剽窃相互起诉。想象一下，当它在全国甚至全世界推广时，成千上万名教职员工的声誉将不可避免地受到损害。

也许这是一件好事。

高等教育对社会和国家的影响

当我 10 月 7 日早上醒来时，我的第一个想法并不是要发起一项努力来拯救高等教育本身。我对这个世界还有其他更紧迫的担忧，而且我仍然有这些担忧。但众所周知，我们的高等教育体系（HES）至关重要，因为它能够影响和影响我们年轻一代的思想，从而深刻影响我们所有人的生活。

HES 可以影响幼儿的教学内容以及小学和高中的教学内容，因为教育学校会培训下一代教师和管理者，并设计他们所教授的课程。

HES 可以让一代人相信，我们中的一些人是压迫者，另一些人是被压迫者，并为什么样的暴力和恐怖主义以及何种程度的暴力和恐怖主义是解决这种压迫的适当工具提供了理由。

HES 可以影响我们的医疗机构和医学伦理，例如，我们一些最具争议的程序和药物，以及它们对儿童使用的明智性等等。我相信你明白了。

HES 影响我们的法律体系、我们的道德以及我们对是非的基本理解。

它影响我们如何看待资本主义和经济体系，如何解决财富不平等、税收、货币和财政政策，以及如何考虑普遍基本收入和其他替代方案。

它还影响到宗教以及全国各地的宗教信仰和不再信仰宗教的方式。

它可以提出一种货币理论，该理论指出，美国作为一个主权国家实际上对其支出没有限制，因为它可以印制新钞而不会产生任何后果或丧失偿付能力。

当然，随着时间的推移，我们教育系统的毕业生会成为法官、最高法院法官、政治家、媒体成员以及其他影响和决定我们生活方式的人，并帮助我们理解真理，但谁的真理呢？你可能会问。

HES 影响我们国家投票系统的管理方式；竞选公职的资格标准；初选系统如何运作，以及如何才有资格在某个州参加投票。

我可以继续，但我相信您已经了解 HES 的强大功能。你不需要我告诉你它有多重要。

鉴于 HES 的力量，那些对权力感兴趣的人当然希望控制我们最有声望和影响力的大学，以便他们最终控制我们的教育系统，我们的政府，进而控制整个国家。

人工智能的力量及其对剽窃的影响

既然我们知道美国（最终是全世界）每所学院和大学的每一位教职员工的学术工作都将受到抄袭审查，那么重要的是要问这会产生什么影响。

如果每个教职员工都遵守自己机构当前的抄袭标准，并且大学执行自己的规则，他们可能不得不解雇绝大多数教职员工。

在过去的几周和几个月里，我确实收到了数百封电子邮件、短信、手写和打字的信件和卡片，以及支持电话（以及 X) 上的上千条帖子和回复（如果不是上百条的话，也有十条）—— 来自朋友和陌生人、校友、教师和学生、外国高级领导人、美国参议员和国会议员、知名媒体人士和几位总统候选人 —— 感谢我为帮助解决哈佛大学、麻省理工学院、宾夕法尼亚大学的问题所做的努力尽管如此，大多数人对必要变革的机会持悲观态度，因为几乎每个人都认为，由于教师的终身任职制度，需要几十年的时间才能解决这个问题。

然而，好消息是，有了人工智能，解雇终身教授不再是一个挑战，因为解雇那些学术记录有问题的教授要容易得多。几乎可以肯定的是，作者会错过一些引号，并且至少在其论文的一小部分页面上无法正确引用或提供其他作者的出处。我说的是页面百分比而不是实例数量，因为通过与拼写检查出现之前的拼写错误进行比较，可以更好地理解当今的抄袭行为。

例如，如果两篇论文各有 10 个错误，其中一篇论文有 30 页，另一篇论文有 330 页，那么说两篇论文都存在拼写错误是不公平的。标准必须是百分比标准。

拼写 / 抄袭错误有多普遍？这是另一个应该问的问题。所谓的抄袭行为是出现在他们的一小部分论文中还是出现在他们的大部分作品中？

重要的是，在现行制度下，最有成效、最重要的学者面临的风险最大，因为你写的论文和页数越多，你错过引文或某些引号的可能性就越大，而且更有可能有人会这样做。检查，（直到昨天）。对于最杰出和被引用最多的学者来说，抄袭是最大的威胁，因为如果没有人读过你的作品，并且你没有公众形象（也没有与知名人士结婚），那么没有人会花时间看你的作品。

作品越有影响力、越重要，就越有可能面临抄袭审查的风险。但如果你只发表了十几篇长度适中的论文，而且这些论文的影响力不是特别大，引用率也不是很高，那么出现大量抄袭并被发现的风险应该相对较小。

baoyu.io/translations/others/last-night-no-one-at-mit-had-a-good-night-sleep

### 28

方军 2024/01/07

网友：下周 OpenAI 的 GPT store 就要正式发布了，向大家汇报一下我这段时间折腾 GPTs 的成果

其中有一些有趣又有用的小工具，欢迎大家试用体验：

Food Detective：通过照片分析一道菜总体的热量与全面的营养成分。

Pet Pal：宠物护理、行为和健康专家。

Biotica Explorer：识别照片中的植物和动物，并提供详细的百科知识。

蔚小理数据通：分析蔚来、小鹏和理想三家公司的财务数据、商业数据以及股价。

真厉害，能折腾。

### 29

方军 2024/01/08

摘：GPT 从技术能力维度本质上是一个 ChatGPT 的分身，能力跟 ChatGPT 是一样的，但区别是每个开发者在创建 GPT 的时候，都为他设定了一个使用场景，这个场景不是万能的场景，不是什么都可以干，是一个具体的场景，是定义了具体为谁解决什么具体问题的场景。

[ChatGPT 插件不行，GPT 就行了？](https://mp.weixin.qq.com/s/D8y53LZ13B59UE9iLFubsw)

### 30

方军 2024/01/08

### 31

方军 2024/01/08

我不怎么愿意参加跨越边界的讨论，更不愿意参加什么 panel，一个原因可能是费曼毒中得太深。（后附一段费曼的吐槽）

和专业的人讨论，很简单啊，你提一个词，人家就明白。

给普通大众讲解也很好，我们努力做好一切，通俗易懂地让人家能懂。

杂七杂八的讨论最烦，你都不知道各自在讨论什么。

有多少人讨论前会定义问题？

我想，工程出身的人不太容易犯这种错，不只是费曼这种理论物理学家，为什么呢？因为工程出身的人，必须先定义问题，并定义目标，然后再解决问题。不定义问题、不定义目标，那就没必要说什么解决问题了。瞎扯呗。

摘一段费曼的吐槽：

\## 自负的傻瓜

最后到了评估这次会议的时候，其他人都在说他们从中取得了多少收获，会议有多成功，等等。当他们问到我时，我说：「** 这场会议比罗夏墨迹测验还要糟糕 **。别人问你，你认为你看到的那个毫无意义的墨水斑点是什么，但当你把想法告诉他们时，他们却说你说得不对！」

更糟糕的是，在会议即将结束时他们本来还要再开一场会，这一次公众也会参与进来，可是负责我们小组的那个人竟然说因为我们的工作成果斐然，所以接下来不需要公众讨论部分了，我们只要告诉公众我们讨论的所有成果就行了。我大跌眼镜：我认为我们连个屁都没有得出来！

最后，当我们讨论到我们是否在不同领域的人之间找到建立对话的方式时 —— 我们的第二个基本「问题」—— 我说，我注意到一件有趣的事。我们每个人说的都是我们所想的「平等伦理」，从自己的观点出发，忽视其他人的观点。举例来说，那位历史学家提出，理解伦理问题的方法就是从历史中找寻人类进化和发展的答案；那位国际律师建议，我们的方法应该是研究人们在不同情境下实际采取行动和制订计划的方式；那位牧师总是在说「知识碎片化」；而我，作为一位科学家，提出我们应该把问题隔离出来，就像伽利略做实验时那样；等等。「所以在我看来，」我总结说，「我们之间完全没有对话。我们有的，只是混乱。」

当然，我被群起而攻之。「你不觉得混乱可以产生秩序吗？」

「哦，是作为总体原则，还是……」我不知道应该如何应对「混乱中会产生秩序吗？」这样的问题。会，不会，问的到底是什么？

参加那场会议的人中有很多傻瓜 —— 自负的傻瓜，而 ** 自负的傻瓜 ** 能把我逼疯。普通傻瓜不成问题，你可以和他们对话，试着帮他们解除误会。

但是我无法容忍自负的傻瓜 ——** 掩饰自己的愚蠢并用连篇的鬼话把自己包装成智者的傻瓜 **！一个普通的傻瓜不是骗子，一个诚实的傻瓜没什么解决不了的，但不诚实的傻瓜令人讨厌。

而这就是我在那场大会上遇到的人，一群自负的傻瓜，我为此感到心烦意乱。我不想再经历这种事情了，所以从此不再参加跨学科会议。

方军：还中了一句费曼毒：

挑战者号费曼报告（调查委员会报告附录）的最后一句话：

一项技术要成功，尊重现实远比维护公共关系重要得多，因为大自然是不会说谎的。

2024-01-08 17:38

### 32

方军 2024/01/08

看费曼总会乐死，他真是个讲故事的天才

第二天早上，一辆豪华轿车来接我 —— 有人安排我们乘坐豪华轿车去参加第一场正式会议。我坐在前座上，旁边是司机。

去参会的路上，司机对我说：「我知道有很多重要人物都在这个委员会里……」

「是啊，好像是……」

「我喜欢收集签名，」他说，「你能帮我个忙吗？」

「没问题。」我说。

我正往外掏钢笔，这时他说：「到那儿之后，你能指给我哪位是尼尔·阿姆斯特朗吗？我想跟他要个签名。」

### 33

方军 2024/01/08

我对翻译没有兴趣，但我真心希望 AI 能够挽救中文翻译。

费曼传（Genius 那本），我本以为之前高教社那本够差，但一对比，啊呀，新版更糟糕。

比如这两句：

A few Europeans were absent, as was Albert Einstein, settling into his statesmanlike retirement, but with these exceptions the Pocono conclave represented the whole priesthood of modern physics.

新版：几名欧洲科学家缺席了，其中包括阿尔伯特·爱因斯坦（Albert Einstein），他正处于像政治家隐退一样的状态。即便如此，波科诺会议代表了现代物理学的全体「神职」人员。

高教版：有几位欧洲物理学家没有出席，爱因斯坦也没到，他刚刚退休，过着政治家一样的退休生活。除了这少数例外，在波可诺秘密会议囊括了当代物理学所有的祭司。

全体「神职」人员。这个翻译也太搞笑了。

其中包括爱因斯坦也不对。

高教版看起来还不错，语句也很通顺。

下一句

Night fell and Feynman spoke. Chairs shifted. The priesthood had trouble following this brash young man.

新版：夜幕降临，费曼开始发言。椅子换了位置。「神职」人员很难跟上这个粗鲁的年轻人。

高教版：天色晚了，轮到费曼作报告，现场可以听到椅子移动的声音。这群祭司不太可能跟得上这个急性子年轻人的思路。

新版这都翻译得什么鬼！

天啦，我这种老牌的费曼粉丝，都会中招，普通人呢？

---

墓志铭的翻译

「An honest man, the outstanding intuitionist of our age, and a prime example of what may lie in store for anyone who dares to follow the beat of a different drum.」

新版：「一个诚实的人，我们这个时代杰出的直觉主义者，也是敢于追随不同鼓点的人可能遇到的最佳楷模。」

高教版：「他是一个诚实的人，是我们这个时代的最卓越的直觉大师，对那些勇于追随不同鼓声前进的人，他是一位非常值得师法的对象。」

这句话蛮难翻译的，有很多隐含含义，高教版要好一些。

改进：「他是一个诚实的人，是我们这个时代的最杰出的直觉大师，对那些勇于追随不同鼓声前进的人，他是一位值得师法的楷模。」

其中的英语用法：lie in store 以前还真没注意过，例句：

"What lies in store for my career as a lawyer?"

---

补上前言的最后一句：

When Feynman was gone, he had left behind—perhaps his chief legacy—a lesson in what it meant to know something in this most uncertain of centuries.

新版：费曼离开了，他留下了一个教训，这也许是他最重要的遗产：在这个最不确定的世纪里，了解一些事，意味着什么。

高教版：费曼走了，他留下了一个教训，告诉我们在这一切都不确定、最混沌不明的 20 世纪，懂一点知识到底有什么意义。这也许是他最重要的遗产吧。

再一次，新版不太好。

不过，按我的理解，高教版似乎也不对。

我认为应该是这样：

费曼走了，他留下了一个教训，这也许是他最重要的遗产，他告诉我们，在（20 世纪）这数个世纪中的最不确定性中：真正理解到底意味着什么？

what it meant to know something

know something，在这里应该是真正的理解。

刚刚才发现，in this most uncertain of centuries. 这句话也好难翻译，尤其其中的不确定性还有量子物理的不确定性的意思。不过这个词组无关大雅，错误都还好。还是关键句最重要，我们究竟要从费曼身上学到什么：

what it meant to know something

方军：刚刚跟一位老师讨论的：三个问题，中文不好的问题基本上无解。目前不太行的，连正常的长句理解都有问题。附加词汇表可以部分解决词汇问题。长句理解靠提示语可以部分解决。中文不好的问题，目前还没好方法。

目前 AI 用来 1）对照理解；2）个别解释。

2024-01-08 23:40

方军：know 翻译成真正理解肯定很多人觉得夸张了，可是这句话应该是这个意思。

就像这句：night fell and feynman spoke. Chairs shifted. 不理解根本不知道讲啥意思。当然这是过场，前后知道，它讲啥不重要，就觉得这两句英文好简单。

2024-01-09 11:10

### 34

方军 2024/01/09

LangChain 0.1.0 发布了。

它终于上了一个版本号，python 和 js 功能看起来完全同步了。

blog.langchain.dev/langchain-v0-1-0

重大变化：

将 langchain-core 分离出来，这个部分应该会相对稳定了。

亮点：

Langchain Express Language LCEL

Stream

Output parsing

Retrieval

Agent

langgraph

### 35

方军 2024/01/09

转：QuestMobile 2023 年 11 月数据显示，文心一言 APP 月日均活跃用户规模已达 155.4 万，甚至不如比亚迪海洋网的 APP。

补充信息，11 月 9 日，文心一言宣布用户规模 7000 万。感受下当下国内 AI 产品的粘性。

另外，字节的豆包 124.6 万日活，讯飞星火 71.9 万日活。

### 36

方军 2024/01/09

百川智能发布角色大模型 ，零代码复刻角色轻松满足游戏领域定制需求

今日起，用户登录 npc.baichuan-ai.com，即可开启全新的角色创建之旅。

为提高角色定制自由度，百川智能自研了强多轮对齐和搜索增强知识库两项特色技术。强多轮对齐技术通过精心设计 System Prompt 中的角色设定字段，强化了角色创建平台 System Prompt 在对话 Session 中的特殊地位。

简单来说，用户在系统提示（System Prompt）中定义了角色特征后，角色就会完全遵循用户设定进行相应的「演绎」。

[百川智能发布角色大模型 ，零代码复刻角色轻松满足游戏领域定制需求](https://mp.weixin.qq.com/s/Edw7D-Fh_cmqq02mJrkHyA)

\#新产品动态 #

方军：对这样的产品，我好大的疑虑啊

2024-01-09 15:36

方军：炫技可以，实用价值 0。

当然，百川这样的公司需要炫技。

2024-01-09 15:38

方军：不知道它的实现。我猜应该是，基础模型 - 微调模型 - 特定微调模型。按描述，它应该在特定微调模型里面干了很多事。

但是，其实大模型公司不应该在特定微调模型里面搞太多事。

openai 的之前也搞了什么 codex，但后来发现，微调模型也就是 instructGPT 才是核心。

特定微调，让客户自己干好了。

2024-01-09 15:48

方军：这儿还把 RAG 加进去，更是真想做基础大模型的公司不该做的事。

当然，我这是站着说话不腰疼，大模型公司都想着法子让客户用，不自己多干点，客户用不起来。没辙，所以多干。

能理解他们的做法。

2024-01-09 15:50

方军：为什么我说实用价值 0？

因为搞过提示工程的都知道啊，所有人学的第一个技巧是赋予角色。

但这个几乎毫无用处。

是个进门了就要扔掉的技巧。

2024-01-09 17:44

### 37

方军 2024/01/09

1 月 3 日，教育科技公司网易有道举办「子曰」教育大模型创新成果发布会。在发布会上，网易有道宣布推出国内首个教育大模型「子曰」2.0 版本，同时还发布了基于大模型研发的三大创新应用及一款智能硬件新品：AI 家庭教师「小 P 老师」、有道速读，虚拟人口语私教 Hi Echo 2.0，以及有道 AI 学习机 X20。

[有道再推多款大模型产品及应用，并开源 RAG 引擎「QAnything」](https://mp.weixin.qq.com/s/Mfrhp4eKM4VzdotGK9hs1Q)

\#新产品动态 #

### 38

方军 2024/01/09

OpenAI 刚发了一条长文回复纽约时报的指控，从 4 个方面进行了回应。

1. 表明对于新闻机构的积极合作态度，愿意共同探索新的合作机会

2. 从法律角度说明训练是合法的，对保持美国科技竞争力是有利的！

3. 原样输出训练内容是个技术上的 Bug

4. 《纽约时报》自己说话也没说全部，因为他们提供证据的数据早就在各大网站被引用，他们采集证据的方式是通过特定的提示词诱导才能偶然复现的。

即便如此，我们还是愿意和新闻结构继续合作，帮助提升新闻能力！

以下为原文翻译：

OpenAI 与新闻业的互动

我们致力于支持新闻行业，与新闻机构建立合作关系，并认为《纽约时报》提起的诉讼缺乏法律依据。

我们旨在开发 AI 工具，帮助人们解决那些难以触及的问题。全球各地的人们已经在利用我们的技术，以提升他们的日常生活质量。目前，有数以百万计的开发者和超过 92% 的《财富》500 强企业在使用我们的产品。

尽管我们对《纽约时报》诉讼中的指控持不同意见，但我们认为这是一个阐明我们业务、意图和技术开发方式的好机会。我们的立场可以概括为以下四点：

1. 我们正在与新闻机构合作，共同探索新的合作机会。

2. 使用 AI 进行数据训练在法律上属于合理使用，但我们提供选择退出的选项，因为这是合乎道德的做法。

3、 技术上的「信息原样输出（Regurgitation）」现象较为罕见，我们正致力于将其完全消除。

4. 《纽约时报》并没有呈现事情的全部面貌。

1. 我们正在与新闻机构合作，共同探索新的合作机会

在我们的技术设计过程中，我们致力于支持新闻机构。我们已经与众多新闻机构以及行业领先组织如新闻 / 媒体联盟进行了会谈，共同探索合作机遇，讨论他们的关切，并提供相应的解决方案。我们的目标是学习、普及知识、倾听反馈，并根据这些反馈做出调整。

我们旨在支持一个健康的新闻生态系统，成为一个值得信赖的合作伙伴，创造互利共赢的机遇。为此，我们已经与多家新闻机构建立了合作关系，以实现以下目标：

部署我们的产品以辅助记者和编辑，帮助他们处理如分析大量公共记录和翻译报道等耗时任务。

通过在额外的历史性、非公开内容上进行训练，增进我们的 AI 模型对世界的了解。

在 ChatGPT 中展示带有归属的实时内容，为新闻出版商提供与读者建立联系的新途径。

我们与美联社、阿克塞尔·施普林格、美国新闻项目和 NYU 的初步合作，展现了我们的合作方法和愿景。

我们的这些早期合作伙伴关系，不仅有助于新闻行业的发展，也展示了我们在技术创新方面的承诺，以及对支持新闻自由和信息传播的坚定立场。

2. 虽然利用公共互联网材料训练 AI 模型属于合理使用，但我们提供退出机制，因为这是负责任的做法

根据长期而广泛接受的先例，利用公开可获得的互联网材料来训练人工智能模型被视为合理使用。我们认为这个原则对创作者公平，对创新者是必需的，同时对美国的竞争力至关重要。

将 AI 模型的训练视为合理使用的原则得到了广泛的支持，包括学术界、图书馆协会、民间社会团体、初创企业、领先的美国公司、创作者、作者等，他们最近向美国版权办公室提交了意见。其他地区和国家，如欧洲联盟、日本、新加坡和以色列也制定了允许在版权内容上训练模型的法律，这对 AI 的创新、发展和投资大有裨益。

尽管如此，法律权利对我们来说并不如做一个良好公民那样重要。我们在 AI 行业中率先提供了一个简单的退出流程，供出版商选择（例如《纽约时报》在 2023 年 8 月选择使用），以防止我们的工具访问他们的网站。

3. 我们正致力于消除「信息原样输出（Regurgitation）」这一罕见的错误

注："Regurgitation" 指的是 AI 模型在生成输出时重复其在训练数据中已经接触过的信息或内容。这通常被视为一种错误或失败，因为理想中的 AI 应该能够产生新颖的、基于理解和推理的回答，而不是简单地复制和重复它在训练过程中所遇到的具体信息。这种现象在模型训练过程中遇到重复或过度代表的数据时更为常见。

我们设计并训练了模型，目的是让它们学习概念，进而能够应用这些概念解决新问题。

记忆问题是学习过程中较为罕见的一个弊端，我们正在努力改进。这个问题在特定内容在训练数据中重复出现时尤为明显，例如同一内容在多个公共网站上出现。因此，我们采取了措施来减少不经意的记忆，并防止模型输出中的内容重复。我们也期望用户能负责任地使用我们的技术；故意引导模型重复输出信息是不恰当的，这违反了我们的使用条款。

就像人类通过广泛学习来解决新问题一样，我们希望我们的 AI 模型能观察到世界各地的信息，包括来自不同语言、文化和行业的知识。由于模型是基于人类知识的大量集合进行学习，任何一个特定领域，比如新闻，都只是训练数据中的一小部分。同样，任何单一的数据来源，如《纽约时报》，对于模型的整体学习目标来说也不是特别关键。

4. 纽约时报并未全面报道真相

我们与纽约时报的对话在 12 月 19 日的最后一次沟通中似乎还在顺利进行。谈判主要围绕 ChatGPT 实时展示新闻内容并标明来源的高价值合作，纽约时报将通过这种新方式与现有及潜在读者建立联系，而我们的用户也能够接触到他们的报道。我们曾向纽约时报明确表示，他们的内容像其他单一来源一样，并没有对我们现有模型的训练产生重大影响，对未来的训练也不会有显著贡献。然而，我们在阅读纽约时报的报道时才得知他们于 12 月 27 日对我们提起诉讼，这让我们感到意外和失望。

在此期间，纽约时报曾提到发现一些内容被重复引用，但他们一直拒绝提供任何具体案例，尽管我们已承诺调查并解决任何相关问题。我们一直严肃对待这一问题，例如在 7 月份，我们得知 ChatGPT 功能可能意外复制实时新闻内容后，我们立即关闭了该功能。

有趣的是，纽约时报所指的重复内容似乎来自多年前的文章，这些文章已在多个第三方 - 网站上广为流传。看来他们故意设置特定的提示语，常包含文章的长篇摘录，以引诱我们的模型进行复述。即便在使用这样的提示语下，我们的模型通常不会如纽约时报所言那样反应，这表明他们可能是指导模型复述或从众多尝试中挑选示例。

不管他们怎么说，这种误用并非典型或被允许的用户行为，也不能代替纽约时报的内容。无论如何，我们正在不断提高系统对防范敌意攻击和复述训练数据的抵抗力，在最新的模型中已经取得了显著进展。

我们认为纽约时报的诉讼毫无依据。尽管如此，我们仍期待与纽约时报建立建设性的合作关系，并尊重其拥有超过 60 年历史的报道，其中包括报道第一个运行中的神经网络和捍卫第一修正案自由的长期传统。

我们期待与新闻机构继续合作，帮助他们利用 AI 的变革潜力，提升制作优质新闻的能力。

来源：openai.com/blog/openai-and-journalism

### 39

方军 2024/01/09

杨立昆：

The speed at which a technology disseminates in the economy is limited by how fast people learn to use it.

技术在经济中传播的速度受到人们学习使用的速度的限制。

twitter.com/ylecun/status/1744561157724119418

### 40

方军 2024/01/09

看到 2022 年 1-3 月写的几篇长到极限的技术指南（tutorial），那是初次写较长的英文文章，现在看几年过去了，有 3 篇 2 万访问量以上，1 篇 1 万访问量以上。还好还好，为某种技术的传播普及做了点微小的贡献。

长到什么程度呢，每篇似乎都有 5000words + 一定数量的代码。

那是对那项技术充满热情的时期，现在我还能写那种代码，但兴趣寥寥了。

### 41

方军 2024/01/10

看人推荐这本书，看似不错，我蛮喜欢图解，其实我都曾想搞本图解。

之前专门写算法的那位写的图解，有点过于简单（太漫画了，有点公众号式的过度简化）

国外那个专门图解 GPT 的系列文章，很赞。这本国内作者写的应该也超不过，但书可能要体系一些。

摘：《GPT 图解大模型是怎样构建的》：写作的特点就是能一环扣一环，每个知识点的讲解都会有铺垫，不会感觉生硬。

[The Illustrated Transformer – Jay Alammar – Visualizing machine learning one concept at a time.](https://jalammar.github.io/illustrated-transformer/)

### 42

方军 2024/01/10

Quroa 创始人刚刚在官方博客宣布，已经从 a16z 那融了 7500 万美金，主要用于旗下 AI 产品 Poe 的发展，不过整个 Quora 的估值为 5 亿美金，比之前最高 18 亿美金的估值大幅下降了。Adam D'Angelo 说，大部分费用可能用于支付给平台上的 Bot 创作者，对于 Bot 创作者来说，这应该是一个好消息，这也意味着 Quora 的未来可能主要放在 Poe 上了，而一种新型创作者经济也就此诞生了。

[超喜欢的一个产品再拿 6000 万美金，a16z 投 Poe 7500 万美金要做 AI 浏览器](https://mp.weixin.qq.com/s/VJWrOO9rDq0f18eNV5p7bg)

### 43

方军 2024/01/10

AI Agent 公司 MultiOn 正式公开亮相。

该公司主要开发从事订票、订餐、购买书籍、预定航班等辅助类工作的 Agent，帮助人类从繁重枯燥的日常工作中解放出来。该公司希望打造类似于 JARVIS 的实体或《HER》中的女友。

公司创始人为 Omar Shaya、Div Garg，两人相识于斯坦福大学，Div 在斯坦福从事 LLMs 和强化学习的研究，后来在苹果、谷歌和英伟达等公司工作；Omar 则在微软和 Meta 公司先后领导团队开发消费类人工智能产品。

该公司已拿到来自 General Catalyst 、 亚马逊 Alexa 基金、 maven ventures 、 三星 Next 以及 OpenAI 员工，GoogleDeepMind 早期支持者等的投资。

\#新产品动态#

### 44

方军 2024/01/11

OpenAI 在推特上更是霸气地表示，目前用户已创建超过 300 万个 GPTs，现在你可以找到最适合你的专属「ChatGPT」。

[重磅！OpenAI 官宣上线 GPT Store！超 300 万个 GPTs 大爆发](https://mp.weixin.qq.com/s/Q9AZHEX6GeloJbMr1-GUXw)

### 45

方军 2024/01/11

《GPTs TOP100 深度体验分析报告》作者椒盐玉兔，用 PPT 的形式很全面总结了 Top100 的 GPTs，他通过算法，筛选出了目前访问量（Chats）超过 1000 的 GPTS，共 458 个，其中 Top 100 为头部 GPTs，门槛是 5.2k Chats；Top 20 为顶级 GPTS，门槛是 20.2k Chats。

2『已下载原文件「20240111GPTs Top100 深度体验分析报告」收录入「2024011大语言模型专题资料」。（2024-01-14）』

### 46

方军 2024/01/11

A16z 投资 Quora 和 Poe 的文章值得一看，节选一部分：

「迄今为止，普通消费者接触 AI 的机会通常仅限于玩玩 ChatGPT 或现有应用程序和工具中的新人工智能生成功能。

同样让我们这些技术人员感到兴奋的是，模型的激增、GPU 效率的提高、开源以及对更小、更专业的模型的微调，这些对于普通消费者来说都是令人生畏的。

我们相信，不会有一种模型能统治所有领域，我们将需要许多模型来满足不同的模式和使用情况。但目前，为了推动 AI 原生工具的采用，存在太多的模型和太多不同的用户界面。要想让人工智能跨越鸿沟，惠及全球 50 多亿互联网用户，它就必须更直观、更易用。

因此，我们非常高兴地宣布，我们已经投资了 Poe 的创造者 Quora。其他人工智能公司专注于构建最佳模型，而 Poe 则肩负着双重使命：1）成为消费者在同一工作流中与各种人工智能产品互动的最佳方式；2）成为开发者构建多模态人工智能产品并触达大众的最简单方式，无论是通过激活现有模型创建 bot 还是自行训练模型。」

「或许更具吸引力的是，就像 Roblox 为游戏所做的那样，Poe 正在构建工具，让创作者修改现有模型，释放那些想要构建人工智能但没有资源的人的创造力。Roblox 创建了游戏引擎，提供分发、信任和安全、基础设施以及创作者赚钱的机会。结果产生了强大的网络效应 —— 创作者越多，用户就越多地来玩这些创作。用户越多，就吸引了更多的创作者。

Poe 的创作者工具正在早期开发阶段，但提供了类似于 Roblox 的好处，包括多平台基础设施、发现功能以及 bot 创作者能够产生收入的能力。目前，Poe 显示出递增的规模回报迹象。目前，Poe 是最大的 5 个人工智能相关生成工具之一，创作者已在 Poe 平台上构建了 100 万个以上的 bots。凭借这一轮最新的融资，Quora 计划进一步帮助 AI 创作者和开发者实现其创作的货币化。」

[Investing in Quora and Poe | Andreessen Horowitz](https://a16z.com/announcement/investing-in-quora-and-poe/)

### 47

方军 2024/01/11

部分赞同：很多人可能对 AI 知识库有一个误解，以为只要把手头现有的各种文档扔给它就叫知识库了，去年我们老板也是这么认为的，觉得那不是很快嘛，分分秒秒就能搞定，然后我和技术部的负责人只好面面相觑。

知识库可以简单地理解为在底层模型的原有基础上，多了一部额外的字典，本来模型只认识 3500 常用字，有了字典后，你可以告诉它在字典里面查找生僻字。

这和模型训练微调的区别在于训练等于让模型从底层也学会了生僻字，模型不再需要这部额外的字典就能查询生僻字。

而知识库只是外挂的手段，模型需要根据你的指令去字典里面查，脱离知识库这部字典，底层模型依然没办法告诉你生僻字。

但是知识库和模型训练又有一点相同的地方，就是你喂给它的数据集是需要编排，需要特定格式的，不是随随便便一个文档就行的。训练微调就不展开说了，这里简单说一下知识库。

知识库一般使用三种方式来建立和处理文档：

一、按字数分段；

二、模型自动按语义分段；

三、QA 问答对。

1、按字数分段，这是最简单也是最粗暴的方式，目前的很多能传文档的框架都是根据你设定的分段字数粗暴地把文档分割成片段。这种分段不会考虑语句、段落、主体的完整性，因此反馈的答案一定是不符合你要求的，数据的召回率正确度非常低，因此这种方式用得很少。

2、模型自动分段，模型根据你的文档，基于本身的能力为你分段，那么这个模型就需要很强，那种 7B、13B 显然不是很合适，起码也要 70B 这种级别以上的，因此我个人觉得不是 GPT4 这个层次的模型，那么也最好别用，否则准确率也是堪忧的。

3、QA 问答对，前面两种都不推荐，那么显然就只剩下最后一种了，QA 问答对是准确率最高的文档编排方式，一问一答，或者多问一答。比如：

Q：中国有多少个省份？

A：中国共有 34 个省级行政区域，包括 23 个省，5 个自治区，4 个直辖市，以及香港，澳门 2 个特别行政区。

同一个答案，肯定不同的人有不同的问法，所以有时候做问答对的时候需要有几个不同的问法，比如：

中国有多少个省份？

中国的省份具体有几个？

中国的行政规划有几个省市？

.....

类似上面这样的，以问答方式编排的文档，是准确率最高的格式，同样也是做知识库，乃至微调模型最好的格式。这么好的方式当然也会带来很显著的问题，就是时间和人工。

客户提供的文档，肯定不会是问答对的格式，因此你需要安排专门的人来把文档做成问答对，这个人啊，需要比较强的语言文字能力，善于归纳总结，提炼问题。这种岗位你说很难吧，干的其实是苦力活，你说简单吧，又需要很好的文字功底。我大概想了想估计只有教师职业是最适合干这个的了，能根据内容想出问题，编排答案。

能把文档做成问答对的人，能力毋庸置疑，然后就是时间成本，从长篇大论中拆分出一个小小的段落，再加上以提问者的角度编排问题，可想而知这种时间和精力的消耗并没有多少人愿意干（除非给钱）。

所以这可不是一些甲方爸爸想的那么简单，丢一篇文档进去 AI 自己就能搞好的。如果是一些通用领域倒还好说，毕竟网络上已经有了不少相关的数据集，拿来就能用，但是很多专业领域，甚至某一个领域中的细分部门要建立自己的知识库，可能只能在内部找人来做这件事情。

各位如果觉得自己的知识库好像效果很一般，那一定是数据集的问题，自己玩玩当然也没必要特地去搞。但如果你有这个业务需求，那就需要准备一个这样的岗位来处理这种细分领域的数据集。

根据我目前接触到的各种项目来看，这块的市场需求非常大，知识库或者专有模型在企业中存在很大的缺口，算力不是桎梏，做数据集的人工和时间才是。

王晓峰：是不是 GPT5 能解决这个问题？

2024-01-12 21:51

方军回复王晓峰：不能

2024-01-12 22:02

### 48

方军 2024/01/12

摘：奥特曼在 YC W24 启动会上的演讲要点：

- 奥特曼暗示我们可能已经非常接近实现通用人工智能（AGI）

- 他建议应该以通用人工智能的实现为前提进行创业和技术开发。（不要再瞎折腾）

- GPT-5 可能会相对于 GPT-4 有一个指数级的跳跃，尽管 GPT-4 已经领先近两年，至今无人超越。

- 这个进展将会给初创企业和现有公司带来了许多问题和挑战。（AGI 将覆盖一大批创业者）

- 建议使用最先进的模型（State of the Art, SOTA），而不是花费太多时间进行微调和优化。（徒劳无功）

- 最正确的做法是设想一个「上帝般的」模型正在运作，然后基于这种设想来构建最好的产品。（要及其有远见）

- @OpenAI API 将继续变得更快、更可靠、更便宜。然而，性能和成本之间始终存在平衡。例如，尽管电池技术已显着改进，但 iPhone 仍将保持 1-1.5 天的电池寿命以优化性能。

- 不建议建立产品业务主要致力于解决当前 GPT4 的限制的内容。因为大多数限制将在 GPT-5 中部分 / 全部修复。（你会被覆盖）

- 初创公司更需要情境优化，而不是行为优化。通过 RAG 等提供更多信息可能比微调更有益。

摘：鉴于 Sam 在 YC 上提到了 GPT-5 和 AGI，这个建议也比较靠谱：正确的策略或许应该是采用最新的模型，而不是过多投入在微调和提前优化上。

全文翻译：

在 Y Combinator 的启动会议上，Sam Altman 强调我们已经非常接近通用人工智能 (AGI)，并建议我们在未来的技术开发中应考虑到这一点。

GPT-5 有望在技术上实现对 GPT-4 的巨大飞跃（他们在将近两年前就已完成了 GPT-4 的开发，而到目前为止还没有任何产品能超越它）。

这种情况给当下的初创企业和大公司带来了众多挑战。

许多人都以为模型只会缓慢进步，但实际情况似乎并非如此。

正确的策略或许应该是采用最新的模型，而不是过多投入在微调和提前优化上。

更好的做法是，想象一个拥有极高智能的模型会如何运作，并以此为蓝本，构建尽可能优秀的产品。

这正是为什么我们在 Cognosys 如此努力地开发最佳产品和用户体验，我们选择使用智能体而不是从零开始训练模型或进行不必要的早期优化。

对我们来说，模型越先进，我们的产品就能越出色（可以想象，性能提升可能达到 10 到 100 倍）。

### 49

方军 2024/01/15

有意思，这个互动讨论最反映当前 AI 的实际情况。

@宝玉 xp: 来自 Paul Graham：

最近我从一家颇有规模的科技公司的 CEO 那里获知了一个有趣的信息。一般来说，28 岁的程序员要比 22 岁的程序员更高效，主要是因为他们拥有更丰富的经验。但有趣的是，现在的 22 岁年轻人因为更加熟练地运用 AI 技术，他们的编程能力已经媲美 28 岁的程序员了。

这对于那些年轻的创业者来说无疑是个利好消息。他们最初往往因为缺乏编程经验而受到限制，但现在，他们可以将 22 岁时的充沛活力与 28 岁时的高效生产力结合起来。

@信号时代_road: 这是翻译错误。不是 22 岁比 28 岁更会使用 AI，而是心理上更能自在地接受直接使用 AI 辅助，因为他们没有经验嘛。至于有经验的程序员，总觉得 AI 写出来的虽然有时候能到写对，但其实质量和水平比起老鸟自己撸出来的代码差了好几个档次，至少目前来说。

请查 more at ease doing 的含义

（注意，宝玉的翻译就是用 AI 多，但他也略微看过翻译内容）

简言之，要把 28 岁和 22 岁混合起来

补充：目前 AI 代码能力，只要模块拆得够细，比有经验的老手快。当然，老手厉害的本来就不是快，而是拆模块。

方军：我个人的体会是，直接信 AI 是不行的。

比如翻译，用它快速筛选特别好，双语对照看，但直接信容易掉沟里。

相对而言，一个较好的进阶用法是请 AI 帮忙解释。比如上面这个词组，我们可以请 AI 帮我们解释。

具体来说，英语还是要学的，并且我们多了很厉害的新工具，随身的老师。

2024-01-15 12:03

方军：这个词，的确如果不是有行家提醒，我们就会忽略过去不思考。当然，如果看英文没问题的，这这个词组的隐含含义，有英文基础的人猜都能猜到。

2024-01-15 12:08

方军：懂英文的人，不会把那个词理解为「更加熟练」

2024-01-15 12:09

### 50

方军 2024/01/15

OpenAI GPT 商店刚上线三天，GPTs「AI 女友」就已泛滥

OpenAI 上线的「GPT 商店」成为 AI 界 App Store，提供各类付费聊天机器人。然而，该平台被「AI 虚拟女友」机器人淹没，触犯了 OpenAI 的使用条款。这暴露出内容审核困境，以及人工智能伴侣可能引发的社会问题。

[GPT 商店上线！引爆 300 万个 GPTs！但刷榜、山寨也来了！](https://mp.weixin.qq.com/s/oyEGdkpZBNTyVV-VzW7eKA?poc_token=HCodpWWjB0m_nRq4hafTgrqOe51rCsHsPOQIlN6a)

### 51

方军 2024/01/15

我在想，这本书，如果让 AI 读行不行？

我觉得可能永远不行。

之前讨论知识付费时，我最重要的观点是：

对于读者而言，书是半成品，我们花时间精力读了，它对我们才变成成品。

花多少时间精力、有多少技巧，决定我们能从一本书中得到的收获。

这也是为什么我其实看不上讲书，讲书是假象。

那么退一步，我编写的这个电子小书，读了会不会帮你更方便地读书呢？我觉得也不会，受益的始终是我，而非别人。（从读书阶段看，这个电子小书背后不是高阶读书，但至少是中阶，因为有了纠正原中文版翻译以更准确理解这个步骤。）

那么，就没有捷径了吗？

有，有些书可以不读，因为如果找到合适的人请教，有些书是可以被有效的请教取代的。

但是，很明显，如果你有能力读书，那么可以更好地请教，向更牛的人请教，得到更深的启发。

AI 的用途是为这个读书过程提供辅助。

### 52

方军 2024/01/15

虽然前几年我们对全数字化的元宇宙、这一两年对 AI 写文章和语音甚至视频有很多设想和探索，但我有个爆论，别以为假人能骗过用户。

互联网有个真实的段子，某论坛早期很多假美女用户，后来人跟创始人说，你们那个里面全是人妖。

怎么突然这个感慨呢，我坐车听旁边人播 AI 配音视频听吐了。自己看的时候没那么明显，但当没有用注意力、只是旁听时，假 AI 声音让人极其烦躁。

另外，假文章也是非常明显的，目前还没法逻辑说明，但其实我们所有人分辨假 AI 文章的能力都特别强。

目前真与假的判断，是任何普通人能随便看出来，但专家却总结不出 1234 的阶段。

### 53

方军 2024/01/15

AI 翻译就这么个水平，我们作为 AI 专业人士，不要被外界的喧嚣迷惑。

摘：国内外新闻用机器翻译有很多陷阱要留个心眼不可尽信。比如英国科幻迷 John 在用 Google Translation 看超侠的成都世界科幻大会见闻录时就遇到了下面这个极端例子离了大谱的错误翻译。据说 DeepL 也不知道撸串的意思。

### 54

方军 2024/01/16

看院士演讲，院士讲得很精彩，深入浅出，不过也很欣慰，我们的认知水平跟院士在一个起点上。

「我们要把机器当作最好的助手。」

同时在看中文区 langchain 资料，发现真是快速变化，当时这个网站做的 v0.0.206 的资料版本（Last updated on June 21, 2023），可以说完全过时了。

这是 AI 发展速度快的一个侧影。

### 55

方军 2024/01/16

这个技术写作手册不错

当然，它的组织方式严重地不技术化。

1『已下载原文档「20240116技术写作手册-Thoughtworks」存入。（2024-01-16）』

### 56

方军 2024/01/16

OpenAI 今日发布了一篇博客，表示为应对 2024 年美国大选，保证平台安全工作做出了一些举措，包括：

防止 deepfakes 等 AI 滥用；

提供 AI 生成内容的透明度；

改善对权威投票信息的获取；

[OpenAI 将推出新的 AI 工具，旨在防止美国大选期间虚假信息传播](https://mp.weixin.qq.com/s/vlMni-ZUhh7EJuiPxENQ0Q)

### 57

方军 2024/01/16

【Bluestone Markdown：所见即所得的 Markdown 编辑器，采用 GFM 语法，支持 Mermaid 图形和 Katex 公式，提供浅色和深色主题。

它允许将 Markdown 文件生成为在线文档，适用于文档发布。

与标准 Markdown 编辑模式相比，Bluestone 将富文本与 Markdown 编辑习惯相结合，使记录更高效。

它还具有自动记录和清除文件历史、代码高亮、表格操作、数学公式支持等功能，以及 HTML 和 PDF 导出。

此外，Bluestone 还支持多标签编辑模式和粘贴 HTML、纯文本和 Markdown 代码。它还可以自动调整文件链接的路径】

Bluestone Markdown - A WYSIWYG Markdown editor, improve reading and editing experience. and generate your Markdown files into online documents in the easiest and fastest way.

GitHub: github.com/1943time/bluestone

方军：我稍后再补些想法。我现在已经完全不能适应所见即所得的编辑器，而这个延展开有很多说道。

2024-01-16 14:55

方军：我已经习惯了多屏幕，然后一个屏幕编辑，一个屏幕显示最终结果。

这个比较适合工程人员的心态，把工程和结果完全分开。

普通人估计还是都极度喜欢可见即所得。但互联网这些年发生的变化是，界面不再支持复杂的编辑。

2024-01-16 15:13

### 58

方军 2024/01/16

我为何依然对这些公司的图像模型提不起兴趣？尤其是图像生成？

图像识别倒是需要的，但目前也仍然找不到场景。

[智谱 AI 发布国产最强大模型 GLM4，理解评测与数学能力接近 GPT-4，还有对标 GPTs 商店的 GLMs 商店与开发者分成计划](https://mp.weixin.qq.com/s/lQauA7WTOrYR8C_pkjS18A)

### 59

方军 2024/01/16

我们作为 AI 专业人士，一个重要的修养就是，

千万别鼓吹 AI，知道它的不足。

比如，GPT 的结果就是这么个结果，是不对的。

Generative AI 是这个吗？放在现在的场景下肯定不对。

为 GPT3.5 的回答，左图。

换成 GPT-4-1106-preview，效果也没有变得更好（右图）。

当然，也许有人认为，这个蛮好的啊，跟书里都一样，但以我当前对生成式 AI 的理解，这个解答是对普通人理解价值很小的。

---

GPT-4-1106-preview 结果：

生成式人工智能（Generative AI），指的是人工智能技术中的一个子集，它能够创造新的内容。这些内容可以包括图像、视频、音乐、文本和代码。「生成式」这个词指的是 AI 能够生成未被明确编程的输出，而是通过学习数据来实现的。

生成式人工智能通常采用机器学习模型，特别是那些在大型数据集上训练的模型，以识别数据中的模式、结构和关系。通过从这些数据学习，AI 可以产生与其训练内容相似但不完全相同的新实例。

一些最常见的生成式 AI 模型包括：

1、生成对抗网络（GANs）：这涉及到两个神经网络，一个生成器用来创造类似照片的图像，一个鉴别器学会区分真实图像与伪造图像。这两个网络以竞争的方式同时训练，互相提高，直到生成器可以制作出非常逼真的图像。

2、变分自编码器（VAEs）：它们通过学习输入数据的压缩表示来生成新的数据点，然后使用这个表示生成与输入数据相似的新实例。

3、变换器模型：当应用于文本时，诸如 OpenAI 的 GPT（生成式预训练变换器）这样的变换器模型可以基于一个初始提示生成连贯且与上下文相关的文本。

4、自回归模型：这些模型通过学习序列的概率分布来预测序列中的下一个项目，例如音乐中的下一个音符或句子中的下一个单词。

生成式人工智能有广泛的应用范围，包括但不限于：

- 内容创造：生成逼真的图像、视频、艺术作品、音乐和书面内容。
- 数据增强：为机器学习模型生成额外的训练数据。
- 药物发现：创造可能导致新药物的分子结构。
- 个性化内容：为游戏、网站和其他互动平台中的用户生成定制体验。

随着生成式人工智能的不断进步，它既带来了创新和创造性的激动人心的可能性，也引发了关于真实性、版权以及在创造深度伪造或传播虚假信息方面潜在滥用的伦理关切。

### 60

方军 2024/01/17

说个特别尴尬的事，今天智谱不是发布 GLM-4 吗。

晚上我说要不跑 langchain 试试。

结果是，GLM-4 的时候，智谱改了一些接口参数，导致原来 Langchain 对 GLM 的支持失效了。

幸亏很多人都不是用 langchain 来集成智谱，如果是，多尴尬。

我刚刚给他们的人提建议，但也不是技术部，我只能说：

估计具体代码你估计暂时不明白的，我的意思就是，想办法找个巧妙的方式推动内部对 langchain 的支持，这会对你们吸引开发者大有帮助的。

不要 break 接口啊，你至少让原来能用。

具体情况是不是 break 接口，我不是很了解，仅从这个代码本身做的判断。

尴尬。

### 61

方军 2024/01/17

有个感慨，不知道发在哪儿好，就发这儿吧：如果水平不够超高，人千万别有「独特观点」。

啥意思呢，如果水平超高，那么没问题，你的独特观点肯定特别有价值。

但是，我看到一大堆有段觉得很惊艳，但后来越看越烦的东西。

是某些水平不够高的，偶尔发现一个「独特观点」，尤其是发现这个独特观点还蛮有流量（或蛮能装的），然后，就天天说啊、天天说啊。

为什么这个事让人讨厌呢，有些可能：

1、这个观点已经不独特了。

2、这个观点已经需要调整了 —— 我认为这个最重要！

3、这个观点过于为了赚流量或装逼，在说的过程中意思已经极度变了。

4、这个观点的深度实在有限，多说无益，对说的人、对听的人都无益。

所以，如果水平不够高，不要太把自己的看法凝聚成一个小小的观点。

人的知识就像金字塔型结构，最上面有个明珠当然好，但是如果水平不够特别高的时候，别以为自己的那个「明珠」是真明珠，它可能只是半途的观点而已。

而最让人烦的，是三。有这个感慨，就是刚刚中午连续看到几个赚流量的观点/名词。烦不烦你们，老师您难道都不曾自我反思下？

就这水平，也就是年纪大了、水平还在程前的状态的那种。别笑程前，他年轻，他还有机会改。

### 62

方军 2024/01/18

027 标准操作流程 SOP 与 AI 的应用

SOP 在工作人群中近乎玄学，其实对于工程师来说，SOP 特别简单：

每个应用程序（或脚本）都是处理一些复杂的逻辑流程，这些被代码固化下来的就是 SOP。

同时，SOP 并不只是程序单线处理，另外也包括了用户的交互。

目前的 AI 发展的一个阶段性的转折点是，单点的技术突破（模型，多模态，RAG 等），目前看起来是有用，但真正有用的是流程化的 SOP。

比方说：

你原来的 SOP 是什么，其中哪些环节可以用 AI 去改变，以及能否用 AI 去重构整个的 SOP。

之前看人吐槽 reenginneering（流程再造），认为当年汉默提这个词纯属造词造概念，以及为企业裁员、折腾提供借口。这个批评是轻佻的，它其实是将工程中的流程及流程再造引入企业管理。

最近看了很多 GPTs 的提示语，更加感慨，光光靠这个是不行的，真正有用的知识都是在流程。

但是，这个就是「不传之密」了，倒不是不能告诉别人，而是我们个人或企业拼凑出来的 SOP，别人拿去也没法用。（今天就给人讲一个 SOP，但我直觉他用不起来，除非我愿意把我的流程变成一个小小的 WEBAPP，让他可以直接用。）

之前看《东京大饭店》，竞争对手买通一个年轻小伙每天密报菜谱。但其实两边的法餐大厨都晓得，菜谱没什么用，否则你也太小瞧做菜这件事了。

接下来的竞争，会是 SOP 的竞争。

模型的能力就那样，所有的聪明人都已经知道了，用最好的模型，别担心费用的事。

应用的技术实现的细节，也都不是什么秘密，差别是你的速度是多少，我的速度是多少。这倒是跟钱紧密相关。

但真正的竞争力，在 SOP，以及 SOP 背后的含义，即，你能不能满足什么人的真需要？

（不成体系，先留个意识流笔记，稍后细想怎么分享。这个话题没想好有什么可以举例的，早期写过一个旅游业的设想性案例，但实用中的案例，由于各种因素，不太好讲。其实讲出来也没什么秘密，比方说，都是搜索引擎，你愿意翻到每页 50 翻到第 10 页，你的搜索效果就自然地好很多。）

\#AI 使用感悟#

### 63

方军 2024/01/18

摘一些信息，相当精彩，越细节的越精彩：我们邀请了四位信息流广告领域的专业人士聊了聊，其中两位来自品牌方、两位来自信息流广告服务商。

鉴锋：零一数科 CEO。零一数科是品牌微信生态全链路服务商

崔世杰：某广告服务商 AIGC 商业化负责人

韩文静：资深信息流优化师，擅长小说、短剧、旅游行业信息流广告投放

王飞宇：蔚车用户运营总监。

---

鉴锋：最先受益的是设计师团队，因为在进行营销活动时，需要大量图片制作。我们原计划今年再招聘 15 名设计师，但引入 AIGC 后，我们调整了招聘计划。原本需要 5 名设计师一周完成的基础工作量，如今两三天时间就可以完成。这样，设计师也有更多时间，去思考打磨创意。

王飞宇：目前，我们用 AIGC，并不是为了生成品牌宣传创意脚本，更多是对营销内容铺量提效。我们自去年 7 月开始通过用 AIGC 辅助生成内容。具体方式是，当内容策略同学在平台上试验成功一种内容形式，就会通过 ChatGPT、Midjourney 等工具生成相似内容，进行铺量。

韩文静：我目前是在漫画公司甲方，专注于信息流投放，以效果广告为主。…… 去年 11 月，因为被邀请参与腾讯广告妙思内测，而且免费，我们才又开始使用 AIGC。我们感觉这个产品对文字的理解相对更准确，因为它有自己的大模型，有广告主和行业数据，产出图片点击率更优。

---

韩文静：以小说投放为例。过去广告形式主要是呈现精彩章节的文字滚屏或者混剪素材，但这种形式可能已经接近疲软，点击率低，只有 1% 到 3%。

而且还需要设计师在电商 APP、短视频平台、电影、电视剧中找图、抠图。但问题是图片不够清晰，给用户一种粗制滥造的感觉，另外也不够有场景。

小说行业也曾经尝试使用真人实拍，希望通过视频呈现，但一方面租场地、请演员等成本高，另一方面由于不是专业演员，废片率高、修改成本大。

但是大家可能忽略了一件事，图文在腾讯广告投放大盘上占比一直不低，是小说行业不能忽略的素材形式，而且生成成本低，速度快，周期短，能快速验证书单和投放策略。

所以，现在只需要梳理小说故事情节，然后将关键词输入给腾讯广告妙思，让它生成相应场景图。比如，我输入关键词「穿盔甲将军吐血，身材魁梧，战斗背景，高清图」，图立即就能生产出来。

合适的场景化、具象化的图片，能够更强有力直接地吸引用户的注意力，提高用户沉浸感，因此推广效果也更好 —— 采用这种形式的广告点击率达到 5% 以上。

---

崔世杰：一是解决广告素材版权难题。

在传统工作流程中，素材收集占据很大一部分工作量，而且这个素材必须没有版权问题、可以商用。AIGC 的接入解决了广告素材的版权问题。

二是丰富广告素材资源库。

广告行业创意审核要求非常严格，比如，电商品类广告中，人物姿势不能有诱导性等。这种严格的审核要求使得素材资源的收集变得更为复杂和受限。

同时，由于广告创意需要不断创新，给用户带来新鲜感，所以素材成为一种消耗品，符合要求的素材越来越少。

AIGC 通过使用 prompt 和扩散模型参数，可以生成符合业务需求和风控要求的资源，丰富资源库。

三是更加自动化。

一旦数据链路打通，形成闭环，后链路数据将能指导前端素材生成，实现自动化流程。这种自动化流程意味着人的干预更少了，他们需要过渡到另一种工作模式，将更多任务委托给自动化流程。

---

崔世杰：举例来说，传统投放流程需要一个优化师和两个剪辑师合作，我接触的比较优秀的剪辑师日产量约为 150 个素材，包含文案配图和视频。考虑到团队规模扩大，如果有 10 个优化师，就需要 20 个剪辑师跟上素材生成需求。

但 AIGC 的接入使得剪辑师的需求大幅减少，人力成本降低，同时为优化师提供更多素材选择，辅助他们在广告创意方向上做出更好的决策。

韩文静：我们之前制作广告素材时，流程相对繁琐。

首先需要给设计师下需求，并详细说明所需素材要求和元素，设计师得到需求后还会进行内部排期。

在制作过程中，可能会反复修改，要么因为不满意，要么平台审核未通过。出图周期最快是两天，慢可能需要 3-4 天，但我们每天需要保证制作 50-100 套图。

但自从使用腾讯广告妙思，图的生成速度明显提升，生成 6 张图只需要 10 秒，一上午就能生成所有我想要的图。

---

韩文静：现在大家都在卷素材，然而在追求数量的同时，不可避免地牺牲了质量。

有些团队会敷衍出图，对图片小改动就直接提交。这种做法可能导致点击率不高，并且平台拥有识图能力，重复度较高的素材会降低账户权重。

AIGC 优势在于能够高效生图，并且保证每个图都不重复。即使关键词一样，每次生成的图都独一无二。

包括对爆款的「复制」也一样，现在腾讯广告妙思有一个功能，可以在爆款素材基础上去换人脸、换造型等，让好的创意经验得到复制和推广。

---

王飞宇：一个素材最终能不能爆，与内容质量关联非常大，但也会有其他因素影响。我们之所以建立营销账号矩阵和内容矩阵，实际上就是通过数量来对抗平台算法的不确定性。

当然，内容也很重要。未来平台投放趋势，也许会把算法的不确定性进一步降低，希望大家更重视创意，以创意撬动增长。

而 AIGC 让内容数量和创意质量都提了上来，因此能提高爆款率。比如使用 AIGC 前，每天只能产出 6-8 个内容，而且会占用大量时间和精力，但现在一个人一天就能产出十几篇内容，这其中就会产生一个「爆款」。

但需要明确的是，我们对于「爆款」的定义与品牌逻辑不同。我们不追求曝光、点赞或收藏等表面数据，更关注评论和私信量等。如果一篇内容能够吸引 50 个以上潜在客户，这就是一篇「爆款」。

---

崔世杰：目前 AIGC 短板在于生产素材过于像 AI，用户看得多了，就能一眼识别出素材是否由 AI 生成，就可能对此「无感」。

在广告创意领域，受众对素材的直观感觉非常重要。如果一个广告过于像广告，用户就越不会去点击，数据表现就会越差。相反，越不像广告，数据表现可能越好。

未来，我期待的 AIGC 创意平台，需要满足以下三点需求：

首先，能激发使用者的创意灵感，比如我们现在每天会整理热点新闻，通过 LLM 整理、筛选后，从中寻找广告素材的灵感。

其次，能提供广告方案。特别是在数据链路打通的情况下，通过后端数据指导，系统可以生成最近效果良好的素材方向，为使用者提供更个性化的推荐方案。

最后，要给人留一定的创造空间。虽然 AIGC 能提供灵感和方案，但它并不能完全替代人的决策性作用。

AIGC 有创意，它确实每次能生成不同的内容，但它并没有真正的创新。因为 AIGC 受限于过去训练数据的范围，只能在已知数据范围内运作，对于训练数据之外的内容毫无了解。

因此，最终的创造力仍然来自人。人需要能够驾驭系统，做出决策，这才是一个真正优秀的创意软件。

---

王飞宇：AIGC 能够替代许多重复性内容，但肯定不会完全取代创作者。

首先，任何一个平台都希望拥有更多具有独特创造力、更符合用户需求的创作者。

其次，从我们的角度来看，目前 AIGC 更多是对已经验证内容模式的批量复制，但在创新方面并没有取得很好的效果。

目前我们的内容创作中，仅有 30% 由 AIGC 辅助生成。虽然可以进一步增加 AIGC 的使用，但我们特意控制了这个比例。

原因在于，AI 还不能生成完全符合平台规则或者平台需求的内容。同时，从用户角度来看，这些内容往往被认为是质量较低且重复的。

[过去一年，他们如何靠 AIGC 搞爆款广告？｜深度对话](https://mp.weixin.qq.com/s/RoJoCF_wpnaKsbbSLwieag)

### 64

方军 2024/01/18

喜欢这张图，MORE DO, MORE CREATING

source: PJ twitter.com/milanicreative/status/1747619968168960493

### 65

方军 2024/01/18

[微软发布 Prompt 压缩技术 LLMLingua，另一种方式突破上下文长度限制，提升推理性能](https://mp.weixin.qq.com/s/o5KhdcZ9F3SPlUnq1G7eYg)

### 66

方军 2024/01/18

11-LangChain 101: 快速启动教程

快速编写完了，讲实话这个教程的质量还是很高的。当然，其中的文字尽量简略了，不想多写了，担心会继续变化很大。

目录

1 大语言模型、LangChain 简介

1.1 AI 大语言模型与应用简介：为何要用 LangChain

1.2 你安装的是什么：如何安装 LangChain？

1.3 注册 OpenAI 开发平台账户

2 实例：使用 LangChain 调用大模型

2.1 安装 LangChain

2.2 设置 OpenAI API KEY

2.3 创建与调用聊天模型

2.4 使用提示语模板

2.5 解析输出结果

2.6 多次调用模型

匹配的 Notebook：

[langchain-quickstart.ipynb - Colaboratory](https://colab.research.google.com/drive/1PUiPg0t8sdqZJomNOXs7a9CRLU2KmnkH)

放在星球专栏里，当然就是我编写的了。

快速启动：用 LangChain 调用 OpenAI _ Alang with LangChain.pdf

April：谢谢方老师，这样私人数据是不是就可以保密了。

2024-01-18 16:21

方军回复 April：并没有，你不是还在调用 openai 嘛。

当然，本地跑个开源模型就可以了，现在本地电脑能跑的模型很多了。langchain 都有很好的支持。

我觉得需要 langchain 的原因，就是因为我们作为应用开发者，必然需要多种模型。

2024-01-18 16:25

2『原文档「20240118快速启动：用 LangChain 调用 OpenAI _ Alang with LangChain」已存入「2024011大语言模型专题资料」。（2024-01-19）』

### 67

方军 2024/01/18

腾讯研究院教育科技报告。

2『原文档「20240118腾讯研究院教育科技报告」已存入「2024011大语言模型专题资料」。（2024-01-19）』

### 68

方军 2024/01/18

LangChain 推的 LangGraph，我还才开始学习。

视频课可以快速看：

[LangGraph (Python) - YouTube](https://www.youtube.com/playlist?list=PLfaIDFEXuae16n2TWUkKq5PgJ0w6Pkwtg)

blog:

[LangGraph](https://blog.langchain.dev/langgraph/)

### 69

方军 2024/01/19

我觉得啊，技术这个事最怕想要在不必要的地方创新，看看 deepseek 这个，多简单直接：

DeepSeek API 使用与 OpenAI 兼容的 API 格式，通过修改配置，您可以使用 OpenAI SDK 来访问 DeepSeek API，或使用与 OpenAI API 兼容的软件。

参数值

base_url  api.deepseek.com/v1

api_key 申请 api_key

大厂不好意思这么搞，但实际上，你并不是真正的「大厂」啊。你专门搞个 SDK，还得至少一个程序员去维护那个 SDK 吧，然后当然还要确保一致，很烦啊。

直接这样多好！

现在在 API/SDK 这个部分，真是绝对跟随 OpenAI 就好了。

举例说，现在有哪家自认为大厂的好意思不支持 function call?

不赶紧支持 assitant api？

以及，赶紧支持结果复现。

这都是过去一年中 OpenAI 确立的标准。接纳标准，采用通用工具。

这个事情不丢人啊，OpenAI 不是也用 pytorch 吗，可以说毫无心思说要自己搞个什么。

---

来自活水智能的信息：

「DeepSeek 开放平台」上线内测，注册即获 1 千万 tokens。

即刻点击，注册 API 专属账：platform.deepseek.com

兼容 OpenAI API 接口 / 支持 16K 上下文长度 / 双模型待命。

还可以使用他们家的网页版对话界面：

chat.deepseek.com

[DeepSeek 开放平台](https://platform.deepseek.com/usage)

[DeepSeek](https://chat.deepseek.com/)

方军：在 blockchain 技术领域也是相似的。

ethereum 实际上是个协议标准，它的 node 有实力都可以来写。

现在占主导的是 geth（go 写的）。

有些直接是运行 geth 代码，但有些在必须要改一点的情况下，直接给出一个代码对比级的清单，告诉所有人我改了什么。

当然还会有个改进，比如又有人写了 reth，用 rust 重写。

同时，在本地开发时，所有人用的其实都是 etheruemjs 这个库。

没人觉得要在这种方面创新。没必要。

2024-01-19 13:51

### 70

方军 2024/01/19

lepton 真心有意思啊

之前看 01 当时争议时它创始人说了几句，看起来它是一个技术服务公司，但真心 Geek。很赞。

[Lepton Search](https://search.lepton.run/)

### 71

方军 2024/01/19

昨天朋友圈半开玩笑半当真：

只有我这么无聊的人才会把这个记下来变成文字。不过真心整个互联网包括英文都没有这样基础性的资料。

反正本来就有，版本又更新，就同步更新记录下吧，也不费事。

langchain 很多资料是不足的，也有问题的，比如刚刚发现它 langsmith 一个文档里面，上面写 question，下面写 input，实际的效果就是，这个示例代码是跑不通的。

现在人们对 AI 有无数的期望，其实就这样的事也是搞不定的。

我愿意编写一些文档，反正也是学习和顺手记录，不过这样的内容如何推广和发挥价值，一直没好的思路。

### 72

方军 2024/01/20

Facebook 居然有 60 万 H100 的算力。

### 73

方军 2024/01/20

又有新的提示语图书，越来越多，就是不知道大众对这个的感受如何。

这篇营销文章开头给了一个对比示例，讲实话第二个很差啊。

[【图书】ChatGPT 高效提问：prompt 技巧大揭秘](https://mp.weixin.qq.com/s/cg5zkYp8UQze8yrL2pVfBw)

### 74

方军 2024/01/20

一个思考，这样符合传统新闻习惯但啰里八嗦的文章，如何用 AI 速读？

（当然，中文互联网的这种资料质量是极差的，标题是误导性的，机器翻译有大量错误，但不妨碍思考这个问题）

[OpenAI CEO 奥特曼和比尔·阿克曼正利用 AI 来「推翻」拜登](https://mp.weixin.qq.com/s/E8MoQgn13ee_MdYsGVDQ7w)

Dean.Bot 的工程师希望这个机器人可以帮助让更多选民能够与他互动。用户可以在桌面或移动设备上访问网站，接受免责声明，点击「开始通话」，然后通过麦克风提问。当 AI「思考」时，菲利普斯的头像周围会有一个加载的圆圈旋转，然后像菲利普斯一样的机器人会回答问题。

其他政治家也发布了假扮候选人的聊天机器人，包括前阿肯色州州长阿萨·哈钦森（共和党）和支持迈阿密市长弗朗西斯·苏亚雷斯（共和党）的政治行动委员会，他们都曾是总统竞选的有望人选。帮助建造 Dean.Bot 的初创公司 Delphi 在去年秋季还开发了一种模仿多个总统候选人的人工智能工具。然而，这些机器人背后的技术似乎使用了预先编写的回答。而 Dean.Bot 则是实时生成答案的。

一份免责声明要求用户同意使用人工智能，其中写道：「这是一个旨在提供娱乐和教育的工具，但不是完美的，欢迎随时提问，但请对答案持谨慎态度！」

为了创建 Dean.Bot，Somers 和 Krisiloff 的团队使用了来自播客、采访和演讲的菲利普斯声音样本，向技术工具提供了 236,000 个词的数据。然后这些工具处理了这些数据，生成了一个能够进行音频对话的机器人，就像通过网站进行的有点生硬的电话聊天。

### 75

方军 2024/01/20

在 AI 这儿想想区块链技术以及技术的意义。

- 区块链技术本身有着极强的技术与经济的精巧性，智能合约技术也很巧妙。

- 从理念上讲，在超长期它有降低交易成本的可能。

- 但是，它 15 年都没找到应用场景，即，它能为最终用户「生产」什么？（信任和价值存储显然都不能作为可接受的答案，去中心化则仅仅是过程）

- 对比而言，生成式 AI 的这个回答对所有人尤其是大众是直接的。之前判别式 AI 的回答对实际用的企业也是直接的。

- 这个缺陷带来的结果是，围绕区块链技术的创业与产品陷入了金融炒作（不客气点是庞氏骗局）

- 如果仅有科研人员、技术人员和 VC 参与，这个还可以是探索。

- 但是，大众的参与导致它的泡沫化严重。

- 克里斯-迪克森的 web3 新书怕是不能给出什么合理的解读。（非技术书都有这个困境，搞技术的可以不想意义，比如普林斯顿教材、AA 的两本都是技术经典）

- 我个人暂时也不能理解传统金融搞的 bitcoin etf 究竟（在终极意义上）创造何种价值？（传统金融市场里面有相当大比例是不知为何搞出来的）

- 暂时的结论是，评价一个技术，关键还是看它能生产什么，即为这个世界创造何种新价值？

- AI 虽然暂时还有这样不能用、那样效果不佳、或仅能用于广告营销等场景，但它的短中期能「生产」什么是清晰的。

### 76

方军 2024/01/20

宝玉这给了我一些启示：

1、不必寄希望于将复杂的任务在一个 Prompt 中完成，拆分成若干子任务成功概率会高一些。

2、AI 可以借鉴人类的优秀实践，例如高手是如何解决编程难题的，让 AI 按照高手的步骤去一步步做。

3、AI 的潜力还有很大挖掘空间。

---

这两天看到的收获很大的一篇论文《AlphaCodium：引领代码生成新境界，从提示工程到流程工程》，它提出了一种新的生成代码的方法，比传统的直接基于 Prompt 生成代码的方式准确率更高。

它用的测试集是 CodeContests ，这是由 Deepmind 推出的一项挑战性编程数据集。相对来说还是很权威的。以 GPT-4 为例的话，准确率从 19% 提升到了 44%。

它的原理有些复杂，但是如果你有过 LeetCode 刷题经验，相对比较好理解一些。

普通人刷 LeetCode，上来就做，这样有可能得到答案，也有可能做不出来，这就类似于你把题目直接丢给 GPT-4，让它直接给出答案，准确率相对要低一些。

高手刷 LeetCode，会有个做题的流程，同样的水平，做出来的概率会大一些。

高手做题时会大概分成几个步骤：

1、先把题目中的要点一条条列出来，确保不会遗漏任何重要信息。

2、通常 LeetCode 会提供 1 个或多个测试用例，仔细看测试用例，分析为什么给定的输入能得到给定的输出。

3、在写代码前，列出几种可能的解决方案，例如暴力算法、递归、动态规划，每一种方案写下思路和伪代码。

4、对于列出来的几种方案进行评估，选出最佳方案。

5、可能还会补充一些测试用例帮助事后验证。

---

以下部分是迭代过程：

6、根据选中的解决方案写代码，如果代码不能运行则修改代码直至能运行。

7、将代码提交到 LeetCode 的测试集去验证，如果无法通过所有测试，则修改错误，如果通过到第 8 步。

8、用第 5 步生成的测试用例验证代码，如果运行不通过则继续优化代码。

这里留个思考题：如果第 8 步出错，怎么判断是代码有问题还是自己生成的测试用例有问题？

而 AlphaCodium 就是完美遵循了以上的步骤来解题（参考图），只不过每一步都是由大语言模型帮助完成！

这给了我一些启示：

1、不必寄希望于将复杂的任务在一个 Prompt 中完成，拆分成若干子任务成功概率会高一些。

2、AI 可以借鉴人类的优秀实践，例如高手是如何解决编程难题的，让 AI 按照高手的步骤去一步步做。

3、AI 的潜力还有很大挖掘空间。

完整的文章参考：

[State-of-the-art Code Generation with AlphaCodium - From Prompt Engineering to Flow Engineering | CodiumAI](https://www.codium.ai/blog/alphacodium-state-of-the-art-code-generation-for-code-contests/)

中文译文：

[AlphaCodium：引领代码生成新境界，从提示工程到流程工程 [译] | 宝玉的分享](https://baoyu.io/translations/prompt-engineering/alphacodium-state-of-the-art-code-generation-for-code-contests)

项目源码：

[Codium-ai/AlphaCodium](https://github.com/Codium-ai/AlphaCodium/)

Prompt 和运行结果参考：

[AlphaCodium/alpha\_codium/gen/example.log at main · Codium-ai/AlphaCodium](https://github.com/Codium-ai/AlphaCodium/blob/main/alpha_codium/gen/example.log)

### 77

方军 2024/01/21

以腾讯广告妙思为例，在写实人物上，沉淀和覆盖 20 种以上的人物类型，涵盖不同的性别、年龄、装扮和时代。如果是用真人模特进行实拍，加上后期制作，生产一组可用素材大概要两三天，通过腾讯广告妙思只用 10 分钟，效率提升数百倍。

[2024 年，腾讯字节们「卷」起 AI 营销的三大趋势](https://mp.weixin.qq.com/s/Hpv-_pAeQQgTi8v0Sc22AA)

### 78

方军 2024/01/21

这个开头那段对 01 的讨论是恰当的，当时喧嚣的声音有点过了。

造成此种问题的原因之一，是大模型技术本身的特殊性。有专家与虎嗅聊到，大模型有三大件：算法、数据和权重。

其中，算法以模型架构为载体呈现，也是零一万物饱受非议的焦点；数据则是大家讨论 AIGC 通常会聊到的数据集，相当于给 AI 提供的学习教材；权重是神经网络的基本概念，代表了两个处理单元之间的连接强度。

这与过往的软件产品截然不同。曾几何时，代码等于一切，对应着大模型概念里的「模型架构」。对于大模型来说，架构只是「三大件」的其中之一。

在 Transformer 架构一统江湖的当下，甚至架构的重要性还不如数据和权重。而数据和权重属于工程性问题，对应着模型的训练。

后面的部分不值得看。标题忽略吧，标题党。

[中国开源，又一次让人失望了](https://mp.weixin.qq.com/s/4wnATYFbld_-9SH4UOdIig)

### 79

方军 2024/01/21

无论你是否同意你看到的信息，你的信息源在决定你的优先级进而左右你的人生，某种程度上来说，这些信息源就是「你」的上游。

—— Balaji Srinvasan

### 80

方军 2024/01/22

给小朋友的 AI 编程第二课

考虑到小朋友的电脑很难有方便的上网环境，搞了本地 Jupyter 笔记本。第一课还是 Google Colab。

第二课就已经不再是看看交互结果了，先知道有几种模型再说。

这里提供了两种模型：

- Zhipuai

- Deepseek

可以说相当贴心。

另外，很贴心的一点是，为了不增加不必要的分叉，直接让把 API 写代码里面了，没辙。

其他链接：

[知识星球 | 深度连接铁杆粉丝，运营高品质社群，知识变现的工具](https://wx.zsxq.com/dweb2/index/topic_detail/411222414118288)

### 81

方军 2024/01/22

傅盛 AI 产品发布会的 PPT，其中有几页蛮有意思的。

第 90 页。

其实 RAG 和 Agent 两个目前都有点误解。

RAG 是一种技术路线。从技术路线，到可用产品，其实差别很大很大。

Agent 是没有明确定义的。大众往往把所有 AI 应用都看成 Agent, AI 专业人士谈到 Agent 时，又是那种 AI 本来要智能体的大一统逻辑。

目前，我比较接受 Langchain 的 agent 定义：

chain，就是一个固定的流程。

agent，就是其中有些流程的走向（包括重复运行，graph），是由 llm 来决定的。

傅盛这儿 PPT 好含糊，我猜他应该是含糊其词的。

我觉得面向公众讲 RAG，很没意思，哪个普通人会关心这些东西，普通人只关心效果，他们这个态度是对的。

面向普通人讲 agent 也不对，因为容易激发大众以为 AI 怎么样的幻想，但实际做不到的。（Agent 方向目前几乎都是未来畅想）。

### 82

方军 2024/01/22

近日会把之前在开智 / 活水 AI 生产力计划分享的个人如何用好 AI 再讲一次，变化不大，但要缩减不少，群体也略不同，其实这个群体里面关心个体的人少到可怜。

面对的是不一样的大众群体，所以名字也搞成了通俗（庸俗）的名字，哈哈，没辙，我倒是觉得，超级个体是蛮好的词。

两点感想：

一是，最近的确进步慢啊，好像没啥新想法，进一步强化了必须要有「流程思维」

二是，看起来想法是比较到位的，方法论层次的改变不多了，但是，「工程细节」有很多的新变化。实际上，最近的实际操作比这里面提到的例子都要进步很多。

---

用好 AI 工具，成为超级个体

1） 成为 AI 超级个体的四步框架

2）用好 AI 的五个启示

3）向 AI 提问的 8 大原则

1) 用好 AI 成为超级个体的四步框架

- 了解
- 评估
- 单点
- 规模化

2）用好 AI 的五个启示

启示 01：将 AI 融入工作流，不追求端到端

启示 02：人机共舞中，人的角色与机器的角色

启示 03： 不追求精确性，而与随机性共舞

启示 04: 自带知识框架，将 AI 投入实用

启示 05：AI 时代需要人的品味与风险共担

3）向 AI 提问的 8 个原则驾驶

原则之一：理解「生成的本质」是预测

原则之二：警惕「幻觉」，始终做事实核查

原则之三：提问采用结构化提示语（ICDO）

原则之四：模型能从提示语中直接学习

原则之五：让模型进行「链式思考」，采用慢思考模式

原则之六：将复杂的任务分解成更简单的子任务

原则之七：用模型能够理解的格式输入信息

原则之八：坐稳主位，与机器共舞

方军：之前在网上看到的一条社交媒体帖子和后面的评论（略作整理）：

不出错的流程思维与小技巧

A:

以前我总是埋怨自己做文件不够仔细，明明自己检查好多遍了，出手还是有错误。

这次我算是宽慰自己了，== 原来真正有效率的团队是自查、第一轮互查、自查、第二轮互查、最后团队主管整体过一遍。==

真是每一个环节都能发现大量错误，当事人都摸脑袋愣半天。看到顶级人才都如此，我也跟着原谅我好多。大家一起交流得出：人就是很容易犯错的动物，工作线程多，头晕眼花，啥低级错误能出。所以只能让团队里每一个人都是认真负责的，通过自查、互查、自查、互查、总查，才能避免大部分的错误。

B:

我们每次出文件的时候会专门配一个人检查，

同时会提前出一个控制表，把关键点和得分项全部以表格的方式列出来，然后一项一项对着看，先自查再互查最后整体过一遍，到最后一遍的时候基本上就不会有很大的问题了

C:

拟稿人、校对、部门负责人、办公室、会签部门、分管领导、主要领导，最后交外包文印公司，层层把关，OA 流程走完后，基本不会有问题

D: 没错，三级审核，编写 / 复核 / 签发，都会仔细审一遍

工作环节中一环扣一环的查核衔接很重要，如果能尽可能避免错误，对工作成效也是及大的提升。

E: 考试成绩核对，简单的加减乘除。三个人，两次互换角色重复检验，然后一定要 == 过一夜 ==，再换人重来一遍。

想起《山茶文具店》的话，文字里有魔鬼，写完的信要供奉一晚上，早上起来再读一遍，看是否有疏漏之处。（大意）

F: 我们一个翻译稿平时是十几个工序，偶尔二十几个工序，还是做不到完全不出错。

24-1-17 18:15 来自北京

G: 我算很细致（强迫症，会反复确认）的人了，一到年底，文字材料、报表、会务、归档…… 事情一多，我就容易出错，而且自己就是检查不出来。只能给关系好的同事看看，对方一眼就能看出来，这样避免了递交给上去的时候被纠错，做事被动

H: 我感觉最有效的方式就是一个人读出声来，同时另外一个或者两个人看着

I：可以让 ChatGPT 查一遍。

2024-01-22 17:02

2『已下载附件「20240122ask-ai-tool-30-export」。（2024-01-22）』

### 83

方军 2024/01/22

都四个了。

[现有四个开源 MOE 大模型进展：从 Mixtral-8x7B 到 LLaMA MOE 再到 DeepSeek-MoE](https://mp.weixin.qq.com/s/-UF-zxUqEsuNhJyPkSpMgA?v_p=90&WBAPIAnalysisOriUICodes=10000001_10000002&launchid=default&wm=3333_2001&aid=01A0VjFEC-8TX6msntzx_IZJsVSdIBL5NqzASu9SjrmTcS5LA.&from=10DC293010)

### 84

方军 2024/01/22

很有意思的应用啊。

[哄哄模拟器的完整复盘，火了，但一度让我很发愁](https://mp.weixin.qq.com/s/DQDQX9Bomnx6ScS6dlGdVQ)

### 85

方军 2024/01/22

给小朋友的 AI 编程课第三课

第二课自然演变成了第三课，但不是 LangChain，而是英语课。

的确生词太多了，并且孩子们对这些词掌握得很不好：

ai / aritificial intelligence

api / application program interface，api key

sdk / software development kit

model

base

url

http

response / respond

message

completion / complete

create / creation

deep / shallow

seek / search

system / iOS operating system

content

assistant / assist

user / use

output

choice / choose

display

markdown / txt, docs(word), html, pdf

app / application

program / programmer / coder

visual

studio

microsoft / software

website

chrome / google / search engine

find / finder

fine-tune

keyboard / shortcut

screenshot

language

llm

langchain / chain

gpt generative pre-trained Transformer

glm general language model

\#给小朋友的 AI 编程课#

### 86

方军 2024/01/22

OS AI 生态系统：

AI 项目和贡献者大幅增长对于生成式 AI 模型而言，「开源」意味着模型的源代码、所有用于训练模型权重和参数都是可公开访问、可用、可修改的，并且允许转载。

基于这个定义，开源人工智能栈包括构建生成式 AI 应用程序的一套综合工具，其中包含基础模型（如 Llama、Mistral）、开发工具和框架（如 Langchain、Fixie、llamaindex）、模型训练平台（如 Weights & Biases、Anyscale）和监控工具（Datadog、Seldon）。

### 87

方军 2024/01/22

《用最简单方法提升模型能力》

这是一个朴素的方法。

简单但是行之有效，是经过理论和实践的双重检验。

不管是产品、运营还是大学生实习，都一学就会，用过之后甚至会觉得比预期的还要简单。

九原客：评估（eval）先行，先把评估方法、数据集、打分标准以及目标定好。再去做各种优化，就不存在什么不确定上了 xxx 效果会不好这种问题。拿数据说话。

这个特别靠谱：

https://blog.orangesai.com/p/a-simple-way-to-impro...

题外话，这是我为什么不肯舍弃 langchain 的原因。别的都可以自己搞啊，调用有什么难的，难的是评测，尤其现在它自带了 langsmith。

### 88

方军 2024/01/22

Three findings from a trial use of a GPT-4 tutor for Harvard's intro CS course:

1) Students found it useful (88% found it helpful) & used it a lot

2) The AI made mistakes, even with RAG (81% accurate)

3) It was pretty cheap

Lots of potential but R&D needed (by ethan mollick)

哈佛大学介绍计算机科学课程对 GPT-4 导师试用的三个发现：

1、学生们发现它很有用（88% 发现它有帮助）并且经常使用它

2、AI 即使使用 RAG（81% 准确）也会犯错

3、它相当便宜

很多潜力，但需要研发。

[Teaching CS50 with AI](https://cs.harvard.edu/malan/publications/V1fp0567-liu.pdf)

### 89

方军 2024/01/22

有意思的类比：

@jxnlco

Scrum is just like long ass prompt engineering session to get midwit engineers to complete a task Successfully.

Scrum 就像是一个漫长的提示工程会话，旨在让中等工程师成功完成任务。

### 90

方军 2024/01/23

联合国教科文组织：2024 人工智能时代的高等教育白皮书

由联合国教科文组织高等教育创新中心和外部专家共同撰写，探讨了目前高等教育教学和管理中有效使用 AI 技术的可能性，具体呈现了可能的解决方案和行动路径，并倡议高等教育各利益相关方共同合作推进技术的善用和相关政策的制定，以支持可持续发展目标的达成 —— 确保包容和公平的优质教育，让全民终身享有学习机会。

2『已下载原文件「20240123联合国教科文组织：2024人工智能时代的高等教育白皮书」。（2024-01-23）』

### 91

方军 2024/01/23

发现现在的孩子真不一样，我基本上不会用 latex，最基本的公式而已。

而现在的孩子论文都是 latex 格式写的，都很熟练。

latex+gpt 颇有些有意思的用法，当然我仅指公式。排版不知道，不懂。

### 92

方军 2024/01/23

这样的学习资料，AI 能辅助做什么？

[监管点名的「雪球产品」竟然和一只企鹅有关？](https://mp.weixin.qq.com/s/ARsoZWs-qKzpRHRewTEhDA)

当然，我觉得这样的雪球产品，金融界不知道创造出来干什么。

### 93

方军 2024/01/23

倪考梦：

[GenAI/AIGC：从好玩、好看到好用](https://mp.weixin.qq.com/s/hF747cIdJLpkZLeB7jIdQA)

其中的火花公开课（原火花私享课）我在最初贡献了一点点推力。

### 94

方军 2024/01/23

《我每天是如何使用 ChatGPT 的（从科学家和开发者的视角）》

推荐阅读 (来自宝玉）

作者列举了他日常使用 ChatGPT 的用法。

1、应用案例 —— 编程和控制台工具。

1) 编写 ffmpeg/ImageMagick 命令行

2) 写小段脚本（Python、Javascript）

3) 编写正则表达式

4) 用不同的语言/框架重写代码片段

5) 制作 LaTeX 图表与表格

6) 数据转换与可视化呈现

7) 从图像和图表中提取数据

2、应用案例 —— 语言、图像和知识。

1) 英语语法纠错

2) 精简和重塑段落

3) 将想法转化为文字

4) 总结文章

5) 总结 YouTube 视频

6) 解释学习过程中遇到的错误

7) 翻译

8) 私人导师

9) 生成图像 - 音乐封面

10) 生成图像 - 灵感集和参考资料

11) 创意头脑风暴 - 挑选标题和主题

12) 知识库

原文：bartwronski.com/2024/01/22/how-i-use-chatgpt-daily-scientist-coder-perspective/

翻译：baoyu.io/translations/ai/how-i-use-chatgpt-daily-scientist-coder-perspecti

作者的结论：

从我之前的描述中，你可能已经明白，我并不经常把大语言模型 (LLM) 当作搜索工具或知识库来使用。

我不会用它们来完整地自动处理一个任务，它们也不是我生活中的自动化工具。

我不依赖生成式 AI 来取代我的创造力。

我更喜欢与它们进行互动，我的决策和专注始终贯穿于这个过程。

大语言模型并没有让我一夜之间成为超级程序员。

那些认为大语言模型和自动化可以替代员工的 CEO 和 AI 界的意见领袖，我认为他们的想法很短视。

但是。

大语言模型给了我极大的快乐，我非常享受与它们的互动。

它们激发了我对所参与的每件事情的兴趣和热情 —— 对我来说，它们不仅仅是一个工具或自动化的替代品，而是一个充满乐趣的助手，帮助我学习和进步。

至少在过去十年中，没有任何技术能像现在这样让我感到这么多快乐和敬畏。

虚拟现实？让人不适和恶心。增强现实？让你时刻被工作、通知和广告所困扰。加密货币？无用，滋生犯罪，充斥着欺诈。Web3？只不过是资本家的小把戏，试图将我们的生活完全商品化。过去的十年，我们见证了太多被过分吹噜的平庸技术。

但是，在我看来，AI 才是真正的下一个（或者说已经是当前的）重大飞跃。我现在所讲的只是大语言模型，还没提到机器学习已在计算机图形和视觉等领域带来的革命性变化。对我而言，大语言模型和生成式 AI 的魅力不在于商业或生产力，而在于它们的趣味性和愉悦感 - 是的，技术应该是有趣的，令人享受的。我想重温我七岁时的那种兴奋，当时我正在探索 DOS、Windows 3.11，学习 Turbo Pascal 编程，并且开始接触 Web 1.0，制作我的第一个「无用」HTML 主页。我们的价值不应该只是在于提高生产力和为资本增值。这也是为什么我坚信，应该发展和推广开源大语言模型，让全球每个人都能平等地接触这些技术（最好是在他们自己的本地设备上，不受任何公司的控制）。

尽管对大语言模型存在一些技术上和社会上的担忧和批评，我仍然保持乐观态度。这些问题看起来是可以解决的，而且这样做是值得的。大语言模型会继续进步，但即便它们不再有太大的变化，我也会满足于现有的模型，因为它们已经在很大程度上丰富了我的生活。我希望这篇文章能展示给你大语言模型的这些乐趣，并鼓励你以新的方式去体验和享受它们。

### 95

方军 2024/01/24

蛮不错的资料。

[做大模型 AI 应用一定要了解的成本计算公式](https://mp.weixin.qq.com/s/IyudyZ0YVFtT2nwSxoH8BA)

### 96

方军 2024/01/24

[微信 AI，和你想的不一样](https://mp.weixin.qq.com/s/r7iMeloRXzHveklP_SGzkQ)

### 97

方军 2024/01/24

现在模型的结果真是很不让人满意啊。

中文错别字校对的效果似乎在下降。

我看这个运行结果完全没感觉。这四个建议都可以说错。

第二的建议和第一组的是相似。

方军：当然，我们这些人又不敢说AI不好，比如，你看这个评估结果，很有条理啊：

{
  "results": {
    "reasoning": "The criterion for this task is \"helpfulness\". The submission suggests a minor modification to the original text, adding \"的话\" at the end of the sentence. This change does not significantly alter the meaning or clarity of the sentence, but it does make the sentence sound more natural in Chinese. Therefore, the submission can be considered helpful as it improves the fluency of the sentence.\n\nY",
    "value": "Y",
    "score": 1
  }
}

### 98

方军 2024/01/25

AI 功能被融进业务流程了。

[剪映上线5秒“AI克隆音色”，一堆AI公司又要进入慢性死亡了...](https://mp.weixin.qq.com/s/nHIPaq4evPbvSQS1ctYZrA)

### 99

方军 2024/01/25

胡泳的介绍文章。

[胡泳丨《纽约时报》诉OpenAI和微软：人工智能与版权的分水岭](https://mp.weixin.qq.com/s/RuAGssbDRmWEQvKsHWX30g)

### 100

方军 2024/01/25

看人如下讨论 AI 的用途，我知道大众会这么用，但怎么就信了呢？当然，社交媒体上胡说八道，人们也信，没辙啊。

---

摘：让 maimo.ai 和 claude.ai 通读 TSLA Q4 财报电话会议记录后给乐观情绪打分，问了两次，都给了 8 分！这是被 Elon 的分析给带跑了么？这是不是明天再跌跌，就可以大量买入股票了？大家可以看看 LLM 的总结，确实乐观。

Elon Musk 和 Tesla 管理层分享了以下几个关键信息：

1. 2023 年实现了创纪录的汽车产量和交付量，达到 180 多万辆，符合官方指引。

2. Model Y 在 2023 年成为全球最畅销的汽车，交付量超过 120 万辆。

3. 能源存储业务在 2023 年实现两位数的增长，交付电池容量达到 15 吉瓦时。

4. 尽管在未来项目上的投入创纪录，2023 年的自由现金流仍保持强劲，达到 44 亿美元。

5. 2024 年，Tesla 正处在两波重大增长浪潮之间，将专注于开发下一代汽车、能源存储、全自动驾驶等项目。

6. 全自动驾驶技术完成了从视觉感知到端到端神经网络的架构重写，将在未来几周内向更多客户开放。

7. 新款 Model 3 已经在全球范围内上市，进行了多方面的改进。

8. 下一代汽车平台有望在 2025 年下半年开始量产，其制造系统将会领先世界其他车企很大程度。

9. 如果执行得当，Tesla 有机会成为全球最有价值的公司之一。但过程将非常艰难。

总的来说，这次电话会议传达了 Tesla 保持增长势头和重点投资未来发展的信息！补充一点：Musk 认为中国汽车公司是世界上最有竞争力的汽车公司，并预计它们将在中国以外的市场取得显著成功 [并不简单]

### 101

方军 2024/01/25

给小朋友的 AI 编程课第四课

这里先介绍迄今为止的整体思路，再具体介绍第四课的内容。

由于这个课程并没有预先的大纲，有什么学什么，到目前为止的大概流程是：

第一课：AI 模型原理、AI 编程 API 调用简介

实践：在 Colab 调用 OPENAI 模型（ChatGPT 等聊天窗口不需要教）

第二课：建立 Jupyter 笔记本，调用智谱、Deepseek 模型

实践：拷贝、理解和运行笔记本

在理解代码的过程中，发现有相当多的非常用单词，因而第三课从原本的 LangChain 调整为：

第三课：AI 模型与 AI 编程相关的单词课

实践：单词背诵

第四课：AI 模型的复杂交互及系统提示语

实践：和 AI 模型进行复杂的问答交互

🔺 第四课的内容：

1）学生问老师「问题」

老师回答：你别问我啊，你问 AI。你现在在笔记本里可以问 AI。

除了简单地问，你还可以这么问：

- 简单地提问。

- 设定角色，进行提问。

- 更精确地描述问题和要求，进行提问。

- 跟进问更多问题，往下追问。

- 换一种方式提问：比如，先问了有什么编程语言的问题，然后，替换为「列出 10 种常用编程语言」，「原神的编程语言是什么」等。

（暂时还没讲提示语原理，先场景为主进行讨论）。

2）介绍 Chat Model 的 System Message 概念。

在 System 角色中加入「系统提示语」，从而让每次回答都调用这个系统提示语。

最初的模型调用就是有 System Message ，但之前没有详细介绍，现在学生进去修改这个模板，并多次运行查看结果了。

说明：

为了简化编程，这里还没有引入多轮对话概念。实际上仍是一轮对话。在稍后，应该可以很容易地用 LangChain 来引入有记忆的多轮对话。（用 LangChain 实现要比自己实现更简单一些，它做了些封装。）

\# 给小朋友的 AI 编程课 #

### 102

方军 2024/01/25

《那么，我是如何使用 ChatGPT 的？》 by 阿禅

1 ChatGPT 是一个实习生

2 首先，我们自己得会

3 接着，缜密的表达能力

4 然后，解构问题的能力

5 最后，持续的学习能力

6 大模型之于个人与企业

挣不到自己认知以外的钱；用 GPT 也做不了自己能力以外的事。

ChatGPT 是一个实习生

毫无疑问，ChatGPT 是目前全球最好的大模型。然而，它并不是万能的。

它的数学很差。

它有时候会胡扯。

它大多数时候不和你聊黄段子。

在和许多朋友分享 ChatGPT 使用经验的时候，我会打这样一个比喻：

ChatGPT 就像一个非常正经的、学习能力很强的、刚刚 985 大学毕业的实习生。

一方面，作为实习生，它的可塑性很强，只要你愿意花时间引导它，它能学会你希望它学会的东西，从而帮你完成你指定的工作。另一方面，你不能对一个实习生期望过高，因为对某件你需要做的事，最熟悉的人是你，而不是它。

在当前的语境下，容易高估它的能力，但低估它的未来潜力。它从推出市场到现在，仅仅才 1 年的时间，它还不是一个让所有人都能轻易上手的产品，因此，把它看作是一个还未成熟的实习生，可能是当下合适的做法。

「

作为 Leader，你让手下做的事，你得自己会做。

这句话的潜台词是：只有你会做你手下做的事，你才不会被懵；只有你会做，你才能合理地发号施令。

把这句话放在 ChatGPT 上是非常合适的。

」

[那么，我是如何使用 ChatGPT 的？](https://mp.weixin.qq.com/s/K3mjmkLye79Khem18QHORw)

### 103

方军 2024/01/25

Meta 推出了Llama2 提示工程指南，主要面向对象是 LLM 的开发人员。

github.com/facebookresearch/llama-recipes/blob/main/examples/Prompt_Engineering_with_Llama_2.ipynb

不长，一个notebook.

\#提示语模版#

### 104

方军 2024/01/26

1 月 26 日凌晨，OpenAI 在官网对 ChatGPT Turbo 模型（修复懒惰行为），免费的审核模型，并对新的 GPT-3.5 Turbo 模型 API 进行了大幅度降价。

模型进行了大更新，发布了两款全新大、小文本嵌入模型，全新的 GPT-4OpenAI 还将推出全新的 API 秘钥和可视化管理方法，帮助开发人员更简单、直观地观察 API 使用情况，并对 API 密钥设置更详细的使用权限。

值得一提的是，全新的嵌入模型可以为 ChatGPT 、Assistants API 中的知识检索以及很多检索增强生成式开发工具提供技术支持。

openai.com/blog/new-embedding-models-and-api-updates

[ChatGPT 模型大更新！全新大、小文本嵌入模型，API 价格大降价！](https://mp.weixin.qq.com/s/7AUnXfJR5WOLnjHtyVYpGw)

[OpenAI 发布新模型！ChatGPT 性能重磅提升，API 大幅降价，GPT-4 「变懒」被修复](https://mp.weixin.qq.com/s/CdQf6nvtzSSyhu-9rOeJTA)

[GPT-4「变懒」bug 被修复，价格暴降 80%！OpenAI 连更 5 款新模型，性能狂飙](https://mp.weixin.qq.com/s/6deJkhCniZPCMdZdy1T2Yg)

### 105

方军 2024/01/26

有时候发现，一切都是反向筛选。

AI 领域也挺相似的，我看到很多反向筛选。

『

鼎益丰要开发的客户很精准：通过中医、玄学、国学、道德经，层层筛选，过滤留下来的客户都是有钱人。

40、50 岁以上，吃到改开的红利，在鹏城或者周边的鹅城、莞城、羊城、渔城有几套房，有几栋楼收租，站在时代风口糊里糊涂发大财，不懂金融、经济、互联网和基本科学素养的这批人，也就是拆迁土豪圈、做小生意买卖发家的这批人。

确实，如果没有金融、经济的基础知识，也不了解互联网商业模式，更没有基本科学素养的话，那相信鼎益丰几乎是板上钉钉。

』

### 106

方军 2024/01/26

不用「搞钱」这个词，不过的确发现我的「搞钱」思维还是太差。

我们还在很缓慢地开发一些有效果没效果的测试

而别人已经用 dify 加上提示语开发一些应用

人家的思路也很简单，啥也不做，直接拿 dify 搞钱

的确厉害啊。

暂时模仿不来，不过要尊重这种简单粗暴满足客户需求的做法。

我理解他这样做法的优势是：

1）直接获得流量

2）直接做销售

3）直接验证产品思路

从而把循环快速地转起来。

简而言之，以搞钱为名的做法，从根本思路上讲，反而是对的。而我们及周围不少朋友，还是用过去的思路，实际上不太对。

### 107

方军 2024/01/26

给小朋友的 AI 编程课第五课

第五课还是按照实际需求产生：

1）交互界面

在第四课中，学生要反复运行提问。

之前的笔记本中采用的方式是：运用 input ()，那么每次都要去重新运行代码。

我们讨论发现，既然如此，那就在笔记本中编写简单的界面，让学生可以方便地运行。

代码还是要老师来写，但把工作原理讲给学生听，并要求绘制流程图。不要求学生编程是因为，这里涉及到 ipywidgets 的使用，如果讲它又偏离了主线。

但通过这个过程，学生掌握了界面编程的基本逻辑。

也有了一个更容易使用的界面，每次重新输入，按按钮即可。

2）历史记录

在第四课中，学生反复运行，但每次的结果没有保存。

现在，在前面加上了变量（由于 python 培训并未先行，实际上并不了解数据变量），最后展示多次对话结果。

以这个为基础，就把数组变量的基本逻辑讲了一下。

\# 给小朋友的 AI 编程课#

### 108

方军 2024/01/27

A16z 最新文章：《产消者的未来：AI Native 工作流的崛起》，总结了当下 AIGC 工具的特性，并展望下一代 AI 生产力工具的重塑。

名词解释：产消者（Prosumer），是 Producer 和 Consumer 的合成词，形容既是生产者又是消费者的个体。国内可能叫个人开发者、独立设计师、个体生产者 ？

整理者：i 陆三金

a16z.com/the-future-of-prosumer-the-rise-of-ai-native-workflows

要点：

- 通过 AI 工具的运用，现在每个人都可以成为程序员、制作人、设计师或音乐家，缩小了创造力和技艺之间的差距。通过使用 AI 驱动的专业级但易于使用的产品，每个人都可以成为新一代的「prosumers」。

- 所有具有生成式 AI-native 工作流的产品都有一个关键特点：将最先进的模型转化为易于使用、高效的用户界面。

- 这类工具的特点：

1、可以帮助将真正的「空白页面」（例如文本提示词转化为幻灯片）进行转换，或者将增量资产（例如草图或大纲）转化为更完整的产品；

2、多模态（和多媒体）组合，例如将图片与文字、音乐与视频或动画与配音结合起来。不过到目前为止，目前还没有一个模型可以生成所有这些资源类型；

3、几乎没有工作成果是「一次到位」的，尤其是在人工智能领域，每一次生成都存在随机性。很少能在第一次生成就得到完全符合要求的结果，需要经常重新生成和 / 或修改提示词；

4、最后 10% 的润色工作通常是创造出好作品和伟大作品之间的区别。但是，要解决以下问题可能会有一些挑战：（1）弄清楚哪些地方需要改进；（2）在不需要转向其他产品的情况下进行这些改进；

5、可重复、可转换的输出。人工智能使内容具有独特的灵活性 -- 每一段内容都是另一次迭代的潜在 "跳板"。如果你曾在 Midjourney 或 ChatGPT 中复制和修改过别人的提示词，那么你就参与了这一过程。

- A16z 判断在未来几个月内有希望看到的几种产品：

1、与内容模式结合的编辑工具，例如一个新的独立的、AI-Native 的编辑器，使用户能够「插入」不同的模型。（编注：个人感觉，有点像 Quora 做的 Poe，「一站式」的模型分发平台，不过这个要求要更高一点，要能帮助用户一站式在各种工具中组合上下游工作流）

2、采用不同互动模式的产品，文字提示词并不总是最好的方式，还可以有语音、草图、分享灵感照片等，A16z 非常看好语音。

3、同时兼顾人类内容制作和 AI 生成的产品。A16z 预计大多数专业内容制作者将混合使用人工智能和人工制作的内容，这个工具应该兼容这两种类型的内容，甚至能让它们更容易地结合在一起。

### 109

方军 2024/01/27

[清华团队新研究：让GPT-3.5比肩GPT-4；SUPIR：智能、逼真图像修复技术｜大模型周报](https://mp.weixin.qq.com/s/dtCWnq7mW8XcPKMJptfsXQ)

### 110

方军 2024/01/27

我觉得，寒假期间，各位家里有小朋友的

真心可以学学AI

学习问答

学习绘画

学习编程

学习原理

各种角度找个小朋友适合的，同时你自己又能教的

### 111

方军 2024/01/27

部分 (灰度) 用户已经收到这样的提示：

现在可以在对话中 @任意 GPT 商店里的 GPTs，就像在群聊中 @一个人。

[ChatGPT 惊艳更新！一个 @让三百万 GPTs 为你打工](https://mp.weixin.qq.com/s/mnvuteSe8cC41lAqU4lVzA?v_p=90&WBAPIAnalysisOriUICodes=10000001&launchid=default&wm=3333_2001&aid=01A0VjFEC-8TX6msntzx_IZJsVSdIBL5NqzASu9SjrmTcS5LA.&from=10DC293010)

### 112

方军 2024/01/27

我还是决定动手写一个非技术版的 langchain 介绍文，我发现如果只有使用介绍、技术详解，没有非技术介绍文，我自己理解得也模模糊糊。那就写一个，写笔记，顺便分享出去，是我的学习方法：

动手，各位请等着。

给小朋友的 AI 编程课第六课

### 113

方军 2024/01/27


由于小朋友基本上相当于没有 Python 基础，给小朋友 AI 编程课不得不临时变成 Python 快速课及 ChatGPT 编程课

🔺Python 快速课

补充和复习几个最简单的概念。

1）变量命名规范：用英文名字，用 input_string 这样的格式（驼峰式稍后再教，Python 里面这种能接受）。

2）数组和字典

索引

key

value

(并不是这么生硬地讲，实际上是拿班级的学号、名字来实际举例。)

3）判断与循环

if, for, while, break

其实基础不错，有 Scratch 基础，流程图画起来很溜，理解无障碍。

4）其他 Python 细节

字符串 replace

isdigit, isnumeric

🔺ChatGPT 编程课

当然，既然是 AI 编程课，那可以去让 ChatGPT（对话界面）编程：

- 有问题疑问，问 ChatGPT

- 要写代码，让 ChatGPT 写

- 要改代码，让 ChatGPT 改

Python 编程课的实践最后变成了 ChatGPT 辅助编程实践。

\# 给小朋友的 AI 编程课 #

### 114

方军 2024/01/27

摘：所有告诉你 AI 可以替代创造型工作的人都是在骗你的，包括那些卖你 AI 课，跟你说 AI 可以替代设计师的人。设计师这个创造力非常强的工作，不是你随便设计一个东西你就可以用的。

有人说 AI 会取代律师和会计师。

我告诉大家，这是绝对不可能的事情。

为什么律师和会计师在很多人看来他是一个非常流程化的工作，因为律师就按照法律打官司，会计师就按照会计规则去审计。

而我告诉你，事实并非如此。其实这两个行业都是创造力非常强的行业。

我给大家举个最简单的例子 —— 律师是要搜集证据的，是要去现场的。AI 怎么去现场？律师很多时候会故意隐藏证据，然后会去推翻对方的逻辑链条，甚至有可能会行贿受贿。

AI 怎么去现场？如何刑事辩护？怎么搜集证据呢？再比如说会计师，很多人以为会计师就是个工具人，是一个非常客观的按照会计师准则去行事的人。

而事实也并非如此。

高级的会计不是记账，而是有很多创造性的工作。比如说把去年的利润移到今年来，把今年的债务移到明年去。会计是有很多项目的，这个钱花出去了到底放在哪个项目上？然后这个项目怎么处理？包括关联交易怎么处理，这是非常有创造性的工作，老板花了钱是一定要见到效果的。他不会请一个 AI 去帮他工作的，知道吗？

再举一个最简单的例子，你如果让 AI 来代替会计师。那么上市公司是要审计的，审计师是要签字的，AI 能负责签字吗？出了问题它能负责吗？AI 有主体责任吗？有法律责任吗？对不对？会计师事务所会计师审计师签了字，如果出现了假账，他是要他这辈他可能要进监狱的，他可能这辈子都干不了审计了，知道吗？那如果 AI 做假账呢？谁来负责？ AI 本质上它不是人，他没有办法负主体责任，他没有办法负法律责任。

所以，AI 不可能替代这种需要负法律责任的岗位，它不可能去当警察，也不可能去当律师，也不可能去当会计师，因为 AI 没有办法负责。

所有告诉你 AI 可以替代创造型工作的人都是在骗你的，包括那些卖你 AI 课，跟你说 AI 可以替代设计师的人。设计师这个创造力非常强的工作，不是你随便设计一个东西你就可以用的。

你做一个动漫，做一个动画，做一个游戏，是要达到客户的要求的，AI 做不出来，AI 只能按照自己的理解去做，再智能都做不出来的，因为它没有办法完全按照你的主观意识去改。

—— 村西边老王

### 115

方军 2024/01/27

LangChain 非技术性介绍写了一半了，这一半草稿分享在这里。

这样的基础资料虽然没啥高科技，但自我觉得还是不错的。

这个部分主要是从五个方面介绍 AI 大语言模型和 AI 应用。

AI 大语言模型与 AI 应用简介

1. AI 大语言模型的训练与推理

2. AI 大语言模型的使用原理

3. AI 应用：ChatGPT 对话机器人

4. AI 应用框架：如 LangChain

5. RAG，Chain 与 Agent

### 116

方军 2024/01/28

zed 还很简陋，但我觉得比 vs code 好

[比 VS Code 快得多！用 Rust 重写，支持 OpenAI、Copilot 的 Zed 编辑器开源了](https://mp.weixin.qq.com/s/hXXX97W2hy8FcBRw6FvTjA)

Zed 支持 GitHub Copilot 与 OpenAI。

作为独立功能，Zed 的 OpenAI 助手面板拥有极高的可配置空间。

开发人员可以选择模型类型并随时变更，甚至在 AI 会话期间也能灵活切换。当然，大家需要先拥有一个 OpenAI 账户，并在 Zed 中配置 API 密钥。这些密钥将按使用的 token 量计费，而 Zed 将始终显示所选模型的剩余 token 数量。

与 OpenAI 大语言模型间的交互会通过 CMD-Enter（而不止是输入）来提交，旨在让使用感受「尽可能接近传统编辑器，即按下回车键只会插入换行符」。这样就避免了意外消耗 token 的情况。对于传回的响应结果，如果开发者觉得没什么帮助，也可以用 ESC 键快速取消。

欧阳：这款编辑器我跟进很久了，很牛。未来写匠可能会在它基础上重构。开源协议较为友好。

2024-01-28 11:38

方军回复欧阳：是，这几天才试用，好赞，vscode 用得多，但实在有点不堪重负。

2024-01-28 12:29

### 117

方军 2024/01/28

LangChain blog 发表的 Sonia health 的客座 blog 有点意思：

Mental Health Therapy as an LLM State Machine

我是被状态机吸引进去的，不过这个地方的状态机似乎跟计算机理论的状态机不一样？（还不太了解。）

blog.langchain.dev/mental-health-therapy-as-an-llm-state-machine/

心理健康治疗作为一个 LLM 状态机

Editor's Note: this blog post was written by Chris from Sonia Health. We're particularly excited to highlight this for a few reasons. First, this is a use case with a really positive societal benefit. Second, the implementation mirrors how we are thinking about more complex workflows internally - as state machines! Check out LangGraph (which we just released) as an easy way to build these types of applications.

编辑说明：这篇博客文章是由 Sonia Health 的 Chris 撰写的。我们特别激动的原因有几点。首先，这是一个具有非常积极社会效益的用例。其次，实施方式与我们内部思考更复杂工作流程的方式相似 —— 作为状态机！查看我们刚发布的 LangGraph，这是构建这类应用程序的简单方法。

Sonia is an AI cognitive therapist that is available anytime, anywhere and for anyone. Think of a standard conversational therapy session, but talking to an empathic voice on your phone instead of to a human in their clinic.

---

AI Therapy AI 疗法

ChatGPT represents a promising step towards making mental health care more accessible through the use of AI. However, the problem with a vanilla model like ChatGPT is the lack of domain-specific conversation structure. A single system prompt isn't able to guide through an entire 30-60 minute conversation where the client and therapist need to continuously dig deeper to get to the core of a problem. While these models were pre-trained on countless psychology textbooks (leading to therapeutical knowledge), transcripts of therapy sessions are barely available publicly (leading to a lack of therapeutical behavior). ChatGPT is an RLHF fine-tuned model that receives instructions and provides solutions, which is very different from how a therapist should engage in a therapy session.

ChatGPT 代表了通过使用 AI 使心理健康护更易获得的一个有希望的步骤。然而，像 ChatGPT 这样的基本模型的问题在于缺乏特定领域的对话结构。一个单一的系统提示无法引导整个 30-60 分钟的对话，其中客户和治疗师需要不断深入挖掘问题的核心。虽然这些模型是在无数心理学教科书上进行了预训练（导致了治疗知识），但治疗会话的转录几乎没有公开可用（导致了治疗行为的缺乏）。ChatGPT 是一个 RLHF 微调模型，它接收指令并提供解决方案，这与治疗师进行治疗会话的方式非常不同。

Cognitive Behavioral Therapy

Before we get started on the technical details, we'll provide a quick introduction to cognitive behavioral therapy, Sonia's main therapeutical approach. CBT is one of the most widespread forms of psychological treatment, proven to be effective for numerous mental health problems including anxiety and depression. The approach is centered around the cognitive model of CBT, which describes the interconnectedness of situations, thoughts, behaviors, and emotions. The model states that it isn't the situation itself that impacts how we feel or react, but rather our interpretations and thoughts about the situation. CBT aims to help clients become aware of, challenge, and reframe these negative interpretations and thoughts.

认知行为疗法

在我们开始技术细节之前，我们将简要介绍认知行为疗法，索尼娅的主要治疗方法。认知行为疗法是心理治疗中最为普遍的形式之一，已被证明对包括焦虑和抑郁在内的许多心理健康问题有效。该方法围绕认知行为疗法的认知模型展开，该模型描述了情境、思维、行为和情绪之间的相互关系。该模型表明影响我们感受和反应的并非情境本身，而是我们对情境的解释和想法。认知行为疗法旨在帮助客户意识到、挑战和重构这些消极的解释和想法。

LLM State Machine 状态机

It is a widespread belief that therapy is more of an art than science. Quite the opposite, CBT is a very structured therapeutical approach. A session as described by its founding father Aaron Beck consists of 8 well-defined stages, that get traversed by the therapist. Each stage of the session, such as「mood check」,「agenda setting」, or「feedback」, has a very specific purpose and objective. Looking at it from a computer science perspective, this structure makes it perfectly suited to be modeled as a finite-state machine, which is exactly what we did.

这是一种普遍的观念，即治疗更多地是一种艺术而非科学。相反，认知行为疗法是一种非常有结构的治疗方法。正如其创始人 Aaron Beck 所描述的，一个疗程包括 8 个明确定义的阶段，由治疗师完成。会话的每个阶段，比如「情绪检查」，「议程设定」或「反馈」，都有非常具体的目的和目标。从计算机科学的角度来看，这种结构使其非常适合被建模为有限状态机，这正是我们所做的。

Architecture 架构

The main task of an AI (and human) therapist is to respond to their client. Every response requires new context and information, which is dependent on past interactions with the client, the stage of the ongoing session, the current topic that is being addressed, or the sentiment of the very last client message, just to name a few. So how can we make sure that our AI therapist has the right context at the right time?

AI（和人类）治疗师的主要任务是回应他们的客户。每个回应都需要新的上下文和信息，这取决于与客户的过去互动、正在进行的会话阶段、当前正在讨论的话题或最后一条客户消息的情绪，仅举几例。那么，我们如何确保我们的 AI 治疗师在适当的时候具有正确的上下文？

Many retrieval-augmented generation (RAG) solutions would simply embed a corpus of psychological knowledge and semantically retrieve the related data. However, fully relying on this would not sufficiently exploit the well-defined structure of CBT therapy and have a suboptimal signal-to-noise ratio.

许多检索增强生成（RAG）解决方案只是嵌入了心理知识语料库并语义检索相关数据。然而，完全依赖这一点将不能充分利用认知行为疗法的明确定义结构，并且信噪比不佳。

On the other extreme, hard-coding a single prompt for each stage does not allow enough flexibility, which is crucial for personalized and effective treatment. In CBT, each stage can be broken down into several more fine-grained substages, which of course shouldn't all be treated equally.

在另一个极端，为每个阶段硬编码一个提示并不够灵活，而这对于个性化和有效的治疗至关重要。在认知行为疗法中，每个阶段可以细分为几个更精细的子阶段，当然这些子阶段并不应该被平等对待。

Aiming to find a middle ground, we built a deep decision tree of structured retrieval and prompting for each stage using the LangChain framework. LangChain's customizable memory modules and agent constructors accelerated our development significantly. Once it was all set up, monitoring and testing on LangSmith saved us many hours while iterating on the prompts.

为了寻找一个折中点，我们利用 LangChain 框架构建了一个深度决策树，用于每个阶段的结构化检索和提示。LangChain 的可定制记忆模块和代理构造器显著加快了我们的开发速度。一旦一切就绪，通过 LangSmith 进行监控和测试为我们节省了大量时间，同时在提示上进行迭代。

Transitions 过渡

After we built the agents for each stage, we needed to think about how to transition between the 8 distinct stages of a CBT therapy session. The tricky part here is that this task is highly domain-specific to therapy. It's neither a fully syntactic, nor a fully semantic problem.

在为每个阶段构建代理之后，我们需要考虑如何在认知行为疗法（CBT）会话的 8 个明显阶段之间进行过渡。这里的棘手之处在于这项任务对治疗领域非常特定。这既不是完全句法问题，也不是完全语义问题。

On the syntactic side, rules such as「there should be exactly 8 messages in stage X」or「stage X should last at most 5 minutes」could easily be implemented. But what if the client asks a follow-up question in the 8th message or has to take a short break for a few minutes? Point being, you can't fully rely on these types of rules (but you also can't completely ignore them).

在句法方面，「阶段 X 应该有确切的 8 条消息」或「阶段 X 的持续时间最多为 5 分钟」等规则可以很容易地实现。但是，如果客户在第 8 条消息中提出了一个跟进问题，或者需要休息几分钟，该怎么办？重点是，你不能完全依赖这些类型的规则（但你也不能完全忽视它们）。

On the semantic side, one potential approach is to run repeated LLM calls to determine whether all stage objectives have been met. The output can then either be used to explicitly switch the context of the agent, or more implicitly by integrating the output into the prompt that generates the response to the client.

在语义方面，一个潜在的方法是运行重复的 LLM 调用，以确定是否已经实现了所有阶段目标。然后可以将输出明确用于切换代理的上下文，或者更隐式地将输出整合到生成对客户端响应的提示中。

No single one of these approaches is sufficient, but collectively they perform pretty well. Not surprisingly, this combination is also being implemented by a human therapist in practice. They need to stay within certain set boundaries such as session duration, but make sure to smoothly finish covering important topics.

没有一种方法是足够的，但它们集体表现得相当不错。毫不奇怪，这种组合也被人类治疗师在实践中采用。他们需要在一定的范围内保持，比如会话持续时间，但要确保顺利地涵盖重要的话题。

Asynchronous Emergency Check

异步紧急检查

As recently described by Bill Gates, an AI mental health agent can and should do much more than just generating responses. One example of such an additional task is emergency detection. If a client is in immediate danger of hurting themselves or others, they shouldn't be talking to a machine - at least not yet in early 2024. We have implemented several asynchronous checks that evaluate the risk contained in every message that the client types or speaks. Above a certain threshold, Sonia immediately redirects clients to national hotlines.

正如比尔·盖茨最近所描述的，AI 心理健康代理可以并且应该做的远不止生成回应。这种额外任务的一个例子是紧急检测。如果客户立即面临伤害自己或他人的危险，他们不应该与机器交谈 - 至少在 2024 年初还不应该。我们已经实施了几个异步检查，评估客户输入或说出的每条消息中所包含的风险。一旦超过一定的阈值，索尼娅立即将客户重定向到国家热线。

Another example are therapeutical worksheets. If a client struggles to articulate their thoughts, values or goals, a therapist has an inventory of exercises and worksheets to help. Implemented quite similar to a tool as described by LangChain, our AI therapist Sonia identifies the right time to interrupt the session and present an interactive worksheet to the client in the frontend. Those results then get analyzed and leveraged to continue the session.

另一个例子是治疗工作表。如果客户难以表达他们的想法、价值观或目标，治疗师会有一系列的练习和工作表来帮助他们。与 LangChain 描述的工具相似，我们的 AI 治疗师 Sonia 会在合适的时机中断会话，并在前端向客户呈现一个互动工作表。然后对这些结果进行分析和利用，以继续会话。

Conclusion 结论

AI has the potential to make mental health care accessible to anyone, anywhere, and anytime at 1% of today's costs. We are excited to build something that has the potential to positively impact the lives of millions around the world and are grateful for partners like LangChain that support and accelerate us in this process.

AI 有潜力以今天成本的 1% 使心理健康护理对任何人、任何地方和任何时间都可获得。我们很兴奋地构建着一些有潜力积极影响全球数百万人生活的东西，并感谢像 LangChain 这样支持并加速我们在这个过程中的合作伙伴。

[Mental Health Therapy as an LLM State Machine](https://blog.langchain.dev/mental-health-therapy-as-an-llm-state-machine/)

### 118

方军 2024/01/28

有意思：

a:

GPTs 刚出来的时候，就有人发现了上传的知识库能被下载。我后续复现，发现要选中「Code Interpreter」才会有这个问题。当时还在想这个问题几时能修复，今天仔细一看，它更新到文字描述了：

Files can be downloaded when Code Interpreter is enabled

有点像有的游戏发现了 bug，然后把文字描述改了

另外，Prompt 窃取应该也不会修复了吧，要不要也加段描述？

b:

刚开始的 Bug 更离谱，就算你不开 Code Interpreter 也能下载，因为同一个用户不同 GPT 都共用一个虚机，所有用过的 GPT 的资料都会下载在这个虚机里面，只要用过的 GPT 有一个开了 Code Interpreter，就能下载所有资料

可惜修复了！

### 119

方军 2024/01/28

我对 perplexity 这样的东西提不起兴趣

搜索能得到多好的结果

而且相对黑箱

不过，大众不在乎

做产品的人看大众喜欢，也跟着去鼓吹

我充满疑虑

我天天觉得 LLM 的结果好差，然后费劲力气去改进

给资料不给好资料，更是自己给自己制造麻烦

现在的垃圾信息太多了

绝大部分社交媒体（实际反映的是多数人）都不愿意用下脖子上方的那个东西

摘：推荐阅读：AI 时代下，用户体验面临的复杂性挑战

2023 年标志着计算技术新纪元的开始。迄今为止，生成式 AI 主要关注于技术层面的发展。同时，大多数 AI 产品仍然在使用最初模型提供商设计的聊天界面，就像早期个人电脑时代的命令行界面，这对用户提出了较高的要求。

但现在是 2024 年了。Perplexity 凭借其在 AI 驱动的用户体验领域的创新，逐渐崭露头角。他们正在改变我们使用 AI 搜索网络的方式。Twitter 上的热烈讨论和他们获得的贝索斯资助的 B 轮融资，足以证明他们正走在正确的道路上。

他们成功的关键之一在于，将目光投向过去。鉴于人类行为改变缓慢，我们可以借鉴一些基本原则。1994 年，雅各布·尼尔森（Jakob Nielson）撰写了一篇文章，题为「用户界面设计的十大可用性启发式原则」。下面是 Perplexity 如何有效运用这些原则，取得了巨大成功。

启发式原则 1：系统状态的清晰可见

设计应确保用户随时了解正在发生的事情，通过适时的反馈来实现。

在任何产品中，当用户感知到性能延迟时，向用户显示系统仍在运行是至关重要的。理想情况下，通过提升系统性能可以缩短等待时间。当这无法实现时，进度指示器成了基本需求。Perplexity 在这方面做得更出色，它能向用户明确展示模型在搜索所需信息时的具体操作。用户可以看到诸如「正在考虑 8 个来源」或「已研究并总结」的提示，这不仅让用户知道系统在运行，还让他们了解其运作方式和这项新技术的工作原理。这样做结果是增强了用户对技术的信任。用户对技术有了更深的理解，感觉更亲切，从而更愿意再次使用这项技术。

启发式 2：以用户的语言为设计语言

在设计中使用用户熟悉的词汇、短语和概念，而非内部专业术语。应遵循现实生活中的习惯，让信息展示顺序自然合理。

Perplexity 之所以容易理解，是因为它借鉴了人类日常对话的思维模式。例如，「提出后续问题……」这样的用语就非常接近日常交流的风格。这不仅是个友好的提示，更体现了 Perplexity 的优势：依据你的初次提问，快速精准地优化网络搜索结果。这种用词看起来简单，实则选择恰当的措辞并不容易。结果，产品变得更亲切、不再令人生畏，给人一种前所未有的自然感。

启发式 3：赋予用户控制权和自主性

用户常会不经意间执行错误操作。他们需要一个明显的「紧急退出」选项，以便能够在不经历复杂流程的情况下立即撤销这些操作。

AI 聊天产品一般会鼓励用户分享聊天内容，作为一种记录。尽管我作为用户对这些功能的价值感知不强，但 Perplexity 在增强用户控制权方面做得很好。用户可以重新编辑之前的指令来生成新的结果，也可以删除后续的问题和答案。这样，用户就能编辑整个对话序列，形成一个更加精炼且易于分享的内容。

启发式 4：保持一致性和遵循标准

用户不应该对不同词汇、情景或行为是否具有相同含义感到困惑。遵循行业和平台的常规惯例。

Perplexity 严格遵循互联网上普遍使用的词汇。当引入新术语或用户界面时，他们常会通过弹出的提示框解释其含义。用户可能不会立即了解所有细节，但 Perplexity 团队让学习和理解新事物变得简单易行。

启发原则 5: 错误预防

虽然清晰的错误提示很关键，但最优秀的设计应着力于从源头避免问题的发生。应当消除易出错的环境，或者在用户确认操作前，检测这些状况并提供确认选择。

这正是 Perplexity 所取得的重大创新之一。当用户的询问预期不能提供具体足够的答案时，Perplexity 会引导用户进一步明确他们的问题。我们可以理解，Perplexity 将答案过于笼统或不具体视作一种失败状态。虽然在搜索产品中这很常见，但令人惊讶的是，其他的搜索服务提供商并没有为此开发出同样精细的解决方案。

请求用户澄清问题，就像人们在日常对话中所做的那样，感觉更加自然。这也进一步增强了用户的信任感。

启发原则 6: 识别优于回忆

通过让元素、动作和选项直观可见，减轻用户的记忆负担。用户不必从界面的一个部分记住信息，然后应用到另一个部分。设计中需要使用的信息（如：字段标签或菜单项）应当在需要时直观展现或易于获取。

这也是 Perplexity 的又一关键创新。其他的生成式 AI 聊天产品往往过分依赖用户的记忆，而非直观识别，这在很大程度上限制了其吸引广泛用户群体的能力。Perplexity 明白，就像很少有人在大型演讲后提问一样，并非所有用户都善于提出后续问题。因此，它会预测用户可能提出的问题，并在每个回答的末尾展示这些问题。

除了提出后续问题外，团队还开发了一个「发现」板块，每日展示新颖而有趣的主题。这些由人工策划的提示，为用户提供了一种即使没有特定问题时也能与产品互动的简便方式。我自己在浏览这些「发现」内容时，经常会受到启发提出后续问题。这成为了一种有趣且全新的方式，让用户与资讯内容互动。

就像从命令行界面演进到图形用户界面一样，Perplexity 通过始终提供基于识别的前进路径，使这项技术更加易于被广大用户接受和使用，这是向前迈出的一大步。

启发式原则 7: 灵活性与使用效率

为初学者隐藏的快捷方式 —— 这可以让专家用户的交互更加迅速，从而使设计既适合新手又适合有经验的用户。应允许用户自定义他们经常进行的操作。

键盘快捷键在界面中随处可见。例如，对我们这些技术行业的早期采用者而言，命令 K 是一个极受欢迎的快捷键。这些细节表明，产品致力于满足用户在不同使用阶段的需求。

启发式原则 8: 美观且简约的设计

界面不应包含无关或鲜少需要的信息。界面中的每一份额外信息都会与关键信息竞争，从而降低其相对显著性。

界面简洁、友好而现代化。与其他偏重技术和工程设计的产品不同，Perplexity 维持了其亲切且先进的风格。

启发式原则 9: 帮助用户识别、诊断并从错误中恢复

错误信息应当用平实的语言（无需错误代码），准确指出问题所在，并提出建设性的解决方案。

我遇到的唯一「错误」是超出了免费计划中 Co-pilot（高级搜索功能）的使用限额。在这种情况下，系统会清楚地提示状态。一个提示工具会告诉你功能不可用的原因。它明确指出了所需的行动：进行升级。

Perplexity 通过根据需要向用户收集更多信息，有效地避免了错误的发生。最理想的错误信息，其实就是不需要出现的错误信息。

启发式原则 10: 提供帮助与文档

最理想的情况是系统无需任何额外说明。然而，有时可能需要提供文档来帮助用户理解如何完成他们的任务。

Perplexity 同样满足了这一点。正如前文所述，他们通过实际使用向用户传授这项新技术的知识。但如果你想深入了解 Perplexity，他们提供了一个简洁的帮助和常见问题解答部分。由于他们显然致力于让产品本身尽可能简单，所以这一部分也非常简单易懂。

看到 Perplexity 如何继续进化将会非常有趣。如果你在 2024 年正在开发以 AI 为核心的产品，不妨参考 Perplexity 的做法：始终记得从过去的经验中学习。

原文：Perplexity's high bar for UX in the age of AI

mttmr.com/2024/01/10/perplexitys-high-bar-for-ux-in-the-age-of-ai/

译文

baoyu.io/translations/ai/perplexitys-high-bar-for-ux-in-the-age-of-ai

### 120

方军 2024/01/28

摘：声明：本期论文解读非人类撰写，全文由赛博马良「AI 论文解读达人」 智能体自主完成，经人工审核、配图后发布。

[Meta 发布自我奖励机制，Llama 在 3 轮训练后超越 GPT-4](https://mp.weixin.qq.com/s/Uo75sGR6s2-pZ9m5GLQObg)

看到这个声明还是蛮感慨的，没觉得这个解读好，也没觉得这个解读不好。

不过，从我个人的信息获取习惯来看，其实这类通常也就是看个标题与前面扫一下，真关心得去看原文，不关心也就放过了。

这样的机构化操作的文章，不管原来是人工翻译，还是现在 AI 翻译与处理，其实我都觉得价值有限。

它与很多个人写的笔记混淆了：

个人写笔记是有意义的，实际上是个人学习的副产物。

它当成一个内容产品时，其实不好也不坏。

这是为什么我觉得爱生活爱可可老师的内容很无聊，但对他个人非常有价值。

### 121

方军 2024/01/28

举例来说，如果想通过应用元提示使 GPT-4 解决一个数学难题的话，通常可以采用三阶段的策略：

Meta Model 的输入指令：首先请教专业的「高级数学家」将难题分解为简单步骤；Meta Model 输出：

其次，将各步骤分配给专业领域的专家（比如让「程序员」来写代码）；专家输出。

最后，协调专家之间的交流并综合他们的输出。

[OpenAI、斯坦福大学提出 Meta-Prompting，有效提升语言模型的性能](https://mp.weixin.qq.com/s/ton58dImkg2VBiH57rlyUg)

### 122

方军 2024/01/28

LangChain 非技术介绍第二部分：为何用它？

我的结论是：总而言之，在 AI 应用开发领域，LangChain 既是一个高效的应用快速搭建工具，又是一个高质量的的学习资源，应用开发者持续跟踪它能够有所收获。

---

有很多 AI 应用开发者选择 LangChain，他们的理由是：

- LangChain 被证明能够快速跟进模型与 API 的变化。比如，在 2023 年，OpenAI 推出 Chat Model、Function Calling、Assistant API 等现在已经成为行业事实标准的 API 接口，而 LangChain 都快速、高质量地提供了相应的服务。

- LangChain 能够快速跟进 AI 研究领域、AI 模型领域、AI 开源领域的变化。AI 目前的发展情况是，大量的论文快速涌现，其中研究部分能够快速改进 AI 应用的效果，这些被快速地融入。新模型、开源领域的新变化也是如此。

- LangChain 在活跃的社区方面有着领先优势，身处这一社区让开发者可以借鉴与学习其他人的最佳实践。LangChain 的大而全实际上让它的社区更为活跃。实际上，要让 LangChain 的可用性更强，不是改变它的定位，而是将其中的各种模块拆分，这也是它在做的。

- LangChain 公司在提供的 LangSmith、LangServe、LangGraph 等让在 LangChain 库之外有了更多的支撑。

上半部分：

LangChain 非技术性介绍：AI 模型与应用

方军：写这个又想起关于写东西的吐槽。

我写东西经常被吐槽：

- 这东西这么简单，说明这个人水平不高啊。（喂，我把东西变简单让普通人能懂好不好，当然水平咱们不争论，没必要）。

- 这人说话看不懂啊（啊呀，我讲太多专业术语了，过于 high-context，但好像再进一步通俗化，我又没有兴趣和乐趣了）

- 怎么这么长？或者，怎么这么短？（我也不知道啊，就是很自然地好像挺长的）。

- 图片完全不需要啊，完全是文字的重复。这个出现在我认为恶意评论者在书的批评里。（也许吧，但我觉得需要啊，图多容易理解）

因为刚刚心里也吐槽某老师了，啊呀，这老师怎么写文章这么啰嗦、这么多截图。也包括看国外报告，怎么这么多的 twitter 引用。也许，文字的特点就是这样吧，很多人形成自己的习惯。

2024-01-28 20:36

2『已下载原文件「20240128LangChain 简介：为什么需要它？」。（2024-01-30）』

### 123

方军 2024/01/28

以前提过 LangChain 和 LlamaIndex 的对比

其实看 Twitter 看 LlamaIndex 蛮焦虑的，不停地有各种框图出来，看着都好炫。

同时，从技术深度上讲，我们应该更关注 index，而不是 LangChain 这样的应用框架。

刚刚看它创始人的转帖又焦虑了。

twitter.com/llama_index/status/1751291798843212111

不过，还是之前下定决心做的判断吧，这些都是屠龙术。

我们现在到不了这种程度，同时，所有的这些其实都没啥用，因为一个笨办法先解决眼前的问题：（由人工参与挑选的）高质量的资料库。

### 124

方军 2024/01/28

这个博主的感慨有意思，是啊，GPT 就是经常告诉我们一些 unknown unknown。

JimmyLv

惊叹一下 ChatGPT，太神奇了，没有它我怎么活呀

RankedRecords 这种我完全 Unknown Unknown 的东西，简直是打破次元壁！

刚刚发现数据表存在多个 Row，从而无法更新内容，需要临时迁移修复一下脏数据，SQL 全都是 ChatGPT 写的，十分钟以内搞定！

---

另外分享一下我之前在笔记软件上做的尝试：

「口述自然语言 -> AI 翻译为 SQL -> 调取 Roam Research 笔记」

Roam Research 本质上是一套 Graph DB，通过 datalog 查询

理论上，这一套完全可行，但是生成的 query 不够稳定。

但是可预见的是：GPT4 + 或者 fine-tune 之后的 AI，完全就可以随口问 note 啦

---

举个例子：

在 Roam Research 里面可以通过时间段查询出刚刚 edited 的内容，然后通过 GPT 自动总结我刚刚做了些什么。

这个 roamAlphaAPI.q() 后面的 datalog 查询语法都是 GPT 帮我生成的，直接通过自然语言 query my second brain 哈哈哈

---

如果可以的话，我真的很想直接做一个根据自然语言查询笔记 blocks 的 query 生成器，然后自动执行，就像 ChatDB 获取任意笔记软件的 ChatSQL：

比如 Roam Research 使用的就是 datalog 语句用于查询，那么是否可以借助 roam/js 实现一个根据自然语言查询 block 的 query 生成器？

---

终极情况下就是：

「Hey roam, 帮我总结过去 25 分钟编辑过的 blocks」

然后 roam/js 自动去执行 GPT 生成的 datalog 语句，然后给出答案

哈哈哈哈，现在还需要手动调试操作一下，GPT 生成的 q () 也不一定完全可用

---

自从我学会了在 Roam 里面操作 datalog，其他任何笔记软件都不香了

而且 datalog 查询语句不用自己生成，让 GPT 来帮我生成就好，Prompt 如下：

Given the natural language query"找出所有与‘机器学习'相关的笔记", translate it into a Datalog query for Roam Research. only return the datalog query

---

twitter.com/Jimmy_JingLv/status/1751225608653475885

### 125

方军 2024/01/28

猎豹能否做成另说，傅盛的选择是合理的选择。

[押注AI大模型，傅盛需要新贵人](https://mp.weixin.qq.com/s/Lu2yfUxHPzdoHgKvz0lKzA)

### 126

方军 2024/01/29

生成式 AI 为创始人提供了一个完全重塑工作流程的机会，并将催生一批新的公司，它们不仅仅是 AI 增强现有业务的公司，而且是完全 AI 原生公司。这些公司将利用我们现有的技术从零开始，围绕人工智能独有的生成、编辑和合成功能打造新产品。

[A16Z 最新观点：内容专业创作领域的未来 ——AI 原生工作流的崛起](https://mp.weixin.qq.com/s/SykFmziKu7jzY03x3JsomQ)

### 127

方军 2024/01/30

写入门教程有点像爬行，好缓慢，如果这事能交给 AI 干就好了。

可惜做不到。

没干活的人很难体会我们的痛苦，也就是当前AI能力的严重不足。

同时这种痛苦也是值得的吧，最便宜的学习路径。

### 128

方军 2024/01/30

摘：今日很多国家的应试教育模式可以追溯到 18 世纪的普鲁士，这种靠知识灌输的教育模式… 过程枯燥痛苦，损伤了青少年的自主学习热情，在 AI 踏平了自学的门槛后，是否依然怀有学习热情，将极大地拉开人和人之间的差距。

河森堡：我之前和 GPT 聊天时，有过一次难忘的经历。

我当时和它聊考古，我说殷墟的发掘让学者对商朝历史的认识变得 clear 了，GPT 纠正我，说应该是 clearer 了，是「更清楚了」，因为在殷墟发掘以前，学者对商朝历史就已经有诸多认识了，我很惊讶，GPT 似乎真的有着一个博雅的人格，对任何我抛出的话题都能侃侃而谈，甚至纠正我的错误，尽管从原理出发，这一切都是幻觉。

事实上，GPT 并不知道自己在说什么。

小破站上有一个视频，名叫《万字科普 GPT4 为何会颠覆现有工作流…》，作者是 UP 主 YJango，他从生成式 AI 的基本工作原理开始讲起，循序渐进地回顾了整个 GPT 及大语言模型的发展历程，并且从数学的角度出发，告诉观众 GPT 所拥有的对话能力，其实是一种基于海量数据的涌现，并不存在什么所谓的人格和性情，这个 50 分钟的视频看完，一个对生成式 AI 的工作原理一无所知的人就可以说是入门了。

视频：www.bilibili.com/video/BV1Kw411t7aV

然而，这个视频真正吸引我的，并不是它对于原理简单直白的解释，而是视频的后半部分，作者对 AI 影响下的未来做出了诸多预见，其中，让我印象深刻的是，随着生成式 AI 的普及，人类创造知识传授知识的方法将被彻底颠覆，而这将震荡每个人的命运。

今日很多国家的应试教育模式可以追溯到 18 世纪的普鲁士，这种靠知识灌输的教育模式足以批量产生拥有基本知识和纪律性的国民，巧合的是，其正好契合了前几次工业革命对于人才的需求，所以一直延续到了今天，但这种教育模式因为过程枯燥痛苦，损伤了青少年的自主学习热情，在 AI 踏平了自学的门槛后，是否依然怀有学习热情，将极大地拉开人和人之间的差距。

AI 带来的变革，让我不禁想起了一个有趣的历史现象，即东汉时期，中国不仅出现了学术成就高超的平民知识分子，而且还涌现出了能融通五经和诸子百家的全才，这在之前的历史中是颇为少见的，之所以如此，在于更早之前的人们在文化教育上多依赖于竹简和口述，知识记录和传播的成本高昂，文化被高度垄断，而到了东汉，纸张开始普及，学习成本骤降，于是一大批人才得以涌现。

回顾历史，每次有新技术让知识更易于传播时，都会崛起一批新的文化精英引领时代，而今日的 AI 技术，足以让一个善于使用它的人学习效率提升 10 倍以上，在未来，真的有可能出现一批在知识广度和思想深度上都前无古人的青年俊杰。

（后略）……

### 129

方军 2024/01/30

【GitHub Copilot 对代码质量的负面影响】

AI 生成的代码类似临时工，倾向于破坏代码库的 DRY (Don't Repeat Yourself) 原则。

- GitClear 的新研究发现 GitHub Copilot 对代码质量有一些负面影响。这与其他一些研究的正面结论形成对比。

- 研究发现代码重构 (代码行变更百分比) 预计在 2024 年将比 2021 年 (AI 之前) 基线翻一番，新增代码和复制粘贴代码所占比例也在增加。

- 研究总结 AI 生成的代码类似临时工，倾向于破坏代码库的 DRY (Don't Repeat Yourself) 原则。

- 研究发现三大变化趋势：代码重构增加、移动代码减少表明重构和重用降低，复制粘贴代码增加意味着未来维护困难。

- 研究认为 Copilot 正在改变开发者的意义，我们进入了代码增加速度前所未有的时代。关键是谁来清理后续的混乱。

- 其他一些研究得出 Copilot 整体正面作用的结论，但也指出需要进一步评估，AI 助手不应独自编写代码。

- 对比研究认为意见分歧较大，Copilot 是一个有前景的工具，但不应独自使用。安全问题也令人担忧。

- 综上，Copilot 是一个有前景但还需谨慎看待的代码生成助手。它对代码质量存在一定负面影响，需要开发者保持警惕，同时发挥其正面作用。还需要更多研究对其影响进行全面评估。

《New GitHub Copilot Research Finds 'Downward Pressure on Code Quality' -- Visual Studio Magazine》

visualstudiomagazine.com/articles/2024/01/25/copilot-research.aspx

方军：我个人的体会是：

1）具体代码，必须反复优化 GPT 生成的代码，它的代码能运行，但质量不高。不要接受它第一次生成的代码，要多次追问，自行修改，相当于把它当成结对编程的伙伴。

2) 整体项目，必须反复地思考整体架构，把 GPT 生成的代码优化进去，也就是，重构要比过去要层次更多、更频繁。

3）就新知识而言（其实不一定新），它对 API 文档的理解是不足的，我们要比过去花更多的时间去理解文档本身。

2024-01-30 11:18

### 130

方军 2024/01/30

每次编写教程的时候，真心觉得只有我这样的「笨人」才会这样一步一步把细节都重新做一遍，调整到位，让普通人也可以方便地掌握。

之前有一个小例子，而这个又做了小小的改进。为什么要改进其实很简单，因为前面的例子一直在想怎么搞，而这儿就自然地整理列出来。

这个过程中是可以学到很多东西的，比如，我之前真不知道可以用「+」来方便地组合形成 ChatModel 模板，现在知道了。

### 131

方军 2024/01/30

028 AI 或老师：教给我们不知道自己不知道的

很多人以为，老师的主要作用是答疑解惑。这当然是优秀老师带给我们的价值。但是，真正的好老师是帮我们打开一扇窗。

也就是，有些知识在老师提到之前，我们根本不知道还有它的存在。

打开窗之后，我们可以方便地去进一步摸索。这时，在探索过程中，我们才需要有老师来答疑解惑。

更具体来说，如果用一个 2x2 的表格来表示，横轴是我们是否知晓，纵轴是我们是否掌握。

老师打开的那扇窗是指向了，「我不知道自己不知道」。

在使用 AI 的过程中，我偶尔发现它也有这种用途。—— 昨日转发一个人的体会也是如此。

AI 的知识库非常庞大，远远超出每个个人的知识。因此，只要我们有意识的去引导，它会在我们所提问的点之外再往外延伸一些。这时经常进入到了「我不知道自己不知道的」领域。

或许，这也是应该变成日常使用 AI 的一个常备技巧，每次提问完了，再多问一句：还有呢？（这句话要根据实际情况具体问）。

目前看，日常使用对话式 AI 至少有如下常备技巧：

- 请 AI 帮你组织提示语，然后再用它改过的提示语提问。

- 在 AI 回答完之后，请它自我评价，回答得如何？

- （出于学习目的），请它就当前回答再往外延展一点知识面。

当然，还是最近的感想，不要太过依赖于 AI，用 AI 的最值得铭记的金句是：

自带高质量知识框架，才能用好 AI。

我们如果自己没有知识框架，既无从提问，也无从判断答案。

在这里 AI 帮我们拓展一点知识面，其实是激励我们进一步学习，掌握知识框架。AI 的片言只语，真心价值很小。

（我不是贬低公众，现在那些盲信 AI 的人，与许知远之前说的「庸众」没什么区别。）

### 132

方军 2024/01/31

Prompting Guide for Code Llama

elvis 又搞大作！厉害。

www.promptingguide.ai/models/code-llama

Excited to release my latest prompting guide for how to effectively prompt Code Llama 70B Instruct with plenty of examples for developers and practitioners.

Code Llama 70B Instruct is one of the most powerful open-source models for code generation. 

After it was released yesterday, I felt we needed to develop a proper guide for it to learn how it could be used for all sorts of interesting code generation tasks like debugging and Text-to-SQL generation.

The guide includes the following:

• Configure Model Access
• Basic Code Completion
• Debugging
• Unit Tests
• Text-to-SQL Generation
• Few-shot Prompting with Code Llama
• Function Calling
• Safety Guardrails
• Notebook
• References

More examples coming soon!

### 133

方军 2024/01/31

给小朋友的AI编程课第七课

给小朋友的AI编程课今天到了提示语部分。我就建议用「ICDO」这个框架。提示语是我们对AI机器人的「命令」，机器人回答说，“I See, DO!（我明白了，做吧）”

I，Instruction，指令
C, Context，上下文
D, Input Data，输入数据
O, Output Indicator，输出要求

由于之前用 Jupyter Notebook 已经搭建好了方便的提问环境，并可以记录提问历史，因此后续的作业就是两个：

- 请AI帮忙修改一个段落，给出修改结果，并列出针对性的建议。
- 请AI做一道数学应用题，调整输出要求，比如写完整答案（含答句），解释解题过程等。

在具体使用时，建议先忽略上下文部分。只考虑 「IDO」。

一个语文修改的示例：

I ，说明角色

你是一个优秀的小学语文老师。

D，准确提问

请帮我：
- 修改病句
- 把句子写得更准确
- 改修辞手法，如排比

O，输出要求

「请给出两个选项。按原话、选项一、选项二给出。」

\#给小朋友的AI编程课#

补充，数学的实测结果太糟了，于是AI编程课变成了对大模型数学能力的吐槽课。

其实不只是数学能力不行，是所有能力都不行，因为数学能力不会就不会，语文看不出来没有对与错的判断。

方军：不过，实测效果不佳，主要是这些模型的数学能力不行。
2024-01-31 15:23
方军：实测数学题都非常令人失望！
2024-01-31 15:40

### 134

方军 2024/01/31

029 AI 可怜的数学能力（或所有能力都很可怜）

我最近实在有点接受不了 AI 的实际能力。今天这种感觉尤其强烈。

就像我一直说的，它的能力是 50 分（对了，外界吹嘘的都是 150 分的感觉），然后，我们努力把它用到 70 分，最好 75 分，勉强用着。

为什么一直推荐用交互式，因为交互式可以把 70 分的功能，用到 85 分的效果。

在实际跑评测（Eval）的时候，是远远没有 75 分的。别看各种模型发布时的评测，都过度美化了。

—— 这带来的一个后果是，我真是不敢乱忽悠。昨日就说起一个话题，人说，不是有 Code Interpreter 功能 (即 Data Analysis) 吗，我的直接反应是，AI 写的代码没那么好。

今天的问题则发生在，再次发现各种大模型的数学能力极其有限，不管是实际上最好的模型，还是那些宣称对数学优化过的。

各种提示语技巧也没有办法再有多少优化。

并没有去做过数学方向上的微调，但我想也是一般的。除非将知识范围缩减到很小，并提供超高质量的数据，当然，这个在数学上是容易做的。

那么，为什么大家认为模型的能力不错呢？📍因为你们让它做的是没有标准答案的。📍

当让它做有标准答案的数学，哪怕只是小学数学时，那种虚假的感觉被刺破了。

不会就是不会。

它可以给你思路上的参考，但你得承认它的数学水平差，可以说极其差。

让我吹嘘大模型的能力，讲实话，我的确做不到。

而让我改进现在有大模型的数学能力，我也做不到。这是心情糟糕的原因。

当然，还是接着干活，目标只是接着从 70 分往 75 分、往 80 分进步。但吹嘘的人也要知道啊，80 分的数学成绩，可以说差到不行，现实世界中的数学要考 99 分才能算数学好。

---

摘网上一段话鼓励一下：

哲别：遇到问题，要遵循「先解决，再总结」的步骤。

人的注意力在哪里，情绪就在哪里。关注正面就开心，关注负面就难过，这是人性。所以，在遇到问题的时候，注意力一定不要放在问题上，因为这世上最大的就是人的想象力，自己会把自己吓死的。

一定是把注意力放在解决问题上，而不是问题本身。少说过去谁错了，这除了显得自己很能耐，树立几个对立面，为自己未来埋下祸根，没有任何价值。而是要多说未来怎么做才是对的。

这叫做永远聚焦下一步「先解决，再总结」。

人在世上，要创造价值，最关键是自己具有「解决问题的能力」。

晓霖：今天向别人介绍大模型玩法时就反复给她上保险：不要问大模型数学问题

2024-01-31 23:29

方军回复晓霖：是啊，但是其实应该问，因为这个才反应真实能力。我用编程多，其实编程的能力也是很差的，中间的严格性没有比数学差一个量级。

2024-01-31 23:31

晓霖回复方军：如果一上来问个简单的数学问题，发现连这都不会，很容易就直接放弃尝试了，反而错过它的优点。编程确实很坑，我也被绕晕好多次，实际上效率没有提高很多，不过对初学者入门编程特别友好，结果忍不住续费了 github copilot。

2024-01-31 23:43

方军回复晓霖：你这第一个观察有意思。赞，的确如此，我以后也这么建议。

2024-02-01 00:10

泽生：不能认同更多！特别是「人的注意力… 先解决，再总结。」

话说回来，AI 可以考 85 分以上的环节有哪些（有限文本的增删改查、赤脚翻译、流水账报告）？

2024-02-01 00:25

泽生回复晓霖：有没有一款产品，可以借助 AI 数据库或其他信息源，快速找到实现编程目标的最佳范例。

2024-02-01 00:30

方军回复泽生：没有，这些都做不到，翻译我都认为只有 80 分吧，然后各种 prompt 技巧 + 流程化之后可能到 85+。

2024-02-01 00:57