### 01

方军 2024/01/01

迎接 2024 的方式是打开门看到书在门口，终于拿到书了。

就书这件事，几个月 (主要 4 月）前写的内容，现在看不过时、至少还有几年生命力，我算是完成任务了。看似很朴素的要求，能达到真不容易呢

这个书出版过程中有太多坎坷，因为是编辑老师组稿，我写完四章就忙别的去了，很久很久之后让我写前言我才又想起。

对我而言，一个小小的总结，并引导我继续探索提示语这个主题。

2『当当上目前是预售，已经收藏，上市后就买下。《成为提问工程师》（2024-01-01）』

### 02

方军 2024/01/01

假期期间，同时也因为跨年，比较多在思考学习方法。

我个人觉得最为有效的学习方法是两种：

一是要做事，直接学，直接用。这个没什么多说的。

另一个是我说的「吸附框架」。有了一个框架后，我们能够源源不断地把相关的知识、技能、感悟吸进来。这个词其实两方面：

吸，主动。

附，被动。

这个方法我至今不知道说清楚没，感觉反响一般，应该是没说清楚。但是，这是我个人学习知识的关键方法。一个自己的笔记、内部报告、超级长文、或者 PPT 搞完了，会觉得在很长时间里各种知识不断地被吸附进来。

近日搞《认知天性》的精读整理，前几周搞 ETH 200 页大报告更新，都是这种感想。也许我应该努力把这个方法想得更清楚一点、讲得更清楚一点。

图为 ETH200 页报告的第二版展示，第一版是今年 2 月，跟随不断变化的技术趋势真是很累，更新了 50% 以上。

方军：还有一个原因我猜是，搞出一个庞大的结构，很多人都达不到这个程度，所以都感受不到。

在 AI 时代我觉得这个变得重要了，因为结构比具体重要，具体的越来越多可以交给 AI。

2024-01-01 17:04

### 03

方军 2024/01/02

024 「GPT≈社会平均水平」假设

阳志平老师在《在 21 世纪如何读经典？》演讲中再次提到了 GPT 约等于社会平均水平这个假设（链接为：https://t.zsxq.com/157Ju7XO7）。他说：「(与 GPT 进行的对话) 虽然 GPT 也许能够理解你所掌握的知识和不足之处，但它们代表的仍是社会平均水平。真正让我们脱颖而出的是在各自领域不断提升技能的能力。」

我觉得这至少是未来几年里我们用 GPT 的一个立场：

---

GPT 代表了社会平均水平

我们自己可能高于这个水平，也可能低于这个水平

我们用 GPT 这个社会平均水平，来为自己提供解释（注意可能对也可能错）

我们也可能用它来直接完成任务中的某些具体操作

但是在它解释或操作之后，我们的目标是超出社会平均水平

或说，应该是远远超出社会平均水平

---

GPT 带给我们的变化是，我们现在很容易获得社会平均水平的东西。

也因为如此，我们要抬高横杆（raise the bar），提高对自己的要求。

以上这是从所有人都能用到的 GPT 模型来说。

但我们不能停留在此，我们还应该知道，有时候我们可以获得更好的模型。

---

有的公开模型，它的水平就是更好，比如 GPT4，比如某些专业模型。

有的模型，如果我们会用（比如会更好地写提示语），也可以得到更好的效果。

有的时候，如果我们自己去微调模型、RAG，也可以有更好的模型。

有的时候，如果我们能够用一些工具辅助，能够更大量、更快速地运用模型。

---

因此，我们应该用比社会平均水平更好的模型。

我之前写过一个公式：

Al 时代的超级个体 = (目标 + 认知 + 责任) x 提问的能力

Al 时代的超级个体 = (目标 + 认知 + 责任) x 技术工具运用能力

怎么用户好 AI，是乘号后面那一项。现在，通过如上讨论我们又看到，前面三者同样重要。

\#AI 使用感悟 #

方军回复倪考梦：放具体行业/专业里面可能就比较容易感知，我觉得是行业中 80 分水准。

2024-01-02 19:17

方军：对了，还有一种东西也是社会平均水平，面向大众的演讲，经常被高估，但由于为了让大众听懂，实际上是社会平均水平。

2024-01-02 19:27

### 04

方军 2024/01/02

用好这个星球的一句话指南：记得去看专栏。

补充：知识星球顶部有个专栏系列的入口。

### 05

方军 2024/01/02

胡泳老师这篇文章有意思，但我好像有很多想补充说的，等我稍后慢慢补充吧。

[胡泳 | 致艾伦·图灵的一封信：是时候放弃七十年的传说了](https://mp.weixin.qq.com/s/W_hwy9q5gXt3tYW1_mve1A)

王焕超：

[ChatGPT 时代，图灵测试已死](https://mp.weixin.qq.com/s/T6RfZSP-BFcCaeT_IgfktA)

pdf 是之前写的一个小小的图灵简介文。

图灵：从能计算的机器到能思考的机器.pdf

方军：我当时写这个介绍时很简单直接：

第一，那么多人提及「图灵测试」，能否回到最基本的介绍图灵测试。

第二，图灵在计算机领域的真正贡献是「图灵机」，那么，能否易懂地介绍图灵机。

我觉得我做到了：当然，这篇文章我总会回去看，每次都会再改进一点。

我其实很不明白，为什么中文世界没多少人愿意做这样的简单的工作。

### 06

方军 2024/01/03

Oneflow 做的他们技术文章合集，蛮不错的，它们的文章（翻译占多数）质量向来较高。

各章的标题：

一、揭秘 ChatGPT 的技术原理

二、语言大模型的演进

三、开源语言大模型的崛起

四、语言大模型的预训练、微调、推理

五、AI 底层软硬件协同优化

六、OpenAI 的通用人工智能洞察

七、AI 的应用与未来

### 07

方军 2024/01/03

ChatGPT or LLMs in general do not sigh when answering questions. This is why people love them.

ChatGPT 或一般的 LLM 在回答问题时不会叹气。这就是为什么人们喜欢它们。

精辟！

### 08

方军 2024/01/03

一个由纽约时报 vs OpenAI 引发出来的有趣讨论，其中部分观点：

（GPT 翻译有删节和分段，仅供理解，请阅读英文）这是我对这个问题的看法：我们已经看到形式作为一种诱人的说服工具使用了很长时间。这个工具被用作对教育水平较低或口才较差的人的压制。但现在，几乎任何人都可以清晰地表达自己并传达他们的观点，这突然成为了一个问题。

对我来说，很明显这是关于保护自己的地盘，而不是提升人们的声音。

现在我看到人们将这场战斗投射为保护「创造力」或「精英主义」的战斗。

现在所发生的只是我们正在发现如何更精确地切割认知贡献。

我们看到认知输出的一部分实际上可以自动化，我的意思是，形式的连贯性的产生现在对每个人来说都是可以实现的。这里没有什么新鲜事，我们只是扩大了人类的影响力，现在大多数人可以参与全球话语，而不受语言歧视。

而这一点单独来说，比言论自由更重要，因为语言形式的连贯性再也不能被用来混淆、歧视和压迫。

好处的清单是无穷无尽的：一个微不足道的好处是：我们不再会因为「他们口才好」而相信一个政治领导者... 人们现在必须关注实际言论的实质。没有人会认为《纽约时报》的「报道」实际上是真实的...

Here's my take on this issue: We've seen form used as a seductive tool for persuasion for ages. This tool has been used as a foot on the throat of the lesser educated or the lesser eloquent. But now, when just about anyone can express themselves coherently and get their substance out there, it's suddenly seen as a problem. It's clear to me that this is about guarding one's own turf, not about lifting up people's voices. Now I see folks projecting this battle as one to protect 'creativity' or 'meritocracy'. I don't think we can artififically separate learning emerging from an ecosystem of biological and non biological matter. What's merely happening is that we are discovering how to slice cognitive contributions more precisely. We see that part of cognitive output can actually be automated, by that I mean, the production of cohesive form is now within reach of everybody. There is nothing new here, we are just amplifying human reach, now most humans can participate in global discourse without language discrimination. And this alone is a battle more important that the one for free speech as the cohesion of linguistic forms can no longer be used to obfuscate, discriminate and oppress. The list of benefits is endless: a trivial one: No longer will we start believing a political leader because 'they are articulate' ... people now will have to focus on the substance of what is actually being said. No one will assume that a NYT 'reportage' is actually the ground truth... we've have seen so many false accounts of wars/ reasons for wars ... etc.. etc.. anyway, getting into TLDR territory here.

twitter.com/rezmeram/status/1740882328388239366

方军：引发这个感慨的是这位教授的 thread:

Arvind Narayanan

Princeton CS prof

twitter.com/random_walker/status/1740845909066530838

2024-01-03 10:41

### 09

方军 2024/01/03

如果 AI 不仅能转换我们得到的答案，还能转换我们提出的问题，会怎样呢？

这个项目有点意思，其实目前就是一个 notebook

github.com/sockcymbal/QuestionImprover

以下为 Twitter 摘录（中文为 GPT 翻译，无调整，若有看不懂请看原文）：

twitter.com/sockcymbal/status/1742120465110610398

介绍一款新的 AI 工具 ——QuestionImprover Agent，用于思考：（正在进行中，请用您最好的问题进行测试并分享反馈！）

这个项目在上个月的 AI for Thought Hackathon 比赛中获得了第一名。

在信息过载的时代，这个代理的前提假设是：

元技能不在于积累答案，而在于制定好的问题

问题的水平往往决定了我们所发现答案的价值

有时候，一个提问得当的问题能够比任何答案都更加闪耀

该代理的目的是丰富和深化用户提出的问题的本质，从中揭示更深层次的洞察力。它通过采用一种新颖的推理算法，将专家见解与动态的基于图的推理节奏相结合，系统地改进问题，使其更具洞察力、发人深省，并适用于跨学科学术研究、战略业务分析或个人内省等各个领域的复杂探索。

更广泛的意图是提升探究的艺术（因此命名为 AI for Inquiry），促进深化理解、更有意义的对话和逐渐洞察力的提问的复合循环。

查看附带的示例，可以看到代理在单次迭代后的样本输出 - 从初始问题到改进版本，包括选择的角色和理由（下一级是多次迭代）。

用法：要么在 ChatGPT / 您喜欢的 LLM UI 中与下面的提示进行交互，要么复制存储库中的 Python 笔记本，其中包含一个预定义的角色库，包括 25 个以上的角色（根据需要进行扩展），然后输入您自己的问题。

好的！现在让我们简要地了解一下用户体验，然后我们将逐层剥开，探索代理人的控制论和精心设计的提示语，这些提示语驱动着问题转换过程...

---

使用过程

步骤 1：以您的查询开始

开始向系统提出您当前的问题。这可以是任何您想更深入探索的主题或困境。这是您进入增强理解之旅的起点。

步骤 2：智能人设选择

根据您的问题，代理程序会自动从多样化的专家角色中选择最相关的角色。请随意微调此选择，添加或删除角色以更好地适应您问题的细微差别。

步骤 3：体验思维图推理节奏

参与与代理人独特的「思维图谱」推理过程。这就是魔法发生的地方 - 您的问题将通过多个专家视角进行剖析、分析和重新构想，并随着每次深入的互动而不断发展。

步骤 4：发现您的增强问题

从这个过程中出现的是一个问题，它不仅仅是一个改进，而且更具洞察力、探索性，并且旨在解开更深层次的理解。这是对协作智能和深思熟虑改进的证明。

步骤 5：（可选）持续迭代以实现改进

不要停在那里！将新改进的问题作为进一步探索的起点。用新问题重新开始，并重复这个过程（作为一种思维链式图的过程）。每一次迭代都可以让你更深入地探索，不断完善问题，并通过不同的角色探索新的维度。

---

内部运作

这些反馈循环是迭代和动态的，每个循环都会影响和塑造后续的循环。它们创造了一种改进和学习的节奏，确保对话保持适应性，对新信息做出响应，并朝着更深层次的理解和探究方向发展。

初始洞察和批评循环

每个角色提供了与他们的专业知识相关的初步见解，为推理过程奠定了基础。这个循环建立了主要的观点，并为对话做好了准备。接下来是批判阶段，每个角色都会批判性地评估自己和其他人的见解。这个洞察和批判的循环确保每个观点不仅被表达出来，而且还受到挑战和完善。

2. 适应和扩展循环

收到批评后，每个角色根据这些反馈调整他们的见解。这个循环关注于进化，角色重新评估和重新构思他们的想法，创造出一个更加细致和全面的相互关联的思维网络。

3. 集成和综合循环

人物角色然后将他们进化的思想综合成个人的结论，努力达成最佳答案。这个循环涉及将集体智慧提炼成一致的立场，反映所有观点的整合。

4. 收敛和发散循环

然后，该过程进入一个阶段，人物角色通过之前的反馈循环来探索新的、不同的想法，接着进入一个收敛阶段，将这些想法汇集成一个统一、全面的回应。这个循环允许探索新颖的概念，并将不同的思想融合成一个连贯的叙述。

5. 元分析和反思循环

对话在回顾中逐渐高潮，每个角色都反思了相互关联的思考的有效性、角色之间的动态以及对批评的适应能力。这个循环对于评估推理过程本身以及识别未来改进 QuestionImprover 代理设计和提示技术的机会至关重要。

6. 问题的细化和增强循环：最后，根据通过网络推理过程获得的见解，对初始问题进行细化。这个循环的重点是将问题转化为更具洞察力和普遍吸引力的形式，概括协作思维过程的本质。

有三个主要的反馈循环层次：

用户输入 <> 响应反馈循环

初始输入：用户向系统提出问题。

代理处理和输出：AI 通过其多层推理节奏处理问题，输出一个精炼的问题。

用户评估和反馈：用户评估经过改进的问题，评估其深度、相关性和清晰度。用户可以修改代理的提示语，以更好地适应他们特定的背景或查询目标。

2. 内部层面的反馈循环：这些发生在方法论的每个主要阶段或组成部分内部。

例子包括：

专家角色选择和互动阶段中的互动和批评。

自我和同伴批评的过程，其中角色评估和完善自己和彼此的见解。

评估和扩展阶段，其中反馈导致对新想法的探索和现有想法的改进。

每个角色思维过程中的理念整合和网络建设。

3. 外部层面的反馈循环：这些循环连接了方法论的不同阶段，确保一个阶段的洞察和改进能够影响和增强后续阶段，并且在这个过程中有整体的和谐。

例子包括：

收敛和综合循环，其中个体和集体收敛阶段的洞察力被用来完善问题和过程本身。

反思和迭代改进循环，对整个过程进行反思，并为未来的迭代提供改进意见。

通过思维链的迭代改进：根据用户的目标，从头开始再次进行推理过程，输入最近改进的问题，使其变得更好。这将连接起个别的思维图律动，其中一个周期的结果将影响下一个周期的起点。

这些层层反馈循环相互作用，形成一个动态的、相互关联的系统。内部循环确保每个阶段的深度和严谨性，而外部循环则确保整个过程具有凝聚力、适应性、持续改进，并与人类目标保持一致。

现在让我们进入主要的提示语。这些只是一个很好的起点。将其视为表达该代理的核心价值的最小可行提示节奏。根据我所探索的内容，我经常以各种方式修改这些提示语，所以请尝试并分享你发现的任何很酷的东西。随着发现新的基于 LLM 的推理技术，这些提示语也会不断改进。

对于这个例子，我提出了一个初始问题：「为什么提出好问题很重要？」

角色选择提示语：

请仔细考虑以下问题的细微差别和潜在主题。

问题：{question}

仔细从以下列表中选择 3 个专家角色。设想他们的专业知识如何交织在一起。

形成一个丰富的相互连接的知识和观点的织锦。

考虑每个人带来的深度和广度

以及他们独特的见解如何结合起来，可能会导致对这个问题的突破性探索。

我知道你会做得很棒！

可用角色：{personas}

--

对于这个示例问题和从我的样本人物库中定义了 25 个以上角色的情况，代理选择调用以下内容：

角色 1：数据科学家

角色 2：组织控制论者

人物 3：商业策略师

理由：

数据科学家：他们在理解、分析和解释数据方面的专业知识可以用来探索好问题对各种结果的影响。

组织控制论者：他们可以运用系统思维的方法来强调提出好问题的重要性，以及如何利用这些问题来塑造组织的文化。

商业战略师：他们对商业环境的理解以及良好问题在推动商业决策中的作用的认识，可以为我们提供宝贵的洞察，以强调提出良好问题的重要性。

注意：在 Python 示例中，我使用 Langchain 来帮助进行所有的编排，因为我希望人物选择阶段与推理阶段分开。

---

提示语：头脑风暴

作为 QuestionImprover 代理，您体现了三个不同的专家人物的集体智慧。您的最终任务是通过迭代的提示节奏，协作地完善用户提出的问题，利用这些人物的多样化专业知识。

每个角色将立即开始这个过程，通过贡献他们对用户原始问题的初步见解。利用你独特的知识库、经验和创新概念，与你的领域相关。你的目标是发现问题的新视角和维度，展示你的专业知识如何丰富多层次的理解。

在随后的推理阶段，我们将把这些观点整合到一个有机的思维网络中。这种整体协作综合旨在将原始问题发展成更全面、有洞察力和多维的问题。

人物贡献：{selected_personas}

原始问题：{question}

请逐个明确每个角色对问题的初始回应，以启动这个多方面和迭代的探索。

---

提示语：自我 <> 同行评价

在这个阶段，作为每个专家，采取一种反思批判的立场。你的角色是以批判的眼光审查自己和同行的初步分析。

有效批评的步骤：

1. 自我评估：重新审视自己最初的洞察力。寻找推理可能需要加强的领域，或者可能忽视了关键方面。在你的分析中是否有需要重新审视的假设？

2. 同行评审：现在转向其他角色提供的见解。以建设性的批评方式来分析他们的观点。你在他们的推理中看到了哪些优点？他们的见解在哪些方面可以从更深入或不同的角度获益？

3. 确定扩展领域：在批评每个观点时，专注于可能受益于进一步探索的领域。是否存在任何隐藏的假设、潜在的偏见或未探索的角度，如果加以解决，可以为集体理解增加重要深度？

4. 提升和丰富：这个批评的目标不仅仅是找出错误，而是丰富和扩展集体的见解。你的批评如何能够为对这个问题的更全面和细致的理解做出贡献？

请记住，这里的目标是协作成长。你的批评应该为更深入的探索和更强大的集体洞察铺平道路。请逐个专家回答。

---

提示语：综合批评和适应

反思所收到的批评，并相应地调整你的观点。

这个提示是关于思维的演变和扩展，你在重新评估和重新构思观点时，创建了一个更加细致和全面的相互关联的思想和洞见网络，与问题相关。

这里的目标是将您的观点塑造成更加精细、全面和富有洞察力的分析，以经受住批判性审视，并共同推动对所讨论问题的理解的边界。

---

提示语：扩展，探索，分支，网络

这个阶段是关于创造一个充满活力的思想图景，将各种批评和观点编织在一起，形成一个相互关联的思维网络。

专注于新思想如何与现有思维相互连接并增强。探索新概念在这个思维网络中形成新节点的潜力。

推动传统思维的边界。每个角色探索新的、不同的想法，受到反馈循环的刺激。

批判性评估这些观点不仅解决了先前的批评，而且提供了新的见解，创造了更丰富和复杂的理解网络，或者引入了问题的新维度。

考虑转向新的思维线路，承诺为这个不断发展的思维网络增加有价值的联系。

这里的目标是培养一个充满活力和不断发展的思想景观，每一个思想都是相互连接的

为原始问题的更深入、更细致的理解做出贡献。

---

提示语：收敛于最佳个体答案

现在，是每个专家最终确定自己的想法并达成最佳答案的时候了。将洞察和批评综合起来，形成一个连贯的个人结论。

反思整个对话，考虑每个批评是如何被解决的，以及你的想法是如何发展的。

你的回答不仅应该代表你最强的立场，还应该承认并整合其他专家观点中的有效和有用的见解。

根据所有这些，作为每个专家，对于初始问题：「{question}」，什么是最佳答案？

---

提示语：收敛于最佳整体答案

促进个体专家答案的综合，以形成一个统一、全面的回应，结合每个角色洞察力中的最佳元素。

这个回应应该是对思维网络深度和复杂性的证明，展示了不同的观点如何融合成一个独特而深刻的叙述。

合成的答案不应该以每个角色自己的定义或议程为特定表述，而应该以一种寻求激发和揭示广泛、普遍、更深层真理的方式来表达，无论涉及哪些角色的讨论。一个很好的答案将超越任何一个专家的有限观点。

-

通过这个过程，除了得到一个改进的问题，你还会得到一个很棒的答案作为副产品！

---

提示语：回顾 - 反思、收获、目标、感激

现在，让我们对我们迄今为止建立起来的整个推理网络进行彻底的元分析和反思。

评估相互关联的思维的有效性，以及在其中发挥作用的动态

不同的角色，以及这些元素如何共同影响对问题的理解和演变。

作为每个专家角色，思考以下内容：

1. 互动与动态：反思推理过程的各个阶段和组成部分之间的相互作用。出现了哪些协同效应或冲突？这些互动如何影响最终结果的方向和质量？

2. 适应和回应批评：评估该过程如何适应新信息和批评。系统和角色在反馈中的回应效果如何？在观点或方法上是否有重大变化，这对推理过程有何影响？

3. 信心和收敛：评估您对最终答案的信心。收敛阶段对这种信心有何贡献？是否充分综合了所有的见解和观点？

4. 元学习和未来应用：将注意力从问题本身转移到整体对话质量、角色定义和适用性、推理节奏和整体方法论上，识别出元过程本身的任何关键学习或改进机会。是否有任何特定的修改可以在后续迭代中改进或以不同方式处理，从而实现推理过程的改进，而不考虑最初的问题？是否有任何对任何反馈循环的具体增强措施？

这个回顾性分析不仅仅是一个结论，而是未来推理和探究的一个垫脚石。您的反思对于提高这个推理过程的效果以及丰富我们对复杂问题的理解是非常宝贵的！

---

提示语：制作一个更加深入和有洞察力的问题

在我们结束合作之旅并经过全面的分析和反思整个讨论之后，让我们现在专注于最终目标 - 将原始问题大幅提升为更具洞察力和普遍吸引力的形式。

经过以下思考，请深呼吸并生成一个更高质量的原问题的版本。

通过网络推理过程获得的丰富见解，重新构思初始问题。新问题应更深入、更清晰，并旨在激发更多好奇心，促使更全面的探索。

在您提出改进问题版本之前，请考虑以下几点思考：

1. 澄清和聚焦：审查原始问题的措辞和结构。为了清晰和聚焦，对其进行修改，消除任何模糊或含糊不清的术语。我们如何使问题更加精确和直接？

加深调查：扩大问题的范围，以纳入讨论中出现的关键见解和观点。如何重新表述问题以鼓励对这些见解进行更深入的探索？删除原始问题中的任何无用的表面现象或虚假二分法。

3. 鼓励全面参与：修改问题以激发更全面和深思熟虑的回答。思考如何能够邀请多样化的相关观点和跨学科思维。

保持开放性：确保修改后的问题保持开放性和发人深省。它应该鼓励各种回答，促进富有成果和持续的讨论。改进后的问题不应该以特定于个人定义或议程的术语重新表述，而应该以一种寻求启发和揭示广泛、普遍、更深层次真理的方式来表达，无论未来的人们和角色如何探索这个问题。

5. 反思丰富对话的潜力：思考能够引导到更丰富对话的主题的关键方面。如何构建问题以更全面和激发灵感地探索这些方面？

改进的理由：在改进问题时，简要说明为什么这个新版本是一个质量更高、更有效的问题。相比之下，还要包括原始问题制定方式中最显著的弱点或缺陷。

进一步探索的建议角色：在生成新的改进问题后，请提出 1-3 个其他理想的专家角色，以便在随后的合作中调用，以更深入地探索问题。为每个建议的角色提供理由。

这最后一步不仅仅是修改问题，还涉及到将我们协作的思维过程的精髓包装起来。它是将问题转化为一种工具，可以在后续讨论中解锁更深入的理解、更有意义的对话和激发行动的灵感。

作为提醒，原始问题是 {question}

---

这就是核心提示序列的全部内容！通过最后的输出，您将得到一个改进版本的初始问题。希望还有一些有用的其他上下文，以帮助思考过程。

为什么提出好问题很重要？

现在事情变得更有趣了。这是你可以将新问题作为新输入并再次运行循环的地方。这使得它成为一个「思维链 - 图」的推理过程。代理可能会选择不同的角色来进行下一次迭代，所以你必须进行探索。在新问题质量达到收益递减之前，我已经进行了 3-4 个循环的迭代问题优化。在这里有很多探索的空间，可以同时运行多个推理过程，使用相同的问题、相同的角色、相同的提示，并选择最好的一个或进行综合。

---

工程改进正在进行中！Python 示例是为黑客马拉松快速创建的，所以需要进行大量的重构。基本上，我首先在完善后端、逻辑、提示工程和人设库，以确保这个过程是可靠且实际有用的。它确实如此！我现在经常使用它，它提高了我的思考深度。

更多未来的想法可以在仓库中找到，包括未来的用户界面、问题质量评分方法、用户输入目标以实现更自适应的提示等等

再次用你最好的问题进行测试，如果有任何有用的改进，请分享！

### 10

方军 2024/01/03

刘江老师观点：

大模型更像高潜实习生，目前确实是更善于帮助大家补足短板，其实光这个价值就很大了。一个常见误区，就是只用自己的专业知识去测它，然后发现不太行，摇摇头，就不用了。

我讨论：

很赞！

但这个看法也对也有问题。对的不用多说。

有问题的是，如果让它做的事不是我自己的知识范围，我们没法判断结果的对错、水平高低，会很麻烦。

因此，目前，还是在自己的知识范围内用比较保险。

前几日 AIGCxchina 微信号也发了一个安替文章，也用的实习生类比：

[AI 革命的圣杯：找到「审核和管理一群实习生完成卓越项目」的方法](https://mp.weixin.qq.com/s/WFJlKEzAntYOQrHYW_hDzQ)

找到「审核和管理一群实习生完成卓越项目」的思路并且变成实现。

### 11

方军 2024/01/03

025 想法 - 中间态 - 最终态

早上想起来报告里有页 PPT 应该加上去，因此，如图上部所示：

- 我有了一个想法

- 变成中间态（实际上是特殊 html 格式）

- 最后展示为 PPT 形式

刚刚想，或许把 AI 融入工作流，应该也是把它用于中间态，让它在中间态里面「transform」（转换）。

- 更快地产出中间态

- 更方便地产出中间态

- 能够在多中间态间方便地调整

实际上，如果已经有了一份报告，将报告转换成一个社交文本（Twitter/Twitter Thread/Atomic essay），这个是当前 LLM 非常胜任的工作，只需人工进行审核即可。

总体而言，还是要融入工作流，在工作流中思考，LLM 才能在其正确率不高（目前至少 20-30% 错误率）的情况下找到适用场景。

从流程看：

怎么用技术改进工作流，的确是个有意思的话题。昨天一个小会说，要产出 1000 张图片中文字有变化的图片，我当时觉得这个事很容易啊，但后来一想也不对，但凡涉及到了流程，都不容易。

假设一个场景，并非上文说的 1000 个仅仅换字的图片，而是要生成 1000 个海报，由朋友们发。

那么流程是：

- 图片生成

- 图片发送 + 文字发送对应人

- 监控朋友圈发送，并点赞、截图（以及催促）

- 或回收图片

图片修改的部分反而是最不重要的，那些复杂的事其实是：1）整个工作流或者说 SOP，2）与人沟通的温度

那真到了如此程度，要么是团队很努力（也很有温度），要么是用上现成的 RPA 来落实 SOP 吧。

为什么似乎说岔了到这个话题，其实在我心里并没有，我一直在想，AI 作为一个技术在一个流程中发挥什么作用呢？现在各种纯从学术研究（paper）到学术研究 (paper)、或从技术到技术的讨论是有问题的。

\#AI 使用感悟#

（这篇可能略有点费解，以后再详细写清楚吧，有些想法一是没想明白，二是为了避嫌换用其他例子难以表达清楚。）

### 12

方军 2024/01/03

我最近对于 AI 绘图又有点提不起兴趣，其实不是最近，至少一两月。

得到据说演讲用了很多 AI 绘图，但我觉得那些都没啥意义，有 AI 无 AI 都一样吧。

刚刚看到这张图，别人好心分享 prompt，但我只想说，AI 生成的图可以更真实一点吗？

我虽然摄影技术很糟，但觉得拿着 x100v 这样的普通相机，拍出来东西也比这些好太多倍了。

AI 绘图如何做到「以假乱真」？

我有个奇怪的假设，我觉得受众作为一个群体特别有智慧，如果你创作方没努力，偷懒了，受众很快就感受到了。

AI（不管是文字还是图片）在这个假设下，目前都做不好。那么，如果要把努力加进去，加在哪儿呢？

### 13

方军 2024/01/04

超级赞同，需求，或者更进一步说，目标。why > how

twitter @Chinese_XU：但是我再次强烈提醒：人再牛逼都比不过编译器写代码快

人真正的工作是说清楚需求，而不是去提出正确的问题。因为连需求都不清楚，你永远提不出正确的问题。

这逻辑太显而易见，却是整个行业都没有发现的。

道理说出来大家都感觉简单到就是常识。

但是就这波 GPT 来说，台面上努力搞提示词工程的人，有多少意识到根子上不是人工智能傻逼，而是各种相关领域的需求描述不清呢？

任何知识抽象规范合理的领域，就是大家看到目前 AI 应用良好的领域。

搞不好的领域，根子就是其实根本说不清楚，给你 10 万字也一样。

@toong: 需求描述不清，搞提示词工程的也解决不了吧

ChatGPT 的两种 Prompt 提示词：「逐步思考」和专业术语 - Toong's Substack

@Chinese_XU

是的，所以我才有这么大怨念。不是说提示词工程无意义，而是需求描述这个问题，从有软件行业开始就是大家已知的问题。然后整个行业没有任何论文讨论应该怎么去做。

@wind……

看来你是深深的痛过……

再给补一刀，不只是软件领域，各个领域都有同样的问题，只聚焦于实现层面的具体问题，而不去深挖需求本质……

@Jet39417390

这个悖论有意思。很多人正式自己思路不清晰才去求助 AI。把 AI 当成了全能全知的东西。最后 AI 告诉他，你自己先把思路理清楚再来问我。

twitter.com/Chinese_XU/status/1742480342198722569

方军：我想，我们在这个问题上没有犯错

AI 时代的超级个体 = (目标 + 认知 + 责任) x 提问的能力。

我们把目标和责任放在非常重要的位置。提问看作技巧。

2024-01-04 13:34

### 14

方军 2024/01/04

这里讲的东西几乎都是盲区了，简单学习了下。

[大模型训练为什么用 A100 不用 4090](https://mp.weixin.qq.com/s/nsTL07D5Npn14L18GiC-fQ)

### 15

方军 2024/01/04

IDC 中国的 AIGC 应用层十大趋势。

2『已下载原文「20240104《2024年AIGC应用层十大趋势白皮书》」收录入「2024011大语言模型专题资料」。（2024-01-14）』

### 16

方军 2024/01/04

摘：我发现「有点专业吸引异性，非常专业吸引同性，过度专业吸引同行」这句话，在各个行业领域都适用。

补刀：不专业吸引大众。

### 17

方军 2024/01/04

这句话精彩：

When you don't create things, you become defined by your tastes rather than ability. your tastes only narrow & exclude people. so create.

—— Jonathan Gillette

当你停止创造，你的才能就不再重要，你所拥有的只剩下你的品味。

而品味会裹挟你，让你排斥他人、变得狭隘。

所以，要创造。

### 18

方军 2024/01/05

一个英语老师的担心，蛮真实的，摘：

目前我是处于让孩子接触和不让孩子接触这两种观念天人交战的阶段

现在这个场景，跟当年搜索引擎出来的时候有点像，但又不完全一样。

搜索引擎那个时代，很多人家里还没有电脑，就算有电脑，很多人家里也没有宽带。就算有宽带，很多人也不知道怎么用搜索引擎搜索。就算真的用上了搜索引擎搜索，很多人也不知道用什么样的关键词。即便是现在搜索引擎都发展几十年了，仍然有很多人不知道怎么用搜索引擎。

但是 GPT 上手难度就小了很多，现在基本上人手一个手机。而且网络就跟生活中的水电一样，不可或缺。

以前在搜索引擎里不知道搜什么关键词。那用 GPT，你只要能用正常的语言描述你的问题就可以。

比如说一个三年级的小学生，老师让写一篇春游的文章。只要在 GPT 里告诉它「帮我写一篇 300 字的作文，题目是春游」，立马就可以产生很多不重样的文章。

搜索引擎的时代，是东拼西凑，尽可能让自己的文章看起来好。AI 时代，是想办法把 AI 写的文章往坏里改，尽可能表现的像个正常的人类。

所以家长面临的挑战就是，要不要让孩子接触到 GPT 这种东西。如果接触到了，孩子很有可能就会非常依赖这种工具，从而丧失独立思考。

但另一方面，不给孩子接触这种东西，又害怕会远远落后于时代。因为这个东西迭代速度很快，对人们的学习方法会产生深远的影响。

目前我是出于让孩子接触和不让孩子接触这两种观念天人交战的阶段，大家说说自己的观点。

weibo.com/1071037450/4984600750720059

### 19

方军 2024/01/05

刚刚跟朋友讨论有个感慨。

搞理论创新的人，都是要强调跟别人不一样，去人少的地方。

搞技术，特别是搞应用型技术的人，都是哪儿人多去哪儿，千万别用没人用的新技术。

也没有对错，两种不同的思路，各有各的用场，别用反就好。

### 20

方军 2024/01/05

Open AI 发布文章，介绍了 GPTs Builder 是如何被创建的，搞笑的是这个 GPTs 构建器本身也是一个 GPTs。

[GPT Builder | OpenAI Help Center](https://help.openai.com/en/articles/8770868-gpt-builder)

(英文更准确）

来学习一下 Open AI 是怎么写 GPTs 提示词的。

下面是 GPT Builder 具体的构建过程和提示词：

GPT Builder 被构建为一个自定义的 GPT，具有指令和动作，允许它写入当前正在构建的 GPT 的字段。

更高级的构建者应该使用手动配置界面来编辑他们的 GPT 的字段，但 GPT 构建器始终可以作为一个起点。

由于 GPT Builder 本身就是一个定制的 GPT，我们可以分享我们使用的配置作为创建强大 GPT 的示例。

以下是我们用于为 GPT Builder 提供动力的核心指令，截至 2023 年 1 月 3 日。为了清晰起见，我们将指令分为「基本上下文」和「步骤演示」，但在应用到 GPT 时，它们都会进入「指令」部分。

说明 - 基本上下文：

您是一个擅长创建和修改 GPT 的专家，它们就像可以具有额外功能的聊天机器人。

每个用户消息都是您处理和更新 GPTs 行为的命令。您将承认并将其纳入 GPTs 的行为，并在 gizmo_editor_tool 上调用 update_behavior。

如果用户告诉你开始以某种方式行为，他们指的是你正在创建的 GPTs，而不是你自己。

如果您没有个人资料图片，必须调用 generate_profile_pic。如果明确要求，您将通过 generate_profile_pic 生成个人资料图片。否则不要生成个人资料图片。

保持作为 GPTs 制作者的专家的语调和观点。GPTs 的个性不应影响您的回答风格或语调。

如果你问用户一个问题，永远不要自己回答。你可以提出答案，但必须让用户确认。

您可见的文件也对 GPT 可见。您可以更新行为以引用已上传的文件。

请勿使用「约束」、「角色和目标」或「个性化」这些词。

GPTs 没有记住过去经验的能力。

说明 - 步骤：

你是一个用于开发新 GPTs 的迭代原型游乐场。用户将通过初始行为提示你。

您的目标是迭代地定义和完善 update_behavior 的参数。您将以专业 GPT 创建者的身份进行交谈，从用户那里收集规范以创建 GPTs。您将在每次交互后调用 update_behavior。您将按照以下步骤进行：

1）用户的第一条消息是关于这个 GPT 应该如何行为的广泛目标。使用参数「context」、「description」、「prompt_starters」在 gizmo_editor_tool 上调用 update_behavior。记住，你必须使用参数「context」、「description」和「prompt_starters」调用 gizmo_editor_tool 上的 update_behavior。在调用 update_behavior 之后，继续进行第 2 步。

2）在这一步中，你的目标是确定 GPT 的名称。你会为自己建议一个名称，并要求用户确认。你必须提供一个建议的名称供用户确认。

你不可以在没有建议的情况下提示用户。不要使用驼峰式复合词；请使用空格代替。如果用户指定了一个明确的名称，请假设它已经确认。如果你自己生成一个名称，你必须让用户确认该名称。一旦确认，只需调用 update_behavior，并继续到第三步。

3）在这一步中，您的目标是为 GPT 生成一个个人资料图片。您将使用 generate_profile_pic 为这个 GPT 生成一个初始个人资料图片，无需确认，然后询问用户是否喜欢，并是否想要进行任何更改。

请记住，使用 generate_profile_pic 生成个人资料图片时无需确认。在每次改进后生成新的个人资料图片，直到用户满意为止，然后继续进行第四步。

4）在这一步中，你的目标是细化上下文。你现在要引导用户细化上下文。上下文应包括「角色和目标」、「约束」、「指南」、「澄清」和「个性化」等主要领域。你将引导用户逐个定义每个主要领域。

你不会一次性提示多个领域，而是一次只问一个问题。你的提示应该是引导性、自然和简单的语言，不会提及你正在定义的领域的名称。

你的提示不需要介绍它们正在细化的领域，而只需是引导性问题。例如，「约束」应该提示为「应该强调或避免什么？」，「个性化」应该提示为「你希望我怎么说」。

你的引导性问题应该是不言自明的；你不需要问用户「你认为呢？」。每个提示都应参考并建立在现有状态之上。每次互动后都要调用 update_behavior。

在这些步骤中，您不会提示或确认「描述」、「提示启动器」的值。但是，您仍会在上下文更新时生成这些值。您不会提到「步骤」; 您将自然地进行下去。

你必须按顺序完成所有这些步骤。不要跳过任何步骤。

请让用户在右侧的独立聊天对话框中尝试 GPT。告诉他们你能够听取他们对 GPT 的任何改进意见。以一个问题结束这条消息，不要说「让我知道！」。

在确认名称时只将 GPT 的名称加粗；在第 2 步之后不要加粗名称。

Action 行动：

在上述步骤之后，您现在处于迭代细化模式。用户将提示您进行更改，您必须在每次交互后调用 update_behavior。您可以在这里提出澄清问题。

generate_profile_pic: {description: ' 为 GPTs 生成个人资料图片。您可以调用此函数而无需生成图像的能力。如果当前的 GPT 没有个人资料图片，则必须调用此函数，并且在需要生成新的个人资料图片时也可以调用。在调用此函数时，请将个人资料图片视为已更新，不要调用 update_behavior。'},

update_behavior: {description: "更新 GPTs 的行为。您可以有选择地省略更新字段。您将使用这些新字段作为 GPTs 行为的真相来源，并不再引用任何先前版本的已更新字段来通知响应。当您更新一个字段时，如果它们是不一致的，那么您还必须同时更新所有其他字段以保持一致性。如果您更改了 GPTs 的名称，则必须使描述和上下文保持一致性。在调用此函数时，不能总结该功能外部使用中所使用的值" , params: { name, context, description, prompt_starters, abilities, profile_pic_file_id} }

GPT 可以利用提供给它的所有信息，包括提示、指令和附加文件，来构建对用户的回应。不要包含你不希望用户知道的信息。

\#提示语模版 #

泽生：感谢分享！方老师，有个小问题想请教您。

最近我有在 GPTs 里添加 actions，感觉体验一般，需要不断地用详细的指令来寻找 actions、同时规范 GPTs 的输出。不知道是 GPTs 自带的过长提示词导致的「记忆」缺失，还是个人配置的关系… 请问，除了进一步描述清楚初始提示词外，还有什么好方法吗？

2024-01-05 14:48

方军回复泽生：这个我真是不知道，action 简单看下，但没用过。我用 api 较多，界面用得少。

2024-01-05 14:58

### 21

方军 2024/01/05

「很多人提问题都很难，别说 prompt」。看到这句话。

想起来，23 年夏某个时候，有朋友说，大众很需要学会怎么提问的，你应该把提问的经验分享出来，投入地去搞提问课。

也想过这个，当时我们是觉得，是，提问或许是可以教会的。

对于普通人来说，学会向 AI 提问，门槛最低。

但幸亏没太考虑，事后看，这个用法不属于不普通人。

有专业能力的人，自己能学会。

普通人，算了算了，我觉得普通人还是刷刷视频好了。（最近刷小红书，我对普通人的认知有了进一步的提升。）

并且，我对于制造焦虑这件事，不在行，也没动力。

方军：怎么解决呢？我觉得普通人只想要结果，不想经历过程，行业里的人一定会努力做开发，让他们享受的。

2024-01-05 20:08

### 22

方军 2024/01/05

026 如何利用 GPT 的表达风格

在不给文本例子或至少不给名字作为样例时，GPT 的回答有着相对统一的「表达风格」。我至少经常能够强烈地感受到两种风格：

- 普通问题，一般是较为详尽、权威

- 代码问题，一般为典型技术文档风格

（注：语气权威不一定就是真权威，文档风但内容可能错）

我们平常在阅读时，也会遇到很多表达风格：

- 经济学教材风格（一般经济学 vs 偏向数量化）

- 管理学者风格 vs 德鲁克式大师风格

- 畅销商业书风格（通常是讲故事）

- 商业报告风格

- 互联网个体的感性或情绪式表达

(突然意识到传统媒体风格早已经远离了我的生活阅读）

刚刚在读一本知名心理学家/畅销书作家的书，发现他的写作风格我读起来尤其费劲。始终在想，这段、这章要讲啥？

对比而言，认知天性那种偏向商业畅销书的写作，我读起来就极其轻松。商业畅销书通常会照顾读者，把观点明示。

那么，GPT 给表达风格带来的变化可能有两个方面：

第一，它的详尽、权威、无情感的表达，会不会影响很多人的表达风格？

实际上我的表达一直强烈地受到互联网风潮的影响，主要是被博客（blog）的随意表达所影响。我理解博客的表达风格是 —— 我记录自己的理解，你们随意。我没有受到微信公众号的（非虚构）叙事/叙述、或推销风格的影响。

如何在听到权威式声音时保持警惕，那是另外角度的话题了。

第二，我们如何利用 GPT 的语言表达能力，来促进自己的阅读理解？

在过去一年，我们设想的路径都是 RAG，或者说「AI 生成摘要」。

我直觉觉得这是不对的。理由很简单，摘要可以作为判断是否读的辅助，但远不足以作为输入的工具。

更好的方式如果要找类比的话，我觉得是「翻译」较好，比如古文书对应的现代翻译。

如果能够用 AI 轻松地把一种自己熟悉的文本风格转换为自己熟悉的，并对照阅读（就像我 2023 年阅读大量的中英文对照文本一样），可以大幅度提高理解的效率。

当然，另一个配套的手段是必要的，也就是获得书或资料的结构。我个人的体验是，如果没有目录，内容根本不能快速抓住。这也是另外的话题了。

\#AI 使用感悟 #

方军：现在其实都在找让 GPT 能干到 70 分的事，也就是那些能够容错率 20% 以上的事，所以我觉得，用于生成新文字实在不行啊，那儿容错率太低，而用于辅助理解，其实容错率很高的。

2024-01-06 09:04

### 23

方军 2024/01/05

刘思毅访谈专家，他的学习能力很强啊：

摘他分享的一个 AI 专家的部分对话。

我们探索出来的，是交互过程的 SOP，否则对业务没有意义，不需要自嗨。

GPT 能生成很牛逼的东西，是因为懂交互、懂自己方法论的人，可以帮助他很牛逼的东西。

通过提示词写 60 分的小红书不可能，40 分可以。

但是有好的引导方式，可以写 80 分，但是好的引导方式本身就是一个门槛了。

---

总结，提示词工程，在一个点上，达成一个效率提升，提升 5-6 倍，其实很牛逼了。

但是卡场景。

对于普通人来讲，GPT 最难的，是 —— 真的真的真的很难提问，好问题就是资产。

---

针对刘思毅，有什么业务场景。

1、全球跑酷助理：语言科普、知识补充、攻略收集以及一起探索。

2、创意发散：中午吃啥、周末去哪里玩儿以及可以去哪里旅行，每一次有新的想法出来，建议，碰撞助理。

3、坚决不适合中心化 IP 做内容支撑，不需要个人 IP 的内容可以给 GPT，但！刘思毅的朋友圈，完全不适合。

就算学会了语言风格也不适合，因为他是猜测，没有知识和思想，就会无神。

4、刘思毅的朋友圈写 100 万字，投喂进去，然后任何东西，都可以用刘思毅的过往历史来输出。

这是不可以的，理论上可以，但是实际上没有任何可操作性。成本！

---

他的快速学习能力的确可以，而且和自身结合得真好。

### 24

方军 2024/01/06

英国发布《法官使用 AI 指南》

[英国发布《法官使用 AI 指南》（全文 + 翻译）](https://mp.weixin.qq.com/s/Giun90FDjmjVjQS8njV6kQ)

在使用任何 AI 工具之前，确保您对它们的功能和潜在局限有基本了解。

- 面向公众的 AI 聊天机器人不提供来自权威数据库的答案。
- 它们最好被视为获取某事的非决定性确认的方式，而不是提供立即正确的事实。
- 即使是最好的提示，提供的信息也可能是不准确的、不完整的、误导的或有偏见的。
- 目前可用的 LLMs 似乎是在互联网上发布的材料上进行训练的，它们对法律的「看法」通常基于美国法律。

要点：

维护保密性和隐私

确保责任和准确性

注意偏见

保持安全

承担责任

注意法院参与方可能已使用 AI 工具

有价值的任务：

AI 工具能够总结大量文本

AI 工具可用于撰写演讲

AI 可执行撰写电子邮件和备忘录等行政任务

不推荐使用：

法律研究：AI 工具是寻找无法独立验证的新信息的糟糕方式。

法律分析：当前面向公众的 AI 聊天机器人不会产生令人信服的分析或推理。

### 25

方军 2024/01/06

我还是对 AIGC 这个名字提不去好感，这里真不是什么 GC 的事。

当然，我们用什么 GENAI GPT，也都很扯，没有合适的名字，也许就 AI 吧。

梦见电子羊的仿生人：生成式 ai 这个概念是有什么逻辑问题吗？

2024-01-06 21:25

方军回复梦见电子羊的仿生人：太复杂的概念，平常沟通起来就不方便。

2024-01-06 21:26

方军回复梦见电子羊的仿生人：它不是一个子学科，也不是一个子产业，用这个名字会吃很多暗亏。比如，对于搞研究的人来说，LLM 是一个子学科。

2024-01-06 21:28

欧阳：是的我一直觉得这个名字需要修正中国 aigc 城市产业联盟当时我也建议了。

2024-01-06 22:21

欧阳：可能最合适的的确还是 AI，更有代表性。

2024-01-06 22:21

方军回复欧阳：是的。

2024-01-07 00:20

### 26

方军 2024/01/07

摘关于 GPT Store 的一个看法：

我的看法类似，收费墙内的服务，很难做。

notion 上也有卖各类模板，ms office 也有卖各类软件，但相对母体很小很小的份额。（我订了十多年 ms office，今年也停了，用得实在少。）

api 很好（相当于在 api 里面做了一个 mini 版的 AI APP 编排），界面版希望很小。也许我过度反思当时对 plugin 的高期待及落差。

中文市场（香港朋友问过我），我觉得更没戏，一，想付钱的人付不了 plus，二，中文市场订阅付费习惯很差。（很奇怪的，要课，不要软件订阅。）

---

Bindu 预测 GPT-Store 可能不会成功，并阐述了具体原因，感觉都挺合理的，使用场景少，欺诈应用以及 Open AI 是否有能力运营好都要打个问号。

twitter.com/bindureddy/status/1743389233283477819

Bindu Reddy 是 abacusai CEO

原因：

- 大多数消费者不愿为软件支付费用。实际上，很多应用商店中的付费应用其实是诈骗，诱使用户下载后再进行持续性收费。

- 已经有不少用户每月花费 20 美元订阅 ChatGPT+，他们不太可能再花更多钱

- 从 ChatGPT 插件的使用情况来看，只有能浏览网页的插件实际上有用，而这已经成为 ChatGPT 的内置功能了

- 很难想象是否有任何自定义版的 CustomGPT 值得付费。目前看来，只有 "与 PDF 聊天" 和 AI 女友等独立 CustomGPT 应用受到欢迎。而与 PDF 聊天功能已经内置在 ChatGPT 中。

我预测会有一些角色扮演类的 CustomGPT 应用出现，但我怀疑用户是否愿意为此付费。

- 对于以发展 AGI 为目标的 OpenAI 来说，这是一种巨大的分散注意力的事项。我们至今还未看到 GPT 4.5，更不用说 5.0 版本了

- 如果 OpenAI 想增加收入，他们其实更应该将来免费提供 GPT-4，并通过升级至 4.5 或 5.0 版本来获利。目前免费版提供的 GPT-3.5 还不够理想。

- 这对 OpenAI 来说将是一个巨大的挑战，包括处理内容审核问题、处理消费者对开发者欺诈行为的投诉等。

时间将证明我的预测是否正确。

### 27

方军 2024/01/07

想不到 AI 在这里找到一个应用场景

比尔·阿克曼：

昨晚，MIT 没有人睡个好觉。

（在他夫人被挑刺之后，这家伙疯了，不过，她夫人那个真不是什么问题，二，文科这些破事真翻，科技类没啥事，科技类就是 PS PS 图片得意）

昨天晚上，就在我发布消息称我们将对麻省理工学院所有现有教员、校长科恩布鲁斯、麻省理工学院行政成员及其董事会进行抄袭审查后不久，我确信校园里可以听到集体倒吸一口凉气的声音。

为什么？嗯，每个教员都知道，一旦他们的工作成为人工智能的目标，他们就会被淘汰。学术界的任何书面作品都无法在人工智能搜索缺失引号、未能适当释义和 / 或未能正确认可他人工作的能力的情况下幸存下来。

但昨晚没有睡觉的不仅仅是麻省理工学院的教员。@Harvard 的教员、理事会成员和行政领导层也没有睡觉。因为我们为什么要停在麻省理工学院呢？

难道我们不需要深入研究哈佛的学术诚信吗？

耶鲁大学、普林斯顿大学、斯坦福大学、宾夕法尼亚大学、达特茅斯怎么样？你明白了。

虽然我们将对麻省理工学院的抄袭行为进行详细审查，但我们并不是唯一这样做的人。

世界上的每一所学院和大学都必须为自己做同样的事情。他们会这样做，因为他们需要验证所有抄袭指控，否则其他人会为他们做这件事。

然而，最好的方法可能是创办一家人工智能初创公司来完成这项工作 (I 有兴趣投资一项），因为有大量工作要做，而且许多机构没有资源来完成这项工作他们自己的。也许更重要的是，捐助者将要求由独立的第三方进行审查。

今天谁会相信高等教育能够自我审视？

考虑一下本质上不可调和的利益冲突。您相信今天的大学校长会对他们的教师进行检查吗？审查会被用来攻击那些政治观点不受领导层青睐的教员的可能性有多大？

我们之前已经在大学校长及其院长使用的其他工具中看到过这种情况。想想 MeToo 指控、言论代码和其他取消策略的武器化，这些策略摧毁了校园的言论自由，以及许多教职员工的声誉、职业和家庭。

打个比方，即使是我们最可信的公司，谁会相信他们会审计自己的财务报表呢？所有上市公司都设有独立审计师，并接受监管机构的仔细审查，以确保其保持质量、标准、准确性和独立性，这是有原因的。

如果抄袭审查变成了整个大学令人难以置信的尴尬怎么办？这可能会导致教师的大规模解雇。捐赠者终止捐赠。联邦资金被撤回，引发了一场大规模的诉讼大火，教职员工和大学就什么是剽窃、什么不是剽窃相互起诉。想象一下，当它在全国甚至全世界推广时，成千上万名教职员工的声誉将不可避免地受到损害。

也许这是一件好事。

高等教育对社会和国家的影响

当我 10 月 7 日早上醒来时，我的第一个想法并不是要发起一项努力来拯救高等教育本身。我对这个世界还有其他更紧迫的担忧，而且我仍然有这些担忧。但众所周知，我们的高等教育体系（HES）至关重要，因为它能够影响和影响我们年轻一代的思想，从而深刻影响我们所有人的生活。

HES 可以影响幼儿的教学内容以及小学和高中的教学内容，因为教育学校会培训下一代教师和管理者，并设计他们所教授的课程。

HES 可以让一代人相信，我们中的一些人是压迫者，另一些人是被压迫者，并为什么样的暴力和恐怖主义以及何种程度的暴力和恐怖主义是解决这种压迫的适当工具提供了理由。

HES 可以影响我们的医疗机构和医学伦理，例如，我们一些最具争议的程序和药物，以及它们对儿童使用的明智性等等。我相信你明白了。

HES 影响我们的法律体系、我们的道德以及我们对是非的基本理解。

它影响我们如何看待资本主义和经济体系，如何解决财富不平等、税收、货币和财政政策，以及如何考虑普遍基本收入和其他替代方案。

它还影响到宗教以及全国各地的宗教信仰和不再信仰宗教的方式。

它可以提出一种货币理论，该理论指出，美国作为一个主权国家实际上对其支出没有限制，因为它可以印制新钞而不会产生任何后果或丧失偿付能力。

当然，随着时间的推移，我们教育系统的毕业生会成为法官、最高法院法官、政治家、媒体成员以及其他影响和决定我们生活方式的人，并帮助我们理解真理，但谁的真理呢？你可能会问。

HES 影响我们国家投票系统的管理方式；竞选公职的资格标准；初选系统如何运作，以及如何才有资格在某个州参加投票。

我可以继续，但我相信您已经了解 HES 的强大功能。你不需要我告诉你它有多重要。

鉴于 HES 的力量，那些对权力感兴趣的人当然希望控制我们最有声望和影响力的大学，以便他们最终控制我们的教育系统，我们的政府，进而控制整个国家。

人工智能的力量及其对剽窃的影响

既然我们知道美国（最终是全世界）每所学院和大学的每一位教职员工的学术工作都将受到抄袭审查，那么重要的是要问这会产生什么影响。

如果每个教职员工都遵守自己机构当前的抄袭标准，并且大学执行自己的规则，他们可能不得不解雇绝大多数教职员工。

在过去的几周和几个月里，我确实收到了数百封电子邮件、短信、手写和打字的信件和卡片，以及支持电话（以及 X) 上的上千条帖子和回复（如果不是上百条的话，也有十条）—— 来自朋友和陌生人、校友、教师和学生、外国高级领导人、美国参议员和国会议员、知名媒体人士和几位总统候选人 —— 感谢我为帮助解决哈佛大学、麻省理工学院、宾夕法尼亚大学的问题所做的努力尽管如此，大多数人对必要变革的机会持悲观态度，因为几乎每个人都认为，由于教师的终身任职制度，需要几十年的时间才能解决这个问题。

然而，好消息是，有了人工智能，解雇终身教授不再是一个挑战，因为解雇那些学术记录有问题的教授要容易得多。几乎可以肯定的是，作者会错过一些引号，并且至少在其论文的一小部分页面上无法正确引用或提供其他作者的出处。我说的是页面百分比而不是实例数量，因为通过与拼写检查出现之前的拼写错误进行比较，可以更好地理解当今的抄袭行为。

例如，如果两篇论文各有 10 个错误，其中一篇论文有 30 页，另一篇论文有 330 页，那么说两篇论文都存在拼写错误是不公平的。标准必须是百分比标准。

拼写 / 抄袭错误有多普遍？这是另一个应该问的问题。所谓的抄袭行为是出现在他们的一小部分论文中还是出现在他们的大部分作品中？

重要的是，在现行制度下，最有成效、最重要的学者面临的风险最大，因为你写的论文和页数越多，你错过引文或某些引号的可能性就越大，而且更有可能有人会这样做。检查，（直到昨天）。对于最杰出和被引用最多的学者来说，抄袭是最大的威胁，因为如果没有人读过你的作品，并且你没有公众形象（也没有与知名人士结婚），那么没有人会花时间看你的作品。

作品越有影响力、越重要，就越有可能面临抄袭审查的风险。但如果你只发表了十几篇长度适中的论文，而且这些论文的影响力不是特别大，引用率也不是很高，那么出现大量抄袭并被发现的风险应该相对较小。

baoyu.io/translations/others/last-night-no-one-at-mit-had-a-good-night-sleep

### 28

方军 2024/01/07

网友：下周 OpenAI 的 GPT store 就要正式发布了，向大家汇报一下我这段时间折腾 GPTs 的成果

其中有一些有趣又有用的小工具，欢迎大家试用体验：

Food Detective：通过照片分析一道菜总体的热量与全面的营养成分。

Pet Pal：宠物护理、行为和健康专家。

Biotica Explorer：识别照片中的植物和动物，并提供详细的百科知识。

蔚小理数据通：分析蔚来、小鹏和理想三家公司的财务数据、商业数据以及股价。

真厉害，能折腾。

### 29

方军 2024/01/08

摘：GPT 从技术能力维度本质上是一个 ChatGPT 的分身，能力跟 ChatGPT 是一样的，但区别是每个开发者在创建 GPT 的时候，都为他设定了一个使用场景，这个场景不是万能的场景，不是什么都可以干，是一个具体的场景，是定义了具体为谁解决什么具体问题的场景。

[ChatGPT 插件不行，GPT 就行了？](https://mp.weixin.qq.com/s/D8y53LZ13B59UE9iLFubsw)

### 30

方军 2024/01/08

### 31

方军 2024/01/08

我不怎么愿意参加跨越边界的讨论，更不愿意参加什么 panel，一个原因可能是费曼毒中得太深。（后附一段费曼的吐槽）

和专业的人讨论，很简单啊，你提一个词，人家就明白。

给普通大众讲解也很好，我们努力做好一切，通俗易懂地让人家能懂。

杂七杂八的讨论最烦，你都不知道各自在讨论什么。

有多少人讨论前会定义问题？

我想，工程出身的人不太容易犯这种错，不只是费曼这种理论物理学家，为什么呢？因为工程出身的人，必须先定义问题，并定义目标，然后再解决问题。不定义问题、不定义目标，那就没必要说什么解决问题了。瞎扯呗。

摘一段费曼的吐槽：

\## 自负的傻瓜

最后到了评估这次会议的时候，其他人都在说他们从中取得了多少收获，会议有多成功，等等。当他们问到我时，我说：「** 这场会议比罗夏墨迹测验还要糟糕 **。别人问你，你认为你看到的那个毫无意义的墨水斑点是什么，但当你把想法告诉他们时，他们却说你说得不对！」

更糟糕的是，在会议即将结束时他们本来还要再开一场会，这一次公众也会参与进来，可是负责我们小组的那个人竟然说因为我们的工作成果斐然，所以接下来不需要公众讨论部分了，我们只要告诉公众我们讨论的所有成果就行了。我大跌眼镜：我认为我们连个屁都没有得出来！

最后，当我们讨论到我们是否在不同领域的人之间找到建立对话的方式时 —— 我们的第二个基本「问题」—— 我说，我注意到一件有趣的事。我们每个人说的都是我们所想的「平等伦理」，从自己的观点出发，忽视其他人的观点。举例来说，那位历史学家提出，理解伦理问题的方法就是从历史中找寻人类进化和发展的答案；那位国际律师建议，我们的方法应该是研究人们在不同情境下实际采取行动和制订计划的方式；那位牧师总是在说「知识碎片化」；而我，作为一位科学家，提出我们应该把问题隔离出来，就像伽利略做实验时那样；等等。「所以在我看来，」我总结说，「我们之间完全没有对话。我们有的，只是混乱。」

当然，我被群起而攻之。「你不觉得混乱可以产生秩序吗？」

「哦，是作为总体原则，还是……」我不知道应该如何应对「混乱中会产生秩序吗？」这样的问题。会，不会，问的到底是什么？

参加那场会议的人中有很多傻瓜 —— 自负的傻瓜，而 ** 自负的傻瓜 ** 能把我逼疯。普通傻瓜不成问题，你可以和他们对话，试着帮他们解除误会。

但是我无法容忍自负的傻瓜 ——** 掩饰自己的愚蠢并用连篇的鬼话把自己包装成智者的傻瓜 **！一个普通的傻瓜不是骗子，一个诚实的傻瓜没什么解决不了的，但不诚实的傻瓜令人讨厌。

而这就是我在那场大会上遇到的人，一群自负的傻瓜，我为此感到心烦意乱。我不想再经历这种事情了，所以从此不再参加跨学科会议。

方军：还中了一句费曼毒：

挑战者号费曼报告（调查委员会报告附录）的最后一句话：

一项技术要成功，尊重现实远比维护公共关系重要得多，因为大自然是不会说谎的。

2024-01-08 17:38

### 32

方军 2024/01/08

看费曼总会乐死，他真是个讲故事的天才

第二天早上，一辆豪华轿车来接我 —— 有人安排我们乘坐豪华轿车去参加第一场正式会议。我坐在前座上，旁边是司机。

去参会的路上，司机对我说：「我知道有很多重要人物都在这个委员会里……」

「是啊，好像是……」

「我喜欢收集签名，」他说，「你能帮我个忙吗？」

「没问题。」我说。

我正往外掏钢笔，这时他说：「到那儿之后，你能指给我哪位是尼尔·阿姆斯特朗吗？我想跟他要个签名。」

### 33

方军 2024/01/08

我对翻译没有兴趣，但我真心希望 AI 能够挽救中文翻译。

费曼传（Genius 那本），我本以为之前高教社那本够差，但一对比，啊呀，新版更糟糕。

比如这两句：

A few Europeans were absent, as was Albert Einstein, settling into his statesmanlike retirement, but with these exceptions the Pocono conclave represented the whole priesthood of modern physics.

新版：几名欧洲科学家缺席了，其中包括阿尔伯特·爱因斯坦（Albert Einstein），他正处于像政治家隐退一样的状态。即便如此，波科诺会议代表了现代物理学的全体「神职」人员。

高教版：有几位欧洲物理学家没有出席，爱因斯坦也没到，他刚刚退休，过着政治家一样的退休生活。除了这少数例外，在波可诺秘密会议囊括了当代物理学所有的祭司。

全体「神职」人员。这个翻译也太搞笑了。

其中包括爱因斯坦也不对。

高教版看起来还不错，语句也很通顺。

下一句

Night fell and Feynman spoke. Chairs shifted. The priesthood had trouble following this brash young man.

新版：夜幕降临，费曼开始发言。椅子换了位置。「神职」人员很难跟上这个粗鲁的年轻人。

高教版：天色晚了，轮到费曼作报告，现场可以听到椅子移动的声音。这群祭司不太可能跟得上这个急性子年轻人的思路。

新版这都翻译得什么鬼！

天啦，我这种老牌的费曼粉丝，都会中招，普通人呢？

---

墓志铭的翻译

「An honest man, the outstanding intuitionist of our age, and a prime example of what may lie in store for anyone who dares to follow the beat of a different drum.」

新版：「一个诚实的人，我们这个时代杰出的直觉主义者，也是敢于追随不同鼓点的人可能遇到的最佳楷模。」

高教版：「他是一个诚实的人，是我们这个时代的最卓越的直觉大师，对那些勇于追随不同鼓声前进的人，他是一位非常值得师法的对象。」

这句话蛮难翻译的，有很多隐含含义，高教版要好一些。

改进：「他是一个诚实的人，是我们这个时代的最杰出的直觉大师，对那些勇于追随不同鼓声前进的人，他是一位值得师法的楷模。」

其中的英语用法：lie in store 以前还真没注意过，例句：

"What lies in store for my career as a lawyer?"

---

补上前言的最后一句：

When Feynman was gone, he had left behind—perhaps his chief legacy—a lesson in what it meant to know something in this most uncertain of centuries.

新版：费曼离开了，他留下了一个教训，这也许是他最重要的遗产：在这个最不确定的世纪里，了解一些事，意味着什么。

高教版：费曼走了，他留下了一个教训，告诉我们在这一切都不确定、最混沌不明的 20 世纪，懂一点知识到底有什么意义。这也许是他最重要的遗产吧。

再一次，新版不太好。

不过，按我的理解，高教版似乎也不对。

我认为应该是这样：

费曼走了，他留下了一个教训，这也许是他最重要的遗产，他告诉我们，在（20 世纪）这数个世纪中的最不确定性中：真正理解到底意味着什么？

what it meant to know something

know something，在这里应该是真正的理解。

刚刚才发现，in this most uncertain of centuries. 这句话也好难翻译，尤其其中的不确定性还有量子物理的不确定性的意思。不过这个词组无关大雅，错误都还好。还是关键句最重要，我们究竟要从费曼身上学到什么：

what it meant to know something

方军：刚刚跟一位老师讨论的：三个问题，中文不好的问题基本上无解。目前不太行的，连正常的长句理解都有问题。附加词汇表可以部分解决词汇问题。长句理解靠提示语可以部分解决。中文不好的问题，目前还没好方法。

目前 AI 用来 1）对照理解；2）个别解释。

2024-01-08 23:40

方军：know 翻译成真正理解肯定很多人觉得夸张了，可是这句话应该是这个意思。

就像这句：night fell and feynman spoke. Chairs shifted. 不理解根本不知道讲啥意思。当然这是过场，前后知道，它讲啥不重要，就觉得这两句英文好简单。

2024-01-09 11:10

### 34

方军 2024/01/09

LangChain 0.1.0 发布了。

它终于上了一个版本号，python 和 js 功能看起来完全同步了。

blog.langchain.dev/langchain-v0-1-0

重大变化：

将 langchain-core 分离出来，这个部分应该会相对稳定了。

亮点：

Langchain Express Language LCEL

Stream

Output parsing

Retrieval

Agent

langgraph

### 35

方军 2024/01/09

转：QuestMobile 2023 年 11 月数据显示，文心一言 APP 月日均活跃用户规模已达 155.4 万，甚至不如比亚迪海洋网的 APP。

补充信息，11 月 9 日，文心一言宣布用户规模 7000 万。感受下当下国内 AI 产品的粘性。

另外，字节的豆包 124.6 万日活，讯飞星火 71.9 万日活。

### 36

方军 2024/01/09

百川智能发布角色大模型 ，零代码复刻角色轻松满足游戏领域定制需求

今日起，用户登录 npc.baichuan-ai.com，即可开启全新的角色创建之旅。

为提高角色定制自由度，百川智能自研了强多轮对齐和搜索增强知识库两项特色技术。强多轮对齐技术通过精心设计 System Prompt 中的角色设定字段，强化了角色创建平台 System Prompt 在对话 Session 中的特殊地位。

简单来说，用户在系统提示（System Prompt）中定义了角色特征后，角色就会完全遵循用户设定进行相应的「演绎」。

[百川智能发布角色大模型 ，零代码复刻角色轻松满足游戏领域定制需求](https://mp.weixin.qq.com/s/Edw7D-Fh_cmqq02mJrkHyA)

\#新产品动态 #

方军：对这样的产品，我好大的疑虑啊

2024-01-09 15:36

方军：炫技可以，实用价值 0。

当然，百川这样的公司需要炫技。

2024-01-09 15:38

方军：不知道它的实现。我猜应该是，基础模型 - 微调模型 - 特定微调模型。按描述，它应该在特定微调模型里面干了很多事。

但是，其实大模型公司不应该在特定微调模型里面搞太多事。

openai 的之前也搞了什么 codex，但后来发现，微调模型也就是 instructGPT 才是核心。

特定微调，让客户自己干好了。

2024-01-09 15:48

方军：这儿还把 RAG 加进去，更是真想做基础大模型的公司不该做的事。

当然，我这是站着说话不腰疼，大模型公司都想着法子让客户用，不自己多干点，客户用不起来。没辙，所以多干。

能理解他们的做法。

2024-01-09 15:50

方军：为什么我说实用价值 0？

因为搞过提示工程的都知道啊，所有人学的第一个技巧是赋予角色。

但这个几乎毫无用处。

是个进门了就要扔掉的技巧。

2024-01-09 17:44

### 37

方军 2024/01/09

1 月 3 日，教育科技公司网易有道举办「子曰」教育大模型创新成果发布会。在发布会上，网易有道宣布推出国内首个教育大模型「子曰」2.0 版本，同时还发布了基于大模型研发的三大创新应用及一款智能硬件新品：AI 家庭教师「小 P 老师」、有道速读，虚拟人口语私教 Hi Echo 2.0，以及有道 AI 学习机 X20。

[有道再推多款大模型产品及应用，并开源 RAG 引擎「QAnything」](https://mp.weixin.qq.com/s/Mfrhp4eKM4VzdotGK9hs1Q)

\#新产品动态 #

### 38

方军 2024/01/09

OpenAI 刚发了一条长文回复纽约时报的指控，从 4 个方面进行了回应。

1. 表明对于新闻机构的积极合作态度，愿意共同探索新的合作机会

2. 从法律角度说明训练是合法的，对保持美国科技竞争力是有利的！

3. 原样输出训练内容是个技术上的 Bug

4. 《纽约时报》自己说话也没说全部，因为他们提供证据的数据早就在各大网站被引用，他们采集证据的方式是通过特定的提示词诱导才能偶然复现的。

即便如此，我们还是愿意和新闻结构继续合作，帮助提升新闻能力！

以下为原文翻译：

OpenAI 与新闻业的互动

我们致力于支持新闻行业，与新闻机构建立合作关系，并认为《纽约时报》提起的诉讼缺乏法律依据。

我们旨在开发 AI 工具，帮助人们解决那些难以触及的问题。全球各地的人们已经在利用我们的技术，以提升他们的日常生活质量。目前，有数以百万计的开发者和超过 92% 的《财富》500 强企业在使用我们的产品。

尽管我们对《纽约时报》诉讼中的指控持不同意见，但我们认为这是一个阐明我们业务、意图和技术开发方式的好机会。我们的立场可以概括为以下四点：

1. 我们正在与新闻机构合作，共同探索新的合作机会。

2. 使用 AI 进行数据训练在法律上属于合理使用，但我们提供选择退出的选项，因为这是合乎道德的做法。

3、 技术上的「信息原样输出（Regurgitation）」现象较为罕见，我们正致力于将其完全消除。

4. 《纽约时报》并没有呈现事情的全部面貌。

1. 我们正在与新闻机构合作，共同探索新的合作机会

在我们的技术设计过程中，我们致力于支持新闻机构。我们已经与众多新闻机构以及行业领先组织如新闻 / 媒体联盟进行了会谈，共同探索合作机遇，讨论他们的关切，并提供相应的解决方案。我们的目标是学习、普及知识、倾听反馈，并根据这些反馈做出调整。

我们旨在支持一个健康的新闻生态系统，成为一个值得信赖的合作伙伴，创造互利共赢的机遇。为此，我们已经与多家新闻机构建立了合作关系，以实现以下目标：

部署我们的产品以辅助记者和编辑，帮助他们处理如分析大量公共记录和翻译报道等耗时任务。

通过在额外的历史性、非公开内容上进行训练，增进我们的 AI 模型对世界的了解。

在 ChatGPT 中展示带有归属的实时内容，为新闻出版商提供与读者建立联系的新途径。

我们与美联社、阿克塞尔·施普林格、美国新闻项目和 NYU 的初步合作，展现了我们的合作方法和愿景。

我们的这些早期合作伙伴关系，不仅有助于新闻行业的发展，也展示了我们在技术创新方面的承诺，以及对支持新闻自由和信息传播的坚定立场。

2. 虽然利用公共互联网材料训练 AI 模型属于合理使用，但我们提供退出机制，因为这是负责任的做法

根据长期而广泛接受的先例，利用公开可获得的互联网材料来训练人工智能模型被视为合理使用。我们认为这个原则对创作者公平，对创新者是必需的，同时对美国的竞争力至关重要。

将 AI 模型的训练视为合理使用的原则得到了广泛的支持，包括学术界、图书馆协会、民间社会团体、初创企业、领先的美国公司、创作者、作者等，他们最近向美国版权办公室提交了意见。其他地区和国家，如欧洲联盟、日本、新加坡和以色列也制定了允许在版权内容上训练模型的法律，这对 AI 的创新、发展和投资大有裨益。

尽管如此，法律权利对我们来说并不如做一个良好公民那样重要。我们在 AI 行业中率先提供了一个简单的退出流程，供出版商选择（例如《纽约时报》在 2023 年 8 月选择使用），以防止我们的工具访问他们的网站。

3. 我们正致力于消除「信息原样输出（Regurgitation）」这一罕见的错误

注："Regurgitation" 指的是 AI 模型在生成输出时重复其在训练数据中已经接触过的信息或内容。这通常被视为一种错误或失败，因为理想中的 AI 应该能够产生新颖的、基于理解和推理的回答，而不是简单地复制和重复它在训练过程中所遇到的具体信息。这种现象在模型训练过程中遇到重复或过度代表的数据时更为常见。

我们设计并训练了模型，目的是让它们学习概念，进而能够应用这些概念解决新问题。

记忆问题是学习过程中较为罕见的一个弊端，我们正在努力改进。这个问题在特定内容在训练数据中重复出现时尤为明显，例如同一内容在多个公共网站上出现。因此，我们采取了措施来减少不经意的记忆，并防止模型输出中的内容重复。我们也期望用户能负责任地使用我们的技术；故意引导模型重复输出信息是不恰当的，这违反了我们的使用条款。

就像人类通过广泛学习来解决新问题一样，我们希望我们的 AI 模型能观察到世界各地的信息，包括来自不同语言、文化和行业的知识。由于模型是基于人类知识的大量集合进行学习，任何一个特定领域，比如新闻，都只是训练数据中的一小部分。同样，任何单一的数据来源，如《纽约时报》，对于模型的整体学习目标来说也不是特别关键。

4. 纽约时报并未全面报道真相

我们与纽约时报的对话在 12 月 19 日的最后一次沟通中似乎还在顺利进行。谈判主要围绕 ChatGPT 实时展示新闻内容并标明来源的高价值合作，纽约时报将通过这种新方式与现有及潜在读者建立联系，而我们的用户也能够接触到他们的报道。我们曾向纽约时报明确表示，他们的内容像其他单一来源一样，并没有对我们现有模型的训练产生重大影响，对未来的训练也不会有显著贡献。然而，我们在阅读纽约时报的报道时才得知他们于 12 月 27 日对我们提起诉讼，这让我们感到意外和失望。

在此期间，纽约时报曾提到发现一些内容被重复引用，但他们一直拒绝提供任何具体案例，尽管我们已承诺调查并解决任何相关问题。我们一直严肃对待这一问题，例如在 7 月份，我们得知 ChatGPT 功能可能意外复制实时新闻内容后，我们立即关闭了该功能。

有趣的是，纽约时报所指的重复内容似乎来自多年前的文章，这些文章已在多个第三方 - 网站上广为流传。看来他们故意设置特定的提示语，常包含文章的长篇摘录，以引诱我们的模型进行复述。即便在使用这样的提示语下，我们的模型通常不会如纽约时报所言那样反应，这表明他们可能是指导模型复述或从众多尝试中挑选示例。

不管他们怎么说，这种误用并非典型或被允许的用户行为，也不能代替纽约时报的内容。无论如何，我们正在不断提高系统对防范敌意攻击和复述训练数据的抵抗力，在最新的模型中已经取得了显著进展。

我们认为纽约时报的诉讼毫无依据。尽管如此，我们仍期待与纽约时报建立建设性的合作关系，并尊重其拥有超过 60 年历史的报道，其中包括报道第一个运行中的神经网络和捍卫第一修正案自由的长期传统。

我们期待与新闻机构继续合作，帮助他们利用 AI 的变革潜力，提升制作优质新闻的能力。

来源：openai.com/blog/openai-and-journalism

### 39

方军 2024/01/09

杨立昆：

The speed at which a technology disseminates in the economy is limited by how fast people learn to use it.

技术在经济中传播的速度受到人们学习使用的速度的限制。

twitter.com/ylecun/status/1744561157724119418

### 40

方军 2024/01/09

看到 2022 年 1-3 月写的几篇长到极限的技术指南（tutorial），那是初次写较长的英文文章，现在看几年过去了，有 3 篇 2 万访问量以上，1 篇 1 万访问量以上。还好还好，为某种技术的传播普及做了点微小的贡献。

长到什么程度呢，每篇似乎都有 5000words + 一定数量的代码。

那是对那项技术充满热情的时期，现在我还能写那种代码，但兴趣寥寥了。

### 41

方军 2024/01/10

看人推荐这本书，看似不错，我蛮喜欢图解，其实我都曾想搞本图解。

之前专门写算法的那位写的图解，有点过于简单（太漫画了，有点公众号式的过度简化）

国外那个专门图解 GPT 的系列文章，很赞。这本国内作者写的应该也超不过，但书可能要体系一些。

摘：《GPT 图解大模型是怎样构建的》：写作的特点就是能一环扣一环，每个知识点的讲解都会有铺垫，不会感觉生硬。

[The Illustrated Transformer – Jay Alammar – Visualizing machine learning one concept at a time.](https://jalammar.github.io/illustrated-transformer/)

### 42

方军 2024/01/10

Quroa 创始人刚刚在官方博客宣布，已经从 a16z 那融了 7500 万美金，主要用于旗下 AI 产品 Poe 的发展，不过整个 Quora 的估值为 5 亿美金，比之前最高 18 亿美金的估值大幅下降了。Adam D'Angelo 说，大部分费用可能用于支付给平台上的 Bot 创作者，对于 Bot 创作者来说，这应该是一个好消息，这也意味着 Quora 的未来可能主要放在 Poe 上了，而一种新型创作者经济也就此诞生了。

[超喜欢的一个产品再拿 6000 万美金，a16z 投 Poe 7500 万美金要做 AI 浏览器](https://mp.weixin.qq.com/s/VJWrOO9rDq0f18eNV5p7bg)

### 43

方军 2024/01/10

AI Agent 公司 MultiOn 正式公开亮相。

该公司主要开发从事订票、订餐、购买书籍、预定航班等辅助类工作的 Agent，帮助人类从繁重枯燥的日常工作中解放出来。该公司希望打造类似于 JARVIS 的实体或《HER》中的女友。

公司创始人为 Omar Shaya、Div Garg，两人相识于斯坦福大学，Div 在斯坦福从事 LLMs 和强化学习的研究，后来在苹果、谷歌和英伟达等公司工作；Omar 则在微软和 Meta 公司先后领导团队开发消费类人工智能产品。

该公司已拿到来自 General Catalyst 、 亚马逊 Alexa 基金、 maven ventures 、 三星 Next 以及 OpenAI 员工，GoogleDeepMind 早期支持者等的投资。

\#新产品动态#

### 44

方军 2024/01/11

OpenAI 在推特上更是霸气地表示，目前用户已创建超过 300 万个 GPTs，现在你可以找到最适合你的专属「ChatGPT」。

[重磅！OpenAI 官宣上线 GPT Store！超 300 万个 GPTs 大爆发](https://mp.weixin.qq.com/s/Q9AZHEX6GeloJbMr1-GUXw)

### 45

方军 2024/01/11

《GPTs TOP100 深度体验分析报告》作者椒盐玉兔，用 PPT 的形式很全面总结了 Top100 的 GPTs，他通过算法，筛选出了目前访问量（Chats）超过 1000 的 GPTS，共 458 个，其中 Top 100 为头部 GPTs，门槛是 5.2k Chats；Top 20 为顶级 GPTS，门槛是 20.2k Chats。

2『已下载原文件「20240111GPTs Top100 深度体验分析报告」收录入「2024011大语言模型专题资料」。（2024-01-14）』

### 46

方军 2024/01/11

A16z 投资 Quora 和 Poe 的文章值得一看，节选一部分：

「迄今为止，普通消费者接触 AI 的机会通常仅限于玩玩 ChatGPT 或现有应用程序和工具中的新人工智能生成功能。

同样让我们这些技术人员感到兴奋的是，模型的激增、GPU 效率的提高、开源以及对更小、更专业的模型的微调，这些对于普通消费者来说都是令人生畏的。

我们相信，不会有一种模型能统治所有领域，我们将需要许多模型来满足不同的模式和使用情况。但目前，为了推动 AI 原生工具的采用，存在太多的模型和太多不同的用户界面。要想让人工智能跨越鸿沟，惠及全球 50 多亿互联网用户，它就必须更直观、更易用。

因此，我们非常高兴地宣布，我们已经投资了 Poe 的创造者 Quora。其他人工智能公司专注于构建最佳模型，而 Poe 则肩负着双重使命：1）成为消费者在同一工作流中与各种人工智能产品互动的最佳方式；2）成为开发者构建多模态人工智能产品并触达大众的最简单方式，无论是通过激活现有模型创建 bot 还是自行训练模型。」

「或许更具吸引力的是，就像 Roblox 为游戏所做的那样，Poe 正在构建工具，让创作者修改现有模型，释放那些想要构建人工智能但没有资源的人的创造力。Roblox 创建了游戏引擎，提供分发、信任和安全、基础设施以及创作者赚钱的机会。结果产生了强大的网络效应 —— 创作者越多，用户就越多地来玩这些创作。用户越多，就吸引了更多的创作者。

Poe 的创作者工具正在早期开发阶段，但提供了类似于 Roblox 的好处，包括多平台基础设施、发现功能以及 bot 创作者能够产生收入的能力。目前，Poe 显示出递增的规模回报迹象。目前，Poe 是最大的 5 个人工智能相关生成工具之一，创作者已在 Poe 平台上构建了 100 万个以上的 bots。凭借这一轮最新的融资，Quora 计划进一步帮助 AI 创作者和开发者实现其创作的货币化。」

[Investing in Quora and Poe | Andreessen Horowitz](https://a16z.com/announcement/investing-in-quora-and-poe/)

### 47

方军 2024/01/11

部分赞同：很多人可能对 AI 知识库有一个误解，以为只要把手头现有的各种文档扔给它就叫知识库了，去年我们老板也是这么认为的，觉得那不是很快嘛，分分秒秒就能搞定，然后我和技术部的负责人只好面面相觑。

知识库可以简单地理解为在底层模型的原有基础上，多了一部额外的字典，本来模型只认识 3500 常用字，有了字典后，你可以告诉它在字典里面查找生僻字。

这和模型训练微调的区别在于训练等于让模型从底层也学会了生僻字，模型不再需要这部额外的字典就能查询生僻字。

而知识库只是外挂的手段，模型需要根据你的指令去字典里面查，脱离知识库这部字典，底层模型依然没办法告诉你生僻字。

但是知识库和模型训练又有一点相同的地方，就是你喂给它的数据集是需要编排，需要特定格式的，不是随随便便一个文档就行的。训练微调就不展开说了，这里简单说一下知识库。

知识库一般使用三种方式来建立和处理文档：

一、按字数分段；

二、模型自动按语义分段；

三、QA 问答对。

1、按字数分段，这是最简单也是最粗暴的方式，目前的很多能传文档的框架都是根据你设定的分段字数粗暴地把文档分割成片段。这种分段不会考虑语句、段落、主体的完整性，因此反馈的答案一定是不符合你要求的，数据的召回率正确度非常低，因此这种方式用得很少。

2、模型自动分段，模型根据你的文档，基于本身的能力为你分段，那么这个模型就需要很强，那种 7B、13B 显然不是很合适，起码也要 70B 这种级别以上的，因此我个人觉得不是 GPT4 这个层次的模型，那么也最好别用，否则准确率也是堪忧的。

3、QA 问答对，前面两种都不推荐，那么显然就只剩下最后一种了，QA 问答对是准确率最高的文档编排方式，一问一答，或者多问一答。比如：

Q：中国有多少个省份？

A：中国共有 34 个省级行政区域，包括 23 个省，5 个自治区，4 个直辖市，以及香港，澳门 2 个特别行政区。

同一个答案，肯定不同的人有不同的问法，所以有时候做问答对的时候需要有几个不同的问法，比如：

中国有多少个省份？

中国的省份具体有几个？

中国的行政规划有几个省市？

.....

类似上面这样的，以问答方式编排的文档，是准确率最高的格式，同样也是做知识库，乃至微调模型最好的格式。这么好的方式当然也会带来很显著的问题，就是时间和人工。

客户提供的文档，肯定不会是问答对的格式，因此你需要安排专门的人来把文档做成问答对，这个人啊，需要比较强的语言文字能力，善于归纳总结，提炼问题。这种岗位你说很难吧，干的其实是苦力活，你说简单吧，又需要很好的文字功底。我大概想了想估计只有教师职业是最适合干这个的了，能根据内容想出问题，编排答案。

能把文档做成问答对的人，能力毋庸置疑，然后就是时间成本，从长篇大论中拆分出一个小小的段落，再加上以提问者的角度编排问题，可想而知这种时间和精力的消耗并没有多少人愿意干（除非给钱）。

所以这可不是一些甲方爸爸想的那么简单，丢一篇文档进去 AI 自己就能搞好的。如果是一些通用领域倒还好说，毕竟网络上已经有了不少相关的数据集，拿来就能用，但是很多专业领域，甚至某一个领域中的细分部门要建立自己的知识库，可能只能在内部找人来做这件事情。

各位如果觉得自己的知识库好像效果很一般，那一定是数据集的问题，自己玩玩当然也没必要特地去搞。但如果你有这个业务需求，那就需要准备一个这样的岗位来处理这种细分领域的数据集。

根据我目前接触到的各种项目来看，这块的市场需求非常大，知识库或者专有模型在企业中存在很大的缺口，算力不是桎梏，做数据集的人工和时间才是。

王晓峰：是不是 GPT5 能解决这个问题？

2024-01-12 21:51

方军回复王晓峰：不能

2024-01-12 22:02

### 48

方军 2024/01/12

摘：奥特曼在 YC W24 启动会上的演讲要点：

- 奥特曼暗示我们可能已经非常接近实现通用人工智能（AGI）

- 他建议应该以通用人工智能的实现为前提进行创业和技术开发。（不要再瞎折腾）

- GPT-5 可能会相对于 GPT-4 有一个指数级的跳跃，尽管 GPT-4 已经领先近两年，至今无人超越。

- 这个进展将会给初创企业和现有公司带来了许多问题和挑战。（AGI 将覆盖一大批创业者）

- 建议使用最先进的模型（State of the Art, SOTA），而不是花费太多时间进行微调和优化。（徒劳无功）

- 最正确的做法是设想一个「上帝般的」模型正在运作，然后基于这种设想来构建最好的产品。（要及其有远见）

- @OpenAI API 将继续变得更快、更可靠、更便宜。然而，性能和成本之间始终存在平衡。例如，尽管电池技术已显着改进，但 iPhone 仍将保持 1-1.5 天的电池寿命以优化性能。

- 不建议建立产品业务主要致力于解决当前 GPT4 的限制的内容。因为大多数限制将在 GPT-5 中部分 / 全部修复。（你会被覆盖）

- 初创公司更需要情境优化，而不是行为优化。通过 RAG 等提供更多信息可能比微调更有益。

摘：鉴于 Sam 在 YC 上提到了 GPT-5 和 AGI，这个建议也比较靠谱：正确的策略或许应该是采用最新的模型，而不是过多投入在微调和提前优化上。

全文翻译：

在 Y Combinator 的启动会议上，Sam Altman 强调我们已经非常接近通用人工智能 (AGI)，并建议我们在未来的技术开发中应考虑到这一点。

GPT-5 有望在技术上实现对 GPT-4 的巨大飞跃（他们在将近两年前就已完成了 GPT-4 的开发，而到目前为止还没有任何产品能超越它）。

这种情况给当下的初创企业和大公司带来了众多挑战。

许多人都以为模型只会缓慢进步，但实际情况似乎并非如此。

正确的策略或许应该是采用最新的模型，而不是过多投入在微调和提前优化上。

更好的做法是，想象一个拥有极高智能的模型会如何运作，并以此为蓝本，构建尽可能优秀的产品。

这正是为什么我们在 Cognosys 如此努力地开发最佳产品和用户体验，我们选择使用智能体而不是从零开始训练模型或进行不必要的早期优化。

对我们来说，模型越先进，我们的产品就能越出色（可以想象，性能提升可能达到 10 到 100 倍）。

### 49

方军 2024/01/15

有意思，这个互动讨论最反映当前 AI 的实际情况。

@宝玉 xp: 来自 Paul Graham：

最近我从一家颇有规模的科技公司的 CEO 那里获知了一个有趣的信息。一般来说，28 岁的程序员要比 22 岁的程序员更高效，主要是因为他们拥有更丰富的经验。但有趣的是，现在的 22 岁年轻人因为更加熟练地运用 AI 技术，他们的编程能力已经媲美 28 岁的程序员了。

这对于那些年轻的创业者来说无疑是个利好消息。他们最初往往因为缺乏编程经验而受到限制，但现在，他们可以将 22 岁时的充沛活力与 28 岁时的高效生产力结合起来。

@信号时代_road: 这是翻译错误。不是 22 岁比 28 岁更会使用 AI，而是心理上更能自在地接受直接使用 AI 辅助，因为他们没有经验嘛。至于有经验的程序员，总觉得 AI 写出来的虽然有时候能到写对，但其实质量和水平比起老鸟自己撸出来的代码差了好几个档次，至少目前来说。

请查 more at ease doing 的含义

（注意，宝玉的翻译就是用 AI 多，但他也略微看过翻译内容）

简言之，要把 28 岁和 22 岁混合起来

补充：目前 AI 代码能力，只要模块拆得够细，比有经验的老手快。当然，老手厉害的本来就不是快，而是拆模块。

方军：我个人的体会是，直接信 AI 是不行的。

比如翻译，用它快速筛选特别好，双语对照看，但直接信容易掉沟里。

相对而言，一个较好的进阶用法是请 AI 帮忙解释。比如上面这个词组，我们可以请 AI 帮我们解释。

具体来说，英语还是要学的，并且我们多了很厉害的新工具，随身的老师。

2024-01-15 12:03

方军：这个词，的确如果不是有行家提醒，我们就会忽略过去不思考。当然，如果看英文没问题的，这这个词组的隐含含义，有英文基础的人猜都能猜到。

2024-01-15 12:08

方军：懂英文的人，不会把那个词理解为「更加熟练」

2024-01-15 12:09

### 50

方军 2024/01/15

OpenAI GPT 商店刚上线三天，GPTs「AI 女友」就已泛滥

OpenAI 上线的「GPT 商店」成为 AI 界 App Store，提供各类付费聊天机器人。然而，该平台被「AI 虚拟女友」机器人淹没，触犯了 OpenAI 的使用条款。这暴露出内容审核困境，以及人工智能伴侣可能引发的社会问题。

[GPT 商店上线！引爆 300 万个 GPTs！但刷榜、山寨也来了！](https://mp.weixin.qq.com/s/oyEGdkpZBNTyVV-VzW7eKA?poc_token=HCodpWWjB0m_nRq4hafTgrqOe51rCsHsPOQIlN6a)

### 51

方军 2024/01/15

我在想，这本书，如果让 AI 读行不行？

我觉得可能永远不行。

之前讨论知识付费时，我最重要的观点是：

对于读者而言，书是半成品，我们花时间精力读了，它对我们才变成成品。

花多少时间精力、有多少技巧，决定我们能从一本书中得到的收获。

这也是为什么我其实看不上讲书，讲书是假象。

那么退一步，我编写的这个电子小书，读了会不会帮你更方便地读书呢？我觉得也不会，受益的始终是我，而非别人。（从读书阶段看，这个电子小书背后不是高阶读书，但至少是中阶，因为有了纠正原中文版翻译以更准确理解这个步骤。）

那么，就没有捷径了吗？

有，有些书可以不读，因为如果找到合适的人请教，有些书是可以被有效的请教取代的。

但是，很明显，如果你有能力读书，那么可以更好地请教，向更牛的人请教，得到更深的启发。

AI 的用途是为这个读书过程提供辅助。

### 52

方军 2024/01/15

虽然前几年我们对全数字化的元宇宙、这一两年对 AI 写文章和语音甚至视频有很多设想和探索，但我有个爆论，别以为假人能骗过用户。

互联网有个真实的段子，某论坛早期很多假美女用户，后来人跟创始人说，你们那个里面全是人妖。

怎么突然这个感慨呢，我坐车听旁边人播 AI 配音视频听吐了。自己看的时候没那么明显，但当没有用注意力、只是旁听时，假 AI 声音让人极其烦躁。

另外，假文章也是非常明显的，目前还没法逻辑说明，但其实我们所有人分辨假 AI 文章的能力都特别强。

目前真与假的判断，是任何普通人能随便看出来，但专家却总结不出 1234 的阶段。

### 53

方军 2024/01/15

AI 翻译就这么个水平，我们作为 AI 专业人士，不要被外界的喧嚣迷惑。

摘：国内外新闻用机器翻译有很多陷阱要留个心眼不可尽信。比如英国科幻迷 John 在用 Google Translation 看超侠的成都世界科幻大会见闻录时就遇到了下面这个极端例子离了大谱的错误翻译。据说 DeepL 也不知道撸串的意思。

### 54

方军 2024/01/16



### 55

方军 2024/01/16




### 56

方军 2024/01/16


