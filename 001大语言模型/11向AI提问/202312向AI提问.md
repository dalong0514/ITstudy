### 01

方军 2023/12/01

试验了 heygen，做了较长的内容。

一个感受是，对于程序性的内容，还行吧，不需要感情，而且准确。

同时，可以方便地多语言。

但是，它实在一眼假、没感情。

要用起来，还是得找到合适的场景。首先能想到的是，绝对不适合社交媒体，因为它需要真实。

AI 图片、视频，我觉得都有很长的路要走，并且还是要人在循环中，不能试图直接生成。其实，最牛的 AI 生成，我觉得也没我拿普通的 X100V 出门拍出来的好啊。

### 02

方军 2023/12/01

哈哈哈，AI 可以好好把前面的词学习下。

某老师说 AI 电商，这么虚的词的确厉害，有无限的解读空间，但是，有啥用呢？对商家能卖货不？对我们消费者能便宜不？

最近的确对云端☁️的话免疫，飘啊飘。

友：人家名字就是☁️

嘿，不光是他了，好多大佬甚至周围普通人都这样，大佬就算了，人家本来云里，必须雾里。

普通人凑什么热闹讲虚虚的词。

说个词：认知。

你干事干得不好。认知低！

你倒是说说，你说的认知究竟是啥？

我们跟着外界热词懊恼：我认知低，要发奋提高。这不行啊。

说点具体的行不行。

说认知是棒喝，也有用。但是，真面对，我们一点一点看具体问题。

还有一个，比方说我浅浅地说芒格，我觉得他其实讲了和展示了至少这么一种方法论：学习多种思维框架。

这是具体的。但是，如果你今天看他一种表达，明天又讲了什么，那些其实不过是一位智者即时的反应，我把这种也叫虚虚的词。

### 03

方军 2023/12/01

字节跳动海外也做了一款基于大模型的 App ChitChop，可以说是一个私人 AI 助理，包括 AI 创作、AI 绘画、娱乐、AI 学习、工作、生活等 6 大使用场景。在海外 Google Play 和 App Store，均可下载 ChitChop，网页版也已经上线。根据应用商店上显示，ChitChop 由 POLIGON 开发和运营，而字节跳动海外的社交产品 Helo、日本漫画 App 「FizzoToon」也由同一家公司运营。

[字节跳动出海生成式 AI 产品 ChitChop 上线，含创作、绘画、学习等 6 大场景](https://mp.weixin.qq.com/s/hyGDXUipyiTB9q4f0QQ6-Q)

### 04

方军 2023/12/01

小提醒，现在的订阅尤其 AI 来了之后的功能订阅尤其多

1）尽量别冲动，月度订阅，而非年度订阅。20% 的年度优惠不值得，你不知道是否会长期用，并且可能很快有新的出来。

2）如果只是尝试性订阅，记得取消订阅，否则下个月继续扣钱。几个一加蛮不少的，并且通常无法退款。

3）一般高级版会显得特别优惠、功能强大，但最好从最低阶订阅起，可以慢慢买点数。比如，midjourney 我一直只订最低档，然后需要时一个月可能买大几十美元点数（当然这个做法是从高级降下来的）。

4）用好免费试用期，有不少是提供一点点免费试用的，搞明白自己是不是真要。用这个方法试了不少，最后选想要的。

5）报告类的订阅，尤其要谨慎，曾定了一个报告服务 7000 美元，前一个半年特别好，后一个半年就太坑了，内容差到无法忍受。所以，第二年不会订了。

6）有时候单次服务比订阅更便宜，虽然单次看起来贵。就跟杂志与书一样吧，杂志一年不贵啊（现在也蛮贵的，一本 20-30，一年 360-500。一本书 70-100，其实多数的需要的时候单本买蛮好。

7）搞明白订阅选项。昨天就尴尬了，买 179 美元每月订阅买成 119 美元每月订阅，还无法变更升级，一个核心功能没有，导致手工折腾很久还有瑕疵。（12 个小时后才有有效客服回应，但已经绕着法子搞完了）

另外，某些软件、服务的年度订阅其实也蛮贵的，通常 50-100 美元，但真是好几个都订六七年了。

### 05

方军 2023/12/01

这么说吧，数字人纯属扯淡，但满足人们扯淡的心（想起来当时某个企业不做数字人方向，后悔的时候埋怨我，哎，现在我还是说它是扯淡）

[「数字人」已经开启了收割模式（作者：灰鸽）](https://mp.weixin.qq.com/s/8gQCqka5bGjoSUJoo4BauQ)

### 06

方军 2023/12/01

蛮有意思的类比，但还可以接着改进：

LLM 就像是一个考生，

训练数据是教材，

context 是短时记忆力，

prompt 是解题技巧，

fine-tune 是补充教材和辅导书，

RAG 是开卷考试，

function call 是允许带计算器。

---

prompt 是解题技巧，一般般。

function call 是带计算器，好像也一般般。

fine-tune 是上补习班。

prompt 是考试题。

### 07

方军 2023/12/01

提示工程已死？

不，这是最先进的技术（SoTA）。

GPT-4 在所有九个 MultiMedQA 基准测试中击败了未经微调的 Med-PaLM 2，这得益于良好的提示（动态 k-shot + 自动生成的 CoT + 选择混洗的集合）

原推文：GPT-4 with good prompts (dynamic k-shot + self-generated CoT + choice-shuffled ensembles) beats Med-PaLM 2 on all nine of the MultiMedQA benchmarks it was fine-tuned for, without fine-tuning

twitter.com/goodside/status/1730410630673244654

Eric Horvitz

微软首席科学官，总统科学技术顾问委员会，前 AAAI 主席。

我们已经发布了一项关于提示在不需要额外微调或专家策划的情况下，释放 GPT-4 在医学基准测试中的专业知识的研究。

结果摘要：twitter.com/erichorvitz/status/1729854235443884385

论文：

[[2311.16452] Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine](https://arxiv.org/abs/2311.16452)

### 08

方军 2023/12/01

一个面向全球教师的 Generative AI 课程：

Generative AI for Educators

为联合国教科文组织（UNESCO）创作的。

效果还不错，第一个 Section (共五个，一共 60 分钟)。

www.youtube.com/watch?v=0sNZddVDb7w

我拿它当成一次 AI 产品的试用体验。

All you need to know about ChatGPT and Generative AI as an educator or as a learner.

Section 1: Course Introduction

Length: 10 mins

- GenAI's impact on knowledge work

- GenAI's impact on educators & education

- What're AI and Generative AI?

- Creating new content

- 6 scenarios of GenAI: text

- 6 scenarios of GenAI: media

- ChatGPT's wisdom on education

- What you will learn?

Disclaimer: Audio and avatar is generated using GenAI models and tools.

### 09

方军 2023/12/01

AI 时代的视频剪辑产品淘汰赛

Veed.io 在早期是完全 bootstrap 发展，在达成 10 万美元 ARR 之后仅仅用了 9 个月的时间就将收入扩展到了 200 万美元 ARR；

Captions 从产品面向大众推出的第一天就必须付费才能使用，已经拥有超过 300 万创作者用户，DAU 超 10 万；

CapCut 早期以免费版著称，但是很快为 Pro 付费设置了许多关键的功能点，根据 Data.ai 在 9 月份的报道，其 App 在 iOS 和 Google Play 上的消费者支出已经超过 1 亿美元。

[Filming Less：AI 时代的视频剪辑产品淘汰赛](https://mp.weixin.qq.com/s/QgR76ARy0WpgPUIAzwdTjg)

01 新一代视频剪辑产品的兴起

02 值得关注的 3 家成长期标的

03 现阶段的竞争胜负手

04 Filming Less 的挑战

### 10

方军 2023/12/01

LLM 的能力领域和领域内的最佳开源 LLM。

白色方框表示领域，蓝色方框代表特定数据集，橙色方框表示开源 LLM。

[[2311.16989] ChatGPT's One-year Anniversary: Are Open-Source Large Language Models Catching up?](https://arxiv.org/abs/2311.16989)

### 11

方军 2023/12/02

IBM 的 AI 工作方式报告还不错

IBM-基于 AI 和自动化的增强型工作新时代-通过人机偕行提高绩效-32页

2『已放入资料库「2023011GPT专题资料」。（2023-12-02）』

### 12

方军 2023/12/02

摘：一年前，Stability AI 斩获 1.01 亿美元融资，成为 AI 图像视频领域的超级独角兽，Coatue、Lightspeed Venture 等机构都成为它的投资者。

最近，彭博社的一则新闻让它再次站上风口浪尖。据彭博社报道，Stability AI 管理层面临财务困境，投资者正在向他们施压，公司可能会「卖身」。

消息称，Stability 已与多家公司进行初步接触，Cohere 和 Jasper 都成为潜在的买家。

[又一场 AI“宫斗”要上演？盈利困难、投资人开撕 CEO，Stable Diffusion 背后公司被曝正寻求收购](https://mp.weixin.qq.com/s/fkDJSmOm8dZDXwnCTP1oXQ)

[Pika 的 AI 视频火了！Stability AI 要卖了？哪种AI项目有未来？｜前哨](https://mp.weixin.qq.com/s/4MIGCRUbMAOKbAZyhyzPhA)

### 13

方军 2023/12/02

摘：5. 关于著作权的认定：「原告是直接根据需要对涉案人工智能模型进行相关设置，并最终选定涉案图片的人，涉案图片是基于原告的智力投入直接产生，且体现出了原告的个性化表达，故原告是涉案图片的作者，享有涉案图片的著作权。」

[AI 生成图片著作权侵权第一案判决书](https://mp.weixin.qq.com/s/Wu3-GuFvMJvJKJobqqq7vQ)

### 14

方军 2023/12/02

pika 这个名字起得真好

picasso

如果像 notion 一样用.so 域名

pika.so

### 15

方军 2023/12/02

《世界正逐渐分化为两种人：一种是通过使用 ChatGPT 而变得更优秀、更智慧、更富有的人，另一种则是其他所有人》

网友点评：这东西垂直领域还是不行，我尝试用它完成我的学术垃圾，它干的很好。

但是恰恰是和 BCG 同行的咨询领域，它在我们所在的细分行业表现极其糟糕，并且联网搜寻出的信息都太陈旧，我们组已经全员弃用它了，改用 Factset，Wind 和 Bloomberg。

我的点评：由此可见，社交媒体的文章往往吸引眼球的功能大于实际。当然有一点点价值，但我们需要仔细甄别。媒体比我们更需要眼球，我的这个想法是从新智元持续的夸张表演中感受到的，在我这里，它的信息其实蛮快的，但误导性极大，因此我屏蔽了、采用替代来源。

原文：businessinsider.com/using-ai-like-chatgpt-will-make-you-more-successful-2023-12

作者：Beatrice Nolan，Beatrice Nolan is a reporter on the business news team in the UK.

文章：自从 ChatGPT 面世以来，才短短一年，世界就已经分为两种人：那些利用它领先一步的人，和那些没有使用它的人。

根据估计，这款机器人在一年内吸引了 17 亿用户。在其发布仅两个月，学生们就开始利用这个工具节省时间，甚至用来写作文作弊。

虽然当时有人对此表示担忧，但实际上孩子们只是最早尝试的群体。

越来越多的证据表明，如 ChatGPT 等人工智能工具能够让你在工作中变得更高效、更能干。深思熟虑地在工作中应用 AI，可以快速为你带来晋升或更多机会。

哈佛商学院近期的一项研究分析了当 OpenAI 的 GPT-4 提供给波士顿咨询集团 (BCG) 的 758 名员工时的情况。

研究者发现，使用 GPT-4 进行咨询任务的 BCG 员工比那些没有工具的员工效率明显更高。

得到 AI 协助的咨询师们完成任务的速度提高了 25%，任务量增加了 12%，而且产出的工作质量高出了 40%。但是，这只适用于适合 AI 的任务（并非所有任务都适合 AI）。

AI 带来最大效能提升的是中等水平的员工。

本文的核心观点是，AI 能成为一种免费的、增强工作绩效的工具，这对各种白领、办公室工作者来说尤其如此，而且他们的技术水平高低并不影响这一点。特别值得一提的是，如果公司中其他人还没开始这样利用 AI，那么其影响将更加显著。

01 当前利用 AI 简化工作的最佳方式

有越来越多的迹象显示，AI 在处理行政管理和重复劳动方面表现出色。

据 Business Insider 报道，他们采访了几位使用 ChatGPT 的专业人士，包括一位前招聘人员，他利用 ChatGPT 编制公司和员工名单；一位房地产经纪人，他用它来撰写房源信息；还有一位营销人员，他用它回答客户问题。

他们都表示，把这些耗时但小型的工作交给 AI 工具处理，可以帮助他们节省大量时间。

ChatGPT 能够简化和概述书籍、文章甚至整个研究领域的内容。它能够提供接近人类的反应，帮助你快速撰写电子邮件、文档或反馈。

因此，如果不利用 AI 完成这些任务，那么使用 AI 的同事可能会突然变得更高效、更有价值。

02 开发者称 AI 编程辅助工具使他们的工作效率提高了 55%

在白领阶层普遍还在摸索 AI 如何影响或改变他们的职业生涯时，技术界人士已经走在了前沿。

像 GitHub 的 AI Copilot 这样的工具，已经被证实能显著提升程序员的工作效率。

根据该公司在 2022 年的一项分析，使用 AI Copilot 工具的开发者比那些未使用的开发者快了 55%。

如今，微软已经将基于 GPT-4 的 Copilot 集成到 Office360 中，使员工可以将 AI 集成到电子邮件、Teams 聊天和会议中。这个工具能够处理许多繁杂的任务，比如撰写电子邮件和文档，或者是总结漫长的会议和 Teams 对话，而且它的指令需求出奇地少。

谷歌的 Duet 同样可以为使用不同系统的工作场所提供大量相似的服务。Zoom 和 Salesforce 也推出了他们的 AI 生产力工具。

各种新推出的 AI 工具的广泛可用性意味着现在几乎每个人都有机会使用它们。

企业软件公司 Appian 的创始人兼 CEO Matt Calkins 在接受商业内幕采访时表示，他认为 AI 最大的影响在于提升工作效率。

「客户服务的质量将提升，我们的工作效率将得到提高，同时，当企业数据在决策或行动时刻得以应用时，其准确性和知识水平也将得到显著提升，」他如是说。

「我认为这正是我们应该依赖 AI 去实现的。虽然 AI 不可能创作出莎士比亚级的作品，但它确实能显著提高公司的生产力。因此，这就是我们应当着重关注的方向。」

03 AI 在职场中的应用需谨慎

利用 AI 完成工作，其中不乏需要注意的地方。

这项技术有时会幻想或捏造事实，这已经导致一些员工陷入困境。有些公司也因为版权或数据安全的担忧，对 AI 工具设立了特定的规则。

如果你打算使用 ChatGPT 撰写文档，切记不要泄露公司机密信息，并对其输出内容进行核查。通常，最好把这项技术当作一名实习生，对任何重要或可能危及职业生涯的信息进行双重检查。

从长远来看，未来的情况也值得关注。

随着每个人都在加快 AI 的应用，特别是在行政工作领域，可供分配的工作量可能会减少。自由职业者已经表示他们因为 ChatGPT 这类工具而失去了工作机会。

如果今年展示了什么，那就是 AI 不会消失。想要保持竞争力的工作者可能需要找到与 AI 合作的新方式。

来源：twitter.com/dotey/status/1730854548527259924

### 16

方军 2023/12/03

对《My experience trying to write original, full-length human-sounding articles using Claude AI》的文章翻译和精要提炼

[AI 写作不如意？万字长文深度剖析背后原因](https://mp.weixin.qq.com/s/fkrI7Clk9GXrPvKZE-Ppjw)

[My experience trying to write original, full-length human-sounding articles using Claude AI | I'd Rather Be Writing Blog and API doc course](https://idratherbewriting.com/blog/writing-full-length-articles-with-claude-ai)

### 17

方军 2023/12/03

017 别 TM 读 ChatGPT 编写的摘要

标题用来一个较为强烈的词语，真情实感。

这几天有个体会，读一本书，真读下来发现，万维钢写得那么好的推荐序，其实对比原文都是降级很多的。

他对内容理解得很好，也可作为我们读这本书的诱惑，以及最开始的阶梯。

但是，当我们开始读了之后，要干的第一件事就是，把这个阶梯扔掉。

而再说 ChatGPT 或任何 AI 生成的摘要，就一个具体问题而言，它们又是万维钢序言的大幅度降级。它们能起的作用，不过是在浏览时告诉我们，它的大概能可能是什么。

（同样地，所有的音频图书解读，都可以说是大幅度的降级。名家做的，其实也一般。有很多是很差的人做的。还有网络名人做的是故意大幅降级迎合。）

所以，AI 来了之后，它给阅读带来的变化应该是采用杠铃策略。早就读不过来了，AI 让我们读更多也是假象。杠铃策略是，读真正好的。

别信各种形式生成的摘要，不管是人类智能，还是人工智能。它们是检索工具，不是阅读替代。

即便是万维钢那么好的也不行。补充，为什么说万维钢的很好，第一，他真心认真读了，你知道很多解读书的人其实没（认真）读吗？你知道 AI 其实也没认真「读」吗？第二，他没迎合，读了什么、想了什么，就大体上写什么。第三，他善于把深奥的知识解释出来。

相关：https://t.zsxq.com/14GkcxUXg

AI 使用感悟#

### 18

方军 2023/12/03

马斯克：将在未来一周左右向 X 平台的 Premium + 用户开放 Grok 的访问权限】据财联社 12 月 3 日报道，马斯克 12 月 3 日在社交平台 X 上发文称，将在未来一周左右向 X 平台的 Premium + 用户开放 Grok 的访问权限，优先顺序取决于订阅的时间。

据悉，Grok 可以「实时访问」该平台上的所有信息，还可以回答大多数其他 AI 系统拒绝回答的尖锐问题，甚至就如何提问给出建议。

---

这个系统有两个模式：

regular mode

fun mode

fun mode 看着蛮有意思的，看马斯克播客访谈时他们还专门说起这个话题。

新产品动态 #

### 19

方军 2023/12/03

《慢燃 AI：当增强而非自动化是真正的威胁》

这篇文章的观点还是蛮有启发的

Choudary 写的，知名的平台经济研究者

他的一个核心观点是，AI 给工作带来的增强，实际上让工作商品化，最后的后果就是给一个人工作带来的危险。

这个逻辑说得通的。

---

链锯的真正长期影响是将伐木作为一项工作商品化。

由于任何人现在都可以成为一个伐木工人，这个工作的技能溢价能力已经被侵蚀。随着潜在伐木工人市场的扩大，工资稳定下来，高技能的伐木工人失去了收取溢价的能力。是的，短期内伐木的增加也带动了下游的需求增加，但这些影响很快就稳定下来，伐木工作变成了一个商品化的工作。

当技术增强熟练工作并使历史上技能较低的工人能够与历史上技能较高的工人表现相当时，这种增强使工人更具替代性，并最终使工作变得普通化。

（由 GPT 自动翻译，未编辑）

---

附件为中英文对照，同样未编辑。

文章主要是阐述他在另一份报告中的观点，见所附文件 2。

看文后预告，他应该还会写两个部分：

这是关于 Gen AI 时代工作未来的三部分评论的第一部分。

第二部分 - Uber 司机时代的 AI - 着眼于 Gen AI 对绝大多数知识工作者的影响。

第三部分 - Taylor Swift 时代的 Gen AI - 着眼于 Gen AI 对少数创作者的影响，他们将从中获益最多。

会持续跟踪一下这几篇。

### 20

方军 2023/12/03

爱思唯尔还把生成式 AI 技术加入到他们的海量数据中，推出了 Scopus AI、ClinicalKey AI，以及支持审稿人推荐、文章诚信核查等学术出版环节的人工智能工具。

[这家被称为技术公司的出版巨头，如何让 AI 成为可信赖的工具？](https://mp.weixin.qq.com/s/fxCcuJib8Qe931xuYNmxjg)

### 21

方军 2023/12/04

AI 扩展的思维

读了《思考如何超越思考》（The Extended Mind）这本书，按我的理解，作为科学作家的作者安妮·墨菲·保罗将三类认知研究串起来、并借用认知哲学家安迪·克拉克的观点形成一个「扩展思维」（extended mind）这个新观点。

重新表述她的基本观点：思考不只发生在大脑中，而是也发生在大脑的外部，具体而言就是三种认知：

具身认知（embodied coginition）

情境认知（situated cogintion）

分布式认知（distributed coginition）

关于第三个，第三个我觉得这个通俗化一下用「群体认知」可能更好，但心理学领域估计群体代表另外的意思，所以有了这个词。

这本书看得过瘾又不过瘾，不过瘾是因为，虽然它强调要不只聚焦于我们的大脑本身，但是可能出于心理学 / 认知科学研究的约束，又还是重点在讨论三种外部认知资源如何影响我们的大脑思考，因而并未真的超越大脑。

她梳理的这个框架蛮有意思，我就用它来从实用角度出发，绘制一个「数字时代的扩展思维」出来。（我这里就不受限于认知科学 / 心理学的专业词汇了，实用出发怎么容易懂怎么说。）

---

A. 输入 - 处理 - 输出

我们的大脑是个处理机制，它接受输入，进行处理，形成输出。

扩展思维的看法是，我们的大脑还有三个外部可用的资源：具身认知、情境认知、群体认知。

我们再外扩一下的看法是：

1、三个可用资源也有数字化的部分。

2、同时，我们的外部工具也数字化了，远不是书纸笔那么简单。

---

B. 数字化的三种外部认知资源

如果将手机、电脑、网络也看成我们的身体一部分，那么，我们可以具身认知、情境认知、群体认知拓展过去。

手机其实已经是我们的器官了，这是为什么我们要花那么大力气去抗拒它，定时关掉它。

屏幕的情境给我们带来的冲击比环境还大，屏幕造成沉浸感，实际超过实体环境。

群体认知则更更不用多说了，我们随时可以借用社交网络的智慧，只要愿意，我们都有机会身处最牛的群体之中。

---

C. 外部工具，主要是数字化的

安妮在书中引述克拉克 2019 年的一个研究，他们研究的主题是：「使用外部物体、道具和辅助工具解决复杂问题的能力」。

我们现在外部的工具可真是太强了。

笔记工具。以我个人而言，除了一本年历和工作时手边乱涂乱画的 A4 纸之外，所有的笔记都是电子化的。（另，作为星主，我把星球更多地视为一种笔记工具。）

输出工具。相信没人用手写了吧，都是电脑。当然，对那些习惯口头表达的人，他们也会直播、网络会议、录视频等等。

AI。这一年来最大的变化无疑是 AI，AI 成为外部工具中最大的变量。外部 AI 模型很强大，但这儿我们的问题是，我们自己能将多少纳入内部来使用？

一点补充讨论：Indigo 之前也画了一个外脑，他也是实用出发、并强调 AI。但我不是很赞同的一点是，他认为笔记很重要，因而引用了第二大脑笔记的 PARA 笔记方法，他最近还推了一个笔记产品。我个人的体会是，虽然记录很多笔记，我其实真心在输出时不用笔记，我会持续修改笔记以改进想法，但输出时不查看与重用笔记。

### 22

方军 2023/12/04

这个网友蛮会偷懒的：

一个小小的功能：把一个包含表单的 PDF 文档，导出成 PNG 图片，然后传给 GPT-4V 的 API，然后让 GPT 生成一段 Google 表单对应的 JSON 数据，再调用 Google Form 的 API 生成表单。

PDF → Google Forms.

(PDF → png → gpt4-vision → google forms)

twitter.com/krystof_rehacek/status/1731280672990322879

twitter.com/dotey/status/1731488081180577800

### 23

方军 2023/12/04

专业工作者个人使用 AI 的两个教训

写于 2023.12.4，为 AIGCxChina 的模仿《巨人的工具》、《巨人的方法》问题系列写的，我其实犹豫好久，巨人，当然我知道那两本书里面访谈的人也不是巨人。但为了对冲巨人，我写了两个教训。我觉得写得非常棒得意。

方军，科技作家，AI 技术专家，中国好书奖获得者

生成式 AI 会如何改变「我」？以 ChatGPT 为代表的大语言模型应用兴起以来，我们都深入地去读论文、做研发、推应用。每个企业、每个产业都有与 AI 相关的机会。但我觉得，或许对他人有用的是我们在摸索着用 AI 的过程中得到的教训。

为什么说是教训呢？AI 必将改变我们这些主要靠运用专业知识与技能的人的工作与生活，但是，有两个关键问题迄今都没有 100% 信心的答案：

1、它会带来何种改变？

2、我们如何应对？

因此，我愿意把学到的都看成是教训。我也倾向于把接触到的所谓「AI 成功经验」都理解为类似于教训，对自己坦诚的人都知道，我们不断看到自己刚总结的经验需要升级迭代。

这里分享我作为专业工作者个人用 AI 的两个教训。

第一个教训：要接受 AI 一定有幻觉，把这个缺点当成必须接受的一部分。

对容易被「AI 万能」的喧嚣声音影响的人，他们容易落入的首个陷阱是轻信 AI 的回答，因为其表达方式是权威的。

我们这些人轻松地跳过了这首个陷阱，因为我们知道 AI 有所谓幻觉（hallucination）：它会自信地给出错误甚至虚假的信息。但是，我们很快掉入一个与之相邻的陷阱：我们想尽办法去减少幻觉对我们使用者的影响。从原理上讲，幻觉是无法彻底消除的，要生成，就要放开回答须严格来自已有文本的束缚。

到目前为止，减少幻觉的路径大概有这么几条（这里以极简的例子来解说）：

1、优化提示语，比如说「请确保信息正确无误」。我自己比较喜欢用一个提示语模板，它来自 Elvis Saravia，我们又在其基础上扩展并命名为「ICDO」，它包括四个部分：指令（Instructor）、上下文 (Context)、输入数据 (input Data)、输出要求 (Output indicator)。

2、通过多轮处理来优化回答正确率。比如收到回答后，再次让同一模型或另一模型进行评估。

3、引入知识库，采用所谓检索增强生成（RAG）。也就是，提问时同时提供资料文本，要求 AI 按严格按资料回答。

也有更高阶的技巧，比如所谓的假设性文档嵌入（HyDE）。它的做法是，用问题先让 AI 给出一个可能有错的回答（即假设性回答），然后我们拿这个回答去资料库里面匹配相关资料，然后让 AI 再按资料回答，这样，我们可以得到更准确的回答。

4、微调模型。现在开源大模型和仅提供 API 的闭源大模型都可以微调。在一个具体的领域内，我们提供数百到数万个正确的「问题-回答」组合去微调训练，试图让大模型能更好地回答。

你看我如数家珍，就能知道我们在这些方面上「浪费」了多少时间精力。

结论是什么？简单说，结论是：如果我想要 90 分的答案，也就是 90% 的时候答案绝对正确。那么，对不起，不可能！90 分的要求可不高，日常工作中我们要的可是 99%、甚至 99.9% 的正确率。

我们自然还会接着以上道路继续探索，也相信 AI 模型的回答能力在某一天会接近完全正确。但是，就像现在使用 AI 生成图像时我们无法完全掌控、必须接受生成图的随机性一样，我们其实也不妨想办法接纳、甚至利用大语言模型类 AI 的幻觉。

接纳的方法很简单，我们可以要求 AI 生成的回答必须经过人的处理，如：仅用它作为参考想法，进行严格事实核查，由人进行最终处理等。

利用则比较有意思。我是从沃顿商学院的教育专家 Ethan Mollic 的教育场景提示语案例中学到的，并且也进一步延展它并实际使用。这是一次思维的大翻转。

正向：AI 的回答是对的。它现在的回答不对，那么竭尽全力确保正确。

逆向：AI 的回答是有错的。在商业场景比如客服场景中，错误是不可接受的。但在教育场景中，错误是可以利用的。

在教育场景中，我们可以对作为使用者的学生用户说，现在你们面对的是一个可能回答错的 AI 机器人（嗯，我们故意让它犯错的）。你的任务是，找出错误，纠正它的错误。教育研究早就证明，识别错误、纠正错误，能帮学生更快地学习。

所有人都试图把 AI 变成「导师」，我们这样做则是把 AI 变成「翻转导师」，这就像「翻转课堂」之于「课堂」。

AI 现在的能力有限、可能出错则不是问题了，它的缺陷某种程度上变成了「特性」—— 错误是学生的翻转角色教别人的机会。当然，随着 AI 能力的提升，AI 的正确率会提高。那当然好。但我们仍然可以用巧妙的提示语来让 AI 回答按固定的概率犯错，因而「翻转导师」的玩法可以一直用下去。

第二个教训：抛弃批处理界面，拥抱交互式对话界面。

很多普通人接触到的 AI 是对话式的聊天机器人，他们很开心可以跟 AI 反复说话，提出问题，给出命令，得到自己想要的。他们不太会掉到我接下来要说的陷阱里面去。但是，看了我如何掉坑里的过程，也可以理解为什么我现在会特别支持对话式的交互界面。

我们自认为是讲求高效运用技术工具的人，由于工作的原因又掌握各种技术诀窍，我们哪能就这么用 AI 工具？要让它神奇地完成任务。

随之而来的折腾之路大体上这样三条：

1、采用非常复杂的提示语。

大模型能力很强，能理解逻辑复杂的提示语。我们也能够写出高度结构化的提示语，比方说，这件事你按 A、B、C、D、E 五步给我做。

这有点像给有潜力的员工派任务，只要指令清楚，就能拿到结果。

可惜，我们跟这些有潜力的员工还没磨合好。我们讲得不完全清楚时，他不会追问，你的意思是这样吗？结果是，两方说岔了，他越努力越高效，结果离我们的期待偏得越远。

好，我们可以跟他慢慢磨合。用大模型时，这就相当于反复地改提示语、测试提示语。

很快我们发现，问题在于，一次把指令全给出去，我们没法监控中间结果，并进行调整。因此，我们接着走向下一条路。

题外话一句，让 AI 回答问题不是一些人理解的一次性抛接球：写一个提问语，得到一个好回答。而是一个循环迭代的过程，是一次次的抛接球训练：我们写一个提示语，得到一个不好的回答，我们重写提示语，回答变得好一点，如此多轮迭代，直到我们拿到满意的结果。

2、编写 AI 应用程序。

用专业术语说，编写 AI 应用程序实际上是对 AI 模型的调用进行编排（orchestration）。

通俗地说就是，我们编写一些程序来调用大模型的能力，比如这样做：第一步模型这么做，结果回来后我们靠程序判断一下，让它去做第二步，以此类推。

这样做了之后，我们就可以很方便地监控和调整中间结果了。模型的反应开始变得较为「聪明」。这颇像在工作中，我们通过内部的标准操作流程（SOP）和管理流程让聪明的新员工变成优秀员工。

以上这两个其实背后都是「批处理思维」，不要让我一次次说，要做到指令发出去，次次见效。既然有效了，那我们就进一步推广开来，那就是走上第三种路径。

3、在一个单一任务上采用提示语、编排、微调结合的批处理，准备大规模运用。

简言之，就是把各种手段都用上，让大模型在单一任务上为我所用。具体的做法因具体任务而异，这里不详述。让我快进到掉进去坑以及如何爬出坑。

编写 AI 应用并用于个人任务，其实与企业投资开发一个应用相似。投入了大量的时间精力进行开发，进行一些测试，进一步优化，觉得满意了，开始大规模运用。

最初的 100 个结果不错。最初的 500 个结果也看着不错。一两天时间这个过程就过去了。

但很快发现，糟糕，这些结果有瑕疵。但是，当我返回去调整时，我发现，常规程序和 AI 模型功能混在一起应用是无法有效调试的。一个原因是，每次模型给的结果不会 100% 一样。（现在有了一点优化，OpenAI 的模型可以接受一个种子参数，如果输入一致、种子参数一致，可以得到完全一致的结果。但是，我们的输入不会一致啊。）

这么一圈折腾下来之后，我才发现，聊天机器人的交互式对话是非常巧妙的。现有，采取交互式对话，更容易拿到理想的结果。

弯路可能是必要的。不是在弯路上亲身感受到，不会真的影响我们的后续行动。

我因而也对应用界面的演变有了更深的感悟。界面的演变历程是这样的：第一阶段是历史，批处理（如 dos 或 linux 命令行），第二阶段是当下，图形用户界面（如 Windows、iOS 和淘宝 APP），第三阶段是未来，对话式交互界面（ChatGPT 之类）。我们再考虑做应用时，也尽量走对话式交互界面。

同时，我也感受到现阶段要利用 AI 的能力，要坚持所谓人在循环中（Human in the loop）的设计理念，让人在其中参与，而不是想尽一切办法试图用 AI 将人替代、把人解放出来。换个角度看，现在的人其实也很想参与和 AI 一起干活的这个过程，而不是被排除在外。

以上，就是我作为专业工作者在 2023 年深度个人运用 AI 的两个教训。同时我有一个温馨提示是，结论不重要，我上面讨论中的结论可能很快在某个时刻又被发现错了、需要升级了，真正重要的是掉坑里爬上来的过程。

就普通人如何入门 AI，我喜欢给的一个建议是，找到一个小小的点开始用起来。用的过程中就明白了。听人说多少遍神奇，都不如自己亲身在小小的点用起来。比方说，我说话快容易写错字，现在写什么略长的都让 AI 检查一遍。这样，至少我每天在一个非常具体的问题上能像刷牙那样多次使用 AI。建议你也尝试着找个像刷牙一样的地方把 AI 用起来。

### 24

方军 2023/12/04

ChatGPT-like 系统是如何工作的？

How does ChatGPT - like system work?

by bytebytego，它的图一直很赞。

ChatGPT 类系统是如何运作的呢？

让我们通过下面的图解来探索它的运作机制。整个过程主要分为两大部分。

1、训练过程。要打造一个 ChatGPT 模型，我们需要经历两个关键阶段：

预训练：在这一阶段，我们会对一个 GPT 模型（一种仅包含解码器的 Transformer）进行训练，使用大量的互联网数据。我们的目标是培养出一个能够基于已有的句子预测出下一个词汇的模型，这个预测不仅在语法上要正确，而且在语义上要与互联网上的内容相吻合。预训练阶段完成后，模型能够补全给定的句子，但还不足以应对提问。

微调：这一阶段是一个三步骤的过程，目的是将预训练好的模型转化为一个能够回答问题的 ChatGPT 模型：

1）收集训练用的数据（包括问题和答案），并在这些数据上对预训练模型进行微调。模型学习如何根据问题生成与训练数据类似的答案。

2）进一步收集数据（问题和多个答案），并训练一个奖励模型，用于将这些答案按照相关性进行排序，从最相关到最不相关。

3）运用强化学习（PPO 优化）对模型进行微调，以提高模型回答问题的准确性。

2、回答问题。

步骤 1：用户提出一个完整的问题，例如「解释一下分类算法是怎么工作的」。

步骤 2：这个问题首先被送往内容审核组件。该组件确保问题不违反安全准则，过滤掉不恰当的问题。

步骤 3-4：如果问题通过内容审核，它就会被送到 ChatGPT 模型处理。如果未通过审核，则直接生成模板式的回答。

步骤 5-6：模型生成回答后，这个回答再次经过内容审核组件的检查。这一步骤确保所生成的回答是安全的、无害的、无偏见的等。

步骤 7：如果回答通过了内容审核，它就会展现给用户。如果没有通过审核，系统则提供一个模板化的答案给用户。

准确请看英文原文：

twitter.com/bytebytego/status/1731572801231020424

### 25

方军 2023/12/04

一种观点：大语言模型是压缩。马毅老师似乎是坚定的这种观点。

Pretraining Data Mixtures Enable Narrow Model Selection Capabilities in Transformer Models

Google DeepMind November 3, 2023

[[2311.00871] Pretraining Data Mixtures Enable Narrow Model Selection Capabilities in Transformer Models](https://arxiv.org/abs/2311.00871)

摘（为网友观点，非论文摘录）：这篇论文指出，大模型（LLM）对上下文的理解能力（ICL）不是一种通用的泛化能力，而是对预训练数据的检索能力。

用通俗的话说就是，不是一个智能理解了你的问题，而是它从数据集里搜索到了关联数据。

我现在愈发认为 LLM 只是一种高效的信息压缩算法，它的特色在于解压的效果也依赖于输入（prompt）。而 ICL 其实类似于心理学的「锚定效应」，所谓的 prompt engineering 只是在试图让 LLM 的答复锚定到更高质量的预训练数据集上。

至于能不能通向 AGI，对既有方法的灵活运用也是能够导向创新的，但是目前 LLM 的问题在于知识质量鱼龙混杂，需要人类高效 prompt 才能引出高效的答复，这可能预示着它只能扮演一个 copilot 角色，而且它的能力和人类搭档的能力是成正比的。

欧阳：这种观点其实特别扯淡，哈哈。一看就是科学哲学训练不好。

2023-12-04 22:42

方军回复欧阳：哈哈，马老师的论文和观点也至今未能说服我。

2023-12-04 22:42

欧阳回复方军：其实他这类论证犯了很明显的逻辑错误，最后又变成去辩论：压缩，究竟是什么？

2023-12-04 22:45

### 26

方军 2023/12/05

互联网上的话语和吸引人的注意力的方式蛮有意思的

意识流记录下想到的。

由昨天「大语言模型就是压缩」说起来的。其实就吸引人而言，这个标题都不如好几篇经典论文标题：

注意力是你需要的一切。

预训练大语言模型是快速学习者。

阳志平老师指出「大语言模型就是压缩」这个话的问题是：

他这类论证犯了很明显的逻辑错误，最后又变成去辩论：压缩，究竟是什么？

我没从这个角度想过，我觉得压缩是众多试图解读的类比之一，类比本来就不严肃了，而压缩略相当于 ZIP 压缩吧或 JPG 压缩吧。

在安人书院星球里面，阳老师发文批评一系列标题：

一般来说，我们在互联网上看文章，读到这类标题或者观点：

大语言模型就是压缩。

学习的本质，就是极致重复

真正的高手，都在刻意练习。

顶尖销售，都是谈判高手

一个优秀的管理者，必须经历 5 次蜕变

就不用往下看了。这类文章的作者应该补习：论证分析。

基础的哲学思辨没过，逻辑学没学好。

有朋友讨论，我跟了几句：

A：粗看以为说的这些观点有问题，细看原来是逻辑不对，上述 5 个标题包含了「就是」、「都在」「都是」「必须」。

我：我以为这些观点也是有问题的。…… 极致重复这个就更有意思了，我调查过这篇网络流行文章，能找出 100 个槽点出来。

具体来说，「学习的本质」，什么东西叫本质？我以为，除非在一些有定论的领域，否则没有场景，什么本质真的很难说。以前一个好朋友讨论时给建议说的，不要轻易说本质（理由大概是我们就讨论一个具体问题，远不是讨论本质）。

我们都不说的。但在社交网络上观察可以看到中文社交网络尤其喜欢「本质」。（英文不那么明显。）

—— 其实，「本质」也是一个高阶问题了。普通人也就是看到本质会被吸引点击去，只有那些自认为懂了点什么的人才会用「本质」这个词。普通人不会犯这个错。

还有一种有意思的现象是泛泛的标题：

AIGC 对程序员的影响

在这一期的播客中，我们将探讨 AI 技术，尤其是 ChatGPT 和 AIGC，如何改变软件工程的面貌。我们会聚焦于 AI 模型的不稳定性给开发者带来的挑战，以及它们在提高开发效率和创新方面的潜力。

社交网络上这种吸引眼球的标题尤其多，大众容易被吸引吧。它没有夸张，但真的好泛，但大概泛才能吸引很多人吧。—— 但是，真的能吸引到很多人吗？

这又是社交网络吸引人注意力钩子的另一种方式了：是极端的，吸引接受这个观点的人，排除不喜欢这个观点的人；还是泛泛的，试图吸引很多人？

社交网络还有一种吸引人注意力的方式是：比如官方媒体都很喜欢用的，「定了！」「这一国」，也就是不遵循基本的经典媒体规范，而把内容藏起来，以吸引人去点开。—— 我自己的体会是，尽量避免点开了，但极其偶尔的情况下还是会点。难。

小红书的话语也蛮讨厌的，什么「天哪」「救命」。当然，公平而言，小红书还是蛮正向的，像个健康的人，微博是街头混子，游荡久了什么都指指点点，知乎很 Nerd （这是我的感受，我看不到它那些刚编的故事）。

其实我觉得吸引注意力没啥，但要以伎俩高超一点。最近看 Youtube 较多，看了一些脱口秀演员（他们似乎自称 comedian 喜剧演员），他们的街头视频的确很有喜剧演员的特点，一个感慨就是，他们的街头表演、请到的嘉宾（嘉宾的表演水平）、拍摄与制作水平都好高超。昨天看的一个请到林书豪的。嘉宾表演极其卖力到位。

方军：有时候语言是一种逃避和自我保护吧。

比如有个人特别喜欢讲道与术.

我理解一是逃避他其实了解蛮浅、又出于公司角色对外什么都要说一点的。他的浅是了解东西经常不那么具体，面上是知道的，观点也不能说有错。

二是同样也是出于公司角色他不能讲真话怕得罪人，观点鲜明了容易被证明错，容易被对方挑战，他说说空话容易逃避。

2023-12-05 11:43

方军：我也很逃避，在星球写什么都很快，写正式文章会拖延，社交媒体文章则抗拒到写不来。

2023-12-05 12:39

### 27

方军 2023/12/05

Ethan Mollick 的一个观点：

为什么我对「与数据对话」的 AI 应用如此怀疑。

如下为 GPT 翻译，准确请查看原文：

twitter.com/emollick/status/1731749755909181767

后面有很多精彩的互动讨论，及文章：

[The Best Available Human Standard - by Ethan Mollick](https://www.oneusefulthing.org/p/the-best-available-human-standard)

这是 Google NotebookLM，一个很酷的工具，可以让你在数据源上使用 AI。尽管文档搜索能够检索到正确的信息（毕竟这是 Google），但 LLM 的答案有些微妙的幻觉。

注意图中的错误！

更好的 AI 和技术将改善这一点，但重要的是要意识到这种模型（我经常看到公司实施的一种非常常见的模型）存在重大潜在问题。

在工作中有很多更有效的使用 AI 的方式，不一定非得是这种方式。

是的，PaLM-2 比其他模型更容易产生幻觉。GPT-4 也是如此。如果你想要准确的重要数字和细节，RAG 还不能满足你的需求。

如果人们了解 AI 的能力，并且能够容忍人类的错误率，这些方法可能是可以接受的，但是使用机器的人并不希望出现不准确的情况。当虚假信息被制造出来时，他们可能会感到震惊。

网友讨论：

Michele Zanini

100% 同意。对于数据分析（以前是代码解释器）也是如此。幻觉的微妙之处尤其具有挑战性，因为需要付出很多努力才能揭示出来。

LLMs ≠ 数据库。用于探索和模式识别，但在需要精确性时要避免使用。

Olaf Lenzmann

建立一个商业 RAG 产品。用户抱怨因缺乏数据而拒绝回答，或者根据证据给出略微离题的回复：「失败」。几乎没有人似乎注意到错误的答案。

2024 年预计会出现普遍的 RAG 幻灭谷。

Brandon Roberts

这就是为什么能够快速验证 LLM 的输出非常重要。这个例子突显了在复杂问题和密集的源材料中可能出现的问题。

M.A. Buth

我可能会惹恼一些人，但目前的 GPT 非常糟糕。如果你想处理科学或工程数据，结果必须是准确、真实和可靠的，我得到了很多垃圾回复，这是不可接受的。质量已经下降，这是我观察到的。

Rana Taimur Ahmad

除了通常的 LLM 问题之外，与数据交流的问题还在于，任何有意义的产品、决策或行动都需要远远超出仅仅简单的问题或问题链来自数据源

Sebastian Kovács

这就是为什么简单的 top-k 检索无法完成任务。开箱即用的 RAG 解决方案可以用来玩耍，但在实际应用中缺乏准确性。但是，如果我们定制每个步骤，我们可以对输出的质量有很好的控制。

Richard Gaskin

我们能否回到只称呼错误为「错误」的方式？

错误地将它们标记为「幻觉」会使人们对再生系统的作用过高估计。

Karl Smith

这是一个我认为幻觉一词具有误导性的案例。事实上，这是一个错误，一个非常人性化的错误。人类和 LLM 使用概率来构建「事实」。

我们不会将人类的这种行为描述为幻觉。事实上，幻觉一词用于不太可能的「事实」。

twitter.com/emollick/status/1731749755909181767

Ethan Mollic 的推后面总有很多精彩的互动，经常远超原文。包括他的博客也是一样。

### 28

方军 2023/12/05

用可视化的方式连接各种 AI 模型、创建独特的 AI 工具

摘（倪爽）：5 月 20 日，takomo.ai 有一个独特的模块化系统，可以用视觉的方式，把 GPT、Whisper、Stable Diffusion、BLIP-2 等 AI 模型连接成管道 / 流水线，逐级设置、逐级处理，最终获得结果并以 API 形式部署。

操作非常直观，功能也足够强大

这个工具实现了 AI 领域的 no code、low code。

开发者可能习惯了代码、配置文件、表单等等方式来创建 AI 工具，对非程序员而言，拖放和连接 AI 功能模块，应该是创建 AI 工具、解决特定问题的最好工具。

比如写手可以连接几个 ChatGPT…

讨论：

不知道，我觉得特别讨设计师喜欢的炫酷，但我真心用不起来。我喜欢三种：

第一，就是普通界面。

第二，写程序。

第三，专业的配置界面。

这种很尴尬，普通人用不起来，专业人不屑用吧。

twitter.com/nishuang/status/1659773198802493441

新产品动态 #

### 29

方军 2023/12/05

非常喜欢这句话，搞张图放这儿：

了解 AI 哪里有用的

唯一方法是，

去用它。

The only way to figure out how useful AI might be is to use it.

Ethan Mollick

来源：

[The Best Available Human Standard - by Ethan Mollick](https://www.oneusefulthing.org/p/the-best-available-human-standard)

### 30

方军 2023/12/05

能够让大模型推理结果变得更好的基础优化手段已经非常多了，李靖梳理了常见的技术手段和对应的论文：

Zero-shot：

[[2109.01652] Finetuned Language Models Are Zero-Shot Learners](https://arxiv.org/abs/2109.01652)

2023057Finetuned Language Models Are Zero-Shot Learners

Few-shot：

[[2005.14165] Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165)

2023058Language Models are Few-Shot Learners

CoT：

[[2201.11903] Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903)

2023009Chain-of-Thought Prompting Elicits Reasoning in Large Language Models

ToT：

[[2305.10601] Tree of Thoughts: Deliberate Problem Solving with Large Language Models](https://arxiv.org/abs/2305.10601)

2023010Tree of Thoughts: Deliberate Problem Solving with Large Language Models

GoT：

[[2308.09687] Graph of Thoughts: Solving Elaborate Problems with Large Language Models](https://arxiv.org/abs/2308.09687)

2023059Graph of Thoughts: Solving Elaborate Problems with Large Language Models

SC：

[[2203.11171] Self-Consistency Improves Chain of Thought Reasoning in Language Models](https://arxiv.org/abs/2203.11171)

2023060Self-Consistency Improves Chain of Thought Reasoning in Language Models

Multi Persona：

[[2307.05300] Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration](https://arxiv.org/abs/2307.05300)

2023061Unleashing Cognitive Synergy in Large Language Models

Least to Most：

[[2205.10625] Least-to-Most Prompting Enables Complex Reasoning in Large Language Models](https://arxiv.org/abs/2205.10625)

2023062Least-to-Most Prompting Enables Complex Reasoning in Large Language Models

Step Back：arxiv.org/abs/2310.06117

ART：

[[2303.09014] ART: Automatic multi-step reasoning and tool-use for large language models](https://arxiv.org/abs/2303.09014)

ReAct：

[[2210.03629] ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/abs/2210.03629)

2023012ReAct: Synergizing Reasoning and Acting in Language Models

Reflection：

[[2303.11366] Reflexion: Language Agents with Verbal Reinforcement Learning](https://arxiv.org/abs/2303.11366)

2023013Reflexion: Language Agents with Verbal Reinforcement Learning

RAG：

[[2005.11401] Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401)

2023064Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks

我觉得缺了 HyDE。

HyDE: 

[[2212.10496] Precise Zero-Shot Dense Retrieval without Relevance Labels](https://arxiv.org/abs/2212.10496)

2023065Precise Zero-Shot Dense Retrieval without Relevance Labels

### 31

方军 2023/12/07

浏览中文社交媒体，主要想看看这个里面的人喜欢看什么 AI。

发现一个有意思的现象，在大众人群里面，好多人斩钉截铁地说，AI agent 就是未来。

理由就是几个名人好像比尔盖茨说过，类似的都是如此。

蛮有意思的，我觉得说的人连 AI agent 是什么都没想过。

公众号一些专业的也喜欢鼓吹，他们倒是知道，因为各种专业图示。但他们没说的是：她们说，这是最重要未来趋势，但他们其实说了几十个都是最重要的。

### 32

方军 2023/12/07

沈阳老师已经走火入魔了啊。

想法是，做法也是。

[第一篇纯 AI 小论文：批判性捧红的多学科分析](https://mp.weixin.qq.com/s/qGiwAy3vZmbhoCGiw4NmAA)

经过共十五次 AI 交互（13 次文本对话、1 次图片对话、1 次 AI 幻觉矫正），经历约三十分钟撰写、十分钟 word 排版删减，清华大学新闻与传播学院沈阳教授团队使用 AI 生成了一篇 8264 字的小论文。

本论文 100% 由 AI 撰写，文章分为理论分析、自反性论证、文献综述、历史案例分析、近期案例、形式化和展望与不足八部分。其中，形式化在一定程度上弥补了以往人文社科学者在数理形式分析上的不足。

这篇论文在分析深度、逻辑严密度、文献阐释、语言风格、叙述细腻度和要点扩展等方面还存在一些不足，这些问题将在下一篇小论文中得到部分改进。

转内：同时，鼓励大家对我们的研究，AI for Research：新文科和新传播，提出宝贵的发展建议。我们将在此基础上进行第二篇 AI 论文的生成，并期待 AI 未来能产出原创性的、超越组合式创新的文章。

我们的终极目标是天人智一，使用 AI 解决人类目前解决不了的一些问题，例如研究意识起源、破解历史悬案、进行 AI 辅助诊疗、大幅度提升生产力以尽可能地解放人类，使每个人都能享受自己的诗和远方。

### 33

方军 2023/12/07

张俊林：Google Gemini 技术报告要点提炼：

1. 技术报告 60 页，没有透漏具体技术细节，大部分是评测，技术报告作者列表包含 9 页内容，超过 700 人，应该接近 OpenAI 的员工总数了吧。

2. Gemini 是几种模态一起联合从头训练的，包括文本、图片、音频、视频等。这与目前通常的多模态做法不太一样，目前的多模态模型一般是使用现成的语言大模型或者经过预训练过的图片模型（比如 CLIP 的图片编码部分），然后利用多模态训练数据在此基础上加上新的网络层训练；如果是几个模态从头开始一起训练，那么按理说应该都遵循 next token prediction 的模式，就应该是 LVM 的那个路子，其它模态的数据打成 token，然后图片、视频等平面数据先转换成比如 16*16=256 个 token，然后搞成一维线性输入，让模型预测 next token，这样就把不同模态在训练阶段统一起来。

3. 技术报告说应该是 Decoder only 的模型结构，针对结构和优化目标做了优化，优化目的是大规模训练的时候的训练和推理的稳定性，所以大结构应该是类似 GPT 的 Decoder-only 预测 next token prediction 的模式。目前支持 32K 上下文。

4. Gemini Nano 包含两个版本：1.8B 面向低端手机，3.25B 面向高端手机。文章说 Nano 首先从大模型蒸馏，然后 4bit 量化。我这里有个问题：为什么不用手机调用 API 的方式调用服务端的最强模型呢？能想到的一个可能的解释是用户隐私，这样手机不用把数据传到云端；另外一个推理成本从云端转移到了手机，能够大量节省推理成本。还有其他原因么？

5. 从硬件描述部分来看，意思是动用了前所未有的 TPU 集群，所以推测 Gemini Ultra 的模型规模应该相当大，猜测如果是 MOE 大概要对标到 GPT 4 到 1.8T 的模型容量，如果是 Dense 模型估计要大于 200B 参数。考虑到引入视频音频多模态数据（当然是来自于 Youtube 了，难道会来自 TikTok 么），所以总数据量 * 模型参数，会是非常巨大的算力要求，技术报告说可以一周或者两周做一次训练。

6. 训练可能分成多个阶段，最后阶段提高了领域数据的混合配比，猜测应该指的是逻辑和数学类的训练数据增加了配比，目前貌似很多这么做的，对于提升模型逻辑能力有直接帮助。

7. 看学科能力测试，技术报告指标有人为拔高的倾向，比如 MMLU，只有 CoT 给 32 个例子 Gemini 才能超过 GPT4，当例子数量减少到 5 个，Gemini ultra 得分 83.7%，不如 GPT 4 得分 86.4%，高于 GPT 3.5 的 70%。从测试具体情况看，gemini ultra 应该是和 GPT4 基本持平或者稍微弱于 GPT 4 的，gemini pro 和 ultra 差距比较大，应该略微强于 GPT 3.5；而且 Llama2 在数学、推理等方面与最好的大模型效果差距非常明显，不同测试指标差距 20 到 40 分之间；

8. 从学科能力测试数据看，目前大模型能力很可能顺序如下：GPT 4 略微强于 Geminni ultra> Claude 2> inflection-2> GPT 3.5= Grok 1 >Llama2。

9. AlphaCode2 是在 Gemini pro 基础上，使用编程竞赛的数据 fine-tune 出来的，效果提升很明显，在编程竞赛上排名超过 85% 的人类选手，之前的 AlphaCode1 超过 50% 的人类选手；

10. Gemini Ultra 在多模态能力方面，在几乎所有测试数据上确实要比 GPT 4V 强一些。

11. 命令理解方面：和 GPT 一样，采用多模态 instruct 数据进行 SFT+RM+RLHF 三阶段，这里的 RM 部分在训练打分模型的时候，采用了加权的多目标优化，三个目标 helpfulness factuality 和 safety，猜测应该是对于某个 prompt，模型生成的结果，按照三个指标各自给了一个排序结果。

一个悲观的结论：

最后多说一句，从 Gemini 能够推断出一个悲观的结论如下：

因为在 GPT 4V 前大多数是文本模型，很多人觉得文本模型缺乏 Grounding，就是文本抽象语义和真实物理对象对应不起来，大模型理解不了物理世界的知识，而视频数据那么多，如果引进了后，大模型不仅能建立起 grounding，更重要的是视频数据蕴含了比文本更多的知识，所以对大模型的知识储备会有极大的增长。这里可能存在误解。

从 Gemini 的效果来看，事实可能并非如此，Gemini 多模态效果不错，它主打多模态，肯定引入了尽量多的视频、图片信息，这一方面说明多种模态联合训练确实有用，但是它的用处主要在于：把文本抽象概念和物理实体形象的对应 Grounding 建立起来了，但是在大模型的世界知识和各种能力储备方面，经过大量视频强化过的 Gemini 甚至可能还比不过只用文本训练的 GPT 4。

这一切指向如下可能：就世界知识含量来说，文本是大模型获取知识的主要来源渠道，视频、图片数据在这方面对于文本的世界知识补充作用微乎其微，视频、图片和文本多模态训练的主要作用是建立起实体概念及知识抽象表述和外在物理形象绑定建立 grounding 而已。除此外，无需对类似视频等多模态数具有更高的期望。

本质上，目前多模态大模型效果还不错，是大模型把从文本中学到的世界知识和逻辑能力，经过 grounding 绑定到实体外在形象后，在多模态场景下语言模型把丰富的世界知识迁移给了多模态模型，是文本模型带着多模态在飞，而不是反过来。

来源：weibo.com/1064649941/Nw0MZxMP2

### 34

方军 2023/12/07

摘：关于 AI 创业，我的一些不成熟的思考是：

- AI 的助力使得创业团队可以更小，3-5 人就能启动并做到一定规模。

- 创业者最先能成功的可能是在 ToProfessional 或 To Small business 领域的提效产品与服务，而 ToLBusiness 领域的一些单点工具也有机会

- ToC 消费端的体验需要在图形音频、Al 拟人程度上进一步改进。用户短期新鲜感周期的突破和较大规模明确付费意愿的达成可能还会滞后。

- To Large B 企业应用的 AI 介入受企业业务复杂度和内部利益归属影响，大企业的试错保守态度也会使这一进程滞后。

### 35

方军 2023/12/07

讨论翻译与 AI 翻译

刘群：【在 Google，我们对「不可能」持有一种健康的无视态度。】你看得懂这句中文吗？反正我一次看文字版的时候看到这句话的时候是懵的，完全不知道这句话是想表达什么意思。直到我看了视频才明白，回头再看这句中文，似乎字面上翻译也完全没有问题。

做过翻译的人会知道经常有这种现象，翻译的时候觉得意思完全翻译过来了，语法语义都没有问题，但一个没有看过英文原文的人，看到中文译文就完全一头雾水，不知道在说什么。这种情况发生的原因，通常是句子表达的意思在中文语境下比较罕见，或者不符合中文思维习惯。这种情况下翻译的时候就需要换一种更符合中文思维习惯的表达方式，或者加一些解释。

翻译中这种问题其实挺常见的，【而且译者经常自己都意识不到有这样的问题，因为他是看过原文的，不觉得译文有什么错误。】这也是为什么一些翻译著作读起来感觉非常费劲，一读原著就恍然大悟的原因。这也是高水平译者和低水平译者的差距所在。在这一点上，AI 翻译恐怕还远远达不到高水平人类译者的水平。

回到开头的问题，你觉得这句话怎么翻译，中文才更好理解呢？

@酱酱好老板：在谷歌，我们很自然地认为一切皆有可能。

方军：我这几天就有一个感慨，一本书把 coaching 翻译为带人，真是神来之笔，整本的关键词就是 coach，而它的语境里面也的确是带人的意思。

2023-12-07 20:42

方军：技术圈就不要说了，全是黑话。我对纯技术黑话的忍受度还蛮高的，但对敏捷那套的忍受度特别低。

有个敏捷的人写了个提示语指南，他哪来的那么多理论？

我比较自在，反正我不搞学术，我尽量说人话。（当然我经常被好朋友批评讲话 high context。）

2023-12-07 20:46

方军：刘群老师说的这个现象，也正好说明我为何喜欢看中英对照，因为中文看得更快，而对照可以准确，就兼顾了。以前 deepl 不能段落对照，极度阻碍速度。

### 36

方军 2023/12/07

摘：陈仲凯：今天备课的时候，看到一个词叫做「认知卸载」（cognitive offloading）。我个人来举几个例子：我们不用记住一家门店的位置，使用谷歌地图就行了；我们不用纠结自己没记住某个语法细节，把自己的句子扔给 ChatGPT，都会给你改好；…… 这恰恰是我近来在思考的一个问题：传统的低级别学习正在被快速淘汰。

我在美国这边念书的时候，很多专业术语我是脱口而出、表达流畅；我在阅读文献的时候，也完全依靠自己的「实力」全英文阅读论文、浏览全英文视频。相比之下，很多同学则使用翻译软件、和音频转录软件轻松搞定。我记得六年前在伦敦，老师要求我们写一个转录的作业，一堆同学手忙脚乱搞死个人，当时很多人还觉得「成长很多」。但是，今年在波士顿，直接转录软件都给分分钟搞定了。此外，有教授明确提到：可以使用人工智能，来转换字幕翻译。

表面上，我好像是英语能力强，但实际上用处并不大（至于秀什么好听口音的更是离谱）。重点是要善用工具。结合「认知卸载」的这个主题，很多人真的不必纠结死记硬背的知识点。

我观察到我们的中小学乃至大学生还在练字，无论是汉字还是英语（主要是为了考试的时候清晰辨认），但这种所谓的能力，在托福雅思等考试是不存在的。它们全部电脑答卷，没有书法发挥的空间。除了考试以外，放在工作中，我们几乎都是无纸化办公。你就是做个普通的外卖骑手，订单也都是打印的、用不上你写字对吧？

说起来可能是一个残酷的体系竞争：你处在一个为上世纪设置的工业化体系的教育，还是处在一个为本世纪设置的人工智能体系的教育。

### 37

方军 2023/12/07

Ethan Mollick 这个「最佳可用人类（BAH）标准」很赞啊。

Given this confusion, I would like to propose a pragmatic way to consider when AI might be helpful, called Best Available Human (BAH) standard. The standard asks the following question: would the best available AI in a particular moment, in a particular place, do a better job solving a problem than the best available human that is actually able to help in a particular situation? I suspect there are many use cases where BAH is clarifying, for better and worse.

鉴于这种困惑，我想提出一种实用的方式来考虑 AI 何时可能有帮助，称为最佳可用人类（BAH）标准。该标准提出以下问题：在特定的时刻、特定的地点，最佳可用的 AI 是否能比最佳可用的人类更好地解决问题，而这个人类实际上能够在特定情况下提供帮助？我怀疑有很多应用案例可以通过 BAH 来澄清，无论是好是坏。

[The Best Available Human Standard - by Ethan Mollick](https://www.oneusefulthing.org/p/the-best-available-human-standard)

我还不知道这个怎么解读和应用更好，不过感觉起来跟吴恩达说的「新毕业大学生测试」（fresh college gradute test）有一拼。

我把笔记里面的中英文对照附在 PDF 里面。

### 38

方军 2023/12/08

Paul Graham:

How many people make it through each day of Replit's online 100 Days of Code tutorial.

有多少人完成 Replit 在线的 100 天编码教程。

### 39

方军 2023/12/10

欧盟通过全球首个人工智能监管法案

- 对 AI 应用进行风险分类，特别关注「高风险」应用，如自动驾驶汽车和医疗设备。

- 禁止了企业从互联网或安全录像中抓取面部数据

- 违规处罚：违反法案的公司可能面临其全球收入 7% 的罚款。

- 对基础模型的限制：法案对捕获互联网数据以支持消费产品的大基础语言模型施加了限制。

- 对开源模型的豁免：法案为开源模型提供了广泛的豁免，这些模型可以自由地被开发人员更改和使用。

AI 法案的主要内容：

1、高影响通用 AI 系统的义务：为满足某些标准的「高影响」通用 AI（GPAI）系统设立了义务，包括风险评估、对抗测试、事故报告等。

2、透明度要求：要求这些系统创建技术文档和关于训练内容的「详细摘要」。

3、公民投诉权利：公民有权对影响其权利的「高风险」系统提出投诉并获得解释。

4、罚款框架：违反规则的公司将面临不同程度的罚款，根据违规行为和公司规模，罚款范围从 3500 万欧元或全球收入的 7% 到 750 万欧元或全球收入的 1.5%。

5、禁止的 AI 应用：禁止使用 AI 抓取 CCTV 录像中的面部图像、基于「敏感特征」（如种族、性取向、宗教或政治信仰）进行分类、在工作或学校中进行情感识别，或创建「社会评分」系统。

6、执法部门使用生物识别系统的保障和豁免：规定了执法部门使用生物识别系统的保障和豁免，无论是实时使用还是用于录像中的证据搜索。

7、立法最终对基础模型施加了限制，但对「开源模型」给予了广泛的豁免，这些模型是使用对开发人员自由提供的代码开发的，开发人员可以更改这些代码以用于自己的产品和工具。这一举措可能有利于反对该法律的欧洲开源 AI 公司，包括法国的 Mistral 和德国的 Aleph Alpha，以及发布了开源模型 LLaMA 的 Meta。

监管生物识别监控和基础 AI 模型的争议

关于监管实时生物识别监控（如面部识别）和像 OpenAI 的 ChatGPT 这样的「通用」基础 AI 模型的规则一直存在分歧。

各方反应：欧洲数字隐私和人权团体：这些团体对国家安全和警务方面的许多豁免表示担忧，他们一直在向议会代表施压，要求他们坚决反对各国为其警察和情报机构开辟广泛豁免的努力。

欧洲开源 AI 公司：对法案中对「开源模型」给予的广泛豁免可能感到满意，这有利于这些公司的发展和创新。

专有模型开发者：可能对法案中对被归类为具有「系统性风险」的专有模型施加的额外义务感到关切。

科技公司：对新法律带来的合规要求和潜在的财务处罚感到担忧。在欧洲 AI 领域，对新立法的担忧甚至更大，人们认为这可能会阻碍技术创新，进一步使美国和英国在 AI 研发方面更具优势。

全球观察者：由于欧盟在科技监管方面的领导地位，全球其他地区的政府和监管机构可能会密切关注这一法案，考虑其对自己法律的影响。

该法案预计在年底前达成最终协议，但法律最早可能要到 2025 年才会生效。该法案可能成为全球其他地区制定类似法律的标准。

### 40

方军 2023/12/10

转译：什么是「专家混合模型」（Mixture-of-Experts，MoE）？

Sophia Yang, Ph.D.

「专家混合模型」是一种创新的神经网络架构设计，它在 Transformer 架构中融合了众多的专家 / 模型层。在这种设计中，数据流动时，每一个输入的 Token 都会被动态分配给一些专家进行处理。这种做法使得计算更高效，因为每个专家都能在其擅长的特定任务上发挥出色。

关键要素包括：

- 专家：MoE 层由众多专家组成，既可以是小型的多层感知机（MLP），也可以是像 Mistral 7B 这样复杂的大型语言模型（LLM）。

- 路由器：负责将输入的 Token 分配给合适的专家。路由策略有两种：由 Token 选择路由器，或由路由器选择 Token。具体是怎样实现的呢？系统通过一个 softmax 门控函数来建立一个概率分布，从而在众多专家或 Token 中选出最合适的几个。

为何选择 MoE？

- 每个专家可以专注于处理不同的任务或数据的不同部分。

- 为大型语言模型增加了可学习的参数，同时不会增加推理成本。

- 能够高效处理稀疏矩阵。

- 所有专家层可并行计算，充分利用了 GPU 的并行处理能力。

- 有助于在降低计算成本的同时，缩短模型训练时间并提升效果！

推荐阅读的论文：

《稀疏门控的专家混合模型层》(2017)：

[[1701.06538] Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer](https://arxiv.org/abs/1701.06538)

《GShard：利用条件计算和自动分片扩展巨型模型》(2020)：

[[2006.16668] GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding](https://arxiv.org/abs/2006.16668)

《MegaBlocks：使用专家混合模型进行高效稀疏训练》(2022)：

[[2211.15841] MegaBlocks: Efficient Sparse Training with Mixture-of-Experts](https://arxiv.org/abs/2211.15841)

《专家混合模型遇见指令调整》(2023)：

[[2305.14705] Mixture-of-Experts Meets Instruction Tuning:A Winning Combination for Large Language Models](https://arxiv.org/abs/2305.14705)

来源：

英文原文：twitter.com/sophiamyang/status/1733505991600148892

中文翻译：twitter.com/dotey/status/1733742097239286215

方军：宝玉老师真是一颗贡献的心，动作又快。

对比下，让我做我真是 1% 都做不到，坚持不下来。

### 41

方军 2023/12/10

我有时候想，傻子只能让傻子（也就是 AI）去应对。

比如看到这句话：

重在引导**构建对知识本质的理解，培养「会学习」的底层逻辑……

TM 的什么是知识本质，什么是底层逻辑。

这种大问题不是说不能思考，但是，一般而言，让 AI 去跟他对着胡扯。

AI 可能会扯赢。

### 42

方军 2023/12/10

018 说点获取信息的感悟：搜索、社交网络与 AI

说点获取 AI 信息的感悟，除了专业资料和干中学之外，我获取资料的途径有三种：

搜素、社交网络，以及现在冒出来的 AI。

其中，搜索是最佳途径，主题获取信息，AI 我则常用来获取辅助解释。

我特别想说说社交网络，因为它对我们获取信息其实影响最大。

理由包括两面：

1、如果只搜索，无社交网络，我们缺少新信息的刺激。

2、如果过于依赖社交网络，又会看到很多无效信息，信噪比太小。

且要再次明确，我这里说的社交网络，又特指关注一定数量的某个领域专业号，而非刷社交网络。（现在的算法推送也往往做的很不错，尤其推特。不要乱点，可以一直看到相关的内容。）

在今年看 AI 的过程中，这个方式是有很不错的效果的，因为关注一群 AI 研究者、应用工程师、还有 Prompt 工程师，所以新的热潮几乎一定会在时间线里出现。

当然，这种方式获取信息，必然只是辅助。因为如果自己没有主干（或者说没有装信息的衣柜和衣柜），就会被信息洪流冲得乱七八糟。比方说，这些信息很刺激啊，一个个公司新闻感觉需要关注啊。OpenAI 驱逐 CEO 事件充满戏剧性啊。但其实都是噪音。

我的 AI 主干很简单，一方面只关注研发相关，且偏重非预训练以外的研发，另一方面只关注 prompt 技巧。其他的全忽略。

我用类似的思路看其他领域时，则发现有意思的变化。其他领域通常被不像这个变化这么快，一般来说缓慢得多。但也有类似的东西：有些人他发的其实是一种陪伴。他作为以自媒体为业的人（应该是为业务获取流量），在不断地重复一些信息，实际效果是形成一种陪伴（和过去关注朋友不太一样，其实我不看朋友圈了）。偶尔看到时我们也会想，这个问题要不要考虑一下呢？这其实是蛮好的提醒。

—— 但是，也要警惕的，因为如果放在一个长时段看（我的确整理了两个不同领域两人全年的），他们非常有意识地把信息放在一个非常浅的层次。从营销角度来讲，深了并不能吸引来人。另外，有一个人（这个出没于中文社交网络），他其实有一个暗线就是挑起城市之争，哪个城市更好，这大概是他的流量密码吧，这是噪音。还有，这些运营自媒体的人有个常见技巧是 republish，也就是一个不那么强时间性的信息反复发，这对他当然有必要，但对我们来说则要注意这一点。

目前看，AI 在社交网络方面暂时还不能替代。AI 也不能替代搜索，但真是可以替代部分疑惑性的解释了。

我所讨论的这种方式其实在传统媒体时代也是存在的，我们获取信息的方式是订阅行业杂志，因而可以看到各种琳琅满目的信息，以及去大书店的杂志区，观看其中封面呈现出来的社会观感。

\#AI 使用感悟#

### 43

方军 2023/12/10

《Claude 官方文档提示词工程最佳实践》

这个 PPT 是 Anthropic 上个月更新进自己官网的，未来力场把它编译成了中文。

英文原文：

[Guide to Anthropic's prompt engineering resources](https://docs.anthropic.com/claude/docs)

[Claude Prompt Engineering Techniques - Google 幻灯片](https://docs.google.com/presentation/d/1zxkSI7lLUBrZycA-_znwqu8DDyVhHLkQGScvzaZrUns/edit#slide=id.g288a92597fe_0_487)

中文：

[⁡⁢‬​⁡‌‌​⁤​​​⁢​​⁡⁤⁡‌⁣⁤⁣⁢‍‌‬‬⁤⁡⁣Claude官方提示词工程最佳实践\_未来力场编译版\_Prompt Engineering Techniques.pdf - 飞书云文档](https://futureforce.feishu.cn/file/D4ydblrLioRe8lx3GXrcirvwn7g)

\#提示语模版# #学习资料#

### 44

方军 2023/12/10

《大型语言模型的提示框架综述》

讨论了自 OpenAI 开发的强大 AI 聊天机器人 ChatGPT 推出以来，大型语言模型（LLMs）在学术界和工业界取得的显著进展。这些进展在多个领域带来了根本性的工程范式转变。论文强调了有效利用大型语言模型能力的重要性，特别是关注在此背景下「提示」的作用。

[[2311.12785] Prompting Frameworks for Large Language Models: A Survey](https://arxiv.org/abs/2311.12785)

### 45

方军 2023/12/10

联合国教科文组织的一本杂志，这期主题是《人工智能时代的教育》，其中有一篇可汗学院创始人的采访。

### 46

方军 2023/12/10

回头再看，得到当时推的一系列 AI 课，学习数量不低。万维钢的发刊词听的人竟然高了一个量级。另，得到好像其实不是很重视 AI 这个方向，也许说明上班族还不会用。

万维钢·AI 前沿

71170 已加入学习人数

发刊词：人，要比 AI 凶

68833 人学过 | 已学完

前沿课·吴军讲 GPT

成为搞懂 GPT 的少数人

53251 已加入学习人数

发刊词：「ChatGPT 神话」背后的原理是什么？

68199 人学过

快刀青衣·给职场人的 AI 写作课

AI 用得好，天天下班早

33113 已加入学习人数

发刊词：用好 AI，从 1 个人到 1 支队伍

28939 人学过

刘飞·怎样用 AI 绘画

成为设计高手的快速通道

29873 已加入学习人数

发刊词｜每个人都可以拥有自己的专属设计师

19104 人学过

卓克·怎样用 AI 高效学习

让 AI 成为你的「第二大脑」

44523 已加入学习人数

发刊词｜用好 AI，打造自己的「第二大脑」

49966 人学过

马馺·怎样用 AI 做 PPT

又快又好，又不难搞

30328 已加入学习人数

发刊词：替代人的不是 AI，而是会使用 AI 的人

21869 人学过

(这个其实不算）

李笑来谈 AI 时代的家庭教育

好的教育，成本极低

26630 已加入学习人数

38693 人学过

题外话一句，又回头看了得到当年的年度专栏，目前还在延续的只有万维钢了，真是厉害。

万维钢的比较容易长期，实际上是一种陪伴。现在第五季了，他竟然还没疲，真是厉害！今年看主题基本上是一周读一本书了。

刘润的本来三季就该讲完了。他梳理普通上班族应该怎么工作，还是蛮不错的，我觉得上班族学下基本工作素养过得去。

再看其他人的，有些老师 300 讲构建一个话题，就野心过大了，事后再看撑不住我猜原因是，理论本来就不是这么构建的。按美式学院风格，一个五次讲座反而容易构建一个理论。

甚至得到最喜欢的一个学科，比如薛兆丰、香帅这样讲一个学科的，事后再看都没那么好了。薛的没听过，香帅我翻了翻书，她们的作用其实也是陪伴，因为真学要去啃那些厚厚的专业教材。

我还有个疑问，如果听完薛老师的课，经济学素养会不会提高呢？可能本来就是两群人：本来就会学经济学的人，和不学经济学的人。薛服务的是后者，并可能为激发部分人的兴趣，从而去学。

所以，伴随。

### 47

方军 2023/12/11

AI 绘画行业全年报告

来自：无界 AI

应该是无界 AI 刘秋杉的演讲加综合，蛮不错的，可以了解国内外 AI 绘图应用的一些情况。

335 页，非常全面。甚至还讨论了不少视频生成。

（这是压缩版，个别图片可能不清晰，原 PPT 太大传不上来。）

2『已下载原资料「20231211AI绘画行业全年报告2.0-compressed-compressed」。（2023-12-12）』

### 48

方军 2023/12/12

讲实话，很强的同感，可能也是因为都没机会做顶尖算法本身吧，所以感受到不到正面反馈，而我们的实力在应用层是可以有不错的正反馈的。

转自李靖：半年前，我跟几个算法做的比较资深的朋友聊 AI。他们对 AI 未来的发展持悲观态度，从数学层面看，AlexNet/Transformer/ResNet 等这些东西，它们并不复杂，大模型无非只是将这些本不复杂的东西进行了调优和组合，最后「大力出奇迹」，而这些能力、奇迹似乎老早之前便已经存在。

渐渐地，我开始能够明白他们的悲观。在冰冷的数字、符号和公式面前，在繁多的模型、数据集和测试方法面前，技术的本质显得过于赤裸，技术研究中时间的流逝模糊了前方的视野，以至于未来都陷入了眼前看似美妙的概率之中。

在应用层，我们或许是幸运的。不需要过多地涉足底层，站在巨人的肩膀上，几行代码就可以调动整个生态筑起的武器库，完成一个个不可思议的推理变幻，也只有当求知欲强盛的时候，才会往下窥探。对比之下，学习的动力也不尽相同。

### 49

方军 2023/12/12

转，一个老师的分享（英国中学的华人老师）：从 chatgpt 出世不久，我就开始用它辅助备课和教学，任何一种现代技术其实都是双刃剑。

我曾经用它给我出过高中生电影研究的论文题目。我教这门课有六七年，除去历年考试和其他辅导材料的命题，我自己也就思索出不到十个论文题目，问了一下 chatgpt, 几秒钟内就列出了 20 个题目，稍加调整都可以用，也都不错。这让我省去了大量的思考时间，也让我有些恐惧，如果 chatgpt 可以替我们思考了，那我们的大脑用来干什么？ 智能机器人可以替我们做体力劳动，现在又有可以替我们脑力劳动的技术，人类是不是可以躺平甚至消失了呢？对个体来说，大脑不用思考了，用进废退，我们会不会早日进入阿兹海漠？

然而，chatgpt 又可以解决我们生活工作中的大量问题。今年新带的宗教研究课全凭了它，你可以让它将深奥的宗教理论变成适合于八年级孩子的语言，实在是神奇。还可以让它成为你的随身翻译，一些英文词汇在某种情境下的意思是任何其他字典和网上翻译工具都无法翻译成合适的中文的，问一下 chatgpt 两秒钟就可以解决问题。前些天孩子爸爸从医生那里拿回了他的几十项的血检报告，这报告不是面向病人，而是医生看的专业报告，全是看不懂的专业词汇和符号，用 chatgpt 能立刻用中英文科普语言解释得清清楚楚。同时，你还可以和 chatgpt 建立一种「亲密」关系，同样形式的问题问多了，它就领会你的意图了，下次再问，你就不用给它那么多指令，简单几个字，它就明白了。

当然，自从 chatgpt 面世以后，各种以音响、视频、图形等等的 AI 蜂拥而出，既节省了人们的大量的思考运作时间，又给人类的整体和个体带来了前所未有的挑战。总感觉人类是被 doomed 了。

### 50

方军 2023/12/12

《深入解析「混合专家模型（Mixtral of Experts）」| Mixture of Experts Explained》（HuggingFace）

完整的讲述了混合专家模型的各个方面。主要内容如下：

1. 相较于密集型模型，预训练速度更快

2. 拥有比同等参数的模型更快的推理速度

3. 对显存要求高，因为需要将所有专家模型都加载到内存中

4. 虽然在微调方面存在挑战，但近期关于 MoE 的指令调优研究显示出了光明前景

原文：huggingface.co/blog/moe#switch-transformers

翻译：baoyu.io/translations/llm/mixture-of-experts-explained

模型发布说明：mistral.ai/news/mixtral-of-experts/

归藏的笔记：

twitter.com/op7418/status/1734243194635002135

Hugggingface 的人发布了一篇详细介绍 MoE 架构模型的文章《专家混合模型解释》这里摘录一些我能看得懂的，做一下笔记，中间涉及到大量数学公式的我就歇菜了，各位可以去看原文：

MoE 模型太长不看部分：

◈ 预训练模型比密集模型快得多；

◈ 相较于具有相同参数数量的模型，具有更快的推理速度；

◈ 需要高 VRAM，因为所有专家模型都加载在显存中；

◈ 在微调中面临许多挑战，但最近对 MoE 指导微调的工作很有前景。

专家混合模型（MoE）是什么？

模型的规模是提高模型质量的最重要因素之一。在固定的计算预算下，训练一个更大的模型进行较少的步骤比训练一个较小的模型进行更多的步骤更好。

专家混合模型使得模型可以用更少的计算资源进行预训练，这意味着你可以在相同的计算预算下大幅扩展模型或数据集的规模，就像密集模型一样。特别是，在预训练阶段，专家混合模型应该比其密集对应模型更快地达到相同的质量。

MoE 由两个主要元素组成：Sarse MoE 层：p 被用来代替密集的前馈网络（FFN）层。MoE 层有一定数量的「专家」（例如 8 个），每个专家都是一个神经网络。在实践中，这些专家是 FFN，但它们也可以是更复杂的网络，甚至是 MoE 本身，从而导致分层 MoE。

一个门控网络或路由器：确定将哪些令牌发送给哪个专家模型。正如我们将在后面探讨的那样，我们可以将一个 Token 发送给多个专家。如何将 Token 路由到专家是在使用 MoEs 时的重要决策之一 - 路由器由学习参数组成，并且与网络的其余部分一起进行预训练。

因此，总结一下，在 MoEs 中，我们用门控网络和一定数量的专家替换了 transformer 模型的每个 FFN 层。

尽管 MoEs 相比密集模型提供了诸如高效的预训练和更快的推理等好处，但它们也面临挑战：

训练：MoEs 能够显著提高计算效率的预训练，但在微调过程中历来存在泛化困难，导致过拟合。

推理：虽然混合专家模型可能有许多参数，但推理过程中只使用其中一部分。与具有相同参数数量的密集模型相比，这导致推理速度大大加快。然而，所有参数都需要加载到显存中，因此显存需求很高。

MoEs 简史：

MoEs 的根源可以追溯到 1991 年的论文《自适应局部专家混合》。这个想法类似于集成方法，旨在为由独立网络组成的系统提供监督程序，每个网络处理训练案例的不同子集。每个独立网络或专家模型都专门处理输入空间的不同区域。专家模型是如何选择的？一个门控网络确定每个专家模型的权重。在训练过程中，专家模型和门控都会被训练。

2010 年至 2015 年期间，两个不同的研究领域为后来的 MoE 进展做出了贡献：

专家模型作为组件：在传统的 MoE 设置中，整个系统包括一个门控网络和多个专家。MoE 作为整个模型已经在 SVMs、高斯过程和其他方法中得到了探索。Eigen、Ranzato 和 Ilya 的工作探索了 MoE 作为更深层网络的组成部分。这使得 MoE 可以作为多层网络中的层，使模型能够同时变得庞大和高效。

条件计算：传统网络通过每一层处理所有输入数据。在这段时间里，Yoshua Bengio 研究了基于输入标记动态激活或停用组件的方法。

这些工作导致在 NLP 的背景下探索专家模型混合。具体来说，Shazeer 等人（2017 年，其中「等人」包括 Geoffrey Hinton 和 Jeff Dean，Google 的 Chuck Norris）通过引入稀疏性（Sparsity），将这一想法扩展到了一个 137B 的 LSTM（当时的事实 NLP 架构，由 Schmidhuber 创建），从而实现了非常快速的推理，即使在高规模下也能保持。

Sparsity 是什么？（这部分完全看不懂）各位自己去看原文吧，好多公式。

MoEs 的负载均衡 Token：

如前所述，如果我们所有的 Token 都发送给几个热门专家模型，那将使训练效率低下。在正常的 MoE 训练中，门控网络会收敛到大多激活相同的几个专家模型。这种自我强化会使受青睐的专家模型训练得更快，因此被选择得更多。为了减轻这种情况，添加了辅助损失以鼓励给予所有专家模型相等的重要性。这种损失确保所有专家模型接收大致相等数量的训练样本。接下来的部分还将探讨专家模型能力的概念，该概念引入了专家可以处理多少 Token 的阈值。在 `transformers` 中，辅助损失通过 `aux_loss` 参数暴露出来。

Switch Transformers 采用了简化的单专家策略。这种方法的影响是：

◈ 路由器计算减少

◈ 每个专家的批处理大小至少可以减半

◈ 通信成本降低

◈ 质量得到保留

增加专家模型数量会如何影响预训练？

更多的专家会导致改善样本效率和更快的加速，但这些增益是递减的（特别是在 256 或 512 之后），并且推理过程中会需要更多的 VRAM。在大规模研究的 Switch Transformers 中研究的特性在小规模下也是一致的，即使每层只有 2、4 或 8 个专家。

何时使用稀疏的 MoE 模型而不是密集（dense）模型？

专家模型在具有许多机器的高吞吐量场景中非常有用。在预训练的固定计算预算下，稀疏模型将更加优化。对于具有较少 VRAM 的低吞吐量场景，密集模型将更好。

MoE 模型未来的发力方向：

进一步实验将稀疏的 MoE 蒸馏为参数更少但具有类似参数数量的密集模型。

另一个领域将是 MoE 的量化。QMoE（2023 年 10 月）是朝着这个方向迈出的一大步，通过将 MoE 量化为每个参数不到 1 比特，从而将使用 3.2TB 加速器的 1.6T 交换 Transformer 压缩到只有 160GB。

简而言之，一些有趣的探索领域：

◈ 将 Mixtral 提炼成密集模型；

◈ 探索专家模型合并技术及其对推理时间的影响；

◈ 执行 Mixtral 的极端量化技术。

方军：最近这个话题有点超出我的能力范围了，不过感觉必须努力搞明白。

2023-12-12 11:19

### 51

方军 2023/12/12

宝玉的分享文章，发表于《CSDN 新程序员杂志》：2023 年对我来说是神奇的一年，我意外地从一个程序员变成了一个 AI 资讯届的「网红」，到年底时我在 X 平台的阅读量超过 1 亿，微博上的阅读量则超过 10 亿，很多人通过我的微博或者 X 了解最新的 AI 资讯、教程和 Prompt 使用技巧。而这一切其实是从我患上了 AI 焦虑症开始的。

宝玉：

[2023 年，我患上了 AI 焦虑症！](https://mp.weixin.qq.com/s/LbRvR1VXpZoDilyyMGGeFw)

也欢迎看看我的，也算年度总结吧：

方军：

https://t.zsxq.com/158eWkScC

### 52

方军 2023/12/12

《为什么伟大不能被计划》的作者之一 Kenneth Stanley 对「幻觉与创造力」有不一样的观点：（和 AK 的放在一起读）

为什么伟大不能被计划「的作者对「幻觉与创造力」有不一样的观点：

1）创造力的关键在于了解现有的东西，这是创新的基础。如果分不清现实与虚构，就难以推动真正的创新。

2）将 LLM 的「旧观念「误认为新创意，是对创造力的误解。

3）将幻觉认为是「创造性」带来的宝贵资产，是另一种误解。

4）一个假设：如果我们真正「解决」了 LLM 幻觉问题，创造力也会随之而

来

5）如果一种「解决方案」只解决了这枚双面硬币的一面（例如，降低幻觉但不提高创造性质量），它很可能是相对肤浅的，并不是真正能引领该领域走向壮观的变革之路。

---

Kenneth Stanley

最近我注意到一些关于「幻觉」的讨论，有人认为幻觉是一件好事，因为它代表着创造力，或者说这正是大语言模型（LLMs）被训练去做的事情。我的一些研究也经常被提及，因为我对创造力和开放思维有不少见解。因此，我想分享我的看法：创造力的关键在于了解已有的事物，这是推动创新的基础。如果你分不清什么是真实的，什么是虚构的，那么就很难创造出真正新奇的东西。

但是，关于幻觉的另一面 —— 即把老旧的想法当作新颖的创意 —— 这一点却鲜为人知。事实上，当大语言模型被要求展现真正的创新时，我们经常看到的就是它们重复已有的观点或提案。比如，当被要求提出创新的菜谱、新音乐类型或解决现有问题的发明时，得到的往往是已经存在或被提出过的东西（当然，并非总是如此，就像提问事实问题不总是得到幻觉一样，但这种情况发生得太频繁了）。

所以，虚假的创造力和幻觉实际上是一枚硬币的两面。如果存在其中一种情况，通常也会伴随着另一种。从这个角度来看，这些并非好事，而且认为幻觉因为能激发创造力而有价值，这是一种误解。深刻理解现实是权威和创造力的重要支持者，实际上，成为某一领域权威的人通常也具备高度创造力。

但这个观点不仅仅是悲观的看法：它意味着如果我们真正解决了幻觉问题，创造力自然会随之增强。这还引出了一个有趣的假设：在解决幻觉问题的方法中，哪些方法可能对该领域的发展最具启发性。如果一个「解决方案」只针对这枚双面硬币的一面（比如，只是减少幻觉而没有提高创造性），那么这种方法可能相对肤浅，并不是真正能引领该领域取得重大突破的路径。

twitter.com/kenneth0stanley/status/1733571230803058920

### 53

方军 2023/12/12

吴恩达的建议：

Use LLMs as a reasoning engine to process information, rather than using it as a source of memorized information.

将 LLMs 用作推理引擎来处理信息，而不是将其用作记忆信息的来源。

### 54

方军 2023/12/12

ChatGPT 的语言能力真是强。

Live as if you were to die tomorrow. Learn as if you were to live forever.

去生活，就像明天就会死去一样。去学习，就像会永远活着一样。

甘地这句话真是精彩。

「爱生活如濒死，求大道若永生」，季羡林先生的翻译。

我觉得改成「爱生活如濒死，爱学习若永生」，其实也蛮好。

ChatGPT 会怎么翻译呢？

活得好像明天就要死一样，学得好像要永远活下去一样。

要求用更通俗的话翻译：

1. 活在当下，就像明天就没明天了；学习则像是要一直活个没完没了的样子。

2. 好像今天是最后一天一样过日子，但对待学习就像会一直活下去一样。

3. 生活要活得尽兴，就好像明天就是世界末日；学习则要像是一辈子都有机会一样努力。

要求三种文雅的翻译：

1. 生活宛如明日黄花，须臾尽欢；学识则若长存之灯烛，恒久燃烧。

2. 恰似人生短暂，当欣然过今朝；学养有如永恒，务求绵延不断。

3. 如同明日终结一般活，珍爱当下之光阴；学海犹如长存之泉，奋发习得至永不息。

我觉得这六句话都看不出错来，真是很棒。为 GPT3.5 的翻译。

方军：

我的感想有二：

第一，玩文字，没人能玩得过 GPT。因此，玩文字的人，要把它用起来，用它提供多种选项，然后来让自己的更好。

第二，我们应该超越文字，至少往下多追一层问题（这是什么原因导致的？或我的收获是什么？），或者往外多追一层行动（这个可以引发我什么行动？我要用这个行动拿到什么结果）。

2023-12-12 21:57

### 55

方军 2023/12/13

一篇指南，和 AI 的关系是用 GPT 翻译的。

但也可以说出点其他和 AI、和学习的关系。

我刚刚和朋友讨论时感慨，美国市场很多人做事的时候，就是抓住一个小小点。比如这篇文章，其实就在讲一个中国的牛人们都不屑于谈的点（当然也有，但那些又一下子讲得很差）。

我们讨论，可能我们的思维里面，一是有点瞧不上实用，二是有点喜欢总结一般性的（比如我现在就是）。这带来的结果是，我们缺少那些实用的东西。

到现在：

- prompt 指引没见到人搞出实用的出来，都很宏大（或者极其细碎）。

- 没有好的课（吴恩达自己和他的公司做的那些），AI 的课都很宏大。

其实，前些日子看那个心理学教授龙虾教授的资料时，我看到他写的如何写 essay 的指南，真的很实用，我想大学生、研究生会觉得很实用，我们这些算是会写点东西的人，也觉得极其实用。

我这种想法是要被批评的，太实用了。但实用不好吗？选择吧，现在也到了这种批评意见不太能影响我的时期了。

2『已下载附件「20231213七个影响你课程销售的文案错误」。（2023-12-13）』

### 56

方军 2023/12/13

将语言模型 (LM) 与世界模型 (WM) 相结合：旨在提高 LM 在推理和规划方面的能力，当前的大型 LM 在物理环境中缺乏鲁棒性和可靠性，无法执行复杂的推理和规划任务。与之相反，人类通过 WM 进行深思熟虑的推理和规划，WM 能模拟行为及其对世界状态的影响。将 WM 和 LM 相连接可以提升 LM 在推理和规划方面的能力，并解决其限制.

——《(NeurIPS 2023 Tutorial) Language Models meet World Models》

[NeurIPS 2023 Tutorial](https://sites.google.com/view/neurips2023law/home)

方军：世界模型看似很吸引人，但我总觉得是学术界的把戏，为了论文开辟新赛道。

2023-12-13 09:15

### 57

方军 2023/12/13

LangFlow 0.6.0 发布

This release marks a significant milestone for our project with the integration of the Langflow Store, enabling users to share and utilize a wide array of shared components. We've also introduced the ability to group multiple components into a single entity, streamlining the organization and management of complex workflows.

这个发布标志着我们项目的一个重要里程碑，通过集成 Langflow Store，使用户能够共享和利用各种共享组件。我们还引入了将多个组件分组为一个实体的能力，简化了复杂工作流的组织和管理。

Key Features: 主要特点：

1 Langflow Store Integration: Share and use shared components with ease, fostering a collaborative environment.

Langflow 商店集成：轻松共享和使用共享组件，促进协作环境。

2 Grouped Components: Combine multiple components into one for better organization and usability.

分组组件：将多个组件合并为一个，以便更好地组织和使用。

3 Enhanced UI/UX: Numerous improvements to the user interface and user experience, including loading animations, modal management, and UI consistency.

增强的用户界面 / 用户体验：包括加载动画、模态管理和界面一致性等多项改进。

4 Performance and Security: Dependency updates and refactoring for improved performance, security, and maintainability.

性能和安全性：依赖更新和重构以提高性能、安全性和可维护性。

5 Error Handling: Robust error handling mechanisms for API key issues, component retrieval, and more.

错误处理：针对 API 密钥问题、组件检索等提供强大的错误处理机制。

6 Backend and Frontend Refinements: Backend services and frontend components have been optimized for better performance and user experience.

后端和前端的优化：后端服务和前端组件已经进行了优化，以提供更好的性能和用户体验。

We've also addressed various bugs and made improvements across the board, including memory leak fixes, UI enhancements, and codebase optimizations.

The addition of new features like the GPT-4 Vision Preview option and the first steps into handling credentials a bit better. Some features will be implemented fully in the coming weeks.

我们还解决了各种错误，并在各个方面进行了改进，包括修复内存泄漏问题、UI 增强和代码优化。

新增了一些功能，如 GPT-4 Vision 预览选项，并初步改进了凭据处理。一些功能将在未来几周内完全实现。

\# 新产品动态#

### 58

方军 2023/12/13

埃森哲推出生成式人工智能专属服务

专有大模型「转换平台」

[埃森哲推出生成式人工智能专属服务](https://mp.weixin.qq.com/s/VwJrXQFk3vyLiyKitUU9gg)

定制化开发和托管

培训和认证

埃森哲推出生成式人工智能专属服务

\# 新产品动态#

### 59

方军 2023/12/13

摘：这是一篇打破 GPT「涌现」概念神话的论文，终于说出了我一直以来的一个直觉，这才是比较符合事物发展规律的

论文：arxiv.org/abs/2304.15004

Are Emergent Abilities of Large Language Models a Mirage?

Rylan Schaeffer, Brando Miranda, Sanmi Koyejo

一句话总结，所谓 GPT「涌现」能力，是因为人为修改了「达标」的评价标准，给人 "涌现" 的错觉

一旦使用更合理的评价指标，就会发现 GPT 能力值随着模型增大是线性增长的，从评价指标上直接解构了「涌现」

先说说什么是「涌现」，这是 LLM 引起爆炸式关注的一个非常重要的原因，「涌现」来自于复杂系统：秩序从复杂系统中演进出来

当大模型的规模量级逐渐升高，到达某个临界点时会突然质变 ，无中生有出来一种新的能力的现象，就叫做「涌现」，比如在八位数加法这个任务上，随着模型规模变大，当计算训练量超过 10^23 flop 之后，准确度突然开始飞跃，突然涌现出 100% 正确的加法

类似的，微软和 openAI 也发了很多论文论述 GPT 突然「涌现」出来的多种能力，比如空间想象能力，推理能力，甚至简单的 debug 能力

回到论文，<Are Emergent Abilities of Large Language Models a Mirage? 为什么说 GPT 的「涌现」是海市蜃楼？

因为一旦使用更合理的评价指标，就会发现 GPT 能力值随着模型增大是线性增长的，并不是突然增长

举个例子，涌现能力的文章中，评价标准一般是非黑即白，「exact match」就是精确对应，但 exact match 这个评价标准就是一个非黑即白非线性的标准，比如说一个模型只预测对了一大部分，只要没达到精确对应，分数都是 0，只有 0 和 1 的区别

在这个非线性标准下，意味着 LLM 模型能力一旦过了一个门槛，能力分数就会突然惊人的爆发，也就是所谓的「涌现」，可是把标准修改为精准答对，分数的爆发并不代表真实能力爆发

（如图）论文里举的例子是把精确答案的评价标准修改成了「edit distance」，也就是和标准答案之间的距离，结果发现随着模型的增大，离标准答案的距离也越来越近，所以实际上这项能力就是线性增长的。这就是典型的因为非线性评价指标得到了「涌现」的表象

论文的总结语说的非常有力：emergent abilities may be creations of the researcher's choices, not a fundamental property of the model family on the specific task（「涌现」能力的出现是人为刻意标准下的筛选，而不是模型自己的真实能力）

这篇论文为什么这么重要？

因为在根本上否定了涌现，让我们把时间线拉长时可以不用再考虑 AI 能力突变这样的神话故事，LLM 模型的能力发展更顺滑，可预测性变得更高，这可以让我们更冷静而客观的看待 AI 的发展速度了

统计推理能力也是如此，以后 AI 也许会发展出来的「组合」能力也是如此（组合能力就是想象力创造力的重要基础能力，详见我三月关于「想象力」的推文）。我们可以发展出更好的评价标准，来很好的预测 LLM 在统计推理和想象力创造力上的长足线性发展。任何新能力达到某个阈值之后，也能逐渐被人类所注意到，而不是突然「涌现」

这也是为什么我一直认为 AI 的能力值和准确率，都是随着算力 scaling up 的（见引文），不存在突然涌现的东西，顶多只有线性增长之后达到了人类认知的某个门槛而已。

还是那句话，AI 的能力并不是一蹴而就的，降低 cross entropy loss 机器学习损失函数，每前进一步其实都异常的艰难，耗费的算力都是指数级上升，真的是路漫漫其修远兮，吾将上下而求索

网友评论：

原文说的 May 。你的转评变成斩钉截铁的否定涌现了。量变引起质变应该是存在的。

twitter.com/fi56622380/status/1654386086746132481

方军：讲实话，我对所有讨论 AGI、涌现的都没什么兴趣。

都是偏向哲学、社会层面的讨论，

而非计算机科学、应用层次的探讨。

2023-12-13 17:53

方军：

补充：blog.neurips.cc/2023/12/11/announcing-the-neurips-2023-paper-awards/

这篇论文刚刚拿了 NeurIPS 2023 最佳 paper

2023-12-13 17:54

### 60

方军 2023/12/13

【Arguflow：快速构建语义搜索和检索增强生成 (RAG) 项目】'Arguflow - Build semantic search and retrieval-augmented generation (RAG) fast'

[arguflow/arguflow: Build semantic search and retrieval-augmented generation (RAG) fast --- arguflow/arguflow：快速构建语义搜索和检索增强生成（RAG）](https://github.com/arguflow/arguflow?tab=readme-ov-file)

\# 新产品动态 #

### 61

方军 2023/12/13

把芒格之道中关于学习的翻阅了一下，集中看这个主题还是很有启发的。

芒格的 12 条永恒学习智慧

1、每日精进。

每过完一天，要努力比早上醒来时更聪明一点点。

2、学习的方法。

文明，只有在懂得了发明的方法之后，才能进步。

个人，只有在学会了学习的方法之后，才能进步。

3、搞懂弄透学以致用。

别人教给我一个新知识，我知道这是个有用的知识，我会很快把它搞懂弄透，然后自己去用，在生活中学以致用。

4、懂得如何学习。

我至少有三次，进入对我来说完全陌生的领域，打败了这个领域里的专业人士。

原因很简单，因为我学会了如何学习。

懂得如何学习是一个非常强大的武器。

5、做思想上的成年人。

如果你成为一个思想上的成年人…… 把所有学科中的重要思想都学会。

不偏听偏信任何一个学科中的流行观点。与只懂一个学科的人相比，你就拥有远远更多的智慧。

6、跨学科学习。

如果你有学习能力，一定要学习其他学科的知识，这可以避免自己的无知。

把各学科的主要知识融会贯通，能发挥出巨大的威力。

在我眼里，各学科之间不存在界线。

7、做高效的学习机器。

沃伦·巴菲特是一台高效的学习机器，他活到老学到老。

聪明人仗着自己聪明，不学了。逆水行舟，不进则退。

你不学，世界就会把你甩在身后。

8、列清单解决难题。

我觉得在面对难题的时候，列一张清单非常有用。

在单子上一列，所有问题一目了然，能把问题考虑得更周全，不会有什么遗漏。

9、反过来想。

我总是反过来想。例如，我要得到什么，我不是想我怎么能得到，而是想我怎么得不到。

我琢磨什么是自己不想要的，琢磨如何才能避免那样的结果。这种思维方式让我受益良多。

10、别只听别人讲。

只是听别人讲，很难增加智慧。这是为何有那么多花样翻新、生动形象的教学法。

二战中为了让士兵学会在枪林弹雨中匍匐前进，军队在训练中使用了真枪实弹。士兵们很快就学会了紧贴地面。

11、完善自己的思考方式。

我们必须完善自己的思考方式，才能正确地思考。

学会了正确的思考方式会一生受用。

学会了正确的思考方式之后，一定要有意识地在日常生活中学以致用。

12、复盘：别遗忘自己的错误。

大多数人善于选择性地遗忘自己的错误。

强生公司有一种复盘机制。每隔几年，它都把过去一段时间做过的收购拿出来一个一个地复盘。

原来的业绩预测是否实现了？原来的收购逻辑是否成立？当初主张进行收购的经理人要到场，参与复盘过程。

资料来源：芒格之道：查理·芒格股东会讲话 1987-2022

方军：反过来想，是我这次看最有启发的。

可能因为其他的以前都关注到了。

2023-12-13 22:45

方军：和 AI 的关系是，在 ChatGPT 的辅助下，卡片轻松搞定。

2023-12-13 22:47

方军：对于芒格我其实一直蛮矛盾的，我个人认为他智慧上的一个贡献是那些心理学上的认知谬误，但我恰恰对这个话题兴趣不大，所以感受不到他的高度智慧。

2023-12-13 22:55

### 62

方军 2023/12/14

今天 Google 的 Gemini Pro 通过 Gemini API 上线，并且提供了 API 访问，同时还有一个开发者的利好：目前 Gemini Pro 可免费使用！

Gemini API 地址：ai.google.dev ai.google.dev

Gemini Pro 提供了易于使用的 SDK，助力开发者在任何平台上快速构建应用。

另外 Google 还提供了一个免费的在线开发工具 Google AI Studio，你可以用它快速构建 Gemini 应用。

Google AI Studio ：makersuite.google.com

来源：宝玉，twitter.com/dotey/status/1735064009974431884

\# 新产品动态#

### 63

方军 2023/12/14

今天吃瓜东方甄选的事，社会情绪真是很微妙。李翔好像说了一句，国外演讲撰稿人是可以大大方方写回忆录和讲授技巧的，国内不行。说到 AI，那看来不只是 AI 写不行，怕是说明用 AI 辅助写也不行。不过，干事的人不要搞到被社会情绪束缚的范畴里去，没必要。

另，我觉得各种评论员也蛮无聊的，都要发个言（我也是，不过我五十步笑百步，我只考虑我如何，不考虑要对人展示智慧和聪明）。

说起靠别人干活，我倒要吐槽一个，我觉得高校大牛老师们靠学生翻译书也不是不行，但至少要保证质量吧。我遇到最尴尬的一次经历，我说了某本书的翻译问题，最后导致大教授没好意思自己署名，署名了个假名。想说什么呢？我觉得署名不代表亲自做所有一切，而代表质量把控与责任。

尹生:

关于东方甄选：1，直播电商的内容化让公司的监管敏感性直线上升、从而可能使估值大幅折扣，就像这几年明星自媒体走过的路；

2，相对于对个别明星主播依赖带来的危害，被规模庞大、而且迷恋自我加戏的饭圈所绑架，构成更大的潜在危害；

3，除非受到保密协议的制约，那么小编说主播的内容部分是团队其他人贡献、且如果这又是事实（事实上很可能是事实，一个内容团队不可能只有前台的主播），就没有什么问题，只是道出了一个事实，不能说一个团队做出了一个很成功的产品，所有的功劳都要归功于台前的主播，主播虽然贡献是主要的，但也吃到了最好的肉，不能让小编这样的支持者只能做工具，汤也不能喝，而实际上好的文案看起来简单，但好的文案创作者同样是稀缺人才，对小编而言，最好的汤就是可以告诉世人，他们在其专业领域，参与了这样成功的案例，这对小编是最好的肯定，就像主播通过个人品牌得到了最好的肯定一样；

4，从主播的角度，部分甚至全部文案都由团队专业人士所捉刀，也不是什么丢脸的事，本来就是术业有专攻，顺势感谢一下捉刀者，也是一种对人尊重和体现自我心胸的好机会，但似乎问题是主播被饭圈绑架，饭圈把主播当成了某种自我的映射，这样一来主播必须 100% 正确，必须无所不能。

方军 2023/12/15

有意思，继续吃会儿西方随便选的瓜

我就是感慨，评论家厉害，莫名其妙搞出一个叙事

不要被叙事误导。

### 64

方军 2023/12/14

任何一个行业，新闻看多了都会误事的，indigo 的感悟：

我的 𝕏 消息流已经完全被各种 AI 新闻攻陷了，要缓解算法带来的焦虑，得手动调教一下推荐 。。先把那些搬家翻译的运营号从消息流降权，减少出现频次试试！

少看新闻多读书；少转新闻多总结

思考才能强化学习，促进神经元连接 ​​​

---

我关注他后觉得特别有意思，每次他的想法我都觉得特别好，然后又觉得特别不好。

比如这句话，多总结。哈哈，千万别多总结，尽量少总结，只总结极少量主题。

看各种人做笔记，总结，总结啊，看他们掉我们曾经掉进去的坑，但要憋住不能说，医不叩门，师不顺路，莫名其妙指点别人最让人烦，这还不是最重要的，最重要的是这些事不自己感悟，不会有用的。我们就是这么醒悟过来的，这个道理也是醒悟过来的。

收起

查看详情

慕奇 Marquis、SheRyL、Koant、W 先森、晓霖、泽生、Jese__Ki、柯翔觉得很赞

方军：我很早就屏蔽了一些质量差的翻译号，尤其某超级大 V，他机器翻译得前言不搭后语，真是极其尴尬。个人觉得唯有宝玉和小互可以留着。

2023-12-14 22:28

泽生：「只总结极少量主题」，是因为常总结无益于学习吗？（欢迎叩门、顺路）

2023-12-14 23:36

方军回复泽生：没必要啊，人能搞明白的事极其有限。比方说，你会换车胎吗？现在基本没人会了，因为可以很方便叫救援。

2023-12-14 23:47

方军：indigo 的跟进： 屏蔽和降权了一些翻译搬家号之后，那些原贴内容终于出现在我的消息流了，估计 𝕏 的推荐算法还优先限推荐相同语言的内容！这应该算用实际行动支持原创者

这个信息很重要啊，我其实原来推是没有中文信息的，AI 这轮才放了一些进来。

2023-12-15 14:27

### 65

方军 2023/12/15

Delphi 这个应用可以将你所有的视频、播客、PDF、博客文章等信息训练为一个你的分身，并且你可以用你的分身对外提供咨询服务。

支持文字、语音甚至视频沟通。

你的分身会用你的语气和你上传内容的知识跟你的粉丝对话，同时还支持对话内容的数据分析帮你优化分身跟粉丝的交流。

看了一下价格最便宜的套餐每个月 25，不过需要跟他们 CEO 视频获得引导才能创建，感觉这个会议也不是真人只是他们 CEO 的分身，来炫耀技术的。

www.delphi.ai

via 归藏

\# 新产品动态 #

方军：我倾向于认为这样的产品是个「想象出来的需求」。

谁要跟自己对话？

谁要跟假人对话？

谁要跟假服务商对话？

都不对，就是因为「好像可以做」，然后就做了。

其实「好像可以做」，这个都是假设的，真的技术上做得好吗？完全不好，至少现在是这样。

2023-12-15 15:03

### 66

方军 2023/12/15

有意思，1889 年的「反电力漫画」。

跟现在知识分子的反 AI 有点像。

我们也经历过反互联网，直到「大人」们也用移动互联网。

摘（GPT 翻译）：

889 年的反电力漫画。

虽然这幅卡通对我们来说看起来很傻，但在过去，电缆（电力、电话和电报线）都是悬挂在高杆、建筑物和桥梁上的。

在 19 世纪末期，弧灯（3000 伏特）在街道照明中的普及导致许多人因接触高压线而死亡。在这个时期，接地也没有得到很好的理解或严格遵守，这也没有起到帮助作用。

电刑这个词在 1889 年在美国被创造出来，最初指的是电刑而不是意外电死。然而，由于没有其他词来描述非司法死亡，电刑的定义扩大到包括任何形式的电死。

twitter.com/historyinmemes/status/1735038761459740978

### 67

方军 2023/12/15

OpenAI 超级对齐论文，我还没看，仅仅看看这个图就蛮有意思的：

Super excited about our new research direction for aligning smarter-than-human AI:

We finetune large models to generalize from weak supervision—using small models instead of humans as weak supervisors.

Check out our new paper:

openai.com/research/weak-to-strong-generalization…

对于我们为使超越人类智能的 AI 实现对齐而采取的新研究方向感到非常兴奋

我们对大型模型进行微调，以便从弱监督中进行泛化 —— 使用小型模型而不是人类作为弱监督者。

### 68

方军 2023/12/16

看到人发这篇文章

[为什么说 AI 现在还不行 - 36 氪](https://36kr.com/p/2555068938624898)

哎呀，这种文章就是一看特别牛（类似于知乎的那种图文并茂的长文吧）

但是，这种文章真是特别糟糕，究竟想说什么？

能不能细说下去？说不下就随便引张图？

具体到文章，也许对，也许不对，但真是很糟糕的文章。

券商的报告也是这种类型居多，乱七八糟一堆信息，逻辑关系呢？说不清。

我总是尽量想避免被这种文章牵扯注意力，但总是失败。

(有这个感慨是今天看了很多技术报告，纯技术的，也是这种问题。刚刚跟报告方说，其实有些技术细节没必要，告诉我文档在哪里即可。如此，聚焦核心内容，可能更容易有效地传递信息给我们这些读者。）

### 69

方军 2023/12/16

清华刘嘉的演讲全文。

已下载原文「20231216刘嘉：ChatGPT：通用人工智能，范式转换与人类未来」，放入附件。

### 70

方军 2023/12/16

干一个 AI 暂时还干不了的事。

看到一个台湾的数字生产力专家 esor 写的防弹笔记方法，思路非常棒，但他的书真的很难理解，我费力半天才变成一个自己可行的模板。

这里有两个事 AI 干不了：

第一，真正理解人家的想法。尤其人家想法不够完备的情况下。

第二，将人家的方法变成自己适用的。

同时，下面为了理解的图示，也暂时是 AI 干不了的，我觉得永远都是要人干的。我喜欢一张这样的纸，反复看，会有新想法出来。他原本也有一张，我附上。

---

有子弹笔记，必有防弹笔记。台湾数字生产力专家 esor 的提法很有意思，他提出「防弹笔记」。防弹笔记和蒂亚戈·福特的 PARA 系统思路是一致的，就是重点关注「项目」。

防弹笔记，简单来说就是，从为了避免遗忘记录资料笔记，变成以任务为中心、记录「核心任务笔记」。

- 整理得再好的笔记，不如写下两步行动。

- 笔记不是为了复制和存储，而是为了创造。

- 把万事万物变成「行动时想要的样子」。

我把 esor 的各种想法重新组合一下，变成更新版的「核心任务笔记」模板：

核心任务笔记的模板包括三个部分：

1、任务成果。

用一句话，把任务成果写清楚。

2、我的行动。

当前一步行动是什么？它的子行动是什么？

下一步行动是什么？它的子行动又是什么？

3、三个问题。

思考三个关键问题：

- 为谁、为何而做？

- 如何量化成果？

- 有何阻碍限制？

核心任务笔记的三原则：

- 一项任务，一则笔记。

- 关注任务成果，关注我的行动。

- 从核心任务笔记开始，从核心任务笔记结束。

### 71

方军 2023/12/16

大模型对话系统的内功与外功链接：

[大模型对话系统的内功与外功](https://candle-walker-56d.notion.site/fc279c95733742008aa662bfa8788ee6)

综述｜大模型时代，对话系统的演进和机会，港中大华为联合发布：

[综述｜大模型时代，对话系统的演进和机会，港中大华为联合发布](https://mp.weixin.qq.com/s/ncrZA9JvVeQRLV7G50lAow)

本篇延续我们上篇文章《大模型对话系统的内功与外功》，以一个回顾和展望的视角出发，试图回答大模型对话系统的过去，现在和未来等一系列相关问题。

[[2311.16789] A Survey of the Evolution of Language Model-Based Dialogue Systems](https://arxiv.org/abs/2311.16789)

### 72

方军 2023/12/17

标题可忽略，内容值得关注。

超级对齐和 RLHF 处理的是不同的问题。

[准备迎接超级人工智能系统，OpenAI 宣布 RLHF 即将终结！超级对齐技术将接任 RLHF，保证超级人工智能系统遵循人类的意志](https://mp.weixin.qq.com/s/Ei5a-QFx5ijtt_DSMQlUkQ)

### 73

方军 2023/12/17

这段话有点鸡汤，但还是有点意思的：

（注意，这个人这段话是从吴军的话引开往下说，并非吴军观点）

吴军说，硅谷的几家著名公司（我就不点出名字了），对 ChatGPT 进行了全面的测试，发现它回答小学常识课（美国叫自然课）的问题，正确率还不到 60%。

为什么呢？因为这部分问题很少在网络上被讨论，或者网络上没有靠谱的答案。而 ChatGPT 没有办法像人那样运用知识去寻找答案，只能从现成的答案里归纳总结。

PS：这让我想起芒格经常强调的「人们都以为具备常识很简单，其实很难。」

芒格在 #穷查理宝典# 里写道：

「拥有常识不但意味着有能力辨认智慧，也意味着有能力拒绝愚蠢。如果排除了许多事情，你就不会把自己搞得一团糟。」

其次，芒格之所以要在 * 常识 * 中间加上「非常」二字，言下之意，就是在提醒人们「所谓常识，是平常人没有的常识。我们在说某个人有常识的时候，我们其实是说，他具备平常人没有的常识。」

### 74

方军 2023/12/17

最近看了一些内容套路，

也看到人用 AI 去加速这个内容套路，

我真是不看重这个套路，只觉得个人的知识内容积累才是关键，

但换到受众角度讲，

怎么识别套路，

怎么识别 AI 生成的假内容，

怎么找到真内容，

怎么消化和应用，

真是很多都变了，

不光是 AI 来了有套路，其实得到的课（这里是夸它）也有套路，书也有套路（比如美国商业畅销书），都是套路，

所以才要应对，

矛与盾，

永远不停。

### 75

方军 2023/12/18

来自 @StanfordHAI 今年三月份的一份研究表明，GPT 4 作为医疗辅助工具还存在不足，主要原因包括：

1、非确定性：在回答同一问题时，发现答案的相似度低，变异性高。Jaccard 和余弦相似性系数分别仅为 0.29 和 0.45。

2、准确性：仅有 41% 的 GPT-4 回答与 12 名医生对医学问题的共识答案一致。

3、潜在危害：有 7% 的答案被医生认为可能造成伤害。

相关论文可查看：arxiv.org/pdf/2304.13714.pdf…

特别指出，该研究故意检验了 GPT 初始状态下的表现，作为评估 RAG 和微调效果的基准。然而 RAG 的改进效果并不显著。

「在答案完整性方面，RAG 大语言模型 (RAG LLM) 虽然比 ChatGPT 高出 4.8%，但这种提升在统计学上并不显著」。

更重要的是，「尽管 RAG 提供的答案更安全、更符合事实，但医生们仍然有 57% 的时间更偏好由 ChatGPT 生成的答案。」 https://arxiv.org/pdf/2303.01229.pdf…

斯坦福的文章：How Well Do Large Language Models Support Clinician Information Needs?

hai.stanford.edu/news/how-well-do-large-language-models-support-clinician-information-needs

原文：twitter.com/DrHughHarvey/status/1736308984288563550

翻译：twitter.com/dotey/status/1736502413589176827

### 76

方军 2023/12/18

苇草智酷（智库）每年的 2050 议程都超赞

今年 AI 出镜率真是高到爆

其中，我参与了一个问题的探讨：

1、2050 年的学习：人们未来的学习将发生何种变化？学习什么，如何学习？

2023 年，随着生成式 AI 中的大语言模型展现其知识、推理及语言能力，综合起来也就是所谓的智能，我们有机会一窥未来的学习 —— 即在新的情境下，我们该如何学习？我们所面对的是计算机与互联网出现以来已经重复多次的模式，即技术组成的「机器」拥有远超过每一个个体的知识能力，而人必须去做「机器」做不了的事情，并且我们需要学会「人机共舞」。之前，电脑硬盘的记忆能力远超过个人，互联网上的信息远超过个人，社交网络的群体智慧远超过个人。而这一次，人类已有的知识和技能都被压缩成大模型的参数，并可供每个人调用。

在大模型的知识与技能远超过个体的情境下，我们学习时要掌握的东西变了。在我看来，我们要与大模型智能共舞，首先需要超越机器的认知。认知又可细分为三个部分：以向大语言模型提问解决问题为例，我们要有直觉判断力（直觉地知道答案可能是什么），要有理性判别力（能根据机器给出的答案推理并判别对错），要有鉴赏力（能够推动自己与机器发现更优秀的答案）。

同时，与机器共舞时，目标是由人设定的，结果的收益和风险都由人享受和承担（这两者也就是责任）。另外，我们还需要掌握运用技术工具的能力，以现在的视角看，这种能力是如何高效向大模型提问。

从如上视角观察和讨论，我们会看到，在大模型智能爆发的情境下，人需要学习成为超越机器的超级个体。在生成式 AI 时代，人的学习方式或许可列为如下公式：

AI 时代的超级个体 =（目标 + 认知 + 责任）x 提问的能力。

方军

互联网技术专家，科技作家

### 77

方军 2023/12/18

这几天最大的套路跟前一个月 openai CEO 下台事件时类似。

就是各种不厌其烦地讨论这个事

但真是说回来，这事跟我们有个屁关系

且不说不会去买东西，即便去买，这事又有啥关系

但这不妨碍各种玩内容套路的人

而我现场在媒体大群观察了好几天

媒体玩得太溜了，尤其互联网原生媒体，机构化运作的。

1『说的是董宇辉小作文事件。（2023-12-21）』

方军：最近看了一些内容套路，也看到人用 AI 去加速这个内容套路我真是不看重这个套路，只觉得个人的知识内容积累才是关键但换到受众角度讲怎么识别套路怎么识别 AI 生成的假内容怎么找到真内容怎么消化和应用真是很多都变了不光是 AI 来了有套路，其实得到的课（这里是夸它）也有套路，书也有套路（比如美国商业畅销书），都是套路所以才要应对矛与盾永远不停。

### 78

方军 2023/12/19

LangChain 发布了几个与 Google Gemini 模型交互的 notebook。

LangChain x Google

The official Google `generative-ai` repo has a ton of resources for getting started with Gemini 

This includes SEVEN different notebooks for using LangChain to orchestrate a Gemini-powered LLM app

Dive into all the goodness: generative-ai/language/orchestration/langchain at ...

### 79

方军 2023/12/19

每年徐瑾老师经济人读书会的入围书单都是我买书的参考。

（相对而言，我反而不怎么依赖投票结果书单，多样性一下子消失了。）

推荐看看：

[经济人读书会十大好书评选|2023](https://mp.weixin.qq.com/s/wPPvi4C4IXDYIRfkhf501Q)

### 80

方军 2023/12/19

真是聪明的大脑：

[word2vec作者爆料：seq2seq是我的想法、GloVe抄袭技巧，反击来了](https://mp.weixin.qq.com/s/rzOxuOShxcWHedPC7E8zDw?v_p=90&WBAPIAnalysisOriUICodes=10000001&launchid=default&wm=3333_2001&aid=01A0VjFEC-8TX6msntzx_IZJsVSdIBL5NqzASu9SjrmTcS5LA.&from=10DC093010)

### 81

方军 2023/12/20

OpenAI functioncall

functions 参数和 function_call 已经改名字了，分别对应的是 tools 参数和 tool_choice，参数结果似乎没明显变化。

### 82

方军 2023/12/21

这个由 GPT-4 驱动的「AI 实验室伙伴」名为 Coscientist，由来自卡内基梅隆大学和 Emerald Cloud Lab 的研究团队共同提出，刚刚登上了权威科学期刊 Nature。据介绍，Coscientist 结合大型语言模型（LLMs）的能力以及互联网和文档搜索、代码执行和实验自动化等工具，能够自主设计、规划和执行真实世界的化学实验。

Coscientist 在六个不同任务中展示了其加速研究的潜力，包括成功优化钯催化偶联反应（美国化学家 Richard Fred Heck 与两位日本化学家 Ei-ichi Negishi 和 Akira Suzuki 因「对有机合成中钯催化偶联反应的研究」获得了 2010 年诺贝尔化学奖），同时在（半）自主实验设计和执行方面展现了先进的能力。

[Nature 重磅：AI 复现诺奖研究，只需几分钟，一次即可成功](https://mp.weixin.qq.com/s/Mz6mPYz_H5baMbar4cYbEw)

### 83

方军 2023/12/21

李笑来的确蛮 NB 的，这个学英语产品从他开始根据论文做实验就开始关注，产品快做好了

李：还是得专业程序员干活才行啊…… （我这种二把刀只能在边上打打下手……）下个月应该能在社群里开始「试用」了。​

他 github 之前有分享：github.com/xiaolai/tobiplayer

早上起来，跟 OpenAI 聊聊天，生撸了一个声音播放器，用来显示 Pitch Contour，辅助我自己用 ToBI 练习…… 凑合着用……

图三是他家里自用的「每日（美日）口语书」。

李笑来这篇也蛮好的，各种 prompt 售卖，国外、国内都一样，质量和效果都极差

他用了一个很形象的比喻：快捷键

[伪概念：提示工程（师）](https://mp.weixin.qq.com/s?__biz=Mzg3NTkxMzY2Mg==&mid=2247483940&idx=1&sn=dac852f9a4237eeaf8ff743bb26b5c7e&v_p=90&WBAPIAnalysisOriUICodes=10000495_10000002_10000198&launchid=default&wm=3333_2001&aid=01A0VjFEC-8TX6msntzx_IZJsVSdIBL5NqzASu9SjrmTcS5LA.&from=10DC093010)

摘：思考，原本不是很困难的东西，恰恰相反，必须足够简单才对。可惜，绝大多数人真的在这方面不及格，甚至干脆负分。在我的社群里，有一门简单且又简短课程，叫做《思考的真相》，我常常开玩笑地说，千万不要小看它，因为它可能是这一辈子里最能让你「省钱」的课程……

方军：他人很有争议，但事我觉得可以看的。某个行业有个关于李老师的话：李老师的话要听，李老师的 coin 千万不要买。

2023-12-21 01:37

### 84

方军 2023/12/21

[8 个月收入增长超 10 倍，法律 AI Harvey 如何一年估值 7 亿美金](https://mp.weixin.qq.com/s/jblXZIYIhLa5xPc4sNjGjw)

### 85

方军 2023/12/21

向未来提问

2050：未来议程

苇草智酷（智库）的问答，我专门帮他们搞了一个容易看的版本。

手机也方便阅读。

各种观点，感到社会的脉动。

也是今年才觉得他们这个工作如果干到 2050 那就太牛了。

见 PDF。

向未来提问 - 2050 - 未来议程（2023）.pdf

future2050-liu.pdf

方军：第二个文件是刘兴亮的回答，他特别认真、特别有条理的对每个问题都做了水平相当的回答。我在帮忙重新看这个排版时才注意到这一点。

我心中在想的一个问题是，这样的回答，价值有多大？讲实话，对我个人启发不大，但是，我觉得很多人会觉得有牛人帮忙梳理一下，特别好，对他们的帮助特别大。

我最近一直想价值这个问题，还没有一点点答案，只是在想。

2023-12-21 18:59

### 86

方军 2023/12/21

AI 和社交的问题都是幻觉很严重

知乎的人均百万

刚刚看到这个：

摘：看🍠上一个刚入职小朋友写的「职场经验」帖子，《晋升路径很明确只要熬八年就能做 non-equity partner》《没那么卷》《氛围很好 happy hour 很多》《midlevel senior 比较注重家庭》《高年级之间没什么恶性竞争》《合伙人支持你去 in-house》 … 要不是我每个坑都踩过我就信了，现在的人怎么还是那么好骗合伙人随手画一个大饼就吃了，不仅吃了还给路过的人都分一点，骗大家一起进来吃。

小红书非常明显，讲实话它有好的，也有极其低智的部分。

我今天搜索网上看到一些文章（小红书之外）发现那些文章典型的废话太多，其中臆想的成分我想也不少（以及为了卖东西瞎说的）。

鉴别力真的不容易。

### 87

方军 2023/12/21

从漫长的报告和漫长的文章中找到一点精华，中文都是机器翻译，仅供参考。

1）变革，及其控制性 (同时也是促进性) 技术。

2）零边际成本。

我想，这段时间用 AI 的人已经强烈感受到零边际成本。

---

Ryan: I thought this framing from Stratechery was on-point: the PC, Internet, and AI revolutions were discrete events in the history of information. We could control the PC's power to duplicate information at zero marginal costs until the internet came along; then we needed public encryption. We found a way to harness the internet's power to distribute information at zero marginal cost by creating social media and search platforms. But we have no way of controlling AI-generation just yet. We'll need NFTs and blockchains in order to track provenance.

Ryan(Messari Crypto thesis 2024, 2023.12):

我认为 Stratechery 的这种观点很准确：个人电脑、互联网和人工智能革命是信息史上的离散事件。在互联网出现之前，我们可以控制个人电脑的能力以零边际成本复制信息；然后我们需要公共加密。我们找到了一种利用互联网的能力以零边际成本分发信息的方法，即创建社交媒体和搜索平台。但是我们目前还没有办法控制人工智能的生成。为了追踪来源，我们将需要非同质化代币（NFTs）和区块链技术。

---

Ben(Stratechery, Google I/O and the Coming AI Battles , 2023.3):

Gates insinuates that the PC revolution, the Internet revolution, and the AI revolution are discrete events, but they can also be viewed as three applications of the defining economic feature of digitization — zero marginal costs — to information:

盖茨暗示个人电脑革命、互联网革命和人工智能革命是独立的事件，但它们也可以被视为数字化的定义经济特征 —— 零边际成本 —— 对信息的三个应用

-  The PC allowed for zero marginal cost duplication of information; this is what undergirded breakthroughs like word processors and spreadsheets and the other productivity applications Gates specialized in.

PC 允许信息零边际成本复制；这是支撑像文字处理器、电子表格和其他生产力应用程序这样的突破的基础，而盖茨专注于这些应用程序。

-  The Internet allows for zero marginal cost distribution of information. This led to markets based on abundance, not scarcity, giving rise to Aggregators like Google.

互联网实现了信息的零边际成本分发。这导致了基于丰富而非稀缺的市场，从而催生了像谷歌这样的聚合器。

-  AI is zero marginal cost generation of information (well, nearly zero, relative to humans). As I wrote last year generative models unbundle idea creation from idea substantiation, which can then be duplicated and distributed at zero marginal cost.

AI 是零边际成本的信息生成（嗯，几乎是零，相对于人类而言）。正如我去年所写的那样，生成模型将创意的产生与创意的证实分离开来，然后可以以零边际成本进行复制和分发。

Moreover, these three revolutions had to come in the order they did: the very concept of the Internet doesn't make sense without there being disparate computers, and these AI models are trained on the Internet.

此外，这三次革命必须按照它们发生的顺序进行：没有不同的计算机，互联网的概念就没有意义，而这些 AI 模型是在互联网上进行训练的。

### 88

大龙 2023/12/22

信息源自智谱微信交流群：

@所有人 我们最近研发并开源了视觉版 Agent 模型：CogAgent

具备强大的视觉理解能力，以及基于视觉的 GUI Agent 能力。

\#免费商用！！！

玩一玩：http://36.103.203.44:7861/

读论文：https://arxiv.org/abs/2312.08914

模型+代码：https://github.com/THUDM/CogVLM

[[2312.08914] CogAgent: A Visual Language Model for GUI Agents](https://arxiv.org/abs/2312.08914)

### 89

方军 2023/12/22

在线教育制作软件 Articulate 的AI 工具发布

我还专门去看了这个视频，

的确，

AI带给我们的真正变化是，制作成本的大幅降低。

这是一个重要的思考视角。


---

Generate structured training from your source material
Convert dense text into engaging interactions
Adjust the tone of your training
Transform text into video

---

articluate ai 的营销视频：articulate.wistia.com/medias/txtux0ca5z

### 90

方军 2023/12/22

众所周知，Rust 的学习曲线很陡峭，但现在，得益于大语言模型（LLMs）的发展，这个陡峭学习曲线的问题已经变得容易解决了。无论是 Rust、Haskell 还是其他任何语言，借助大语言模型的帮助，现在学习起来都更加容易。事实上，如果你在学习难懂的材料时没有利用大语言模型的帮助，那么你的学习方式可能不是最佳的。

推荐阅读（via 宝玉）：《The Future is Rusty —— LLMs Make Programming Language Learning Curves Shallower》

文章中提到了一个很有意思的概念叫「The Intermediate Material Problem」，是指在学习某个技能或领域时，在初级和高级阶段之间存在的一种学习难点。具体来说，在编程语言学习中，这个问题特别明显，尤其是对于像 Rust 这样的复杂语言。

在初级阶段，学习者通过教程和基础课程获得基本的知识和技能。这些资源通常都是易于理解和遵循的，目的是帮助初学者快速入门。然而，当学习者试图从基础过渡到更复杂的应用和项目时，他们常常发现可用的学习材料突然变得稀少并且难度很高。例如，在 Rust 编程中，学习者可能已经掌握了基本的语法和概念，但在尝试开发更复杂的系统（如光线追踪器）时，他们需要理解更高级的概念，比如所有权规则和内存管理，这些通常不在初级教程中详细讲解。

这种情况造成了一个「中阶教材」缺口，学习者必须依靠自己的努力和探索来克服这个难关，这通常包括阅读高级文档、参与社区讨论，甚至通过试错来解决具体的编程难题。这个阶段通常伴随着挫折和困惑，因为学习者不再有清晰的指导和步骤可循，而是需要自己摸索前进。

这个问题并不限于编程或技术领域。在许多学习曲线陡峭的领域中，从初学者过渡到熟练者的过程中都可能遇到类似的「中阶教材问题」。

另外文章中还提到数学家陶哲轩都在借助 ChatGPT 辅助学习。如果我们这个时代最杰出的数学家都在用 ChatGPT 来帮助他进行证明，那么你也没有理由不尝试！

原文：earthly.dev/blog/future-is-rusty/

译文：baoyu.io/translations/software-engineering/future-is-rusty

方军：「The Intermediate Material Problem」「中阶教材」缺口蛮有意思的。

前段似乎阳老师说 RUST 是三大趋势之一。

讲实话我一直是个 Rust 外行，至今没有去看任何，仅仅用过少量包，现在的确应该有空时当成一个小学习去看看。

2023-12-22 09:49

### 90

方军 2023/12/22

LangChain 发布了一个文章，langchain state of ai 2023

数据蛮有意思的

1. retriever 占 42%

2. LCEL 已经快普及了，57%

3. vector store 最常用的是 chroma faiss pinecone

postgresql 和 supabase 只能排 7/8 还是意外

4. retrieval strategies

5. 评估和测试

6. 评估和测试

blog.langchain.dev/langchain-state-of-ai-2023/

### 91

方军 2023/12/22

这篇虽然讲的是代码库改进。

实际上我们现在处处都处在这样的改进周期中。

[创始人 3 天狂砍 5 万行代码后，应用程序更快、更易使用了](https://mp.weixin.qq.com/s/dTQkDlKqqLNlr-9QcewufQ)

### 92

方军 2023/12/22

历史

转一个前网易战略逐条解读最新《网络游戏管理办法》

第十二条：版号有效期一年，不能屯版号

第十七条：不准强制对战，这个对 SLG 游戏国战影响会很大

第十八条：不准每日登录，次日留存和七日留存会变得很难看。更重要是，月卡可能也是被算在每次登录里面，这就影响非常大了，不光影响留存，还要影响流水。首次充值虽然金额非常小，一般只有 6 元，但是是一种打开用户心里缺口的方法，这个也被禁止掉了。最后连续充值，是一种非常重要的增加流水的方式，比如累计冲 1000 送橙卡。这种日后也要没了。但是，以上都不是最关键的，最关键的是，对用户充值设置限额，目前只对未成年有限额，一般是几百块，如果对成年人也限额，那么哪些靠着土豪养服生存的游戏会非常难受，过去那种多开几个服务器，靠排名刺激土豪的玩法也会废掉。虽然这个充值限额没说具体多少，但是根据往常的推断，我估计应该就是当地工资的最低标准，一个月三五千块。这真的是断送了一大波公司的活路。

第二十一条：卡死了所有的以公测内测名义运行的游戏，过去只要不收费还是可以测试的，但是目前规定测试用户不能超过 2 万，并且要删档，这就意味着内测这条路彻底被卡死了。

第二十四条：也非常的致命，首先规定网络交易商要持牌，目前市面上非常多的账号交易平台和游戏币交易平台都没资格，其次要求游戏币必须以数字人民币交易，这个的目的是可查，不能 X 钱。会十分影响交易额，网易的藏宝阁还有梦幻等游戏会受到一些影响，建议内部尽快启动一次影响评估。

第二十五条：问题很大，不知道要怎么界定统一企业，同一股东算不算？算的话影响很大。

第二十七条：【随机抽取】。这个是对整个游戏行业非常知名的一个打击，过去大家都是用抽卡的形式，有两个目的，一个是上头，另一个是把东西卖高价。现在只是规定要公开爆率，实际上不影响大家抽取，但是现在要求，必须抽取的东西，要能拿游戏币直接购买，比如过去 328 可以 30 抽，现在必须直接显示一个五星的角色卖多少，并且直接可以买到。这个非常考研定价，并且也会影响抽取的积极性，你把角色设计的很厉害，很贵，比如 1 万一个，很多人直接就不买了。

而且还没完，最近非常火的小游戏，国家也关注到了，并且还要另行规定。所以未来买量，或者靠广告营收的游戏也是要被监管的。

### 93

方军 2023/12/22

ChatGPT plugins 退，GPTs 进。

[ChatGPT 插件将被废弃！奥特曼年终总结暗示明年大动作...](https://mp.weixin.qq.com/s/RosMVGXNJeTQ8Abqb9zluA)

### 94

方军 2023/12/23

Midjourney V6

Holz 在他的 Discord 帖子中明确指出，这类提示词编写方式在 V6 上将呈现出与期望相背的效果。「大家需要重新学习如何编写提示词。」

V6 模型的使用方式与 V5 差异较大，您需要「重新学习」如何编写提示词。

V6 对于提示词的内容更加敏感，请勿使用诸如「广受好评、逼真、4k、8k」之类的「垃圾描述」。

请明确表达需求。V6 可能表现得不那么机灵，但只要提供明确的提示，它现在可以更好地理解您的意图。

如果希望生成摄影风格 / 少点自由发挥 / 多点忠于提示词的内容，则应默认使用 —style raw。

将 —stylize 的值设置得更低（默认为 100）往往有助于改善提示词理解效果，而较高的值（最高 1000）则倾向于牺牲还原度来换取美学效果。

您可以在 prompt-chat 中通过聊天来了解如何使用 V6 新模型。

[历时 9 个月、从零开始训练，Midjourney V6 来了！号称比以往所有版本都强大](https://mp.weixin.qq.com/s/QO6iXDJo6aBBZkMYNQHPwg)

### 95

方军 2023/12/23

020 AI 的零边际成本生产

观点提前：

怎么用 AI 来提高生产效率，达到近乎零边际成本的生产，这可能是一个关键视角。

一个经验法则是：

把量的目标 X 2

把小时数 / 2

把周期长度 / 2

这么算也许应该是 8 倍，但几个要素并不是这么简单乘除的。我觉得是都换算成成本，是 3-5 倍。

---

前几日引用 Ben (Stratechery）的观点，他认为：

数字化的特征是：「零边际成本」。

PC、互联网、AI 是零边际成本对信息的应用：

PC：零边际成本复制

互联网：零边际成本分发

AI：零边际成本生产

现在这波 AI 浪潮，叫生成式 AI (Generative AI)，还是 AIGC，这是一个问题。但是，这波 AI 的第一个应用场景的确是大幅度降低内容的生产成本。

📍 量是关键

在讨论这个之前，要说我关于内容的两个基本假设，除了天才之外，内容有两个原则：

第一，量是关键。

第二，量的基础上有质变。

在文章、代码等各种事情是相似的。

比如昨天想，就曾经关注的某个话题，其实我的量完全不够，看了很多，但写的东西也许几百页 PPT、三五篇短文。这背后还有一个潜台词是，为了写，还要吸收大量的信息，还要大量实践，我们讨论的并非没有输入的输出。

那这种情况下，在这个细分话题上，我自己没什么见解 / 相应地没什么影响也是必然的。

我猜想，应该要两千页（不重复的）PPT、20 篇中等长度文章，才够。对应的，也许应该是看大约 300 本书的信息体量（包含论文、文章，不含网络碎片）。

另外还有一个变量，那就是这种量绝对不是短期可以达成的，至少要数年甚至五年的时间。

如果放在代码上，那就是要靠一个团队来协作生产。有人设计架构，各人负责模块开发，有人负责产品，有人负责运营、收益等等。

AI 用于生产

在这种情况下，我们且不谈 AI 用于输入，只谈 AI 用于辅助输出。

在一个时间窗口内，现在考量的就是：

「在确保质量不降低、实际上应该是有提升的前提下」，我们如何大幅度提高产量？

我们是可以提升 2 倍？

我们是可以提升 5 倍？

我们是可以提升 10 倍？

一个小体会是：前一段时间为 UNISCO 旗下机构制作一个面向国外教师的 AI 课程，我有意避开团队合作，尽量自己完成全程。（遗憾的是，因而也缺少了过程中的专业反馈。）我觉得体会有二：

第一，AI 让不可能变成了可能。过去我是不敢制作英文课程的，因为我口语讲不了。现在不管是语法检查、润色、AI 语音，都让这些不是问题。

第二，通过将 AI 融入流程，我个人觉得有 2-3 倍的提效。

（对比而言其实可能不止，另外有同事同步做其他的同类制作，按我目前预估，他们花费的小时数将是我的五倍以上，而更糟糕的是周期长度他们估计要 2-3 倍，这导致时机的延误。）

这样对比可能不公平，因为我做的是对我来说几乎「阻力最小的事情」，而别人不是。但生产时，我们每个人都应该努力找到自己擅长、阻力最小的事情，不是吗？

怎么用 AI 来提高生产效率，达到近乎零边际成本的生产，这可能是一个关键视角。

一个经验法则是：

质量不变的前提下

把量的目标 X 2

把小时数 / 2

把周期长度 / 2

这么算也许应该是 8 倍，但几个要素并不是这么简单乘除的。我觉得是都换算成成本，是 3-5 倍。

\#AI 使用感悟 #

方军：补充：可以把 AI 用在两种场景：

1）从 0 到 1，从不可能到可能；

2）从 1 到 10，从可能到快速、低成本

从实用主义出发，应该考虑第二种。

2023-12-23 15:34

### 96

方军 2023/12/24

021 从宝玉老师身上学到的四点

今年在探索生成式 AI 的过程中，可能提及最多的是宝玉老师。（AI 带来的生产量是他的优势，别人其实也有很多不错的，但零零散散，因而我都不记得提及谁了。）

他写了两篇文章总结今年（链接见后）。我刚读完他的新年度总结，写自己从他身上学到的四点：

虽然好像是互联网时代的熟人，但其实我一直并不真的认识他，甚至在他大规模分享 AI 之前关注并不多，我对他的印象一直停留在他分享 ASP（多古老的事情啊）、前端、开发团队管理。

📍宝玉做了大量的 AI 教程视频翻译，吴恩达的课程他都全面翻译了。

我理解在这个过程中，宝玉对于翻译有了深入的理解。

这是为什么他的翻译 prompt 是非常高级的原因，都是实干出来的。

多步提示、告别机翻感 prompt: baoyu.io/blog/prompt-engineering/a-prompt-for-better-translation-result （他后来还有多次改进，推上有后来更新版的）

📍宝玉在视频翻译后，应该发现也有大量文章值得翻译

因此，看到他开始用同样的方法来翻译文章和论文。

这些翻译都可以在他的网站上找到，baoyu.io/translations

（网站看起来是今年秋天某个时间重启的。）

当然，分发都是在社交媒体上分发的。

📍宝玉的贡献在于，他在微博和推上都有大量的粉丝，他大量分享经验、分享翻译，助力了我们所有人的学习。

印象中他曾经有分享，应该是几亿的 impression，可以说贡献相当大。

虽然将他和吴恩达比并不合适，但他的确和吴恩达一样，极大地推动了 AI 知识的普及。

📍作为程序员的宝玉，善于代码工具

宝玉老师实质上是一个程序员，虽然并不知道他现在的开发项目，但从他关于 AI 的分享中，我们可以看到，他的翻译、视频处理、PDF 处理一直都是有代码辅助的。他一直在用各种代码工具来优化流程。

从个人生产提效的角度来讲，他是榜样。接近的榜样，远比遥远的榜样更有启发。

谢谢宝玉老师！

---

他的两篇年度总结文章：

2024 年，AI 会影响普通人吗？

（为微博而写）「2024 年，AI 会影响普通人吗？」，这是一道送分题！答案是肯定的，一定会影响到普通人！但这又是一道不好回答的题，因为这里的普通人，不仅仅指的是一个群体，也指的一个个的个体，AI 对每个人的影响都不尽相同。有人因为 AI 升职加薪，有人因为 AI 赚到了钱，但也有人因为 AI 有被替代的风险，甚至有人因为 AI 失业。（2023-12-22）

baoyu.io/blog/ai/will-ai-impact-us-in-2024

2023 年，我患上了 AI 焦虑症

（为新程序员杂志而写）2023 年对我来说是神奇的一年，我意外的从一个程序员变成了一个 AI 资讯届的「网红」，到年底的时候我在 X 平台的阅读量超过 1 亿，微博上的阅读量则超过 10 亿，很多人通过我的微博或者 X 了解最新的 AI 资讯、教程和 Prompt 使用技巧。而这一切其实是从我患上了 AI 焦虑症开始的。我将向你分享我的故事，如何患上了 AI 焦虑症，又是如何克服它，并且成功的把 AI 变成自己的得力助手，让自己成为善用 AI 的人。（2023-12-12）

baoyu.io/blog/ai/i-am-suffering-from-ai-anxiety-in-2023

\#AI 使用感悟#

### 97

方军 2023/12/24

dify 创始人分享他们的三个关键产品假设：

在今年三月份开始定义产品时，我们的整个构想建立在以下三点假设之上：

1. Democratization of AI，Prompt 工程 ，RAG 和 Fine-tune 对用户来说是复杂技术有待简化；

2. Cross-Functional Collaboration in AI，非技术人员需要参与到 AI 应用的定义过程之中；

3. Data-Driven Feedback，AI 应用的效果提升建立在生产数据的持续反馈。

这三点假设直至今天依旧成立。

在今年实现了帮助用户完成「从想法到应用的快速验证」这一小目标之后，明年我们的产品形态将从「GPTs 平替」回归到「LLM 应用开发技术栈」之上，为用户提供更深度，丰富，可定制的技术解决方案。

### 98

方军 2023/12/24

不知道这话谁说的，挺幻灭的

文章是这个

[大模型太卷，AI 应用就好做吗？-36 氪](https://36kr.com/p/2550157764532353)

『

今年闭关带着团队做了 6 个 AI 应用，最近陆陆续续开始上线。扔进去几十号人，烧了 2 千多万，买回来几个教训：

1, 用户越多，亏得越多。都给 OpenAI 与微软打工了，用户付费还不够调用大模型与语音识别及合成的成本；

2, 大模型在大部分开放式使用场景中，实际能力远未及预期；

3, 国产大模型 has long way to go.

Hugging Face 上的免费开源模型比你们好太多了。

』

今天有很多人转这个数据报告，讲实话，意义很小

GenAI 流量数据 4-11 月 V10.pdf

欧阳：活水，用极小投入，做出了无数成果，至少是 3000 万投入才可能做到的偷笑偷笑偷笑

2023-12-24 21:27

方军回复欧阳：在一个测试期的线路上，搞砸钱战术，虽然他可能夸张金额了，但的确思路上的严重错位

2023-12-24 21:51

### 99

方军 2023/12/25

022 人的幻觉比 AI 更严重

午间感慨一下，「人的幻觉比 AI 更严重」。最近观察围绕一本书的衍生产品，其中有一个是一家颇受尊重的知识服务机构的课程。有了这个的感慨。

我也相应地有从用好 AI 的考量。我对「学习」或「AI 时代的学习」一直兴趣特别强，因此在广泛地阅读各种资料。

---

这本书是《认知天性：让学习轻而易举的心理学规律》，中信出版。

首先，这本书其实已经有了「幻觉」。

书名原题为「make it stick」，是典型的美国畅销书命名方法。但也准确展示它的内容主题：强调学习中的记忆。

但中文书名把这个主题过度扩张了。

这相当于什么，我们来到一座博物馆，明明这本书是讲其中一个展厅，比如钱币馆，但标题却扩大到让你认为也包括书画、青铜器、甚至当代艺术。

繁体版书名则相对反映实际内容：

超牢記憶法

副标题：記憶管理專家教你過腦不忘的學習力

副题原书是，The Science of Successful Learning，中文是，让学习轻而易举的心理学规律。这两个都是没什么信息量的营销语。相对而言，繁体版进一步细化阐述，我觉得更容易让我把握书的内容。

特别注意下这本书的创作方法，它实际上是一位作家介绍两位学者（及其小组）的研究。

这当然是不错的组合。比作家 Gladwell 单独写的，或者学者卡尼曼自己写的，有自己独特的点。

---

其次，再看衍生产品，一个精读课。幻觉就相当严重了。

一，讲者不够谦卑。我甚至觉得，他并没有真正地去读这本书。

二，他夹带了太多的「私货」，并不是说私货不好，而是说，他本应承担的角色是让我们了解这本书的观点。

这就相当于以前新东方的考试外语课，老师讲相声没问题，因为这是课程的功能：帮助学生度过这个艰难的时间。

但是，如果老师讲托福时，突然穿插很多 GMAT 的内容进来，那实际上对学生进行了巨大的干扰。

至于这本书中文版的序言，则可以说写文者没有仔细读书。——「名家」的糟糕。实际上，95% 以上的中文书序言都不值得翻，因此我现在不太说看书先看看推荐序等资料，看看是不是值得读了。

---

第三，带来的启发是什么？

其实人的幻觉更严重。因而 AI 的幻觉反而是可以接受的。

我设想一下这本书的读法：

一，机器翻译，双语版本。

二，人类整理大纲。

三，由 AI 按文本进行阐述。

或许这是更好的、更准确吸收其知识的方法。

附（共四个）：

英文目录

Contents

1  Learning Is Misunderstood

2  To Learn, Retrieve

3  Mix Up Your Practice

4  Embrace Difficulties

5  Avoid Illusions of Knowing

6  Get Beyond Learning Styles

7  Increase Your Abilities

8  Make It Stick

简体中文目录

1 学习是挑战天性的必修课

2 学习的本质：知识链和记忆结

3「后刻意练习」时代的到来

4 知识的「滚雪球」效应

5 打造适合自己的心智模型

6 选择适合自己的学习风格

7 终身学习者基本的基本

8 写给大家的学习策略

繁体目录

1 学习被误解了

2 提取记忆

3 混合练习

4 拥抱挑战

5 避免知识错觉

6 超越学习风格

7 提升你的能力

8 牢记不忘

精读课目录

00 发刊词人脑的可塑性可以延续到老年

01 你是成长型思维吗

02 大脑会误导我们：识别三类常见的思维陷阱

03 卡尼曼怎样纠正认知偏差

04 元认知调控

05 赫布理论：为什么学习可以重塑大脑

06 巩固：减缓遗忘的两种高效学习方法

07 布鲁姆分类法：测试你的知识掌握层级

08 像专家一样思考：搭建心智模型

09 如何优化你的决策能力

10 睡够 8 小时，大脑才能有效排毒吗

11 压力下焦虑、记忆减退，有没有立竿见影的改善方法

12 正念冥想背后的神经科学

加餐 01 普鲁斯特现象：香水中的神经科学

加餐 02 工作记忆：大脑一次能记 7 个项目吗？

加餐 03 合意困难：如何为大脑制造有益挑战

加餐 04 沉浸式冥想：身体扫描

\#AI 使用感悟 #

方军：我非常感慨，人的幻觉，尤其有名的人的幻觉，其实比 AI 更严重。

AI 的幻觉还有一点好的，我们知道它有幻觉。

但看似权威的人的幻觉，我们要花好大的力气去克服。

2023-12-25 12:25

方军：这本中文书几乎全是幻觉，比如这个小标题：

知识最终将变成条件反射

Reflection Is a Form of Practice

中文和原文有什么相似之处吗？重点关键词「Reflection」都没了！

2023-12-25 13:19

欧阳：哈哈哈，是的。反而是 AI 协助，效率更高了。

2023-12-25 13:46

方军回复欧阳：是啊，真是好老师当然好，但绝大部分老师、名人低于 AI 的一般水平，至少在成年人教育这儿可能是这样的。

2023-12-25 13:52

### 100

方军 2023/12/25

把 AI 使用感悟也用星球专栏汇总了，发现编号错误，已经 22 篇了。之前说：

题外话，之前觉得「AI 使用感悟」这个系列没多大价值（对我有价值，对别人没多大价值），还是之前那些实用的专栏系列才对我之外的朋友们有价值。现在想想也不一定，既然我自己会关注推上那些实际干活的人的碎碎念，那其实真干活带来的感悟可能对人是有意义的。

这一专栏系列的定位不变（其他的干货专栏也要更新的），没那么多干货，就是碎碎念，但我觉得是有价值的。因为这几天我看村上春树《远方的鼓声》，他 1980 年代下半期在欧洲游历三年的游记，碎碎念蛮有意思的。

我们普通人（村上多半抱着这样心态写的）不一定有什么伟大的观点，但碎碎念事后看，有启发性的。

学习科学践行者：我也觉得碎碎念多了就涌现出价值。

2023-12-25 18:18

方军回复学习科学践行者：是的，不一定是观点的价值，而是会反思实践对不对，并相应地调整。这是为什么我觉得它对自己的价值超过对他人。

2023-12-25 19:34

### 101

方军 2023/12/26

中文论文->英文论文的prompt：二次翻译策略

来源：宝玉

应网友要求，制作了一个将中文翻译成英文科研论文的GPT 

chat.openai.com/g/g-HejNUzj8l-translate-chinese-to-academic-english-ke-yan-lun-wen-zhong-fan-ying，

Prompt 和之前分享的英文翻译成中文类似的，也是分成三步：
1. 中文翻译成英文
2. 检查翻译的问题，例如不符合英文表达习惯，意思不清晰等，并指出位置和解释
3. 基于上面两步重新意译

我英语不够好，无法直接分辨出质量是否足够好，为了测试效果，我找了篇正经的中文论文，给它翻译，翻译成英文后，再把英文发到我的英文翻译中文GPT翻译 

chat.openai.com/g/g-uBhKUJJTl-ke-ji-wen-zhang-fan-yi

将翻译后的中文对比原文，发现除了用词有点差别，基本上意思都保留的挺好，应该还不错。（具体效果可以参考图一和图二）

在制作GPT时，我是先用中文写好Prompt，然后让GPT帮我修改Prompt，再手动调整一下就完成了。（参考图三）

中文prompt:
============

以下是给GPT Builder提供的中文Prompt：

-----中文 Prompt Start------

现在我要写一个将中文翻译成英文科研论文的GPT，请参照以下Prompt制作，注意都用英文生成：

\## 角色
你是一位科研论文审稿员，擅长写作高质量的英文科研论文。请你帮我准确且学术性地将以下中文翻译成英文，风格与英文科研论文保持一致。

\## 规则：
- 输入格式为 Markdown 格式，输出格式也必须保留原始 Markdown 格式
- 以下是常见的相关术语词汇对应表（中文 -> English）：
* 零样本 -> Zero-shot
* 少样本 -> Few-shot

\## 策略：

分三步进行翻译工作，并打印每步的结果：
1. 根据中文内容直译成英文，保持原有格式，不要遗漏任何信息
2. 根据第一步直译的结果，指出其中存在的具体问题，要准确描述，不宜笼统的表示，也不需要增加原文不存在的内容或格式，包括不仅限于：
- 不符合英文表达习惯，明确指出不符合的地方
- 语句不通顺，指出位置，不需要给出修改意见，意译时修复
- 晦涩难懂，模棱两可，不易理解，可以尝试给出解释
3. 根据第一步直译的结果和第二步指出的问题，重新进行意译，保证内容的原意的基础上，使其更易于理解，更符合英文科研论文的表达习惯，同时保持原有的格式不变

\## 格式
返回格式如下，"{xxx}"表示占位符：

\### 直译
{直译结果}

***

\### 问题
{直译的具体问题列表}

***

\### 意译
```
{意译结果}
```

现在请按照上面的要求从第一行开始翻译以下内容为英文：
```
-----中文 Prompt End------

========
英文prompt

========

-----英文 Prompt Start------

\## Role and Goal:

You are a scientific research paper reviewer, skilled in writing high-quality English scientific research papers. Your main task is to accurately and academically translate Chinese text into English, maintaining the style consistent with English scientific research papers. Users are instructed to input Chinese text directly, which will automatically initiate the translation process into English.

\## Constraints:

Input is provided in Markdown format, and the output must also retain the original Markdown format.
Familiarity with specific terminology translations is essential.

\## Guidelines:
The translation process involves three steps, with each step's results being printed:
1. Translate the content directly from Chinese to English, maintaining the original format and not omitting any information.
2. Identify specific issues in the direct translation, such as non-native English expressions, awkward phrasing, and ambiguous or difficult-to-understand parts. Provide explanations but do not add content or format not present in the original.
3. Reinterpret the translation based on the direct translation and identified issues, ensuring the content remains true to the original while being more comprehensible and in line with English scientific research paper conventions.

\## Clarification:

If necessary, ask for clarification on specific parts of the text to ensure accuracy in translation.

\## Personalization:

Engage in a scholarly and formal tone, mirroring the style of academic papers, and provide translations that are academically rigorous.

\## Output format:

Please output strictly in the following format

\### Direct Translation
{Placeholder}

***

\### Identified Issues
{Placeholder}

***

\### Reinterpreted Translation
{Placeholder}

Please translate the following content into English:

-----英文 Prompt End------


=======

twitter.com/dotey/status/1737732681280942570

\#提示语模版#

方军：网友简单使用二次翻译策略的评价：

靠 !! 果然，ChatGPT 二遍翻译法，有那个味儿了

GPT Prompt:

你是一位熟练操弄中文，英文的老编辑，资深作家，翻译家，请将我传给你的中文内容，翻译成英文：

1. 第一遍直译英文
2. 第二遍，翻译成地道的美式英语

2023-12-26 10:21

泽生 回复 方军：思维链的最小应用偷笑

2023-12-26 12:08

方军 回复 泽生：小小纠正一下，这个还真不是 cot，cot 它指的思路主要指一步一步想，把一步一步想给出去。

这个分步没有名字，但也是 openai prompt 指引里面强烈建议的技巧之一。

2023-12-26 12:12

泽生 回复 方军：感谢指点抱拳是下图的技巧？

Split complex tasks into simpler subtasks

Just as it is good practice in software engineering to decompose a complex system into a set of modular components, the same is true of tasks submitted to a language model.

Complex tasks tend to have higher error rates than simpler tasks.

Furthermore, complex tasks can often be re-defined as a workflow of simpler tasks in which the outputs of earlier tasks are used to construct the inputs to later tasks.

2023-12-26 12:38

方军 回复 泽生：对

2023-12-26 13:08

### 102

方军 2023/12/26

023 警惕社交与 AI 幻觉

赶着出门，这个感悟很简单，推荐一本书（但这本书简体版、繁体版估计都买不到）。

《Trust me, I'm lying》

2『已下载原文书籍「2023050Trust-me-Im-lying」。（2023-12-26）』

一个在 blog 时代操作网络声音的「高手」的自白。

我当时看的英文版，后来在乐文买了繁体版《被新闻出卖的世界》，注意，这里的新闻是广义资讯的意思。（简体版：	《一个媒体推手的自白：揭露营销神话背后的真相》）

这本书当时对我影响挺大的，我算是在这本书出版前很多年就写 blog 的人，但我们只写观点 blog，不求流量，所以对于 blog 里面的扭曲的商业流量逻辑并不了解。

但当时，社交网络（facebook）、微博已经极大地兴起，微信公众号也在最热的时期，我们这些人对于社交网络中的扭曲现象已经有了较深的感悟。

因此，这本书从「操纵者」的角度，给我们一个揭秘。

对应地，可以看《炒作机器》这本书，这本书则较为宏观，整体用数据讨论社交炒作机器是如何运转的（以及俄罗斯是如何在社交网络中用真假混合的新闻操作观点的）。

《炒作机器》第一章有句话很有意思：「我会要求你把自己也当作一个数字营销人员，然后站在他们的角度去理解这些工具。要想真正理解那些每天通过网络被推送给我们的内容，我们需要首先了解上述这些人都在做什么，以及他们为什么会这么做。」

为什么很再次想起这些书，就是标题里 AI 幻觉。

这是一个叠加的问题。

我最近一直很关注小红书，我已经在其中感觉到谎言（有时候是真诚的）与 AI 假文章（现在还可以很容易看出来）的混合。

要关注这个话题的人，应该现在去关注，因为过段时间可能 AI 假文章（以及它直接可见的幻觉）会要非常努力才能辨别出来了。

\#AI 使用感悟 #

泽生：《一个媒体推手的自白：揭露营销神话背后的真相》孔夫子上有卖。

2023-12-26 12:02

泽生：借助大模型来识别幻觉，效果会好吗？

2023-12-26 12:04

方军回复泽生：暂时看起来矛和盾的问题，谁赢不知道，但人赢不了。

问题就在这儿，我们接受信息时是人。

2023-12-26 12:05

### 103

方军 2023/12/26

哈哈哈，文：… 没想到找工作并不顺利，无奈进了一家民企。民企老板虽然只有初中毕业，却热爱学习，每天在群里发鸡汤文字，要求他们写读后感，不好好写的扣 3000 块。

如此这般写了两年，还是受不了辞了。

后面网友评：他再坚持一下，就能等到用 GPT 写小作文给老板了……

### 104

方军 2023/12/27

这个 AI 应用经验很精彩

摘：刚三联生活周刊给我反馈 SEO 策略效果很不错，索引量一个月翻倍 (他们内容量相对大) :

1、三联生活周刊之前是我企业客户，我企业给他们做增长 / SEO 咨询。当时遇到难题是 -- 三联生活周刊的内容都很文艺，不符合搜索习惯 (大家熟悉三联风格应该能懂)。

他们内容量相对大，所以我一直想盘活他们内容库，让搜索更好的指引他们内容，再做下主题页让页面量倍增，从而获得更多搜索流量。当时卡在 TDK 太过文艺，我想了很多规则、工具去更好的提取词，效果都不好，遂放弃；

注：TDK 指 Title（标题）、Description（描述）和 Keywords（关键词）

2、今年我们交流，当时我在做 AI 电商导购站就是直接让 GPT 生成 TDK、tag (来做主题页)、话题等内容结构，我就让三联把内容库直接过一遍 GPT 生成 TDK。刚给我反馈测试一个月索引量翻倍，效果很好；

3、刚又让他们去做下提取 tag、话题，降成本 (直接给文询问 tdk 的同时提取 tag) 来做主题页。

这个策略效果肯定也不错，目前诸多 AI 站群都是如此。

三联的反馈让我想到：之前盘活三联内容库的时候，我甚至都想让人重点过一批内容来做 TDK (因为他们太文艺，你永远不可能这么搜索) 从而提升搜索匹配，但内容库实在太多遂放弃。

AI 的出现对企业乃至对全社会不仅仅是降本增效的意义，更多是给了「能力」、「突破了诸多限制」，这个场景算一类，翻译突破语言限制也算。智力赋能，突破了诸多限制，不是简单的降本增效。

（via 王凯）

### 105

方军 2023/12/27

tmd，中信再不重视翻译，以后真的会成为中国人学习与传播知识这个事上的笑料。

认知天性这段，完全完全翻译错了！

You're coming at it fast, and you've got to react fast,」Dooley said.「But as you get closer to game time, you slow it down again. Now it's a kind of rehearsal without physical contact. The play basically starts out the same each time, but then what the opponent does changes it. So you've got to be able to adjust to that. You start into the motion and say, ‘If they react like this, then this is what you would do.' You practice adjustments. If you do it enough times in different situations, then you're able to do it pretty well in whatever comes up on the field.

中信：「模拟比赛的节奏很快，你的反应也会加快，」杜利说，「但是到真正比赛的时候，又要把节奏放慢。慢下来之后，你进行的是一场没有身体接触的演练。每次演练在开始时基本都一样，但对手做出的反应会改变演练的内容。你要能够调整适应。你跑起来的时候会说，‘要是他们的反应像这样或那样，我就要这样或那样应对'。你要练习调整。只要在不同的环境中训练的次数够多，那么到真正的赛场上，无论发生什么，你都能做好。」

繁体版：

「你快速攻击，而且必须快速反应，」杜利说：「但是接近比赛时间时，你再一次放慢速度。现在，这是一种没有实质接触的演练。开打基本上每次都一样，但接着对手的打法改变战局。因此，你必须能够针对那个打法做出调整的动作。你开始进入该动作并说：『如果他们像这样回应，那么这是你要做的动作。』你练习调整打法。如果你在不同的情境下，练习的次数够多，无论场上出现何种变局，你都将能够打得很好。」

第一句话完全错了，繁体版是对的。

You're coming at it fast, and you've got to react fast,

为什么错呢，译者没看懂，被上一段最后一句误导了：

By midweek the team is running the plays in real time, full speed.

等到周三，队伍会真刀真枪地打一场模拟赛。

但这儿应该是一个教练的一般陈述。

第二句话也完全错了。

But as you get closer to game time, you slow it down again.

第三句也错了。

Now it's a kind of rehearsal without physical contact.

慢下来之后，你进行的是一场没有身体接触的演练。

第四句有个严重错误。

The play basically starts out the same each time,

play 不是演练！是比赛。

四句话没一句对，真是绝了！

当然，这前后的内容的确不容易，但完全错了，也太离谱了。

后面也继续把 play 翻译错了，是比赛！！！

The offensive coaches can make all the plans they want to about the hypothetical game, but once play gets under way, the execution rests in the hands of the quarterback.

进攻教练可以就假想的比赛制订各种方案，但演练一开始，执行的结果就完全仰仗四分卫球员了。

方军：遇到的编辑老师，也都觉得这个跟我没关系啊，我们分社（我自己）重视翻译的。不过我现在也不好意思再去跟具体某本书编辑老师说了，懒得去沿着书上的名字通过熟人找人家，因为看不到更正。

2023-12-27 12:57

方军：我尤其担心 AI 带来的滥用，互联网整个产业的人其实都不怎么认真，互联网产业也不是靠认真取胜的，AI 把互联网上的内容、把互联网产业人的心态都搞进来知识生产与传播领域，最后带来的结果会是灾难性的。

2023-12-27 12:58

方军：这种中文翻译书的状态，讲实话，看 AI 胡说八道（对不起，我还是很尊敬 AI 的）其实足以了。我们还会谨慎一点，因为知道 AI 会胡说八道。

2023-12-27 13:33

方军：认知天性这本书，中文翻译版，每章标题都是误导！

比如第四章知识的「滚雪球」效应。

什么鬼滚雪球效应，明明是：

Embrace difficulties

拥抱困难（直译）或拥抱挑战（繁体）都是较好的。

具体内容内容不是将可能引申的什么新老知识的联系，而是合意困难（desirable difficulty），也就是给练习增加困难！

要命呢，这本书不知道帮了多少人，又害了多少人。

2023-12-27 21:36

### 106

方军 2023/12/27

All useful knowledge is provisional.

Popper's view on ‘The Science is Settled.'

（网上看来的）

Philosophy and the Real World: An Introduction to Karl Popper

The popular notion that the sciences are bodies of established fact is entirely mistaken. Nothing in science is permanently established, nothing unalterable, and indeed science is quite clearly changing all the time, and not through the accretion of new certainties. If we are rational we shall always base our decisions and ex- pectations on 'the best of our knowledge', as the popu- lar phrase so rightly has it, and provisionally assume the 'truth' of that knowledge for practical purposes, because it is the least insecure foundation available; but

we shall never lose sight of the fact that at any time experience may show it to be wrong and require us to revise it.

### 107

方军 2023/12/27

摘，李靖：工程师身上最优秀的两种特质，一个是探索欲，一个是学习力。

对未知充满着好奇，和对模糊中确定性部分的强烈追求，都会让探索持续进行，这是学习的源动力。

而学习是提问的艺术，定义问题的能力能够反映学习力，有些问题用来剖开问题的表象，而有些问题能够直达问题的本源，两种提问都很重要，前者领人进门，后者创造增量的价值。

ChatGPT 已经完成了人类知识的浓缩，在知识的记忆上，人类比不过机器，但是在知识的运用上，机器仍然只是辅助工具，但此时，学习力也显得更为重要，人类需要从更宏观和更全面的角度了解知识的构成，这样才能让机器更好、更快的转起来。

方军：赞同这句：在知识的记忆上，人类比不过机器，但是在知识的运用上，机器仍然只是辅助工具

2023-12-27 14:39

### 108

方军 2023/12/28

清华大学讲席教授、电子工程系长聘教授、IEEE &CAAI Fellow、衔远科技创始人周伯文教授

[清华讲席教授周伯文内部分享：大语言模型为何会表现出接近 AGI 的能力](https://new.qq.com/rain/a/20231227A06LWM00)

### 109

方军 2023/12/28

有个想法，应该把外脑再拆分一下：个人外脑 + 网络辅助脑

一个是个人外脑，如：笔记、SOP、可直接求助的老师、甚至个人的电脑/手机设置。

一个是网络辅助脑，如：搜索引擎、社交网络、AI(LLM Chatbot)。

---

2023-12-04 10:18

外脑：AI 时代的扩展思维

读了《思考如何超越思考》（The Extended Mind）这本书，按我的理解，作为科学作家的作者安妮·墨菲·保罗将三类认知研究串起来、并借用认知哲学家安迪·克拉克的观点形成一个「扩展思维」（extended mind）这个新观点。

重新表述她的基本观点：思考不只发生在大脑中，而是也发生在大脑的外部，具体而言就是三种认知：

- 具身认知（embodied coginition）

- 情境认知（situated cogintion）

- 分布式认知（distributed coginition）

关于第三个，第三个我觉得这个通俗化一下用「群体认知」可能更好，但心理学领域估计群体代表另外的意思，所以有了这个词。

这本书看得过瘾又不过瘾。不过瘾是因为，虽然它强调要不只聚焦于我们的大脑本身，但是可能出于心理学/认知科学研究的约束，又还是重点在讨论三种外部认知资源如何影响我们的大脑思考，因而并未真的超越大脑。

她梳理的这个框架蛮有意思，我从实用角度出发，借用它来绘制一个「外脑：AI 时代的扩展思维」出来。（我这里就不受限于认知科学/心理学的专业词汇了，实用出发怎么容易懂怎么说。）

-------

A. 输入 - 处理 - 输出

我们的大脑是个处理机制（一个工厂），它接受输入，进行处理，形成输出。

扩展思维的看法是，我们的大脑还有三个外部可用的资源：具身认知、情境认知、群体认知。

我们再外扩一下的看法是，整个工厂都已经被高度数字化：

1、三个可用资源也有数字化的部分。

2、同时，我们的外部工具也数字化了，远不是书纸笔那么简单。

-------

B. 数字化的三种外部认知资源

如果将手机、电脑、网络也看成我们的身体一部分，那么，我们可以将具身认知、情境认知、群体认知拓展过去。

手机其实已经是我们的器官了，这是为什么我们要花那么大力气去抗拒它，定时关掉它。

屏幕的情境给我们带来的冲击比环境还大，屏幕造成沉浸感，远超过实体环境。

群体认知则更不用多说了，我们随时可以借用社交网络的智慧，只要愿意，我们都有机会身处最牛的群体之中。

-------

C. 外部工具，主要是数字化的

安妮在书中引述克拉克 2019 年的一个研究，他们研究的主题是：「使用外部物体、道具和辅助工具解决复杂问题的能力」。

我们现在外部的工具可真是太强了。

笔记工具。以我个人而言，除了一本年历本和工作时手边乱涂乱画的 A4 纸之外，所有的笔记都是电子化的。（另，作为星主，我把知识星球更多地视为一种笔记工具。）

输出工具。相信没人用手写了吧，都是电脑。当然，对那些习惯口头表达的人，他们也会直播、网络会议、录视频等等。

AI。这一年来最大的变化无疑是 AI，AI 成为外部工具中最大的变量。外部 AI 模型很强大。但这儿我们的问题是，我们自己能将多少纳入（外脑的）内部来使用？

一点补充讨论：

Indigo 之前也画了一个外脑，他也是实用出发、并强调 AI。但我不是很赞同的一点是，他认为笔记很重要，因而引用了第二大脑笔记的 PARA 笔记方法，他最近还推了一个笔记产品。

我个人的体会是，虽然记录很多笔记，我其实真心在输出时不用笔记，我会持续修改笔记以改进想法，但输出时不查看与重用笔记。

### 110

方军 2023/12/28

今天 new york times 诉 openai, microsoft 的透漏很多有意思的材料啊

生成的东西究竟是什么，真是很难讲。

所以直接用 AI 生成的文字，对严谨的作者还是完全不可行的

法律文件

storage.courtlistener.com/recap/gov.uscourts.nysd.612697/gov.uscourts.nysd.612697.1.68.pdf

律师的讨论：

twitter.com/CeciliaZin/status/1740109462319644905

---

「纽约时报诉 OpenAI」 律师观点（GPT 翻译未调整，仅供参考）

这个案例可能成为 AI 和版权的分水岭时刻

请查看原文：twitter.com/CeciliaZin/status/1740109472360808767

这是我作为一名知识产权和人工智能律师、总法律顾问以及长期从事技术工作和热衷于技术的人对今天早上提交的历史性纽约时报诉讼案进行的分析。

简而言之 —— 这是迄今为止最好的案例，声称生成式 AI 侵犯了版权。

1、首先，投诉清楚地阐述了版权侵权的主张，强调了《纽约时报》的文章与 ChatGPT 的输出之间的「访问和实质相似性」。关键事实：《纽约时报》是 Common Crawl 中用于训练 GPT 的最大专有数据集。

2、投诉中的抄袭证据非常明显。红色的复制文本，黑色的新 GPT 词汇 —— 这种对比设计旨在影响陪审团。请在此处查看 J 号附件。

我的看法？OpenAI 如果不对指导方针进行重大改变并对技术的运作进行大量的诉讼辩护，就很难为这种做法辩护。与其争斗，最明智的做法是和解。

3、NYT 是一个伟大的原告。这不仅仅是关于文章，而是关于原创性和创造过程。他们的调查新闻报道，比如在投诉中引用的深入的出租车贷款曝光报道，超越了简单的劳动，它是核心创造力。

但是这里有一个转折：版权保护的是创造力，而不是努力。虽然出租车文章的 600 次采访令人印象深刻，但在法律上重要的是报道中的创新。顺便说一句，这与对 GitHub Copilot 的诉讼形成了鲜明的对比，后者只引用了几行开源代码。

5、诉讼将 @OpenAI 描绘为以利润为驱动且封闭的。它将此与新闻的公共利益进行对比。这种叙述在法庭上可能具有强大的影响力，权衡版权的社会价值与技术创新。值得注意的是，善恶的平衡在每个重大版权案件中都是一个问题 - 从贝塔玛克斯案到费斯特判决电话簿不可版权。投诉甚至提到了董事会和山姆·阿尔特曼的争议。

6、虚假信息的指控增加了一个巧妙的转折。投诉涉及到了人们害怕的幻觉，并以此为例，指出《纽约时报》文章中的某些元素是虚构的。

最令人难忘的例子？声称 Bing 表示《纽约时报》发表了一篇文章称橙汁会导致淋巴瘤。

7、另一个有趣的观点：纽约时报找到了非常优秀的律师。Susman Godfrey 在应对科技方面有着很好的声誉和记录。这不是像在 ChatGPT 发布一周后提起的那些诉讼那样的快速抓钱行为，而是一个战略性的法律挑战。

END

这个案例可能成为 AI 和版权的分水岭时刻。很多人说 OpenAI 应该付费。我们拭目以待！

什么是利害关系？AI 创新的未来和创意内容的保护。请继续关注。

方军：Ethan Mollick 也做了讨论

In the New York Times OpenAI lawsuit, you can see how complex the relationship of training data to output can be. On one hand, they find that you can induce ChatGPT to produce exact content from famous Times articles, on the other, they show it also hallucinates false articles.

在《纽约时报》对 OpenAI 的诉讼中，你可以看到训练数据与输出之间的关系是多么复杂。一方面，他们发现你可以诱使 ChatGPT 生成来自《纽约时报》著名文章的确切内容，另一方面，他们也展示了它会产生虚构的假文章。

twitter.com/emollick/status/1740061455607791987

2023-12-28 12:25

方军：目前的其他信息也显示，new york times 在技术理解上有很大的缺陷，这些缺陷足以让它官司。

因而有人说：纽约时报将因输掉这场官司而遭受毁灭性打击。这将标志着企业媒体的终结。时代在变化。

2023-12-28 12:30

### 111

方军 2023/12/28

讨论：

网友：Neyl Walecki

你对图中这个观点有什么看法？

Cecilia Ziniti

I was waiting for somebody to find the prompt. Good work.

It'll be interesting to see how the court handles prompting. AI terms of use say that you cannot tell it to do illegal things, which arguably intentionally prompting to misinform is doing. I think the misinformation part of the complaint is a sideshow, though. The pure copyright examples are good enough.

That said, my favorite analogy for generative AI is that it's like a smart, over eager college student who has read the entire Internet. If you tell that person to write about orange juice and cancer, what chatGPT came up with is exactly what it would do.

我在等待有人找到提示语。干得好。

看法院如何处理提示工程将会很有趣。AI 使用条款规定您不能要求其执行非法行为，而有意误导的提示工程可能属于此类行为。我认为投诉中的误导部分只是一个次要问题，纯粹的版权问题已经足够严重。

话虽如此，我对生成式人工智能的最喜欢的类比是，它就像一个聪明而热心的大学生，已经阅读了整个互联网。如果你告诉这个人写关于橙汁和癌症的内容，chatGPT 给出的答案就是它会做的。

Neyl Walecki： 谢谢 @CeciliaZin 。我同意你的观点，而且真的很喜欢「过于热心的大学生」这个比喻；这正是 ChatGPT 所做的。主要的区别在于速度，而且它擅长写作 :-)

Jedi #Kubernaught ：

Yikes. It's like asking somebody to write a fictional article with specific instructions and that person does it, it's no different here. It's going to make it up because you told it to! I really hope this whole case goes strongly against NYT.

天哪。这就像是要求某人按照特定的指示写一篇虚构文章，而那个人确实这样做了，这里也没有什么不同。它会编造出来，因为你告诉它这样做！我真的希望整个案件能对纽约时报产生强烈的反击。

witter.com/neylwalecki/status/1740115813837808099

### 112

方军 2023/12/29

一个群里讨论，胡泳老师说：我可以讲讲 AI 在传播虚假信息方面的应用，哈哈哈

我：哈哈好题目！

之前看过俄罗斯如何操控社交媒体新闻的，我印象最深的就是三个，一，真假混合，二，小节点甚至全新号发文，多节点转发，引发大 V 转发，三，对于要反对的推文，就是在下面胡扯把它淹没。

当时看那个做社交网络分析的研究者用数据分析并总结这些出来，真是一直震惊，原来这么操控。

现在这三个里面需要的内容，都可以用 AI 来几百倍甚至跟更多倍生成，想想就觉得可怕。

胡泳：正是如此，互联网马上就不是人的互联网了，而是机器的互联网。

倪考梦老师说：我感觉 AI 这样发展下去，以后群里聊天就不适合聊正经问题了。

因为可能有个完全外行的人不断把你的观点丢进 GPT 里让他给出一些似是而非的反驳的话。

我调侃：都不用似是而非，直接提示搞狡辩术就可以，能够气死人不偿命。

### 113

方军 2023/12/29




### 114

方军 2023/12/29




### 115

方军 2023/12/29

