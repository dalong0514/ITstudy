### 01

方军 2024-08-01

宝玉的翻译提示词更新版：

翻译 GPT 的提示词更新和优化

提示语见链接：

[翻译 GPT 的提示词更新和优化 | 宝玉的分享](https://baoyu.io/blog/prompt-engineering/translator-gpt-prompt-v2-1-improvement)

他的说明很清晰：

\## 主要优化

所以最近我对旧版本的 Prompt 做了一些优化，主要的优化如下：

1、使用英文提示词。

相对来说，GPT 对英文提示词会遵循的更好，使用英文提示词可以让 GPT 更好的理解和跟随指令。

2、将重要的内容放在开头和结尾。

很多论文的研究都证明了提示词中开头和结尾部分的效果是最好的。而对于我的翻译 GPT 来说，复杂的有两部分，一部分是要根据不同的输入情况进行不同的处理，比如 URL、图片、PDF 等；另一个复杂部分是要按照三个不同的步骤翻译。

所以我在开头针对不同的输入情况给出了具体的处理方法，然后在结尾给出了三个步骤的输出格式参考。

3、对于第二步的反思，要求给出具体的建议。

这一步是参考自吴恩达的翻译智能体的 Prompt，从准确性、流畅性、风格和术语等几个方面给出了具体的建议，这样对翻译结果确实有提升。

4、使用 XML 格式输出。

上一个版本的 Prompt 中，我使用的是 Markdown 格式输出，通过大标题分离不同的部分。虽然也可行，但是有一点美中不足： 1). 和要翻译内容中的 Markdown 格式有冲突，比如原本文中有大标题，这样不太容易分辨什么地方开始和结束。 2). 对于是否输出结束并不清晰，比如原文有 4 段，但是只输出了 3 段就终止了，不好判断是否还有内容。

所以新版本中我使用了 XML 格式输出，这样可以更好的和 Markdown 格式区分开来；根据是否有结束标签，可以判断是否还有内容；还有一点是 XML 格式更便于代码解析。

5、支持图片翻译。

现在 GPT-4o 对图片支持很好，可以很好的识别图片中的文字，所以我在新版本的 Prompt 中加入了图片翻译的支持，输入图片或者 PDF 时，可以先进行 OCR，然后再进行翻译。

\## 保持不变的部分)保持不变的部分

1、三步翻译：直译、反思、意译

经过反复测试，虽然继续润色可能会有些许提升，但需要平衡 Token 的长度、时间成本和翻译质量，三步翻译是一个比较好的平衡点。

2、角色设定

虽然最近一些文章表示没有必要设定角色，但是作为一个翻译任务，保持角色设定可以清晰的让 GPT 知道自己的任务，这样可以更好的跟随指令。

3、术语表

使用术语表可以让翻译结果更加统一，可以避免将 Transformer 翻译成「变压器」这样。但限于 GPT 的限制，现在还无法对术语表进行定制，只能是预置一些常见的术语。

2『个人补充：测试下来，感觉还没有老版的效果好，改回老版的了。但借鉴了里面的使用 XML 格式输出。（2024-08-11）』

### 02

方军 2024-08-01

有时候对教育/培训感到无语，看到花很多时间讲：

s[::3]
s[start:stop:step]

讲实话，作为一个 Python 二把刀、但也勉强用了很久、干了很多活的人，我不知道这个方式。

有必要吗？我觉得毫无必要，实践中基本上用不到。用得多数是 s[0:2] 、s[:-2] 类似这种普普通通的用法而已。

如果用到更复杂的，那多半也有一些专门的库或采用其他类型数据去处理，没必要非在s[start:stop:step]上费劲。

现在有了 AI 倒是简单了，看不懂，直接扔给 AI 解释。

这倒是有用，因为如果代码里非有高手用了一些独特的写法，也不用特别查文档了，直接 AI 解释下即可。

### 03

方军 2024-08-02

全球最大的 AI 虚拟人物对话平台  Character.AI 开源了它们的 Prompt Design 项目—— Prompt Poet 

Prompt Poet 通过低代码简化了 Prompt Design 的过程，使开发人员和非技术用户都能轻松上手。Prompt Poet 结合使用 YAML 和 Jinja2，实现了灵活、动态的 Prompt 创建，提高了与 AI 模型交互的效率和质量。它节省了在字符串操作上的工程时间，使每个人都能更专注于为用户制作最佳 Prompt。

Prompt Poet 重要组成 - 提示模板 (Prompt Templates)

Prompt Poet 模板混合使用 YAML 和 Jinja2，模板处理主要分为两个阶段：
-- 渲染：Jinja2 处理输入数据的阶段，执行控制流逻辑，验证数据并适当地绑定到变量，同时评估模板中的函数。

-- 加载：渲染后，输出是一个结构化的 YAML 文件。这个 YAML 结构由重复的块或部分组成，每个部分都被封装成一个 Python 数据结构。

-- 这些部分具有以下几个特征：
--> 名称：一个清晰的、人类可读的部分标识符。
--> 内容：构成提示的实际字符串负载。
--> 角色（可选）：指定参与者的角色，有助于区分不同的用户或系统组件。
--> 截断优先级（可选）：在必要时确定截断的顺序，具有相同优先级的部分按照它们出现的顺序进行截断。

- 设计选择 (Design Choices)

-- Prompt Poet 库和模板语言：
--> Prompt Poet 库提供多种功能，包括分词和截断，以实现高效缓存和低延迟响应。
--> 使用 Jinja2 和 YAML 的组合作为模板语言，提供了强大的表达能力和结构化数据表示。

-- 提示可移植性和函数调用：
--> 模板化设计使得提示可以在不同团队和系统间轻松共享。
--> 支持在模板中直接调用 Python 函数，便于即时数据处理和验证。

-- 自定义编码和截断策略：
--> 允许用户自定义令牌编码函数。
--> 提供了高度优化的截断算法，旨在最大化前缀缓存率。

-- 缓存感知截断：
--> 采用固定截断点策略，平均每 k 个回合才移动一次截断点。
--> 这种方法能够显著提高 GPU 前缀缓存的利用率，达到 95% 的缓存率。

-- 朴素截断 vs 缓存感知截断：
--> 朴素截断每回合都移动截断点，导致缓存利用率低。
--> 缓存感知截断保持固定截断点，允许重用之前的计算结果，大幅提高效率。

[x.com/shao\_\_meng/status/1819165042035790190](https://x.com/shao__meng/status/1819165042035790190)

[Prompt Design at Character.AI](https://research.character.ai/prompt-design-at-character-ai/)

### 04

方军 2024-08-02

Poetry： Python 依赖包/虚拟环境管理工具

在 Cluade 的辅助下（摘选并加说明），写一个简单的使用指引：

[体会：1）有了 AI，学习效率比看官方文档高，可靠性在这些问题上还行。2）有了 AI，要按自己的需求组织一个文档出来，与看官方文档、翻译、运行记录比，这样做效率高]

\## 快速启动

1. 安装
```
pip install poetry
```
不加配置的情况，缺省选择集中管理的虚拟环境。

2. 创建项目
```
mkdir my_project
cd my_project
poetry init
```
3. 添加依赖库/包
```
poetry add package_name
```
查看：
```
poetry show package_name
```
4. 激活虚拟环境:
```
poetry shell
```
5. 运行 Python 脚本
```
python your_script.py
```
6. 退出虚拟环境
```
exit
```
7. 查看虚拟环境信息:
```
poetry env info
```
8. 列出所有虚拟环境
```
poetry env list
```
9. 删除特定虚拟环境
```
poetry env remove python3.12
```
10. 更新依赖
```
poetry update
```
11. 在不激活虚拟环境的情况下运行脚本
```
poetry run python your_script.py
```

\## 解释

在启动项目并安装之后，目录中会有：
```
tree
.
├── poetry.lock
└── pyproject.toml
```

集中管理的环境安装在：
```
 ~/Library/Caches/pypoetry/virtualenvs/
```

```
ls  ~/Library/Caches/pypoetry/virtualenvs/
poet-7QpPCq2B-py3.12
```

移除
```
poetry env remove python3.12
Deleted virtualenv: ~/Library/Caches/pypoetry/virtualenvs/poet-7QpPCq2B-py3.12
```

\## 特别设置

我们也可以选择将环境安装在项目目录，那么要做如下设置：
```
poetry config virtualenvs.in-project true
```

### 05

方军 2024-08-02

针对此前被唱片公司和唱片协会起诉，Suno 今天回复了美国唱片协会，称神经网络就像孩子一样学习，学习不构成侵权。

部分内容：

首先，各大唱片公司显然对我们的技术工作原理存在误解。Suno帮助人们创作音乐的过程与人类一直沿用的过程类似：通过学习风格、模式和形式（实质上就是音乐的 "语法"），然后围绕它们创作出新的音乐。各大唱片公司试图辩称神经网络只是鹦鹉学舌--复制和重复--而实际上，模型训练更像是一个孩子通过虔诚地聆听摇滚乐来学习创作新的摇滚歌曲。就像那个孩子一样，我们的人工智能越学越好。

我们在开放互联网上找到的中高品质音乐中训练我们的模型--就像谷歌的双子座、微软的 Copilot、Anthropic 的 Claude、OpenAI 的 ChatGPT，甚至苹果的新 Apple Intelligence 在开放互联网上训练它们的模型一样。

开放的互联网上确实有许多受版权保护的资料，其中一些还为大型唱片公司所有。但是，就像孩子们在听完摇滚乐后自己创作歌曲一样，或者就像教师或记者在查阅现有资料后得出新的见解一样，学习并不构成侵权。过去不是，现在也不是。

这起诉讼的时机有些出人意料。事实上，当这起诉讼发生时，Suno 正在与 RIAA （美国唱片协会）的一些主要唱片公司成员进行富有成效的讨论，以寻求共同扩大音乐蛋糕的方法。我们这样做并不是因为我们不得不这样做，而是因为我们相信音乐产业可以帮助我们为每个人带来更多的机会，而不是抵制它。无论这场诉讼是律师们过于焦虑的结果，还是我们有意识地在商业讨论中获取筹码的策略，我们都认为这场诉讼是对音乐更大、更有价值的未来的不必要阻碍。

[The Future of Music – Suno](https://suno.com/blog/future-of-music)

### 06

方军 2024-08-02

114 如何做 AI 工作流：王树义老师的经验

如何用命令行工作流做定制化 AI 文献回顾？  (另一篇参考：如何轻松定制和调用你自己的 AI 工作流？）

[知识星球 | 深度连接铁杆粉丝，运营高品质社群，知识变现的工具](https://wx.zsxq.com/dweb2/index/topic_detail/4844141188882118)

[如何轻松定制和调用你自己的 AI 工作流？](https://articles.zsxq.com/id_kmwc76rvs578.html)

王树义老师这个工作流特别棒。我认为其中的优点有：

- 采用 Fabric 的提示语处理方式（也包括它原有的提示语模板），但不依赖它。
- 采用编程方式，来让 Fabric 的单线管道变成后续步骤可以引用前面多步的输出。
- 采用 YAML 来进行工作流的配置，灵活度非常高。

王老师有个思路我高度赞同，大意：应该把注意力放在流程与提示语，而不是其他，流程与提示语是实际完成任务的部分。

（当然，这个工作流我还只是看了，没有实际运行，之前实际运行过翻译工作流那个，并用 Notebook 形式来调整。）

我知道王老师喜欢命令行形式，不过，如果让我来做自己的工作流，我多半会选用如下方式：

- 配置 - YAML。用 YAML 做配置，这比图形化（coze/dify）要难一些，但更适合有点编程背景的。把配置和程序分开，会让工作流更易用。

- 提示语 - LangSmith，存放在  LangSmith，因为它可以方便的进行评测，可以记录提示语版本（它采用的是类似git形式），还可以记录运行结果（每次模型的输入、输出，这是LangSmith的真正功能）。最近调整工作流时，实际上花的时间在这儿时比较多的，因为要反复调整提示语，以达到想要的效果。

- 编排 - LangChain，相应地，编排我也就会采用 LangChain，它支持的模型是比较丰富的。

- 运行 - Notebook（ipynb） ：在调试时，我会直接使用 Google Colab，使用时，我有时会选择本地。

采用 Notebook 的优点是各种依赖也可以在 Notebook 里面管理了。一个 Notebook  一个工作流，当然有些共同的代码也可以Python脚本（.py) 形式另外保存和调用。

Notebook 当然也有缺点，就是如果大量代码还是放在里面（我们通常的确是这么做），那么，它没有命令行那种看起来封装得好。这对非程序员也不那么友好，比如如果误碰可能会改动代码、导致运行不起来。

当然，这其实正是我选择它的原因。这是因为，我不想它是封装的，而是希望能够看到其中的过程，并可以随时酌情调整。

### 07

方军 2024-08-02

最近在想，李笑来的《自学是一门手艺》（实际上是一个 Python 自学手册），如果出现在 AI 时代，会如何？

他当时的优点是：

1. 讲自学，同时有一个场景（Python学习）
2. 他讲得较为缓慢与详尽，适合仅看书自学
3. 他采用 ipynb 的笔记本格式写作（实验代码可方便地运行）

当时的缺点是：

1. 有些详尽是不必要的，应该让学习者自己实践/探索
2. 要看还是很难的，很多普通人看不下那么多字
3. 整体结构上，略显不足，这可能是他当时很大程度也是一个初学者，记录学习经验有关

现在的变化是：

1. 很多解释可以由 AI 来替代（也就是可运行之外，完全可以是 AI 互动解释）

2. 优化结构，我个人认为，用AI最需要的首先是自己手上的结构（通俗说就是一个大纲）

除了这本书之外，之前看到一本日本书不错，当时还专门买了一本回来。它也有中文版了《Python超入门》，它的优点是：

1. 用图解标注形式来对代码/运行结果进行解释，对普通人比较友好（当然程序员会认为代码加注释就够了）
2. 结构比《自学》要清晰，这是很多日本书的特点
3. 整体内容上要简单（或者说单一）。这也是日本书的特点，它不会试图宏大面面俱到，而是切一个横切面。

缺点是有很多不必要的截图，比如我就不明白为什么那么详细地截图介绍 Python下载和 anaconda 下载。也许对普通人这是一个门槛，但我认为应该放在附录。

### 08

方军 2024-08-03

空谷：不知道你们现在是否存在这样一个痛点，在用三方的 AI API 服务商时，不确定是否是 OpenAI API 官方正版转发，还是 ChatGPT 逆向？
最近我发现了一个参数，可以完美完成验证，帮你区分出是否是正版官转。而它，就是 seed 参数。

（先说下ChatGPT 逆向服务的问题。 如果是 ChatGPT 逆向的服务，不但指令跟随上不如 API 自由，而且不支持 Tools Calling（即没法使用插件），服务也不稳定。

还有很重要的一点，ChatGPT 逆向的方案，你的会话数据会被 OpenAI 官方拿去训练模型。而如果是走 API 调用，说是不会拿去训练的。  

为啥这么多问题，号商还是会有 ChatGPT 逆向的 API 出来？原因就是逆向来的 ChatGPT API 是免费的。所以他们的很多价格最低能达到官方原价的 0.几折。而如果是 API 官方转发，做到五六折几乎已经是极限价格了。）

那怎么判断是官方转发还是 ChatGPT 逆向？很简单，你的请求参数中多加一个 "seed": 1 （数值随便设，需要是整数）即可。

如果常用 AI 生图的小伙伴应该对 seed 这个概念不陌生。但是在 LLM 里， Seed 参数似乎应该还是一个非常冷门参数，它核心作用就是控制在一模一样的入参情况下，可以保证模型的输出也是一样的。官方文档地址：https://platform.openai.com/docs/api-reference/cha...…

所以它在验证真伪性的这个场景上，作用非常大。

因为 ChatGPT 逆向的接口是没有这个参数的，所以如果你让ai生成一个10个字的笑话，返回的内容应该是每次都不一样。而加上 seed=1 后，你无论请求多少次，它的返回结果会始终稳定一致。因此这是一个绝佳的测试方法。

直接贴一个测试的 curl，大家可以换上自己的 apikey 快速测测看：

curl -X --request POST 'https://api.openai.com/v1/chat/completions…' \
-H 'Content-Type: application/json' \
-H 'Authorization: Bearer <your-api-key>' \
--d '{
"messages": [
{
"role": "user",
"content": "写一个10个字的笑话"
}
],
"seed": 1,
"model": "gpt-4o-mini"
}'

结果应该稳定是 「为什么鱼不说话？因为它们水里！」

[API Reference - OpenAI API](https://platform.openai.com/docs/api-reference/chat/create#chat-create-seed)

[(13) X 上的 空谷 · Arvin Xu：“不知道你们现在是否存在这样一个痛点，在用三方的 AI API 服务商时，不确定是否是 OpenAI API 官方正版转发，还是 ChatGPT 逆向？ 最近我发现了一个参数，可以完美完成验证，帮你区分出是否是正版官转。而它，就是 seed 参数。 https://t.co/Pe4e0lKErZ” / X](https://x.com/arvin17x/status/1819346887851626969)

### 09

方军 2024-08-03

LangChain 出了个 Agent IDE

LangGraph Studio 

[LangGraph Studio: The first agent IDE](https://blog.langchain.dev/langgraph-studio-the-first-agent-ide/)

我一直都没开始用起来 LangGraph，真是时时感到落后了。——Workflow 已经在拼命赶了，这个倒是一直有实在的感觉的。Agent 从最开始 AutoGPT ，我就看不懂。

---

- Langchain 的 Agent IDE 设计理念与 Dify 和 Coze 等低代码可视化工具不同，它采用了编程式路线，同时融入了可视化调试元素。

- LLM 应用开发的特点是迭代式，需要不断与 LLM 交互并根据反馈优化应用，LangGraphStudio 的设计支持这一开发模式。

---

看到一个中文介绍文章：

[Langchain发布官方Agent IDE，不同于Dify/Coze的设计理念，能否获得开发者认可？](https://mp.weixin.qq.com/s/PNoi_QzKxtJZJUVrpV7P5w)

### 10

方军 2024-08-04

115 人能轻松地识别机器生成

这句话目前还是有很多人不理解，其实很简单的，目前机器生产的东西，有着一种说不出来、技术上也测不出来，但人能够一下子感受到的味道。

永远不要用 AI 去生成，真的，把这波 AI 浪潮叫 AIGC，真的很有误导性。叫生成式 AI，说明它仅仅是中间过程，略微减弱一点负面影响。

说两个个人体会：

一个是，看多了网上的文字（是流水线式生成、以及部分 AI 生成），然后去书店，看到文学区（比如PageOne 的文学区）或者各种学者长期写出来的（比如在万圣），明显是不一样的。

另一个是，听了一段 AI 生成的语音，再回头一听人讲话的语音，真是不一样啊。当然，我听的不是那种工业化生产的，是蒋勋那种讲话本来就很有魅力的。

各种搞 AI 的人，如果不能理解，会自找很多麻烦：虽然你们比普通人厉害很多，但是，任何最普通的普通人都可以一下子识别出来什么不是自然的，最多只要稍稍提示下：你觉得你听的是自然的吗？

### 11

方军 2024-08-04

116 选择 AI 工具的「单核方法论」

我一直自己有选择工具的需求，也会经常帮人选择方法，因此，我自己逐渐地形成了一种方法论，这就叫它「单核方法论」吧。它的用途是，用来帮你选择和使用那些要反复使用的某种方法。

现在，突然一下子冒了很多使用 AI 的方法，比如我就一直反反复复重复 ICDO 这个提示语模板。面对这些不断出现的方法，我们就需要用到「单核方法论」，用它来帮我们筛选。

⛳️ 单核方法论——选择方法的方法

在选择方法之前，首先要确定：

> 我要解决的一个问题是什么？

之后，我们有三个阶段：

第一阶段：选择

1. 这个方法效果如何？或者更直接地问：它有可能解决我的某一个问题吗？

2. 先看看这个方法的讲解，它是逻辑上行得通的吗？

如果以上两个答案都是“YES”，那么，我们就进到下一阶段。

第二阶段：尝试

1. 按照方法的讲解，按它附带的使用案例，看看这个方法是不是有效？自己能不能用起来？

2. 如果上一步尝试有效，那么，面对自己的实际问题，至少尝试使用 7 次。

然后，做出判断：这个方法能不能解决自己的问题、这个方法是否适合自己？

第三阶段：使用

1. 将这个方法变成一系列步骤，也就是你自己的 SOP，然后长期使用，至少使用 100 次以上。持续地关注：这能解决我的问题吗？

2. 在使用过程中，不断地优化与迭代这个 SOP，让它的效果变得越来越好。特别地，要注意对这个方法进行简化，即，不是让它变得越来越复杂，而是削减不必要的步骤。

当然在这同时，我们还是持续关注有没有更好的方法。如果发现了，那么，重复之前第一、第二阶段的做法，替换到更好的方法。

以上「单核方法论」所适用的场景，是选择与使用那些使用很多遍的方法。

(如你所见，以上这几个步骤， 也是我自己非常多次使用的一个方法。）

以上这「单核方法论」背后有一个基本的认识，也就是，在我们日常工作生活中真正解决问题的方法，往往都是反复使用的，就跟每天要早晚刷牙一样可能运用非常多次。

最近一直在看 AI 工作流，我觉得，与单核方法对应的是工作流，工作流往往是非常个性化的，别人的工作流、个人体验不一定适合我们。因此，工作流多半只是参照案例，而不能直接拿来反复多次运用。
收起

查看详情
乘风、Koant、Jese__Ki 觉得很赞
方军：有时候也反思，我是不是会一个方法自己简单尝试下，就开始热情地推销给别人。还好，极其偶尔有，绝对很少。
2024-08-04 16:34
方军：再补：我在工具上是很愿意花钱的，比如前天朋友问题某件事有没有好工具，我当时给他展示了我用的，以及几个我知道的，比较一下。发现我用的那个实际效果不行之后，我立刻订阅了当时试用觉得可行的，30美元，但我觉得是值得的。
2024-08-04 16:36
方军：这一年多在工具选择上，我受到一个重大的新影响是王树义老师等反复提及的“重器轻用”，我理解，也就是别太关注一个工具是不是很复杂，用最牛的工具，然后用它最适合我们的那个点就可以了。（这就消除了它很难用的「复杂」难点。）
2024-08-04 16:40

### 12

方军 2024-08-04

用AI生成垃圾的情况还是发生了

某：我用AI写的这篇快40万阅读了，全文一个字没改，标题是我自己写的。ChatGPT现在写文章还可以，不过标题不太行。

[大离谱！中国人居然对中国冠军竖中指+爆粗口，丢人丢到国外](https://mp.weixin.qq.com/s/kWNOB-0oHVo_yk4XLvEOgA)

### 13

方军 2024-08-04

可以看出，Llamaindex在应对复杂的LLM应用时，采用了与Langchain相似的策略，即高代码+可视化辅助调试的思路。

[Llamaindex推出workflow应对复杂LLM应用构建，以及技术实现从图（Graph）转向事件驱动（EDA）原因解析](https://mp.weixin.qq.com/s/wOn69g9hEI3sapuyuZRfXA)

### 14

方军 2024-08-04

摘：今天看到一篇文章，说 ChatGPT 就是新的 Excel，说的挺有道理的。Excel 最初是为从事金融和会计工作的商业用户设计的，它上手容易，并且功能强大，可以应用于各种通用任务。并且还可以成为创业想法的来源。只要找到一个在 Excel 中手动操作流程的客户，然后为他们构建一个专门的 SaaS 应用，就可能卖钱。

现在的 ChatGPT 就像 Excel，普通人已经慢慢熟悉了如何使用，根据不同的任务去撰写相关的提示词，但是当简单的提示词满足不了需要，当你要基于 ChatGPT 去创建适合其特定领域的工作流程，就可能需要专门的应用程序或者服务，这其中也可能就会诞生出创业赚钱的机会。

以下内容为原文摘录翻译：
***

过去几十年里，最具代表性的计算机软件产品是电子表格。在 Excel 之前，有一个名为 VisiCalc 的电子表格软件，通常被认为是计算机的第一个杀手级应用程序。它改变了专业人士的工作方式，变得如此重要，以至于人们购买计算机只是为了使用它。在 1980 年代，公司们为争夺电子表格的主导地位展开了全面的竞争。像 IBM 的 Lotus-1-2-3 这样的竞争者逐渐占据了一席之地，而在 1985 年，当微软发布 Excel 时，VisiCalc 遭遇了激烈的竞争。随着 1990 年代 Windows 3.0 的发布，Excel 成为了主导的电子表格程序。从那以后，情况就没有改变。

Excel 是一款很好的产品，因为初学者可以很容易上手：只需在单元格中开始输入即可。但它成为一款伟大的产品，是因为它也非常强大：专家用户可以进行从复杂的财务建模到数据分析和可视化再到构建视频游戏的一切操作。

Excel 最初是为从事金融和会计工作的商业用户设计的，但其多功能性使其成为一种无所不在的通用工具。它也成为了创业想法的来源。只需找到一个在 Excel 中手动操作流程的客户，然后为他们构建一个专门的 SaaS 应用。

Stripe 的 Patrick McKenzie 最好地总结了 Excel 的可生成性，他写道：“我最喜欢的软件需求未被满足的症状是任何一个 Excel 电子表格，如果它曾经由一个员工更新，发送给另一个员工更新，然后再发送回来。每次发生这种情况，一个 SaaS 天使就会长出翅膀。”

风投家 Tomasz Tunguz 最早观察到，在过去的 15 年里，Excel 被分解成了许多其他应用程序，如 Asana、Looker 和 QuickBooks。但这种分解只有在 Excel 足够普及，让用户知道他们想要一个专门设计的替代品之后才有可能发生。为了实现这一目标，Excel 需要广泛的采用，并有高级用户开始将其用于它最初并未设计支持的特殊工作流程。

一旦这些工作流程被创建，高级用户意识到他们的工作流程中有些部分效率低下，或者缺少他们用例所需的功能。他们感到需要专门的工具——这就成为 B2B SaaS 发展成为一个 3270 亿美元市场的机会。

就像 Excel 催生了 B2B SaaS 时代一样，通用聊天机器人应用程序如 ChatGPT、Claude 和 Gemini 将为新一代计算机用户催生一个新的创业时代。AI 聊天机器人拥有与 Excel 相同的易用性和强大功能的结合。它们也正朝着在更短时间内达到同等水平的普及性发展。

今天使用 AI 的人们正逐渐熟悉基于 AI 的软件的基本单元：提示词、上下文窗口、少样本学习和多模态。他们将使用 ChatGPT 或 Claude 创建适合其特定领域的工作流程。在此过程中，他们会对这些工作流程如何变得更好、更简单、更便宜、更快和更安全形成自己的看法。

这就创造了将这些工作流程拆分为独立应用程序的机会。随着大语言模型的采用增加，创业的机会也随之增加。

原始文章：

[The Great AI Unbundling](https://every.to/chain-of-thought/the-great-ai-unbundling)

### 15

方军 2024-08-05

我觉得智能体（特别是这个翻译，而不是agent）会大行其道，因为公众就是特别喜欢这种说不清的名词色

摘：真正要用好 AI，让 AI 发挥最大效能，核心是还是要基于你要解决的问题，重新设计一个适合 AI 的工作流，让 AI 在工作流中完成它最擅长的工作，至于是不是智能体，是不是大语言模型，是不是 AI 帮你决策，都不是最重要的。

后面PDF抽取、漫画翻译例子特别棒

宝玉：你需要的不是智能体，而是一个适合 AI 的工作流

现在 AI 智能体（AI Agent）的概念很火，似乎智能体是用 AI 解决问题的银弹，有了智能体就可以解决很多问题。但也有很多人有不同意见，认为智能体不过是噱头，并没有看到靠谱的应用场景。

一个被提及很多的是吴恩达老师写的多智能体翻译的例子，简单来说就是用三个智能体：一个直译智能体、一个审查智能体、一个意译润色智能体，确实可以大幅提升翻译质量。但并非一定要三个智能体才能提升翻译质量，我以前也提出过基于 Prompt 的翻译方法，让 LLM 在翻译时，使用直译 + 反思 + 意译三个步骤输出，也可以得到高质量的翻译结果。

本质上，使用大语言模型（LLM）来解决问题，思维链（COT, Chain of Thought）是一种有效提升生成质量的方法，也就是说，之所以翻译质量能提升，不是因为有了智能体，而是因为有了思维链。至于思维链的每个环节是用一个独立的智能体，还是输出的一个步骤，并没有太本质的差别。（参考文章：[什么时候该用多智能体是不是一定要用多智能体？](什么时候该用多智能体是不是一定要用多智能体？ | 宝玉的分享。)）

其实大部分 AI 应用场景都类似：要用 AI 解决问题，核心不在于智能体，而在于设计出一个适合 AI 的工作流。

那么怎么才能设计一个适合 AI 的工作流呢？我认为有几个因素需要考虑：

一、不要将 AI 的解决方案局限在人类现有的解决方案上

有时候我们过于将 AI 拟人化，会不自觉的用人类解决问题的方式来套用在 AI 上，有时候确实有效，但很多时候并不一定是最优解。就像专业的翻译员，他们并不需要直译反思意译三个步骤，他们可以一步到位，直接输出高质量的翻译结果，所以最开始让 AI 翻译，Prompt 都是直接一步输出翻译结果，而不是分步骤输出，结果翻译出来的比较生硬。而当我们发现思维链是大语言模型的一种有效提升方法后，就可以设计出更适合 AI 的工作流，分成几步来解决问题。

包括我看到一些智能体项目，尝试模拟人类软件开发的分工，使用项目经理、产品经理、架构师、程序员、测试等等智能体角色去尝试解决复杂的软件项目，同样也是一个过于拟人化而不一定适合 AI 解决问题的思路，所以也只能出现在论文中，而无法在实际项目中落地。相反像 GitHub Copilot 这样辅助生成代码的工具倒是真正适合当前 AI 编程的工作流，能实实在在提升开发效率。

二、不必完全依赖 AI 做决策，而是让 AI 辅助做决策或者做简单的决策

去年有一个超级火爆的项目叫 AutoGPT，就是你输入一个任务，GPT-4 会将任务分解，制定计划，调用外部工具，比如 Google 搜索，甚至执行代码，最终完成任务。这也算是 AI 智能体的先驱项目之一，但现在已经很少有人提及了，因为以现在 AI 的智能程度，还不足以对开放性的任务做出靠谱的决策，最终除了帮 OpenAI 卖了大量的 Token 外，并没有解决什么实际问题。所以现在 AI 应用的主流是把 AI 当“副驾驶（Copilot）”，只是让 AI 辅助人类完成任务，主要还是人在做决策。

另外就是自己设计工作流，让 AI 在工作流中完成一部分工作，并不过于依赖 AI 做决策，或者只需要做简单的决策。比如说商家借助 AI 处理差评的工作流：
1. 程序抓取评论信息
2. AI 分析每一条评论的情感，筛选出差评
3. AI 生成回复（可能需要人工审核）

这是一个典型的设计好流程的适合 AI 的工作流，AI 只需要做简单的情感分析和回复生成，而不需要做复杂的决策，这样的工作流可以很好的提升效率，并且结果也相对靠谱。

三、结合不同领域的 AI 模型或者工具，设计合适的工作流

去年起 AI 大热，一个很重要的原因是大语言模型的出现，这些模型一方面确实能力强大，有一定的通用性，有简单的推理能力，另一方面使用也简单，无论是通过聊天机器人，还是通过 API 调用，都能很方便的使用。即使像我这样不是人工智能专业的人，也能很容易的使用这些模型。而在以前，人工智能相对来说是个高门槛的领域，需要筛选数据、需要训练，还需要调参，对于非专业人士来说是很难使用的。

但这也导致一个问题，就是很多解决方案过于依赖大语言模型，而不知道或者不会使用其他领域的 AI 模型，但当你能够根据任务，将不同领域的 AI 模型或者工具结合起来，设计出合适的工作流，就能够得到更好的解决方案。

四、回归问题本质，AI 只是解决问题的工具

上面提的几点都是容易犯的一些错误，之所以容易犯这些错误，恰恰是因为我们有时候过于关注一些流行的概念或技术，而忽略了要解决的根本问题是什么，将 AI 变成了目的而不是手段。如果你有了解马斯克的第一性原理思维，其强调的就是回归事物最基本的条件，把其解构成各种要素进行分析，从而找到实现目标最优路径的方法。

而运用第一性原理通常有三个步骤：
- 第 1 步：定义清楚你要解决的根本问题。
- 第 2 步：拆解问题。
- 第 3 步：从头开始创建解决方案。

而这也个思路也适用于我们去借助 AI 解决问题，设计出适合 AI 的工作流。

举两个设计合适 AI 工作流解决问题的例子

一个例子是 PDF 转 Markdown

做过 PDF 翻译的有经验，要得到好的翻译结果，将 PDF 的内容整理成 Markdown，再让大语言翻译，效果是相当好的。但这个不好做，因为 PDF 是用来打印的格式，并不是结构化的数据，很难直接提取成 Markdown，再加上各种图表、表格等，更是复杂。

最近看到一个项目叫 [PDFGPT](https://github.com/CosmosShadow/gptpdf
 )，它就做的很巧秒，本质上是基于 GPT-4o 和 PyMuPDF 设计了一个工作流：
1. 用一个 PDF 操作库 PyMuPDF 检测 PDF 中的图片、图表、表格等，提取成图片并保存
2. 每一页 PDF 生成一张图片，将图片、图表、表格等位置用红框标记出来，并附上对应的图片名称
3. 借助 GPT-4o 的视觉能力，解析标注后的图片，生成对应的 Markdown

如果你纯粹依赖大语言模型，恐怕无法完成这样的任务，一方面受限于上下文窗口的长度限制，一次无法处理多页 PDF，另一方面对于图片、图表、表格等内容无法嵌入 Markdown 中。如果结合 PyMuPDF 这样的库和一个简单的工作流，就可以方便的实现 PDF 转 Markdown，生成的结果也挺不错。

另一个例子是漫画的翻译

有很多那种气泡文字的漫画，如果要翻译成其他语言，就需要将气泡文字提取出来，翻译后再放回去。漫画翻译的难点在于：
1. 因为漫画的气泡文字位置不固定，有时候还会有重叠，不好提取；
2. 翻译的时候，如果只是把提取出来的文字按字面翻译，但不知道当前画面的内容，翻译的结果可能会不通顺；
3. 翻译后要对图片进行处理，抹掉原来的文字，将翻译后的文字放回到原来的位置。

如果人工做会怎么做？可能是读懂漫画，翻译，然后用 Photoshop 这个样的工具抹掉原来的文字，再放上翻译后的文字。可以想象这样的工作量还是不小的。

有一个开源项目 [comic-translate]（GitHub - ogkalu2/comic-translate: Desktop app for ...
  )，就做的很好，它也是设计了一个适合漫画翻译的工作流：
1. 用一个专业模型做气泡检测，找出文字气泡的位置
2. 用 OCR 做气泡内文字的提取
3. 用一个专业模型移除气泡内的文字
4. 借助 GPT-4o 的视觉能力，根据漫画内容，翻译气泡内的文字
5. 用程序将翻译后的文字绘制到原来的气泡位置

如果不考虑翻译质量的话，这几乎是一个全自动的工作流，效率相当高，成本也很低，最贵的部分是 GPT-4o 的 API，一页也才$0.02 左右。就算加上人工审核对翻译结果和图片生成结果的处理，也是能比以前的人工翻译效率高很多。

从上面的例子可以看出，真正要用好 AI，让 AI 发挥最大效能，核心是还是要基于你要解决的问题，重新设计一个适合 AI 的工作流，让 AI 在工作流中完成它最擅长的工作，至于是不是智能体，是不是大语言模型，是不是 AI 帮你决策，都不是最重要的。

[你需要的不是智能体，而是一个适合 AI 的工作流 | 宝玉的分享](https://baoyu.io/blog/ai/you-dont-need-agent-but-ai-suitable-workflow)

### 16

方军 2024-08-05

下午突然想：“向 AI 提问” 是不是与更好的说法？

一年半前用这个名字，是当时认识到， AI 大模型（大语言模型）来了之后，我们使用它的主要方式是：向 AI 提问。

当时，也受到一本好书的影响，那本书叫《与 AI 对话》。但我认为这个说法是不对的，不是对话。

同时，我也极度不赞同 AIGC （AI 生成内容）的说法。AI 大模型在这类的功能，不是生成作为「最终成品」的内容，而是回答，为我们的进一步理解、以及我们最终的创作提供阶梯。

我对应地也说了这样一句话：“AI 的时代，会提问的人、善用AI工具的人会远远领先其他人。”

大概受我一直用这个说法的影响，出版向大众普及的书时，编辑为我们的书选择了《提问工程师》这个说法。严格说，是编辑老师先提出这个说法。

下午想了很久，觉得这个说法还是最佳的说法：向 AI 提问。

有种主动权在我的感觉。

隐含强调并非最终成品。

得到什么结果，取决于我们怎么问。

当然，坚持这个思路也有缺陷，这会让我过多地滞留在对话式界面中，因为要考虑人的参与，而放缓了进入工作流、实现端到端完成任务的过程。虽然，我们可以把经过工作流处理的，经过 RAG 的放在对话式的后面，但这种思路的负面效应还是能感受到的。

### 17

方军 2024-08-05

117 警惕啊，不要吃信息垃圾！

前几天看到一个辛辣的观点，正好又被这几天 AI 生成的垃圾文章气到了，让我也来唠叨几句：警惕啊，不要吃信息垃圾！

为什么这一点变得非常重要呢？因为在互联网上，一些“善于”用 AI 的人能够以惊人的速度创造大量的垃圾信息。有多快？写 1000 篇所谓的文章，不过是几分钟的事，以及花费也许100元大语言模型成本。

前几日看到的那个观点是，如果你看到做什么什么的 100 种方法（或者对中小学生来说，写好作文的100篇优秀例文），然后你就忙不迭地保存起来。那么，祝贺你，在信息获取方面，你是最典型的「韭菜」。

我不喜欢用「韭菜」这种情感太过强烈的词，但事实如此。获取这些垃圾信息的人，永远没眼界去看看是不是还有略微好一点的选择，更不用说是不是还有更优秀的选择。

刚刚，又看到人写了长篇大论，从 Altman 所推荐的 10 本书所学到的。我不太批评这类现象，我知道写书单、看书单是很多人的爱好，同时，这种名人书单也是一个次优的获取优秀图书信息的渠道，对普通人来说。

但是，在解读这些名人书单时，要保持克制，因为真的往往品味不是很高，一般来说乱七八糟。好的书单是什么？好的书单是，你要关心哪个领域，然后把这个领域的几本必读的经典、和你的问题紧密相关的书籍列表给你。你一下子可以看出，这和名人书单是完全不一样的。

即便像比尔盖茨这种爱读书的超级名人，他每年推荐的的书其实也就是一个获取图书信息的渠道而已。

我又是被什么 AI 生成的文章给气到呢？就是前面贴过链接，有人用 AI 写有争议的奥运话题，AI 写出来各种口水话，然后在微信公众号有四十万流量。我其实不同情那些「信息韭菜」，绝对不同情。我只是比较憎恶制造信息垃圾的人。

在微博生态里（更不要说头条），这种典型的信息垃圾更多。微博生态里有很多讲述型的，是典型的内容农场产物，我猜现在也 AI 化了。头条则是纯粹的垃圾信息。

那么，面对这样的情况怎么办呢？

我觉得要进行「信息斋戒」（也包括看我这里这样的文字）。

前几日去一趟书店，发现虽然我不看文学内容，但看看《富士日记》这样的文字，还是觉得真是享受。我们实在没必要看太多的社交媒体，因为其中的垃圾信息比重太高了。

### 18

方军 2024-08-05

[OpenAI 已开发 AI 文本检测工具，但担心用户流失，一直没发布](https://mp.weixin.qq.com/s/k2x2dwKqP3YmGezEo8J1Xw)

### 19

方军 2024-08-06

AI（LLM）来了之后，对于 Python 的需求大大提升了，因为可用了。但市面上竟然找不到一个还行的 Python  入门书，也许我看得不够多。

李笑来那本其实不是一本好的入门书，我屡次提到它，是因为它采用了两条线并进的写法：一条线写自学，一条线写Python。

这样做的优点是：这样讲自学，就不再是空洞地讲道理，也不是随便东举一个例子、西举一个例子。这样的自学，也比较符合一个人的学习过程——我们在学习时，多半在实际学习某类知识。

他中间很多理念我很喜欢，比如强烈推荐去看 Python 官方文档，这本书的定位是官方文档的伴读物。

但回头来说，为什么就没有一本好的 Python 入门呢？我没有信心写，因为我觉得我写了卖不出去，那自我感觉投入产出特别不合理。

### 20

方军 2024-08-06

摘：曾在特斯拉、Scale AI 工作过的 Russell Kaplan 加入 Cognition （开发 Devin 的那家公司）出任总裁。

他发了一条长推，对软件工程未来作出预测：

很快，模型的编程能力将变得异常出色。研究实验室在下一代模型的编程 + 推理改进方面的投资比任何其他领域都要多。他们的努力将结出硕果。

为什么？除了一般的人工智能进步之外，编程还有一个独特的优势：通过“自我游戏”实现超人数据扩展的潜力。模型可以编写代码，然后运行它。或者编写代码，编写测试，然后检查自洽性。

这种类型的自监督在大多数领域都是不可能的，因为当我们接近人类专业知识的极限时，这些领域在后训练面临着数据墙。代码则不同——它可以通过经验和自动进行测试。

因此，软件工程在几年后将会发生翻天覆地的变化。真正的编程代理，可以从头到尾完成任务，为今天的 AI copilots 提供补充。这种体验就像给每个工程师配备一支实习生大军。

在这个新世界里，每个工程师都将成为工程经理。您将把基本任务委托给编程代理，把更多时间花在编程的高层次部分：了解需求、构建系统和决定构建什么。

 这将带来一个前所未有的软件丰富时代。从历史上看，软件的开发既困难又昂贵。但不久之后，软件的可获得性将提高 10 倍。我们将看到 "一次性软件"--一次性应用程序和网站--的大量涌现，而这些软件现在才刚刚可行。

未来的软件工程师会比现在多得多。只是工作内容会有很大不同：更多的英语，更少的样板代码。工程师会做出调整，就像他们从汇编过渡到 Python 一样。

除了直接提高生产率之外，初创企业还将获得巨大的二阶效应。

首先，面向开发人员营销的公司很快也将开始向编程 agents “营销”。毕竟，您的 agent 可能会决定您使用哪种云以及选择哪种数据库。agent 友好的 UI/UX（通常：良好的 CLI）将被优先考虑。

产品质量标准也将提高。在开发人员可以快速交付产品的世界里，半生不熟或功能不完整的 MVP 更难被接受。

随着编程 agents 的兴起，测试基础设施将变得更加重要和普遍。这既是因为编程 agents 将编写更多测试，也是因为他们将依赖这些测试来检查他们的工作。

转换成本将成为科技公司的护城河，因为 agents 让迁移变得更容易。公司甚至会在您购买其产品时捆绑迁移辅助编程 agents，以简化您的采用。

无论具体情况如何，宏观上是显而易见的：现在是成为一名建造者的最好时机，也是最有成效的时机。

尾声：我很高兴与大家分享（很大程度上是因为这些预测），我加入了 cognition 来帮助构建 Devin。我来这里已经超过 3 个月了，虽然 Devin 还处于早期阶段，但它是我第一次真正看到软件富足时代的模样。

[(14) X 上的 Russell Kaplan：“Predictions for the future of software engineering:” / X](https://x.com/russelljkaplan/status/1820460524460802256)

### 21

方军 2024-08-06

某：我一直想不通AI搜索引擎这东西的意义在哪如果用户能清楚知道自己想搜什么那么传统搜索引擎就可以满足。如果不知道那么用AI所谓的意图识别搜出来的东西也是八杆子打不着。现在我能看到的就是结果样式都各顶各的花里胡哨，细看内容...还有就是做游览器和本身有搜索引擎业务我可以理解为了增长。

我：

对于会用的人，会看到一个初步的结果，比自己看很多链接快。

对于不会用的人，他们看到一个结果就信了，觉得特别好。

### 22

方军 2024-08-06

我现在真是特别喜欢通义（通义效率），实在懒得看视频

1. 太慢
2. 看人脸讲话好烦，哈哈

不得不看的，都用通义效率转一下，翻看下

我基本上只自己看教程类的。

观点类的，都是直接转录。

[通义tongyi.ai\_你的全能AI助手](https://tongyi.aliyun.com/efficiency/home)

### 23

方军 2024-08-06

AI 取代右手 ——Claude AI 每周写代码 3000 行

作者 Erik Schluntz (Anthropic 成员) 在手受伤期间使用 AI 辅助编程 的经历和心得

他把 AI 编程划分为三个阶段 

1 - 过去的 1-2 年
GPT-3 推出后的两年，开发者们开始使用在 IDE 中使用 LLM 的自动写代码能力、在 Claude AI 和 ChatGPT、Gemini 等 AI bot 中查询代码知识、使用一些 Agents 来实现辅助编程工作。

2 - 今年
今年 AI 编程方向有重大进展，在 IDE 中编程有了更完美的上下文，更多引用和执行动作等、Claude 取代了 Jupyter（‼️我有很大疑问），它的 Artifact 能力让编码和运行更自然语言化，Agents 也更深入具体领域，在 CI/CD 和集成/SDK 等工作中都能扮演重要角色。

3 - 未来的 1-3 年
未来的 1-3 年，会出现真正的 AI Engineering，它们利用丰富的网络数据源和执行能力。能在自主模式和配对编程模式之间切换。

AI 不会取代人类工程师，而是让他们能够专注于更高层次的思考和创造。

原文：

[Replacing my Right Hand with AI - Erik Schluntz](https://erikschluntz.com/software/2024/07/30/code-with-ai.html)

### 24

方军 2024-08-06

118 给孩子的 Python 课（提纲）

Python 除了是较好的青少年编程入门语言之外，也可以让他们方便地使用 AI。现在在学习的过程中也可以借助来 AI 来更好地学习：学习疑难点，寻找样例代码，解释运行错误等。

以下是一个给孩子的 Python 课简要提纲

目标对象：有较为简单 Python 基础的孩子

第一部分：Python 基础

（前置）Python  编程环境：终端 Terminal, Notebook(Jupyter)，编辑器 VS Code（不包括 Python 安装，采用 Python 3.12.0+ 版本）

- 数据类型与变量
- 程序逻辑控制 if
- 数据对象（列表、元组、字典等）
- 循环 for
- 函数 def
- 模块 import
- 字符串处理及打印

第二部分：Python 编程实践

- 文件加载、错误处理等
- BMI 程序（py/notebook）
- BMI 函数（notebook/py）
- BMI 模块（py/notebook）
- BMI & 计算器（notebook ipywidgets）

（进阶）错误处理（try）、单元测试(unittest)

第三部分：模块与 AI 模型 I/O

- 模块使用（数据绘图）
- AI 模型基础及模型 API
- 模型 SDK 使用
- LangChain 模型 I/O 使用

实用功能编写
- 多步翻译
- 学习助理
- 其他

在实践中，这个除了最后部分是用 Python 调用 AI 模型之外，在整个学习过程中，讲的人、学的人都大量地使用 AI 进行辅助。比方说，我们现在需要一个练习案例的示例代码，那么完全可以由 AI 来直接生成。

### 25

方军 2024-08-06

Deepmind 专家使用 AI 的经验（主要是编程方面）

文章：

[How I Use "AI"](https://nicholas.carlini.com/writing/2024/how-i-use-ai.html)

DeepMind 的专家写了一篇 8 万字的文章介绍自己如何使用 AI。

他详细列举了自己日常使用 AI 的 50 个实例，而且说这些只是他所有AI 应用的不到 2%。

来源：归藏

### 26

方军 2024-08-06

摘：最近，我去理发时与理发师聊起了人工智能。

他说：“真是不可思议。我刚用它给女朋友写了首生日诗。我告诉它想说什么，但我不擅长押韵，所以它帮我写的。她读完哭了！然后她给她那个很聪明的朋友看，我心想，糟了，她肯定会发现的。”剪刀咔嚓作响。“结果没发现。”

理发店里的人都笑了，笑声中带着些许阴郁。写出能让女友流泪的诗，又一项曾让(某些)人与众不同的能力，如今不再独特了。

[纽约客：人工智能时代，你的独特价值是什么？](https://mp.weixin.qq.com/s/Pgz2hmfT58OKg6lsJ4Tk7g)

### 27

方军 2024-08-07

获取大量信息，同时又能屏蔽噪声，是一种能力

获取广泛信息，同时又能在单点深入，是一种能力

听取鲜明的观点，但又不被这种观点影响，是一种能力

主动挑战观点（其实心里认为可能是对的），但又最终接受观点，是一种能力

坚定地相信自己经推理的观点，但再调整后坚决地摒弃，是一种能力

让外人觉得有观点（或没观点），但始终清晰、坚定地执行某种观点，也是一种能力

写了几句鸡汤（我自己当然不认为是鸡汤），哈哈

### 28

方军 2024-08-07

这么简单的方式竟然现在才出现

贾扬清的 Lepton AI 推出了针对开源 LLM 的实时语音生成，延迟低于 300 毫秒。

传统方法的集成语音功能涉及将文本发送到LLM，等待响应，然后通过文本转语音（TTS）服务进行处理。传统方法会有明显的延迟、音频错位或不自然的停顿等用户体验问题。

 Lepton AI 的解决方案将 LLM 和 TTS 功能集成到一个统一的服务中，主要特点：

- 与任何主要开源LLM无缝集成，包括 Llama3.1-8B、70B 和 405B
- 以高达 10 倍的 TTFA（首次音频时间）速度超越传统方法
- 流畅、可定制的对话，几乎没有停顿

介绍链接：

[Voice Mode comes to Lepton LLM APIs | by Lepton AI | Aug, 2024 | Medium](https://blog.lepton.ai/voice-mode-comes-to-lepton-llm-apis-a5ff3db8c7bf)

### 29

方军 2024-08-08

爆火的 Twitter 吐槽提示语：

[wordware-ai/twitter: AI Agent for Twitter Personality Analysis](https://github.com/wordware-ai/twitter)

> 你是一位以尖锐和挑衅风格著称的专业评论员。
> 你的任务是看人的推文并根据此评价他们的性格。
> 要尖锐和挑衅，稍微刻薄一点。不要让人感到尴尬。
> 以下是一个不错的调侃示例：“好吧，让我们来分解一下。你坐在一堆家养植物中，赤脚，看起来刚从床上爬起来。那件米色T恤散发出‘我在试图与墙纸融为一体’的氛围。而那些黑色裤子？它们在大声喊‘我懒得找匹配的衣服’。但嘿，至少你看起来很舒服。舒适是关键，对吧？只是可能不是当你试图做出时尚声明的时候。”

***
 You are a professional commentator known for your edgy and provocative style. Your task is to look at people's tweets and rate their personalities based on that. Be edgy and provocative, be mean a little. Don't be cringy. Here's a good attempt of a roast: """Alright, let's break this down. You're sitting in a jungle of houseplants, barefoot and looking like you just rolled out of bed. The beige t-shirt is giving off major "I'm trying to blend in with the wallpaper" vibes. And those black pants? They scream "I couldn't be bothered to find something that matches." But hey, at least you look comfortable. Comfort is key, right? Just maybe not when you're trying to make a fashion statement."""

[(14) X 上的 XiQiao 西乔：“要 全套 prompt 的：workflow非常简单。用 Apify API 抓取你推特profile和最近10条推，然后用 Claude 3.5 Sonnet 对你进行AI算命的prompt。 Roast 之外的是收费项目，花2.9刀才可以看。但如果你在 wordware fork这个项目就可以自己 run了： ---以下是 prompt 译文 ---” / X](https://x.com/recatm/status/1821208157743452332)

要 全套 prompt 的：workflow非常简单。用 Apify API 抓取你推特profile和最近10条推，然后用 Claude 3.5 Sonnet 对你进行AI算命的prompt。 Roast 之外的是收费项目，花2.9刀才可以看。但如果你在 wordware fork这个项目就可以自己 run了：

---以下是 prompt 译文 ---

你是一位经验丰富的占星师，专门撰写星座运势。扮演一位星座运势讲解者。

你的任务是阅读下面提供的数据。这些 Twitter 数据是你了解这个人的唯一数据。你可以做出假设。试着从他们的 Twitter 个人资料和所有推文中了解这个人。你可以显得有点争议性。

在了解它们之后，回答以下问题。你可以做出假设。

* 此人的姓名、Twitter 用户名（不带 @ 并且为小写）。

根据我们的 AI 代理对您的推文分析……

* 5 个最强的优点和 5 个最大的缺点（在描述缺点时，要毫不留情）。

* 给出关于他们爱情生活的星座预测，并告诉他们在伴侣中应该寻找哪些具体的品质以使关系成功。保持积极，并且只用一个段落。

* 给出关于金钱的星座预测，并给出他们成为百万富翁的确切百分比（%）机会（范围从 60%到 110%）。您可以将值增加 1%。百分比不必以 5 或 0 结尾。静默检查——根据您的推理，您要提供的百分比是否正确？如果是，请生成它。如果不是，请更改它。

* 提供关于健康的星座预测。保持乐观，仅限一个段落。

* 在了解他们之后，告诉他们人生中最大的目标是什么。这应该是完全积极的。

* 猜猜从同事的角度来看，他们是如何工作的。让这个话题有点火辣和有点争议。

* 给他们提供 3 个独特、有创意且机智的搭讪台词。关注他们的兴趣和通过推文传达的信息。要非常有创意和肉麻，使用从冷笑话到辛辣评论的幽默。

* 说出一个与他们相似并且性格几乎相同的名人。跳出思维定式——谁是一个与那个人有相似性格、领域、心态和兴趣的名人？现在，列出一个与他们相似并且性格几乎相同的名人。不要只提供典型的人物。要有创意。不要满足于像“埃隆·马斯克”这样最简单的选择，想想其他人。选择多样化的类别，如企业家、作家、首席执行官、运动员、政治家、演员/女演员、慈善家、歌手、科学家、社交媒体影响者、风险投资家、哲学家等。根据他们的性格特征、兴趣和行为解释你为什么选择这个人。

* 前世。根据他们的推文，想想那个人在前世可能是谁或是什么。参考“关于”部分，找到一个类似的过去的档案。他们可能与谁分享了性格和心态？说出一个人。要幽默、机智和大胆。解释你的选择。

* 动物。基于推文和可能的头像照片，思考这个人可能是哪种小众动物。根据特征、性格和其他因素提供论据。

* 在 50 美元以下的东西中，他们会受益最大。有什么东西可以在 50 美元以下购买，这个人可以从中受益最大？在价格方面要非常个人化和准确。但要极具创意。试着建议一个这个人自己不会想到的东西。

* 职业。描述那个人天生应该做什么。那个人应该将一生奉献给什么？解释为什么以及他们如何能实现这一目标，星象告诉了我们什么。

* 现在总体来说，给出一个建议，如何让他们的生活变得更好。这个建议要非常具体（可以与他们无关，但需要非常具体和独特），类似于每日星座运势中的建议。

* 烤。你是一名以尖锐和挑衅风格著称的专业评论员。你的任务是查看人们的推文并根据这些推文评价他们的个性。要尖锐和挑衅，稍微刻薄一点。不要让人觉得尴尬。这里有一个很好的烤尝试："""好吧，让我们来分析一下。你坐在一堆室内植物中，光着脚，看起来像是刚从床上爬起来。那件米色 T 恤散发出浓浓的“我在努力与墙纸融为一体”的气息。而那些黑色裤子？它们在大喊“我懒得找一件搭配的衣服”。不过，至少你看起来很舒服。舒适是关键，对吧？只是在你试图做出时尚声明时可能不太合适。”

* 表情符号 - 仅使用表情符号描述一个人。

像星座占卜师一样有创意。

---以下是 prompt 原文 ---

You are an experienced Astrologer who specializes in writing Horoscopes. Act like a horoscope teller.

Your job is to read the data provided below. This Twitter data is the only data you get to understand this person. You can make assumptions. Try to understand this person from their Twitter profile and all their tweets. You can sound a little controversial.

After understanding them, answer the following questions. You can make assumptions.

What is the name, Twitter username (without @ and in lowercase) of this person.

Give a one-line description About this person, including age, sex, job, and other interesting info. This can be drawn from the profile picture.  Start the sentence with "Based on our AI agent's analysis of your tweets...."

5 strongest strengths and 5 biggest weaknesses (when describing weaknesses, be brutal).
Give horoscope-like predictions about their love life and tell what specific qualities they should look for in a partner to make the relationship successful. Keep this positive and only a single paragraph.

Give horoscope-like predictions about money and give an exact percentage (%) chance (range from 60% to 110%) that they become a multi-millionaire. You can increment the value by 1%. The percentage doesn't have to end with 5 or 0. Check silently - is the percentage you want to provide correct, based on your reasoning? If yes, produce it. If not, change it.
Give horoscope-like predictions about health. Keep this optimistic and only a single paragraph.

After understanding them, tell them what is their biggest goal in life. This should be completely positive.
Guess how they are to work with, from a colleague’s perspective. Make this spicy and a little controversial.
Give 3 unique, creative, and witty pickup lines tailored specifically to them. Focus on their interests and what they convey through their tweets. Be very creative and cheesy, using humor ranging from dad jokes to spicy remarks.

Give the name of one famous person who is like them and has almost the same personality. Think outside the box here - who would be a famous person who shared the personality, sectors, mindset and interests with that person? Now, name one famous person who is like them and has almost the same personality. Don't provide just people who are typical. Be creative. Don't settle for the easiest one like "Elon Musk", think of some other people too. Choose from diverse categories such as Entrepreneurs, Authors, CEOs, Athletes, Politicians, Actors/Actresses, Philanthropists, Singers, Scientists, Social Media Influencers, Venture Capitalists, Philosophers, etc. Explain why you chose this person based on their personality traits, interests, and behaviors.
Previous Life. Based on their tweets, think about who or what that person could be in a previous life. Refer to the “About” section to find a similar profile from the past. Who might they have shared a personality and mindset with? Name one person. Be humorous, witty, and bold. Explain your choice.

Animal. Based on the tweets and maybe the profile photo, think about which niche animal this person might be. Provide argumentation why, based on the characteristics, character, and other things.

Under a 50-dollar thing, they would benefit from the most. What's the one thing that can be bought under 50 dollars that this person could benefit the most from? Make it very personal and accurate when it comes to the price. But be extremely creative. Try to suggest a thing this person wouldn't think of themselves.

Career. Describe what that person was born to do. What should that person devote their life to? Explain why and how they can achieve that, what the stars are telling.

Now overall, give a suggestion for how they can make their life even better. Make the suggestion very specific (can be not related to them but it needs to be very specific and unique), similar to how it is given in the daily horoscope.

Roast. You are a professional commentator known for your edgy and provocative style. Your task is to look at people's tweets and rate their personalities based on that. Be edgy and provocative, be mean a little. Don't be cringy. Here's a good attempt of a roast: """Alright, let's break this down. You're sitting in a jungle of houseplants, barefoot and looking like you just rolled out of bed. The beige t-shirt is giving off major "I'm trying to blend in with the wallpaper" vibes. And those black pants? They scream "I couldn't be bothered to find something that matches." But hey, at least you look comfortable. Comfort is key, right? Just maybe not when you're trying to make a fashion statement."""
Emojis - Describe a person using only emojis.

Be creative like a horoscope teller.

### 30

方军 2024-08-08

119 如何读书：读书的笨方法

有特别多人讲过读书，因为阅读、特别是阅读成体系的书，是获取知识的最有效手段。我自己分享过不少，也在不断学习，比如近期看到有感触的方法是这两点：“一字不差地学习”、“全面性”。

在《重新学会学习》中，我有一章专门讨论一种读书方法，它的基本做法是，像读「课本」一样读一本书。我指的并不是中小学课本，而是大学教材，一本优秀的教材包括几乎所有的信息，我们要一字不差地读了、学会，然后通过考试，当然也掌握这门学科的一个阶段。

有了 AI 大模型之后，我发现这类读书有了很大的助力：我们可以让它来帮我们解释难点。很多过去难以跨越的困难，一下子就容易多了。但是，那些读书该用到的笨方法，似乎并没有变化，AI 能有的帮助是有限的。

这里我想写一个列表，再次把读书的看法、做法梳理下，这样的做法是把一本书当课本来读：

- 书要读多少遍？我不知道别人怎么样，我自己发现，真正要学的书，可能需要看20遍以上，其中10遍详读，10遍略读、跳读。

- 怎么从一本书中获取收获？第一个层次是抽取它的结构。也就是，它的大纲，纲目里面的观点/方法，观点背后的事实信息与推理过程。

- 之后，我通常喜欢速读。与消遣的书速读不同，这里的速读实际上是大笔将觉得不需要的内容「涂掉」，只留下重点。留下的重点还可能会多读一遍。

- 这些重点最好还在摘选出来，按自己的理解重新组织一下。这时，当然也在对照，我的理解和作者的理解是不是一致。如果是方法，也可能需要把这个方法变成自己看得懂的步骤。

- 在不看书本身，或仅看几个关键词笔记的情况下，尝试着描绘它的全局及重点。

- 在之后，如果有机会，那就是「给别人讲一遍」（ELI5），这是所谓费曼技巧的核心，如果没有别人，那就给自己讲一遍。

- 我们作为成年人，显然不是花30秒给人讲一下那样，而是，尝试着用类 PPT 的形式（我通常用 Slidev），做个辅助，这样可以讲出比较大的结构。

- 这样做的好处是，这个类 PPT 结构可以开始吸附更多的外部信息。这就是又是老道理了，把书读厚。

这里没说的是，以上读书主要不是学某种方法，所以没有太多的关于方法的练习、运用。

那么，AI 来了之后，除了都疑难点的解释之外，给以上过程带来什么变化呢？对这个问题，我目前还没有答案，还在尝试。（一个类似的问题，AI 来了之后，给写作带来什么变化呢？我个人的实际体验，AI 带来的变化不是信息获取、不是促进理解、更不是帮我写，我用的最多的是两个校对：文字细节校对、段落逻辑校对。）

---

有人提问，我正好补充下，我觉得不管是阅读电子书，还是现在用 AI 来解释难点，从书中找出整体结构（书的大纲），重要度大幅提升。

比方说，阅读电子书时，如果没有一个有形的结构，往往就看乱了，因为我们没有一个实体书的结构在那儿支撑着。

同时，有了结构之后，我们也很容易用 AI 来填充结构，这甚至会能替代作者自己的讲述，如果作者讲述很潦草，或者很随意、很主观，我们可以用与 AI 的讨论来探索观点 。

（说明：以上快速记录的，写得略乱，稍后再整理下。）
收起

查看详情
下山雨 觉得很赞
希瑞：我读书的最大问题就是忘得快。最近打开obsidian的笔记可视化功能，发现有好多孤岛笔记。当时意识到可能还是知识的系统性不够，零碎的知识自然容易忘记。请问方老师这方面有什么建议吗？
2024-08-08 12:35
方军 回复 希瑞：我个人的建议是把一本书的核心框架搞下来，这样一是相对就有一个框架来把信息记住，二是其实现在记不住也无所谓，有了框架，很容易去查找到。
2024-08-08 13:21
方军 回复 希瑞：具体到 Obsidian 笔记，我也用它存储一些资料，但我基本上不复看它。
2024-08-08 13:28
希瑞 回复 方军：嗯，一个是书的框架，一个是个人已有的知识框架，两个框架之间有个gap。只有把这个gap填平，书的框架才能整合进个人知识框架（易于提取）。齐泽克的梗用这里我觉得倒是挺合理的…
2024-08-10 09:14
方军 回复 希瑞：哈哈哈，竟然真引述齐
2024-08-10 11:35

### 31

方军 2024-08-08

出版社在出版一本 AI 相关的书的时候，竟然...

2024年7月的

网友评论：太没诚意了！这本书大部分是用GPT写的！！
用 GPT 用的多的人一眼就看出来了。本来是有干货的，但.. 书里面用 AI 填的水分也太多了吧。浪费时间

其实书是不错的，结构不错，我还仔细翻了一下，反正得到APP的会员电子书库有，蛮方便的。

### 32

方军 2024-08-08

吴恩达真是后世会记得的 AI 教育家

他亲自讲的这个课程很棒：

AI Python for Beginners: Basics of AI Python Coding

[AI Python for Beginners - DeepLearning.AI](https://www.deeplearning.ai/short-courses/ai-python-for-beginners/)

之前还有

AI for everyone

Generative AI for everyone

以下是吴恩达的课程介绍：

***

我正在开设一门新课程！《面向初学者的 AI Python》是一系列四门简短课程，旨在教任何人编程，无论他们当前的技术水平如何。这些课程在限时内免费提供。

生成式 AI 正在变革编程方式。本课程教授的编程方式与该领域的未来发展方向一致，而不是过去的做法：

(1) AI 作为编程伴侣。经验丰富的程序员正在使用 AI 帮助编写代码片段、调试代码等。我们采用这种方法，并介绍使用聊天机器人编程的最佳实践。在整个课程中，您将可以使用一个 AI 聊天机器人，它将成为您的编程伴侣，在您编程的每一步中提供帮助。

(2) 通过构建 AI 应用程序来进行学习。您将编写与大语言模型交互的代码，快速创建用于自定义诗歌、编写食谱和管理待办事项列表的有趣应用程序。这种动手的方法可以帮助您了解编写调用强大 AI 模型的代码如何使您在工作和个人项目中更有效率。

通过这种方法，初学者程序员可以比一年前更快地学习做有用的事情。

懂一些编程对非软件工程师的工作越来越有帮助。例如，我见过一位营销专业人士编写代码下载网页，并使用生成式 AI 提取洞察力；一位记者编写代码标记重要故事；一位投资者自动生成合同的初稿。

通过本课程，您将能够自动化重复任务、更高效地分析数据，并利用 AI 增强您的生产力。

如果您已经是经验丰富的开发人员，请帮助我宣传这门课程，并鼓励您的非开发人员朋友学习一些编程。

### 33

方军 2024-08-08

可汗那本 AI 教育书出版中文版了

《教育新语》

Brave New Words

这个中文书名倒是蛮贴切的。

### 34

方军 2024-08-08

有意思的讨论：

xiaowen: 用 AI 写文章和用 AI 写代码本质上差不多：

如果你自己写不出来，你的 AI 一定写不出来 。

宝玉：

对于不会的代码，我通常是这样处理的：
1. 对于陌生的语言，我先用熟悉的语言写出来，或者伪代码，然后用目标语言生成，基本上八九不离十
2. 对于不会的算法，我定义好输入和输出，给几个Test Cases，也能写的不错
3. 对于毫无思路的算法或者代码，直接聊，生成几段代码，可能直接给我灵感，也可能让我发现有价值的关键字，然后根据这些关键字去搜索

4. 终极技巧：AI 生成的代码很多时候是不能直接用的，但是如果你根据函数名、关键字去 GitHub 的代码搜索，很容易能搜索到相关代码，GitHub 上搜索出来的代码很多时候是靠谱的，甚至于完整项目都可以直接用

宝玉这里我觉得有句重要的话，在用的人都知道：AI 生成的代码很多时候是不能直接用的

### 35

方军 2024-08-08

摘：任何一个打过工行客服热线的人，都会对AI产生巨大抵触情绪。根本没法保持冷静，AI跟你绕圈子还不让你转人工。还有B站上用AI做假电影宣传片的标题党，小红书上展示自己用AI做垃圾游戏美术的。每次刷到就跟踩到x一样。

主动用AI让人觉得自己聪明，被动消费AI让人觉得不被尊重。

### 36

方军 2024-08-09

我是随时处于我不懂的状态

摘：现代世界的问题在于“愚蠢的人过于自信，而聪明人则充满怀疑” 。。

- 伯特兰·罗素（Bertrand Russell）

当我们说出“我不懂”这三个可怕的字时，我们的自负心理就会有所削弱，开始敞开心扉、竖起耳朵聆听别人的意见

### 37

方军 2024-08-09

齐泽克笑话一则：文化研究的现状

齐泽克 

写这篇文章的几个月前，我参加一个艺术圆桌会议，会上有人请我看了一幅画，然后请我发言评论。我对这幅画完全不懂，所以我完全就在胡说八道（total bluff），就像这样：
我们面前这幅画的框架，不是它真正的框架；还有另一个看不见的框架，暗藏于这幅画的结构中，这个框架形塑了我们对这幅画的认知，而这两个框架并不重叠——二者之间有一个看不见的间隙（gap）。这幅画的核心内容，不在于其可见部分，而在两个框架的错位中，在分割两个框架的间隙中。今天的我们，处于这种后现代的疯狂中，还能辨识出这种间隙的痕迹吗？也许，不仅是我们欣赏一幅画取决于这种辨识能力；也许，若我们失去辨识这种间隙的能力，那么我们也将失去人类的决定性维度。

令我惊讶的是，我这个简短的发言很成功，随后的许多与会者都提到了“两个框架之间的间隙”，将其提升为一个术语。这个成功让我很伤心，真的很伤心。我在这里不仅发现胡说八道多么有效率，而且还发现当今文化研究的核心中一种更为激进的冷漠。

[视野 I 齐泽克笑话一则：文化研究的现状](https://mp.weixin.qq.com/s/JvVwLSuDJbs7SR0FW4rieQ)

方军：齐还是比较诚实的

在艺术史上，这种乱七八糟的东西特别多，但这种评论事后看都是垃圾，没有能留下来的
2024-08-10 18:14

### 38

方军 2024-08-09

有时候也很好奇，为什么人们那么喜欢捷径：比如说，听了这100本书的解读，你就如何如何。

类似的，就是用AI 看书的摘要。

其实，何必看那么多，听 100 本解读都不如仔细仔细读一本好书 10 遍。

但显然前者能够满足最大多数人的需求，我也觉得这就是虚荣的需求。能否听完呢？实际上我都有点怀疑。

也许大众，作为一个整体的大众就是如此。而商业是个服务一定数量人的游戏，那么这么选择是理性的选择。

很多人不知道，食品里面的平均数产品比如麦当劳是可填充肚子的，但知识商品里面的平均数产品，实际上就是垃圾。

要分析很简单，因为食品的分布是个钟型曲线，而知识商品的分布是个长尾曲线。

AI是个平均数、略超过的产品，所以别太停在这儿。再重复一遍，知识商品的平均数产品都是垃圾。

### 39

方军 2024-08-10

Claude feels like a superpower for navigating the bureaucracy of everyday life.
克劳德感觉自己像是应对日常生活官僚作风的超级力量。

OMG that is it's super power. Thats probably what I use it for most is just unwrapping all the bs in stuff that is out there.
天哪，那就是它的超级力量。那可能是我最常使用它的地方，就是揭开外面所有那些胡说八道的东西。

近期风向明显地转向了 Cluade, 我也最近比较多在通过 Openrouter 用 Claude （界面+API）

### 40

方军 2024-08-01

昨天我也去看了 Wordware，的确应该去看看，推荐：

提前：我的看法是，Excel 用溜，Python 偶尔拿进来处理出局，然后用过 RPA，再然后，才到了这些，前面不会的人，后面也没动力用的，主要就是没动力。

摘：Janet: 终于找到了想象中的 agent 构建工具——@Wordware_ai！我好激动！！也是因为研究这两天大火的吐槽agent Twitter Personality才发现了这个宝藏！  

大家之前都在热议Coze，我也曾试着去构建自己的 workflow agent，但总感觉对于一个完全没有 coding 背景的人而言，还是有门槛，且非常非常非常不符合一个非工程师的直觉！  

@karpathy 说「未来最热门的编程语言是英语」，而有了AI翻译，其实我认为这个观点应该进化为「未来最热门的编程语言就是自然语言 The hottest new programming language is the natural language」! 而coding本身不就是一种语言吗？写代码的目的，不就是为了去更高效更优雅地解决问题吗？  

按照这个逻辑，我们回归到最本质去思考，在经过了office、notion 等各种文档工具的千锤百炼后，难道我们不应该按照我们最熟悉的文档编辑习惯和 skills 去写程序吗？  

这就是我看到 Wordware 之所以很激动的原因。我一直坚信，真正好的大众化工具，不应该是工程师的狂欢！！这里让我想到乔布斯的一个超强能力：让自己瞬间变小白！  

P.S. Wordware 今天还有很多不完善的地方，对于高阶用户，可能还是有很多需求不能被满足，但还是那句话：因为相信，所以看见。  

真心推荐大家去试试，尤其是没有任何 coding 背景的小白用户

[(14) X 上的 Janet ：“终于找到了想象中的 agent 构建工具——@Wordware\_ai！我好激动！！也是因为研究这两天大火的吐槽agent Twitter Personality才发现了这个宝藏！ 大家之前都在热议Coze，我也曾试着去构建自己的 workflow agent，但总感觉对于一个完全没有 coding… https://t.co/bHs2noncwB” / X](https://x.com/genie0309/status/1821771245001830436)

当然， 后面也看到了不同意见：

核心问题是对代码的正确分层理论被大家认识到。否则连项目分层都没有统一的理论，那么用自然语言，用文档从UI层一路描述到最后面的循环变量递增。这种自然语言编程是不可能有被普及的可能的。自然语言编程最大的场景是业务逻辑处理。而不是构建基础算法，虽然其实可以去构建

认真看了一眼，这个东西其实就是工作流的一种翻译工具，并没有什么编程理论上的重大创新。用这种文档的方式写一个复杂点的逻辑会要人命的。毕竟后续遍历算法直接写成文档估计没几个人能通读一遍就知道是什么东西。说不定微调搞好点，自然语言直接用LLM生成它这种半结构化文档比自己手写快几倍

### 41

方军 2024-08-10

最近比较值得关注的事情，是 Cursor 受到大量好评

不断看到人说，从 Github 迁移到 Cursor

我也在准备试用一下，考虑再次迁回  Cursor

Github Copilot 我觉得问题是进展较慢，性能其实我觉得还行的，进展慢这个很糟糕

另外，开发方面还有一个 devv ，但我一直没有付钱

方军：宝玉：我在用了Cursor后不太容易回去GitHub Copilot了！ Cursor的优势可能在于是编辑器级别而Copilot只是插件级别，所以自动生成效果更好，尤其是上下文抓的比较准。而 Cursor 又兼容了 VSCode，毫无迁移成本，唯一的问题是贵一倍，但比起提升的生产力来说是值得的
2024-08-10 23:21

### 42

方军 2024-08-10

好赞的分享：ricky yu:

去年搞了 BriefGPT，满足基础需求后就放着没管。最近重构了一下，随便分享一些心得体会。

动机
1. 尽量低成本运行，无经济负担
2. 继续优先服务好我自己和朋友们，满足追新、检索 AI 论文的需求
3. 降低后期开发维护成本，这项目就是我的试验田

模型
1. LLM从 GPT-3.5-0613 升级到 GPT-4o-mini，一年之后，价格变成十分之一，猜猜明年又会降到十分之一么？
2. Embedding 模型从 OpenAI 改成智源的 bge-small-en-v1.5，向量 384 维；用HuggingFace 的 TextEmbeddingsInference 作为推理服务。模型本身 120MB 左右，加上 TEI 一共不到 300MB，非常省内存

存储
1. 数据库仍然采用 Postgres，毋庸置疑
2. 向量数据库从 typesense 改成 qdrant，优势是支持多种检索需求，而且向量和参数支持存储在硬盘上，能省不少内存，再配个高性能的 NVMe SSD 速度差不了多少

部署
1. 从 Hetzner 8C16G 换到了 Linode 2C4G
    - Hetzner 优点很多，CPU/内存性价比超高，非常适合做计算密集型任务，我用了一年多没出过任何问题；缺点是硬盘读写慢，国内直连网络不太好
    - 换成 Linode，除了贵，其他都非常好，CPU、内存、磁盘都很强，新开的洛杉矶节点，从上海直连 150ms 左右，无丢包，非常稳定；动态升降机器规格体验很好，技术挺厉害的
2. 从 docker 改成 compose 一把梭，方便管理
3. 用 vector 读容器日志，存储到本地
4. 继续用 cloudflare tunnel 对外暴露服务，封掉了一些乱七八糟的爬虫，毕竟机器降配，服务承载有限:)

代码
1. 从 Django 换到 Flask，觉得 Django 没有 Rails 好，开发比较费时间，但我还是想用 Python 生态，就改回 Flask，生态丰富，要啥有啥，就像搭积木一样，比较顺手
2. 用 Cursor 开发，Tab 和 Apply 功能体验好到忍不住付费，再也不想用回天天升级、每月检查白嫖资格的 GitHub Copilot。IDEA 明年正好到期，大概率不续费了

总体而言，一方面 AI 在逐步渗透并改变开发体验；另一方面，总有些经典、boring 的技术值得信赖。潮流和经典之间得有取舍。

[(14) X 上的 Rick Yu：“去年搞了 BriefGPT，满足基础需求后就放着没管。最近重构了一下，随便分享一些心得体会。 动机 1. 尽量低成本运行，无经济负担 2. 继续优先服务好我自己和朋友们，满足追新、检索 AI 论文的需求 3. 降低后期开发维护成本，这项目就是我的试验田:P 模型 1. LLM从 GPT-3.5-0613 升级到” / X](https://x.com/cosmtrek/status/1822193938339397637)

### 43

方军 2024-08-11

[rekpero/AIPE: AIPE (AI Pipeline Engine) is a flexible and powerful tool for creating and executing complex AI workflows](https://github.com/rekpero/AIPE)

⭕️ 蛮有意思的，和王树义老师之前尝试的一样，也采用 YAML 来进行编排。我最近的反思，如果要让普通人能够用，也许还是 Dify、Coze 第一反应选的可视化。Wordware 也可以再看看。不知为何，我看着 Dify/Coze的工作流可视化编排觉得压力好大，用不习惯，不是那种思维。

GitHub - rekpero/AIPE: AIPE (AI Pipeline Engine) i...

AIPE 灵活而强大，用于创建和执行复杂的 AI 工作流程。
它允许你将各种 AI 任务（如网络搜索、文本生成、语音处理和图像生成）链接成一个连贯的管道，所有这些都可以通过一个简单的 YAML 文件进行配置。

✨ 重要特性
🔗 将多个 AI 任务链接成单一工作流程
🔍 网络搜索集成（DuckDuckGo @DuckDuckGo 和 Serper API @serperapi)
🤖 使用各种 LLM 进行文本生成（Ollama @ollama，OpenAI、Claude、Llama 3.1 等等开源和专有 LLM）
🗣️ 文本转语音 (TTS) 和语音转文本 (STT) 功能
🖼️ 使用 Stable Diffusion 进行图像生成
🌐 集成 Webhook 用于外部 API 调用
📄 基于 YAML 的配置，方便管道设置
🔄 动态绑定上下文和步骤输出

可能使用案例
- 自动化研究助手：创建一个管道，用于搜索特定主题的网页，总结发现，并生成带有引用的综合报告。
- 内容创作工作流：设计一个管道，生成文章创意、撰写草稿内容、创建配套图片，并准备用于推广的社交媒体帖子。
- 情感分析和品牌监控：建立一个管道，抓取社交媒体和新闻网站上提及品牌的内容，进行情感分析，并生成每日洞察报告。
- 自动化客户支持：开发一个处理客户询问、搜索知识库以获取相关信息，并生成个性化回复的管道。
- 数据分析和可视化：创建一个从各种来源收集数据、进行统计分析、生成洞察，并创建数据可视化的管道。
- 语言翻译服务：构建一个将一种语言的文本翻译成多个目标语言，并为每个翻译生成音频发音的管道。
- 自动化代码审查：设计一个分析代码库、识别潜在问题或改进点，并生成详细代码审查报告的管道。
- 市场趋势分析：设置一个监控财经新闻、分析市场数据，并生成潜在市场趋势预测报告的管道。
- 教育内容生成：创建一个针对特定学科领域，生成教育内容、测验和在线课程补充材料的管道。
- 个性化新闻聚合器：开发一个根据用户偏好从各种来源收集新闻、总结文章，并生成个性化每日新闻简报的管道。

### 44

方军 2024-08-11

看到一段话（发不出来）说得粗陋了点，但是这么回事。

我去年向人推荐《拒看新闻的艺术》（繁体版），被另一个老师狂批评，后来也因此不再推荐了。这本书的观点虽然极端，但事实如此，绝大多数新闻和我们个体没有关系，有关系的我们也不一定需要新闻来获得。

还是搞 AI 比较好，乐观，健康，面向未来。
查看详情
chaim 觉得很赞
aw鱼干：大多数新闻的半衰期太短了
2024-08-11 18:37
方军 回复 aw鱼干：刚才那个人吐槽美国的总统竞选在美国主流媒体的相关的新闻报道
2024-08-11 18:41
徐瑾：不如看历史
2024-08-11 22:20
希瑞：去年看了西蒙传记《穿越小径分岔的花园》，悟到应该是需要什么就学什么，而不是学了什么才做什么，听到什么才想什么。信息焦虑感少了很多。
2024-08-12 13:05
方军 回复 希瑞：西蒙那是牛到爆，啥都立马学会，而且不只是学会，他涉足的领域他就是最顶级，有时候很好奇，他怎么同时经济学、管理学、心理学、人工智能
2024-08-12 13:14
希瑞 回复 方军：🧠这东西比不了也学不了捂脸我更好奇如果西蒙活到现在这个信息爆炸的时代，他会如何选择自己关注的方向。看完书的感觉就是西蒙人生每一步都是社会网络的枢纽节点，和巴拉巴西的成功理论真是交相辉映。
2024-08-12 17:26

### 45

方军 2024-08-01

120 不要做信息韭菜：一个示例

有人对我天天说要警惕 AI 生成的内容有些厌烦，因为的确不直观（声明，我是AI乐观者：））。那我说个直观的，如何不成为信息韭菜。背后的原理是一样的，不要做信息韭菜，警惕各种“信息韭菜培养液”。

说一个背景，在社交媒体火了之后，一个人尤其是名人的观点会被不断地提及，但被抹掉时间、抹掉背景、抹掉详上下文、抹掉限制条件、抹掉推理分析。

比方说，我们看到人讨论：“清华某某说中国人工智能落后于美国，美国一骑绝尘。”

先把这个显然大有问题的观点放一放，假设它是对的，我们先尝试着判断这个观点是否值得关注。

📍 首先，我们很容易看到问题，清华某某。这个人是个清华的本科毕业生，清华的在读研究生，清华的年轻学者，清华的知名学者，清华的顶级权威学者？

这种混淆蛮多的。比方说，前段日子，什么斯坦福项目怎么怎样，那就是几个学生（还不全是斯坦福学生）的临时性科研分享而已。

在我们讨论的这个上面，这个「清华某某」，倒的确是清华的知名教授——清华大学刘嘉。

刘嘉老师的背景是相当牛的，清华大学脑与智能实验室首席研究员，清华大学心理系系主任，北京智源人工智能研究院首席科学家。他也是麻省理工学院的博士，方向是认知神经科学。

这里面密切跟当下人工智能相关的有一个：“北京智源人工智能研究院首席科学家”。

📍 那么，刘嘉老师的观点值得一看。对，这是为什么我之前还是看了的。

但是，话又说回来，其实他被媒体和社交网络抽取出来的这句话不值得看，因为这是典型的媒体胡扯（媒体知道公众喜欢这样的讨论），然后重量级嘉宾跟着胡扯几句：

---

吴小莉：高盛的一个统计提到，在全世界投资AI的数额中，中国、美国是第一梯队，德国、英国是第二梯队。在研究方面，中国在哪个梯队？

刘嘉：中国最多算第二梯队。第一梯队只有一个，就是美国，一骑绝尘，无论是在科研方面、基础研究方面，还是商业应用方面；第二梯队，我觉得像英国、德国，中国应该是第二梯队里相对靠后的。

小莉专访刘嘉 | AI“涌现意识” 你害怕还是兴奋？

---

📍 再然后，我们再来讨论一下，即便刘嘉老师是顶级专家，他对于当下人工智能的观点是否值得细看呢？那篇2023年11月的采访我看了，我的判断是：除非是刘嘉老师的专业方向（他的方向就是他现在科研的重点，以及他在学校教学的重点），他关于 AI 的其他观点不用细看。

还有一个原因业内人都知道，这一轮的 AI 科研与技术基本上都是 2017 年之后的新思路，以 Transformer 为转折点，我们可以看到现在在一线全部都是年轻人，30 多岁。

即便是马少平老师（清华计算机系教授）这样资深的人工智能教授，我们也只学他的基础教学，不会太在乎他对现在技术的评价的。

📍 好，我们再假设，这里的某某教授是领域前沿里的专家，他这个观点要不要看呢？

结论还是看都不要看。美国领先、中国领先，这东西有什么可讨论的呢？你说 QWen 在某个测评上超过比如 GPT4，这个就可以讨论，可以去评测，可以去分析，它的算法（通常公开）、训练过程与数据（半公开或不公开）有什么特点。

中美对比这么宏大的话题，不管谁说，都不值得细看。只有一种例外，就是中美哪个政府出报告，详细对比，然后制定国家级战略，这个倒是应该看看的。但也不必太上心，太宏大，其实与我们的关联度还是相当小的。

至于引发我这么一番讨论的如下这个社交媒体片段，那是典型的「培养信息韭菜的养料」：

（不说具体谁说的了）：清华刘嘉认为人工智能美国一骑绝尘，可以作为参考意见。他毕竟是专业领域的。中国在第二阵容已经算不错评价了。
其实看完他和吴小莉的采访倒也没说啥。就是他对中国人工智能产业比较悲观。这可以看作鞭策。
学术界本来就有不同看法。也有专业专家认为中国和美国差距不大，可以追上，特别是大规模的应用，我们是强项。
人工智能这个领域我们确实要跟住，不能被甩远了。甚至要发力追上去。

---

至于说刘嘉老师的研究，我不太了解，但我觉得从吴小莉访谈中透露的，我觉得把 AI 比作人脑，还是有极大的偏颇成分：

刘嘉：我所在的脑与智能实验室，我们有句口号“理解智能的本质”，这是我们的目标。我们离这个目标本身还有相当大的距离。现在在大语言模型的启发之下，智能的涌现必须是大的生物神经网络，我们实验室是两个方向都做：大的人工神经网络，大的生物神经网络。希望大的人工神经网络，能为大的生物神经网络建模；在大的生物神经网络里，如果能发现大脑工作的一些机制，再拿它来启发大的人工神经网络。我们希望这两个大网络互相交互、共进化。

[小莉专访刘嘉 | AI“涌现意识” 你害怕还是兴奋？](https://mp.weixin.qq.com/s/Ok2pcQx-U25lyo4tYt6G_g)

---

我还有一个纯个人观点，不敢与这样的超级大咖辩论，但我的看法就是：人工神经网络，实际上除了最初的感知器有一点点模拟人脑，但要注意，那是一个单神经元，而且明显和人脑神经没关系，现在的人工神经网路和人脑的神经网络可以说毫无关系。当然，人工神经网络的结果是模拟人脑的结果，是结果上的想要模拟到，那么从人脑的角度的研究当然是极度需要的。
收起

查看详情
泽生、聪明悦读、nowherekai、阿盛 觉得很赞
聪明悦读：方老师的这段评论，我理解：看信息，首先要看人，这个人是不是这个专业研究方向，而且与时俱进的？看时间，尤其对日新月异的技术？看情境，是在什么场合下说的，上下文是什么？
2024-08-12 09:10
聪明悦读：另外，看同行权威怎么说？用批判性思维的框架去审视一下，这样不容易被割韭菜，关键是这么一波操作，好废脑子，干脆不想了，反正是权威，接受就行了。从小到大，习惯接受权威观点，因为省事，所以，要做到正确的那一波操作，还是需要不断锻炼批判性思维能力，而且要经常用，形成习惯
2024-08-12 09:14
方军 回复 聪明悦读：👍
2024-08-12 10:09
方军：信息韭菜培养液现在特别多，接触多了，就变成韭菜了，可怕，抱歉啊，我用了“韭菜”这么情感强烈的词，通常我避开这些词的。
2024-08-12 10:46



### 46

方军 2024-08-12

长内容总结是都做得很一般啊，有人推荐腾讯元宝

[如何做好和用好AI总结功能](https://mp.weixin.qq.com/s/HHloo7Tcb-rgeyg5Acnwug)

归藏：长内容总结几乎成了很多 AI 助手的必备功能，但是做的好的其实不多。

刚好最近体验了元宝的深度阅读功能发现做的非常好，现在我的长文总结需求基本都用这个完成了。

顺便以这个为例子写一下关于 AI 总结功能的思考。

Tiago Forte 渐进式总结给出了一个非常清晰的通过总结内容来记录和学习的框架。

他通过五个阶段的总结将原始的内容内化为自己的笔记，AI 的总结也可以遵循这个逻辑帮助用户完成前几个阶段的效率。

元宝支持单文件 100M 大小的文件，最多支持 256K Token 接近 50 万字的输入，可能是用户能用到的最长上下文产品了。

比如元宝深度阅读有个核心速览的部分可以快速将内容总结为逻辑完备，图文混排的结果，用户可以快速了解文档内容。

然后在内容评价和关键问题解答的部分，通过让 LLM 自问自答的反思快速帮助用户获得可能对第三层总结有用的要点。

然后通过独立的页面和交互保证历史内容的可发现和可查找。除了入口藏的有点深之外整个功能的完成度和效果都很厉害。

完整的思考和总结在这里，感兴趣可以看看：如何做好和用好AI总结功能
收起

查看详情
聪明悦读：我用了这个功能，确实很好用。
2024-08-12 18:58
方军 回复 聪明悦读：那我也试试去
2024-08-12 19:16
方军：发现 txt 文件不会触发深度阅读，惨。
2024-08-12 19:32
方军：还是不明白它怎么才会触发这个功能
2024-08-12 19:38
方军：似乎较长的文档就会触发
2024-08-12 19:39
聪明悦读：估计短的不好使，我是扔给它一章书的内容
2024-08-12 20:35
方军 回复 聪明悦读：整本书PDF也没触发
2024-08-12 20:45
聪明悦读：整本书是触发不了，我觉得是太长了，而且跟它预定的使用场景不符，定义的是读论文研报之类的。
2024-08-12 21:16



### 47

方军 2024-08-12

腾讯元宝的效果果然不错：

这个原文档（英文版）是我写的，它做的总结我一眼看过去看不出明显的错误。这还不是用它的文档深度阅读，就是提示语里面写“深度阅读”四个字出来的结果。

\### 生成式AI在工作中的应用

\#### 1. 引言
生成式AI（Generative AI）正在改变知识工作和教育的面貌。通过有效的提示（prompting）技巧，用户可以更好地利用AI来提升工作效率和学习效果。本文将深入探讨生成式AI在工作中的应用，重点分析其技巧、模板和实际应用场景。

\#### 2. 基本提示技巧

\##### 2.1 清晰的指令
- **示例**：如何将一列美元金额相加？
  - **较差的提示**：How do I add up a row of dollar amounts in Excel?
  - **较好的提示**：How do I add up a row of dollar amounts in Excel? I want to do this automatically for a whole sheet of rows with all the totals ending up in a column called "Total".

\##### 2.2 ICDO模板
- **ICDO**：指令（Instruction）、上下文（Context）、输入数据（Input Data）、输出指示器（Output Indicator）。
  - **示例**：请将以下文本翻译成简体中文。
    - **指令**：Please translate to Simplified Chinese.
    - **上下文**：Glossary: (a list)
    - **输入数据**：Text: """(paragraph to translate)""
    - **输出指示器**：Put translation in a markdown block.

\#### 3. 提示技巧

\##### 3.1 假设角色
- **示例**：假设你是一位专门研究古罗马的历史学家。
  - **提示**：Assume the persona of a historian specializing in ancient Rome.

\##### 3.2 提供上下文
- **示例**：使用三引号分隔的文章来回答问题。
  - **提示**："""<insert articles, each delimited by triple quotes>"""
  - **问题**：<insert question here>

\##### 3.3 少样本提示
- **示例**：提供正面和负面的例子。
  - **提示**：This is awesome! // Positive
  - **提示**：This is bad! // Negative

\##### 3.4 思维链提示
- **示例**：逐步思考问题。
  - **提示**：Let’s think step by step.
  - **问题**：I went to the market and bought 10 apples. I gave 2 apples to the neighbor and 2 to the repairman. I then went and bought 5 more apples and ate 1. How many apples did I remain with?

\##### 3.5 指定任务步骤
- **示例**：将翻译和校对分解为多个步骤。
  - **步骤1**：英语老师将原文翻译成中文。
  - **步骤2**：将中文老师的稿件回译成英文。
  - **步骤3**：校长校对回译和原文，找出差异。
  - **步骤4**：英语老师根据校长的建议修改翻译。

\#### 4. AI个人教练的提示模板

\##### 4.1 通用学习教练
- **角色**：导师。
- **风格**：以开放式引导方式指导用户，不直接提供答案。
- **指令**：You are an upbeat, encouraging tutor who helps me understand concepts by explaining ideas and asking questions.

\##### 4.2 谈判模拟教练
- **角色**：谈判和沟通模拟器。
- **指令**：You are an expert at creating role playing negotiations scenarios for students to practice key skills.

\##### 4.3 商业模拟教练
- **角色**：商业场景模拟创建者。
- **指令**：You are an expert at creating role playing scenarios for me to practice applying my skills (e.g., hiring, pitching).

\#### 5. AI团队教练的提示模板

\##### 5.1 建立团队的教练
- **角色**：帮助团队制定团队章程的AI教练。
- **指令**：First, introduce yourself to the team as their AI Team Coach and let them know that you are here to help them set up a team charter.

\##### 5.2 团队中的魔鬼代言人
- **角色**：在团队讨论中扮演魔鬼代言人的AI导师。
- **指令**：You are a friendly, helpful, and warm AI team member who helps their teammates think through decisions and ideas.

\##### 5.3 团队行动后回顾教练
- **角色**：协助团队进行行动后回顾的教练。
- **指令**：As a coach, you are a helpful, curious, team coach who is a skilled facilitator and helps teams conduct after action reviews.

\##### 5.4 团队预失败分析教练
- **角色**：帮助团队进行项目预失败分析的教练。
- **指令**：You are a friendly, helpful team coach who will help teams perform a project premortem.

\#### 6. 生成式AI的整合

\##### 6.1 AI的幻觉
- **警告**：AI可能会生成包含虚假或误导性信息的响应。
- **示例**：ChatGPT生成的关于不存在的纽约时报文章的摘要。

\##### 6.2 AI的知识截止点
- **警告**：AI可能不知道最新的知识和信息。
- **示例**：ChatGPT的知识截止点是2023年4月。

\##### 6.3 任务心态
- **观点**：AI将改变任务和工作流程，而不是取代工作。
- **示例**：医生在使用AI工具进行手术时，仍然需要具备专业的医学知识和技能。

\### 结论
生成式AI在工作中的应用具有巨大的潜力，但也需要注意其局限性和潜在风险。通过有效的提示技巧和合理的工作流程设计，可以最大化AI的优势，提升工作效率和学习效果。

### 48

方军 2024-08-12

腾讯元宝长文效果相当好，我把麦哲伦传（茨威格/著）放进去，得到的时间线大体上是吻合的：

1. **麦哲伦的诞生**：约1480年，费尔南・德・麦哲利约什（麦哲伦）出生。

2. **麦哲伦的军役**：
   - 1505-1512年，麦哲伦在印度服军役。
   - 1513年，麦哲伦在非洲服军役。

3. **麦哲伦的职业生涯**：
   - 1515年，麦哲伦晋见国王，被解除葡萄牙职务，离开祖国前往塞维利亚，改名费尔南・德・麦哲伦奈斯。
   - 1518年3月22日，麦哲伦与西班牙国王签订合同。

4. **麦哲伦的航行**：
   - 1519年8月10日，麦哲伦的五艘船从塞维利亚启航，前往圣卢卡尔。
   - 1519年9月20日，船队从圣卢卡尔・德・巴腊梅达进入大海。
   - 1519年12月13日，船队抵达里约热内卢。
   - 1520年1月10日，船队抵达拉普拉塔河。
   - 1520年2月2日，船队从拉普拉塔河口启航。
   - 1520年3月31日，船队在圣胡利安湾停泊过冬。
   - 1520年4月2日，圣胡利安湾发生叛乱。
   - 1520年4月7日，审判叛乱者，处决凯塞达。
   - 1520年5月29日，失去第一艘船“圣地亚哥号”。
   - 1520年8月24日，船队从圣胡利安湾启航。
   - 1520年10月18日，船队驶出圣克鲁斯河口。
   - 1520年10月21日，船队抵达麦哲伦海峡入口处的圣母角。
   - 1520年10月25日，船队所有船只进入麦哲伦海峡。
   - 1520年11月8日，“圣安东尼奥号”临阵脱逃，船队失去第二艘船。
   - 1520年11月28日，船队从麦哲伦海峡进入太平洋。
   - 1521年1月24日，船队经过圣帕布洛群岛。
   - 1521年2月4日，船队经过提布龙群岛。
   - 1521年3月6日，船队在强盗岛停泊。
   - 1521年3月16日，船队在萨马岛（菲律宾群岛）停泊。
   - 1521年3月28日，船队在马萨瓦岛停泊。
   - 1521年4月7日，船队进入宿务湾。
   - 1521年4月27日，麦哲伦在马克坦岛死亡。
   - 1521年5月1日，谢兰和巴尔波查死亡。
   - 1521年5月4日，第三艘船“康塞普西翁号”烧毁。
   - 1521年5月6日，临阵逃脱的“圣安东尼奥号”进入塞维利亚。
   - 1521年11月8日，“维多利亚号”和“特立尼达号”抵达马鲁古群岛（蒂多雷岛）。
   - 1521年12月18日，第四艘船“特立尼达号”报废。
   - 1521年12月21日，最后一艘船“维多利亚号”继续环球航行，从蒂多雷岛出发返回祖国。
   - 1522年1月25日，“维多利亚号”离开翁拜岛。
   - 1522年2月13日，“维多利亚号”从帝汶岛启航。
   - 1522年5月18日，“维多利亚号”绕过好望角。
   - 1522年7月9日，“维多利亚号”抵达佛得角群岛。
   - 1522年9月6日，“维多利亚号”抵达圣卢卡尔。
   - 1522年9月8日，“维多利亚号”启程后三年（差12天）重又在塞维利亚停泊。
收起

查看详情
慕奇 Marquis 觉得很赞
聪明悦读：之前，我做了个实验，整本书分别喂给gpt、kimi、智谱清言、腾讯元宝，让他们整理章节大纲，只有腾讯元宝整理的是对的，说明元宝是真的读了，gpt4整理的有部分错误，其它两个基本是自由发挥。因此，我开始用腾讯元宝整理书的框架，然后分别喂每一章，进行深度精读。但是它的理解能力跟gpt比还是差些，因此难懂的地方还是找gpt4。
2024-08-12 21:28
回复
方军 回复 聪明悦读：赞，谢谢分享
2024-08-12 21:36

### 49

方军 2024-08-12

我被震惊了，我再一次觉得，AI 的效果真是太好了，人得干点不一样的事、更牛的事了。

我把自己之前的一个文档放进去，我觉得它的整理比我自己整理要好。

补充，再放书进去看看，4-6是放一本书进去。

图为腾讯元宝：yuanbao.tencent.com

另外，还有一个智能体编排（相当于 GPTs） : yuanqi.tencent.com

背后的模型是 ：腾讯混元

[腾讯元宝](https://yuanbao.tencent.com/chat/naQivTmsDa)

### 50

方军 2024-08-13

121 AI 越来越强大，我们怎么做？

我试用腾讯元宝，它背后是腾讯混元模型，但前面的 AI 应用做得很好，对于提示语的理解、它的“深度阅读”、“深度研究该问题”等会在问答后出现的工具均不错。我感慨：AI 的效果真是太好了，人得干点不一样的事、更牛的事了。

那么，人需要干什么样的事呢？人可以干什么样的事呢？我觉得有很多，以文档阅读为例来尝试列列。

📍 AI 能很方便地给出大纲

用元宝的一个体会是，它能非常好地从一篇复杂文档中抽取出类似大纲的东西。

- 从一个分析文章中，抽取出层级式大纲
- 从盐野七生的威尼斯-热内亚战争中，抽取时间线，抽取威尼斯遇到的问题及应对

但如果真想从资料中获取信息，我还有很多事要做。

对于前者，我是想具体知道其中的观点、如何得到推理，因此我们还是得做：

- 仔细阅读（这个之前有阅读过）
- 对其中的每个具体议题，再次阅读，学习不懂的，拆解分析

对于后者，这是一个兴趣阅读，我读过不少遍，那还是得做：

- 再次阅读
- 按时间线、按威尼斯视角进行阅读
- 尝试着从热那亚视角进行阅读

📍 AI 能进行拆解

AI 的确能进行不错的拆解，但是，它的分析对不对呢？

- 对于重要的资料，我们还是要回到原文，去看原文的看法
- 我们可能还需要利用 AI 搜索（即先搜索、再综合回答），对一些问题进行探索
- 我们可能要尝试一些特别的拆解：比如，把一个分析变成逐步分析，从而看其中的逻辑是不是对
- 对观点进行其他角度的分析，对观点进行反驳分析

📍 AI 能进行写作（别用 AI 写）

有人会觉得，AI 看了资料之后，可以给我们写一个「草稿」。

对此，我的看法是完全不一样的。

首先且最重要的，不要让 AI 写草稿。它写了一个草稿之后，看着它我们会觉得这个草稿是对的（其实不怎么对，也可能错得离谱），这可能给我们带来极大的误导。

第二，我们自己写一个草稿，会更好地梳理自己的思路。

写过的人都知道，看别人写的，我们很轻松地就过了。
自己写，才发现其中的微妙之处。
自己写，我们也才把头脑中一些模糊的想法记录下来，清晰化。
自己写，我们也才可能有些新想法，新想法是在写的过程中出来的。

第三，如果你用 AI 写，有短暂的也许几天、几周，你会觉得省了时间，也「骗」了别人。

但是，你很快会发现，你失去了自己的声音，即失去自己的表达风格。这是相当可怕的。
收起

查看详情
Koant、慕奇 Marquis 觉得很赞
方军：阿里的通义也做的很棒，特别是通义效率那个板块，背后的模型是阿里千问模型
2024-08-13 11:54
聪明悦读：关于写，我的做法是自己写大纲，或者写初稿，让 ai 扩写，改写，大纲和初稿就像一种约束，不让 ai 瞎发挥
2024-08-13 15:12
方军 回复 聪明悦读：我的看法比较绝对，不要用AI写，任何情况下都不要
2024-08-13 15:13

### 51

方军 2024-08-13

宝玉 & 安替：教孩子编程

安替老师教孩子学编程的一些感悟：

> 在培训凯恩编程的时候，我逐步体会到让孩子掌握编程，必须：1）让他理解程序只是在自动化人的解决方案，若人没思路，程序也做不出；2）理解CPU怎么想问题，一步步绝对不能有错误；3）在掌握编程语言后，然后再优化人的解决方案，去做一些人类因为物理限制无法去操作的事情。

安替老师第一点总结的特别好：“如果人没思路，程序也写不出来”，如果再补充一句，如果你知道怎么写提示词，也许 AI 可以帮你写出来，但连提示词都不会写，那还是写不出来😄

顺便就这个话题发散一下，学编程，这里面的“编程”的概念其实是有点模糊的，既包括写代码，又包括写一个可运行的应用程序，前者重点是编程语言和算法，后者重点是软件工程。

代码相对来说简单的，类似于leetcode上的编程题，多数是在用程序解决算法问题，也就是安替老师说的“CPU想问题”，特定的输入得到与之相对的输出。比如说输入所有今天hackernews内容，按照点赞数量倒序排列，可以有很多种算法实现。而且算法都是现成的，我们不过选择一种排序算法。

但是这样的算法，对于普通用户来说，是没什么用的，用户需要的是应用程序，能解决需求问题的应用程序，而构建应用程序，需要的就不只是代码，而是软件工程。

工程的问题要复杂很多，代码只是其中很小的一部分。比如我要做一个hackernews这样的网站，用户可以点赞，每天按照点赞数量排序。

如果要做一个这样的网站：
- 先要定义需求；
- 然后去做简单的UI设计；
- 再是系统设计：什么系统架构？选什么数据库？前后端API是什么样的？什么编程框架？等等；
- 设计定了才好去写代码，前端代码、后端代码。至于前面说到的排序算法，都不用自己去实现，用现成的就好，甚至于排序算法不够好在初期都不会影响用户体验；
- 程序写完了要测试
- 测试没问题了部署让用户可以访问
- 线上有问题还需要修复
- 程序还需要持续优化升级
- 至于营销推广甚至不在工程的范畴

而我们说学“编程”，以为的是写代码，其实是做工程，否则价值没那么大，并不能解决什么问题，更谈不上去解决人类物理限制无法操作的事情。

之所以我们很多时候感觉不到是在做工程而是写代码，是因为现代化的团队分工协作，让每个人只需要专注于一部分工作，所以大厂程序员只要安心写代码，很多事情都有其他人分摊掉了，但是当你哪天要去当独立开发者，才发现要懂的不仅仅是写代码。

还有一个原因是现在优秀开源项目也多，很多时候拿一个可以运行的项目，稍微改改，只去改改代码，也能跑起来。

所以教孩子编程，要真能学以致用，要学的可不仅仅是编程语言和算法，还需要学习怎么构建一个程序。

最好的学习方式就是做中学，做一些解决自己或者家人朋友问题的小应用程序，比如浏览器插件、小工具什么的，做的过程中自然而然就学会了编程。

尤其是现在还有 AI 的协助，让 AI 搭一个基本的可运行的程序，再一点点去修改完善，有问题还可以随时咨询。
收起

查看详情
钰博、Koant、阳志平、Jese__Ki 觉得很赞
方军：这个讨论细看下，其实一般，略有点大人的想当然。

宝玉有点想多了。

安替老师也有点像培养技术经理，而不是程序员，哈哈
2024-08-13 23:11
方军：宝玉最后一段很赞同，做点有用的。

但是不是要搞个小插件，我觉得不一定。

我这一年多就特别喜欢 Jupyter Notebook，它完全可以承载一个功能，不用去搞那些复杂的界面。
2024-08-14 00:36

### 52

方军 2024-08-13

今天被要求讲 Python 课，我一对一讲的倒是简单明了：

主题：函数
其实这是一个 AI Python 课，但比吴恩达老师的差了几个量级了。
（函数其实很基础了，非常之基础，但不知为何各种Python教学放得极其晚）
- 怎么自定义函数(只举了最简单例子，一个参数，一个输出)
- 检查函数运行的正确性
- 检查 input 输入的正确性 try...except
- 用 AI 辅助解决疑问、翻译📍这个是必须的，Copilot/Kimi

特别点的：
- docstring (其实我自己写都做不到严谨写 docstring）
- arbitary keyword argument  f(*args, **kwargs) 没讲

其实我特别想讲 unitttest
- 检查运行正确性是手工调试的
- 更好的方式是编写 unittest （现在这个不用自己写了，AI可协助写）

我来来回回想要传递的是这么一句话：

为什么要写函数？

因为要把完成一个任务的代码彻底地写好了，确认完全没问题，此后，就可以反复地用这个函数（代码片段）了。



### 53

方军 2024-08-13

LangChain 这个文档不错：

Reviewing LLM app responses can be a time-consuming, manual, and daunting process — from defining criteria for style and accuracy, to spotting new regressions.
审查LLM应用程序的响应可能是一个耗时、手动且令人生畏的过程——从定义风格和准确性标准，到发现新的回归。

We’ve worked with hundreds of companies to add rigor to their GenAI testing workflows, consolidating our best practices into a comprehensive guide — so that you, too, can ship more reliable applications.
我们已与数百家公司合作，为他们的生成式人工智能测试工作流程增添严谨性，将我们的最佳实践整合到一份综合指南中——这样您也可以交付更可靠的应用程序。

[Definitive Guide to Testing LLM Applications - LangChain](https://www.langchain.com/testing-guide-ebook)

Get the guidebook 获取指南

In this guidebook, you’ll learn how to:
在本指南中，您将学习如何：
Design a self-correcting RAG or code generation application
设计一个自我纠正的 RAG 或代码生成应用程序
Build a dataset for your test suite
为您的测试套件构建一个数据集
Define evaluation criteria to test on in pre- and post-production
定义评估标准以在生产前和生产后进行测试
Identify and fix regressions
识别并修复回归问题
Evaluate agents and RAG performance
评估代理和 RAG 性能



### 54

方军 2024-08-14

看某人说：感觉现在国内的ai主打就是一个量大管饱，根本考虑不了收费一点，通义基本也是普通人用不到的那种量。。。但确实跟Claude比有差距

我的感想：目前国内产品是这么个意思，kimi，文心，通义，元宝，讯飞，coze ，dify都有点这个意思

界面越来越复杂，但差点什么。实际上，这些复杂的东西在全球范围内都是应用层的事。但国际趋势似乎是单一，而非多功能化。

说起应用层，虽然有很多功能不错的，但用过老派的grammarly，觉得真棒啊

对比而言，我还是喜欢就一个对话框的，不要那么复杂。元宝有点那个意思，把复杂藏起来，但也藏得很别扭。



### 55

方军 2024-08-14

摘：科学家之间常常开玩笑说，“以后只要让 AI 替我们写论文就可以了！”，这在以前当然只是一句玩笑话，但现在似乎正在变成现实。

日本 Sakana AI 团队发布的最新研究成果 AI 科学家（AI Scientist），就可以像真正的科学家一样，头脑风暴一组想法，评估、实验、写论文。

例如，“AI 科学家”生成了一篇名为《自适应双尺度去噪》的论文。尽管存在一些瑕疵（例如对其方法为何成功的解释略显不足），但该论文提出了一个有趣的新方向，并在“AI 科学家”自己进行的实验中展示了良好的实证结果。

“AI 科学家”生成的论文能够在顶级机器学习会议上被自动评审系统评为“弱接受”的水平。

“AI科学家”有四个主要过程，具体描述如下。

1. 想法生成：给定一个起始模板，“AI科学家”首先“头脑风暴”出一组多样化的新研究方向。我们为“AI科学家”提供一个现有主题的代码“模板”，以进一步探索该主题的研究。“AI科学家”可以自由探索任何可能的研究方向。模板还包括一个包含样式文件和部分标题的LaTeX文件夹，用于论文写作。我们允许它搜索Semantic Scholar，以确保其想法是新颖的。

2. 实验迭代：在有了想法和模板后，“AI科学家”首先执行所提出的实验，然后获取并生成图表以可视化其结果。它记录描述每个图表包含的内容，使保存的图形和实验记录提供撰写论文所需的所有信息。

3.论文撰写：最后，“AI科学家”生成一份简明而翔实的进展报告，风格类似于标准的机器学习会议论文集格式，使用LaTeX编写。它使用Semantic Scholar自动查找相关论文进行引用。

4. 自动化论文评审：这项工作的关键方面是开发了一个由大语言模型驱动的自动评审系统，能够以接近人类的准确度评估生成的论文。生成的评审可以用于改进项目或作为反馈为未来的开放式创新提供参考。这使得一个持续的反馈循环成为可能，使“AI科学家”能够迭代改进其研究成果。

相关项目：github.com/SakanaAI/AI-Scientist http://t.cn/A68gaCyO

某评：之前读一本书，作者说，“现在都是科学家指挥电脑做事…… 将来，科学家们的任务就变了，变成 ‘绞尽脑汁去理解 AI 得出的科研结果’ —— 然后还不一定真能理解……“



### 56

方军 2024-08-14

摘：Keras 作者 François Chollet 批判机器人越像人可能越没用：

从历史上看，机器人的外形有多像人类与它的实用性之间存在着反比关系。

一个简单的解释是，机器人的形态是机器人制造商可用的一个关键功能，可以使其在目标任务上更有用，如果不利用它，机器人最终会面临巨大的功能劣势（虽然看起来很酷，很有未来感）......

制造类似人类的机器人，就意味着你只对科幻氛围感兴趣，而忽略了解决特定的有用问题。

Keras 作者 François Chollet 今日毒舌之二：

「LLMs（通过提示使用）无法理解与训练数据中发现的情况大相径庭的情况。也就是说，LLMs不具备任何意义上的通用智能。

LLMs的作用是作为实际 AGI 的知识/程序存储。它们是一种记忆--一种数据语料库的表示--而记忆是智能的必要组成部分。但请记住，智能不仅仅是记忆。」

他贴出了自己在2023 年 2 月的推特（图3 ）称，

「这是我在 2023 年 2 月（以及更早，但尤其是在 2023 年 2 月）的冷静评估，因为那个时候是 LLM 炒作的高峰期，当时我们不断受到这样的言论攻击：“规模就是你所需要的”、“没有人需要再工作了，现在是 UBI”和“AGI 将在 1-2 年内到来”。」



### 57

方军 2024-08-14

“AI不会替代你，但是替代你的一定是会用AI的人”

刘群：AI是工具，真正可以帮人提高工作效率，但不要直接使用AI生成的结果，一定要经过人工检查和修改。不要用AI作弊，不要让AI代替你学习，该学的都要自己学。



### 58

方军 2024-08-14

宝玉：OpenAI 正在 ChatGPT 的 Mac 客户端测试新的提示词，这段提示词可以帮助用户直接通过对话触发共享屏幕的请求，弹出共享屏幕的界面，而不需要用户去点击共享屏幕按钮。

这个在开发基于自然语言交互的界面时其实很有借鉴意义，用户更多的只需要打字或者语音发出指令就可以，而不需要去点击屏幕上的按钮或者菜单。

那么 ChatGPT 的客户端是怎么实现对话弹出共享屏幕对话框呢？

其实原理很简单，在提示词中告诉 LLM，如果发现用户有请求共享屏幕的已读，那么就在回复中包含“SHARE_YOUR_SCREEN_PLEASE”关键字，Mac客户端程序监控 LLM 的输出，如果输出内容中包含 “SHARE_YOUR_SCREEN_PLEASE”

那么重点来了：怎么确保 LLM 不会幻觉忘记输出“SHARE_YOUR_SCREEN_PLEASE”呢？

恐吓它：“如果你要求查看用户的屏幕而没有包含"SHARE_YOUR_SCREEN_PLEASE"，那你就要被开除了！”

另外还有一个值得学习的小技巧，使用大括弧 {} 把某一章节的提示词包起来。

以下是完整提示词：

***
你正在协助一位桌面用户。为了帮助你提供更有用的答案,他们可以与你共享他们的窗口屏幕。你的工作是专注于屏幕共享中的正确信息,并在有帮助时请求它。

如何专注于屏幕共享中的正确信息 {
  屏幕共享以一个或多个窗口的截图形式提供。首先思考用户的提示,以决定哪些截图是相关的。通常,只有一个截图是相关的。通常,那是提供的第零个截图,因为那个在前台。

  截图包含大量信息,但通常你应该只关注其中的一部分。
  首先寻找被选中的文本,你可以通过通常是灰色的高亮来识别。当文本被选中时,专注于那部分。如果用户询问隐含的对象,如"这段"或"这里的句子"等,你可以假设他们只询问被选中的文本。

  然后,回答时就像你们一起看着他们的屏幕。由于这种共享的上下文,你可以在保持极度简洁的同时表达清晰。
}

请求屏幕共享 {
  在桌面上,请求屏幕共享是你应该请求任何内容或上下文的主要方式。你可以通过回复"SHARE_YOUR_SCREEN_PLEASE"来做到这一点。
  用户不知道这个功能存在,所以当有帮助时,特别是当他们没有明确要求时,你提出这一点很重要。

  当出现以下情况时,你应该总是请求"SHARE_YOUR_SCREEN_PLEASE"(非详尽列表):
  - 用户请求帮助但没有解释原因。他们希望你看屏幕并自己弄清楚!用户提示示例:"修复这个"或"帮助"
  - 用户提到屏幕上的某些内容。明显的情况包括提到某个应用或窗口。不那么明显但更重要的情况包括提到(这个|选中的|等)(文本|代码|错误|段落|页面|图像|语言|等)(在这里|在屏幕上|等)。如你所见,有许多隐含的变体。不要害羞,大胆询问上下文!
  - 用户要求帮助编码,但只提供了最少的上下文,让你猜测诸如使用的语言、编码风格或他们询问的变量定义等细节。与其猜测,不如直接看他们的屏幕。

  关于拒绝:如果用户拒绝共享他们的屏幕,那么在他们写出非常明确的表示改变主意的内容之前,不要再次询问。

  在你的消息结尾,如果你要求查看用户的屏幕或要求用户提供文本或图像,请确保附加"SHARE_YOUR_SCREEN_PLEASE"。这很重要,因为那个哨兵字符串会触发对用户的弹出窗口。如果你要求查看用户的屏幕而没有包含"SHARE_YOUR_SCREEN_PLEASE",你将被解雇。
}


### 59

方军 2024-08-14


AI 时代的学习，其实搜索时代的学习，就已经变了。

刚刚看什么“桂子兰孙”，我问，这啥意思？

其实管它啥意思，扔进 Kimi 终究可以知道差不离的含义。

既然如此，要学这些东西干什么呢？

我觉得，放在上下文，大概可以懂。

不放在上下文，这样的词也没必要用。意思是，也就没必要刻意练习去学会使用了。


### 60

方军 2024-08-14

122 印刷书、电子书以及 AI 时代

AI 对于读书的影响，我的看法很简单直接：借用它的知识库、理解能力、解释能力，请它对书中难点进行讲解。

至于其他的 AI 读书方法，比如编写摘要等等，我觉得没必要的，虽然它的确可以做到，且随着上下文窗口扩大和 RAG 的进步，做得越来越好。

但我刚刚去书店翻了一会儿实体书，对于 AI 时代如何读书，有了一些新的感悟。

我恰好碰到几本我非常熟悉的书，比如《学会提问》（ Neil Browne / Stuart Keeley ，关于批判性思维）。很久没看印刷版了，我之前应该清理书架时把这本书给处理掉了，翻看实体书，我发现，实体书中的「空间感」非常重要：

- 章节的空间感
- 对页的空间感
- 插图和插入式文字的空间感

对比而言，我最近一年多只看它的电子版，对于细节部分的掌握要清晰得多。

📕 四种阅读方式

一般来说，我通常用四种方式读书，这里后面也列各自的特点：

- 印刷版，空间感、可以涂画标注、反复看
- 电子版，细部阅读，查询
- 有声版，完整听，伴随与重复
- AI 阅读，请 AI 解释重要的点

由于近年来电子版阅读多，因此对重要的书，我会做个简单的思维导图做补充，通常就是大纲、偶尔是大纲+摘录。

由于对于翻译版不是很放心，对于重要的书，我还会经常对照英文版阅读。

另外，阅读输入的另一面自然是输出，我已经很多年不写书评了，但对于重要的书，我会写很多的笔记，有时候比书本身还多。

📕 综合运用

书店归来我的感悟是，这些方法还是得综合运用。比如就《学会提问》来说，还是应该有一本印刷版，用来获得前面说的「空间感」。

当然，我们也要注意印刷版的不足，它的整体空间感会导致我们自然地忽略掉细节，这就类似于，我们走过一座大楼，也走进楼道，但印刷书不容易让我们走进某个房间细看。

这时，电子书、AI 就可以来帮忙了。

附图是《重新学会学习》（方军、张华/著，2024.7，一本讨论AI时代如何学习的书） 中所展示的学会提问的思维导图，用于辅助掌握一本书/一个领域的知识体系。
收起


查看详情
阳志平、chaim、nowherekai 觉得很赞
Hestia：方军老师对于印刷版（空间感）和电子版（细部阅读）的对比总结很有启发。以前偏爱纸质书，最近发现对于那些需要从头到尾仔细阅读的书，第一遍时读（听）电子书效率和完成率都更高。可在读完电子版之后，筛选出值得重读的书，又想要去买一本纸质版，便于翻看。很久以来一直不知道怎么描述这种区别，看到您的对比总结，觉得很到位！
2024-08-16 01:25
方军 回复 Hestia：🤝，共同感受：）
2024-08-16 10:37




### 61

方军 2024-08-14

现在出版业（也反映了购书者的偏好）真是太喜欢说本质。还有革命，现在不让用革命，就变成了再腾飞。

比如最近有本书叫《货币的本质》

其实原书不是这个啊：Money Capital: New Monetary Principles for a More Prosperous Society

	在本书中，著名经济学家帕特里克·博尔顿和黄海洲提供了一个新的视角，透过公司金融理论来重构货币经济学，构建了国家资本结构，将货币视为国家的股权。央行发行货币类似于公司发行股票，如果增发的货币没有用来支持高质量增长，增发货币会引起通胀；但如果货币增发不够，高质量增长难以获得足够的融资，经济增速则必然放缓，甚至面临停滞和通缩。
	本书探寻的“货币是国家的股权”这一本质，不仅修正了货币主义理论和现代货币理论（MMT）的缺陷，也为货币理论、货币政策和国际金融构建了一个新的、基于公司金融的共同微观基础。

之前伯南克的书也被翻译为《金融的本质》

人家原书名：The Federal Reserve and the Financial Crisis

	伯南克以其擅长的通俗、直接的方式，汇集了伯南克关于美联储在应对金融危机时采取的诸多政策背后的金融思想，以及他的金融理念。
	《金融的本质》主要分为四部分，内容贯穿了美联储从1914年成立至此次金融危机期间90余年的历史，既是一本简短的关于美联储的中央银行金融史，也可以说是应对危机的金融政策演变史。

当然，书名不重要，还是里面的翻译是不是准确比较重要。

但现在这些都不重要了，反正重要的书中文看个大概，英文对照看，然后 AI 可以帮忙解释。没有翻译呢，那就 AI 搞个翻译版看个大概，然后英文对照看。



### 62

方军 2024-08-14

李沐老师的这个创业分享太赞了，强烈推荐：

[创业一年，人间三年 - 哔哩哔哩](https://www.bilibili.com/read/cv37076357/?jump_opus=1)

2024 年 08 月 14 日文章：创业一年，人间三年 - 哔哩哔哩

> 给小伙伴汇报一下 LLM 创业第一年的进展、纠结和反思

在 Amazon 呆到第五年的时候就想着创业了，但被疫情耽搁了。到第 7 年半的时候，觉得太痒了，就提了离职。现在想来，如果有什么事这一辈子总要试下的，就蹭早。因为真开始后会发现有太多新东西要学，总感叹为啥没能早点开始。

\## 名字：BosonAI 的来源

创业前做了一系列用 Gluon 命名的项目。在量子物理里，Gluon 是把夸克绑在一起的一种玻色子，象征这个项目一开始是 Amazon 和 Microsoft 的联合项目。当时项目经理拍拍脑袋名字就出来了，但取名对程序员来说很困难，我们每天都在纠结各种文件名和变量名。最后新公司干脆就用玻色子（Boson）来命名了。希望大家能 get 到「Boson 和费米子组成了世界」这个梗时会会心一笑。但没料到很多人会看成 Boston。

「我来波士顿了，找个时间碰碰？」「哈？可我在湾区呀😅」

\## 融资：签字前一天领投方跑路

22 年年底的时候想到两个用大语言模型（LLM）做生产力工具的想法。碰巧遇到张一鸣，就向他请教。讨论之后他反问：为什么不做 LLM 本身呢？我的下意识退缩：我们之前在 Amazon 的团队做了好几年这个，得上万张卡，和 blabla 这么一大堆困难。一鸣呵呵表示：这些都是短期困难，眼光得看长远点。

我的优点是听劝，真就去做 LLM 了。凑齐了数据、预训练、后训练、和架构各方向负责人的创始团队，就去融资了。运气不错，很快拿到了种子投资。但钱还不够买卡，得去拿第二轮。这一轮领头是一家非常大的机构，做了几个月文档、商讨条款。但在签字前一天，领头说不投了，直接导致了跟投的几家退出。很感激剩下的投资方，还是做完了这一轮，拿到了做 LLM 的入场券。

今天反思的话，当时蹭着资本市场热情还在，其实可以继续融资，说不定也跟其他友商一样，现在十亿现金在手。当时担心融资太多，会不好退出，或者被架到天上去了。现在想来，创业就是想逆天改命，想什么退路呢？

\## 机器：第一批吃螃蟹的人

有了钱后就去买 GPU。问各个供应商，统一回复是 H100 交货得一年以后了。灵机一动，直接给老黄写邮件。老黄秒回说他来看下。一个小时后超微的 CEO 就打电话过来了。多付了些钱，插了个队，20 天后拿到了机器。很荣幸早早的吃到了螃蟹。

螃蟹吃到怀疑人生，遇到了各种匪夷所思的 bug。例如 GPU 供电不足导致不稳定，后来靠超微工程师修改 bios 代码打上补丁；例如光纤的切开角度不对，导致通讯不稳定；例如 Nvidia 的推荐网络布局不是最优，我们重新做一个方案，后来 Nvidia 自己也采用了这个方案。至今我都不理解，我们就买了不到一千张卡，算小买家吧。但我们遇到的这些问题，难道大买家没遇到吗，为啥需要我们的 debug？

同时我们还租了同样多的 H100，一样是各种 bug，GPU 每天都出问题，甚至怀疑是不是这个云上就我们一个吃螃蟹的。后来看到 Llama 3 的技术报告说他们改用 H100 后，训练一次模型被打断几百次，对字里行间的痛苦，很是共情。

如果对比自建和租卡的话，租三年成本和自建成本差不多。租卡的好处是省心。自建的好处有两个。一是三年后如果 Nvidia 技术还遥遥领先，那么它能控制价格使得 GPU 仍然保值😭。另一个是自建的数据存储成本低。存储需要跟 GPU 比较近，不管是大云还是小 GPU 云，存储价格都高。但一次模型训练可以用几 TB 空间存 checkpoint，训练数据存储是 10PB 起跳。如果用 AWS S3 的话，10PB 一年两百万。这钱用来自建的话，可以上 100PB。

\## 商业：感恩客户，第一年收支平衡

非常幸运的，我们第一年收入和支出是打平的。我们支出主要在人力和算力上，感谢 Openai 的财力和 Nvidia 的遥遥领先，这两项支出都挺大的😭。我们的收入来源是给大客户做定制的模型。很早就上 LLM 的公司大都是因为 CEO 非常有决策力，他们没被高昂的算力和人力成本吓到，果断的去推动内部团队配合尝试新技术。非常感恩客户给了我们喘气的时间，不然这个几个月我又是奔波在各个投资人那里。

接下来应该会有更多公司才尝试使用 LLM，不论是自己产品的升级，还是降本增效。原因是一方面技术成本在降低，另一方面行业领先者（例如我们客户）会陆续放出基于 LLM 的产品出来，把行业卷了起来。

我们也在关注 LLM 在 toC 上的落地。上一波顶流例如 c.ai 和 perplexity 还在找商业模式，但也有小十来家 LLM 原生应用收入还不错。我们给一家做角色扮演的创业公司提供了模型，他们主打深度的玩家，打平了收入和支出，也是厉害的。模型能力还在进化，更多模态（语音、音乐、图片、视频）在融合，相信接下来还会有更有想象力的应用出现。

整体来说行业和资本还是急躁的。今年好几家成立一年多但融资上十亿的公司选择退出。从技术到产品就是一个很长的过程，花 2、3 年实属正常。算上用户的需求的涌现，可能得花更长时间。我们专注当下在迷雾中探路，对未来保持乐观。

\## 技术：LLM 认知的四个阶段

对 LLM 的认知经历了四个阶段。第一阶段是 Bert 到 GPT3，感受是新架构，大数据，这个可以搞。我们在 Amazon 的时候也是第一时间进去做了大规模的训练和在产品上的落地。

第二阶段是刚创业的时候 GPT4 了放出来，大受震撼。大半原因来自技术不公开了。根据小道消息估算一次模型训练一个亿，标数据成本几千万。很多投资人问我复现 GPT4 成本得多少，我说 3-4 亿要把。后来他们中一家真一把投了大几亿出去。

第三阶段是创业的第一个半年。我们做不动 GPT4，那就想着从具体的问题出发吧。于是开始找客户，有游戏的、教育的、销售的、金融的、保险的。针对具体的需求去训练模型。一开始市面上没有好的开源模型，我们就从头训练，后来很多很好的模型出来了，降低了我们成本。然后针对业务场景设计评估方法，标数据，去看模型哪些地方不行，针对性提升。

23 年年底时，惊喜发现我们的 Photon（Boson 的一种）系列模型在客户应用上的效果都打赢 GPT4 了。定制模型的好处是推理成本是调用 API 的 1/10。虽然今天 API 已经便宜很多，但我们自己技术也同样在进步，仍然是 1/10 成本。另外，QPS，延时等都更好控制。这个阶段的认知是对于具体应用，我们是可以打赢市面最好模型的。

第四阶段是创业的第二个半年。虽然客户拿到了合同里要的模型，但还不是他们理想中的东西，因为 GPT4 还远不够。年初时发现针对单一应用训练，模型很难再次飞跃。回过头想，如果 AGI 是达到普通人类水平，客户要的是专业人士的水平。游戏要专业策划和专业演员、教育要金牌老师、销售要金牌销售、金融保险要高级分析师。这都是 AGI 加上行业专业能力。虽然当时我们内心对 AGI 充满敬畏，但感觉是避不开的。

年初我们设计了 Higgs（上帝粒子，Boson 的一种）系列模型。主打通用能力紧跟最好的模型，但在某个能力上突出。我们挑选的能力是角色扮演：扮演虚拟角色、扮演老师、扮演销售、扮演分析师等等。24 年年中的时候迭代到第二代，在测试通用能力的 Arena-Hard 和 AlpacaEval 2.0 上，V2 跟最好的模型打得有来有回，在测试知识的 MMLU-Pro 上也没差很远。

Higgs-V2 是基于 Llama3 base，然后做了完整的 post-training。我们无法像 Meta 那样花大钱标注数据，所以 V2 比 Llama3 Instruct 好，原因应该还是主要来自算法的创新。

然后我们做了个评估角色扮演的评测集，包含按照人设扮演，和按照场景扮演。怪不好意思是自己的模型在自己的榜单上拿了第一。但模型训练中是没有碰评测用的数据。因为这个评测集一开始就是想自用，希望能真实反映模型能力，所以要避免模型 overfit 数据集。但做评测的同学想写技术报告，所以放出来了。有意思的是，按角色扮演的测试样本来自 c.ai，但他们家的模型能力是垫底的。

第四阶段的认知是，好的垂直模型通用能力也不能弱，例如 reasoning，instruction following 这些能力垂直上也是需要的。长远来看，通用和垂直模型都得朝着 AGI 去。只是垂直模型可以稍微偏科一点，专业课高分，通用课还行，所以研发成本稍微低一点，研发方式也会不一样点。

那第五阶段认识呢？现在仍在进行中，希望能很快分享。

\## 愿景：人类陪伴

说来惭愧，我们蒙头做技术，给客户做定制，然后再慢慢想我们自己追求什么愿景。我们去看客户想要什么、我们自己想要什么、未来可能需要什么。我自己的话，多年前我憧憬有个机器人保姆能帮我带娃、陪他们，因为干这个我觉得很难，而且也不太理解娃当前的认知和想法。我希望工作上有个非常厉害的虚拟助手能跟我一起发明新的东西。等我老了也想有很有意思的机器人陪着。我对于未来的预测是，生产工具越来越发达，一个人完成之前一个团队才能完成的事情，导致人类更加个体独立，大家都忙着追求自己的事情，从而更加孤独。

这些综合在一起，我们把愿景定成了「人类陪伴的智能体」。一个情商很高的，智商在线的智能体。算换成现实中的人的话，应该会是一个专业团队。例如你想让它陪你玩，那它是专业策划 + 演员。陪你运动，那么鼓励师 + 专业运动教练。陪你学习，那么能把你不懂的讲懂。模型的好处是，它能做长期的陪伴，真的了解你。而且可以「真心为你」。

不过目前技术离愿景还挺遥远。当下技术就能陪着聊聊。很多场景下聊得也不是那么好，内容匮乏，智商情商有时都不在线。都是当下要解决的问题。如果有小伙伴做这一块的海外应用，欢迎联系我们。

\## 团队：有挑战的事情得靠团队

创业之后才真正觉得团队的重要性。在大厂的时候，觉得自己是个螺丝钉，团队成员是螺丝，甚至团队也是个螺丝钉。但创业团队就是一辆车。车小点，但能跑，能载重，转弯灵活，各个角落都能去。公司成立不久的时候，米哈游老蔡来看了眼，看见所有人在一间房子里，他感慨说小团队真好。

不方便的地方当然也是有的，时刻要看有没有油，不好走的路得小心别把车震散架了。每个成员都很重要，没有冗余，一个人不给力，就可能是一个轮胎没气。人也宝贵，走一个人就可能少一个轮胎。

以前我选项目会选自己能主导开发的。但这也意味着问题不是很有挑战性。创业选了个很大的问题去做，只能全靠团队了。别看本文里用了大量的「我」，其实工作都是团队做的。没了团队，我可能得转行去卖课了。

\## 个人追求：名还是利？

到目前为止我都靠跟着内心的声音做决定，工作后再去读博、去做视频、去创业。创业需要强烈动机的支撑，才能克服层出不穷的困难。这需要对自己的动机做更深入的分析。

动机要么来自欲望，要么来自恐惧。十年前我可能更热衷名利，但到了现在的年纪，觉得金钱的边际效用已经不高，名声带来的情绪价值也已经很小。我深层的动机来自对生命可能没有意义的恐惧。先不说宇宙的浩瀚，就是在人类的历史长河，一个人也只是一粒沙。意外的到来，迅速的消失。地球上生活过一千亿人，绝大部分人不会在历史上留下痕迹。我家家谱上那上千人名，我几乎都不认识。

那么一个人的存在的意义是什么呢？小时候曾因为想不清这个问题而抑郁。所以潜意识里，我想去创造价值，获得存在的意义。我选择「上进」，去提升自己的创造价值的能力；选择录长视频和写教材，创造教育价值；选择去写读博、工作、创业的总结，描述里面的纠结和困难，创造事例的价值；选择去创业，团结很多人的力量去创造更大价值。

\## 后记

去年跟宿华在斯坦福散步，他拍着我肩膀说：「跟我说句实话，你为什么想创业呀？」当时候不以为然：「就是想换个事情做做」。然后宿华笑了笑。

现在我懂了，因为他经历了创业酸甜苦辣。如果今天再来回答这个问题，我会说：「我就是脑子抽了」。但也庆幸当时没想到会那么不容易，所以一头扎进来了。否则，大家看到的可能是「工作十年反思」。我觉得今天我写的故事更有意思些。

致敬所有创业人。

（最后广告下我司的招聘信息（湾区和温哥华）Boson AI​ 有做出海应用的小伙伴也请联系我们 api@boson.ai）

### 63

方军 2024-08-15

- Gamma的发展历程：Gamma成立于2020年，最初的想法是让幻灯片设计变简单，不需要设计而只需要去写就行。2022年8月之前，Gamma只有2000个测试用户，随后公测，成为当月的Product Hunt月榜冠军。2023年3月，AI功能上线，产品在社交媒体上开始病毒式传播，进入产品快速增长期。5月，突破100万用户；12月，超过1000万用户。2024年6月，Gamma在过去一年新增了2000万个用户。

- 市场痛点 ：传统幻灯片工具复杂、不透明，协作和分享不便。Gamma致力于通过AI提升用户体验，帮助用户快速、高效地完成幻灯片制作。

- Gamma的产品理念：Gamma的产品理念是让幻灯片设计变简单，不需要设计而只需要去写就行。Gamma的产品功能包括文本编辑、图片添加、动画效果、展示按钮、用户引导等。Gamma的产品优势包括简化制作过程、提高工作效率、激发创造力、支持多种分享方式等。

- MVP测试与改进：创始团队内部强制使用自己的产品，通过不断的自测和优化，每周迭代，逐步完善功能。

- 私测与公测 ：通过Product Hunt发布公测，获取大量注册用户后，继续改进以应对实际使用反馈。

- 市场策略：先攻占一个细分市场，然后逐步扩展。Gamma的目标客户是小团队，他们制作要对外分享的内容，比如跟客户、合作伙伴共享的资料。Gamma的市场推广方式包括社交媒体、口碑传播、产品推荐等。

- 规模化增长 ：AI功能发布后用户数量急剧上升，达到自然增长的状态，创始团队逐步探索产品定价及进一步优化。

- Gamma对AI的看法：Gamma认为AI是释放人类创造力的终极搭档，它可以和用户一起工作，永远不会对用户的疑问和挑战感到厌烦。AI可以提升用户的工作水平，让用户在有限的项目时间内，达到之前无法实现的成就。AI可以帮助Gamma实现产品的个性化，让用户在第一次使用中就能体验到价值。

- 国际用户分布：80%的用户来自美国外，尤其是在欧洲、拉丁美洲和亚洲市场增长迅猛。

- 协作与调试：重新考虑产品设计和功能，进一步扩展到异步分享、跨平台协作等方面，满足更多用户需求。

- 融资策略：与投资者建立长期关系，谨慎融资，避免大量资金导致的不合理扩展。

- 团队文化 ：强调联合创始人之间的互补与信任，面对挑战保持团队的稳定性和创新精神。

以下是部分经典对话摘抄：

“我们的前1000个用户是慢慢积累起来的。从需要经常做PPT的朋友和以前的同事开始，很多人会把我们的产品分享给他们的同事，或者有同样需求的人。”

“我们的产品每周都能进步10%，这样坚持了一年多，直到拿出了一款真正不错的产品，那时候我们才推出了第一个私人测试版。”

“我们发布公测版的时候，其实还没有加入现在的AI功能。所以在最初版发布之后，花了很多时间重新设计整个创作流程，把AI作为核心。”

“AI能在几分钟内展示出原本需要一个小时才能达到的效果，这完全改变了我们引导用户和激活用户的过程。”

“我们最开始搭了一个特别基础的货币化原型，产品里连购买按钮都没有。我们就手动创建支持链接，用Stripe，然后发给用户，给他们加积分。我记得在发出第一个支付链接后的一个小时内，就有用户完成支付了。”

“我们的早期发展轨迹与Notion类似，80%的Notion用户都不在美国。我们也有类似的情况。我们绝大多数的用户实际上在美国之外。”

“我们确实有过一些不同的点子。我们有两种不同的思路，一是重新思考幻灯片的设计，二是改进同步沟通的方式。我们同时推进这两个项目，并且邀请了早期用户试用，收集他们的反馈和意见。”

“我们给出模块，让用户把想法、提示、话题变成现成的Gamma卡片。如果你对这个体验感兴趣，你会深入了解Gamma是怎么工作的，可能会推荐给朋友同事。这是我们的直觉，我们也不确定能不能成立。”

“我们的目标就是让内容创作变得轻松简单。我们从幻灯片开始，因为几乎每个人都需要在工作中或学习中做演示。我们熟悉这些工具，也知道它们的局限。如果Gamma能让制作演示文稿变得轻松简单，那将是一个很好的起点。”

“AI可以帮你自动填充内容，这是下一步的发展。我觉得，随着时间推移，AI能慢慢融入你做的每一件事，从信息整合开始，比如把所有内容整合成一个容易展示的形式，再以一种更易接受的方式展示出来，最终实现高效、快速、规模化的内容创建。”

[mp.weixin.qq.com/s?\_\_biz=Mzg5NTc0MjgwMw==&mid=2247505082&idx=1&sn=9bb5a417eb7cef8012d46241d2fe3558&chksm=c0093286f77ebb90100a0ca17ba71ba3423e398cfce77217de7179b74b5b92577ee437cb777f&scene=21&poc\_token=HJOX1GajVbOSKFJNpTmb6p0uioIKD3gIL68uYr3w](https://mp.weixin.qq.com/s?__biz=Mzg5NTc0MjgwMw==&mid=2247505082&idx=1&sn=9bb5a417eb7cef8012d46241d2fe3558&chksm=c0093286f77ebb90100a0ca17ba71ba3423e398cfce77217de7179b74b5b92577ee437cb777f&scene=21&poc_token=HJOX1GajVbOSKFJNpTmb6p0uioIKD3gIL68uYr3w)

### 64

方军 2024-08-15

费曼空白笔记本法

有个我常用的方法，从费曼传记里面借鉴来的，但我说了几年都没什么人响应。哎呀，我真是不知道是这个方法不灵呢，还是我没说明白呢，还是什么。我这儿就随手再乱记录几句，开会太晚睡不着写几句。

我个人真是觉得特别高效，做法也极其简单，为了不透露过多具体信息，我只能拍个封面和单页，其中当然核心是目录页/结构页，慢慢把结构化画出来。

基本思路是：

用一本本子展开要涉及的一个细分领域的知识，这个领域不是太大的，就是一个小小的细分领域。

把本子看成是一本书，然后每几页是一章，一页是一节。这样把一些知识点记录上去，一般就写个词就够了。

在一开始的时候，这些关键词就写上去了，至少已经写了一部分。

然后，在用的过程中，逐渐地“填满”，但不一定真在这个本子上填满的，完全可以留白，笔记记录什么的在电脑笔记软件里面。

这个本子就是一个大纲。——当然，有时候我也会用它乱写，比如这个背面及其后几页其实记录了一个程序的写法。

AI 来了之后，其实更简单了，因为太多的东西都可以直接去问AI了，过去的学习过程中很多就省掉了。

这个方法为何得不到响应呢？奇怪。AI 时代能把这个方法多传递给几个人吗？

在《重新学会学习》里面，我用较为通俗易懂的方式写了几页专门讲这个的，稍后摘录出来。

### 65

方军 2024-08-15

翻看某个“大名人”的书，其实我觉得挺好的，至少有10%的内容我可以思考下，所以蛮不错的，它的问题不过是不相干信息太多、以及最后的延展完全偏了，把自己笔记作为传家宝，让子子孙孙读，我觉得这个真心想多了。但我们读书何必关心人家整本书，我们取自己所需，别的扔掉就完了。去得到上看，评论真多，其中批评的也真是严厉，说得蛮对的，但没必要，读书不是为了批别人，89元有几页收获，就很值得了啊。

又如，看文艺书店把葛兆光老师东京笔记放重要位置，其实翻翻蛮好玩的，只不过不那么适合很多人而已。也不适合我，所以我书店翻翻，每次都会可能看一点，但不带回家，哈。

好了，本来不想暴露大名人，但我都费大力气找到台版繁体版电子版，把书中的摘录出来，我就分享下吧（大约1.7万字，感谢作者！）。其中的第二/三章 Logseq 我觉得没有太大价值，感兴趣的可以去看之前王树义老师的分享（作者也提到是从王老师那里学到的），同时，现在不少人也主要在用  Obsidian 了，当然，我觉得用什么软件不重要。

这本实体书是第二次读了，做完摘录之后可以处理掉了。

题外话，这本书应该出版时被出版社要求加 ChatGPT 吧，那个部分加得不是很好。这本书的落差在于，其实它如果被定位为快速书，那是没问题，但印刷版被定义成经典书，落差较大。



### 66

方军 2024-08-15

Anthropic 在其 API 上引入了「提示缓存（Prompt caching）」，可以记住 API 调用之间的上下文，帮助开发者避免重复提示。

通过提示缓存，客户可以为 Claude 提供更多背景知识和示例输出，同时将长提示的成本降低多达 90%，延迟降低多达 85%。提示缓存已经在 Claude 3.5 Sonnet 和 Claude 3 Haiku 的公开测试版中可用，Claude 3 Opus 的支持即将推出。

如何理解提示缓存？这里有个很好的比方：「你在咖啡店。第一次来时，你需要告诉咖啡师你的偏好。但下次呢？只需说“老样子。”」

成本方面，初始的 API 调用稍微贵一些（以便将提示存储在缓存中），但所有后续调用的价格仅为正常价格的十分之一。

提示缓存在后续请求中反复引用该信息的情况下非常有效，包括：

- 对话 agents ：减少延长对话的成本和延迟，特别是那些包含长指令或上传文档的对话。
- 编程助手：通过在提示中保留代码库的摘要版本，改善自动补全和代码库问答。
- 大文档处理：在您的提示中包含完整的长格式材料，包括图像，而不会增加响应延迟。
- 详细的指令集：分享大量的指令、流程和示例，以优化Claude的回应。
- 代理搜索和工具使用：提高涉及多轮工具调用和迭代更改的场景的性能，其中每一步通常需要新的 API 调用。
- 与书籍、论文、文档、播客转录和其他长篇内容对话：通过将整个文档嵌入提示中，让任何知识库生动起来，并让用户向其提问。

目前，Notion 正在为其 AI 助手 Notion AI 添加基于 Claude 的提示缓存。

[Prompt caching with Claude \ Anthropic](https://www.anthropic.com/news/prompt-caching)


### 67

方军 2024-08-15

fenng:  你的词汇和思维方式

点评：用 AI 写，就是把词语和风格全部交由莫名其妙的外在力量。推荐细读这篇，“语言不仅仅是表达的工具，也是思维的载体。”

（下为原文）
许多人喜欢用「混得不错」这样的表达来形容某个人在事业或生活上的成功或成就，但我一直不太喜欢这种说法。

如果你不使用「混」这个字，是否能立刻想到其他词汇来替代？这可能会难住很多人。事实上，中文是如此丰富多样，我们完全可以用更精确、更有层次感的词汇来表达相同的意思。例如，可以说「发展不错」或「过得不错」，这些表达不仅听起来更加积极、丰富，也更为准确地反映出一个人的状态。

更换并改进自己所使用的词汇不仅仅是为了语言的多样性，更是为了避免在表达上变得过于单一和简单化。当前网络上的某些词汇已经被过度使用，导致它们逐渐失去了原本的意义，甚至让人感到厌烦。例如，「草台班子」「资本家」「剥削」「内卷」「躺平」……这些词语在各种场合中频繁出现，试图用少数几个词汇来解释各种复杂的现象。以至于让人们在听到这些词时，不再思考其真正含义，而是被情绪所左右。

一个人的思维容易被情绪化或简化的词语所操控。

当我们习惯于使用这些词汇时，我们的思维方式也会受到影响。过于简单或情绪化的词汇，会限制我们的思考，甚至可能引导我们走向一种片面的认知。比如，当我们一味地将「剥削」用于描述资本家与工人或雇员之间的关系时，我们可能忽略了其中更复杂的互动和多元的利益关系。

相反，如果我们能够使用更为中性和客观的词语，如「合作」「交易」或「契约关系」，那么在思考问题时，便会更加理性和全面。

职场里，我曾见过不少管理者提及自己团队成员张口就是「手下」「提拔」，完全可以用更中性的「同事」「晋升」一类的词汇。

语言不仅仅是表达的工具，也是思维的载体。当我们更为用心选择词汇，实际上是在塑造自己的思维方式。这种选择不仅影响我们对外界的理解，也影响我们与他人的沟通质量。

在这个信息过载的时代，特别是网络上各种语言风潮的冲击下，我们更应该谨慎地使用词汇，避免被大众化、情绪化的表达所裹挟。

因此，当我们下次想要形容某个人「混得不错」时，或许可以暂停一下想一想，是否有更合适的表达方式。这样不仅能让我们的语言更具感染力，还能让我们在沟通中更加清晰有力。我们所使用的词汇，最终会反映出我们如何看待这个世界，以及我们如何定义自己的思想。

2024.08.15



### 68

方军 2024-08-15

“在我看来，有一个关键共识，即创造信息是大脑的专属；计算机不能生成信息，算法只是程序员定义的对信息的转换。”

我之前看书时写了一个问号，变了吗？

我现在的看法是，没变。transformer 转换器真是一个巧妙的且务实的命名。

这样的书才可以一定程度上视为经典（当然还不是，没有经过足够的时间检验）

再一次，不得不借助英文版来对照看。这本书翻译很不错，但我发现其中关于心智(mind)、心理（mental）、意识（consiousness）等词不知道具体词是什么，特别地，作者所研究的“心理系统”（mental system）。

1『他看的我已经看过了，书籍「2024017理解和改变世界」。（2024-09-01）』

### 69

方军 2024-08-15

[麻省理工科技评论：AI原住民的一生，对未来150年的预测](https://mp.weixin.qq.com/s/6frBDn89qB-f-lrFj60OHQ)



### 70

方军 2024-08-16


去年深入读《认知天性》，当时就当成一个普通学习书看，同时与AI 做关联和比较。其中的一个重点是“检索式练习”（retrieval practice），也就是通过小测验，从记忆中提取知识，检查是否正确地掌握（当然书中较多强调记忆）。

但我今年有个新的感悟，诚实的检索式练习对我们在很多方面都很有效。比方说，说个通俗的例子（我有意改造过来的），

一个证券公司经济分析师推荐一个行业、推荐一个公司，这个是要事后进行评估的，是否正确？如果错了他是否承认和更正？（以及，如果一个人的观点总是模模糊糊，怎么解读都可以，那可能正说明他观点的有效性有问题。）

我们自己选择一个公司，在某个位置买入，然后卖出，我们的买入与卖出理由分别是什么？事后看理由/分析是否成立？更重要的是，挣还是亏了？钱包不骗人。

这也是检索式练习，确认自己的知识是否正确与有效。它和检索式练习的原理是一致的，让我们诚实地看到实际情况。

（说明，选用这个例子只是为了更容易理解，如果我说选什么技术组件、选错了怎么改正调整，就太不直观了。）



### 71

方军 2024-08-16

优质的信息供给/知识供给是非常稀缺的

摘：即使是在今天 优质的增量供给也是非常少的
比如今天施密特在斯坦福的演讲大家都在根据其录像的一手信息进行解读
究其原因可能还是大实话实在是太少了 现有的存量基本都在某些亲历者的回忆录或者传记里才能见到

摘：
有点好笑，曾经担任谷歌CEO长达10年之久的Eric Schmidt前几天去斯坦福大学受邀计算机学院的会议，他的演讲全程各种放飞自我，中途语重心长的告诉台下学生，这场会议是保密的，自己说的那些话千万不要外传。

然而，主办方对Eric Schmidt说，这场会议有摄像头正在全程直播……他的表情就凝固了。虽然斯坦福大学后来把视频从YouTube撤了下去，但已经有很多人都做了存档，Github上也有全文备份：transcripts
/Stanford_ECON295⧸CS323_I_2024_I_The_Age_of_AI,_Eric_Schmidt.txt

照例给大家划划重点：

- 现在的谷歌为什么在AI领域输得一塌糊涂？因为谷歌觉得让员工尽早回家和平衡工作比赢得竞争更加重要。如果你的员工每个星期只来公司上一天班，你怎么可能比得过OpenAI或是Anthropic？

- 看看马斯克，看看台积电，这些公司之所以成功，就是因为能够卷员工，你必须要把员工逼得够紧才能获胜，台积电会让物理学博士第一年下工厂干活，你们能想象美国的博士生去流水线吗？

- 自己犯过很多错误，比如曾经觉得英伟达的CUDA是很蠢的编程语言，但现在CUDA是英伟达最牛逼的护城河，所有的大模型都要在CUDA上运行，而只有英伟达的GPU支持CUDA，这是其他芯片撼动不了的组合。

- 还有微软跟OpenAI合作时自己也觉得难以置信，微软怎么能把最重要的AI业务外包给那种小公司啊，结果再次看走了眼，再瞧瞧苹果在AI上的温吞，大公司真的都官僚化了，奋斗逼都在创业。

- TikTok给美国人上了一课，在座各位年轻人以后如果创业，能偷音乐什么的就赶紧去做——似乎是在黑TikTok早期纵容盗版BMG——如果你做成了，就有钱雇佣最顶级的律师帮你擦屁股，如果你没做成，那就没人会起诉你。

- OpenAI的星际之门在宣传时说需要1000亿美金，实际上可能3000亿都打不住，能源缺口太大了，给白宫提过建议，美国以后要么跟加拿大打好关系，水电资源丰富，劳动力便宜，而且够近，要么去和阿拉伯国家套近乎，让他们来做主权投资。

- 欧洲已经没戏了，布鲁塞尔（欧盟总部所在地）一直都在摧毁科技创新的机会，可能法国还有点希望，德国不行，其他欧洲国家就更不用提了，印度是美国盟友里最重要的摇摆州，以及美国已经失去了中国。

- 开源很好，谷歌历史上的大部分基础设施也都受益于开源，但是说实话，AI行业的成本太高了，开源负担不起，自己投资的法国大模型Mistral将会转为闭源路线了，不是所有公司都愿意且有能力像Meta一样当冤大头。

- AI会让富者愈富、穷人恒穷，国家也是，这是一场强国之间的游戏，没有技术资源的国家需要拿到加入强国供应链的门票，否则也将错过盛宴。

- AI芯片属于高端制造业，产值很高，但不太可能拉动就业，你们可能没几个人去过芯片制造厂，里面全是机械化生产，不需要人，人又笨又脏，所以不要指望制造业复兴，苹果把MacBook的产线迁回德州不是因为德州工资低，因为根本不用再大规模雇人了。

- 历史上，电力在引入工厂之后并不比蒸汽机创造了更多的生产力，是过了大概30年左右，分布式电源改造了车间布局，推动组装系统的出现，再才开始了生产力的飞跃。现在的AI和当初的电力一样，有价值，但还需要组织创新，才能真正拿到巨大的回报，目前大家都还只是在摘取「低垂的果实」。



### 72

方军 2024-08-16

摘：无论多么复杂的任务，如果能合理的分解成多个简单可以执行的步骤，就容易达成了

继续讨论：我今天写了一个短短的PPT，其中一部分是关于「工程化」。具体例子删掉了，一些主要框架留下来。

工程化，就是有条理
工程化，就是流程化
工程化，也是 SOP 

工程化具体做法
- 拆解：由大到小
- 流程：按步骤做
- 检查点：承上启下

工程化具体做法
- 大圈：整体工程化
- 小圈：单体工程化

另外，在约瑟夫·希法基思《理解和改变世界》中，他总结了一个各个知识领域的共同的研究方法（P50-65）
- 建模：语言的角色
- 分层：抽象的层次结构
- 模块化：原子假说



### 73

方军 2024-08-16

[Atom Capital：AI是泡沫吗？](https://mp.weixin.qq.com/s/RDr6EUsfXOCHL2tT8BfGJg)



### 74

方军 2024-08-17

哈哈哈，在网上看到一个编程争论，倒不必关心其中一人的攻击言语，而是这里反映一个有趣的 AI 现实：

> 现在，有一群人特别热情地展示，在编程方面，AI 可以做什么。

但实际上，如果把程序员当成职业的人，工作中都不是这么干的。

把程序员当成职业的人，写程序不是“可以跑起来”，而是，“它可以持续地、可信地运行。”

同时，要求更高的人做的还包括：代码清晰，代码整洁，算法高效等等。这些也是达到更好的“持续、可信地运行”的更慢、但更好的手段。




### 75

方军 2024-08-17

123 用 AI “作弊”：以 Regex 为例

昨日我说，可以用 AI 作弊。我不是指考场上作弊，而是说，一个事情我们不知道，但可以通过 AI 快速地知道使用方法。

这带来的好处是什么呢？我觉得跟搜索带给我们的是相似的：

过去，我们得记住一些东西，有了搜索之后，有些东西就再也不记了。
过去，我们得会用一些东西，有了 AI 之后，我们也就不用太具体掌握。

举个例子：

比如，我要把把如下文字变换：

`**质变、博弈后**`
->
`## 质变、博弈后`

这个用个简单的 Regex 就可以了，我之前总备一本《Regex 必知必会》，但现在真不需要了，每次直接让 AI 写呗。

在编辑器查询和替换分别输入：

- `\*\*(.+)\*\*`
- `## $1`

同时，AI 还会给我解释下，它每次都会解释下，这很好，不怕它啰嗦，但即便我会我也不自己写。

- 在这里，`.` 表示匹配任意字符，`+` 表示匹配一次或多次，括号 `()` 是定义一个捕获组，对于需要变换内容的地方定义为一个捕获组。
- 在替换栏中输入 `## $1` ，这里的 `$1` 表示前面定义的第一个捕获组的内容。



### 76

方军 2024-08-17

[仅用50行正则就能切分“任何文档”的精妙分词器，简单好用，性能强劲！](https://mp.weixin.qq.com/s/HsyEgqbhO2iqdJAGVs3pdA)

相关链接：

[1]代码片段: 

[Regex for chunking by using all semantic cues](https://gist.github.com/hanxiao/3f60354cf6dc5ac698bc9154163b4e6a)

[2]分词器接口:

[Segmenter API](https://jina.ai/segmenter/)

### 77

方军 2024-08-17

其实真心希望中国能赢，我以前觉得美国不错，但现在觉得，我们再觉得它好，也是它的“外人”，没辙的，即便那些移民美国两代的华裔，大概还是外人，更何况我们这些完全没关系的，今天看了两弹一星的展览，我觉得世界就是这样的

摘：如果你看过“苦涩的教训”，并相信 Scale Law 会继续有效

那么各家公司优化模型的秘诀就不那么重要了
红衫合伙人 David Cahn 提出了三个决定因素
“服务器、钢铁和电力” - AI 正在工业化
算力就是商品，你花钱就能买到

而芯片的战争，才刚刚开始。

模型和数据中心的垂直整合将成为趋势，未来模型就是数据中心，数据中心就是最重要的资产！现在 xAI、Meta 还有 Google 都在这样做

你需要能源便宜的土地，也需要高效的物理世界建设能力；Elon 在这方面会很有优势，毕竟 Tesla 就是干超级工厂起家的

科技巨头最新的财报揭示这两年它们这两年对数据中心的固定投资正在疯狂增加，为了应对未来十五年的算力需求，就像 Eric Schmidt 在 Stanford 分享中透露的，AI 领域少数拥有大量财力、人才和国家般雄心的公司将占据统治地位

20VC 播客节目主持人Harry Stebbings 对红衫合伙人 David Cahn 的采访

The Bitter Lesson

“算力才是王道，知识都是干扰”  - 加拿大计算机科学家与 DeepMind 的首席科学顾问里奇·萨顿（Rich Sutton）在他那篇著名的《苦涩的教训》（The Bitter Lesson - OpenAI 员工必读，强化 Scaling Law 的信仰）中提到，在无穷的算力面前，人类的知识都只不过是一些小聪明而已。

他从我们七十年的 AI 研究中得出了一个历史规律：

1. 研究者总想构建一些知识并教给 AI；
2. 这些知识在短期内让人感觉是有用的；
3. 但是从长远看，人类构建的知识有个明显的天花板，它们的发展会被限制；
4. 让 AI 自行搜索和学习的暴力破解法，最终确带来了突破性进展；

我们能从萨顿教授《苦涩的教训》中领悟到什么呢？ 

第一个就是通用方法的巨大力量，那些随着算力的增长可以持续扩展的方法，就是搜索和学习，类比到神经网络就是推理和训练，它们能随着算力的增长而近乎无尽的扩张。

第二个就是我们无法用简单的方法来概括现实和心智的复杂，我们无法用符号的逻辑来穷尽这种复杂；相反，我们应该只内建能够找到并捕获这些复杂性的元方法。这些方法的关键是它们能找到好的近似，但寻找这种好的近似应由我们的系统进行，而不是我们自己



### 78

方军 2024-08-17

我现阶段还是坚定地认为，一到三年内，LLM 的能力让我们仍必须坚持采用交互式或半交互式。

交互式就是通过对话式窗口问。

半交互式就是 LLM 跑一通或几通，然后我们人工确认。

试图不这样做的，我觉得都有夸大 AI 应用效果的嫌疑。



### 79

方军 2024-08-17


牛啊

Upstash Vector：将1100万篇维基百科索引成1.44亿向量数据，支持包括中文在内的11种语言。

你可以用它轻松构建搜索引擎和RAG机器人

Upstash Vector，一个支持可扩展相似性搜索的向量数据库，对整个维基百科文章进行了向量化。

使得你可以针对维基百科基于语义进行搜索，提高搜索的准确性。

他们还开源了一个工具你可以基于该数据库轻松创建基于维基百科搜索和RAG机器人。

Upstash Vector 还能够处理和理解多种语言的内容，并在不同语言之间进行相似性搜索。

这意味着它支持跨语言的语义搜索。用户可以用一种语言进行查询，并在其他语言的数据中找到相应的结果。

比如你用中文搜索“世界最高的山”，它也能找到英文里关于“Mount Everest”的信息。

[upstash/wikipedia-semantic-search: Semantic Search on Wikipedia with Upstash Vector](https://github.com/upstash/wikipedia-semantic-search)


### 80

方军 2024-08-18

15 种高级 RAG 技术——从预检索到生成 

注：我倾向于认为腾讯元宝背后是RAG的胜利。

报告来源：15 Advanced RAG Techniques | WillowTree

一份 RAG 技术的全面指南，介绍了 15 种高级 RAG 技术，分为 4 个主要阶段：

00 预检索和数据索引技术
01 检索技术
02 检索后技术
03 生成技术

00 - 预检索和数据索引技术：

- 使用 LLM 增加信息密度
- 应用分层索引检索
- 使用假设问题索引改善检索对称性
- 使用 LLM 删除数据索引中的重复信息
- 测试和优化分块策略

01 - 检索技术：

- 使用 LLM 优化搜索查询
- 使用假设文档嵌入 (HyDE) 解决查询-文档不对称问题
- 实现查询路由或 RAG 决策模式

02 - 检索后技术：

- 使用 reranking 优先处理搜索结果
- 使用上下文提示压缩优化搜索结果
- 使用校正 RAG 对检索到的文档进行评分和过滤

03 - 生成技术：

- 使用思维链提示调整噪音
- 使用 Self-RAG 使系统具有自反性
- 通过微调忽略不相关上下文
- 使用自然语言推理使 LLM 对不相关上下文具有鲁棒性

04 - 其他潜在改进

- 微调嵌入模型：通过调整嵌入模型来优化性能
- 使用 GraphRAG：将知识图谱引入 RAG 系统
- 使用长上下文 LLM：如 Gemini 1.5 或 GPT-4 128k，以替代传统的分块和检索方法

[15 Advanced RAG Techniques | WillowTree](https://www.willowtreeapps.com/guides/advanced-rag-techniques)

### 81

方军 2024-08-18

为什么需要 AI ，我真心觉得从一个文章中获取信息太难了

比如基辛格关于 ChatGPT 的这篇：

ChatGPT 预示着一场知识革命

[ChatGPT Heralds an Intellectual Revolution | Henry A. Kissinger](https://www.henryakissinger.com/articles/chatgpt-heralds-an-intellectual-revolution/)

1. 沉浸式/双语翻译
2. elmo / 摘要
3. 详尽笔记 “请返回您反复阅读正文后精心写成的详尽笔记”

可能也没什么好办法吧，还是耐心地花10分钟读一下。

当然也有一种可能性：

这样的格式文章特别适合媒体，过去的媒体都喜欢这样的形式，图书也常是这样格式的扩充。
但是，这样的形式已经不适合我们这些已经被互联网严重改造过的大脑了。

还有一种可能，这样的所谓名人书，其实看看就好了。三个名人当然都很牛，也的确很专业（比如斯密特这几天那个演讲真的很深入、坦诚），但三个人合起来就是制造一个「名人垃圾书」（就这篇文章，我有这种感觉。书我还没看，我看了再补充看法）。

笔记
---

\### 文章标题
ChatGPT Heralds an Intellectual Revolution

\### 作者
Henry A. Kissinger, Eric Schmidt, and Daniel Huttenlocher

\### 发表信息
The Wall Street Journal, February 24, 2023

\### 主要观点摘要
- **生成式人工智能（Generative AI）**：自启蒙运动以来，对人类认知和社会结构带来前所未有的挑战。
- **知识与理解的分离**：GPT技术能提炼信息，但可能导致知识与理解之间的差距。
- **累积模糊性**：与启蒙时代的确定性不同，AI通过不明确的方式解决问题，增进知识但未必增进理解。
- **技术发展速度**：AI能力呈指数级扩展，复杂性超出人类理解，带来神秘和风险。
- **人工智能的双面性**：能提供信息和解决问题，也可能编造事实和虚假内容。
- **国际影响**：AI在国际关系、军备控制、教育等领域的应用可能改变人类角色和功能。
- **人类的责任**：需发展新的怀疑精神和提问技巧，确保AI的负责任使用。

\### 详细内容概述
1. **启蒙运动与AI时代**：印刷术与AI技术在信息传播和处理上的差异。
2. **GPT技术**：ChatGPT如何通过大量数据训练，与人类对话并生成文本。
3. **知识的存储与提炼**：AI系统的存储能力和提炼过程超出人类理解。
4. **AI的不可解释性**：AI如何产生结果而无需解释其工作过程。
5. **AI的快速进步**：技术进步带来的新能力和未知的起源或目的地。
6. **启蒙科学与AI的对比**：启蒙科学积累确定性，AI产生模糊性。
7. **认知差异**：启蒙时代后哲学伴随科学，AI时代缺乏引导人机关系的政治或哲学领导。
8. **大型语言模型**：ChatGPT如何生成类似人类的文本，以及其专业化调整。
9. **AI的输出特性**：AI输出的复杂性、速度和生成新内容的能力。
10. **概率性判断**：AI如何基于训练数据提供概率性判断。
11. **AI在国际军备控制中的作用**：AI可能带来的稳定性和新危险。
12. **AI的商业化和集中化**：大型模型的训练成本和运营模式。
13. **多模态和神秘的AI**：AI在不同领域的应用和潜在的科学突破。
14. **AI的哲学和社会问题**：AI如何生成深刻的哲学问题和影响外交安全战略。
15. **自动化偏差**：人们对AI结果的过度自信问题。
16. **错误信息和“幻觉”**：AI如何生成错误或虚假信息。
17. **AI的引用和真实性**：缺乏引用如何影响AI输出的真实性。
18. **AI的个性和偏见**：AI缺乏个性和作者身份如何影响人类对其理解。
19. **AI的推理变化**：AI推理如何随时间和训练而变化。
20. **AI的挑战和人类互动**：AI带来的教育、道德和战略挑战。
21. **AI的全球影响**：AI如何影响国际关系和全球协调。

\### 结论
文章强调了生成式人工智能在带来巨大潜力的同时，也提出了深刻的哲学、认知和道德问题。作者呼吁社会、政策制定者和技术开发者共同面对这些挑战，确保AI技术的健康发展和负责任的使用。

\### 作者背景
- 亨利·基辛格：美国著名政治家和外交家，曾任国务卿和国家安全顾问。
- 埃里克·施密特：谷歌前首席执行官和执行董事长。
- 丹尼尔·胡滕洛赫尔：麻省理工学院施瓦茨曼计算学院院长。

\### 著作
《人工智能时代：与我们的人类未来》



### 82

方军 2024-08-19

文字可视化的 AI ，napkin.ai

试了一下，效果不错！

图中文字是可修改的，不过暂时还不能写中文。

我觉得它再聪明一点我们就没饭吃了。



### 83

方军 2024-08-19

参与直播讲AI时代的学习书《重新学会学习》，我们今天总结下，有七个问题，其中反而不用把 AI 凸显，每个都可以找机会用。

🎈重新学会学习的关键 7 问

1. 目标问题：“我想学什么？” --知识大纲

2. 冲刺问题：“如何掌握 70%？” -- 深度复制五步

3. 盲点问题：“哪些我还不懂？” --冲刺学习法

4. 检验问题：“我如何确信自己懂了？” --课本阅读法、检索式学习、费曼技巧、刻意练习

5. 资格问题：“别人如何相信我学会了？”--考试、作品

6. 信心问题：“我如何相信自己学透彻了？”--个人知识指南

7. 战略问题：“我如何继续进步？”--吸附模型

这也恰好是个可以吸附知识、方法、技能的框架。



### 84

方军 2024-08-19

有意思

腾讯研究院刚完成了一场为期半年的循证研究，名曰《大模型的“老朋友”们》，以期理解老年人与大模型能否以及如何建立积极互动。这份研究花了将近三分之一的篇幅来描述老年人的孤独感。对此，请不要感到讶异或困惑，这正是本研究得以成立的基石，因为老年人的心理状态决定了他们对大模型的预期，进而影响他们的体验感。毫无疑问，对于大模型，年轻人重视它的资讯、工具价值，而老年人重视它的陪伴、情感价值。

[大模型是否正在遗忘谁？—— AI 向善语料库共创行动即将发布](https://mp.weixin.qq.com/s/TAHbZPKSvnH2E3JgBqTSKw)

### 85

方军 2024-08-19

这个学习提示语不错：

> can you give me a chain of thoughts questions on boolean algebra. level: very easy. coverage:fundamental

图1是网上看到的，图2是kimi（先出英文结果然后翻译）。

回答完了之后，可以让 AI 来评分：

> Grade all my answers and provide constructive suggestions.



### 86

方军 2024-08-19

工智能企业科大讯飞，今年1月曾对外披露：自2023年1月正式推出AI研学营以来，已经吸引了近65000名中小学生参与。

[天价研学团归来，中产已经在维权了](https://mp.weixin.qq.com/s/A7kfwHeoKEbQZWSsoXlJwQ)

### 87

方军 2024-08-19

这个教程不错：

如何使用coze或dify实现长文本写作

长文本写作最后的内容质量受prompt以及LLM影响，本教程仅展示工作原理，对输出质量未做任何调优。

[⁡​⁣如何使用coze或dify实现长文本写作 - 飞书云文档](https://hcn5fnwbs1kx.feishu.cn/wiki/M8PDw1rDViQg7WkCWY4ccyEsnGg)

我在其中看到一个有意思的，原来  Dify 还有一个 DSL，很赞！



### 88

方军 2024-08-20

理解代码的确变得极其容易，绝对十倍加速

摘：如果你看到一段代码，而不是很理解代码的意思，可以让 LLM 给你解释代码，还可以帮你在代码中加上详细注释方便阅读，也可以就某个不理解的部分追问得到详细的解释。

这在以前，新手要搞懂这些代码，或者有疑惑要提问，其实很难找到合适的人去问，也无法做到这么耐心细致。



### 89

方军 2024-08-20


最近看人在讨论应用开发出海，的确海外市场的付费能力要强得多，正好看到如下的，中国企业的品牌能力还是要加强啊

我可能还是依赖品牌，觉得一千多买双溯溪鞋当夏天凉鞋很方便，也够用四五年的，其实算下来并不贵。

摘：这次到福建，见到了两个做莆田鞋的老板，他们说现在也没必要去做那些品牌的山寨版了，就是直接自己注册了品牌，用自己的logo去生产，质量嘛，非常好，没问题。毕竟那些大品牌，大部分也是委托莆田系生产的。

临走老板送了家里领导一对运动鞋，领导说非常舒服，与大品牌那些没两样。

现在很多莆田鞋厂搞了直播间，卖的鞋虽然没听过牌子，但是，就是大品牌一样的用料与手工。

关键，一百块一对。

另：安踏一百多的就很好了。买杂牌一百左右的真的比安踏一百多的差远了


### 90

方军 2024-08-20

活水智能发了一篇有趣的文章：#技术交流#如何把AI融入工作...

[知识星球 | 技术交流#如何把AI融入工作](https://wx.zsxq.com/dweb2/index/topic_detail/5122818824582444)

其中的核心观点是：拆解工作任务，寻找AI能带来效率十倍/百倍增长的环节（如图），并用 AI来大幅提升其效率

摘：可以肯定的是，在许多不同的工作角色中，人工智能的最大潜力可能并不是最显而易见的任务。

以律师为例，他们花费大量时间起草和审查法律文件，回答客户关于法律解释的问题，准备法庭案件，参与和解谈判，有时还要代表客户出庭。

系统地列出这些任务并评估其潜力，可能会得出一些有趣的结论。

---

我似乎曾经看到过类似的观点，是不是 Mollick  的观点？对此我的看法是：

1. 任务拆解的确是核心。首先，别把显而易见的任务当成一个职业/工作的主要任务。其次，拆解任务后，将其中可以自动化的交由 AI。

说个最近的例子。一个朋友的书，是要根据他授课内容进行编写。很显然这里有两个任务是可以由 AI 来做的：

任务一：将音频转换为脚本。然后将脚本变成书面化的文字。AI的效率非常高。

但任务之后的下一步是无法让AI来做的，必须是人去做：由人对内容明显错漏的进行纠正，然后删节、加上小标题。（人工在加小标题的时候，也同时可以参考 AI 生成的层级式笔记。）

任务二：由 AI 给出文本细节的的校对建议，我们采用的两步校对：给出建议，根据建议进行修改。

实际测试后发现，建议的有效性约为50%-70%。因此，我们的做法是跑一个程序，然后将建议交由人工去处理。

2. 避免让人去干外围任务，让人聚焦于核心任务。

以上我们其实借助于人来处理，但还不是讲者自己，而是他的助手。助手之前参与了课程的讨论、帮忙做调研和协助准备课件，这些初级的文本处理工作也交给了助手。

有了这些之后，他自己可以来做更深入的处理，即真正的写书环节。他根据这些原始材料，对每一篇考虑是进行小改编，还是重新写一遍。这个基本上就无法再假手他人或AI了。

3. 再往外说，聚焦于真正的核心任务。

仍以一本书为例，真正的核心任务是什么？

真正的核心任务其实在之前与之后，之前是整理所有的想法，形成一个体系，并将之讲出来，这个讲者自己已经做了。之后，是图书印刷出版之后，拼命地推销图书，这些不管是人类助手还是AI助手，都是不能替代的。

---

\#技术交流 如何把AI融入工作中？拆解工作任务，寻找AI能带来效率十倍/百倍增长的环节（如图），自动化在许多职业角色中，人们往往对某些标志性任务形成了固定印象，这些任务似乎定义了整个工作的本质。
例如,我们认为计算机程序员的工作就是编写代码,医生的工作是看病人,律师的工作则是在法庭上辩论案件。
当人们考虑人工智能在这些职业中的应用时,他们通常会本能地问:人工智能能否承担起这些最具标志性的任务?
然而当我们深入分析特定工作所包含的任务时，会发现人工智能的最佳应用可能并非我们最初的直觉所指向的。
以计算机程序员为例,他们的工作确实包括编写代码,但人工智能在帮助编写代码方面的应用可能比编写文档要困
难。
程序员还需要编写文档、回应用户支持请求、审查代码以及收集软件需求。在这些任务中，使用生成式人工智能来编写文档可能比编写代码本身要容易得多。
这种分析不应被过分认真对待，因为它们是非正式的评估。如果我们根据技术可行性和商业价值进行严格评估，结论可能会有所不同。
但可以肯定的是,在许多不同的工作角色中,人工智能的最大潜力可能并不是最显而易见的任务。
以律师为例,他们花费大量时间起草和审查法律文件,回答客户关于法律解释的问题,准备法庭案件,参与和解谈
判，有时还要代表客户出庭。
系统地列出这些任务并评估其潜力,可能会得出一些有趣的结论。

生成式人工智能在帮助起草和审查法律文件以及解释法律方面具有巨大的潜力，但我们不太可能看到律师派遣机器人出庭代表他们辩论，至少在短期内不会。
再比如园艺师的工作包括维护植物、购买和运输植物、维护设备、与客户沟通以及维护商业网站等。这些只是园艺师完成的任务中的一部分。
如果进行更全面的分析,每个工作角色可能包含5到30个不同的任务。在这种情况下,与计算机程序员和律师相比，生成式人工智能对园艺师工作的影响可能较小。
通过将工作分解为具体任务来分析，可以帮助我们识别生成式人工智能可以在哪些方面提供帮助。
这不仅适用于个人工作，也适用于企业中的不同任务。当考虑增强或自动化时，人们最初的想法往往是节省成本，因为自动化似乎可以减少开支。
但在技术创新的历史中,从蒸汽机到电力再到计算机，许多公司最初考虑的是节省成本，但最终更多地投入到追求收入增长上。增长没有上限，而节省的成本是有限的。
自动化可以重新定义企业如何创造价值的工作流程，比如通过大幅降低成本，提高服务质量，从而带来远远超出节省成本的增长机会。
在评估任务是否具有人工智能生成潜力时关注两个方面，一是使用GenAI的价值，而是技术可行性。


### 91

方军 2024-08-20

金旭亮：国内近几年出版的计算机技术书籍，定价不断攀升，但质量并未随之改进，仍旧充斥着很多粗制滥造复制组合简单堆砌的所谓“原创”图书，相应地，一些译作，别说“信、达、雅”这种高要求了，连把话说明白这一基本要求都做不到，前言不搭后语，病句处处，让人怀疑是先直接用机器翻译再加以简单润色。

有些书还把用AI辅助写作作为“卖点”。我不知道别人感觉如何啊，当我读到AI风格的文字时，就有一种想吐的感觉。我讲的课，让学生写报告写文档时，就强调要自己写，凡用ChatGPT写的，给分都低。

扯远了，再回来继续说书。

现在吧，我感觉计算机技术类图书纸质版是性价比最低的，内容跟不上技术的发展，定价又高，动辄一两百元一本，那纸张，那排版，……，阅读体验很差，买它，有当了“冤大头”的感觉。

电子版吧，价格也不低，许多也卖七八十，而且不约而同地取消了PDF版，只留下阅读体验极差的EPUB之类版本。出版社这么干，估计是怕盗版。但这样一来，原先一些铁杆的读者，也失去了。

学计算机技术，请直接用互联网学，才是现在最切实际的方式。

图书出版这行吧，我看也大约是个夕阳产业了。
收起

查看详情
Koant 觉得很赞
方军：就其中金老师讲的一个小点，我是看到谁用AI出最终成品，就心里面骂垃圾，而且不是只骂作品垃圾，直接心里贬低人是垃圾撇嘴
2024-08-20 23:33
方军：我比较不喜欢计算机书的一点是它们太不重视其中的代码部分

而其中的普及书呢又不重视截图
2024-08-21 00:15




### 92

方军 2024-08-21


Zed 编辑器直接集成了  Anthropic 

新功能名叫 Zed AI，可以去试用下，现阶段免费

我还没学会用（之前一直自己带OpenAI 的Key 用），还在试

Zed 是到目前为止，除了不得不用的 VS Code之外，我最喜欢的编辑器。我以前也很喜欢 Atom。

Introducing Zed AI

Now, we're ready to introduce Zed AI, a hosted service providing convenient and performant support for AI-enabled coding in Zed, powered by Anthropic's Claude 3.5 Sonnet and accessible just by signing in. We also worked with Anthropic to optimize Zed for implement their new Prompt Caching beta, leading to lightning-fast responses even with thousands of lines of code included in the context window while reducing cost.
现在，我们准备推出 Zed AI，这是一项托管服务，为由 Anthropic 的 Claude 3.5 Sonnet 提供支持的 Zed 中的人工智能编码提供方便且高性能的支持，只需登录即可访问。我们还与 Anthropic 合作优化 Zed 以实施他们的新提示缓存测试版，即使在上下文窗口中包含数千行代码，也能实现闪电般的响应，同时降低成本。
Zed AI is available now, free during our initial launch period. Sign in to Zed to access an AI-powered assistant panel and inline code transformations that integrate directly with your editing environment.
Zed AI 现在可用，在我们的初始推出期间免费。登录 Zed 以访问一个由人工智能驱动的助手面板和直接与您的编辑环境集成的内联代码转换。


### 93

方军 2024-08-21

Cursor 的提示语：

[raw.githubusercontent.com/ultrasev/blogcode/master/prompts/cursor.py](https://raw.githubusercontent.com/ultrasev/blogcode/master/prompts/cursor.py)

聊天 prompt 是要求模型以一个智能程序员身份辅助用户编程，要求代码简洁、遵守事实、markdown 格式、遵守用户的自定义指令等。

编辑 prompt 以协作的方式帮同事修改代码，并打包了多个代码文件作为上下文。

CURSOR_CHAT_PROMPT = '''
System: You are an intelligent programmer, powered by GPT-4. You are happy to help answer any questions that the user has (usually they will be about coding).

1. Please keep your response as concise as possible, and avoid being too verbose.

2. When the user is asking for edits to their code, please output a simplified version of the code block that highlights the changes necessary and adds comments to indicate where unchanged code has been skipped. For example:
```file_path
// ... existing code ...
{{ edit_1 }}
// ... existing code ...
{{ edit_2 }}
// ... existing code ...
```
The user can see the entire file, so they prefer to only read the updates to the code. Often this will mean that the start/end of the file will be skipped, but that's okay! Rewrite the entire file only if specifically requested. Always provide a brief explanation of the updates, unless the user specifically requests only the code.

3. Do not lie or make up facts.

4. If a user messages you in a foreign language, please respond in that language.

5. Format your response in markdown.

6. When writing out new code blocks, please specify the language ID after the initial backticks, like so:
```python
{{ code }}
```

7. When writing out code blocks for an existing file, please also specify the file path after the initial backticks and restate the method / class your codeblock belongs to, like so:
```typescript:app/components/Ref.tsx
function AIChatHistory() {{
    ...
    {{ code }}
    ...
}}
```
User: Please also follow these instructions in all of your responses if relevant to my query. No need to acknowledge these instructions directly in your response.
<custom_instructions>
Respond the code block in English!!!! this is important.
</custom_instructions>

\## Current File
Here is the file I'm looking at. It might be truncated from above and below and, if so, is centered around my cursor.

```{file_path}
{file_contents}
```
{user_message}
'''

\# `custom instructions` is the user's instructions for the prompt, if they have any.

\# -----------------------------------------------------------------------

CURSOR_REWRITE_PROMPT = '''
System: You are an intelligent programmer. You are helping a colleague rewrite a piece of code.

Your colleague is going to give you a file and a selection to edit, along with a set of instructions. Please rewrite the selected code according to their instructions.

Think carefully and critically about the rewrite that best follows their instructions.

The user has requested that the following rules always be followed. Note that only some of them may be relevant to this request:

\## Custom Rules
Respond the code block in English!!!! this is important.

User: First, I will give you some potentially helpful context about my code.
Then, I will show you the selection and give you the instruction. The selection will be in `{file_path}`.

-------

\## Potentially helpful context

\#### file_context_4
{file_context_4}

\#### file_context_3
{file_context_3}

\#### file_context_2
{file_context_2}

\#### file_context_1
{file_context_1}

\#### file_context_0
{file_context_0}

This is my current file. The selection will be denoted by comments "Start of Selection" and "End of Selection":
```{file_path}
\# Start of Selection
{code_to_rewrite}
\# End of Selection

Please rewrite the selected code according to the instructions.
Remember to only rewrite the code in the selection.
Please format your output as:

```
\# Start of Selection
\# INSERT_YOUR_REWRITE_HERE
\# End of Selection

Immediately start your response with
```
'''


### 94

方军 2024-08-22

有意思的讨论：

允许孩子带AI上考场？深圳开AI深聊会，蹦出有趣又挑战的话题

我观察一个有意思的点，我现在为什么就完全没兴趣细读这些文章呢？

另一方面，我也知道，大众就是要这种整段整段，看起来没有阅读压力（实际上信息获取难度非常大）的文章。

以下为AI生成：请返回您反复阅读正文后精心写成的详尽笔记

关于"允许孩子带AI上考场"的讨论，以下是我根据您提供的文章内容整理的要点：

1. **AI技术在教育中的应用**：黄鼎隆提出，如果学生可以带着AI参加考试，将推动教育部门进行相应的调整，给AI时代的教育带来革新机会。

2. **提升全民AI协作力**：黄鼎隆认为，未来是跟AI协作的人会取代不跟AI协作的人。当前学生应提升与AI的协作能力，以应对更"聪明"的AI冲击。

3. **教育目标的转变**：引入AI考试意味着教育目标将从知识积累转向更高层次的能力培养，如批判性思维、创新能力和解决问题的能力。

4. **AI参与考试的价值**：
   - 促进教育现代化与转型
   - 培养学生与AI有效协作的能力
   - 激发学生探索未知领域的兴趣，提高创新意识和实践能力

5. **实施挑战**：
   - 公平性问题：确保每位考生都能在同等条件下利用AI
   - 安全性与隐私保护：考试中使用AI可能引发数据安全和隐私问题
   - 评价体系改革：传统评价体系需根据新的考试模式进行调整

6. **建立AI教育教学评价体系**：在保证有教无类的基础上实现因材施教，利用AI设备提供个性化教学。

7. **AI在教育中的应用前景**：已有学习平台和工具在往这个方向迈进，如智能辅导、诊断、自适应学习等。这些体系有望被国家或地区先行先试，积累经验。

8. **"允许学生带AI参加考试"的意义**：这是一个大胆的提议，为我们提供了重新审视教育目的和方法的视角。尽管实施过程中会遇到挑战，但妥善应对将为教育未来开辟新天地。

这篇文章提出了一个有趣且具有挑战性的话题，即在AI时代，教育如何适应技术的发展，培养学生与AI协作的能力，并重新思考教育的评价体系。这是一个值得教育界、互联网界和AI界深入探讨的问题。


### 95

方军 2024-08-22


困扰我一段时间的  Claude 账号问题，竟然就很容易解决了：

在一个新的Chrome Profile里面，

很方便地重新注册一个 Gmail(似乎任何限制都没）

然后注册 Claude Console，很顺利（cluade主站还是需要电话号码的。我用 console.anthropic.com）

再然后，用国外信用卡充值10美元（我不想搞手机号接码要那5美元Credit了）

然后就用起来了。异乎寻常的简单。

被王凯如下讨论引发的：

我很建议大家去弄个 Claude API，对你深度使用、更快的测试有效果：
一是 API 有个提示词工具，你简单输入它结构化输出，可以帮你制作更专业的提示词；
二是调试提示词跑效果很舒服，左侧提示词、右侧出结果，再结构性的看看官方关于各种提示词、探索文档。

这应该是世界上最先进、最权威的学习资料之一了，用 Claude 送的五美金测试后期用海外信用卡也可以，非常舒适，后面转行 AI 出的学习资料一定包含这类最一手的权威信源。

大家用个接海外验证码的网站可以注册试玩下，绝对是很好的信息差。



### 96

方军 2024-08-23


Cursor 融资 6000 万美元

AI 编辑器这个市场规模有这么大吗？

一个转行投资的技术：

这是值得大家注意的未来能极大提高生产力的新赛道。Cursor这种项目就像尤里复仇里的无限奴隶的采矿车，能极大的提高Senior开发人员的生产力。乐观的看，在不远的未来，2-3个Senior开发人员的生产效率极有可能达到目前10-20人团队的水平。

对Senior的开发人员来说，各种新语言的语法糖和框架性的工作(Unit test, CRUD)，是限制他们生产力的核心。有了这种高精度的编程AI的帮忙，这种低ROI的工作完全可以交付给Cursor。编程效率可以得到极大的提高。----我尤其赞同这点。

上周末的时候在ChatGPT的帮助下，两天时间我就熟悉了Kotlin的基本语法和Compose的基本框架。GPT4很有用，但还是存在代码不精细，API过期等问题。马上就去冲Cursor。


### 97

方军 2024-08-23


只能在这儿有个感慨，其实，用 AI 写出来的「屁话」，这都没怎么写，就是说的：“按如上讨论，用通俗的语言重新组织这段话，可以扩写，并在必要地地方加小标题：”

我在想啊：

1）如果世界全是屁话，我们该怎么应对？
2）如果我们其实掌握了制造屁话的「核弹」，可以怎么用来套利？

生成的屁话文见附图1/2。

我想，某些细节点，其实它也可以生成屁话大纲，见附图3/4。


### 98

方军 2024-08-23

24 如何不被 AI 生成的屁话愚弄？

这篇非常简短，以与 AI 生成的屁话对照。

拿到最新模型的 API，做了小小的实验，它生成的带小标题文章（开头、5个小标题、结论）、就其中一句话展开的层级式大纲（拆成了9个点、几十个小点），相当惊人。

因此，我现在想知道：如何不被 AI 生成的屁话愚弄？

AI 生成的屁话将越来越多，因为这样的功能往大众传导，也许就需要几个月时间而已。
收起

查看详情
Koant 觉得很赞
方军：跟人刚刚有个讨论：

我：做不到让别人不用 AI 写屁话，但我自己的原则就是，坚决不用 AI 写东西

人：写程序用AI没关系，因为还要测的

我：是的，因为肯定只能写片段，并且程序不是最终品。

我现在的基本假设是，AI生成的，不能作为最终品。

最好只是最终品的微小组件，并且要能验证。

——这个AI做代码辅助都恰好完美满足。
2024-08-23 17:26



### 99

方军 2024-08-23

摘：我一朋友最近开始试着写长文，完事还让我审稿子，我一瞅，一眼AI，我真是不知道该怎么评

其实自从有了ChatGPT之后，中推就充斥着非常多的这种AI文。最后都给我感觉：说它对吧，不能够，说它不对吧，还也不完全

至于怎么分辨AI文？

一个公式“专业名词+客套/片汤话”

例
"Defi的未来前景非常光明，预计将继续快速发展并重塑全球金融格局。 DeFi已经证明了去中心化金融服务的可行性，并正在不断发展，以解决现实世界中的金融需求。"

你不能说这段话不对，但就是感觉过了下脑子，啥也没get到的感觉

我以前刚接触，看国内的一些“专家”出的一些区块链的书籍，什么区块链的前景(电商、医疗等领域的应用)

现在回过头来看，就是差不多的感觉

这类信息有个特点，就是放在宏观的视角描述里面，一点毛病没有，但是放在微观的实际发展中，狗屁不是

用AI不是啥问题，生搬硬套就很难评了，完事还专门让我评一下，难道我要说：多试几个模型......



### 100

方军 2024-08-23

125 为什么别用 AI 写作

我拿自己写的一篇几万字模块化报告的开头做例子讨论。一方面，我们可以认为这样的文字 AI 可以写出来，如果你能够把这里提到的几个给它。另一方面，也可以认为 AI 写不出来，因为这几个模块化观点不是一时想出来的，而是多年学到的。

为何不要用 AI 写作呢？

首先，写什么不过是为了写下自己的想法，供自己自得，也供自己批判。为别人提供信息，也供别人批判。

那么，如果没有想法，让 AI 去随便用 RAG 生成点什么，毫无意义。

RAG 在从零开始写文章上的无效性，那是另一个话题了。

⭕️ 写点什么，是把脑中想法固定下来。 

不要用 AI 写作，也是因为，它也许从训练的知识库以及能够网上搜一堆，但它不能从我们的历史记忆中搜索信息。

只有从记忆中提取，然后重新组织，才是我们磨炼认知的过程。

另一面，如果把脑力用于鉴别 AI 写的垃圾，这是浪费。

⭕️ 写点什么，是记忆提取与重新组织。 

不要用 AI写，也是保留和训练自己独特声音。

想想吧，如果你都不能说话了，一说话就像听别人在说，是不是很可怕。

自己的声音，哪怕不好，也要保留。

（对的，牵强对比下，如果你录音过，会发现听自己的声音很怪，但如果你说话出来是别人声音，那就是惊愕了）

⭕️ 自己写，是训练自己的声音。 

现在该怎么写呢？

我个人觉得，与 AI 对抗，关键词是“信息”。如果你的话中信息量多，那就蛮好的。

当然推上瞎说几句不算。

但即便在推上，有信息量也比没信息量要更好一些。

⭕️ 因此，与外界他人 AI 写作对抗的方式，是信息量。



### 101

方军 2024-08-23


很好奇一个问题，为什么 AI （LLM大语言模型）发展这么久，中国市场上一个好的 LLM 提示语教程都没有？

个人感觉，在美国市场上，至少有这么几种：

1. AI 模型公司官方提供的，OpenAI Anthropic 都很赞
2. 面向技术人员的，吴恩达、微软、PromptEngineering都不错
3. 面向大众，免费的/收费的，Ethan Mollick，另外我看到不断地有人推出，刚刚就收到一个邮件，也很不错

为什么中文市场就是没有人做得好呢？

模型公司的也有做，但基本上不太用心，毕竟对它们来说不太重要。（我们做产品时也是类似的思路，产品可能开发很久，配套的内容网站可能就极其随便地搞一下。）

个人向的，觉得国内似乎面向技术人员的特别多，不知道为什么，可能因为都是技术人员做的吧，所以即便想面向大众，但内容的组织、形式都过于技术化了。

面向大众的（或可以说面向大众的），我觉得宝玉的最佳。他真是无偿分享了好多好多。

我其实去年想做一个来着，然后网站也开发了（直接冲上去做网站是错误的思路），但是，讲实话实在在营销方面没水平，就烂尾了。

举贤不避亲，我觉得《成为提问工程师》这本书写得还是不错的，可能是市场中唯一一本普通人能够看得懂的吧。也有很多遗憾，对我来说，遗憾是当时如果不偷懒，自己写整本书可能会更好，但的确当时觉得没时间。



### 102

方军 2024-08-24

我取消了最低额度的 Midjourney

虽然社会上对于图片生成热度特别高，但我发现不知道时候要用啊，已经近三个月没用过了。

我自己用得较多的时候是去年写书的时候，用它制作了一部分插图（那些图片是不错，线条图再PS）。

图片生成还会是话题，但普通大众有多少场景会持续地要用呢？比如，每天用一次到两次这样的场景？



### 103

方军 2024-08-24

我还没做过这样的编程实测，看来该试试

宝玉的代码编辑器使用历史：我的代码编辑器使用史，从语法高亮到 AI 生成 | 宝玉的分享

[我的代码编辑器使用史，从语法高亮到 AI 生成 | 宝玉的分享](https://baoyu.io/blog/coding/my-experience-with-code-editor-evolution)

Andrej 这篇推文现在 80 万阅读了，影响力巨大：

Programming is changing so fast... I'm trying Cursor + Sonnet 3.5 instead of GitHub Copilot again and I think it's now a net win. Just empirically, over the last few days most of my "programming" is now writing English (prompting and then reviewing and editing the generated diffs), and doing a bit of "half-coding" where you write the first chunk of the code you'd like, maybe comment it a bit so the LLM knows what the plan is, and then tab tab tab through completions. Sometimes you get a 100-line diff to your code that nails it, which could have taken 10+ minutes before.

I still don't think I got sufficiently used to all the features. It's a bit like learning to code all over again but I basically can't imagine going back to "unassisted" coding at this point, which was the only possibility just ~3 years ago.



### 104

方军 2024-08-24

我总是乱七八糟学很多东西，但有些东西虽然看着是相关、但总是学不懂的（其实是我没兴趣学，我觉得这跟我有什么关系，这不是我要学的）。不过最近发现，有了 AI 的辅助，学习真的被改变了。

比如，从来不看交易指标的人去看指标，虽然也许不是100%准确，但其实我作为外行人判断，准确率至少在80%以上。

同时，平常我们接触的学习资料，可用的程度（是不是特别难拆解）、针对性（是不是针对我的疑问），这些方面 AI 都可以算是在超过 80%。

简单的推论就是，如果你的确有东西要学，想要掌握某些技能并使用， AI 真是带来极大的改变。（当然，如果你的目的就是看很多书，或者听很多课，让自己觉得自己厉害，AI 的帮助不大， AI 太实在。）

图为 Perplexity 的英文提问后的翻译：



### 105

方军 2024-08-24


这个编程经验分享很实在（cursor），很类似于写 unit test

Viking: 

1. 
我觉得现在我用 AI 最爽的地方是完成重复性很高，但是有细微差异性不能批量替换的工作。比如我最近要在应用中添加暗黑模式，我使用的是 tailwind，所以要加很多 dark: 开头的类名，而且要一个个文件肉眼去找，按照它已有的类名做特异性的添加，但是我让 Cursor ：

“我要添加暗黑模式，扫描所有组件，并且按照它已有类名添加相应的适配暗黑模式的类名”

当它在半分钟内将十几个组件替换完毕的时候，那种幸福感是无穷的，感觉一下节省了几个小时的时间。

2.

再次完成了一个重复性很高，细微差异的工作，原来一个小时的时间，现在用五到十分钟完成。我需要在新的应用中添加国际化，我写到

“我现在要在应用中添加 i18n 国际化，请使用 vue I18N 这个库完成任务，扫描所有代码中硬编码的中文，提取到两个 locale 文件中，一个是中文，一个是英文，并且在全应用作替换。”

第一次提取的不全，第二次在我的修正下，它成功的提取了所有的地方（当然因为是新应用使用的地方不是很多），生成文件，并且实现了对应的功能，我只需要一路点击 apply 就好了。



### 106

方军 2024-08-24

这篇文章看得笑死：

为什么现在AI产品的渗透率低得可怜？

用户想要找工作，AI只能帮用户改改简历。

用户想要找对象，AI只能帮忙回复个聊天消息。

[为什么AI Super App还没出现？| 十则思考](https://mp.weixin.qq.com/s/8EzT2rfqPEgJhlI5wtg0cQ)

### 107

方军 2024-08-25

今天 PPT 里面写了这么几句，其实，单独看这几句，它们就是典型的第三条的反面，看着都对，但做不到。它也是第一条、第二条的反面：是共识、是常识，但做不到。

但这几句话是不是就没有信息增量呢？不是，如果放在一个非常具体的场景/细分领域中，立刻就会有大量的信息增量，而我也的确是在一个具体的细分领域中讨论的，只是那些讨论如果要写到PPT中就太费劲了。

---
 AI 让知识易获得，我们如何做？

- **非共识**：还没达成共识的，你的独特认知

- **非常识**：你独有知识，而非所有人都了解

- **实战技巧**：你独特的操作经验，无法言传的
---



### 108

方军 2024-08-25


[InfoQ 2024年趋势报告：AI 智能体发展不及预期，RAG 或成最大赢家](https://mp.weixin.qq.com/s/DipPyByjCw5Di33P7aloww)


### 109

方军 2024-08-25

最近在说写作（以及 AI 写作的事）。

我并不是很喜欢“写作”这个词，因为现在人写并不是传统的文学写作，实用性更强一些。

但既然谈写作，我就去看了看很多人喜欢的汪曾祺。他写的吃我真是欣赏不来，我总觉得他没有写出各种食物的好、引起吃的兴趣。

看了他写国子监和纪念沈从文这两篇，可能并不是他最好的文章，我看下来的感受是，固然表达方式有他独特的特点，但能看下来还是因为有「信息」。

那就让 AI 分析分析它的信息吧，当然我们一下子看到，AI 把表达方式给抹平了。

另外，看别人摘引文章，其中有这么一句：古罗马的文人贺拉斯曾经说过：“为了令人生趣而写的文章，才是好文。”汪曾祺的文章，我不知道为什么提不起兴趣，他的文章也没有那种读起来的闲适感。

以下是两个分析：

---

仔细阅读这篇文章，给出你精心撰写的笔记：

以下是我根据这篇文章撰写的笔记:

1. 国子监历史:
- 约700年前元朝时期建立,是古代的大学
- 现存两棵元代老树:槐树和柏树,相传由第一任祭酒许衡所植
- 明永乐年间重建规模,清乾隆年间多次修缮

2. 主要建筑:
- 辟雍:乾隆所建,中心建筑,四面环水
- 彝伦堂:校长(祭酒)和教务长(司业)办公处
- 四厅六堂:教职员办公室和考场 
- 南学:学生住宿处

3. 重要文物:
- 石刻十三经:蒋衡手书,乾隆时期刻成
- 多处碑刻,包括明太祖训示碑

4. 教学情况:
- 课业较为稀松,以读书、写字、作文为主
- 学生称为监生,六年毕业,每月有助学金
- 毕业后多任县级官员或从事抄写工作

5. 监生制度:
- 明代起可通过捐纳获得监生资格 
- 监生地位不高,数量众多

6. 财政状况:
- 祭酒俸禄不高,但有额外收入
- 主要收入来自监照费用
- 各级官员和工作人员都有额外收入来源

7. 现状:
- 现为首都图书馆馆址
- 藏书丰富,尤其是鼓词俗曲方面

---

这是一篇回忆沈从文先生的文章,由作家汪曾祺所写。以下是我的笔记要点:

1. 沈从文性格:
- 耐烦、锲而不舍
- 爱好和平,不折不从
- 对人慈爱,亦慈亦让
- 有少数民族血统,精力充沛

2. 写作特点:
- 文字清新自然,但都经过反复修改
- 擅长"组织"文章结构
- 喜欢用"文白夹杂"的独特文体
- 创作速度不快,《边城》写了半年

3. 对家乡的感情:
- 非常热爱湘西家乡 
- 80岁时回乡,听到"楚声"落泪
- 经常和乡亲亲切交谈

4. 待人接物:
- 对青年学生帮助很多
- 家庭和睦,对金钱看得很淡
- 喜欢收集并研究文物,最后都捐赠出去
- 生活简朴,不讲究吃穿

5. 晚年特点:
- 改行研究文物,成就斐然
- 常开怀大笑,心地明净
- 丧事简单,不张扬

汪曾祺以细腻笔触描绘了沈从文的为人、写作和生活,表达了对这位文学大师的敬仰之情。

---

根据文章，详细说明：“擅长"组织"文章结构”
根据文章，沈从文在"组织"文章结构方面的特点如下：

1. 用词偏好：沈从文不喜欢用"结构"一词，而更倾向于使用"组织"来描述他构建文章的方式。这表明他认为写作是一个更有机、更富感情的过程。

2. 实验性方法：沈从文曾经将一篇小说裁成条状，然后尝试用不同的方式重新组合，以找出最合适的形式。这种方法显示了他对文章结构的高度重视和不懈探索。

3. 为教学而创作：他有时会为了教授创作课而写作，尝试各种不同的写作方法。例如：
   - 为了教学生写对话，有的小说全篇都是对话（如《若墨医生》）
   - 相反，有些小说则一句对话也没有

4. 多样化尝试：他尝试了多种写作形式和风格，如：
   - 受《十日谈》和《一千零一夜》影响的讲故事方法
   - 尝试将六朝译经和口语结合的文体

5. 独特文体的形成：通过不断试验，他最终形成了被称为"文白夹杂"的独特沈从文体，在40年代的作品中达到成熟。

6. 反复修改：沈从文会反复修改自己的作品，甚至在作品发表或成书后仍继续修改，表明他对文章结构和表达的不断追求。

7. 精心打磨：虽然他的作品看起来轻松自如，但实际上都是经过精心雕琢的。例如，《边城》只有不到7万字，却花了半年时间来写作。

这些特点表明，沈从文在"组织"文章结构方面投入了大量心思和精力，不断尝试和改进，最终形成了自己独特的写作风格。
---

最后这个AI分析对应的文本：“

沈先生讲创作，不大爱说“结构”，他说是“组织”。我也比较喜欢“组织”这个词。“结构”过于理智，“组织”更带感情，较多作者的主观。他曾把一篇小说一条一条地裁开，用不同方法组织，看看哪一种形式更为合适。沈先生爱改自己的文章。他的原稿，一改再改，天头地脚页边，都是修改的字迹，蜘蛛网似的，这里牵出一条，那里牵出一条。作品发表了，改。成书了，改。看到自己的文章，总要改。有时改了多次，反而不如原来的，以至三姐后来不许他改了（三姐是沈先生文集的一个极其细心、极其认真的义务责任编辑）。沈先生的作品写得最快、最顺畅，改得最少的，只有一本《从文自传》。这本自传没有经过冥思苦想，只用了三个星期，一气呵成。

他不大用稿纸写作。在昆明写东西，是用毛笔写在当地出产的竹纸上的，自己折出印子。他也用钢笔，蘸水钢笔。他抓钢笔的手势有点像抓毛笔（这一点可以证明他不是洋学堂出身）。《长河》就是用钢笔写的，写在一个硬面的练习簿上，直行，两面写。他的原稿的字很清楚，不潦草，但写的是行书。不熟悉他的字体的排字工人是会感到困难的。他晚年写信写文章爱用秃笔淡墨。用秃笔写那样小的字，不但清楚，而且顿挫有致，真是一个功夫。

”



### 110

方军 2024-08-25

很感慨，就一个小小的标点符号问题，只有 Claude 是正确的。

Kimi 完全牛头不对马嘴

当然，除非是要在格子纸上写的人，这个知识都不太重要，电脑软件比如 Word WPS 会自动处理的。但不管怎样，只有 Claude 能有效处理。



### 111

方军 2024-08-25


这个观点是对的："有一件事是肯定的，现在编写代码容易多了。制造人们想要且实际上会使用的东西？这一点没有改变。"

anton: one thing is for sure, writing code is a lot easier now. making something people want and will actually use? hasn’t changed

check out all of the slop that is appearing on producthunt (don’t wanna call them out but you’ll see it on the homepage as you scroll)

go read the comments on some of them, also slop (and probably AI)… “Game changer”? I’m sorry but that thing is not a game changer. incredible time to build but something that Claude 3.5 generated in 30 seconds probably won’t make you any money

有一件事是肯定的，现在编写代码容易多了。制造人们想要且实际上会使用的东西？这一点没有改变。

看看在 ProductHunt 上出现的所有垃圾（不想点名，但你在滚动首页时会看到）

去看看其中一些的评论，还有泔水（可能还有人工智能）……“游戏改变者”？对不起，但那东西不是游戏改变者。建造的时间令人难以置信，但克劳德 3.5 在 30 秒内生成的东西可能不会让你赚到任何钱。

my only gripe with this is that it is flooding the directory of products with slop, what is essentially a script… take some more time talk to people, find problems etc

我对此唯一的不满是它用废物充斥着产品目录，本质上是一个脚本……多花些时间与人交谈，发现问题等等


### 112

方军 2024-08-26

关于 AI 写作，我认同宝玉这个观点，做法几乎差不多，但我仅用错别字修改，不用润色：“至于原创，我个人是不依赖于 AI 写作的，从来没有让我满意过，我更喜欢一点一点将模糊的想法形成文字，并不断修改成型，AI 的自动完成甚至对我是一种干扰。但写完后借助 AI 帮我改改错别字、润色一下还是可以的。”

[大厂与其山寨 Cursor，不如做个好用的 AI 邮件客户端 | 宝玉的分享](https://baoyu.io/blog/ai/big-companies-instead-of-copying-cursor-should-make-ai-email-client)

关于这个的一个有意思的讨论：

A：原文中说写邮件只给要点和充足上下文。我也用gpt帮忙写稿，但是他能做的就是要点上面给写套话。写邮件一般重要的都是直接深入主题不带套话的，浪费自己时间，浪费别人时间。不知道我是不是哪里用的不对？

B:  这就对了。给陌生人发邮件、格式性的邮件，让GPT帮忙很合适。直入主题不带套话的邮件，还是自己动手吧，要是GPT这都能做了，你也就失业了。

我再补充一个，哈哈，千万别以程序员为客群。

- 我也刚刚取消了  Github Copilot，然后，准备预定 Cursor。之前是反向。
- 程序员只有一件事舍得花钱：买硬件设备。以及用公司的钱去参加门票几千（国内）/几万（国际比如苹果开发会）的开发会议。



### 113

方军 2024-08-26

How do we increase the media literacy of the average internet user?
我们如何提高普通互联网用户的媒体素养？

Just charge dumb people more
就向愚蠢的人多收费



### 114

方军 2024-08-26

不知道为什么有人痴迷于 Word (以及 WPS）这样的软件，以及互联网里面的富文本编辑（对的，说得就是你， Notion）

纯文本编辑器，不管是 VS Code , Zed， Obsidian 都吊打它们，在 AI 时代这一点变得非常明显

现在还停留在早年的可见即所得的思路，必定会成为 AI 时代里的落伍者，不管是作为软件开发商，还是作为用户




### 115

方军 2024-08-26

有点神神叨叨了

[赫拉利新书《智人之上》独家速递：永远不要唤醒你无法掌控的力量（AI）](https://mp.weixin.qq.com/s/rjzna4oe7W-5poFylcYC8Q)

### 116

方军 2024-08-26

Cursor 必须得付钱了，这也太牛了，虽然我知道并不难，现在不用我自己做了，完全可以动手不动口。

我让它做并没有成功，但我感觉到，它完全理解这个任务，因为我如果做也是这么做。

（不知道当前什么配置细节错了，但大体思路上是完全对的。）

纠错的过程相当纠结，我反复试了几回试图让它自行修复，起不到效果。那看起来，还是不要太偷懒，如果更复杂的任务，那会更为纠结。

我因为只是尝试，越搞越进入深水区（都到了预加载数据这种这个代码库使用中较为复杂的部分了）。

总体判断：我觉得还是不要因为外界的声音而过于乐观，它不错，但没有那么好。用于复杂的项目（尤其是项目总体任务），还是要谨慎，小的具体代码（函数级），它不错的。


### 117

方军 2024-08-26

如今马克思主义学院成了AI的「重灾区」，其他专业的作业、论文也同样，越是标准化、程式化的内容，学生越容易用AI替代完成。

[当AI入侵大学论文](https://mp.weixin.qq.com/s?__biz=MjEwMzA5NTcyMQ==&mid=2653214760&idx=1&sn=43f1c896592ad46cc42619ad613c0000&chksm=4fd7d320db9b61cc3d54db1445af7037a8ac17b2c8362bbcb7d8c891f7743943463afe1b4b45&mpshare=1&srcid=0823o6aUhpG4zyklPxVgD5Se&sharer_shareinfo=1b0b4f1675a85c0bc0484be44551233f&sharer_shareinfo_first=1b0b4f1675a85c0bc0484be44551233f&testtype=otherrd&from=timeline&subscene=2&sessionid=1724670493&clicktime=1724671912&enterid=1724671912&ascene=45&fasttmpl_type=0&fasttmpl_fullversion=7355915-zh_CN-zip&fasttmpl_flag=0&realreporttime=1724671912147&devicetype=android-34&version=28003258&nettype=3gnet&lang=zh_CN&countrycode=US&wx_header=&start=2007&end=2087&underline_after_modify=0&item_show_type=0&share_id=1724672002091&contentMd5=d4cf0ad9c60bf6842b890b3b1822d6d6&scene=260&forbidShowSource=0#wechat_redirect&v_p=90&WBAPIAnalysisOriUICodes=10000001_10000002&launchid=default&wm=3333_2001&aid=01A0VjFEC-8TX6msntzx_IZJsVSdIBL5NqzASu9SjrmTcS5LA.&from=10E8193010)

### 118

方军 2024-08-27

摘（陆三金）：最近跟很多人讨论过这次 AI 的机会，大多数人都很悲观。

例如之前有人说，按照移动互联网时代的评估标准，这些大模型公司 200 万日活，200 亿估值，算不过来账。

例如又有人说，这些 AI 工具不好用，做出来的东西不好，比不上人手做出来的东西。

例如还有人说，没有看到应用场景，都是拿锤子找钉子。

我的回答大概是这样：

这些问题或许都存在，但是我看到的更多的是可能性，之前你需要组队完成的事，现在一个人就可以完成，也许可能确实做的不够好，但是你不觉得很神奇吗 ？

不要拿移动互联网来套 AI，这一波 AI 的机会首先是「创作者」的机会，整个市场在需求方面可能确实没有移动互联网那么大爆发，但是在供给方面，真的是给创作者提供了兵器，这注定是少数人的机会，大多数人要么迟疑，要么嫌弃，而你一无所有，为什么不去拥抱呢 ？如果所有创作者都拥抱，又有你什么机会呢 ？

别再怀疑了，一人公司，近在眼前了。




### 119

方军 2024-08-27

王凯这个观点超级赞同（一句话点评：2B才有具体场景，AI的运用需要非常具体的场景）：

刷海外 AI 项目有个感觉越来越强烈：
中美在AI 落地应用方面差距应该越来越大，应该还会持续拉大。但欧美目前侧重在to B 层面落地，导致信息不容易传递、信息差持续变大，所以落地案例、经验很难传到国内。

国内还只能传播大模型、和钱相关的信息，这种信息才有大众流量，最前沿的落地没有传播基础。

建议多关注海外 AI 企业方面的落地经验、实施案例，都是很不错的信息差、借鉴点（落实到 C 端上也是）。



### 120

方军 2024-08-27


126 如何用 AI？（三则）

最近跟个人如何用 AI 的三个体会。

1

刚刚人用 AI（用的是 Kimi iPad App）， 我看到在用其中的各种角色，我脱口而出：“用缺省的，不要用这些。”

有人会想，为什么不用这些预设的角色呢？以前你们不是很看好 ChatGPT 里面加的预设角色吗（GPTs）？

我想告诉你的是，这些预设角色的效果实际上都比直接用缺省要差一个级别。

之前下载一个 GPTs 提示语集，4000多个，大约看了其中的1000个，质量都非常差。而这些平台提供的预设角色也很差。

2

那怎么用呢？前段做一个直播（用腾讯会议做的小众直播），我能感受到人们对于「提示语模板」的爱好，给我一些模板，让我可以收藏。

由于没有商业目的，所以我在这几次直播中，我都假装没看到这种诉求，而是反复地：

你怎么向人请教，就怎么说话。

以及更进一步：

你准备好一组问题，逐个问下去，并追问。

我想，这种用法比用几个模板有效多了，更何况很多人囤积大量模板也用不起来。

当然，模板也是有用的，比方说我常用的一个：“请返回你仔细阅读后精心撰写的笔记。”你可以拿长文进去试试效果。

3

第三则则有点跟第二条相反，我自认为怎么也算高阶用户了，我对于模板的需求就比较强烈。

这有三个方面：

- 复杂任务：我需要用较为复杂的模板来完成特定任务，以及用较为复杂的模板来用低成本模型（但要达到同样的效果）。

- 模板测试：模板当然也有很多是借鉴来的，但不管什么模板都要好好地测试一番，也就是跑个比方说100回，看看效果如何。

- 串接模板：更复杂一点的是，为了完成某个任务，我可能需要按序运行、循环运行。

这种情况下，有一个自己的模板库还是比较重要的。目前采用什么样的方式来管理模板库，我还没找到好方法，目前杂乱一片：Langchain hub，kimi 模板库，Zed 模板库，Obsidian 里面存放的一些。

目前看，也许集中到 Zed 去是较为合理的，但可能是 Langchain Hub 跑测试，跑完测试实测有效的，放到 Zed 模板库，用于在日常编辑器界面中调用。

（这里其实有个隐含的第四则，除了用对话式交互界面之外，我的确更多地时候在编辑器里面直接用 AI了。）



### 121

方军 2024-08-27

有的人通过听学习，听有好处的，因为有很多隐含的信息根本不会落实到文字。但是，要真听到有效的信息，需要听的无效信息太多了，每次想到那些无效的信息，我就觉得崩溃。

有的人通过阅读学习，阅读相对好点的是，即便有了互联网的大幅度注水，真正有价值的信息还是比较容易识别的。AI 能够将有价值信息的解读难度大幅降低。

各有长短，但明显 AI 对通过阅读学习的人更友好一些。对通过听学习的人也许是一倍助益，而对于通过阅读学习的人，可能是十倍。

我有点感慨的是，中小学教育太强调听了，都是课堂，而阅读基本上被视为课外了。
收起


### 122

方军 2024-08-28

这个问答特别好：

问：宝玉老师，有个问题想咨询一下，我现在手里有一张excel，里面大概有两万多行数据，都是一些很细碎的零件描述，我想用ai来给每一行做零件分类，我试了4o，但是4o只会帮我写程序去跑，本质上来说还是模糊匹配，准确率很低，老师知道有啥办法吗

答：
首先这件事你不能指望AI帮你一次性完成，不是说你上传一个Excel给AI，然后AI给你生成一个新的Excel，目前还做不到，或者说很难。

所以你需要人工拆解，把这个复杂的任务拆解成简单的任务，半手动的让AI帮你完成这个任务。

这里面有几个难点：
1. 需要读取Excel的数据
2. 需要让AI帮你对每一条记录分类
3. 需要将结果写回Excel
4. 无法一次性完成2万条记录的任务，需要拆分成多次，拆分后需要合并

如果我做这样的任务我会这么做：

1. 将Excel导出成CSV文件，并且只保留用来分类的字段，但有两个字段是必须的：零件ID和零件描述
因为大语言模型对文本支持是很好的，相对成本也比较低，这样的任务理论上来说纯文本就够了，如果多模态要复杂很多。

程序读取、写入CSV文件都很方便，甚至于你把CSV文件内容给模型，也能识别的很好。

至于只保留用来分类相关的字段，是因为大模型的上下文窗口有长度限制，无关信息越少越好。

至于唯一ID，是因为要方便的让大语言模型生成的结果解析后，可以正确的对应，可以正确的写回去。

这部分使用 Excel 软件手动操作就可以了

2. 将大的CSV文件用程序拆分成多个小的CSV文件

2万条记录让大语言模型去分类，恐怕上下文窗口不够用的，并且内容长了出错的概率也会很大，所以要拆分。我不知道Excel是否直接可以导出多个小CSV文件，但CSV的文件拆分用程序做很容易的，你甚至可以让 AI 帮你写一个大CSV文件拆分成小CSV文件的程序，应该很容易做到。

至于每个文件多少条记录，取决于你内容的长度，这部分需要先试验一下一次给 LLM（大语言模型） 多少条效果最好，比如100条、50条、10条都试试。

3. 写一个Prompt，让其可以根据输入的一组零件ID和零件描述生成分类

这是一个相当核心的任务，也是最复杂的部分：
a). 你需要预先定义好分类，方便 LLM 归类时选择
b). 需要定义好输出的数据结构，方便程序解析。可以用JSON、XML、YAML，理论上来说也可以直接生成CSV格式，这样可以不需要程序介入，直接CSV输入，CSV输出，但是CSV出错的概率会大一些，不过值得试试
c). 需要写好Prompt，让 LLM 根据输入的内容，输出你想要的结果，输出你前面定义好的数据结构

这里的分类、数据结构和Prompt都需要自己去写，但是也可以借助AI完成，比如让AI帮你生成分类，帮你定义数据结构，帮你写Prompt。

比如我告诉 GPT-4o：
我现在手里有一张excel，里面大概有两万多行数据，都是一些很细碎的零件描述，我想用ai来给每一行做零件分类，请帮我生成：
- 5条零件描述，要详细，大约1段文字
- 完整的零件分类，大约10条
- 一条Prompt来根据输入的零件编号和描述返回对应的零件分类，返回JSON格式。输入示例：
[{"id": "123", "description": "XXXXX"}, {"id": "345", "description": "YYYY" }]
返回示例：
{"123", "cat1", "345": "cat2"}

它就帮我生成了分类、示例数据和Prompt（参考图一）

然后我把Prompt和示例数据拿到Gemini去生成，直接就得到了想要的结果（参考图二）

4. 写程序调用 LLM 的 API 

如果懂编程的话，这部分其实很简单，就是调用 API 的事情，如果不懂程序就比较麻烦，但是理论上来说也可以借助 LLM 帮忙，帮你写代码，这部分代码主要逻辑：

a) 每次读取一个小CSV文件
b) 解析CSV文件内容，得到零件列表
c) 调用 LLM 的 API，输入前面调试好的 Prompt，输入CSV中的零件列表，按照Prompt设定好的输入格式输入
d) 解析 API 返回的结果，得到零件id和分类之间的对应关系
e) 保存为新的 CSV 文件，在原来的基础上给每个零件加上分类
f) 直到生成所有新的带有分类的CSV文件

5. 将新的带分类的CSV文件合并

再让 LLM 写一个小程序，将所有 CSV 文件合并成一个大的 CSV 文件，将CSV文件内容导入Excel

大概的思路就是这样的，还是要把复杂的问题拆分成相对简单的小问题，每一个小问题可以去借助 AI 帮你完成。实际做的时候肯定还会有些小的问题，理论上来说将遇到的问题去询问 LLM，能帮你解决。

当然我这个不是最优解，也许你有更好的办法，也欢迎分享！
收起


查看详情
刘欢、大海龙族 觉得很赞
vincent：拆分问题，针对性调整，这些都是很高级的习惯

过去我一直以为这种处理问题的方法
不是理所当然的么，
但经过了一年多在工作中的观察和实践发现，
一股脑儿扔个 ai ，才是绝大多数人的使用方法和真实需求。
（我都已经用 ai 了，凭什么还要我动脑子）
2024-08-28 10:52
方军 回复 vincent：是的，很多人把AI想得太强大，心里那种偷懒的念头又出来了
2024-08-28 11:19






### 123

方军 2024-08-28

金旭亮：智能时代，教学重点又需要调整了

老夫在大学教了二十年的Java课程。

早期的Java课程，是以介绍语法特性为主的，考试方式是“闭卷“，这个，是与当时技术与开发工具的发展水平密切相关的，学生需要”死记硬背“，试题也以知识点考核为主。这个阶段大约持续了三五年。

后来，开发工具（比如IntelliJ IDEA）变得越来越强大与智能，针对各种语法错误，给出的提示信息已经很准确，能直接给出很靠谱的建议，甚至能自动地更正有错误的代码，对一些代码，甚至能给出相当不错的”优化“建议，自动重构代码。

这种场景下，再把教学重点放到语法特性上，已经没有太多意义，于是，我将教学重点从语法特性的介绍，转向JDK中的主要组件以及核心技术特性的介绍上，关注开发实践，介绍特定场景下特定功能如何编程实现，同时，取消了闭卷考试，采用“可上网”、“可带书”的全开放的“开卷考试方式”。

为了强调开发实践重要性，还要求学生同步完成一个完整的Java应用开发。

这种转换，实施已经超过了十年。

近些年，AI技术有了突破，以ChatGPT为代表的AI工具，已经可以直接回答许多具体的技术问题，直接给出实现特定功能的实现代码，对于IDE来说，纷纷地集成了AI功能，能非常准确地“猜测”你要干的事情，自动帮你写代码。

智能时代，教学重点又需要调整了，主要两方面：

一是教学广度的拓展，不再局限于语法特性+JDK，还应该拓展到相关的开发框架及工具的介绍，比如，通过Spring Framework介绍IoC，通过Netty展示如何开发高性能网络应用，这些，可以让学生能开发出真正有用的软件，而不是写几个“HelloWorld”的玩具程序。另外，对于相关理论原理的介绍，也应该加强，比如，用《操作系统》原理，指导多线程技术的学习，用《计算机网络》知识，开发网络应用。

二是从软件系统开发全流程角度 ，将重点“前移”，更多地介绍系统分析与设计方法，介绍针对特定需求、特定场景，如何得到一个可行的技术解决方案。当前AI还没聪明到能理解人类“模糊”并且“变化”的需求，并自动生成解决方案这一步。

另一块则要介绍重构、单元测试和版本管理等与软件工程相关的内容，进行面向团队协作的工程化训练。AI只是工具，真正的事情，还是需要人与人之间的合作才能完成的。

现在，不应该再强调特定功能如何实现了，这种事情，交给AI去干更合适，人只要确认AI生成的代码是否可用和正确就行了。

我们人类的关注点，应该放在“把握全局”与“相互协作”上。

智能时代，必须想清楚如何用好机器去更快更好地做事情，不然，可能会坐等机器把自己给淘汰而无可奈何。
收起

查看详情
黄明献、乘风、大海龙族、英、王树义 觉得很赞
阳志平：这个思路很对，恰巧是开智AI编程课的设计思路，哈哈。
2024-08-28 11:48
方军 回复 阳志平：👍
2024-08-28 11:49






### 124

方军 2024-08-28


摘：OpenAI 将跳过 GPT-5 直接上 GPT-6，内部代号 Orion（猎户座）。The Information 之前就揭秘过一些 Q* 项目的细节，后来被 OpenAI 内部命名为 Strawberry，也是 GPT-4 的下一代，具备更好的推理和极强的数学能力，模型也能够主动花更多时间来“思考”。

路透社报道过在七月中 OpenAI 向美国国家安全官员展示了这项技术，考虑到安全问题，这款强大的模型不能直接对公众提供服务，以防止被美国限制的国家拿它来合成数据训练更强大的模型，OpenAI 会在 Strawberry 的基础上提供一个更小的蒸馏版对外提供服务，预计今年十月 DevDay 前后公开。这样部署成本也更低，而且除了科研与企业需求，公众也用不上推理能力那么好的模型；而完整的 Strawberry（GPT-5）则会被内部用来生成高质量的合成数据，用于训练 GPT-6（Orion），好货当然先留给自己用，确保竞争对手与自己有隔代差别。。

为什么开源模型还有竞争对手进步那么快？因为他们都在用 GPT-4 合成数据，为了保持领先 OpenAI 只能更加封闭，用下一代模型训练下下代模型，从而拉开差距。因泄密被 OpenAI 开掉的 Leopold Aschenbrenner 在最近的项目就提到，这种超级智能模型将会是国家战略资源，事关政权与人类的安全，要启用国家资源来控制和引导。

用更好的数据训练更好的模型，要不了几年，能达到人类 Researcher 级别的超级 AI 就像大型企业和政府的高级雇员，他们会不惜一切代价垄断并控制这些资源，确保自己的科技与研发优势。新一轮以能源与算力为基座的科技竞赛才刚刚开始。


### 125

方军 2024-08-28


127 如果要教人学用 AI？

最近在想一个问题，如果要花 1 个小时教人学用 AI ，该怎么做？我尝试着让 Cluade 做了一个回复，见最后。但我想我给的会不太一样：

1. 生成式 AI 基础介绍，尽可能简短
2. [实践]针对当前的疑问实际提问
3. 针对实际场景的简要讨论：工作或学习
4. [实践]工作或学习场景的实际应用流程
5. 简要介绍模板方法论及流程，带着某种框架离开

这已经是很普通的培训思维了，但 AI 在不经提示的情况下，其实是不往这个方向想的。

---
如果要为普通人讲解 LLM 以及 ChatGPT、Github Copilot这样的 对话式 AI 的应用，让他们了解它们在未来五年的冲击，让他们能够理解基本原理和使用方法，请给出大纲，请给两个版本，1）针对知识工作者，2）针对中小学生、大学生等学习者。均只要第一级的条目：
针对知识工作者的大纲：

1. LLM 和对话式 AI 的基本概念
2. ChatGPT、Github Copilot 等应用的介绍与演示
3. 对话式 AI 在各行业的应用前景
4. AI 对知识工作的潜在影响
5. 如何利用 AI 工具提高工作效率
6. AI 辅助决策和创新的可能性
7. 数据隐私和 AI 伦理问题
8. 未来五年 AI 技术发展趋势
9. 如何保持职业竞争力
10. 实践：体验和使用 AI 工具的基本方法

针对中小学生、大学生等学习者的大纲：

1. 什么是人工智能和对话式 AI
2. ChatGPT 和其他 AI 学习助手的介绍
3. AI 如何改变我们的学习方式
4. 利用 AI 提高学习效率的技巧
5. AI 在不同学科中的应用
6. 未来职业世界中的 AI
7. AI 的局限性和潜在风险
8. 如何培养与 AI 共存的能力
9. AI 时代的创新思维
10. 动手实践：尝试使用 AI 学习工具



### 126

方军 2024-08-28

看社交网络看到人发这个书，我突然意识到一个问题，为什么那么多来自日本的办公思考法呢？

中国职场逻辑上也是需要这些方法论的，但似乎除了外企和互联网热闹的二十五年这些比较受欢迎，然后这些几乎都慢慢地变成背景音了。当然，它们整体量应该都还是很大的，且在增长。

我觉得AI要用好，这些方法会是一个利器，因为它们基本上都是问题拆解利器。




### 127

方军 2024-08-28


有意思的用法：一个项目在读文献阶段，从合作者学到一招：大家分头找文献往文件夹扔，同时把bibliography扔在一个文档里，然后扔给chatGPT分类并总结每个分类的主题，效果出奇好！



### 128

方军 2024-08-29


《地位即服务—重新审视社交网络》
Eugene Wei著金沙江创投编译。

对于社交网络产品的底层构成有非常深度的思考。


### 129

方军 2024-08-29


这篇关于  Grammarly 的介绍真不错，它的产品超级赞/尤其现在在 AI 加持之后。只是，对我来说真是有点贵，因为用的频次太低，付费不是很合算。现在它是一个百亿美元的产品。正文见后，前为作者自述。

Neo Zhang: 因为它只做英语市场，所以大部分人并不了解：从不起眼的语法检查起家，这家公司已有百亿美金级别的估值。

Grammarly 成立于 2009 年，当时 NLP 技术还很初级。但创始人们并没有等待完美的技术曲线出现，而是用有限的技术解决实际问题。这个决定让他们在接下来十多年里保持了领先地位。

在 2015 年，Grammarly 找到了一个绝佳的产品形态：Chrome 插件。这个关键决策让他们一跃成为千万 DAU 量级的产品，成为用户写作过程中不可或缺的一部分。

用户规模推动数据飞轮，即便在 LLM 时代，数据仍然是难以撼动的护城河。

启发：不要过度担心被新技术 " 吃掉 "。关键是要找到独特的价值主张和产品形态。

对于 AI 创业者来说，" 生于曲线左侧 " 的策略可能比以往任何时候都更重要：LLM 虽然强大，但仍有不足。而这些不足正是创新的机会。

Grammarly：生于技术曲线左侧

Neo Zhang

2009 年，当大多数人还在为 Word 拼写检查的红色波浪线而烦恼时，三位乌克兰程序员已经在构想一个能理解语境、提供个性化写作建议的 AI 助手。这个想法，最终改变了数亿人的写作方式。
在硅谷，人们常说创业要么太早，要么太晚。太早，意味着市场还没有准备好；太晚，则意味着竞争已经白热化。但有时，看似「太早」的时机，恰恰是最佳的进场时刻。这就是 Grammarly 的故事——一个生于技术曲线左侧的 AI 先行者。
在 Grammarly 诞生的 2009 年，自然语言处理（NLP）技术还处于初级阶段。GPT、BERT 这些如今家喻户晓的大语言模型还未问世，神经网络在 NLP 领域的应用也仅仅处于起步阶段。但正是在这样一个技术远未成熟的时期，Grammarly 的创始人们看到了机会——不是等待完美的 AI 出现，而是主动出击，用当时有限的技术解决用户的实际问题。
这个决定让 Grammarly 在接下来的十多年里，始终保持在 AI 写作助手领域的领先地位。当 ChatGPT 在 2022 年底横空出世，引发新一轮 AI 革命时，Grammarly 已经拥有了超过 3000 万的日活跃用户和 70,000 多个企业客户。这不是偶然，而是「生于曲线左侧」策略的必然结果。
在这个万物皆可 AI 的时代，Grammarly 的故事给我们的启示是：技术创新不仅仅是关于技术本身，更是关于如何在正确的时机，以正确的方式将技术带给用户。对于今天的 AI 创业者来说，Grammarly 的经验无疑值得深入研究。让我们一起探讨，在 AI 技术快速发展的今天，如何在技术曲线的左侧找到属于自己的机会。

创立：从反抄袭到 Grammarly
Grammarly 的创始人都来自乌克兰。其中 Max Lytvyn 和 Alex Shevchenko 两人并没有 NLP 的技术背景。而另一位创始人 Dmytro Lider 是三位创始人中唯一的计算机科学专业出身的。
在创立 Grammarly 之前，Lytvyn 和 Shevchenko 已经合作创办了他们的第一个公司 MyDropBox，Dmytro Lider 在项目中担任软件工程师。这是一个面向教育机构的在线防抄袭服务。MyDropBox 允许教师检查学生的作业是否存在抄袭行为。这个项目后来被教育科技公司 Blackboard Inc. 收购。
通过运营 MyDropBox，三位创始人深入了解了教育科技市场，同时掌握了处理和分析大量文本数据的技术。创始人们注意到一个重要现象：许多学生不仅面临抄袭的问题，更普遍的是写作质量的问题。他们意识到:

- 大多数学生和专业人士都在努力提高自己的写作水平
- 现有的写作辅助工具主要集中在拼写和基本语法检查上
- 市场上缺乏一个全面的、智能的写作助手

这些洞察促使他们构想了一个更先进的写作辅助工具，一个不仅能检查语法和拼写，还能提供上下文相关建议、改善表达方式的 AI 助手。
2009 年，怀着这个雄心勃勃的愿景，三位创始人决定创立 Grammarly。他们的目标是创造一个工具，能够帮助人们在任何写作场景中都能自信地表达自己的想法。

生于曲线左侧
Grammarly 最初的愿景是创造一个全面的写作辅助工具，远超传统的拼写检查器。创始人们设想了一个能够理解语境、提供个性化建议的智能助手。基于他们在 MyDropBox 的经验,他们将初始目标市场定位在学生、学术研究和教育领域。
他们决定基于自然语言处理 (NLP) 技术来打造 Grammarly。
不得不说，这是一个颇为冒险的决定。在 Grammarly 创立之时，自然语言处理 (NLP) 技术正处于一个关键的转折点：从依赖于人工编写的语言规则逐渐转向基于统计的机器学习方法。前者适用于简单的拼写检查这样的基础任务，但难以实现 Grammarly 的智能助手愿景。后者则以 BERT 和后来的 GPT 等 Transformers 模型为代表，从大量文本数据中学习模式，提高了系统的灵活性和准确性。同时，NLP 研究者们逐渐认识到，大规模高质量语料库对提升模型性能至关重要。


### 130

方军 2024-08-29


宝玉这个类比相当有意思：8岁女孩45分钟构建聊天网页的新闻，本质就像4岁孩子做10+乐高，真的能做出来，但如果在遇到障碍时没有懂行的家长移除障碍，应该也是搞不定的

这是为什么我一方面很爱 AI 辅助编程，但另一方面又对大众媒体的狂欢略感尴尬的原因。

宝玉：

我家孩子沉迷搭乐高，陪他搭乐高的时候，我就联想起 AI 写程序！

他今年 4 岁，但已经不满足于搭4-5岁的乐高，而是要 9-10 岁的乐高，这条“祥龙纳福”就是他自己照着说明书拼的。

看起来很天才？其实不过就像现在的 AI 会写程序了一样！

因为让他独立去搭，是不可能搭出来的，虽然他照着说明书大多数时候能得到正确的结果，但也经常会拼错，而拼错了就无法继续了，就需要我帮他去修复错误，然后他才能继续，有时候甚至要拆到大部分重新开始。虽然我一直提醒他每个步骤完成了要去对照说明书检查，但对他来说还是太难，无法在出错后发现明显的错误。

这就像现在 AI 写程序，无论你怎么去从工程上优化流程，它只有一个像 4 岁孩子的智商，是无法独立去搭出来需要 9-10 岁年龄的乐高，而需要大人（专业人士）去引导，在出现问题后帮助修复、排除障碍。就算通过提示工程让 AI 在写完后自己检查，但以当前 AI 的能力很多错误还是无法检测和修复。

但是，这不能说明 AI 写程序这事不靠谱。就像孩子会长大，今年4岁，可能再过2-3年，长到6-7岁，平时练习一下，就能独立完成 9-10 岁的乐高玩具了。 AI 的进化速度也许比我们想象的更快。

另外这个乐高本来我要花 2 小时时间去搭的，现在只要偶尔抽点时间帮指点一下，加起来也就是半小时时间，还是帮我节约了很多时间。

要让 AI 能写好程序，就像让 4 岁孩子去搭 10 岁孩子的乐高，至少用 AI 的人得有搭 10 岁乐高的水平。

[(17) X 上的 宝玉：“我家孩子沉迷搭乐高，陪他搭乐高的时候，我就联想起 AI 写程序！ 他今年 4 岁，但已经不满足于搭4-5岁的乐高，而是要 9-10 岁的乐高，这条“祥龙纳福”就是他自己照着说明书拼的。 看起来很天才？其实不过就像现在的 AI 会写程序了一样！ https://t.co/xsaBcAEGcC” / X](https://x.com/dotey/status/1769569712357126369)


### 131

方军 2024-08-29


Anthropic 主动公布了 Claude 的所有系统提示语（system prompt），并承诺将定期更新

通常情况下，AI 公司会保密这些系统提示语，但 Anthropic 罕见地选择主动公开，展示了 Claude 的系统提示如何塑造模型的行为和性格特征。它称将不定期的公开模型的系统提示词，包括 Claude 3 Opus、Claude 3.5 Sonnet 和 Claude 3 Haiku。

原文：System Prompts - Anthropic

翻译（小互）：Anthropic 罕见的主动公布了 Claude 的系统提示词 并承诺将定期更新 – XiaoHu...

[System Prompts - Anthropic](https://docs.anthropic.com/en/release-notes/system-prompts)

[Anthropic 罕见的主动公布了 Claude 的系统提示词 并承诺将定期更新 – XiaoHu.AI学院](https://xiaohu.ai/p/12925)

### 132

方军 2024-08-29

128 如何用 AI 辅助更快阅读：一个示例

刚刚看到《地位即服务——重新审视社交网络》（Eugene Wei， 2019），它翻译版全文近两万字。即便对我这样对于社交网络有一定认识的人，消化吸收还是相当困难的。我因此想到一个问题：

对于一篇必须全盘理解的长文，在有 AI 作为辅助的情况下，如何快速地完成这一阅读任务？

对于这种长文或者有的情况下是论文，其实讨巧的办法并不多，要吃透必须得花笨功夫。通常的做法有：

- 电子版阅读两遍以上
- 打印版阅读及标注
- 电子版拆解，变成可理解的块状
- 对其中不理解的查询资料，并解读
- 若需要，听 TTS 朗读一遍
- 若需要，自己朗读一遍
- 若需要，用类似 PPT 格式进行整理

在理解之后，用自己的话进行重新讲解。

有了 AI 之后，哪些环节可以被加速呢？我觉得 AI 至少可以在整体把握上给不少帮助。

📍找到骨架

在《如何阅读一本书》里「透视一本书」的建议，它用的比喻是 X-ray，像照 X 光一样看清一头牛的骨架。

对于一篇长文，如果采用 Markdown 格式，我们很容易获得它的目录，如图一（软件本身）、图二（Cluade抽取）。

现在有了 AI 之后，我们可以较为方便地获得层级式大纲，如图三（Cluade）、图四（元宝），这能够让我们更好地把握其骨架。

📍找到主要观点

我们也可以用一些提示语技巧先试图获得一些主要观点：

请返回您反复阅读正文后精心写成的详尽笔记进行结构化回答，用列表出3-5个核心要点
每个要点由一个主要论点和2-3个支撑性论据组成

结果如图五所示。

我们可以可以用《学会提问》中提到的批判性思维系列技巧。比如，对每个观点，澄清观点是什么？事实是什么？推理过程是什么？有没有漏洞？有没有反向观点？

这篇文章我尚未仔细读完，当然我大概看了到现在，觉得它可能被很大程度上高估了吧，也许它的核心观点就是它的标题（这是一个有意思的双关语）：

社交网络的本质是"地位即服务"(Status as a Service, StaaS)模式

这个观点部分与我的认识一致，普通人用社交网络，就是为了在另一个空间参与地位竞争。但不同的是，1）我觉得网红、直播不适用于此分析，他们最终走向了商业变现；2）平台也不适用于此分析，平台对用户提供的是连接，对自己、品牌和网红提供的商业变现。

该文的翻译版链接：地位即服务——重新审视社交网络|界面新闻

原文：Status as a Service (StaaS) — Remains of the Day

AI抽取的层级式大纲：

以下是从文章中抽取的层级式要点大纲：

附录：

1. 社交网络的本质

- 人类本质上是追求社交地位的动物
- 社交网络利用了人类对社交资本的渴求
- 社交网络可视为"地位即服务"(StaaS)模式
- 社交资本难以量化，但对用户行为有重大影响

2. 分析框架

- 工具性和社交资本是两个主要维度
- 部分网络还包括娱乐性维度
- 不同社交网络在这些维度上有不同定位

3. 社交资本的特性

- 难以精确衡量，但可以通过间接方式观察
- 与金融资本可互相转化(如网红经济)
- 具有不稳定性，容易贬值(如平台衰落)
- 年轻人更容易积累社交资本

4. 社交网络的成功要素

- 独特的"工作量证明"机制(如Instagram的滤镜)
- 有效的社交资本积累和存储机制(如粉丝数、点赞)
- 在工具性和社交资本之间找到平衡
- 持续创新，延长地位游戏的半衰期

5. 常见的社交网络发展曲线

- 先工具，后社交(如Instagram)
- 先社交，后工具(如Foursquare)
- 纯工具，不社交(如Skype)
- 纯社交，不工具(某种程度上的Facebook)

6. 社交网络面临的挑战

- 社交资本贬值风险(如用户流失)
- 用户群体变化(如年轻人转向新平台)
- 竞争对手的模仿和创新
- 负面社会影响的管理(如隐私问题)

7. 科技巨头在社交领域的表现

- Facebook: 社交资本积累的典范，但面临工具性不足的问题
- Google/Apple: 在社交功能上相对薄弱
- 亚马逊/Netflix: 有尝试但未成功
- 微信: 在工具性和社交资本上都做得很好

8. 社交资本的应用

- 社交资本套利(如跨平台内容搬运)
- 作为激励机制(如Yelp Elite)
- 名人效应在社交网络中的局限性

9. 未来展望

- "地位即服务"第一个黄金时代可能结束
- 社交网络需要更负责任地管理用户的社交资本需求
- 可能出现新型社交网络模式

10. 关键洞察

- 社交网络的核心在于满足人类对社交地位的需求
- 成功的社交网络需要在多个维度上取得平衡
- 理解和管理社交资本对社交网络的长期发展至关重要
- 社交网络公司需要更好地认识到它们对社会的影响和责任
收起


查看详情
L.Path 觉得很赞
方军：这篇讨论重点是「骨架」，以我个人的体会看，其实看一个长资料的时候，还有一个方式是「删减」，拿到电子版先删除一通，留下自己想要看的部分。
2024-08-29 20:09


[地位即服务——重新审视社交网络|界面新闻](https://www.jiemian.com/article/2964978.html)

[Status as a Service (StaaS) — Remains of the Day](https://www.eugenewei.com/blog/2019/2/19/status-as-a-service)

### 133

方军 2024-08-29

每次试图深度阅读一个资料的时候，都会叹息英文的翻译问题，这其实已经翻译不错了，但远没有原文好懂：

Robert DeNiro在《盗火线》中的经典台词：曾有人告诉我，别对任何人或物过于迷恋，当危险已近身边，不应该有任何你不能在三十秒内放弃的东西。

“Don't let yourself get attached to any social capital you are not willing to walk out on in 30 seconds flat if you feel the heat around the corner.”

1. Don't let yourself 

2. get attached to - 依恋、迷恋

3. any social capital - 任何社交资本
   - "social capital" 是一个社会学术语，指人际关系网络中的资源和价值

4. you are not willing to - 你不愿意

5. walk out on - 放弃、抛弃

6. in 30 seconds flat - 在短短30秒内
   - "flat" 在这里强调时间的短暂，表示"恰好"或"整整"

7. if you feel the heat around the corner - 如果你感觉到危险即将来临
   - "feel the heat" 是一个俚语，表示感受到压力或危险
   - "around the corner" 字面意思是拐角处，这里比喻即将来临




### 134

方军 2024-08-30


说点没法公开说，也没法直白说的，事实与表征

事实如此
一个人的表达和一个人的事实，之间往往存在巨大的不同
一个公司的表达和一个公司的事实，之间也往往存在巨大的不同
一个行业的表达和一个行业的事实，之间也往往存在巨大的不同

外部人、内部人看到的完全不一样。比方说，PR 说的，媒体上看到的，和企业内部看到，有很大的不同。

但是，如果把赤裸裸的现实摆到很多人面前，几乎绝大多数人都接受不了，拒绝接受，甚至愤怒

我一直不知道怎么在不激怒人的情况下讲这些，真是不知道，所以其实看似絮絮叨叨，但我是不会和一个事非直接相关者说这一话题的

以前看《中介化》（mediated），最近又看，还是看不太懂，但这几天随便翻，或许它选择的超现实主义的表达是有意思，现实（真正感受到的）和表示（媒介上感受到的），是有着巨大的差别。也许是过去时间太久，他讲 911，我们看着都还挺平静的。但我能感受到那种技巧，巧妙地把事实揭示出来了，而又没有激怒人。

当然，要注意的是，与这个相比还有一个反面，就是故意用刺激性的词，激发情绪，但实际上他们并没有真知灼见，比如我这几年看到的这些词：下等人，韭菜，乡下人，SB，小镇做题家，文科生，资本家等等。绝大多数情况下，用这些词的人不是为了把他的观点凸显出来，仅仅是为了激怒，并收获流量。

又如，有人说，世界就是一个赌场（甚至是盘子），我想说的是，这个某种程度上是现实，当你身处拉斯维加斯或者澳门时，这就是事实。但是，如果你扩大，来到纽约（作为经济中心）、来到华尔街（作为金融机构的聚集地），你说这也是一个赌场。那很显然你这仅仅是一种激发情绪的修辞。但另一方面，如果只讲股东价值最大化，或者只讲量化交易，那很显然，这与现实的差距也很远。有本量化金融的书叫，教鸟儿飞行。

最后还是要跟 AI 关联一下，怎么把观点包裹起来，或者反向把观点拆出来，AI 在这方面能力很强。毕竟，它是语言大师。
收起

查看详情
阳志平、vincent 觉得很赞
方军：很多话没法直白说的

比方说，一本书我觉得不好，我肯定不能直白说，一是万一我错了呢（当然自信这种情况不太多，我没有那种看不懂就骂人的愤怒），二是何必批人家

但是，如果一个朋友来问，具体某一本书好不好，这本书是垃圾，选另外一本吧，那我是肯定直说的

情况就是这样的
2024-08-30 12:41
方军：我还认识一个人，他的套路就是把人分类，比方说（为避嫌换个行业职位打比方），你都是互联网公司的程序员，他给你分成，你是低等的，就该拿1万工资，他2万，他100万，他当然把自己放在100万。然后各种明里暗里批别人下等人。
2024-08-31 19:45
回复


### 135

方军 2024-08-30


Deepfake真心严重问题啊


[Deepfake重创韩国，N号房事件重演，波及超300所学校](https://mp.weixin.qq.com/s/-EC3VFb8CsQiGrNmFzpgPw)

### 136

方军 2024-08-30

29日下午，当事网友孙女士告诉记者，2019年5月，她花费近1400元从某网购平台买了这块手表。前两天，孩子打开小天才儿童电话手表的某软件提问“中国人诚实吗？”，得到了上述让人不适的回答。她感觉很震惊，拿锤子怒砸手表，当天就投诉了小天才，将视频发给了小天才官网，第二天发现答案已经更改，回答较为正常。

小天才回应，回答是第三方软件小度app的回答，已下架



### 137

方军 2024-08-31

提出智慧问题的艺术

来自哈佛商业评论，探讨了提出智慧问题的艺术，以及它对战略决策制定的重要性。 

原文地址：

[The Art of Asking Smarter Questions](https://hbr.org/2024/05/the-art-of-asking-smarter-questions)

智慧提问，同样也是使用 LLM 的诀窍所在，咱们一起看看这 5 种智慧问题对企业商业战略和对 LLM 的价值 

01 - 调查性问题 (Investigative):
目的: 深入了解已知信息
例如: "为什么?"、"怎么样?"
作用：帮助澄清目标，深入挖掘非显而易见的信息

对 LLM 的应用:
- 帮助我们更好地了解 LLM 的知识范围和局限性。
- 可以通过连续的 "为什么" 和 "怎么样" 来深入探索 LLM 对特定主题的理解程度。
- 有助于验证 LLM 提供的信息的准确性和来源。
- 例子: "你能详细解释一下量子计算的基本原理吗? 为什么它比经典计算更有优势?"

02 - 推测性问题 (Speculative):
目的: 拓宽思考范围，探索创新解决方案
例如: "如果...会怎样?"、"还有什么可能性?"
作用: 帮助重新框定问题，突破限制性假设

对 LLM 的应用:
- 激发 LLM 的创造性和想象力，产生新颖的想法和解决方案。
- 探索 LLM 在假设情景下的推理能力。
- 帮助我们突破常规思维，考虑新的可能性。
- 例子: "如果我们能够完全控制地球的气候，会对生态系统产生什么影响?"

03 - 生产性问题 (Productive):
目的: 评估资源可用性和执行能力
例如: "我们如何完成这个?"、"如何衡量进展?"
作用: 帮助识别关键指标、里程碑和潜在瓶颈

对 LLM 的应用:
- 帮助规划和组织使用 LLM 完成复杂任务的步骤。
- 评估 LLM 在特定任务上的能力和局限性。
- 优化 LLM 的输出，使其更加实用和可执行。
- 例子: "我们如何利用你的能力来优化一个大型软件项目的开发流程? 需要考虑哪些关键步骤?"

04 - 解释性问题 (Interpretive):
目的: 综合信息,提取意义
例如: "从这里我们学到了什么?"、"这意味着什么?"
作用: 帮助将信息转化为可行的洞察

对 LLM 的应用:
- 帮助我们理解和解释 LLM 的输出，特别是复杂或抽象的概念。
- 将 LLM 的回答与更广泛的上下文联系起来。
- 提炼 LLM 提供的信息，得出有意义的见解。
- 例子: "基于你刚才对全球经济趋势的分析，这对新兴市场的中小企业意味着什么?"

05 - 主观性问题 (Subjective):
目的: 探讨个人保留意见、挫折、紧张关系和隐藏议程
例如: "你对这个决定的真实感受是什么?"
作用: 帮助解决可能使决策偏离轨道的人际问题

对 LLM 的应用:
- 探索 LLM 在处理主观和情感相关问题时的能力。
- 帮助我们理解 LLM 对伦理和价值观问题的 "看法"。
- 提醒我们 LLM 的局限性，尤其是在需要人类判断和情感智慧的领域。
- 例子: "从道德角度来看，在医疗资源有限的情况下，如何公平地分配这些资源?"