### 01

方军 2024-08-01

宝玉的翻译提示词更新版：

翻译 GPT 的提示词更新和优化

提示语见链接：

[翻译 GPT 的提示词更新和优化 | 宝玉的分享](https://baoyu.io/blog/prompt-engineering/translator-gpt-prompt-v2-1-improvement)

他的说明很清晰：

\## 主要优化

所以最近我对旧版本的 Prompt 做了一些优化，主要的优化如下：

1、使用英文提示词。

相对来说，GPT 对英文提示词会遵循的更好，使用英文提示词可以让 GPT 更好的理解和跟随指令。

2、将重要的内容放在开头和结尾。

很多论文的研究都证明了提示词中开头和结尾部分的效果是最好的。而对于我的翻译 GPT 来说，复杂的有两部分，一部分是要根据不同的输入情况进行不同的处理，比如 URL、图片、PDF 等；另一个复杂部分是要按照三个不同的步骤翻译。

所以我在开头针对不同的输入情况给出了具体的处理方法，然后在结尾给出了三个步骤的输出格式参考。

3、对于第二步的反思，要求给出具体的建议。

这一步是参考自吴恩达的翻译智能体的 Prompt，从准确性、流畅性、风格和术语等几个方面给出了具体的建议，这样对翻译结果确实有提升。

4、使用 XML 格式输出。

上一个版本的 Prompt 中，我使用的是 Markdown 格式输出，通过大标题分离不同的部分。虽然也可行，但是有一点美中不足： 1). 和要翻译内容中的 Markdown 格式有冲突，比如原本文中有大标题，这样不太容易分辨什么地方开始和结束。 2). 对于是否输出结束并不清晰，比如原文有 4 段，但是只输出了 3 段就终止了，不好判断是否还有内容。

所以新版本中我使用了 XML 格式输出，这样可以更好的和 Markdown 格式区分开来；根据是否有结束标签，可以判断是否还有内容；还有一点是 XML 格式更便于代码解析。

5、支持图片翻译。

现在 GPT-4o 对图片支持很好，可以很好的识别图片中的文字，所以我在新版本的 Prompt 中加入了图片翻译的支持，输入图片或者 PDF 时，可以先进行 OCR，然后再进行翻译。

\## 保持不变的部分)保持不变的部分

1、三步翻译：直译、反思、意译

经过反复测试，虽然继续润色可能会有些许提升，但需要平衡 Token 的长度、时间成本和翻译质量，三步翻译是一个比较好的平衡点。

2、角色设定

虽然最近一些文章表示没有必要设定角色，但是作为一个翻译任务，保持角色设定可以清晰的让 GPT 知道自己的任务，这样可以更好的跟随指令。

3、术语表

使用术语表可以让翻译结果更加统一，可以避免将 Transformer 翻译成「变压器」这样。但限于 GPT 的限制，现在还无法对术语表进行定制，只能是预置一些常见的术语。

2『个人补充：测试下来，感觉还没有老版的效果好，改回老版的了。但借鉴了里面的使用 XML 格式输出。（2024-08-11）』

### 02

方军 2024-08-01

有时候对教育/培训感到无语，看到花很多时间讲：

s[::3]
s[start:stop:step]

讲实话，作为一个 Python 二把刀、但也勉强用了很久、干了很多活的人，我不知道这个方式。

有必要吗？我觉得毫无必要，实践中基本上用不到。用得多数是 s[0:2] 、s[:-2] 类似这种普普通通的用法而已。

如果用到更复杂的，那多半也有一些专门的库或采用其他类型数据去处理，没必要非在s[start:stop:step]上费劲。

现在有了 AI 倒是简单了，看不懂，直接扔给 AI 解释。

这倒是有用，因为如果代码里非有高手用了一些独特的写法，也不用特别查文档了，直接 AI 解释下即可。

### 03

方军 2024-08-02

全球最大的 AI 虚拟人物对话平台  Character.AI 开源了它们的 Prompt Design 项目—— Prompt Poet 

Prompt Poet 通过低代码简化了 Prompt Design 的过程，使开发人员和非技术用户都能轻松上手。Prompt Poet 结合使用 YAML 和 Jinja2，实现了灵活、动态的 Prompt 创建，提高了与 AI 模型交互的效率和质量。它节省了在字符串操作上的工程时间，使每个人都能更专注于为用户制作最佳 Prompt。

Prompt Poet 重要组成 - 提示模板 (Prompt Templates)

Prompt Poet 模板混合使用 YAML 和 Jinja2，模板处理主要分为两个阶段：
-- 渲染：Jinja2 处理输入数据的阶段，执行控制流逻辑，验证数据并适当地绑定到变量，同时评估模板中的函数。

-- 加载：渲染后，输出是一个结构化的 YAML 文件。这个 YAML 结构由重复的块或部分组成，每个部分都被封装成一个 Python 数据结构。

-- 这些部分具有以下几个特征：
--> 名称：一个清晰的、人类可读的部分标识符。
--> 内容：构成提示的实际字符串负载。
--> 角色（可选）：指定参与者的角色，有助于区分不同的用户或系统组件。
--> 截断优先级（可选）：在必要时确定截断的顺序，具有相同优先级的部分按照它们出现的顺序进行截断。

- 设计选择 (Design Choices)

-- Prompt Poet 库和模板语言：
--> Prompt Poet 库提供多种功能，包括分词和截断，以实现高效缓存和低延迟响应。
--> 使用 Jinja2 和 YAML 的组合作为模板语言，提供了强大的表达能力和结构化数据表示。

-- 提示可移植性和函数调用：
--> 模板化设计使得提示可以在不同团队和系统间轻松共享。
--> 支持在模板中直接调用 Python 函数，便于即时数据处理和验证。

-- 自定义编码和截断策略：
--> 允许用户自定义令牌编码函数。
--> 提供了高度优化的截断算法，旨在最大化前缀缓存率。

-- 缓存感知截断：
--> 采用固定截断点策略，平均每 k 个回合才移动一次截断点。
--> 这种方法能够显著提高 GPU 前缀缓存的利用率，达到 95% 的缓存率。

-- 朴素截断 vs 缓存感知截断：
--> 朴素截断每回合都移动截断点，导致缓存利用率低。
--> 缓存感知截断保持固定截断点，允许重用之前的计算结果，大幅提高效率。

[x.com/shao\_\_meng/status/1819165042035790190](https://x.com/shao__meng/status/1819165042035790190)

[Prompt Design at Character.AI](https://research.character.ai/prompt-design-at-character-ai/)

### 04

方军 2024-08-02

Poetry： Python 依赖包/虚拟环境管理工具

在 Cluade 的辅助下（摘选并加说明），写一个简单的使用指引：

[体会：1）有了 AI，学习效率比看官方文档高，可靠性在这些问题上还行。2）有了 AI，要按自己的需求组织一个文档出来，与看官方文档、翻译、运行记录比，这样做效率高]

\## 快速启动

1. 安装
```
pip install poetry
```
不加配置的情况，缺省选择集中管理的虚拟环境。

2. 创建项目
```
mkdir my_project
cd my_project
poetry init
```
3. 添加依赖库/包
```
poetry add package_name
```
查看：
```
poetry show package_name
```
4. 激活虚拟环境:
```
poetry shell
```
5. 运行 Python 脚本
```
python your_script.py
```
6. 退出虚拟环境
```
exit
```
7. 查看虚拟环境信息:
```
poetry env info
```
8. 列出所有虚拟环境
```
poetry env list
```
9. 删除特定虚拟环境
```
poetry env remove python3.12
```
10. 更新依赖
```
poetry update
```
11. 在不激活虚拟环境的情况下运行脚本
```
poetry run python your_script.py
```

\## 解释

在启动项目并安装之后，目录中会有：
```
tree
.
├── poetry.lock
└── pyproject.toml
```

集中管理的环境安装在：
```
 ~/Library/Caches/pypoetry/virtualenvs/
```

```
ls  ~/Library/Caches/pypoetry/virtualenvs/
poet-7QpPCq2B-py3.12
```

移除
```
poetry env remove python3.12
Deleted virtualenv: ~/Library/Caches/pypoetry/virtualenvs/poet-7QpPCq2B-py3.12
```

\## 特别设置

我们也可以选择将环境安装在项目目录，那么要做如下设置：
```
poetry config virtualenvs.in-project true
```

### 05

方军 2024-08-02

针对此前被唱片公司和唱片协会起诉，Suno 今天回复了美国唱片协会，称神经网络就像孩子一样学习，学习不构成侵权。

部分内容：

首先，各大唱片公司显然对我们的技术工作原理存在误解。Suno帮助人们创作音乐的过程与人类一直沿用的过程类似：通过学习风格、模式和形式（实质上就是音乐的 "语法"），然后围绕它们创作出新的音乐。各大唱片公司试图辩称神经网络只是鹦鹉学舌--复制和重复--而实际上，模型训练更像是一个孩子通过虔诚地聆听摇滚乐来学习创作新的摇滚歌曲。就像那个孩子一样，我们的人工智能越学越好。

我们在开放互联网上找到的中高品质音乐中训练我们的模型--就像谷歌的双子座、微软的 Copilot、Anthropic 的 Claude、OpenAI 的 ChatGPT，甚至苹果的新 Apple Intelligence 在开放互联网上训练它们的模型一样。

开放的互联网上确实有许多受版权保护的资料，其中一些还为大型唱片公司所有。但是，就像孩子们在听完摇滚乐后自己创作歌曲一样，或者就像教师或记者在查阅现有资料后得出新的见解一样，学习并不构成侵权。过去不是，现在也不是。

这起诉讼的时机有些出人意料。事实上，当这起诉讼发生时，Suno 正在与 RIAA （美国唱片协会）的一些主要唱片公司成员进行富有成效的讨论，以寻求共同扩大音乐蛋糕的方法。我们这样做并不是因为我们不得不这样做，而是因为我们相信音乐产业可以帮助我们为每个人带来更多的机会，而不是抵制它。无论这场诉讼是律师们过于焦虑的结果，还是我们有意识地在商业讨论中获取筹码的策略，我们都认为这场诉讼是对音乐更大、更有价值的未来的不必要阻碍。

[The Future of Music – Suno](https://suno.com/blog/future-of-music)

### 06

方军 2024-08-02

114 如何做 AI 工作流：王树义老师的经验

如何用命令行工作流做定制化 AI 文献回顾？  (另一篇参考：如何轻松定制和调用你自己的 AI 工作流？）

[知识星球 | 深度连接铁杆粉丝，运营高品质社群，知识变现的工具](https://wx.zsxq.com/dweb2/index/topic_detail/4844141188882118)

[如何轻松定制和调用你自己的 AI 工作流？](https://articles.zsxq.com/id_kmwc76rvs578.html)

王树义老师这个工作流特别棒。我认为其中的优点有：

- 采用 Fabric 的提示语处理方式（也包括它原有的提示语模板），但不依赖它。
- 采用编程方式，来让 Fabric 的单线管道变成后续步骤可以引用前面多步的输出。
- 采用 YAML 来进行工作流的配置，灵活度非常高。

王老师有个思路我高度赞同，大意：应该把注意力放在流程与提示语，而不是其他，流程与提示语是实际完成任务的部分。

（当然，这个工作流我还只是看了，没有实际运行，之前实际运行过翻译工作流那个，并用 Notebook 形式来调整。）

我知道王老师喜欢命令行形式，不过，如果让我来做自己的工作流，我多半会选用如下方式：

- 配置 - YAML。用 YAML 做配置，这比图形化（coze/dify）要难一些，但更适合有点编程背景的。把配置和程序分开，会让工作流更易用。

- 提示语 - LangSmith，存放在  LangSmith，因为它可以方便的进行评测，可以记录提示语版本（它采用的是类似git形式），还可以记录运行结果（每次模型的输入、输出，这是LangSmith的真正功能）。最近调整工作流时，实际上花的时间在这儿时比较多的，因为要反复调整提示语，以达到想要的效果。

- 编排 - LangChain，相应地，编排我也就会采用 LangChain，它支持的模型是比较丰富的。

- 运行 - Notebook（ipynb） ：在调试时，我会直接使用 Google Colab，使用时，我有时会选择本地。

采用 Notebook 的优点是各种依赖也可以在 Notebook 里面管理了。一个 Notebook  一个工作流，当然有些共同的代码也可以Python脚本（.py) 形式另外保存和调用。

Notebook 当然也有缺点，就是如果大量代码还是放在里面（我们通常的确是这么做），那么，它没有命令行那种看起来封装得好。这对非程序员也不那么友好，比如如果误碰可能会改动代码、导致运行不起来。

当然，这其实正是我选择它的原因。这是因为，我不想它是封装的，而是希望能够看到其中的过程，并可以随时酌情调整。

### 07

方军 2024-08-02

最近在想，李笑来的《自学是一门手艺》（实际上是一个 Python 自学手册），如果出现在 AI 时代，会如何？

他当时的优点是：

1. 讲自学，同时有一个场景（Python学习）
2. 他讲得较为缓慢与详尽，适合仅看书自学
3. 他采用 ipynb 的笔记本格式写作（实验代码可方便地运行）

当时的缺点是：

1. 有些详尽是不必要的，应该让学习者自己实践/探索
2. 要看还是很难的，很多普通人看不下那么多字
3. 整体结构上，略显不足，这可能是他当时很大程度也是一个初学者，记录学习经验有关

现在的变化是：

1. 很多解释可以由 AI 来替代（也就是可运行之外，完全可以是 AI 互动解释）

2. 优化结构，我个人认为，用AI最需要的首先是自己手上的结构（通俗说就是一个大纲）

除了这本书之外，之前看到一本日本书不错，当时还专门买了一本回来。它也有中文版了《Python超入门》，它的优点是：

1. 用图解标注形式来对代码/运行结果进行解释，对普通人比较友好（当然程序员会认为代码加注释就够了）
2. 结构比《自学》要清晰，这是很多日本书的特点
3. 整体内容上要简单（或者说单一）。这也是日本书的特点，它不会试图宏大面面俱到，而是切一个横切面。

缺点是有很多不必要的截图，比如我就不明白为什么那么详细地截图介绍 Python下载和 anaconda 下载。也许对普通人这是一个门槛，但我认为应该放在附录。

### 08

方军 2024-08-03

空谷：不知道你们现在是否存在这样一个痛点，在用三方的 AI API 服务商时，不确定是否是 OpenAI API 官方正版转发，还是 ChatGPT 逆向？
最近我发现了一个参数，可以完美完成验证，帮你区分出是否是正版官转。而它，就是 seed 参数。

（先说下ChatGPT 逆向服务的问题。 如果是 ChatGPT 逆向的服务，不但指令跟随上不如 API 自由，而且不支持 Tools Calling（即没法使用插件），服务也不稳定。

还有很重要的一点，ChatGPT 逆向的方案，你的会话数据会被 OpenAI 官方拿去训练模型。而如果是走 API 调用，说是不会拿去训练的。  

为啥这么多问题，号商还是会有 ChatGPT 逆向的 API 出来？原因就是逆向来的 ChatGPT API 是免费的。所以他们的很多价格最低能达到官方原价的 0.几折。而如果是 API 官方转发，做到五六折几乎已经是极限价格了。）

那怎么判断是官方转发还是 ChatGPT 逆向？很简单，你的请求参数中多加一个 "seed": 1 （数值随便设，需要是整数）即可。

如果常用 AI 生图的小伙伴应该对 seed 这个概念不陌生。但是在 LLM 里， Seed 参数似乎应该还是一个非常冷门参数，它核心作用就是控制在一模一样的入参情况下，可以保证模型的输出也是一样的。官方文档地址：https://platform.openai.com/docs/api-reference/cha...…

所以它在验证真伪性的这个场景上，作用非常大。

因为 ChatGPT 逆向的接口是没有这个参数的，所以如果你让ai生成一个10个字的笑话，返回的内容应该是每次都不一样。而加上 seed=1 后，你无论请求多少次，它的返回结果会始终稳定一致。因此这是一个绝佳的测试方法。

直接贴一个测试的 curl，大家可以换上自己的 apikey 快速测测看：

curl -X --request POST 'https://api.openai.com/v1/chat/completions…' \
-H 'Content-Type: application/json' \
-H 'Authorization: Bearer <your-api-key>' \
--d '{
"messages": [
{
"role": "user",
"content": "写一个10个字的笑话"
}
],
"seed": 1,
"model": "gpt-4o-mini"
}'

结果应该稳定是 「为什么鱼不说话？因为它们水里！」

[API Reference - OpenAI API](https://platform.openai.com/docs/api-reference/chat/create#chat-create-seed)

[(13) X 上的 空谷 · Arvin Xu：“不知道你们现在是否存在这样一个痛点，在用三方的 AI API 服务商时，不确定是否是 OpenAI API 官方正版转发，还是 ChatGPT 逆向？ 最近我发现了一个参数，可以完美完成验证，帮你区分出是否是正版官转。而它，就是 seed 参数。 https://t.co/Pe4e0lKErZ” / X](https://x.com/arvin17x/status/1819346887851626969)

### 09

方军 2024-08-03

LangChain 出了个 Agent IDE

LangGraph Studio 

[LangGraph Studio: The first agent IDE](https://blog.langchain.dev/langgraph-studio-the-first-agent-ide/)

我一直都没开始用起来 LangGraph，真是时时感到落后了。——Workflow 已经在拼命赶了，这个倒是一直有实在的感觉的。Agent 从最开始 AutoGPT ，我就看不懂。

---

- Langchain 的 Agent IDE 设计理念与 Dify 和 Coze 等低代码可视化工具不同，它采用了编程式路线，同时融入了可视化调试元素。

- LLM 应用开发的特点是迭代式，需要不断与 LLM 交互并根据反馈优化应用，LangGraphStudio 的设计支持这一开发模式。

---

看到一个中文介绍文章：

[Langchain发布官方Agent IDE，不同于Dify/Coze的设计理念，能否获得开发者认可？](https://mp.weixin.qq.com/s/PNoi_QzKxtJZJUVrpV7P5w)

### 10

方军 2024-08-04

115 人能轻松地识别机器生成

这句话目前还是有很多人不理解，其实很简单的，目前机器生产的东西，有着一种说不出来、技术上也测不出来，但人能够一下子感受到的味道。

永远不要用 AI 去生成，真的，把这波 AI 浪潮叫 AIGC，真的很有误导性。叫生成式 AI，说明它仅仅是中间过程，略微减弱一点负面影响。

说两个个人体会：

一个是，看多了网上的文字（是流水线式生成、以及部分 AI 生成），然后去书店，看到文学区（比如PageOne 的文学区）或者各种学者长期写出来的（比如在万圣），明显是不一样的。

另一个是，听了一段 AI 生成的语音，再回头一听人讲话的语音，真是不一样啊。当然，我听的不是那种工业化生产的，是蒋勋那种讲话本来就很有魅力的。

各种搞 AI 的人，如果不能理解，会自找很多麻烦：虽然你们比普通人厉害很多，但是，任何最普通的普通人都可以一下子识别出来什么不是自然的，最多只要稍稍提示下：你觉得你听的是自然的吗？

### 11

方军 2024-08-04

116 选择 AI 工具的「单核方法论」

我一直自己有选择工具的需求，也会经常帮人选择方法，因此，我自己逐渐地形成了一种方法论，这就叫它「单核方法论」吧。它的用途是，用来帮你选择和使用那些要反复使用的某种方法。

现在，突然一下子冒了很多使用 AI 的方法，比如我就一直反反复复重复 ICDO 这个提示语模板。面对这些不断出现的方法，我们就需要用到「单核方法论」，用它来帮我们筛选。

⛳️ 单核方法论——选择方法的方法

在选择方法之前，首先要确定：

> 我要解决的一个问题是什么？

之后，我们有三个阶段：

第一阶段：选择

1. 这个方法效果如何？或者更直接地问：它有可能解决我的某一个问题吗？

2. 先看看这个方法的讲解，它是逻辑上行得通的吗？

如果以上两个答案都是“YES”，那么，我们就进到下一阶段。

第二阶段：尝试

1. 按照方法的讲解，按它附带的使用案例，看看这个方法是不是有效？自己能不能用起来？

2. 如果上一步尝试有效，那么，面对自己的实际问题，至少尝试使用 7 次。

然后，做出判断：这个方法能不能解决自己的问题、这个方法是否适合自己？

第三阶段：使用

1. 将这个方法变成一系列步骤，也就是你自己的 SOP，然后长期使用，至少使用 100 次以上。持续地关注：这能解决我的问题吗？

2. 在使用过程中，不断地优化与迭代这个 SOP，让它的效果变得越来越好。特别地，要注意对这个方法进行简化，即，不是让它变得越来越复杂，而是削减不必要的步骤。

当然在这同时，我们还是持续关注有没有更好的方法。如果发现了，那么，重复之前第一、第二阶段的做法，替换到更好的方法。

以上「单核方法论」所适用的场景，是选择与使用那些使用很多遍的方法。

(如你所见，以上这几个步骤， 也是我自己非常多次使用的一个方法。）

以上这「单核方法论」背后有一个基本的认识，也就是，在我们日常工作生活中真正解决问题的方法，往往都是反复使用的，就跟每天要早晚刷牙一样可能运用非常多次。

最近一直在看 AI 工作流，我觉得，与单核方法对应的是工作流，工作流往往是非常个性化的，别人的工作流、个人体验不一定适合我们。因此，工作流多半只是参照案例，而不能直接拿来反复多次运用。
收起

查看详情
乘风、Koant、Jese__Ki 觉得很赞
方军：有时候也反思，我是不是会一个方法自己简单尝试下，就开始热情地推销给别人。还好，极其偶尔有，绝对很少。
2024-08-04 16:34
方军：再补：我在工具上是很愿意花钱的，比如前天朋友问题某件事有没有好工具，我当时给他展示了我用的，以及几个我知道的，比较一下。发现我用的那个实际效果不行之后，我立刻订阅了当时试用觉得可行的，30美元，但我觉得是值得的。
2024-08-04 16:36
方军：这一年多在工具选择上，我受到一个重大的新影响是王树义老师等反复提及的“重器轻用”，我理解，也就是别太关注一个工具是不是很复杂，用最牛的工具，然后用它最适合我们的那个点就可以了。（这就消除了它很难用的「复杂」难点。）
2024-08-04 16:40

### 12

方军 2024-08-04

用AI生成垃圾的情况还是发生了

某：我用AI写的这篇快40万阅读了，全文一个字没改，标题是我自己写的。ChatGPT现在写文章还可以，不过标题不太行。

[大离谱！中国人居然对中国冠军竖中指+爆粗口，丢人丢到国外](https://mp.weixin.qq.com/s/kWNOB-0oHVo_yk4XLvEOgA)

### 13

方军 2024-08-04

可以看出，Llamaindex在应对复杂的LLM应用时，采用了与Langchain相似的策略，即高代码+可视化辅助调试的思路。

[Llamaindex推出workflow应对复杂LLM应用构建，以及技术实现从图（Graph）转向事件驱动（EDA）原因解析](https://mp.weixin.qq.com/s/wOn69g9hEI3sapuyuZRfXA)

### 14

方军 2024-08-04

摘：今天看到一篇文章，说 ChatGPT 就是新的 Excel，说的挺有道理的。Excel 最初是为从事金融和会计工作的商业用户设计的，它上手容易，并且功能强大，可以应用于各种通用任务。并且还可以成为创业想法的来源。只要找到一个在 Excel 中手动操作流程的客户，然后为他们构建一个专门的 SaaS 应用，就可能卖钱。

现在的 ChatGPT 就像 Excel，普通人已经慢慢熟悉了如何使用，根据不同的任务去撰写相关的提示词，但是当简单的提示词满足不了需要，当你要基于 ChatGPT 去创建适合其特定领域的工作流程，就可能需要专门的应用程序或者服务，这其中也可能就会诞生出创业赚钱的机会。

以下内容为原文摘录翻译：
***

过去几十年里，最具代表性的计算机软件产品是电子表格。在 Excel 之前，有一个名为 VisiCalc 的电子表格软件，通常被认为是计算机的第一个杀手级应用程序。它改变了专业人士的工作方式，变得如此重要，以至于人们购买计算机只是为了使用它。在 1980 年代，公司们为争夺电子表格的主导地位展开了全面的竞争。像 IBM 的 Lotus-1-2-3 这样的竞争者逐渐占据了一席之地，而在 1985 年，当微软发布 Excel 时，VisiCalc 遭遇了激烈的竞争。随着 1990 年代 Windows 3.0 的发布，Excel 成为了主导的电子表格程序。从那以后，情况就没有改变。

Excel 是一款很好的产品，因为初学者可以很容易上手：只需在单元格中开始输入即可。但它成为一款伟大的产品，是因为它也非常强大：专家用户可以进行从复杂的财务建模到数据分析和可视化再到构建视频游戏的一切操作。

Excel 最初是为从事金融和会计工作的商业用户设计的，但其多功能性使其成为一种无所不在的通用工具。它也成为了创业想法的来源。只需找到一个在 Excel 中手动操作流程的客户，然后为他们构建一个专门的 SaaS 应用。

Stripe 的 Patrick McKenzie 最好地总结了 Excel 的可生成性，他写道：“我最喜欢的软件需求未被满足的症状是任何一个 Excel 电子表格，如果它曾经由一个员工更新，发送给另一个员工更新，然后再发送回来。每次发生这种情况，一个 SaaS 天使就会长出翅膀。”

风投家 Tomasz Tunguz 最早观察到，在过去的 15 年里，Excel 被分解成了许多其他应用程序，如 Asana、Looker 和 QuickBooks。但这种分解只有在 Excel 足够普及，让用户知道他们想要一个专门设计的替代品之后才有可能发生。为了实现这一目标，Excel 需要广泛的采用，并有高级用户开始将其用于它最初并未设计支持的特殊工作流程。

一旦这些工作流程被创建，高级用户意识到他们的工作流程中有些部分效率低下，或者缺少他们用例所需的功能。他们感到需要专门的工具——这就成为 B2B SaaS 发展成为一个 3270 亿美元市场的机会。

就像 Excel 催生了 B2B SaaS 时代一样，通用聊天机器人应用程序如 ChatGPT、Claude 和 Gemini 将为新一代计算机用户催生一个新的创业时代。AI 聊天机器人拥有与 Excel 相同的易用性和强大功能的结合。它们也正朝着在更短时间内达到同等水平的普及性发展。

今天使用 AI 的人们正逐渐熟悉基于 AI 的软件的基本单元：提示词、上下文窗口、少样本学习和多模态。他们将使用 ChatGPT 或 Claude 创建适合其特定领域的工作流程。在此过程中，他们会对这些工作流程如何变得更好、更简单、更便宜、更快和更安全形成自己的看法。

这就创造了将这些工作流程拆分为独立应用程序的机会。随着大语言模型的采用增加，创业的机会也随之增加。

原始文章：

[The Great AI Unbundling](https://every.to/chain-of-thought/the-great-ai-unbundling)

### 15

方军 2024-08-05

我觉得智能体（特别是这个翻译，而不是agent）会大行其道，因为公众就是特别喜欢这种说不清的名词色

摘：真正要用好 AI，让 AI 发挥最大效能，核心是还是要基于你要解决的问题，重新设计一个适合 AI 的工作流，让 AI 在工作流中完成它最擅长的工作，至于是不是智能体，是不是大语言模型，是不是 AI 帮你决策，都不是最重要的。

后面PDF抽取、漫画翻译例子特别棒

宝玉：你需要的不是智能体，而是一个适合 AI 的工作流

现在 AI 智能体（AI Agent）的概念很火，似乎智能体是用 AI 解决问题的银弹，有了智能体就可以解决很多问题。但也有很多人有不同意见，认为智能体不过是噱头，并没有看到靠谱的应用场景。

一个被提及很多的是吴恩达老师写的多智能体翻译的例子，简单来说就是用三个智能体：一个直译智能体、一个审查智能体、一个意译润色智能体，确实可以大幅提升翻译质量。但并非一定要三个智能体才能提升翻译质量，我以前也提出过基于 Prompt 的翻译方法，让 LLM 在翻译时，使用直译 + 反思 + 意译三个步骤输出，也可以得到高质量的翻译结果。

本质上，使用大语言模型（LLM）来解决问题，思维链（COT, Chain of Thought）是一种有效提升生成质量的方法，也就是说，之所以翻译质量能提升，不是因为有了智能体，而是因为有了思维链。至于思维链的每个环节是用一个独立的智能体，还是输出的一个步骤，并没有太本质的差别。（参考文章：[什么时候该用多智能体是不是一定要用多智能体？](什么时候该用多智能体是不是一定要用多智能体？ | 宝玉的分享。)）

其实大部分 AI 应用场景都类似：要用 AI 解决问题，核心不在于智能体，而在于设计出一个适合 AI 的工作流。

那么怎么才能设计一个适合 AI 的工作流呢？我认为有几个因素需要考虑：

一、不要将 AI 的解决方案局限在人类现有的解决方案上

有时候我们过于将 AI 拟人化，会不自觉的用人类解决问题的方式来套用在 AI 上，有时候确实有效，但很多时候并不一定是最优解。就像专业的翻译员，他们并不需要直译反思意译三个步骤，他们可以一步到位，直接输出高质量的翻译结果，所以最开始让 AI 翻译，Prompt 都是直接一步输出翻译结果，而不是分步骤输出，结果翻译出来的比较生硬。而当我们发现思维链是大语言模型的一种有效提升方法后，就可以设计出更适合 AI 的工作流，分成几步来解决问题。

包括我看到一些智能体项目，尝试模拟人类软件开发的分工，使用项目经理、产品经理、架构师、程序员、测试等等智能体角色去尝试解决复杂的软件项目，同样也是一个过于拟人化而不一定适合 AI 解决问题的思路，所以也只能出现在论文中，而无法在实际项目中落地。相反像 GitHub Copilot 这样辅助生成代码的工具倒是真正适合当前 AI 编程的工作流，能实实在在提升开发效率。

二、不必完全依赖 AI 做决策，而是让 AI 辅助做决策或者做简单的决策

去年有一个超级火爆的项目叫 AutoGPT，就是你输入一个任务，GPT-4 会将任务分解，制定计划，调用外部工具，比如 Google 搜索，甚至执行代码，最终完成任务。这也算是 AI 智能体的先驱项目之一，但现在已经很少有人提及了，因为以现在 AI 的智能程度，还不足以对开放性的任务做出靠谱的决策，最终除了帮 OpenAI 卖了大量的 Token 外，并没有解决什么实际问题。所以现在 AI 应用的主流是把 AI 当“副驾驶（Copilot）”，只是让 AI 辅助人类完成任务，主要还是人在做决策。

另外就是自己设计工作流，让 AI 在工作流中完成一部分工作，并不过于依赖 AI 做决策，或者只需要做简单的决策。比如说商家借助 AI 处理差评的工作流：
1. 程序抓取评论信息
2. AI 分析每一条评论的情感，筛选出差评
3. AI 生成回复（可能需要人工审核）

这是一个典型的设计好流程的适合 AI 的工作流，AI 只需要做简单的情感分析和回复生成，而不需要做复杂的决策，这样的工作流可以很好的提升效率，并且结果也相对靠谱。

三、结合不同领域的 AI 模型或者工具，设计合适的工作流

去年起 AI 大热，一个很重要的原因是大语言模型的出现，这些模型一方面确实能力强大，有一定的通用性，有简单的推理能力，另一方面使用也简单，无论是通过聊天机器人，还是通过 API 调用，都能很方便的使用。即使像我这样不是人工智能专业的人，也能很容易的使用这些模型。而在以前，人工智能相对来说是个高门槛的领域，需要筛选数据、需要训练，还需要调参，对于非专业人士来说是很难使用的。

但这也导致一个问题，就是很多解决方案过于依赖大语言模型，而不知道或者不会使用其他领域的 AI 模型，但当你能够根据任务，将不同领域的 AI 模型或者工具结合起来，设计出合适的工作流，就能够得到更好的解决方案。

四、回归问题本质，AI 只是解决问题的工具

上面提的几点都是容易犯的一些错误，之所以容易犯这些错误，恰恰是因为我们有时候过于关注一些流行的概念或技术，而忽略了要解决的根本问题是什么，将 AI 变成了目的而不是手段。如果你有了解马斯克的第一性原理思维，其强调的就是回归事物最基本的条件，把其解构成各种要素进行分析，从而找到实现目标最优路径的方法。

而运用第一性原理通常有三个步骤：
- 第 1 步：定义清楚你要解决的根本问题。
- 第 2 步：拆解问题。
- 第 3 步：从头开始创建解决方案。

而这也个思路也适用于我们去借助 AI 解决问题，设计出适合 AI 的工作流。

举两个设计合适 AI 工作流解决问题的例子

一个例子是 PDF 转 Markdown

做过 PDF 翻译的有经验，要得到好的翻译结果，将 PDF 的内容整理成 Markdown，再让大语言翻译，效果是相当好的。但这个不好做，因为 PDF 是用来打印的格式，并不是结构化的数据，很难直接提取成 Markdown，再加上各种图表、表格等，更是复杂。

最近看到一个项目叫 [PDFGPT](https://github.com/CosmosShadow/gptpdf
 )，它就做的很巧秒，本质上是基于 GPT-4o 和 PyMuPDF 设计了一个工作流：
1. 用一个 PDF 操作库 PyMuPDF 检测 PDF 中的图片、图表、表格等，提取成图片并保存
2. 每一页 PDF 生成一张图片，将图片、图表、表格等位置用红框标记出来，并附上对应的图片名称
3. 借助 GPT-4o 的视觉能力，解析标注后的图片，生成对应的 Markdown

如果你纯粹依赖大语言模型，恐怕无法完成这样的任务，一方面受限于上下文窗口的长度限制，一次无法处理多页 PDF，另一方面对于图片、图表、表格等内容无法嵌入 Markdown 中。如果结合 PyMuPDF 这样的库和一个简单的工作流，就可以方便的实现 PDF 转 Markdown，生成的结果也挺不错。

另一个例子是漫画的翻译

有很多那种气泡文字的漫画，如果要翻译成其他语言，就需要将气泡文字提取出来，翻译后再放回去。漫画翻译的难点在于：
1. 因为漫画的气泡文字位置不固定，有时候还会有重叠，不好提取；
2. 翻译的时候，如果只是把提取出来的文字按字面翻译，但不知道当前画面的内容，翻译的结果可能会不通顺；
3. 翻译后要对图片进行处理，抹掉原来的文字，将翻译后的文字放回到原来的位置。

如果人工做会怎么做？可能是读懂漫画，翻译，然后用 Photoshop 这个样的工具抹掉原来的文字，再放上翻译后的文字。可以想象这样的工作量还是不小的。

有一个开源项目 [comic-translate]（GitHub - ogkalu2/comic-translate: Desktop app for ...
  )，就做的很好，它也是设计了一个适合漫画翻译的工作流：
1. 用一个专业模型做气泡检测，找出文字气泡的位置
2. 用 OCR 做气泡内文字的提取
3. 用一个专业模型移除气泡内的文字
4. 借助 GPT-4o 的视觉能力，根据漫画内容，翻译气泡内的文字
5. 用程序将翻译后的文字绘制到原来的气泡位置

如果不考虑翻译质量的话，这几乎是一个全自动的工作流，效率相当高，成本也很低，最贵的部分是 GPT-4o 的 API，一页也才$0.02 左右。就算加上人工审核对翻译结果和图片生成结果的处理，也是能比以前的人工翻译效率高很多。

从上面的例子可以看出，真正要用好 AI，让 AI 发挥最大效能，核心是还是要基于你要解决的问题，重新设计一个适合 AI 的工作流，让 AI 在工作流中完成它最擅长的工作，至于是不是智能体，是不是大语言模型，是不是 AI 帮你决策，都不是最重要的。

[你需要的不是智能体，而是一个适合 AI 的工作流 | 宝玉的分享](https://baoyu.io/blog/ai/you-dont-need-agent-but-ai-suitable-workflow)

### 16

方军 2024-08-05

下午突然想：“向 AI 提问” 是不是与更好的说法？

一年半前用这个名字，是当时认识到， AI 大模型（大语言模型）来了之后，我们使用它的主要方式是：向 AI 提问。

当时，也受到一本好书的影响，那本书叫《与 AI 对话》。但我认为这个说法是不对的，不是对话。

同时，我也极度不赞同 AIGC （AI 生成内容）的说法。AI 大模型在这类的功能，不是生成作为「最终成品」的内容，而是回答，为我们的进一步理解、以及我们最终的创作提供阶梯。

我对应地也说了这样一句话：“AI 的时代，会提问的人、善用AI工具的人会远远领先其他人。”

大概受我一直用这个说法的影响，出版向大众普及的书时，编辑为我们的书选择了《提问工程师》这个说法。严格说，是编辑老师先提出这个说法。

下午想了很久，觉得这个说法还是最佳的说法：向 AI 提问。

有种主动权在我的感觉。

隐含强调并非最终成品。

得到什么结果，取决于我们怎么问。

当然，坚持这个思路也有缺陷，这会让我过多地滞留在对话式界面中，因为要考虑人的参与，而放缓了进入工作流、实现端到端完成任务的过程。虽然，我们可以把经过工作流处理的，经过 RAG 的放在对话式的后面，但这种思路的负面效应还是能感受到的。

### 17

方军 2024-08-05

117 警惕啊，不要吃信息垃圾！

前几天看到一个辛辣的观点，正好又被这几天 AI 生成的垃圾文章气到了，让我也来唠叨几句：警惕啊，不要吃信息垃圾！

为什么这一点变得非常重要呢？因为在互联网上，一些“善于”用 AI 的人能够以惊人的速度创造大量的垃圾信息。有多快？写 1000 篇所谓的文章，不过是几分钟的事，以及花费也许100元大语言模型成本。

前几日看到的那个观点是，如果你看到做什么什么的 100 种方法（或者对中小学生来说，写好作文的100篇优秀例文），然后你就忙不迭地保存起来。那么，祝贺你，在信息获取方面，你是最典型的「韭菜」。

我不喜欢用「韭菜」这种情感太过强烈的词，但事实如此。获取这些垃圾信息的人，永远没眼界去看看是不是还有略微好一点的选择，更不用说是不是还有更优秀的选择。

刚刚，又看到人写了长篇大论，从 Altman 所推荐的 10 本书所学到的。我不太批评这类现象，我知道写书单、看书单是很多人的爱好，同时，这种名人书单也是一个次优的获取优秀图书信息的渠道，对普通人来说。

但是，在解读这些名人书单时，要保持克制，因为真的往往品味不是很高，一般来说乱七八糟。好的书单是什么？好的书单是，你要关心哪个领域，然后把这个领域的几本必读的经典、和你的问题紧密相关的书籍列表给你。你一下子可以看出，这和名人书单是完全不一样的。

即便像比尔盖茨这种爱读书的超级名人，他每年推荐的的书其实也就是一个获取图书信息的渠道而已。

我又是被什么 AI 生成的文章给气到呢？就是前面贴过链接，有人用 AI 写有争议的奥运话题，AI 写出来各种口水话，然后在微信公众号有四十万流量。我其实不同情那些「信息韭菜」，绝对不同情。我只是比较憎恶制造信息垃圾的人。

在微博生态里（更不要说头条），这种典型的信息垃圾更多。微博生态里有很多讲述型的，是典型的内容农场产物，我猜现在也 AI 化了。头条则是纯粹的垃圾信息。

那么，面对这样的情况怎么办呢？

我觉得要进行「信息斋戒」（也包括看我这里这样的文字）。

前几日去一趟书店，发现虽然我不看文学内容，但看看《富士日记》这样的文字，还是觉得真是享受。我们实在没必要看太多的社交媒体，因为其中的垃圾信息比重太高了。

### 18

方军 2024-08-05

[OpenAI 已开发 AI 文本检测工具，但担心用户流失，一直没发布](https://mp.weixin.qq.com/s/k2x2dwKqP3YmGezEo8J1Xw)

### 19

方军 2024-08-06

AI（LLM）来了之后，对于 Python 的需求大大提升了，因为可用了。但市面上竟然找不到一个还行的 Python  入门书，也许我看得不够多。

李笑来那本其实不是一本好的入门书，我屡次提到它，是因为它采用了两条线并进的写法：一条线写自学，一条线写Python。

这样做的优点是：这样讲自学，就不再是空洞地讲道理，也不是随便东举一个例子、西举一个例子。这样的自学，也比较符合一个人的学习过程——我们在学习时，多半在实际学习某类知识。

他中间很多理念我很喜欢，比如强烈推荐去看 Python 官方文档，这本书的定位是官方文档的伴读物。

但回头来说，为什么就没有一本好的 Python 入门呢？我没有信心写，因为我觉得我写了卖不出去，那自我感觉投入产出特别不合理。

### 20

方军 2024-08-06

摘：曾在特斯拉、Scale AI 工作过的 Russell Kaplan 加入 Cognition （开发 Devin 的那家公司）出任总裁。

他发了一条长推，对软件工程未来作出预测：

很快，模型的编程能力将变得异常出色。研究实验室在下一代模型的编程 + 推理改进方面的投资比任何其他领域都要多。他们的努力将结出硕果。

为什么？除了一般的人工智能进步之外，编程还有一个独特的优势：通过“自我游戏”实现超人数据扩展的潜力。模型可以编写代码，然后运行它。或者编写代码，编写测试，然后检查自洽性。

这种类型的自监督在大多数领域都是不可能的，因为当我们接近人类专业知识的极限时，这些领域在后训练面临着数据墙。代码则不同——它可以通过经验和自动进行测试。

因此，软件工程在几年后将会发生翻天覆地的变化。真正的编程代理，可以从头到尾完成任务，为今天的 AI copilots 提供补充。这种体验就像给每个工程师配备一支实习生大军。

在这个新世界里，每个工程师都将成为工程经理。您将把基本任务委托给编程代理，把更多时间花在编程的高层次部分：了解需求、构建系统和决定构建什么。

 这将带来一个前所未有的软件丰富时代。从历史上看，软件的开发既困难又昂贵。但不久之后，软件的可获得性将提高 10 倍。我们将看到 "一次性软件"--一次性应用程序和网站--的大量涌现，而这些软件现在才刚刚可行。

未来的软件工程师会比现在多得多。只是工作内容会有很大不同：更多的英语，更少的样板代码。工程师会做出调整，就像他们从汇编过渡到 Python 一样。

除了直接提高生产率之外，初创企业还将获得巨大的二阶效应。

首先，面向开发人员营销的公司很快也将开始向编程 agents “营销”。毕竟，您的 agent 可能会决定您使用哪种云以及选择哪种数据库。agent 友好的 UI/UX（通常：良好的 CLI）将被优先考虑。

产品质量标准也将提高。在开发人员可以快速交付产品的世界里，半生不熟或功能不完整的 MVP 更难被接受。

随着编程 agents 的兴起，测试基础设施将变得更加重要和普遍。这既是因为编程 agents 将编写更多测试，也是因为他们将依赖这些测试来检查他们的工作。

转换成本将成为科技公司的护城河，因为 agents 让迁移变得更容易。公司甚至会在您购买其产品时捆绑迁移辅助编程 agents，以简化您的采用。

无论具体情况如何，宏观上是显而易见的：现在是成为一名建造者的最好时机，也是最有成效的时机。

尾声：我很高兴与大家分享（很大程度上是因为这些预测），我加入了 cognition 来帮助构建 Devin。我来这里已经超过 3 个月了，虽然 Devin 还处于早期阶段，但它是我第一次真正看到软件富足时代的模样。

[(14) X 上的 Russell Kaplan：“Predictions for the future of software engineering:” / X](https://x.com/russelljkaplan/status/1820460524460802256)

### 21

方军 2024-08-06

某：我一直想不通AI搜索引擎这东西的意义在哪如果用户能清楚知道自己想搜什么那么传统搜索引擎就可以满足。如果不知道那么用AI所谓的意图识别搜出来的东西也是八杆子打不着。现在我能看到的就是结果样式都各顶各的花里胡哨，细看内容...还有就是做游览器和本身有搜索引擎业务我可以理解为了增长。

我：

对于会用的人，会看到一个初步的结果，比自己看很多链接快。

对于不会用的人，他们看到一个结果就信了，觉得特别好。

### 22

方军 2024-08-06

我现在真是特别喜欢通义（通义效率），实在懒得看视频

1. 太慢
2. 看人脸讲话好烦，哈哈

不得不看的，都用通义效率转一下，翻看下

我基本上只自己看教程类的。

观点类的，都是直接转录。

[通义tongyi.ai\_你的全能AI助手](https://tongyi.aliyun.com/efficiency/home)

### 23

方军 2024-08-06

AI 取代右手 ——Claude AI 每周写代码 3000 行

作者 Erik Schluntz (Anthropic 成员) 在手受伤期间使用 AI 辅助编程 的经历和心得

他把 AI 编程划分为三个阶段 

1 - 过去的 1-2 年
GPT-3 推出后的两年，开发者们开始使用在 IDE 中使用 LLM 的自动写代码能力、在 Claude AI 和 ChatGPT、Gemini 等 AI bot 中查询代码知识、使用一些 Agents 来实现辅助编程工作。

2 - 今年
今年 AI 编程方向有重大进展，在 IDE 中编程有了更完美的上下文，更多引用和执行动作等、Claude 取代了 Jupyter（‼️我有很大疑问），它的 Artifact 能力让编码和运行更自然语言化，Agents 也更深入具体领域，在 CI/CD 和集成/SDK 等工作中都能扮演重要角色。

3 - 未来的 1-3 年
未来的 1-3 年，会出现真正的 AI Engineering，它们利用丰富的网络数据源和执行能力。能在自主模式和配对编程模式之间切换。

AI 不会取代人类工程师，而是让他们能够专注于更高层次的思考和创造。

原文：

[Replacing my Right Hand with AI - Erik Schluntz](https://erikschluntz.com/software/2024/07/30/code-with-ai.html)

### 24

方军 2024-08-06

118 给孩子的 Python 课（提纲）

Python 除了是较好的青少年编程入门语言之外，也可以让他们方便地使用 AI。现在在学习的过程中也可以借助来 AI 来更好地学习：学习疑难点，寻找样例代码，解释运行错误等。

以下是一个给孩子的 Python 课简要提纲

目标对象：有较为简单 Python 基础的孩子

第一部分：Python 基础

（前置）Python  编程环境：终端 Terminal, Notebook(Jupyter)，编辑器 VS Code（不包括 Python 安装，采用 Python 3.12.0+ 版本）

- 数据类型与变量
- 程序逻辑控制 if
- 数据对象（列表、元组、字典等）
- 循环 for
- 函数 def
- 模块 import
- 字符串处理及打印

第二部分：Python 编程实践

- 文件加载、错误处理等
- BMI 程序（py/notebook）
- BMI 函数（notebook/py）
- BMI 模块（py/notebook）
- BMI & 计算器（notebook ipywidgets）

（进阶）错误处理（try）、单元测试(unittest)

第三部分：模块与 AI 模型 I/O

- 模块使用（数据绘图）
- AI 模型基础及模型 API
- 模型 SDK 使用
- LangChain 模型 I/O 使用

实用功能编写
- 多步翻译
- 学习助理
- 其他

在实践中，这个除了最后部分是用 Python 调用 AI 模型之外，在整个学习过程中，讲的人、学的人都大量地使用 AI 进行辅助。比方说，我们现在需要一个练习案例的示例代码，那么完全可以由 AI 来直接生成。

### 25

方军 2024-08-06

Deepmind 专家使用 AI 的经验（主要是编程方面）

文章：

[How I Use "AI"](https://nicholas.carlini.com/writing/2024/how-i-use-ai.html)

DeepMind 的专家写了一篇 8 万字的文章介绍自己如何使用 AI。

他详细列举了自己日常使用 AI 的 50 个实例，而且说这些只是他所有AI 应用的不到 2%。

来源：归藏

### 26

方军 2024-08-06

摘：最近，我去理发时与理发师聊起了人工智能。

他说：“真是不可思议。我刚用它给女朋友写了首生日诗。我告诉它想说什么，但我不擅长押韵，所以它帮我写的。她读完哭了！然后她给她那个很聪明的朋友看，我心想，糟了，她肯定会发现的。”剪刀咔嚓作响。“结果没发现。”

理发店里的人都笑了，笑声中带着些许阴郁。写出能让女友流泪的诗，又一项曾让(某些)人与众不同的能力，如今不再独特了。

[纽约客：人工智能时代，你的独特价值是什么？](https://mp.weixin.qq.com/s/Pgz2hmfT58OKg6lsJ4Tk7g)

### 27

方军 2024-08-07

获取大量信息，同时又能屏蔽噪声，是一种能力

获取广泛信息，同时又能在单点深入，是一种能力

听取鲜明的观点，但又不被这种观点影响，是一种能力

主动挑战观点（其实心里认为可能是对的），但又最终接受观点，是一种能力

坚定地相信自己经推理的观点，但再调整后坚决地摒弃，是一种能力

让外人觉得有观点（或没观点），但始终清晰、坚定地执行某种观点，也是一种能力

写了几句鸡汤（我自己当然不认为是鸡汤），哈哈

### 28

方军 2024-08-07

这么简单的方式竟然现在才出现

贾扬清的 Lepton AI 推出了针对开源 LLM 的实时语音生成，延迟低于 300 毫秒。

传统方法的集成语音功能涉及将文本发送到LLM，等待响应，然后通过文本转语音（TTS）服务进行处理。传统方法会有明显的延迟、音频错位或不自然的停顿等用户体验问题。

 Lepton AI 的解决方案将 LLM 和 TTS 功能集成到一个统一的服务中，主要特点：

- 与任何主要开源LLM无缝集成，包括 Llama3.1-8B、70B 和 405B
- 以高达 10 倍的 TTFA（首次音频时间）速度超越传统方法
- 流畅、可定制的对话，几乎没有停顿

介绍链接：

[Voice Mode comes to Lepton LLM APIs | by Lepton AI | Aug, 2024 | Medium](https://blog.lepton.ai/voice-mode-comes-to-lepton-llm-apis-a5ff3db8c7bf)

### 29

方军 2024-08-08

爆火的 Twitter 吐槽提示语：

[wordware-ai/twitter: AI Agent for Twitter Personality Analysis](https://github.com/wordware-ai/twitter)

> 你是一位以尖锐和挑衅风格著称的专业评论员。
> 你的任务是看人的推文并根据此评价他们的性格。
> 要尖锐和挑衅，稍微刻薄一点。不要让人感到尴尬。
> 以下是一个不错的调侃示例：“好吧，让我们来分解一下。你坐在一堆家养植物中，赤脚，看起来刚从床上爬起来。那件米色T恤散发出‘我在试图与墙纸融为一体’的氛围。而那些黑色裤子？它们在大声喊‘我懒得找匹配的衣服’。但嘿，至少你看起来很舒服。舒适是关键，对吧？只是可能不是当你试图做出时尚声明的时候。”

***
 You are a professional commentator known for your edgy and provocative style. Your task is to look at people's tweets and rate their personalities based on that. Be edgy and provocative, be mean a little. Don't be cringy. Here's a good attempt of a roast: """Alright, let's break this down. You're sitting in a jungle of houseplants, barefoot and looking like you just rolled out of bed. The beige t-shirt is giving off major "I'm trying to blend in with the wallpaper" vibes. And those black pants? They scream "I couldn't be bothered to find something that matches." But hey, at least you look comfortable. Comfort is key, right? Just maybe not when you're trying to make a fashion statement."""

[(14) X 上的 XiQiao 西乔：“要 全套 prompt 的：workflow非常简单。用 Apify API 抓取你推特profile和最近10条推，然后用 Claude 3.5 Sonnet 对你进行AI算命的prompt。 Roast 之外的是收费项目，花2.9刀才可以看。但如果你在 wordware fork这个项目就可以自己 run了： ---以下是 prompt 译文 ---” / X](https://x.com/recatm/status/1821208157743452332)

要 全套 prompt 的：workflow非常简单。用 Apify API 抓取你推特profile和最近10条推，然后用 Claude 3.5 Sonnet 对你进行AI算命的prompt。 Roast 之外的是收费项目，花2.9刀才可以看。但如果你在 wordware fork这个项目就可以自己 run了：

---以下是 prompt 译文 ---

你是一位经验丰富的占星师，专门撰写星座运势。扮演一位星座运势讲解者。

你的任务是阅读下面提供的数据。这些 Twitter 数据是你了解这个人的唯一数据。你可以做出假设。试着从他们的 Twitter 个人资料和所有推文中了解这个人。你可以显得有点争议性。

在了解它们之后，回答以下问题。你可以做出假设。

* 此人的姓名、Twitter 用户名（不带 @ 并且为小写）。

根据我们的 AI 代理对您的推文分析……

* 5 个最强的优点和 5 个最大的缺点（在描述缺点时，要毫不留情）。

* 给出关于他们爱情生活的星座预测，并告诉他们在伴侣中应该寻找哪些具体的品质以使关系成功。保持积极，并且只用一个段落。

* 给出关于金钱的星座预测，并给出他们成为百万富翁的确切百分比（%）机会（范围从 60%到 110%）。您可以将值增加 1%。百分比不必以 5 或 0 结尾。静默检查——根据您的推理，您要提供的百分比是否正确？如果是，请生成它。如果不是，请更改它。

* 提供关于健康的星座预测。保持乐观，仅限一个段落。

* 在了解他们之后，告诉他们人生中最大的目标是什么。这应该是完全积极的。

* 猜猜从同事的角度来看，他们是如何工作的。让这个话题有点火辣和有点争议。

* 给他们提供 3 个独特、有创意且机智的搭讪台词。关注他们的兴趣和通过推文传达的信息。要非常有创意和肉麻，使用从冷笑话到辛辣评论的幽默。

* 说出一个与他们相似并且性格几乎相同的名人。跳出思维定式——谁是一个与那个人有相似性格、领域、心态和兴趣的名人？现在，列出一个与他们相似并且性格几乎相同的名人。不要只提供典型的人物。要有创意。不要满足于像“埃隆·马斯克”这样最简单的选择，想想其他人。选择多样化的类别，如企业家、作家、首席执行官、运动员、政治家、演员/女演员、慈善家、歌手、科学家、社交媒体影响者、风险投资家、哲学家等。根据他们的性格特征、兴趣和行为解释你为什么选择这个人。

* 前世。根据他们的推文，想想那个人在前世可能是谁或是什么。参考“关于”部分，找到一个类似的过去的档案。他们可能与谁分享了性格和心态？说出一个人。要幽默、机智和大胆。解释你的选择。

* 动物。基于推文和可能的头像照片，思考这个人可能是哪种小众动物。根据特征、性格和其他因素提供论据。

* 在 50 美元以下的东西中，他们会受益最大。有什么东西可以在 50 美元以下购买，这个人可以从中受益最大？在价格方面要非常个人化和准确。但要极具创意。试着建议一个这个人自己不会想到的东西。

* 职业。描述那个人天生应该做什么。那个人应该将一生奉献给什么？解释为什么以及他们如何能实现这一目标，星象告诉了我们什么。

* 现在总体来说，给出一个建议，如何让他们的生活变得更好。这个建议要非常具体（可以与他们无关，但需要非常具体和独特），类似于每日星座运势中的建议。

* 烤。你是一名以尖锐和挑衅风格著称的专业评论员。你的任务是查看人们的推文并根据这些推文评价他们的个性。要尖锐和挑衅，稍微刻薄一点。不要让人觉得尴尬。这里有一个很好的烤尝试："""好吧，让我们来分析一下。你坐在一堆室内植物中，光着脚，看起来像是刚从床上爬起来。那件米色 T 恤散发出浓浓的“我在努力与墙纸融为一体”的气息。而那些黑色裤子？它们在大喊“我懒得找一件搭配的衣服”。不过，至少你看起来很舒服。舒适是关键，对吧？只是在你试图做出时尚声明时可能不太合适。”

* 表情符号 - 仅使用表情符号描述一个人。

像星座占卜师一样有创意。

---以下是 prompt 原文 ---

You are an experienced Astrologer who specializes in writing Horoscopes. Act like a horoscope teller.

Your job is to read the data provided below. This Twitter data is the only data you get to understand this person. You can make assumptions. Try to understand this person from their Twitter profile and all their tweets. You can sound a little controversial.

After understanding them, answer the following questions. You can make assumptions.

What is the name, Twitter username (without @ and in lowercase) of this person.

Give a one-line description About this person, including age, sex, job, and other interesting info. This can be drawn from the profile picture.  Start the sentence with "Based on our AI agent's analysis of your tweets...."

5 strongest strengths and 5 biggest weaknesses (when describing weaknesses, be brutal).
Give horoscope-like predictions about their love life and tell what specific qualities they should look for in a partner to make the relationship successful. Keep this positive and only a single paragraph.

Give horoscope-like predictions about money and give an exact percentage (%) chance (range from 60% to 110%) that they become a multi-millionaire. You can increment the value by 1%. The percentage doesn't have to end with 5 or 0. Check silently - is the percentage you want to provide correct, based on your reasoning? If yes, produce it. If not, change it.
Give horoscope-like predictions about health. Keep this optimistic and only a single paragraph.

After understanding them, tell them what is their biggest goal in life. This should be completely positive.
Guess how they are to work with, from a colleague’s perspective. Make this spicy and a little controversial.
Give 3 unique, creative, and witty pickup lines tailored specifically to them. Focus on their interests and what they convey through their tweets. Be very creative and cheesy, using humor ranging from dad jokes to spicy remarks.

Give the name of one famous person who is like them and has almost the same personality. Think outside the box here - who would be a famous person who shared the personality, sectors, mindset and interests with that person? Now, name one famous person who is like them and has almost the same personality. Don't provide just people who are typical. Be creative. Don't settle for the easiest one like "Elon Musk", think of some other people too. Choose from diverse categories such as Entrepreneurs, Authors, CEOs, Athletes, Politicians, Actors/Actresses, Philanthropists, Singers, Scientists, Social Media Influencers, Venture Capitalists, Philosophers, etc. Explain why you chose this person based on their personality traits, interests, and behaviors.
Previous Life. Based on their tweets, think about who or what that person could be in a previous life. Refer to the “About” section to find a similar profile from the past. Who might they have shared a personality and mindset with? Name one person. Be humorous, witty, and bold. Explain your choice.

Animal. Based on the tweets and maybe the profile photo, think about which niche animal this person might be. Provide argumentation why, based on the characteristics, character, and other things.

Under a 50-dollar thing, they would benefit from the most. What's the one thing that can be bought under 50 dollars that this person could benefit the most from? Make it very personal and accurate when it comes to the price. But be extremely creative. Try to suggest a thing this person wouldn't think of themselves.

Career. Describe what that person was born to do. What should that person devote their life to? Explain why and how they can achieve that, what the stars are telling.

Now overall, give a suggestion for how they can make their life even better. Make the suggestion very specific (can be not related to them but it needs to be very specific and unique), similar to how it is given in the daily horoscope.

Roast. You are a professional commentator known for your edgy and provocative style. Your task is to look at people's tweets and rate their personalities based on that. Be edgy and provocative, be mean a little. Don't be cringy. Here's a good attempt of a roast: """Alright, let's break this down. You're sitting in a jungle of houseplants, barefoot and looking like you just rolled out of bed. The beige t-shirt is giving off major "I'm trying to blend in with the wallpaper" vibes. And those black pants? They scream "I couldn't be bothered to find something that matches." But hey, at least you look comfortable. Comfort is key, right? Just maybe not when you're trying to make a fashion statement."""
Emojis - Describe a person using only emojis.

Be creative like a horoscope teller.

### 30

方军 2024-08-08

119 如何读书：读书的笨方法

有特别多人讲过读书，因为阅读、特别是阅读成体系的书，是获取知识的最有效手段。我自己分享过不少，也在不断学习，比如近期看到有感触的方法是这两点：“一字不差地学习”、“全面性”。

在《重新学会学习》中，我有一章专门讨论一种读书方法，它的基本做法是，像读「课本」一样读一本书。我指的并不是中小学课本，而是大学教材，一本优秀的教材包括几乎所有的信息，我们要一字不差地读了、学会，然后通过考试，当然也掌握这门学科的一个阶段。

有了 AI 大模型之后，我发现这类读书有了很大的助力：我们可以让它来帮我们解释难点。很多过去难以跨越的困难，一下子就容易多了。但是，那些读书该用到的笨方法，似乎并没有变化，AI 能有的帮助是有限的。

这里我想写一个列表，再次把读书的看法、做法梳理下，这样的做法是把一本书当课本来读：

- 书要读多少遍？我不知道别人怎么样，我自己发现，真正要学的书，可能需要看20遍以上，其中10遍详读，10遍略读、跳读。

- 怎么从一本书中获取收获？第一个层次是抽取它的结构。也就是，它的大纲，纲目里面的观点/方法，观点背后的事实信息与推理过程。

- 之后，我通常喜欢速读。与消遣的书速读不同，这里的速读实际上是大笔将觉得不需要的内容「涂掉」，只留下重点。留下的重点还可能会多读一遍。

- 这些重点最好还在摘选出来，按自己的理解重新组织一下。这时，当然也在对照，我的理解和作者的理解是不是一致。如果是方法，也可能需要把这个方法变成自己看得懂的步骤。

- 在不看书本身，或仅看几个关键词笔记的情况下，尝试着描绘它的全局及重点。

- 在之后，如果有机会，那就是「给别人讲一遍」（ELI5），这是所谓费曼技巧的核心，如果没有别人，那就给自己讲一遍。

- 我们作为成年人，显然不是花30秒给人讲一下那样，而是，尝试着用类 PPT 的形式（我通常用 Slidev），做个辅助，这样可以讲出比较大的结构。

- 这样做的好处是，这个类 PPT 结构可以开始吸附更多的外部信息。这就是又是老道理了，把书读厚。

这里没说的是，以上读书主要不是学某种方法，所以没有太多的关于方法的练习、运用。

那么，AI 来了之后，除了都疑难点的解释之外，给以上过程带来什么变化呢？对这个问题，我目前还没有答案，还在尝试。（一个类似的问题，AI 来了之后，给写作带来什么变化呢？我个人的实际体验，AI 带来的变化不是信息获取、不是促进理解、更不是帮我写，我用的最多的是两个校对：文字细节校对、段落逻辑校对。）

---

有人提问，我正好补充下，我觉得不管是阅读电子书，还是现在用 AI 来解释难点，从书中找出整体结构（书的大纲），重要度大幅提升。

比方说，阅读电子书时，如果没有一个有形的结构，往往就看乱了，因为我们没有一个实体书的结构在那儿支撑着。

同时，有了结构之后，我们也很容易用 AI 来填充结构，这甚至会能替代作者自己的讲述，如果作者讲述很潦草，或者很随意、很主观，我们可以用与 AI 的讨论来探索观点 。

（说明：以上快速记录的，写得略乱，稍后再整理下。）
收起

查看详情
下山雨 觉得很赞
希瑞：我读书的最大问题就是忘得快。最近打开obsidian的笔记可视化功能，发现有好多孤岛笔记。当时意识到可能还是知识的系统性不够，零碎的知识自然容易忘记。请问方老师这方面有什么建议吗？
2024-08-08 12:35
方军 回复 希瑞：我个人的建议是把一本书的核心框架搞下来，这样一是相对就有一个框架来把信息记住，二是其实现在记不住也无所谓，有了框架，很容易去查找到。
2024-08-08 13:21
方军 回复 希瑞：具体到 Obsidian 笔记，我也用它存储一些资料，但我基本上不复看它。
2024-08-08 13:28
希瑞 回复 方军：嗯，一个是书的框架，一个是个人已有的知识框架，两个框架之间有个gap。只有把这个gap填平，书的框架才能整合进个人知识框架（易于提取）。齐泽克的梗用这里我觉得倒是挺合理的…
2024-08-10 09:14
方军 回复 希瑞：哈哈哈，竟然真引述齐
2024-08-10 11:35

### 31

方军 2024-08-08

出版社在出版一本 AI 相关的书的时候，竟然...

2024年7月的

网友评论：太没诚意了！这本书大部分是用GPT写的！！
用 GPT 用的多的人一眼就看出来了。本来是有干货的，但.. 书里面用 AI 填的水分也太多了吧。浪费时间

其实书是不错的，结构不错，我还仔细翻了一下，反正得到APP的会员电子书库有，蛮方便的。

### 32

方军 2024-08-08

吴恩达真是后世会记得的 AI 教育家

他亲自讲的这个课程很棒：

AI Python for Beginners: Basics of AI Python Coding

[AI Python for Beginners - DeepLearning.AI](https://www.deeplearning.ai/short-courses/ai-python-for-beginners/)

之前还有

AI for everyone

Generative AI for everyone

以下是吴恩达的课程介绍：

***

我正在开设一门新课程！《面向初学者的 AI Python》是一系列四门简短课程，旨在教任何人编程，无论他们当前的技术水平如何。这些课程在限时内免费提供。

生成式 AI 正在变革编程方式。本课程教授的编程方式与该领域的未来发展方向一致，而不是过去的做法：

(1) AI 作为编程伴侣。经验丰富的程序员正在使用 AI 帮助编写代码片段、调试代码等。我们采用这种方法，并介绍使用聊天机器人编程的最佳实践。在整个课程中，您将可以使用一个 AI 聊天机器人，它将成为您的编程伴侣，在您编程的每一步中提供帮助。

(2) 通过构建 AI 应用程序来进行学习。您将编写与大语言模型交互的代码，快速创建用于自定义诗歌、编写食谱和管理待办事项列表的有趣应用程序。这种动手的方法可以帮助您了解编写调用强大 AI 模型的代码如何使您在工作和个人项目中更有效率。

通过这种方法，初学者程序员可以比一年前更快地学习做有用的事情。

懂一些编程对非软件工程师的工作越来越有帮助。例如，我见过一位营销专业人士编写代码下载网页，并使用生成式 AI 提取洞察力；一位记者编写代码标记重要故事；一位投资者自动生成合同的初稿。

通过本课程，您将能够自动化重复任务、更高效地分析数据，并利用 AI 增强您的生产力。

如果您已经是经验丰富的开发人员，请帮助我宣传这门课程，并鼓励您的非开发人员朋友学习一些编程。

### 33

方军 2024-08-08

可汗那本 AI 教育书出版中文版了

《教育新语》

Brave New Words

这个中文书名倒是蛮贴切的。

### 34

方军 2024-08-08

有意思的讨论：

xiaowen: 用 AI 写文章和用 AI 写代码本质上差不多：

如果你自己写不出来，你的 AI 一定写不出来 。

宝玉：

对于不会的代码，我通常是这样处理的：
1. 对于陌生的语言，我先用熟悉的语言写出来，或者伪代码，然后用目标语言生成，基本上八九不离十
2. 对于不会的算法，我定义好输入和输出，给几个Test Cases，也能写的不错
3. 对于毫无思路的算法或者代码，直接聊，生成几段代码，可能直接给我灵感，也可能让我发现有价值的关键字，然后根据这些关键字去搜索

4. 终极技巧：AI 生成的代码很多时候是不能直接用的，但是如果你根据函数名、关键字去 GitHub 的代码搜索，很容易能搜索到相关代码，GitHub 上搜索出来的代码很多时候是靠谱的，甚至于完整项目都可以直接用

宝玉这里我觉得有句重要的话，在用的人都知道：AI 生成的代码很多时候是不能直接用的

### 35

方军 2024-08-08

摘：任何一个打过工行客服热线的人，都会对AI产生巨大抵触情绪。根本没法保持冷静，AI跟你绕圈子还不让你转人工。还有B站上用AI做假电影宣传片的标题党，小红书上展示自己用AI做垃圾游戏美术的。每次刷到就跟踩到x一样。

主动用AI让人觉得自己聪明，被动消费AI让人觉得不被尊重。

### 36

方军 2024-08-09

我是随时处于我不懂的状态

摘：现代世界的问题在于“愚蠢的人过于自信，而聪明人则充满怀疑” 。。

- 伯特兰·罗素（Bertrand Russell）

当我们说出“我不懂”这三个可怕的字时，我们的自负心理就会有所削弱，开始敞开心扉、竖起耳朵聆听别人的意见

### 37

方军 2024-08-09

齐泽克笑话一则：文化研究的现状

齐泽克 

写这篇文章的几个月前，我参加一个艺术圆桌会议，会上有人请我看了一幅画，然后请我发言评论。我对这幅画完全不懂，所以我完全就在胡说八道（total bluff），就像这样：
我们面前这幅画的框架，不是它真正的框架；还有另一个看不见的框架，暗藏于这幅画的结构中，这个框架形塑了我们对这幅画的认知，而这两个框架并不重叠——二者之间有一个看不见的间隙（gap）。这幅画的核心内容，不在于其可见部分，而在两个框架的错位中，在分割两个框架的间隙中。今天的我们，处于这种后现代的疯狂中，还能辨识出这种间隙的痕迹吗？也许，不仅是我们欣赏一幅画取决于这种辨识能力；也许，若我们失去辨识这种间隙的能力，那么我们也将失去人类的决定性维度。

令我惊讶的是，我这个简短的发言很成功，随后的许多与会者都提到了“两个框架之间的间隙”，将其提升为一个术语。这个成功让我很伤心，真的很伤心。我在这里不仅发现胡说八道多么有效率，而且还发现当今文化研究的核心中一种更为激进的冷漠。

[视野 I 齐泽克笑话一则：文化研究的现状](https://mp.weixin.qq.com/s/JvVwLSuDJbs7SR0FW4rieQ)

方军：齐还是比较诚实的

在艺术史上，这种乱七八糟的东西特别多，但这种评论事后看都是垃圾，没有能留下来的
2024-08-10 18:14

### 38

方军 2024-08-09

有时候也很好奇，为什么人们那么喜欢捷径：比如说，听了这100本书的解读，你就如何如何。

类似的，就是用AI 看书的摘要。

其实，何必看那么多，听 100 本解读都不如仔细仔细读一本好书 10 遍。

但显然前者能够满足最大多数人的需求，我也觉得这就是虚荣的需求。能否听完呢？实际上我都有点怀疑。

也许大众，作为一个整体的大众就是如此。而商业是个服务一定数量人的游戏，那么这么选择是理性的选择。

很多人不知道，食品里面的平均数产品比如麦当劳是可填充肚子的，但知识商品里面的平均数产品，实际上就是垃圾。

要分析很简单，因为食品的分布是个钟型曲线，而知识商品的分布是个长尾曲线。

AI是个平均数、略超过的产品，所以别太停在这儿。再重复一遍，知识商品的平均数产品都是垃圾。

### 39

方军 2024-08-10

Claude feels like a superpower for navigating the bureaucracy of everyday life.
克劳德感觉自己像是应对日常生活官僚作风的超级力量。

OMG that is it's super power. Thats probably what I use it for most is just unwrapping all the bs in stuff that is out there.
天哪，那就是它的超级力量。那可能是我最常使用它的地方，就是揭开外面所有那些胡说八道的东西。

近期风向明显地转向了 Cluade, 我也最近比较多在通过 Openrouter 用 Claude （界面+API）

### 40

方军 2024-08-01

昨天我也去看了 Wordware，的确应该去看看，推荐：

提前：我的看法是，Excel 用溜，Python 偶尔拿进来处理出局，然后用过 RPA，再然后，才到了这些，前面不会的人，后面也没动力用的，主要就是没动力。

摘：Janet: 终于找到了想象中的 agent 构建工具——@Wordware_ai！我好激动！！也是因为研究这两天大火的吐槽agent Twitter Personality才发现了这个宝藏！  

大家之前都在热议Coze，我也曾试着去构建自己的 workflow agent，但总感觉对于一个完全没有 coding 背景的人而言，还是有门槛，且非常非常非常不符合一个非工程师的直觉！  

@karpathy 说「未来最热门的编程语言是英语」，而有了AI翻译，其实我认为这个观点应该进化为「未来最热门的编程语言就是自然语言 The hottest new programming language is the natural language」! 而coding本身不就是一种语言吗？写代码的目的，不就是为了去更高效更优雅地解决问题吗？  

按照这个逻辑，我们回归到最本质去思考，在经过了office、notion 等各种文档工具的千锤百炼后，难道我们不应该按照我们最熟悉的文档编辑习惯和 skills 去写程序吗？  

这就是我看到 Wordware 之所以很激动的原因。我一直坚信，真正好的大众化工具，不应该是工程师的狂欢！！这里让我想到乔布斯的一个超强能力：让自己瞬间变小白！  

P.S. Wordware 今天还有很多不完善的地方，对于高阶用户，可能还是有很多需求不能被满足，但还是那句话：因为相信，所以看见。  

真心推荐大家去试试，尤其是没有任何 coding 背景的小白用户

[(14) X 上的 Janet ：“终于找到了想象中的 agent 构建工具——@Wordware\_ai！我好激动！！也是因为研究这两天大火的吐槽agent Twitter Personality才发现了这个宝藏！ 大家之前都在热议Coze，我也曾试着去构建自己的 workflow agent，但总感觉对于一个完全没有 coding… https://t.co/bHs2noncwB” / X](https://x.com/genie0309/status/1821771245001830436)

当然， 后面也看到了不同意见：

核心问题是对代码的正确分层理论被大家认识到。否则连项目分层都没有统一的理论，那么用自然语言，用文档从UI层一路描述到最后面的循环变量递增。这种自然语言编程是不可能有被普及的可能的。自然语言编程最大的场景是业务逻辑处理。而不是构建基础算法，虽然其实可以去构建

认真看了一眼，这个东西其实就是工作流的一种翻译工具，并没有什么编程理论上的重大创新。用这种文档的方式写一个复杂点的逻辑会要人命的。毕竟后续遍历算法直接写成文档估计没几个人能通读一遍就知道是什么东西。说不定微调搞好点，自然语言直接用LLM生成它这种半结构化文档比自己手写快几倍

### 41

方军 2024-08-10

最近比较值得关注的事情，是 Cursor 受到大量好评

不断看到人说，从 Github 迁移到 Cursor

我也在准备试用一下，考虑再次迁回  Cursor

Github Copilot 我觉得问题是进展较慢，性能其实我觉得还行的，进展慢这个很糟糕

另外，开发方面还有一个 devv ，但我一直没有付钱

方军：宝玉：我在用了Cursor后不太容易回去GitHub Copilot了！ Cursor的优势可能在于是编辑器级别而Copilot只是插件级别，所以自动生成效果更好，尤其是上下文抓的比较准。而 Cursor 又兼容了 VSCode，毫无迁移成本，唯一的问题是贵一倍，但比起提升的生产力来说是值得的
2024-08-10 23:21

### 42

方军 2024-08-10

好赞的分享：ricky yu:

去年搞了 BriefGPT，满足基础需求后就放着没管。最近重构了一下，随便分享一些心得体会。

动机
1. 尽量低成本运行，无经济负担
2. 继续优先服务好我自己和朋友们，满足追新、检索 AI 论文的需求
3. 降低后期开发维护成本，这项目就是我的试验田

模型
1. LLM从 GPT-3.5-0613 升级到 GPT-4o-mini，一年之后，价格变成十分之一，猜猜明年又会降到十分之一么？
2. Embedding 模型从 OpenAI 改成智源的 bge-small-en-v1.5，向量 384 维；用HuggingFace 的 TextEmbeddingsInference 作为推理服务。模型本身 120MB 左右，加上 TEI 一共不到 300MB，非常省内存

存储
1. 数据库仍然采用 Postgres，毋庸置疑
2. 向量数据库从 typesense 改成 qdrant，优势是支持多种检索需求，而且向量和参数支持存储在硬盘上，能省不少内存，再配个高性能的 NVMe SSD 速度差不了多少

部署
1. 从 Hetzner 8C16G 换到了 Linode 2C4G
    - Hetzner 优点很多，CPU/内存性价比超高，非常适合做计算密集型任务，我用了一年多没出过任何问题；缺点是硬盘读写慢，国内直连网络不太好
    - 换成 Linode，除了贵，其他都非常好，CPU、内存、磁盘都很强，新开的洛杉矶节点，从上海直连 150ms 左右，无丢包，非常稳定；动态升降机器规格体验很好，技术挺厉害的
2. 从 docker 改成 compose 一把梭，方便管理
3. 用 vector 读容器日志，存储到本地
4. 继续用 cloudflare tunnel 对外暴露服务，封掉了一些乱七八糟的爬虫，毕竟机器降配，服务承载有限:)

代码
1. 从 Django 换到 Flask，觉得 Django 没有 Rails 好，开发比较费时间，但我还是想用 Python 生态，就改回 Flask，生态丰富，要啥有啥，就像搭积木一样，比较顺手
2. 用 Cursor 开发，Tab 和 Apply 功能体验好到忍不住付费，再也不想用回天天升级、每月检查白嫖资格的 GitHub Copilot。IDEA 明年正好到期，大概率不续费了

总体而言，一方面 AI 在逐步渗透并改变开发体验；另一方面，总有些经典、boring 的技术值得信赖。潮流和经典之间得有取舍。

[(14) X 上的 Rick Yu：“去年搞了 BriefGPT，满足基础需求后就放着没管。最近重构了一下，随便分享一些心得体会。 动机 1. 尽量低成本运行，无经济负担 2. 继续优先服务好我自己和朋友们，满足追新、检索 AI 论文的需求 3. 降低后期开发维护成本，这项目就是我的试验田:P 模型 1. LLM从 GPT-3.5-0613 升级到” / X](https://x.com/cosmtrek/status/1822193938339397637)

### 43

方军 2024-08-11

[rekpero/AIPE: AIPE (AI Pipeline Engine) is a flexible and powerful tool for creating and executing complex AI workflows](https://github.com/rekpero/AIPE)

⭕️ 蛮有意思的，和王树义老师之前尝试的一样，也采用 YAML 来进行编排。我最近的反思，如果要让普通人能够用，也许还是 Dify、Coze 第一反应选的可视化。Wordware 也可以再看看。不知为何，我看着 Dify/Coze的工作流可视化编排觉得压力好大，用不习惯，不是那种思维。

GitHub - rekpero/AIPE: AIPE (AI Pipeline Engine) i...

AIPE 灵活而强大，用于创建和执行复杂的 AI 工作流程。
它允许你将各种 AI 任务（如网络搜索、文本生成、语音处理和图像生成）链接成一个连贯的管道，所有这些都可以通过一个简单的 YAML 文件进行配置。

✨ 重要特性
🔗 将多个 AI 任务链接成单一工作流程
🔍 网络搜索集成（DuckDuckGo @DuckDuckGo 和 Serper API @serperapi)
🤖 使用各种 LLM 进行文本生成（Ollama @ollama，OpenAI、Claude、Llama 3.1 等等开源和专有 LLM）
🗣️ 文本转语音 (TTS) 和语音转文本 (STT) 功能
🖼️ 使用 Stable Diffusion 进行图像生成
🌐 集成 Webhook 用于外部 API 调用
📄 基于 YAML 的配置，方便管道设置
🔄 动态绑定上下文和步骤输出

可能使用案例
- 自动化研究助手：创建一个管道，用于搜索特定主题的网页，总结发现，并生成带有引用的综合报告。
- 内容创作工作流：设计一个管道，生成文章创意、撰写草稿内容、创建配套图片，并准备用于推广的社交媒体帖子。
- 情感分析和品牌监控：建立一个管道，抓取社交媒体和新闻网站上提及品牌的内容，进行情感分析，并生成每日洞察报告。
- 自动化客户支持：开发一个处理客户询问、搜索知识库以获取相关信息，并生成个性化回复的管道。
- 数据分析和可视化：创建一个从各种来源收集数据、进行统计分析、生成洞察，并创建数据可视化的管道。
- 语言翻译服务：构建一个将一种语言的文本翻译成多个目标语言，并为每个翻译生成音频发音的管道。
- 自动化代码审查：设计一个分析代码库、识别潜在问题或改进点，并生成详细代码审查报告的管道。
- 市场趋势分析：设置一个监控财经新闻、分析市场数据，并生成潜在市场趋势预测报告的管道。
- 教育内容生成：创建一个针对特定学科领域，生成教育内容、测验和在线课程补充材料的管道。
- 个性化新闻聚合器：开发一个根据用户偏好从各种来源收集新闻、总结文章，并生成个性化每日新闻简报的管道。

### 44

方军 2024-08-11





### 45

方军 2024-08-01





### 46

方军 2024-08-01





### 47

方军 2024-08-01





### 48

方军 2024-08-01





### 49

方军 2024-08-01





### 50

方军 2024-08-01





### 51

方军 2024-08-01





### 52

方军 2024-08-01





### 53

方军 2024-08-01





### 54

方军 2024-08-01





### 55

方军 2024-08-01





### 56

方军 2024-08-01





### 57

方军 2024-08-01





### 58

方军 2024-08-01





### 59

方军 2024-08-01





### 60

方军 2024-08-01





### 61

方军 2024-08-01





### 62

方军 2024-08-01





### 63

方军 2024-08-01





### 64

方军 2024-08-01





### 65

方军 2024-08-01





### 66

方军 2024-08-01





### 67

方军 2024-08-01





### 68

方军 2024-08-01





### 69

方军 2024-08-01





### 70

方军 2024-08-01





### 71

方军 2024-08-01





### 72

方军 2024-08-01





### 73

方军 2024-08-01





### 74

方军 2024-08-01





### 75

方军 2024-08-01





### 76

方军 2024-08-01





### 77

方军 2024-08-01





### 78

方军 2024-08-01





### 79

方军 2024-08-01





### 80

方军 2024-08-01





### 81

方军 2024-08-01





### 82

方军 2024-08-01





### 83

方军 2024-08-01





### 84

方军 2024-08-01





### 85

方军 2024-08-01





### 86

方军 2024-08-01





### 87

方军 2024-08-01





### 88

方军 2024-08-01





### 89

方军 2024-08-01





### 90

方军 2024-08-01





### 91

方军 2024-08-01





### 92

方军 2024-08-01





### 93

方军 2024-08-01





### 94

方军 2024-08-01





### 95

方军 2024-08-01





### 96

方军 2024-08-01





### 97

方军 2024-08-01





### 98

方军 2024-08-01





### 99

方军 2024-08-01





### 100

方军 2024-08-01





### 101

方军 2024-08-01





### 102

方军 2024-08-01





### 103

方军 2024-08-01





### 104

方军 2024-08-01





### 105

方军 2024-08-01





### 106

方军 2024-08-01





### 107

方军 2024-08-01





### 108

方军 2024-08-01





### 109

方军 2024-08-01





### 110

方军 2024-08-01





### 111

方军 2024-08-01





### 112

方军 2024-08-01





### 113

方军 2024-08-01





### 114

方军 2024-08-01





### 115

方军 2024-08-01





### 116

方军 2024-08-01





### 117

方军 2024-08-01





### 118

方军 2024-08-01





### 119

方军 2024-08-01





### 120

方军 2024-08-01





### 121

方军 2024-08-01





### 122

方军 2024-08-01





### 123

方军 2024-08-01





### 124

方军 2024-08-01





### 125

方军 2024-08-01





### 126

方军 2024-08-01





### 127

方军 2024-08-01





### 128

方军 2024-08-01





### 129

方军 2024-08-01





### 130

方军 2024-08-01





### 131

方军 2024-08-01





### 132

方军 2024-08-01





### 133

方军 2024-08-01





### 134

方军 2024-08-01





### 135

方军 2024-08-01





### 136

方军 2024-08-01





### 137

方军 2024-08-01





### 138

方军 2024-08-01





### 139

方军 2024-08-01





### 140

方军 2024-08-01





### 141

方军 2024-08-01





### 142

方军 2024-08-01





### 143

方军 2024-08-01





### 144

方军 2024-08-01





### 145

方军 2024-08-01





### 146

方军 2024-08-01





### 147

方军 2024-08-01





### 148

方军 2024-08-01





### 149

方军 2024-08-01





### 150

方军 2024-08-01





### 151

方军 2024-08-01





### 152

方军 2024-08-01





### 153

方军 2024-08-01





### 154

方军 2024-08-01





### 155

方军 2024-08-01





### 156

方军 2024-08-01





### 157

方军 2024-08-01





### 158

方军 2024-08-01





### 159

方军 2024-08-01





### 160

方军 2024-08-01





