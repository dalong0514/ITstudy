### 01

方军 2024-06-01

摘：OpenAI 分享他们在 RAG 技术的最佳实践：

客户需求：他们有大量文档（比如 10 万份），希望模型只基于这些文档进行知识检索。

解决方案：

1. 直接将 PDF 和 docx 文件嵌入，准确率是 45%。

2. 经过 20 次调优迭代，解决细节小 Bug - 准确率到 65%

3. 基于规则进行优化，譬如先判断问题属于什么领域（退一步思考），然后再回答，效果提升到 85%

4. 发现数据里有一些是结构化数据（如表格），为此定制提取解决，准确率提升到 98%。

[A Survey of Techniques for Maximizing LLM Performance - YouTube](https://www.youtube.com/watch?v=ahnGLM-RC1Y)

### 02

方军 2024-06-01

这个用户的体会蛮有意思的：经过我一上午的摸索，ChatGPT4O 和 4 对我的工作毫无帮助，都是坑货。

我把一个危重病人的连续 5 天的化验结果导出成 PDF（打印出来需 24 页），然后让 GPT 抓取其中的指标按时间排列，来辅助表现病情变化。先抓取了 4 个指标：

白细胞、中性粒细胞、血红蛋白、C 反应蛋白。

抓取缺项漏项很多，我只能把大量的检验结果生成成文字，然后复制给 GPT，再让它抓取。

它不仅会无中生有，还会误判时间，漏掉最低值和最高值，把有些值乱放。

多次调教，但是同样性质的错误，这里改对了，那里还是错。

列个表而已，基本上也是瞎写一气！

有这个摸索的功夫，我用眼睛看数据，手输 excel 也输完了。

当然了，没有白费功夫，起码下个月不用花钱买号了。

方军：简单说，这个人用法不对，PDF 不对，后面结构化数据也不对，这个任务甚至都不应该依靠 LLM，也许应该用 LLM 的 functioncall + 代码生成

2024-06-01 13:24

### 03

方军 2024-06-01

有意思的类比，摘：试过几次就知道了，AI 总结出来的东西就跟甘蔗渣一样索然无味，一点营养价值都没有。

这些天又相继看到了一些 AI 写作的工具，据说微博也在策划推出 AI 辅助写作，更加感觉无语。写作是思考的载体，让 AI 来写作相当于让 AI 代替你去思考，这怎么能行？

有人说，AI 只是起到辅助作用，比如列一下大纲啊，提供一些表达参考，文字风格润色之类的，最终还是需要作者本人来把控输出质量的。

但我觉得，这些步骤都是写作过程中必不可少的环节，属于是作者本人必须要经受的「必要困难」，不能假以援手。如果长期把这些工作外包给 AI，写作能力必然会遭遇退化。

从阅读到写作，如果这种端到端的知识工作流程都被 AI 侵蚀的话，很难不怀疑在之后 AI 普及的时代里，大部分人的大脑会有一定程度的退化。

都说语言是思维的载体。一个很少有人想过的逻辑是，互联网大厂们在使用各种语料训练 AI，但反过来 ，AI 产出的语料又在训练广大的互联网用户。

### 04

方军 2024-06-01

为什么说这个是胡说？因为它一开头给了一个巨大的定论，是对还是错的呢？根本说不明白。然后下面一堆，正确和错误、似是而非混在一块，主讲一个乱七八糟，真要辩论，就要它拆解开，一点一点地辨别，累啊。这也是为什么我频繁吐槽讨论 AGI 的人，你倒是先定义下再说啊。

以下这个人说的话就是典型的 LLM 胡说，摘：

LLM 本质上是文字接龙，是大号检索，只不过因为大力出奇迹，它训练的数据够多参数够多，所以他接龙的文字显得很聪明，但它其实并不知道自己在说什么，他并不真的具备「智能」。一个很简单的例子，让它做稍复杂一点的数学运算都会算错，连个计算器都比不上。

所以 LLM 通过各种插件在补充自己的能力，比如 TTS、文生图、生成编码、function call、RAG。但这些都只是手脚，还不是大脑，真正离大脑接近的，或者说至少看起来是「智能」的部分是：prompt 中的引导和 ReAct，这个是最大化人工智能潜力的关键。LLM 模型本身强大是必要的，再就是我们的引导了，两者缺一不可。

workflow 其实不是智能，感觉没有 LLM 也能实现 workflow，比如 stable diffusion 也有 ComfyUI，它只是自动化脚本，无关智能。所以我在看 LangChain 的 multi-agent 解决方案 Langgraph 时，总觉得怪怪的，既然 action 准备好了，agent 也准备好了，edge 究竟是什么呢？和直接编程写 if else 有多大区别？如果不这么设计，又该如何设计呢？我没找到答案，只是隐隐觉得哪里不对。。。

prompt 和 ReAct 才是「智能」的宝藏。类似 OCR 和 TTS 的传统小模型不是，非 LLM 的 AIGC 不是，基于 LLM 基座做垂直大模型不是，多模交互不是，workflow 也不是。同样是 AIGC，同样是大模型，为什么 chatGpt 比 midjourney 受关注得多？就是因为文字类的 AIGC 恰巧表面上看起来具备「推理能力」，正是这种推理能力才让 ReAct 成为可能，借助 function call 又有了从「想」到「做」的能力。这是 LLM 得天独厚的优势。

方军：定义一个大词，是个艰难的任务。

不试图定义，就容易多了。

你管 workflow 是智能干啥，你看它能不能满足一个你具体的任务，完成得好不好，是不是容易多了

看着过于务实，但这是可有效讨论的范围啊。

2024-06-01 18:23

方军：LLM 的胡说某种意义上，还比这个好些，因为目前 LLM 在不有意指令的情况下，会相对聚焦，不会太分散

2024-06-01 18:27

### 05

方军 2024-06-02

引发认真的讨论啊，摘：（宝玉）看到 @Summer 最聪明医生这条被 ChatGPT-4o 坑的微博，尝试从技术角度解读一下，这样也许能更好的理解现阶段大语言模型的优缺点，在实际应用中能扬长避短。

首先回顾一下原博文中的用法，以保证我们讨论的是一件事，避免因为我的误解而错误解读。

「病人连续 5 天的化验结果，24 页 PDF 发送给 ChatGPT，让其抓取 4 个指标（白细胞、中性粒细胞、血红蛋白、C 反应蛋白），按照时间顺序排列」

结果：「抓取缺项漏项很多」

然后：「把大量的检验结果生成成文字，然后复制给 GPT，再让它抓取」

结果：「它不仅会无中生有，还会误判时间，漏掉最低值和最高值，把有些值乱放。」

这个结果确实不尽人意，然而对于现阶段的大模型来说，也不奇怪，这里面涉及几个大模型的短板：

1. 上下文窗口长度不够长

2. 纯文本难以表达和解析结构化的数据

3. 推理能力较弱，需要通过 Prompt 引导

首先说上下文窗口长度不够的问题

每一次和 LLM 的交互，输入和输出的长度是有限制的，以 ChatGPT-4o 为例，上限是 32K Tokens，也就是输入和输出加起来大约是 2 万左右的汉字或英文单词，大约 50 页。看起来还不少，但是每次交互的上下文内容越多，生成质量会下降，成本也会急剧上升。就好比我们做阅读理解，一次阅读一小段文章和几页文章的效果是完全不一样的。

所以当你一次给 GPT 24 页的 PDF，并希望快速得到你想要的内容，这很可能超出了上下文窗口长度，或者说过长影响了生成效果。如果能减少输入的内容可能会效果更好一些。

然后就是文本格式的问题

现在大语言模型主要是以文本信息为主，像 GPT-4o 属于多模态，也就是还能支持图片、视频和音频。但是对于一些复杂的格式，比如图表、表格可能就效果没那么好了。

如果用户输入的是 PDF，那么通常会将 PDF 转换成纯文本，然后再进一步和大语言模型交互，这就意味着像化验结果这种包含图表、表格的数据，在转换成纯文本的过程中，会丢失很多有效信息，最终会影响生成结果。

即使后来通过复制粘贴再次输入，对于表格这样的数据，在复制粘贴的过程中，一样会丢失掉其格式，而一旦失去行列关系，大语言模型是很难从中解析出来有效的信息。

目前大语言模型有几种方案可以比较好的表达结构化的数据：

1. Markdown，Markdown 可以表达表格格式

2. JSON，JSON 支持数组、对象等复杂格式的表达

3. XML，XML 类似于 JSON，也能表达复杂的数据结构，只是冗余较多

4. 其他格式，例如 YAML、HTML、TypeScript 的 Type 等等

通常所有大语言模型对于 Markdown 都很友好，GPT 对于 JSON 支持更好，而 Claude 对 XML 支持更好

最后就是推理能力

所有复杂的任务都需要一定的推理能力，比如医生交代实习生：「抓取 4 个指标（白细胞、中性粒细胞、血红蛋白、C 反应蛋白），按照时间顺序排列」，实习生会将其拆分成若干个子任务：

1. 找到所有的指标信息

2. 过滤出其中的 4 个指标

3. 对结果排序

但是这个对于大语言模型来说，还很难，哪怕推理能力最强的 GPT-4（依然是比 GPT-4o、Claude 3 和 Gemini 更强），这任务也不一定能做得很好，但稍弱一些的模型几乎是做不到的。

不过，这类复杂的推理任务，如果借助提示工程，也就是在 Prompt 里面，把要求改一下：

「接下来你按照以下步骤帮我抓取指标信息，并打印每一步结果：

1. 列出所有 XXX 指标的信息，以 Markdown 的表格格式显示

2. 仅列出其中包含白细胞、中性粒细胞、血红蛋白、C 反应蛋白的指标信息，以表格格式显示

3. 对结果按照时间排序「

（根据需要 1-2 步也可以合并，但是打印第一步可以知道是否第一步就出错了）

这样的话，通常会更容易得到更好的结果，这其实也就是提示工程中的 CoT（思维链），也就是将复杂的任务拆分成一步步来执行。

上面列的三点，主要是从技术的角度来指出了问题，以及可能的改善方法。回头最开始医生使用 AI 来辅助查看报告这个应用场景，如果想能真正有用，有没有方法可以改善呢？

按照我的经验，是有一些事情可以做的，尤其是如果这是高频的应用场景的话，做好了可以极大的提升医生的效率，但需要做的却超出医生的控制范围，因为这可能需要整个医疗 IT 系统的升级。

现阶段的 AI 应用，还远没有达到 AGI （通用人工智能）的程度，需要从整个工作流上来配合，将 AI 作为整个工作流的重要一环，但是上游和下游有其他应用程序的配合。

首先是报告的输出格式，能输出 LLM 友好的格式，比如支持 Markdown 格式，将表格和图表都用 Markdown 通用格式表达，有利于 LLM 解析。

然后就是预先对报告内容分类，以减少上下文窗口大小，比如可以将医生关心的指标信息单独提取成 Markdown 表格，就不需要 LLM 大海捞针一样从整个报告去提取

再有就是对于 LLM 返回的格式可以有程序二次处理，比如说如果数据很多，让大语言排序其实是做不到的，但是结构化的数据让程序排序，反而很简单。

最后再总结以下：

LLM 擅长处理和生成文本，但是受限于上下文窗口长度，并且对于复杂的数据格式，需要用格式化的数据格式表达，并且要借助提示工程将复杂的任务进行拆解。

如果要用好 LLM，最好是充分利用 LLM 的长处，把一些高频的使用场景，但是原本不适合或者无法自动化的工作流的，借助 LLM 的文本处理能力，变成自动化的工作流。

方军：赞 //@你是少年呀：和最近教授教我们做文献综述的观点完全一样！ 1. 注意 token 数 2. 让 ai 分批输出效果会更好 3. 分步骤分步骤，让 ai 辅助的关键首先是自己明白工作流是什么，而不是无脑输出自己的问题，

另外和 ai 对话一个好处是你可以通过打字的方式缕清自己思路毕竟有的时候混沌状态有些人连问题都提不好

2024-06-02 13:46

### 06

方军 2024-06-02

有意思的体会：一个可能比较反直觉的情况。

从翻译这个行当诞生一直到现在，译者的工作性质没什么是指进化。发明电脑也好、CAT 工具也好，都没有在根本上简化译者的工作。如果说唐僧那种纸笔一个个字写的方式是原始人手工打制石头轮子，21 世纪的译者就是手工磨制石头轮子，旧石器时代到新石器时代，额外又发明了一些圆规之类可以提升产品质量但并没有减少弱智级笨劳力的玩意儿。

译者最大的敌人其实就是：

打字

工作中占时间最多的就是打字

导致肉体磨损最多的也是打字

产生人为错误最多的还是打字

直到大语言模型出现之前，哪怕再直白粗浅的套话废话口水话，也得一个个字打出来。之前的机翻引擎理解力太差，省不了多少工夫。

所以从 ChatGPT 发布以来这一年多我特别高兴，仿佛一个原始人忽然跨进了 21 世纪。大约六成笨活我指导 GPT 干（哪怕连续让它改五遍也比我自己从头到尾手打一遍省手省心），另外它从根源上杜绝了低级笔误，完工之后清场擦屁股省了很多力。擦屁股这个环节听着不重要，实际谁干活谁知道。三五万字的东西翻译到最后已经快要油尽灯枯了，根本没心思擦屁股。放着歇几天再擦吧，就更不想动手了。忍着疲惫强行硬擦结果就是擦不干净。一开始拉的时候就不脏腚最好了。

确实！体力劳动的部分大大减少了！[哈哈]

### 07

方军 2024-06-02





### 08

方军 2024-06-02





### 09

方军 2024-06-02





### 10

方军 2024-06-02





### 11

方军 2024-06-01





### 12

方军 2024-06-01





### 13

方军 2024-06-01





### 14

方军 2024-06-01





### 15

方军 2024-06-01





### 16

方军 2024-06-01





### 17

方军 2024-06-01





### 18

方军 2024-06-01





### 19

方军 2024-06-01





### 20

方军 2024-06-01





### 21

方军 2024-06-01





### 22

方军 2024-06-01





### 23

方军 2024-06-01





### 24

方军 2024-06-01





### 25

方军 2024-06-01





### 26

方军 2024-06-01





### 27

方军 2024-06-01





### 28

方军 2024-06-01





### 29

方军 2024-06-01





### 30

方军 2024-06-01





### 31

方军 2024-06-01





### 32

方军 2024-06-01





### 33

方军 2024-06-01





### 34

方军 2024-06-01





### 35

方军 2024-06-01





### 36

方军 2024-06-01





### 37

方军 2024-06-01





### 38

方军 2024-06-01





### 39

方军 2024-06-01





### 40

方军 2024-06-01





### 41

方军 2024-06-01





### 42

方军 2024-06-01





### 43

方军 2024-06-01





### 44

方军 2024-06-01





### 45

方军 2024-06-01





### 46

方军 2024-06-01





### 47

方军 2024-06-01





### 48

方军 2024-06-01





### 49

方军 2024-06-01





### 50

方军 2024-06-01





### 51

方军 2024-06-01





### 52

方军 2024-06-01





### 53

方军 2024-06-01





### 54

方军 2024-06-01





### 55

方军 2024-06-01





### 56

方军 2024-06-01





### 57

方军 2024-06-01





### 58

方军 2024-06-01





### 59

方军 2024-06-01





### 60

方军 2024-06-01





### 61

方军 2024-06-01





### 62

方军 2024-06-01





### 63

方军 2024-06-01





### 64

方军 2024-06-01





### 65

方军 2024-06-01





### 66

方军 2024-06-01





### 67

方军 2024-06-01





### 68

方军 2024-06-01





### 69

方军 2024-06-01





### 70

方军 2024-06-01





### 71

方军 2024-06-01





### 72

方军 2024-06-01





### 73

方军 2024-06-01





### 74

方军 2024-06-01





### 75

方军 2024-06-01





### 76

方军 2024-06-01





### 77

方军 2024-06-01





### 78

方军 2024-06-01





### 79

方军 2024-06-01





### 80

方军 2024-06-01





### 81

方军 2024-06-01





### 82

方军 2024-06-01





### 83

方军 2024-06-01





### 84

方军 2024-06-01





### 85

方军 2024-06-01





### 86

方军 2024-06-01





### 87

方军 2024-06-01





### 88

方军 2024-06-01





### 89

方军 2024-06-01





### 90

方军 2024-06-01





### 91

方军 2024-06-01





### 92

方军 2024-06-01





### 93

方军 2024-06-01





### 94

方军 2024-06-01





### 95

方军 2024-06-01





### 96

方军 2024-06-01





### 97

方军 2024-06-01





### 98

方军 2024-06-01





### 99

方军 2024-06-01





### 100

方军 2024-06-01





### 101

方军 2024-06-01





### 102

方军 2024-06-01





### 103

方军 2024-06-01





### 104

方军 2024-06-01





### 105

方军 2024-06-01





### 106

方军 2024-06-01





### 107

方军 2024-06-01





### 108

方军 2024-06-01





### 109

方军 2024-06-01





### 110

方军 2024-06-01





### 111

方军 2024-06-01





### 112

方军 2024-06-01





### 113

方军 2024-06-01





### 114

方军 2024-06-01





### 115

方军 2024-06-01





### 116

方军 2024-06-01





### 117

方军 2024-06-01





### 118

方军 2024-06-01





### 119

方军 2024-06-01





### 120

方军 2024-06-01





### 121

方军 2024-06-01





### 122

方军 2024-06-01





### 123

方军 2024-06-01





### 124

方军 2024-06-01





### 125

方军 2024-06-01





### 126

方军 2024-06-01





### 127

方军 2024-06-01





### 128

方军 2024-06-01





### 129

方军 2024-06-01





### 130

方军 2024-06-01





