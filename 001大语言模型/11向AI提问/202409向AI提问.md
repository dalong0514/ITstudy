### 01

方军 2024-09-01

看着一个比较厉害的家教博主发文，因为提到KIMI，转一下，讲实话，这些家教博主的阅读品味真是糟糕（当然也是中小学教育的问题）

【浅谈语文的整本书阅读】昨晚大女儿想让我帮她做校内的语文作业，文言文和古诗文部分她自己完成了，但是整本书阅读部分《童年》和《鲁滨逊漂流记》她压根没工夫读，也来不及读，也不想读，让我找kimi帮做一下。确实是，暑假压根没时间搞这些阅读，每周都有考试，数学和物理，等到这周三考完了，周末直接要去旅行了，旅行归来学校军训。哪还有时间搞整本书阅读？整个暑假能利用晨读的时间把文言文阅读和英文原版阅读给坚持下来就不错了。

所以最后还是得靠Kimi做学校作业。但是我告诉她，现在我可以让kimi帮你做，但是这两本书是中考必读科目，回来之后这两篇还是要完成，尽量读原著，实在没时间，就读邵鑫老师的精讲版本（博主上学的时候这两本也没看过原著，太枯燥了，读不下去）。

小朋友说可是这两本书太无趣了啊，为了中考，只能硬着头皮去读。我说这只是开胃菜，到了初升高的时候，你的语文阅读还会更无趣，上海这边初升高的暑假，就会开始两本整本书阅读，一本是费孝通的《乡土中国》，一本是《红楼梦》。到了高中阶段，再过度到刘擎老师的《现代西方哲学讲义》《做一个清醒的现代人》，余党绪的《说理与思辨》，那个你才会觉得是真枯燥。因为深度阅读本身就是一个非常难以习得的技能，可不比高联一试简单哦。

真的实在想偷懒，就从邵鑫老师的解读入手，因为老师会提供你一个视角。比如，《童年》是高尔基的苦难文学，你可以不经历苦难，但你不能不阅读别人的苦难，哪怕是许多年前人类的苦难。这个时候，小屁孩就开始打断我，觉得自己这代人不会经历苦难了，出生在最幸福的中国，最繁华的上海，每天都生活乐无边，刷题都不觉得苦。
…

只有阅读过苦难，阅读过他人的孤独，在自己面临困境的时候，才不会被情绪淹没，就会很冷静的接纳这些无可更改的现实，接纳，忍耐，看看找时机反击，对抗。我们人类就是这样进化过来的，而我们也必须保留这些生命的原始性。比如《鲁滨逊漂流记》，我和你爸爸在你没有出生前，每年都去边境自驾游，额尔古纳河，天山，独库公路，塔克拉玛干的沙漠公路，冰川，云南与缅甸交界处……只有阅读过冒险与孤独，才会在成年后有能力去对抗这些孤独。

小屁孩被我说服的似乎感觉有那么些道理，内心不那么抵触了。我知道她会读，哪怕为了中考和高考，但是我不希望她硬着头皮的去读，而是希望点一盏灯，引领着探索他人的文字，这些文字如同一条迷雾中的丛林，最终帮助她去构建自己的成长与独立人格的建立，在苦难与孤独来临时，不嘶吼，不对抗，如同几千年来我们人类所做的那样，迎接，拥抱，接纳，最终在苦难中进化，并改造这个世界。是“进化”让我们改造，并不是对抗，对抗只会被命运的洪流一个猛子给冲走。

### 02

方军 2024-09-02

Quote: In the GenAI era, I've come to realize this even more clearly: spoon-fed knowledge doesn't sit well. It's like indigestion. 

在生成式人工智能时代，我更加清楚地意识到这一点：填鸭式的知识并不合适。就像消化不良一样。



### 03

方军 2024-09-02

[两万字讲清楚：现在的AI产品有多难做？](https://mp.weixin.qq.com/s/pMt_VMs6uq5wsPPscOyefA)

点评：讲实话我对这个文章有另外的感慨，我其实有时候看着这几万字觉得很尴尬，它究竟在讲什么？我还没细看，但我直觉认为可能不需要这几万字。

文章目录：  

01 比起大模型产品，要更关注 API  
02 大模型可能永远都没法解决的问题
03 大模型目前工程上的难点
04 大模型未来可能会被解决的问题
05 从 RAG 角度理解大模型产品
06  从媒介角度理解大模型价值
07  为什么我们高估了大模型？
08  对产品经理的工作启示
09 几个 AI Agent 实践的建议

---

另外，最近不少人推荐 n8n

摘：就我自己来看，我认为 n8n 更靠谱。n8n 是一个 Coze 的开源免费上位替代，一个可视化低代码自动化 Workflow 平台，能够方便的让不会写代码的朋友体验 AI 开发的乐趣和效果。用它可以轻易的创建很多扣子完成不了的复杂自动化 Workflow。

比如 Webhook 触发，比如 1000 多种第三方接入，比如发起自定义的 HTTP Request。并且因为 n8n 不是从这一轮 AI 浪潮才开始做的，所以它的生态也比这一轮 AI 后才涌现出的 Workflow 工具（比如 Dify）更完善，官方接入的集成服务更多，社区更活跃。

n8n 就是大模型的五官、躯干和四肢，动手又动脑，才能有创造。在这里我推荐一个 n8n 的中文教程《简单易懂的现代魔法》，这应该是目前市面上最好的 n8n 中文教程。

教程地址：

[简单易懂的现代魔法 | 一个中文 n8n 学习社区](https://n8n.akashio.com/)

### 04

方军 2024-09-02

我发现，我有个常用的方法还是不错的，简单来说就是：

对相似的两个作品进行对比

各个领域都可以，尤其是如果是两个相似的，一个好点，一个差点，这种对比会有很不错的效果

比方说，得到有两本书：

《研究的方法》 vs 《笔记的方法》

笔记的方法相对要差得多，虽然看起来很实用，也符合得到的定位，但明显《研究》的两位学者更会用一种逻辑来组织自己的观点（深度也深得多）。

又比方说，最近在考虑怎么提问，看了一个可能点成功学的人的书，他前后写了两本：

《关键7问》vs《建议陷阱》

关键7问的结构非常明了，而建议陷阱基本上只有第二章有点价值，后面的有点拼凑。

我要把一个方法变得适合自己用的时候，我多半也是采取类似的思路。

比如，我最近一直在用所谓的「费曼空白笔记本」方法（这个方法就是把一个主题的大纲，也就是章、节放在一本本子里面，一页一个）。

这个方法怎么变得可用呢？

我就需要用它和别的方法去对比，然后逐渐地把这个方法用好。


### 05

方军 2024-09-02

又是两个特别长的文章（Podcast讨论）

[AI产品经理指南：我是谁，从哪来，到哪去｜对谈字节AI产品负责人Vanessa，面试了100位AI产品经理后的心得总结](https://mp.weixin.qq.com/s?__biz=MzAxMDMxOTI2NA==&mid=2649089748&idx=1&sn=be4da157f3de74d57cb44a1548824bf9&scene=21#wechat_redirect)

[AI 工程师指南：我是谁，从哪来，到哪去？｜对谈硅基流动创始人袁进辉与独立开发者 idoubi | BestBlogs](https://www.bestblogs.dev/article/41eb18)

### 06

方军 2024-09-02

很感慨，有这样一种现象，为什么那么多人从一本很差的书获得收益呢？我看到太多人说，这本书中的方法帮到了他。

在我看来，这本书略带荒谬感（我尽量避免直接透露这本书，毕竟太多人从中获得帮助了）。比如，它说，简洁是最重要的，但是，它的该节写法恰恰是最不简洁的。（我理解，简洁不是字少，简洁是一目了然，一看就明白，简洁也是把最重要的信息凸显出来，一眼看得见。）

我有一个略有愤世嫉俗的想法，或许，人们要的不过是一个方法名字。他们并不真正去用这个方法。

又或者，他们在获得了这个名字之后，实际上是从其他地方去获得了使用的方法。（但是，整个讨论里面的「双链笔记」思路，实际上我都是有着巨大的怀疑的。）

还有一种可能，其实作者就是讲了一些自己的方法，与这个名字之间的没有那么强的关联（作者自己讲的技巧、思考、实践很有意思。）

这本书我也的确读了第二遍，第二遍是挑着读的，插入的笔记纸（包括标注的笔记）可以说是相当多。我有着一个又一个的巨大疑问。

我能感受到荒谬，是因为我这次想知道，这个方法究竟怎么做？

补充：太多人从中获得帮助了，我自己也是。简单来说，它的核心是其所说的用自己的话重写的“永久笔记”（我没用过），以及这些笔记在卡片盒中产生的关联（我几乎采用完全相反的做法，工作性质决定的，我采用所谓从上而下的吸附法）。我学到的却不是这些，我学到的是它对于学术性写作（或许等同于阳志平老师说的认知写作）的逻辑，虽然它过于强调从下而上，而我采取完全相反的写法，但他的分析是非常有价值的。

希瑞：我理解吸附法可能更适用于已经有成熟框架的情形吧。如果是刚开始学习新知识，这个阶段从下而上可能更合适，因为我们需要先对一些实例有了直观感受，才能形成更抽象的概念和框架。通过多次迭代框架稳定了，后面整个知识体系就可以在这个基础上滚雪球了。
2024-09-05 09:30
方军 回复 希瑞：刚学习时尤其需要吸附这种方式

找一个这个领域被普遍接受的框架，用它来吸附
2024-09-05 09:44
方军 回复 希瑞：如果是探索完全全新的领域，即是做前沿研究

实际上大师会先做一个假设

然后这个假设可能被证伪

但这种框架都是非常重要的
2024-09-05 09:51



### 07

方军 2024-09-03

[ClassIn创始人瓜总：AI能够给教育带来什么？](https://mp.weixin.qq.com/s/T5p6lzmWng8VztG2btUq9A)


### 08

方军 2024-09-03


AI 帮我学到一个新知识：延异。（我偶然听说这个词，但不知道它的背景，看了才知道原来是德里达）

新的文本带来新的 文本，新的链接带来新的链接，这个用什么词描述？

（第一遍没答对）这种现象可以用“迭代”（iteration）这个词来描述，它意味着一个过程或事件重复发生，每次都可能带来新的内容或变化。在文本和链接的情境中，每次的重复都可能引入新的信息或连接。

延异，如何？

“延异”（differance）是法国哲学家雅克·德里达（Jacques Derrida）创造的一个术语，它是“差异”（difference）和“延迟”（deferral）的结合。在德里达的解构主义理论中，“延异”用来描述意义生成的过程，其中意义不是固定不变的，而是通过语言的不断差异和推迟来产生和变化的。

在文本和链接的情境中，如果使用“延异”这个词，它可能暗示了每次文本或链接的更新或变化都不仅仅是简单的重复，而是在原有基础上引入了新的差异，并且这种差异可能会随着时间的推移而进一步发展和变化，从而产生新的意义和理解。这个词强调了变化的连续性和动态性。

维基百科：

https://en.wikipedia.org/wiki/Diff%C3%A9rance

蛮好玩的，我稍后细看，看起来的确是个有意思的概念。


### 09

方军 2024-09-03

A scissor label is a word or phrase that, for the first time, establishes a widely embraced name for a trend without simultaneously establishing a canonical definition. It is a vague term masquerading as a specific one, where the missing definition is still up for grabs. Scissor labels aren't coined or engineered, nor formally initiated by an institution.
Rather, they're discovered by accident, suddenly adopted en masse amidst a trend that's already in motion.
Once a scissor label is established, controlling its definition means controlling whatever the trend represents. A scissor label therefore represents the battleground for a power struggle. By nature, scissor labels have a peculiar divisive power, building energy and momentum around a trend while simultaneously bringing about controversy and debate.

剪刀标签是一个词或短语，它首次为一种趋势建立了广泛接受的名称，但同时并未确立一个权威的定义。它是一个伪装成具体术语的模糊词语，其缺失的定义仍有待确定。剪刀标签不是人为创造或设计的，也不是由机构正式发起的。
相反，它们是被偶然发现的，在一个已经在进行中的趋势中突然被大规模采用。
一旦剪刀标签被确立，控制其定义就意味着控制该趋势所代表的一切。因此，剪刀标签代表了一场权力斗争的战场。按其本质，剪刀标签具有特殊的分裂力，它在为趋势积聚能量和势头的同时，也引发争议和辩论。



### 10

方军 2024-09-04


我一直在用的一个方法，估计也是很难得到响应，这么笨拙的方法：

如果一本书内容真的好，并且我真的需要把它吃透了，我会把它变成类似 PPT 的格式（并不会用 PPT 做，我用 Markdown 格式）。这是转换格式。

然后在它基础上反复地看（这是认知科学里面最反对的，你就是熟练了。但是，熟练不是必须的前提嘛）。

再然后，我会略作精简（会精简一些，但不会删掉太多）。

这里还有个特点是什么，这事真不能假手他人。

这事还有个特点，别人（我这样的别人）看本书不是两个小时，这本书看来看去花了20个小时。其实不止20个小时，对于真正重要的（不是它是经典、大部头，而是我可能有用），花200个小时又如何。

有时也有点挫折感，别人一下子就抓住重点了，而为何我要走这么多弯路才到终点？其实这无所谓了，站在终点，这种挫折感都是微风而已，最多打个颤。

这方法放在 AI 场景里也没人要听，他们都想要：让 AI 读！你给我一个摘要呗。


### 11

方军 2024-09-04

最近我为了保护眼睛，也常听 TTS 的书，这个听书和以前为了学英语听 audible 还不太一样，以前那不过是为了听个熟练。如下这个虽然是针对孩子的讨论，我觉得是一样的，听书就是浏览型阅读（检视阅读）吧，聊胜于无。真正有效的阅读还是《如何阅读一本书》里面说的分析型阅读，这种阅读不追求数量的，一本书多读几次。

我以为，AI 在阅读里面发挥作用也是在分析阅读，用它来协助进行疑点和难点的解释。什么总结个摘要之类的，咱们真想从书中获取知识、提升自己的，没必要自欺欺人。

摘（毛毛妈）：因为今天有两个家长跟我说了，孩子语文成绩不行，尤其是阅读和作文。从这两个家长的描述里，都提到了「孩子喜欢听故事」。

我讲一下，适当的听故事不能说是坏事，但是它一定不能代替阅读。

首先第一个原因就是听书很难形成沉淀。

家长想让孩子去听书、看书，无非就是希望形成沉淀。要么对成长有帮助，要么对语文学习有帮助，要么对写作文有帮助。

但是听书是很难形成这种有益的沉淀的。

因为听书得到的信息是一维的流通，是一个时间线，前面一句话说完了就没有了，是抓不住的，后面很快会再来一句话。孩子的思路要跟着音频的节奏走，没有时间去思考。

看书不一样，阅读当中，文字在书本上的呈现是二维的，你看到后面，随时都可以翻到前面来看。这就特别适合在阅读中去研究那些比较深的文本，比如说红楼梦、水浒传，前后照应又有一些巧思伏笔、草蛇灰线这些东西。你一定是反复翻看，看到后面，随时要翻到前面来回顾的。

如果说像红楼梦、水浒传这样伟大的小说，只靠听的话，你只能听一个故事情节，是没办法进行深度理解和审美的。更不用说，通过听书没办法去摘抄一些好词好句啊，段落和写作手法的分析啊之类的。

好书和好文章需要反复阅读，多次阅读，听书很难形成有益的沉淀。

第二个，听书对于孩子的阅读能力培养是不利的。​​​

为什么呢？听书其实是个偷懒的事，为什么那么多的孩子都喜欢听书，因为不用费劲，不用动脑子，把音频一打开，这个声音就会往耳朵里灌，被动接受就行了。

哪怕孩子有不懂的不理解的地方，听个一知半解，那也就听个热闹了，声音过去了也就过去了。

看书不一样，你得专注地坐在书桌前，一页一页的看，一行一行的看，一个字一个字的看，是比较辛苦的。而且看书的时候，如果遇到不懂的地方，遇到晦涩的地方，是需要好好的去琢磨思考，否则是没办法往后读的。

从阅读文字、提取信息、总结归纳和深度思考，阅读的习惯是通过兴趣引领慢慢养成的一个过程，不是先天就有。听书没法去培养这个过程。

所以很多孩子在童年时期过度的依赖于听书，对于文字阅读就懒了，不想去阅读。等他长大之后，阅读能力和阅读习惯没有培养起来，但不是所有书都是可以通过听去接收的。比如说文言文的书，光靠听是听不懂的。再比如数学书、物理书、化学书，等等，所有理科的书，靠听都没办法学习。

所以因为依赖听书而忽视了对于阅读能力的培养和提高，将来悔之晚矣。

### 12

方军 2024-09-04

这篇写得好啊，张的文字能力真是这些年畅销书作家里面的最高水平之一。

张佳玮：《西游记》改编得好不好，是一回事。
许不许改编，是另一回事。

我觉得《西游记》是中国所有古典小说里，最适合放开改编的——这本书本就是个大改编，揶揄当时已有的一切宏大设定，一整本轻盈的大玩笑。

玄奘西行取经，是历史上的真事，佛家传奇。好，那就安排一只猴子一只猪一个沙和尚，陪着玄奘去取经。
百姓崇奉的玉帝宝座？好，偏要让一只猴子来折腾，而且“皇帝轮流做明年到我家”。
雨神四海龙王？好，偏要让他们被个猴子搅得头昏脑涨。
大禹治水的定海神珍铁？好，偏要让这玩意变成个猴子用的铁棒。
道家孜孜以求成仙得道的金丹？好，就让猴子如吃炒豆一般吃了吧！
西王母与蟠桃，都是传说中的神品？好，就让猴子一口一个吃了玩吧！
天高高在上吧？圣人了不起吧？那就让一个猴子齐天大圣吧！
天上宫阙是玄妙难问的吧？好，那就让一只猴子去闹一闹！
唐僧一个志诚君子？好，那就让西梁女国国王和蝎子精，女追男，倒追着玄奘要成亲吧！
老子骑青牛出函谷关是道家传说？好，那就让青牛变成个妖怪，用金刚镯为害人间吧！
国王尊贵？生病要请御医？好，那就让猴子化作个医生，给朱紫国国王玩悬丝诊脉；再用锅底灰和马尿，给国王治病！
八十一难到了雷音寺，如来居然会替弟子们索要贿赂！
猪八戒够能吃，那就当净坛使者吧？
佛教道家、仙人神话，一切高尚的、认真的、严肃的、庄重的，都变成了猴子与猪的玩笑。

本来艰难庄严的旅途，一路变了游戏：这可以解释许多“为什么孙悟空不够强”的矛盾设定。孙悟空一路过去不是斗战胜，是解谜题变戏法，是“老孙的买卖上门了”，是一场大游戏。
车迟国，明明可以直接把三个妖怪打死，猴子偏要哄三个妖怪喝尿，跟人家比猜东西，比砍头下油锅。
没事就喜欢钻进铁扇公主、黄眉怪和狮子精的肚里，喜欢变成孩童去骗金鱼大王。
明明可以抢了小妖的葫芦，却要变成道士搞装天的把戏。也要变成总钻风，去骗小钻风。
他的法术，比如定身法、变化和瞌睡虫，都不是横扫八荒的破坏技，却是游移躲避的手法。
他被十万天兵围困，与二郎神大战，到最后也是玩变化：你变条鱼，我变只鸟，最后还变了个土地庙之类：大兵当前，玩捉迷藏。还跑去灌江口扮二郎，只为了说句便宜话，“这庙已姓孙了！”

我觉得最体现《西游记》精神的瞬间，是狮驼岭之役，师徒们被捉住，妖怪吩咐，要蒸和尚吃了：
“小的们，着五个打水，七个刷锅，十个烧火，二十个抬出铁笼来，把那四个和尚蒸熟，我兄弟们受用，各散一块儿与小的们吃，也教他个个长生。”
生死之际，猪八戒都慌了，孙悟空的反应却是：“不要怕，等我看他是雏儿妖精，是把势妖精。”
妖怪要蒸猪八戒，“不好蒸，剥了皮蒸。”
猪八戒赶紧嚷：“不要剥皮！粗自粗，汤响就烂了！”
老怪吩咐：“不好蒸的，安在底下一格。”孙悟空就说了：“八戒莫怕，是雏儿，不是把势。”
沙僧：“怎么认得？”
孙悟空：“大凡蒸东西，都从上边起。不好蒸的，安在上头一格，多烧把火，圆了气，就好了；若安在底下，就不好蒸了。”
性命交关时节，孙悟空还在讨论蒸东西该放最下格还是最上格？

整本《西游记》，充满了类似的文字游戏。猪八戒见了寿星都要玩梗，孙悟空当医生都要玩梗；妖怪和小妖，总是大惊小怪彼此斗嘴，就是背了妖精皮的山大王和喽啰。
比起《封神演义》一本正经的斗法斗阵，比起《三国演义》“鼎足三分浑如梦，后人凭吊空牢骚”，《西游记》轻盈得多。从头到尾，就是场“Tom哪怕追到了Jerry，大家也知道不会真有人死掉”的喜剧。

《西游记》最后一回，明说唐僧出发时是贞观十三年，十四年后归来，小说原文：
太宗笑道：“久劳远涉，今已贞观二十七年矣。”
——正史，贞观只有二十三年。

《西游记》的作者，不会不知道这细节：古代人对年号，尤其对唐朝贞观这种传奇朝代的年号，比我们习惯公元纪年的这代人，要敏感得多。
但还是这么写下来了，且全书出现过许多次唐僧的出发点，“贞观十三年”，如果想改，早就改了。
所以《西游记》本身是个半开源小说，尽可以放开编。三界六道，揶揄世情，悲欢离合，这里都有。整本书都在告诉你：
“可别太当真了！没什么是神圣的！这可是个猴子和猪都能取经都能成佛的、贞观都能有二十七年的虚构时空！”

方军：题外话，这些名著我们小时候真没认真看，反正我小时候的印象是租书看金庸和金庸新著，至少初中高中是这样的。

这些名著里面我后来算细看的是红楼梦，因为有蒋勋的讲座，就跟着他一讲一讲“看”完了，他不管岔开多少，还是把文本都仔仔细细讲了一遍。
2024-09-04 20:14




### 13

方军 2024-09-04

说说从《卡片笔记写作法》中学到的，用列表说，压力小点：

- 卢曼卡片的特点，是分了三种卡片（实际上是四种）：闪念卡片，随便记录；文献卡片，摘录；永久卡片，用自己话写；项目卡片，事务性的。

卢曼卡片的特点是「永久卡片」，用自己的话写了之后，作为之后研究与写作的资料，也在这些永久卡片之间建立关联。因此，卢曼卡片实际上有两个盒子：一个盒子是文献卡片，一个是永久卡片。

- 这本书中文书名叫「写作法」是高度合理的，英文书名叫 How to take smart notes，但的确作者讲的就是一件事，如何用永久卡片来构建一个收集资料、收集想法、组织想法、并最终把（主要是文科的）研究性文章写出来的「工作系统」。

这本书一共三章，第三章的六个步骤就是建议了这么一个系统：

步骤1：明确区分（写作中）独立而又相关联的任务
步骤2：阅读和理解
步骤3：记卡片盒笔记（写永久笔记）
步骤4：发展想法（组合想法）
步骤5：分享你的洞见（写出来最终文章）
步骤6：养成习惯——这一个有点弱，其实可去掉

- 作者主要推荐的就是写永久卡片、然后自下而上组织想法，他强烈反对计划、自上而下。但我的看法与他几乎彻底相反：

不管怎样，一开始还有要有一个框架，虽然知道这个框架可能有50%以上都要被废掉，甚至改得面目全非，但是，有一个框架，才可以「吸附」各种想法。（作者主要担心我们只吸引来支持自己的资料，而不去关注反对自己的资料。）

永久卡片的做法就是重用这些用自己的话重讲的内容，但我几乎不重用自己的内容。除了比如讲述别人的故事/案例，我可能会用下自己以前写的，其他时候我宁愿每次都从头开始。（至于永久笔记之前的闪念笔记，比如我记录在这个星球里面的一些，我则是根本不会考虑重看重用。）

- 这本书其实不应该视为卢曼卡片的书，虽然它的确讲了不少了，但更有价值的是作者对于（主要是文科研究性）写作的一些体会。这几年有点奇怪，其实我从来不需要写这样的文章，但看了好几个指南，包括《研究的方法》，还有乔丹·彼得森的 《课程论文写作指南》一文。这个作者的优点是，虽然他没有那么坦白、甚至有点掩饰，但他把写作的那种痛苦挣扎写出来了。——他当然是想说明，卢曼卡片系统可以用来帮忙，但他那种挣扎会让经过类似过程的人有同感的。

我虽然不写这类文章，但写任何一本书，实际上都是类似的经历。文学类写作的那些参考，比如《创作者的日常生活》其实对我们这种写一本书是没有多大启发的。（我一般有三种东西要写：1）书，2）PPT，3）代码，在某个层面上三者挺相似的。）



### 14

方军 2024-09-05

哈哈哈，摘：我现在关注知识图谱技术动态的心态完全是乐子人式的：我现在认为逻辑对于知识工程来说是一种美而无用的东西。
大会主持人说：现在请认为符号主义好的同志坐到会场右侧，请认为连接主义好的先生们坐到会场左侧。
我坐在中间，没有动。主持人问我：你为什么不选边站？
我说：我认为符号主义好，但是我平时只用连接主义。
主持人慌忙道：快请您来主席台跟我们一起赚大钱。



### 15

方军 2024-09-05


摘

a：严谨一点说是模型能力上限和使用者上限取最高者，目前AI水平模块能力达到中级，整体水平初级

b：我的看法是AI的能力，取决于使用人的上限，否则就是在交付一个自己也不知道是非对错的东西。

c：机器写的代码谁来负责确认是正确的？出了问题找谁？AI现阶段就是生产力工具而已


### 16

方军 2024-09-05

当答案变得唾手可得

真正有价值的反而是提出问题的能力

—— 凯文凯利

KK 的确善于表达趋势：

凯文·凯利在开幕主论坛上发表演讲：当人工智能深刻影响经济和文化时，将涌现三大趋势！

AI 时代三大趋势：

1、全球主义：

全球正在共同构建一个基于技术的「超级有机体」，将全球的设备连接成巨大的计算系统，所有数字技术包括人工智能都运行在这个新平台上。

全球主义推进推动了新兴的全球文化，人们的生活方式和穿着逐渐趋同，底层需求达成一致。

人工智能将实现真正的「实时翻译」，打破全球语言障碍，加上增强现实（VR）技术，全球化「劳动力」将第一次出现。

2、创新加速：

AI 技术加速了创新的步伐，体现在新发明和新思想传播速度加快，通过增强现实（AR）和虚拟现实（VR）技术提高学习效率，AI 通过机器及其他传感器感知世界，以及 ChatGPT 等人工智能工具加快人们学习速度。

当答案易得时，提出正确问题和掌握正确思维方式变得更有价值，「学会如何学习」将成为未来毕业生的核心技能。

3、AI 驱动生成：

人工智能能帮助人们摆脱机械、枯燥的工作，完成无法独立完成的任务，甚至生成超乎人类想象的全新事物。

人工智能系统正在生成新事物且不断完善，人工智能是多样的，将填补许多智能领域。

从人工智能工具中获益最多的是表现一般或较差的员工，人工智能工具能帮助他们更好地完成工作。

回答中国网友提问：

对于人工智能是不是人类的下一个进化阶段，凯文·凯利给出肯定答案，认为其重要性不亚于火、印刷术和工业革命，但实现需要至少一个世纪甚至更长时间，人类正在通过人工智能重塑文明，创造人造「外星人」并引入新思想和文化。

为确保人工智能带来有益未来且不加剧不平等，应利用技术引导其发展，推动其开源化，形成更具包容性的技术生态系统。

未来几乎所有工作都会使用人工智能，但不会被完全取代。


### 17

方军 2024-09-05

129 用纸笔与 AI 搭配

我有个小小的习惯，最近总要准备分享题目，我会拿张纸写与改，然后录入在微信里转交别人，如图所示。

这一行字直接用手机写也不是不行，很明显纸与笔的效果要好很多。

对应地，我也有一个使用 AI 的体会，AI 很强大，但也别过分依赖，现在反而有了更多场景需要纸笔处理。

1. 我们虽可以随时问，但累积点一起问更好

这在编程应用上很明显，因为现在应该有不少人已经形成在编辑器不断问的习惯。

始终在与他人（AI）讨论，可能会造成思路的极度混乱。

思考和让 AI 做，还是要分开。有些任务，在纸上做可能会效果更好，比方说思考流程。

2. 核心内容要仔细看，尤其是几个核心概念的关系

AI 不管是写代码，还是回答问题，还是写文字，都能一下子“吐出”很多相对正确的内容出来。

这些内容的冗余度通常有点高，但这还不是主要问题。大麻烦是，其中可能有大逻辑错误。

我现在的体会是，很多错漏在电脑屏幕上都看不出来。我总是要把几个关键点打印出来，然后仔细地考虑一番。

3.  用好打印出来的纲要

可能跟我的个人习惯有关，我比较重视大纲/结构，而在使用 AI 之后，我更需要随时手边有一个一个事务/领域的打印出来的大纲。

大纲让我有整体感，因而可以不断地「指挥」 AI 员工干活。

我同时也会在大纲上做些标记，因此也用它做进度跟踪表。

这几天一直写个短文介绍费曼空白笔记本方法，也就是把大纲/概念点铺到一本空白本子里面的做法，像一本书的章节一页，一页一个点/词。它背后的逻辑是相似的，除了抓住纲要之外，也是让无形的东西用有形的东西撑起来。

有了 AI 之后，这个方法我又用了好几回（也是恰好要学东西），相互搭配用起来很好，并且现在更放心把本子留白着了。



### 18

方军 2024-09-06

真是各种古怪的「奇思妙想」/「异想天开」

这玩意作个实验不是不可以，但是，人要记录这些干嘛，还要把它们变成（空洞的）文字记下来。

阮一峰：看到一个项目，AI 写个人传记。

[The Infinite Audio Book](https://www.lampysecurity.com/post/the-infinite-audio-book)

作者用树莓派 + 摄像头，做了一个随身装置（图一）。你把它戴在身上，每隔一段时间，它会对周围环境自动拍照。

然后，它把照片发送给 OpenAI，生成一段描述。只要这些照片和描述，按时间顺序连起来，就是你的个人传记，好像一部电影一样。

我就随便找了一张上海的街景照片（图二），按照它的提示词，试了一下。

AI 返回的结果还真的很像传记（图三）。我觉得，这个用法有很大的想象空间，用户的每一天都可以变成文字记录的故事了。

[科技爱好者周刊（第 316 期）：你一生的故事 - 阮一峰的网络日志](https://ruanyifeng.com/blog/2024/09/weekly-issue-316.html)

### 19

方军 2024-09-06

摘：“一个孩子借助 GPT 等技术工具，再加上专业人士的协助，就能炮制出连行业巨擘都难以验证的骗局，那么真实信息的获取成本将愈加高昂，而其传播也会变得更加困难。” 

这种事其实已经在发生了，大部分人并没有专业的知识或精力去验证一个骗局。



### 20

方军 2024-09-06


Ethan Mollick 推荐的论文

The Effects of Generative AI on High Skilled Work: Evidence from Three Field Experiments with Software Developers
22 Pages Posted: 5 Sep 2024

[The Effects of Generative AI on High Skilled Work: Evidence from Three Field Experiments with Software Developers by Zheyuan (Kevin) Cui, Mert Demirer, Sonia Jaffe, Leon Musolff, Sida Peng, Tobias Salz :: SSRN](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4945566)

Zheyuan (Kevin) Cui
Princeton University - Bendheim Center for Finance
Mert Demirer
Massachusetts Institute of Technology (MIT)
Sonia Jaffe
Microsoft Research
Leon Musolff
University of Pennsylvania - Business & Public Policy Department
Sida Peng
Microsoft Corporation
Tobias Salz
Massachusetts Institute of Technology (MIT); National Bureau of Economic Research (NBER)
Date Written: September 03, 2024

（此推荐为 AI 翻译）：我一直在等待的大论文：人工智能对程序员生产力的真正影响是什么？

这是一项使用较旧、功能较弱的由 GPT-3.5 驱动的 Github Copilot 对财富 100 强公司的 4867 名程序员进行的随机对照试验。

它发现已完成任务增加了 26.08%。


### 21

方军 2024-09-06

发现知乎给站内文章加了无数的「知乎直答」链接，产品还不错，但真是相当困扰

[知乎直答](https://zhida.zhihu.com/)

知乎真是一个有实力、又奇怪的组织

### 22

方军 2024-09-06


这一周对卡片感兴趣，再翻看下这本书，原来京大型卡片那么大啊

但想想是合理的，小卡上写不了几个字

当然，我们现在再看这些要考虑原理，不要考虑形式了，现在没多少人用手写卡了吧

反正我的书写早就是A4 格式，因为A4 纸张最易获得，至于说自己印某种特色稿纸，我们这些人应该都没有体会过

另有一个细节，这是一本原出版于1969年的书，比很多人的父母年纪都大


### 23

方军 2024-09-06

【男子常年用AI做音乐大赚千万美金被控欺诈】 -- FBI把这哥们抓了，然后起诉了，你怎么看？原文在新乡时报，以下纯机翻：

检察官表示，一名北卡罗来纳州男子利用人工智能创作了数十万首假乐队假歌曲，然后将其上传到流媒体服务，供假听众欣赏。

他们指控他欺诈时说，他一点一点地捞了非常真实的1000万美元。

这名男子名叫迈克尔·史密斯(Michael Smith)，现年52岁，在周三公布的联邦起诉书中被指控在七年内从数字流媒体平台窃取版税。起诉书称，史密斯先生是一位活的音乐家，他制作了人工智能生成的音乐，并使用他编写的机器人播放了数十亿次。

根据起诉书，这些所谓的艺术家分别取名为“Callous Post”、“Calorie Screams”和“Calvinistic Dust”，他们制作的音乐包括“Zygotic Washstands”、“Zymotechnical”和“Zygophyllum”，在亚马逊音乐、苹果音乐和Spotify上表现优异。

“史密斯窃取了本应支付给音乐家、词曲作者和其他合法流媒体歌曲权利持有人的数百万美元版税，"美国纽约南区检察官达米安·威廉姆斯(Damian Williams)在周三的一份声明中说。

史密斯先生于周三被捕，面临包括电汇欺诈和洗钱阴谋在内的指控。如果罪名成立，他每项罪名最多可被判处20年监禁。

周三，史密斯先生的律师身份尚未确定。史密斯先生在夏洛特附近北卡罗来纳州科尼利厄斯市登记的电话无法接通。

这是威廉姆斯办公室起诉的第一起涉及音乐流媒体操纵的刑事案件。尽管流媒体公司为艺术家提供的报酬微不足道，但越来越多的艺术家越来越依赖演唱会来赚钱，因此，数字收听量越来越成为衡量行业商业成功与否的标准。

但现代流行音乐已经高度数字化，艺术家们使用电脑来制作哔哔声、嘟嘟声和节拍，并弥补他们歌声中的瑕疵。粉丝们不再需要携带笨重的黑胶唱片或易损坏的盒式磁带，而是通过一串零和一的短暂文件来接收声音。

检察官表示，史密斯先生几乎完全摒弃了人为因素。

他们说，他的计划涉及一个循环过程。首先，史密斯先生使用他在网上购买的电子邮件地址创建了数千个虚假的流媒体账户。他拥有多达1万个账户，甚至在创建账户的工作变得过于繁重时，将任务外包给付费的同谋者。

检察官称，他随后创建了软件，在不同电脑上循环播放他的音乐，从而营造出听众来自不同地方的感觉。

根据他于2017年(检察官称他开始实施该计划的那一年)给自己发送的财务明细，史密斯先生计算出他每天可以播放他的歌曲661440次。他估计，按照这个速度，他每天可以带来3307.20美元的版税收入，一年可达120万美元。

检察官表示，为了逃避流媒体平台的检测，史密斯先生将他的活动分散到大量假歌曲中，从不重复播放同一首作品。

检察官表示，史密斯先生最初将自己创作的歌曲上传到这些平台，但在发现自己的曲目太少，无法产生任何实际收益后，他试图增加自己能够访问的歌曲数量。首先，他使用了一个音乐宣传员的目录，后来他试图向其他音乐家出售他的服务，这些音乐家会付钱让他播放他们的音乐，或者在他播放时支付一部分版税。检察官表示，这两个计划都失败了。

检察官称，2018年，史密斯先生与机器人合作。

他与一家人工智能音乐公司的首席执行官和一名音乐推广人联手，制作了数量惊人的假歌，每周向流媒体平台上传数千首。

“请记住我们在这里做的音乐，“史密斯先生在2019年给人工智能高管的电子邮件中写道，”这不是'音乐'，而是'即时音乐'。”

史密斯先生收到的乐曲文件名是“n_7a2b2d74-1621-4385-895d-ble4af78d860.mp3”。然后，他为这些歌曲和艺术家取了看似合理的名字:“Zygopteris”、“Zygopteron”、“Zygopterous”、“Zygosporic”等等。

在这个世界上，有名为Dirty Projectors、Neutral Milk Hotel和Sunn 0)))的真实乐队，有《Yankee Hotel Foxtrot》这样的真实专辑，有《MMMBop》这样的真实歌曲，这些标题并不突出。

起诉书称，截至2019年6月，史密斯先生每月收入约为11万美元，其中一部分给了同伙。在今年2月的一封电子邮件中，史密斯先生吹嘘说，自2019年以来，他的流媒体播放量已达到40亿次，版税收入达到1200万美元。

检察官表示，史密斯先生对音乐发行公司公然撒了谎。2018年10月，一家公司告知史密斯先生，他们收到了“多起关于流媒体滥用的报告”，并计划从所有商店下架他的歌曲。
起诉书称，史密斯先生对此做出了措辞强烈的否认:

“这绝对是错误的，也是疯狂的！“，他说，”绝对没有欺诈行为！我该如何上诉?”



### 24

方军 2024-09-06


Cursor 的超长访谈

[Cursor创始人万字访谈：全球爆火的AI编程应用，真正找到PMF](https://mp.weixin.qq.com/s/2tZUH3hjKpB3L34okjio0A)

元宝的总结（删节数个大条目）：

Cursor公司的创始人Aman Sanger的创业思考、技术发展以及未来展望。

1. Cursor的出发点：
   - 重新设计软件开发流程：Cursor的初衷是彻底重新设计软件开发的流程和用户体验，不仅仅是自动补全代码。
   - GPT-4的早期体验：Cursor团队在GPT-4发布前提前体验了该模型，发现其在编程方面的潜力巨大。
   - 未来展望：Aman Sanger认为未来的AI模型在编程方面会更加强大，需要重新设计整个IDE和软件开发方式。

2. 技术实现与工具选择：
   - GPT-4的使用：Cursor团队利用GPT-4进行代码生成、重构和调试，效果显著。
   - 对Copilot的看法：虽然Copilot有用，但其功能有限，无法满足更复杂的编程需求。
   - 开发自己的IDE：Aman Sanger认为开发自己的IDE可以提供更灵活和强大的功能，避免平台风险。

3. 创业历程与团队背景：
...

4. 产品功能与用户体验：
   - 内联编辑功能：Cursor允许用户通过快捷键进行修改和生成代码，提升了用户体验。
   - 未来的功能规划：团队正在开发更多功能，如代码补全下一行或接下来几行代码，进一步提升编程效率。

5. 行业洞察与未来趋势：
   - 对AI编程应用的看法：Aman Sanger认为Cursor和其他AI编程应用正在改变软件开发的方式。
   - AI技术的未来发展：Aman Sanger预测未来的AI技术会更加强大，重新定义软件开发的方式。


### 25

方军 2024-09-06


近有个感悟，别被各种刺激的语言影响了看法

其实我觉得腾讯元宝不错啊，因而对它背后的混元模型印象不错（也没觉得多好，但肯定不错）

但总是会想起来一个人说的，混云模型在腾讯内部，狗都不用。（注意！这个观点是错误的，故意用极其刺激、恶心的词汇来影响我们的看法。）

这种社会语言现象真是很糟糕，但我们不能怪社会，只能自己尽量控制它们的负面影响。



### 26

方军 2024-09-06

最近是有3篇prompt的综述非常出名：

The Prompt Report: A Systematic Survey of Prompting Techniques

A Systematic Survey of Prompt Engineering in Large Language Models: Techniques and Applications

A Survey of Prompt Engineering Methods in Large Language Models for Different NLP Tasks

[prompt综述的解释和个人思考](https://mp.weixin.qq.com/s/7wzQxk7X1zg5U8QWY59uBw?v_p=90&WBAPIAnalysisOriUICodes=10000001&launchid=default&wm=3333_2001&aid=01A0VjFEC-8TX6msntzx_IZJsVSdIBL5NqzASu9SjrmTcS5LA.&from=10E9093010)

### 27

方军 2024-09-06


《重新学会学习》的导言我觉得写得蛮好的

\## 指南针 > 地图
\## 刺猬 > 狐狸
\## 苹果树 > 苹果
\## 开车 > 走路
\## 心灵 > 大脑

[赠书 | AI时代，如何重新学会学习？](https://mp.weixin.qq.com/s/LBM_ypTHE2uiDvyNNPu4gg)

### 28

方军 2024-09-07

哈哈哈哈，这篇究竟是不是AI写的？（不过的确这一类文字的价值被AI摧毁了，即便人能写，但AI能编写一个80%水平的，普通人分辨不出来）—对普通人来说，分辨能力的确很重要，怎么分辨呢？我觉得从源头开始，可疑的来源、可疑的人、看着可疑的，先忽略，把住输入的质量。讲实话，如果不是宝玉写这段，我是不会看的。

宝玉的回应：文字的价值不在于文笔或者字数，在于自己的观点和洞察，你说的80%只是文字数量，如果你先列出自己的观点AI能帮你扩充剩余80%的字，那依旧是你自己的洞察，但如果你没有引导只是让AI写，它没有真正自己的观点，只有概率下的预测生成。

我：其实很有意思，我发现越一本正经写，越容易被人当AI，我这种偶尔瞎说八道，不会令人产生这种猜测

我的感慨还有，这样的东西总会激发讨论，甚至我也会参与，这是因为它表面，还是因为它基础？

或许，表面与基础，是一体两面的。基础的东西，总可以用所有普通人能懂的方式讲明白。

宝玉（他说AI含量为0）：

现在不懂软件开发的人对 AI 是普遍乐观的，认为 AI 很快就要替代程序员了，而程序员群体作为最了解开发最常使用 AI 的群体怎么反而大多数认为这些工具无法替代人类程序员的角色呢？

**首先现在的成功案例，都是偏向原型性质的、简单的产品，离真正的复杂商用产品还是有一段距离。**原型产品的特点就是不需要考虑后期维护，不需要考虑各种使用场景，满足特定场景的演示、验证需求即可。但程序员们日常实施的项目，需要在保障各种不同使用场景下的稳定运行，以及对复杂庞大的代码库长期维护。

**然后 AI 目前还只能生成代码，而在软件工程中，编码只是软件生命周期的一部分。**程序员的日常工作，还有很多编码之外的工作，比如需要和产品经理反复沟通确认需求，基于需求去设计合理的架构，将复杂的架构拆分成小的模块并保证模块之间可以正常通信，需要对结果进行反复测试，发现 Bug 要去跟踪和修复，开发完成还要部署到线上去运行。

**最后受限于 AI 的上下文窗口长度，AI 还不具备大项目的代码开发和管理能力。**当前 AI 都有上下文窗口长度限制，也就是说每次和 AI 的交互，内容不能太长，也不能生成太长的代码，这就意味着你无法把整个代码库都扔给 AI，只能是每次选取一部分代码，加上提示词一起交给 AI 生成，所以在让 AI 生成代码时，仍然要程序员去把复杂的需求拆分成简单的模块，仍然需要手动去选取最相关的代码供 AI 参考。

所以现在说 AI 能替代程序员还为时尚早，但是善于使用 AI 的程序员一定能大幅提升效率，甚至于不懂写程序的人借助 AI 的帮助作出原型类产品也是完全有可能的。除此之外，现在的 AI 本身是一个极好的知识库，通过和 AI 的交互，我们还可以让 AI 成为我们的导师，帮助我们学习各种开发上知识，解答开发中遇到的难题，快速提升自己。

刘群点评：是的，我前面说过，让AI帮人编程序，类似于“哄机器”，“哄机器”并不比“哄人”更容易。想一想，“哄人”容易吗？我们的日常工作，不就是“哄领导”、“哄老公老婆”、“哄孩子”、“哄客户“、“哄考官”、“哄评委”，哪个都不需要懂编程，又有哪一件事容易了？用AI编程，虽然也许你不需要记忆大量的编程语言的语法和库函数细节，但你需要用自然语言把你想做的每一件事情的细节告诉AI，让AI帮你写出程序，写错了你还要检查，告诉AI怎么改，听上去一点也不比辅导孩子写作业容易吧？

宝玉：由于昨天我一篇微博 Sina Visitor System 用了Markdown，以及GPT惯用的“首先、然后、最后”句式，让人误以为我是用GPT生成的，其实都是自己写的，只不过摘录的是我给CSDN写的一篇稿子的片段。

不过我尝试了一下把第一段的提问分别发给GPT-4o、GPT-4、Claude，看生成的如何！

Prompt：
现在不懂软件开发的人对 AI 是普遍乐观的，认为 AI 很快就要替代程序员了，而程序员群体作为最了解开发最常使用 AI 的群体怎么反而大多数认为这些工具无法替代人类程序员的角色呢？

***
GPT-4o 生成：

这是一个非常有趣的问题，实际上可以从多个角度来解释为什么程序员和普通人对 AI 替代程序员的看法存在差异。这里是一些关键原因：

1. 程序员更了解 AI 的局限性
程序员作为开发和使用 AI 技术的人，深入了解 AI 的实际能力和局限性。当前的 AI 工具（例如 GPT-4 或 Copilot 等代码生成工具）虽然能够帮助程序员编写代码或自动生成一些简单的代码片段，但它们的局限性也非常明显：

- 上下文理解不足：AI 在理解复杂的项目上下文、业务逻辑或系统架构时，能力有限。它擅长处理局部问题，但难以管理大规模复杂系统的整体设计。
- 缺乏创造性思维：编程不仅仅是将代码堆砌起来，程序员需要根据项目需求做出创造性的选择，解决棘手的问题，而 AI 目前在这方面还无法胜任。
- 调试和修复问题：生成代码容易，但调试和修复复杂问题需要深厚的领域知识和思维能力，这是现阶段的 AI 工具难以处理的。

2. AI 是一个辅助工具，而不是独立工作者
现有的 AI 编程工具，如 GitHub Copilot 或其他类似工具，实际上主要是用来提升程序员的生产力，而不是完全替代程序员。它们可以帮助编写重复性代码或生成常见的代码模式，但仍然需要程序员来验证、修改和优化生成的代码。这意味着 AI 更像是程序员的助手，而不是替代者。

3. 软件开发是一个复杂的社会-技术活动
软件开发不仅仅是编写代码，还涉及到需求分析、系统设计、架构决策、团队协作、与利益相关者沟通、项目管理等。程序员不仅要写代码，还需要与人打交道，理解业务需求并将其转化为技术解决方案。AI 在这些涉及人类认知、社会动态和沟通的环节上依然远远落后。

4. AI 在编程中的应用仍处于初期阶段
程序员清楚地知道 AI 技术在编程中的应用还处于相对早期的阶段。尽管有了显著进步，但 AI 生成的代码往往需要大量的人工干预和修改，尤其在涉及到复杂、定制化系统时。程序员知道，AI 目前可以显著提高效率，但距离完全替代还非常遥远。

5. 程序员理解编程的长期演变
许多程序员意识到，编程技术和工具始终在不断演变，编程方式在过去几十年间已经发生了巨大变化。但即便如此，真正的开发者依然在工作。每次新技术的引入（如高级编程语言、自动化测试工具、IDE 的引入）都会改变程序员的日常工作，但这些技术的核心是让程序员的工作变得更加高效，而不是完全消除编程的需求。

6. 大众对 AI 的过度乐观预期
普通大众由于缺乏对 AI 技术的深入理解，可能会对 AI 的能力产生一些不切实际的期待。媒体和宣传经常过度渲染 AI 的潜力，使得很多人认为 AI 即将全面接管很多领域的工作。对于不熟悉软件开发的人来说，编程可能看起来就是一些复杂的指令，而 AI 能够生成指令，这让他们错误地认为 AI 很快会替代程序员。

结论

总的来说，程序员对 AI 目前的局限性有更深刻的理解，知道编程不仅仅是简单的代码生成，而是包含了很多复杂的思维过程、团队协作和创造性解决问题的能力。虽然 AI 确实可以提高效率，但它短期内很难完全替代程序员的角色。 AI 更多的是作为一种强大的工具，来帮助程序员完成工作，而不是取代他们。

***

GPT-4 生成：

关于 AI 是否能够替代程序员的问题，实际上涉及到对 AI 技术的理解以及编程工作的复杂性的认识。

1. AI 技术的局限性：尽管 AI 在自动化编程的某些方面取得了显著进展（如代码生成、错误检测等），但它仍然存在局限性。AI 模型通常依赖于大量的数据进行训练，并在特定的、已知的范围内表现良好。然而，软件开发不仅包括编写代码，还涉及需求分析、设计、项目管理和用户交互等方面，这些方面需要深刻的业务理解和人类情感的参与，这是目前的 AI 还难以完全掌握的。

2. 程序员的工作内容：程序员的工作不仅仅是编写代码，还包括了解和定义问题、设计解决方案、处理复杂和动态的需求变更以及优化用户体验等。这些任务往往需要创造性思维、战略规划和人际沟通，这些是 AI 目前还难以全面胜任的。

3. 工具的辅助性质：大多数程序员认为 AI 和相关的开发工具更像是助手而不是替代者。这些工具可以提高生产效率，帮助程序员自动化一些重复性的编码任务，减少人为错误，但在需求理解和创新解决方案的开发方面，人类的作用仍然是不可替代的。

4. 对新技术的看法：不懂软件开发的人可能会因为 AI 在特定任务上的出色表现而过于乐观，认为 AI 的能力可以无限扩展。而熟悉技术的程序员更能理解 AI 的工作原理和限制，因此他们的看法通常更为现实和客观。

综上所述，虽然 AI 在软件开发领域将持续发挥越来越重要的角色，但它目前和在可预见的未来内，更多的是作为人类智能的延伸和辅助，而不是完全的替代。程序员群体的这种看法反映了他们对技术的深刻理解和实际应用的经验。

***

Claude 3.5 Sonnet 生成：

这是一个很有趣的现象。程序员对AI取代人类的看法相对谨慎,主要有以下几个原因:

1. 深入了解AI的局限性:程序员更清楚地知道当前AI技术的能力和局限。他们理解AI在特定任务上表现出色,但在创造性、抽象思维和复杂问题解决方面仍有不足。

2. 软件开发的复杂性:开发过程涉及需求分析、系统设计、代码实现、测试等多个环节,需要综合考虑业务逻辑、用户体验、性能优化等因素。这种复杂性使得完全自动化变得困难。

3. 人机协作的经验:程序员日常使用AI辅助工具,更能体会到AI是增强人类能力的工具,而非完全替代。

4. 创新和问题解决能力:高质量的软件开发需要创新思维和解决前所未有的问题的能力,这些仍然是人类的强项。

5. 沟通和协作的重要性:软件开发通常是团队合作的结果,需要与客户、同事和其他利益相关者进行有效沟通。这种社交和协作能力是AI难以完全模仿的。

6. 对技术的适应性:程序员习惯于不断学习新技术,他们相信即使AI发展,人类也能够适应并找到新的角色。

7. 道德和责任问题:软件开发涉及道德决策和责任承担,这些方面目前仍然需要人类的参与。

总的来说,程序员认为AI是强大的辅助工具,能够提高生产力,但难以在短期内完全取代人类在软件开发中的核心角色。他们预见的更可能是人机协作的模式,而不是完全替代。

如果您想进一步讨论这个话题,我可以更深入地分析某些具体方面。您对哪一点特别感兴趣?

方军：一个有意思的例子

@渔多多2018:这个问题用一个简单的例子来比较，我们公司园区有个无人智慧超市(便利店)，出门结账用支付宝刷脸支付。我进去过一次，很多商品有灰尘，陈列比任何一个有人便利店都要差，还有些商品过期了。就饮料来说也缺很多常规品种。里面还有尿骚味，没有顾客。这是把营业员工作简单抽象成收银员，无人化替代。
2024-09-07 12:34




### 29

方军 2024-09-07

专业服务的费用现在的确是昂贵的：

在美国，一部分 Canva Teams 用户报告称，其订阅费已经 从每年 120 美元（最多 5 个用户）上涨至每年 500 美元，幅度令人咋舌。更新后的前 12 个月将享受 40% 的折扣，因此实际价格为 300 美元。在澳大利亚，五名用户每月订阅费为 39.99 澳元（约合 26 美元）的固定费率，也将调整为每位用户 13.50 澳元（约合 9 美元）。也就是说同样的五人团队，至少要多付 68% 的订阅费用而且没有任何折扣。

[订阅费超普通人月薪！一个月1.4万人民币，谁还用得起大模型？](https://mp.weixin.qq.com/s/2jE-bvUJeMdKq-C6cNjTVQ)

### 30

方军 2024-09-07


20多页的演讲稿，并且一半是出版时的配图吧，信息真是丰富，我觉得吧，AI生成的信息真是要少看，不把握好这个度，我觉得想有点见识、知识、文化、修养的人，在各种AI生成的垃圾包围的时代，会很难。

（另附注事后有增添，不知增添了多少？ 书后一章是一个此文更多的补充《漫长的补记》）

作者陈丹青，我很喜欢他的文章，但公平说，他讨论专业是超赞，开始发专业之外的感慨时，其实也就是一个普通人，总之他是个有意思的人。


### 31

方军 2024-09-07

[长文本分块的新策略——后期分块（Late Chunking），让RAG应用"又准又高效"](https://mp.weixin.qq.com/s/tT0ySo1NBRBTpXL2qCME_w)

没特别明白，但看着好像很特别（不过已经不是RAG的概念了）

而“后期分块”方法首先将嵌入模型的转换层应用于整个文本或尽可能多的文本。这为文本中的每个标记生成了一个包含整个文本信息的向量表示序列。随后，对这个标记向量序列的每一部分应用平均池化，产生考虑整个文本上下文的每个部分的嵌入。与生成独立同分布（i.i.d.）分块嵌入的简单编码方法不同，后期分块创建了一组分块嵌入，其中每个嵌入都“依赖于”之前的嵌入，从而为每个分块编码了更多的上下文信息。



### 32

方军 2024-09-07

刚才写了几句，然后又删掉了，重写简单写一句：看书的最大教训是什么？

我觉得最大的教训是，看到朋友师长看什么，也就看。结果在有些书上浪费太多时间。有些真不一定看得懂，比如我就不明白当时看《传习录》的时间有价值吗？现在还有什么收益吗？

排第二的教训是，有些书没有看足，其实这些书如果当时纳入精读，看个十遍，并做笔记，某些领域的基础会更好。

其他的就不多说了。出版业是一个工业，爱推荐书的人也是一个倾向，同时我们爱看周围人爱看的又是一个自我倾向，叠加起来浪费太多时间精力。

希瑞：最近在《人工智能时代与人类未来》看到这么一段: “信息不是不言自明的，而是依赖于情境的。信息要想有用处或至少有意义，就必须通过文化和历史的视角来加以理解。当信息被情境化时，他就变成了知识。当知识令人信服时，它就变成了智慧。” 阅读也需要情境，否则无处“吸附”。
2024-09-10 13:07


### 33

方军 2024-09-08

构建一个生成式人工智能平台

Chip Huyen

摘（为 AI 翻译）：在研究了公司如何部署生成式人工智能应用程序之后，我注意到他们的平台有许多相似之处。这篇文章概述了生成式人工智能平台的常见组件、它们的作用以及它们是如何实现的。我尽力使架构保持通用，但某些应用程序可能会有所偏离。这就是整体架构的样子。

[Building A Generative AI Platform](https://huyenchip.com/2024/07/25/genai-platform.html)





### 34

方军 2024-09-08


数学大佬陶哲轩力荐，哈佛反向学习法火了：教会AI就是教会自己。

 蛮好玩的：

他最新分享了哈佛应用数学和应用物理学教授Michael P. Brenner的一个教学方法——
利用提示工程，让学生尝试教AI完成平时数学作业（不纳入正式考核），期末再让这些AI参加考试。

Michael P. Brenner教授认为，这一方法能够教会学生拆解问题，并深度掌握提示词工程技术。
学生在教AI时需要自己理解问题，他们将问题分解为小步骤的过程本身就是一项极好的锻炼。
而且，学会提问在AI应用中也非常具有挑战性，这一教学方法可以帮助学生掌握提示词工程技术。

[陶哲轩力荐，哈佛反向学习法火了：教会AI就是教会自己\_澎湃号·湃客\_澎湃新闻-The Paper](https://www.thepaper.cn/newsDetail_forward_28603408)


### 35

方军 2024-09-08


我有个小感慨，prompt 应该怎么翻译

2023年我们有个小讨论，我当时觉得，我们给 AI 的是一段话，并且 AI 是以这段话为种子，接着往下「续写」

因此， prompt 的较好翻译应该是「提示语」

这也是跟「搜索关键词」做对应。

不过一年多过去了，我觉得多数领域内文章就是接受「提示词」，很难与多数人的普遍习惯做对抗

当然，现在大众还是没有决定用什么翻译，也许大众永远不会接受一个什么翻译，比如“搜索关键词”并不是大众在用搜索时考虑的，他们就是凭直觉用了

对了，还有一个相当神奇的翻译：「指令」，我个人觉得指令是非常棒的，如果不非要直接翻译的话。

就这个词的翻译，我觉得无法改变多数人的共识，但我自己还是尽量用「提示语」这个说法吧。

我也坚定地认为，「提示词」这个思路是有误导性的，不是光靠几个关键词来起租用的，将给 AI  的输入看成是「词」，会导致一个阶段后无法更进一步用好 AI。

实际上，我现在较为推荐的 AI 用法是，对于对话式的AI工具：

别管那些技巧，有什么问什么，追问下去，就可以了。

这个建议的好处是，不是先掌握什么巧妙的技巧，而是先获得效果。假若这个作为第一步，远比掌握什么模板能进到较深的程度。



### 36

方军 2024-09-09

130 学会 Markdown

我基本上觉得，虽然 Markdown 是这么简单、易用、强大，但很难教会普通人，更难让他们日常用起来。

但在 AI 时代，Markdown 可算是基本生存技能。比如，给 AI 一段信息，怎么说这一个标题、小标题，最简单的方式肯定是 Markdown 的#、##。

最近因为它的 AI 功能， 我推荐朋友用 Zed 编辑器，我觉得他因为恐惧还是没有用起来。也许，可能的收益还是没有大过困难，毕竟他用浏览器或APP中的ChatGPT等等已经很熟练了。

这里，我不借助资料，就随手列几条必备的 Markdown 使用指引。

1. Markdown 是什么？

它就是一种纯文本。不过，在其中可以加入少量标签，用来表示一级标题（#）、二级标题（##）、加粗（**）、引用（>）。

2. 标题

我们可以用 # 来表示各级标题，比如：

\# 一级标题
\## 二级标题
\### 三级标题
\#### 四级标题

通常，在常见的 Markdown 编辑器里面，我们可以方便地在左侧显示出标题结构，方便地在标题间浏览。

3.  加粗

当我们要**加粗(或高亮)**信息时，可以用“**”，如这里所示。

当我们把一段文字输入给 AI 时，由**包围的文字也被加粗表示需重视了。

另，在 Obsidian 这样的笔记软件中，它还额外支持了 “==”这个高亮符号。

4. 引用

在文章中，我们经常需要引用，比如：

> Markdown 是 AI 时代的文本格式。——鲁迅

用“>”这个符号就可以形成引用。

5. 无序列表与有序列表

我们可以用如下方式来编写无序列表：

- 条目一
- 条目二
	- 条目二之一
	- 条目二之二
- 条目三

以及有序列表：

1. 条目一
2. 条目二
3. 条目三 

5. 其他 Markdown 功能

我自己常用，同时在使用 AI 时也经常用到的有：

- 表格
- “---”横线分隔符
- 脚注
- 代码块“```”
- Regex
- Mermaid图表（我稍后会专门写一篇）
- LaTeX 数学公式

额外的资料：虽然飞书对 Markdown 的支持相当糟糕，但它这个 Markdown 介绍文档倒是简单明了，附上供参考：在文档中使用 Markdown
收起

查看详情
李福森、阳志平、Koant、钰博、April 觉得很赞
方军：我很好奇的一点是，是什么阻碍很多人使用 Markdown?

我的一个初步理由是，他们不太使用 Markdown 编辑器，而日常编辑器（不管是桌面比如WPS，还是网页），都不太支持 Markdown。
2024-09-09 10:35
陈牧之：普通人只会用office全家桶
2024-09-09 11:01
方军 回复 陈牧之：对，都用WPS，连WPS的智能文档都不会用
2024-09-09 11:13
不努力的梦想：我觉得markdown出现就是为了内容创作者更容易的投入于内容创作而不是被排版占据很长时间，所以只有有大量内容创作需求的人才会去主动学习markdown，没有这个需求的人就可能用不上，只用三件套足够了
2024-09-09 17:26
方军 回复 不努力的梦想：现在一个变化是，给AI用.markdown才行
2024-09-09 17:30
不努力的梦想 回复 方军：我同意，现在在关心ai的那批人和前几年研究双链笔记的人群感觉重合度蛮高的
2024-09-09 20:01



### 37

方军 2024-09-09

某老师简直走火入魔：

智能的本质只能通过数学的语言才能严谨的描述。我遇到太多的人（学生、研究员、甚至投资者）都说自己对人工智能极度感兴趣。但很少有相关的数学基础知识的。所以即便对智能已经有了完善的理论，他们也基本上无法理解。 ​​​

我只能追着他问：

啊呀，老师，您先定义下

---

我理解比较浅，我至今认为图灵测试对智能的界定相当经得住时间的考验

看着像鸭子，走路像鸭子，叫起来也像鸭子，那么就是鸭子



### 38

方军 2024-09-10

131 让人用通用工具是不对的

如果面前有了两个 AI 工具：

一个是通用的，就是一个对话窗口，你可以做任何提问。
一个是专用的，你可以选择角色或功能，然后它执行特定的功能。

就我们所知，目前这两个 AI  产品的实质是一样的，只不过第二种为你预置了“系统提示语”（system prompt）。

我自己的 AI 使用习惯则介于两者之间，我保存有少量的系统提示语，然后每次输入它们作为系统提示语。

对于大众适合什么样的产品，或者换个角度说，大众需要什么样的产品，我之前有一些看法，但其中的很多假设被证明是有问题的，如下是一次重新思考：

1

首先有一个基本认识，大众不想了解过程，大众只想看到神奇的效果。

2

然后，我又认为，正如大众都接受了搜索一样（这其实是一个有问题的假设），大众会更喜欢通用产品。

这个判断是有合理性的，你看，大众都在用 ChatGPT（或者Cluade、Kimi）。但这个判断不对，缩小到一个具体的群体，这个群体往往要的还是一个“专用”的 AI 产品。

3

再然后，我还有一个假设，我认为，人都有动力去优化自己常用的工具。比如，即便用 WPS，总会做些设置，让自己舒服，对应地，人会自己去略微调整某个专业系统提示语，让它的效果更好。

这个假设也是完全错的，其实我早就知道。比如，多少次我看人投屏展示 Excel，他们不会把工具栏隐藏掉，让我们更方便地看数据表格本身。

那么，在使用 AI 这儿，我们假设人会去自己略微调整系统提示语也完全不对了，也许有 10% 的人知道可以做这样的调整，但最终也只有 1% 的人会做这样的调整。

4

因此，最终的推论就是，对于某个群体的大众而言，他们不要通用产品，而是要能立刻、马上解决他们问题的专用产品。

至于能不能解决，并不重要。人都不是笨蛋，他们看到结果不如意时，会自然地再进一步处理。这都没必要再废话给人多做解释，这儿反而要把人设想成是聪明的、具有适应性的。

这最后一点尤其重要，我们试用各种专业产品，看到结果并不好（比如刚使用一个将文章转换为linkedin帖子的功能），我们往往会贬低专用产品。

但普通人不是这么想的，他们看到不满意的结果时，只要他们对结果的需求足够强大，有了一个不满意的中间结果，他们会自己去再调整。



### 39

方军 2024-09-10


据说是这样，哈哈哈哈

高盛那个问门（portal）在哪儿的故事又重现了啊

摘：前两天高盛发报告说ChatGpt近期用户暴跌 ，然后真相来了：ChatGpt 5月份更换了官网域名，高盛报告用的还是老域名下的访问数据。只能说这个世界真是个巨大的草台班子


### 40

方军 2024-09-10

发现一个有意思的现象，我本来以为得到会特别强调 AI  大语言模型的应用，但从近期的直播看，也许他们认为图像生成需求更大。

当然可能是碰巧。

得到的直播所反映的大众对 AI 需求有点意思，跟我的看法相似，只有放在场景里才行。

https://www.dedao.cn/live/home

这个有个得到内部工具的分享，主要是文字类的：

https://www.dedao.cn/live/detail?id=5Ba2YRDqjZBXk7...



### 41

方军 2024-09-10


时时觉得，加德纳曲线真是神奇的曲线，事物的发展都有这样一个曲线的存在


### 42

方军 2024-09-10

今天说别的又说起这个毕加索四环，真心觉得它很有启发性

不过，多少人进不了环。以阅读为例，很多人连第一环都进不了。

另外还是找跟AI的关系，这四个没一个AI能替代。



### 43

方军 2024-09-10

媒体已经彻底完蛋了

我曾经很喜欢的媒体出这样的标题

2000-2010，我至少读了十年，当年好多朋友在这家媒体啊

[《人类简史》作者赫拉利：当AI决定说谎，人类会落得什么下场？](https://mp.weixin.qq.com/s/wGmTS_59mQjKM9WvHoth9w)

补充，为何这样的标题有问题。一个人是可能作出这样的假设，但是，这个是主要的观点吗？如果不是，用一个这样的偶然说出的话作为标题，是很过分的行为

好标题是什么的，是，巴黎烧了吗？

最近密集报道，是推他的《智人之上 : 从石器时代到AI时代的信息网络简史》这本书。



### 44

方军 2024-09-10


哈哈哈哈哈，摘：AI已经开始污染文字资料库了是吗……
看上传时间是2022年，内容之天马行空有一种AI石器时代的美感。现在再让AI写肯定不是这样了，但这份东西也永远地搁浅在数据库里，甚至你一搜大象无形，它还会在文库推荐序列排第一。
真的不知道大象无形是什么意思的孩子，搜到这种东西会怎么样呢？


### 45

方军 2024-09-11

大仲马工作室

据说，大仲马是他小说的第一个读者。大仲马作品实在太多，有人一直怀疑他有大量的代笔，当然这无法证实。

我最近有个好奇点，我看到一些人的「作品/产品」署名是「某某人名工作室」。

这种非原创的工作，工作室做也没什么问题。「某某人」负责出思路、做审核、做背书。

略有相似的，在学术领域，几位作者共同署名，究竟谁亲笔动手撰写的稿件并不重要。当然这里不太一样的是，学术领域（特别是实验性科学）的重点还是研究成果，动笔撰写只是将内容「固定」下来。

不过，想这个问题还是觉得不舒服，我为何要看「某某人名工作室」的内容呢？

另外，这其实在教学领域也是有的，某些录制课的PPT、脚本是别人写的，名人/老师就负责出面录制，我们这是在看戏剧吗？

类似地，为什么我现在尤其反感AI写作的东西，因为我真心没法判断，它署名某人（当然这个某人也是不负责任的、极其不讲究的），这其中有多少这个人的真正看法？

（就把想法变成文字这个事，我应该会一直坚持，资料探索可以用 AI ，最终语法校对可以用 AI，但写作过程，要坚决避免让AI介入，因为有时候自己会不知道，这个想法是自己的吗？这和程序是不同的，程序是最低限度能正确地跑就行了，文字垃圾这个最低限度都做不到。）

参阅资料：亚历山大·仲马（Alexandre Dumas，1802年7月24日—1870年12月5日），人称大仲马，法国19世纪	浪漫主义	作家。大仲马各种著作达300卷之多，以小说和剧作为主。代表作有：《	亨利三世及其宫廷	》（剧本）、《	基督山伯爵	》（长篇小说）、《	三个火枪手	》（长篇小说）等。

方军：我早上手残了，怎么就把“读者”写成“作者”，哈哈，意思完全不一样了

据说，大仲马是他小说的第一个读者。

据说，大仲马是他小说的第一个作者。
2024-09-11 15:07





### 46

方军 2024-09-11

最近的  Cursor 吹嘘实在太多了，我的试用跟这个较为相似吧（AI翻译）：

点评：我有时候觉得，啊呀，这些吹嘘 Cursor 编程的人好牛啊，不怎么会编程还可以吹嘘一个编程应用？学到了。（其实人家都自己说不会编程，“不会编程的人 2 分钟做一个Chrome插件！”）

另外，很多鼓吹 AI 编程的人我总觉得有个基本常识不知道，编程要一行一行（如果不是一个字母一个字母）地看代码。

摘作者一句话：根据我的经验，Cursor AI 最好用作一个经常犯错的“初级开发人员”，你必须仔细审查他们的工作以正确“指导”他们。

https://x.com/mayowaoshin/status/18335576284016272...

在我看来， Cursor+ Claude 编码的炒作有些过头了。作为 Cursor 的早期采用者和重度用户（到目前为止至少使用了 1000 小时），在过去的几个月里，我注意到了三个主要问题：

1. 首次生成的输出通常包含细微的错误，这可能会花费你大量的时间和金钱。

我在时间轴上看到的大多数Cursor演示都集中在用户界面、流行的前端框架和基本的后端身份验证/应用程序编程接口上。这些应用程序可以承受犯错，而且大多数都没有部署到付费的实时用户身上。

但是，如果您的应用程序已部署到生产环境并使用复杂或关键的后端逻辑（即支付处理），则细微的错误开始出现。

例如，cursor ai 在下面所附的图像中生成了支付订单管理器类。乍一看，它可能对生产看起来不错，但仔细检查后，你会注意到当一个产品被移除时，订单的“总价”没有更新。结果，系统将错误地向客户收费，导致客户信任损失、连锁错误和潜在的诉讼。

当使用AI“重构”代码或当 Cursor 试图为你自动修复问题时，也会出现同样的问题。通常，对原始代码库所做的更改会给逻辑添加隐藏的错误。

因此，大量时间可能会浪费在审查和重构AI生成的代码上。

是的，我知道……在部署之前应该进行测试以捕捉AI错误，但说实话，大多数开发人员没有精力或纪律对每次提交进行单元测试。

2. 输出质量不一致

如果你多次向 Cursor 提供相同的提示，你可能最终会得到截然不同的问题解决方案。这可能发生在同一使用会话中，也可能相隔数天/数周。

事实上，如果你复制一个先前生成的AI解决方案，并让 Cursor “审查代码中的错误”，十有八九它会发现有问题。

此外，如果你向AI提出任何包含建议或替代解决方案的问题，它将道歉并再次重构整个代码。

示例：

用户问题：感谢您的解决方案。使用 Map 函数处理支付订单更好，还是我应该使用类似 Redis 的东西？

AI回应：“你完全正确，我为忽略了那个关键方面而道歉。”

3. 它会显著增加技术债务。

即使当AI生成一个“好”的代码块解决方案时，它也没有考虑到应用程序的整个软件设计和架构。

由于缺乏整体视角，出现的问题包括整个应用程序中不一致的错误处理、模块性和数据建模。因此，短期的快速修复往往会在长期导致可扩展性、性能和维护问题。

一旦你的代码库增长到一个庞大、复杂且混乱的组件网络，重构将是一个漫长、痛苦且代价高昂的过程。

小结：Cursor AI（或一般的AI编码）是一种有用的自动补全工具，在短期内可以提高你的开发效率，但从长远来看，如果你不彻底审查生成的输出，它可能会浪费大量的时间和精力。

根据我的经验，Cursor AI 最好用作一个经常犯错的“初级开发人员”，你必须仔细审查他们的工作以正确“指导”他们。

然而，如果你仅仅因为缺乏知识、技能或不愿审查结果而“信任”AI的输出，那么长期损害将超过你如此“兴奋”的最初生产力收益。

Imo the @cursor_ai + claude sonnet ai coding hype is blown out of proportion. As an early adopter and heavy user of cursor (at least 1,000 hours so far), here are 3 major issues I've noticed over the past couple of months:1. The first generated output(s) often contains subtle bugs that could cost you a ton of time and money

Most cursor demos I see on my timeline are focused on the UI, popular frontend frameworks and basic backend auth/api. These applications can afford to make mistakes and most aren't deployed to live paying users.

But if your application is deployed to production and utilises complex or critical backend logic (i.e. payments processing), subtle bugs begin to emerge. 

For example, cursor ai generated the payment order manager class in the image attached below. At first glance it may look good for production, but upon close inspection you'd notice that the `totalPrice` of the order isn't updated when a product is removed.  As a result, the system will charge customers incorrectly leading to loss in customer trust, cascading errors, and potential lawsuits.

The same issue occurs when "refactoring" code using AI or when Cursor attempts to auto-fix problems for you. Often, changes are made to the original codebase that add hidden bugs to the logic. 

As a result, a lot of time can be wasted reviewing and refactoring AI generated code.

Yes I know.... tests should be run before deployment to catch AI bugs, but let's be honest, most devs don't have the energy or discipline to unit test every commit.

2. Inconsistent quality of outputs 

If you provide the same prompt several times to the chatbot, you may end up with drastically different solutions to the problem.  This can happen within the same session of usage or days/weeks apart. 

In fact, if you copy a previously generated AI solution and ask the cursor chatbot to "review the code for bugs", 9/10 times it finds something wrong.

In addition, if you ask the AI any questions that contain suggestions or alternative solutions, it will apologize and refactor the entire code again.

Example:-

User question: Thank you for your solution. Is it better to handle the payment orders using a Map function or should I use something like Redis?

AI response: "You're absolutely right, and I apologize for overlooking that crucial aspect."

3. It can significantly increase technical debt

Even when the AI generates a "good" code block solution, it doesn't take into account the entire software design and architecture of the application. 

Due to the lack of a holistic perspective, problems emerge includes inconsistent error handling, modularity, and data modelling across the app. As a result, the short term quick fix often leads to scalability, performance, and maintenance issues over the long run.

Once your codebase has grown to a large, complex web of messy components, refactoring will be a long, painful and costly process.

TLDR: Cursor AI (or AI coding in general) is a useful autocompletion tool that can boost your development productivity in the short run, but in the long run, it can waste significant time and energy IF you don't thoroughly review generated outputs.

In my experience, Cursor AI is best used as a "junior developer" who often makes mistakes and you have to review their work carefully to "guide" them correctly. 

If however, you simply "trust" the AI outputs due to lack of knowledge, skill, or willingness to review results, the long term damage will outweigh the initial productivity gains you got so "hyped" about.

后面跟的评论：

如果你（1）从头开始一个新项目或（2）在一个小 Code base 上工作，Cursor 非常棒。你用它能多快地推出一个 v1 真是令人惊叹。

它在大型现有代码库上确实很吃力，在那里它无法自己弄清楚所有相关上下文。它在更复杂的代码片段上也很吃力，即使你给了它所有必要的上下文（尽管这更多是底层LLMs的“过错”）。我经常遇到这样的问题，即输出有小但致命的错误，或者它没有涵盖所有边缘情况。

但是嘿，如果你把它当作一个初级开发人员，审查所有的代码，我觉得它仍然可以为你节省时间，而且比纯粹的自动完成，比如 GH Copilot 要好
收起


查看详情
陈牧之、不努力的梦想、Ricardotan*、乘风、Jese__Ki 觉得很赞
希瑞：不知道其他行业怎么样，汽车行业的软件是要跑全V cycle的，即使敏捷开发也不会少步骤，不然迟早出问题，且越后期越难维护。cursor只是一个高效coding工具，在需求设计/验证和架构设计/验证方面仍然有大量工作需要做。
2024-09-11 11:13
方军 回复 希瑞：汽车软件的要求那又是高好几个量级的：）
2024-09-11 11:17

### 47

方军 2024-09-11





### 48

方军 2024-09-11





### 49

方军 2024-09-11





### 50

方军 2024-09-11





### 51

方军 2024-09-11





### 52

方军 2024-09-01





### 53

方军 2024-09-01





### 54

方军 2024-09-01





### 55

方军 2024-09-01





### 56

方军 2024-09-01





### 57

方军 2024-09-01





### 58

方军 2024-09-01





### 59

方军 2024-09-01





### 60

方军 2024-09-01





### 61

方军 2024-09-01





### 62

方军 2024-09-01





### 63

方军 2024-09-01





### 64

方军 2024-09-01





### 65

方军 2024-09-01





### 66

方军 2024-09-01





### 67

方军 2024-09-01





### 68

方军 2024-09-01





### 69

方军 2024-09-01





### 70

方军 2024-09-01





### 71

方军 2024-09-01





### 72

方军 2024-09-01





### 73

方军 2024-09-01





### 74

方军 2024-09-01





### 75

方军 2024-09-01





### 76

方军 2024-09-01





### 77

方军 2024-09-01





### 78

方军 2024-09-01





### 79

方军 2024-09-01





### 80

方军 2024-09-01





### 81

方军 2024-09-01





### 82

方军 2024-09-01





### 83

方军 2024-09-01





### 84

方军 2024-09-01





### 85

方军 2024-09-01





### 86

方军 2024-09-01





### 87

方军 2024-09-01





### 88

方军 2024-09-01





### 89

方军 2024-09-01





### 90

方军 2024-09-01





### 91

方军 2024-09-01





### 92

方军 2024-09-01





### 93

方军 2024-09-01





### 94

方军 2024-09-01





### 95

方军 2024-09-01





### 96

方军 2024-09-01





### 97

方军 2024-09-01





### 98

方军 2024-09-01





### 99

方军 2024-09-01





### 100

方军 2024-09-01





### 101

方军 2024-09-01





### 102

方军 2024-09-01





### 103

方军 2024-09-01





### 104

方军 2024-09-01





### 105

方军 2024-09-01





### 106

方军 2024-09-01





### 107

方军 2024-09-01





### 108

方军 2024-09-01





### 109

方军 2024-09-01





### 110

方军 2024-09-01





### 111

方军 2024-09-01





### 112

方军 2024-09-01





### 113

方军 2024-09-01





### 114

方军 2024-09-01





### 115

方军 2024-09-01





### 116

方军 2024-09-01





### 117

方军 2024-09-01





### 118

方军 2024-09-01





### 119

方军 2024-09-01





### 120

方军 2024-09-01





### 121

方军 2024-09-01





### 122

方军 2024-09-01





### 123

方军 2024-09-01





### 124

方军 2024-09-01





### 125

方军 2024-09-01





### 126

方军 2024-09-01





### 127

方军 2024-09-01





### 128

方军 2024-09-01





### 129

方军 2024-09-01





### 130

方军 2024-09-01





### 131

方军 2024-09-01





### 132

方军 2024-09-01





### 133

方军 2024-09-01





### 134

方军 2024-09-01





### 135

方军 2024-09-01





### 136

方军 2024-09-01





### 137

方军 2024-09-01





### 138

方军 2024-09-01





### 139

方军 2024-09-01





### 140

方军 2024-09-01





### 141

方军 2024-09-01





### 142

方军 2024-09-01





### 143

方军 2024-09-01





### 144

方军 2024-09-01





### 145

方军 2024-09-01





### 146

方军 2024-09-01





### 147

方军 2024-09-01





### 148

方军 2024-09-01





### 149

方军 2024-09-01





### 150

方军 2024-09-01





### 151

方军 2024-09-01





### 152

方军 2024-09-01





### 153

方军 2024-09-01





### 154

方军 2024-09-01





### 155

方军 2024-09-01





### 156

方军 2024-09-01





### 157

方军 2024-09-01





### 158

方军 2024-09-01





### 159

方军 2024-09-01





### 160

方军 2024-09-01





