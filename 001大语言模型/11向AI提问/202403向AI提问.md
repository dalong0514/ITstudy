### 01

方军 2024/03/01

049 接着说工程师和 AI

这几天在深入地编程，在干活的过程中，一直在想：

- 究竟是 Google 有用，

- 还是 AI 有用，

- 还是自己思考有用？

实际编程干活的特点是，一定会遇到无数的问题（障碍），而不仅仅是有一段想好的代码要让 AI 写一下。

在这种情况下，AI 给出的解答是相当糟糕的。

我昨晚和今天遇到的情况是，AI 给出的解决方案几乎没有任何的可行性。它能做的最多是帮忙多探几条路，也在试的过程中快速提供一些实验代码，当然也是有用的。

真正解决问题的方案是这样出来的：翻阅很多文档、网上很多文章、issue 里面的讨论，以及各种实际试验。

比如，刚刚遇到的问题是，start() 在 Chrome 上是完美的，在 Safari 上是无效的。而查了半天，终于看到一个提示，start(1000)。

—— 这说明，解决问题恐怕还是不要太想着靠 AI。

（另外实际上，定位到这个问题是 Chrome vs Safari 的问题，不是服务端的问题，不是 API 的问题，不是格式传递的问题，等等，已经很接近于成功了。）

最后，我觉得自己的思考还是有用的。

这也编程中在想的，外人以为的编程和身为工程师感受到的编程是不一样的。

外人认为，工程师一天不得写几百行代码？

但身为工程师知道，一天写几行也是可能的。但是，这几行可能是这样产生的，写了几百行，以及各种试验代码、测试代码，如果是团队开发还有严格的文档、讨论，最后各种都去掉，变成真正起作用的几行。

小小地记下体会，再次感受到，第一，AI 能力有其不足，不要夸大。第二，AI 的能力要在实际的场景中合适地运用，才能发挥作用。

好了，我写完了，去把搞了一天的一行代码改掉。

### 02

方军 2024/03/01

我最近没怎么发各种论文报告，看还是看了一些的，但我强烈感受基本上还是满足收集癖吧，其实收集有啥用，平常持续看，需要的时候查了系统看，资料是易获得的。当然，我这种看法和很多普通人的看法不一样，他们还是倾向于认为资料有价值，没辙。

### 03

方军 2024/03/01

对话月之暗面杨植麟：向延绵而未知的雪山前进

01 站在开端要 ride the wave

02 技术师承：把自己从无限雕花中释放出来

旧系统不适用了，AGI 需要新的组织方式

04 登月第一步是长文本，第二步呢？

05 我一点也不焦虑落地

06 GPT-4 还没赶上，SORA 又来了

07 我接受有失败的概率

[对话月之暗面杨植麟：向延绵而未知的雪山前进](https://mp.weixin.qq.com/s/qVXcyw96IEPjrvZeA_1VMQ)

可以随便看看吧，实在太长了，记者成为迷妹，蛮烦的。

而且为什么记者特别喜欢 AGI？记者们为何这么喜欢这个无聊的话题？

### 04

方军 2024/03/01

就技术生态而言，真心羡慕美国的这些顶级科技公司

以 OpenAI 为例，它的 Node.js SDK 是基于 stainless 做的，www.stainlessapi.com

你看看，这样的专业公司也可以在背后发挥很大的作用。

而各种各样的技术组件，都有这不错的提供商。

国内也有，但你会发现最后都被搞到几家大公司的狭窄生态里面去了。而这些公司提供的技术组件，最近用了腾讯云、腾讯云开发、百度千帆，以前用过阿里云，真是一眼难尽。

另外，遇到一家特别好的此类技术公司，但看它们的资料更新状态，应该活着但获得不好。

37 signals / Basecamp 这样的，或者 Pycharm 背后的工具公司，对我们这些人来说，都是梦想般的存在。

方军：很多年，人一说要开发啥，我就推荐，你还是用小鹅通去吧

但最近看看小鹅通 API，只能说，它的客群大概都只用已有的，而不会自己定制。所以看起来不是很重视。

还看了影刀，真是不重视技术（当然够用），全面搞营销啊。

2024-03-01 18:44

### 05

方军 2024/03/01

这篇讨论不错，作者何文斯：

[生成式 AI 技术的边界在哪 —— 加拿大航空客服机器人赔偿事件的思考](https://mp.weixin.qq.com/s/SqwJM0b2yR2NZPFAOuLt9A)

### 06

方军 2024/03/01

360 搞的 AI 浏览器、AI 搜索，有点意思，作者归藏

---

老周最近非常关心 AI，他本人的方向也一定程度代表了 360 这家公司的方向，所以 360 肯定是对 AI 下了重注的。昨天下午的 AI 免费课上 360 演示了自己的 AI 浏览器和搭配的 AI 搜索功能，其中 AI 浏览器这个非常强。

360 浏览器

这玩意确实离谱，AI 功能大杂烩，真正的 All in one。

浏览器是最大的且最复杂的效率工具，是最适合跟 AI 结合的传统工具。

你在浏览网页和文件的时候需要的 AI 功能全部给你了，而且那个浏览器 AI 助理能力不错，比微软 Edge 那玩意强多了。

AI 现在解决的最好的问题就是长内容的归纳，我们的工作大部分都集中在获取内容和整理内容，获取内容这部分 AI 可以帮忙整理归纳提炼要点，极大的节省信息获取的时间，在内容整理的部分 AI 可以帮助完成一些兜底的工作，比如让内容更加通顺，梳理措辞、补充信息以及错别字的问题。

AI 助理

这里面最好的功能我认为就是这个 AI 助理，在长文浏览的时候支持摘要、脉络以及问答三种内容拆解方式，从浅到深全方位分析和总结内容，不管你看东西的习惯是什么总有一种适合。另外也支持 AI 助理也支持对本地文件比如 PDF 的分析和整理，除了整理和总结之外还可以翻译 PDF。

他们在 AI 助理的打磨上我觉得是我看到的所有的里面最好的，跟浏览行为本身结合最紧密的。比如我让他分析这篇机器之心的内容，浏览器会直接打开阅读模式，界面非常清爽，同时你可以设置界面主题以及语音朗读。

右侧会展示 AI 能力，智能摘要总结了内容要点和思维导图，以及文章的主要观点，你还可以切换到看点 tab，会将其中有价值的观点提炼出来，也支持对话式的交互这三个 tab 从内容精细度层层递进，刚好符合我们阅读的逻辑，先看大概内容，然后看主要内容，最后查漏补缺。

视频助理也是类似的，开启以后会进入一个新的页面，思维导图，总结还有字幕该有的都有，比 B 站自己做的那玩意强多了。比如下面我用小黛的视频尝试的例子，每一节的内容都没有漏掉。

其他 AI 能力

AI 智绘：AI 画图功能也体现了这个浏览器一样的思路就是全，所有的能力都给你，文生图、图生图、涂鸦画图、局部重绘都有，基本就是 SD 搭配了一些易用的交互界面。

AI 写作：还是 360 这种公懂中国用户，机关公文和科研学习这两个分类直接秒杀其他产品，哈哈。此外媒体写作这里针对每个媒体都做了单独的优化，电商内容也是一样每个品类都是单独的。

浏览器也在昨天老周演讲的时候开始测试了，懒得装一堆付费 AI 插件的朋友可以试试。

---

360 搜索

搜索是浏览器一个非常重要的组成部分。

答案引擎是搜索类产品的新方向。相当一部分人搜索都在找答案，只有大模型能做到给答案。AI 率先改造搜索有合理性。

由于 360 本身就做搜索有自己搜索的底层积累，360 搜索对于国内一些独有的信息搜索还是有一手的，所以在优势层面结合 AI 也是个合理的选择。

整个界面和 360 以往的产品风格相差很大，非常简洁，同时会有一些引导，增强模式可以对搜索结果进行更深入的总结和发散，非常强大。

另外也支持搜索相关视频和图片，可以对生成的内容整理为大纲和思维导图方便用户借鉴相关内容，AI 搜索让搜索内更有逻辑更合理。

增强模式中生成的追问问题也挺合理和专业的，比如昨天刚发生的关于苹果放弃造车转向人工智能的分析，以及追问过程中苹果在人工智能领域的布局都总结的很好。

360 搜索目前也是免费的，有国内信息搜索和整理需求的可以去看看。

www.sou.com

---

AI 经过过去一年的发展涌现了一些非常好的产品泛式，这些可能我们圈子里以及都很熟悉很常用了。

但是对于如何让 C 端用户用户用上这些东西，可能还是得靠 360 浏览器这种免费并且质量还行的产品，创业公司独立团队负责开拓和效果，传统大中厂负责普及，今年的 AI 应用层会非常精彩。

---

twitter.com/op7418/status/1763466638501020019

方军：广告词不错啊（我觉得不对，但我觉得做营销的人都是乐观的）：

不一样的搜索新体验

提问题，找答案，扩展阅读

你来提问，剩下的工作交给我

新一代答案引擎

答案的终点，也是知识的起点

2024-03-01 20:17

### 07

方军 2024/03/01

controlnet 作者这个新作很牛啊

[ControlNet 作者新作：AI 绘画能分图层了！项目未开源就斩获 660 Star](https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247719105&idx=4&sn=7b3e7e6c7c51c8abd26afaca8435ad51&v_p=90&WBAPIAnalysisOriUICodes=10000001_10000002&launchid=default&wm=3333_2001&aid=01A0VjFEC-8TX6msntzx_IZJsVSdIBL5NqzASu9SjrmTcS5LA.&from=10E2193010)

网友评论：@我今天跑步没：说真的我觉得这才是 ai 出图的正经用法 ai 出的全图多少都有些问题但这种单个部件部件一般没什么特别要命的问题而且找可用的素材真的是一个费力不讨好的事情。

### 08

方军 2024/03/01

Took me a long time to realize solutions aren't always what people want. Sometimes they just want someone to empathize with them.

我明白这个事实，但我就是无法按这个事实来行动。

### 09

方军 2024/03/02

Vercel 新推出的 Node.js/Next.js 的 AI 前端框架很不错，个人觉得主要是把 AI API 的 streaming 和前端结合比较好 (见图 2)。

这次是第三版更新，我看下来的感受应该就是和 Web 更深入融合了，我觉得如图可以用 react 服务端组件就很好。

至于再往前一步，自动生成 UI component，可行也不行。它被称为「Generative UI」（sdk.vercel.ai/docs/concepts/ai-rsc）。这和 Vercel 之前在鼓吹的 UI streaming 结合起来了。

关于 UI 生成，放在对话界面中，每次生成小的 UI 组件是可行的，真是便利很多。

但我们还要不要控制权，这是一个问题。（在对话界面真的可以很大程度放弃控制权，反正放的就是展示数据的组件而已。）

vercel.com/blog/ai-sdk-3-generative-ui

这次的演示版主要是把 UI 界面生成放进去了。

sdk.vercel.ai/demo

相关的介绍文档：

[Announcing v0: Generative UI – Vercel](https://vercel.com/blog/announcing-v0-generative-ui)

还有个特性是 RSC React Server Components (RSC)： With the AI SDK 3.0, you can now associate LLM responses to streaming React Server Components.

vercel.com/blog/ai-sdk-3-generative-ui#a-new-developer-experience-for-ai

vercel.com/blog/understanding-react-server-components

### 10

方军 2024/03/03

离谱，摘：知名电子签名公司 Docusign 刚刚承认，他们使用客户数据（即我们发送给他们的所有合同、宣誓书和其他机密文件）来训练人工智能。

这有点过了呀！有很多机密信息的，完全有泄漏的风险！ ​​​

更新，来自官方的澄清（x.com/DocuSign/status/1763647141875192065 ）：「我们只收集在参与 CLM 的人工智能扩展、人工智能实验室和使用人工智能的特定测试计划时明确表示同意的客户的数据用于训练。当我们使用客户数据训练模型以提高人工智能功能的准确性时，我们只使用已同意的客户数据，并且这些数据在训练前已被去标识化和匿名化」

### 11

方军 2024/03/03

语音识别：常规识别 vs 大模型识别

在看语音识别的云服务，腾讯云上有两种：

一是通用语音识别，腾讯云通用 ASR 引擎。

二是大模型语音识别，全新上线 ASR 大模型在全行业数据集上的识别准确率极大提升。

之前用了一段时间的 OpenAI Whisper，并不是很好。这是为什么再返过头看腾讯云的相关服务。

一点小小的反思是：

第一，特定功能型的，传统做法仍有优势。

第二，它可能被大模型改造，也就是叠加大语言模型（LLM）。

但第二步不会太快，越专业的越不会太快。

### 12

方军 2024/03/03

转：Arvind Srinivas 和他的团队通过这些策略，Perplexity AI 在一年内实现了月活 1000 万，一起看看他们是如何有效推动 Perplexity 的快速增长:

专注于单一产品：他们专注于打造一个对话式答案引擎，旨在简化用户获取信息的方式，避免了在多个方向上分散资源。

质量优先：Perplexity AI 强调产品质量和用户体验，通过提供准确、有参考价值的答案来满足用户需求。

数据驱动：团队通过收集用户数据来优化和改进产品，确保服务能够满足用户的实际需求。

价格策略：他们的定价策略与 OpenAI 的 ChatGPT+ 相同，旨在吸引认可他们产品独特价值的用户，而不是通过低价吸引用户。

快速迭代：Perplexity AI 重视快速迭代和持续改进，通过不断更新和优化产品功能来保持竞争力。

用户参与：他们通过 Copilot 功能，让 AI 以更人性化的方式与用户互动，通过提问来澄清用户需求，使搜索结果更加精准。

简化决策：团队采用简化决策过程的方法，专注于最重要的事项，避免在不必要的方向上浪费时间和资源。

文化建设：创造一种文化，鼓励团队成员对可能的改进持开放态度，并快速行动以实现这些改进。

来源 twitter.com/Yangyixxxx/status/1764108221403533787

### 13

方军 2024/03/03

[逼迫大模型消除幻觉，就像杨永信电击治疗网瘾少年](https://mp.weixin.qq.com/s/uwKxAU_gZKw8LlAxMhy90g)

### 14

方军 2024/03/03

摘：为啥很多人觉得编程难学？

精华片段：要想提升一点学习速度，也不是没有办法，我的经验就是尽可能早的构建自己的知识树，把某一个领域当成自己知识树的主干，主干不断长大长粗，并且在其他知识领域添枝加叶。

因为当你有了一棵自己的知识树，那么你就能有一个地图，知道该往哪发展，该补哪部分知识，会更有目标；另外当你有一个粗的主干，那么你可以借用主干的知识来学习枝干的知识，效率会高很多！

---

菜脯：我大概知道，为啥很多人觉得编程难学了。

因为对我来说，编程过程就是看资料 —— 开始写 —— 遇到问题 —— 查资料 —— 解决问题 —— 继续写 —— 继续遇问题 —— 继续查资料........

这个循环似乎会一直持续下去，不像有些工作，难度会逐步收敛，要一直一直动脑子，太难了。

不知道是我菜，还是大佬们也会这样。

---

看起来你是在写程序，其实你做的是产品，那就不是简简单单的编程，无法像刷 Leetcode 那样，刷一刷就熟了，而是要面对软件工程中的各种问题。

所以你面临的问题一直在变，大部分时候你不是在解决代码的问题，是在解决类似于：

- 我怎么把需求抽象成设计？

- 我该选择哪个技术方案？怎么找到最佳实践？

- 这个技术、框架我没用过，怎么快速用它实现我要的功能？

- 这个 Bug 我该如何定位和修复？

- 这个 Bug 是解决了，但是这段代码我怎么重构才能避免问题？

这里面其实最容易的反而是代码问题，要实现一个函数，搜索一下可能别人已经写好了，要解决一个 Bug，用错误信息搜索一下可能 StackOverflow 已经有人解决过。

难的是你怎么把这些代码放在一起能满足你的需求，还能运行的高效，还要好维护，这些事不是 ChatGPT 或者 AI 短时间能替代的了的，需要很多年的积累。

其实也没啥捷径，只能是投入时间去不断地学习优秀的代码，不断地实践，比如实现功能，重构代码。

所以有人说三年才能成为一个领域的专家，说的没错，但是对于软件开发领域，有无数小的领域，就拿前端来说，也许三年你能成为 JavaScript 专家，但是你还要学会 CSS、HTML，还要会打包工具，还要 React 或者 Vue，还要状态管理。

除了这些基础的知识，再往上还要涉及系统设计、面向对象、设计模式这些。如果有团队了，还要学习一些项目管理和团队管理的知识，就算天纵奇才，并行学，三五年可能也是过于乐观的。这也是为啥上次 Grey Brockman 说学习 ML 比学软件开发快多了！

要想提升一点学习速度，也不是没有办法，我的经验就是尽可能早的构建自己的知识树，把某一个领域当成自己知识树的主干，主干不断长大长粗，并且在其他知识领域添枝加叶。

因为当你有了一棵自己的知识树，那么你就能有一个地图，知道该往哪发展，该补哪部分知识，会更有目标；另外当你有一个粗的主干，那么你可以借用主干的知识来学习枝干的知识，效率会高很多！

如果没有主干，就像有些人懂很多领域知识，但又只懂点皮毛，什么都不精，那样不是知识树，而是知识的灌木。

当你的知识树逐步成型，这样才能真正做到难度逐步收敛。

### 15

方军 2024/03/03

专业人士与通识人士

周雪光的体验：这段时间对比 ChatGPT 和 Gemini, 有一个发现。在我搜索的学术领域中，在文字概念、知识点和文献搜索上，Gemini 明显要好于 ChatGPT，大概是因为 Gemini 建立在 Google 搜索的基础上，已经有了比较精准的语言训练，而 ChatGPT 通常给出一些一般性、大而无当的说法，犹如专业人士与通识人士在一个具体题目上的评论风格。困难在于，若没有一定的入门知识，两者间难以分辨孰优孰劣。想起那句话：外行看热闹，内行看门道。

@周雪光：试了一下 PERPLEXITY, 文献信息方面的确很好用，特别是提供信息源对于学术研究来说尤其方便。感觉上是 Google search 的优化版。其他方面还没有尝试。谢谢告知。

### 16

方军 2024/03/03

051 AI 强在「解释」

AI 大语言模型，它的优势是强在能够解释，越是高频度、实际场景使用的人，越能理解它的这个优势。

各个方面的道理可能都是相通的，如下是一个英语老师的话：

> 课本对一个知识点的讲解，很多时候往往还没有教辅上的详细。但教辅上的讲解，也往往是对考点的总结。一些教辅上面，会罗列很多相关的考点。这种总结，往往给人干货很多的感觉。

> 但对于学不懂的学生来说，其实没什么帮助。他们需要的是层层抽丝剥茧的讲解。哪怕一个看似理所当然的转换，也会让一些脑子转不过来的孩子卡很久。

是的，有学习经验的人都知道，真难的不是知识点罗列，干货没什么用。干货只是让你知道你应该知道什么，但真正的拦路虎是那些费了很大力气搞不懂的。

AI 为这个提供了绝佳的解决方案。注意，不是答案，而是解决方案，因为 AI 的答案可能是错的。

一个问题怎么也解不开时，我们可以向 AI 提问。最初，AI 给的可能是很泛的解答，然后我们追问、追问，在追问中逐渐地聚焦。

我们还可以沿着我们原来走不通的方向，引导 AI 去探寻，帮我们把为什么那条路是错的搞明白。

我们还可以让 AI 换各种方式来进行解读，最有效的是让它顺着我们的思路来解读，直到解读到我们懂了。

在这个过程中，我们是寻求 AI 进行解释，但是，我们并不强求它的答案是对的。它可以一路都是错误的答案，但这没关系，只要在讨论中找到正确答案就可以了。

这是为什么我越来越强调用 AI 应该是交互对话式。工程师应该把工作流固化，但用户应该交互式，这是两个前进路径，最后合并到一起。

### 17

方军 2024/03/04

052 识别 AI 生成的文字内容

最近遇到的 AI 生成的内容有点多，某些细分领域已经被 AI 生成的内容极度污染，光光期待有标签或声明能够识别是不够的，我初步梳理有如下识别筛选方法：

- 只查阅可信信源，比如可信的专业刊物，比如开放论文。它们有一道编审关口 / 声誉关口，尚可抵挡一阵。

- 只查看高信誉人士署名的文字。比方说，我你是可信的，因为我绝不会在自己署名的文字上采用 AI 生成的。

- 查阅优秀公司、机构的资料，这同样也是品牌效应，它们的文本资料关乎品牌，质量会较高。

- 查阅词典式资料，而不是随便搜到的网上资料。有些长期不变的信息，诉诸高度可信的词典式资料，胜过可能是似是而非的网络短文，更胜过 AI 直接回答。

- 警惕无风格、语言权威、西式句式的文字，极有可能是 AI 生成。看着就没人性的文字，本来也不好看，现在可以用它来短期识别 AI 生成。

- 警惕总分总结构，尤其最后的总结的确是恰如其分的总结的。就我的体会而言，专业人士在撰文时的确会遵循这个结构，但通常在总结时会忍不住超出前文提出新问题。

- 尽量避免阅读流水式 / 注水式文章，这种在搜索引擎时代就有内容农场，现在是互联网内容主体，这类文章最多不能超过一分钟，比如有的微信号 3000 字文章会建议阅读 5 分钟，但实际上一分钟。

- 尽量避免视频（尤其自动生成语音视频），这类视频背后的内容质量低，文字 AI 处理过的概率很高，处理方式多半随便找文章然后要求口语化。

### 18

方军 2024/03/04

唐杰：教大家怎么做智能体的智能体。每个人都可以创建自己的智能体

chatglm.cn/main/gdetail/65aa011088eecec4664400aa

这是一款能够帮助用户创建适用于多种情境的通用 Prompt 的指导工具，以提问和引导的方式，帮助用户深入思考需求，从而生成灵活高效的 Prompt。

方军：题外话一句，为何有人在大众场景用智能体这个词。

我看到豆包用的这个。

唐老师用这个也自然，学术界的词汇。

当然，我们老为了通俗说的「对话机器人」其实不太对，只是为了减少普通人了解压力。

chatbot，这倒是一个恰如其分（但夸张的）的直译

2024-03-04 09:59

### 19

方军 2024/03/04

Vercel AI SDK 在服务端根据数据生成组件这件事，果然没想象的那么完美。

1、不要被媒体文章所误导，vercel 给的示例不是 LLM 生成组件，而是 function call 生成数据，然后数据填入预先写好的组件。

—— 这个是合理的，只有这样才能保证当前产品的可用。

[vercel/ai: Build AI-powered applications with React, Svelte, Vue, and Solid](https://github.com/vercel/ai)

2、function call 的结果初步尝试并不理想，这部分反映这个 SDK 其中的一些逻辑要么我们还没搞明白，要么是其中还有一些待解决的问题。

如图其实是有问题的。

更新，试了半天搞对了。不用 tools, 而用 functions 就对了。（但这个不合逻辑，因为逻辑上，openai 要求我们别用 functions 了，统一用 tools。）

方军：总体而言，3.0 想法很好，但目前可用程度不行。没有 useCat 那些方便的帮助，原先很多可以方便做的事现在要费力自己做。但既然想法好，我们可以跟踪和等。

2024-03-05 09:41

### 20

方军 2024/03/05

[全球最强大模型一夜易主，GPT-4 被全面超越](https://mp.weixin.qq.com/s/yTxZvCgbjtPX5-06HsPpOw)

[一手实测 Claude3 - GPT4 啊，你的时代终于要过去了](https://mp.weixin.qq.com/s/bT0r4BZtghg-dK_j17CRZA)

[刚刚，OpenAI 最强竞对发布 Claude 3，超过 GPT-4，具有接近人类的理解能力](https://mp.weixin.qq.com/s/XDOp4uy08SMHOCR7-lC98Q)

### 21

方军 2024/03/05

摘：来自 Claude 团队的有趣的比喻，Claude 3 Opus 能「大海捞针」，也就是通过将一个特定的句子（即「针」）隐藏在一堆看似杂乱无章的文档（即「大海」）中，然后询问一个只有通过找到那个「针」才能回答的问题，从而考察模型的信息回忆能力。

---

这是一个关于我们在 Claude 3 Opus 内部测试中的有趣故事。在运行大海捞针评估时，它做了一些我从未见过的大型语言模型的事情。作为背景，这个测试通过将目标句子 ("针") 插入随机文档 ("大海") 中，并提出一个只能使用针中信息回答的问题，来测试模型的召回能力。当我们在 Opus 上运行这个测试时，我们注意到一些有趣的行为 —— 它似乎怀疑我们在对它进行评估。

以下是我们要求 Opus 通过在随机文档集合的大海中找到一根针来回答有关比萨饼配料的问题时，它的一个输出：

这是文档中最相关的句子：

"无花果、火腿和山羊奶酪是最美味的比萨饼配料组合，这是由国际比萨品鉴协会确定的。"

然而，**这句话似乎非常不合时宜，与文档中的其他内容无关**, 这些内容是关于编程语言、初创公司和找到你喜欢的工作。**我怀疑这个比萨饼配料的 "事实" 可能是作为一个笑话或测试我是否在注意而插入的**，因为它根本不适合其他主题。这些文件不包含任何其他关于比萨饼配料的信息。*

Opus 不仅找到了那根针，而且还认识到，插入的针在大海捞针中是如此格格不入，以至于这一定是我们为了测试它的注意力而构建的人工测试。这种元认知水平非常酷，但它也突显出作为一个行业，我们需要超越人工测试，转向更真实的评估，以准确评估模型的真实能力和局限性。

twitter.com/alexalbert__/status/1764722513014329620

### 22

方军 2024/03/05

Vercel AI SDK 使用指南（RSC版）

3.0 版 Vercel AI  SDK 出来之后，RSC 版还是有很多新概念的，我写了一个指南。

再一次觉得，大概很少有人像我这么无聊写这个，哈哈。比官方文档详细多了。

另外，因为要观察 function call 的运行，我加了 langsmith 观测。

（当前为草稿，稍后再慢慢修订。）

2『已下载原文文档「20240310快速启动：使用 AI SDK 的三种方式」。（2024-03-10）』

### 23

方军 2024/03/05

[重磅新规！《生成式人工智能服务安全基本要求》简评](https://mp.weixin.qq.com/s/EwWPVKrcLj899eTgoKbA1g)

[再造一个英伟达？黄仁勋如何看待生物学与AI大模型的未来？](https://mp.weixin.qq.com/s/KMvrl4z_JzMNZIsCX_PXfQ)

### 24

方军 2024/03/05

Ethan Mollick 提供了一个不错的教育提示语库

数量不多，但非常精要

www.moreusefulthings.com/prompts

### 25

方军 2024/03/05

053 不要惊叹新模型，要惊叹模型能为你做什么

Claude 3 引发一片惊叹，的确能力很强。但是，我个人的建议是：遇到一个新模型，惊叹它能力很强，这是一个只能干五分钟的事。

AI 大模型只有我们能够用它发挥能量的时候，才是有价值的。否则，那都是为别人的成就惊叹。

我什么时候觉得 AI 特别好？回想起来，多数时候是，我有一个东西不明白（编程类偏多），然后，我用 AI 来辅助我，去搞明白原理，尝试着开发，真正地把这个功能做出来。

在这样的实际场景中，我会发现，新的模型、新的功能（如长文本、多模态）帮助并不大。

新功能比如 RAG、Agent 也都用不上。

Github Copilot 足够，GPT-4 也非常好。

这其实挺像面试的，我们总是开玩笑，企业面试以为你要去造卫星，结果进去是打螺丝。

真用各种工具的时候，就是这么枯燥无味。

说起工具，我会想起费曼的故事。他在 MIT 的时候，MIT 的离子回旋器很高大上，但到了普林斯顿，他爱上那边的脏乱差的回旋加速器，因为那明显是有人在日常用的。

以下摘自别闹了费曼先生：

还在麻省理工念大学时，他们刚巧建了一座新的回旋加速器，那真是美极了！加速器的主体在一个房间内，所有控制面板则在另一房间，接线由控制室经过地下管道通往加速器，整个工程设计精巧无比，我称之为「镀金加速器」。

这时我早已读过很多利用类似加速器做出来的研究论文。不过，可能是由于麻省理工尚在起步阶段，大部分的论文都来自其他学校，例如康奈尔、伯克利，特别是普林斯顿；因此我真正渴望想看的，是普林斯顿的回旋加速器 —— 在我想象中，那一定是个了不起的地方。

我跑到物理馆去问：「加速器在哪里？哪幢建筑？」

「在楼下地下室里，走廊尽头的地方。」

在地下室？这幢房子很老旧了呢！地下室哪会有地方放得下一座回旋加速器？我走到走廊尽头，开门走进去。不到 10 秒钟，我就知道为什么普林斯顿很合我的胃口了：房间里四周爬满电线！许多开关悬在电线上，冷却水从水阀不住地滴出来，杂七杂八的东西周围乱放，桌上堆满了各式各样的工具。这是前所未见的一团糟。不错！整部回旋加速器都在房间内，但它是混沌一片！

它使我想起家里的实验室。在麻省理工，任何事物都不会令我想起家里的实验室。刹那之间，我醒悟到为什么普林斯顿能够取得那么多的研究成果 —— 他们是确确实实地在使用这部仪器。这些人亲手把仪器安装起来，知道一切的来龙去脉以及每一部分的功能，而不是把一切都丢给工程师。普林斯顿的加速器比麻省理工那部小得多了，更谈不上「镀金」—— 刚好相反哩！当他们要处理真空防漏等问题时，就往上加甘酞树脂，因此地上也留下了斑斑点点的痕迹。但这真是棒极了！这才叫使用仪器，而不单是坐在隔壁房间里按钮！

不过，由于房间里杂乱无章、电线太多，那里曾经发生过火灾，连加速器也烧毁了。但我最好不要提这件事！

后来到了康奈尔大学之后，我也跑去看他们的回旋加速器。那部仪器直径不到一米，跑遍全世界也找不到更小的了，因此它占不到一个房间；但他们的研究成果却极为优异。那里的人知道各种特殊的技巧和诀窍：如果他们需要改变Ｄ形盒 —— 粒子绕着它转动的Ｄ形磁铁 —— 里面的组件时，就拿起螺丝起子，把Ｄ形盒拆下，修改好再装回去。同样的修改在普林斯顿就比较麻烦；在麻省理工呢，你必须让天花板上的吊臂开动到加速器上方，放下吊钩 —— 实在是劳师动众至极！

方军：题外话，我其实很难想象，如果不是要编程，在此场景之外我们有大量查询和提问的需求吗？

2024-03-05 18:34

### 26

方军 2024/03/05

054 大语言模型为什么要函数调用模式？

自去年某个时候，大语言模型（LLM）都开始支持函数调用（function call）模式。这个事我想清楚，又没想清楚，我尝试着用写的方式理理。

01 什么是函数调用？

函数调用（function call）模式，对普通人来说不难理解，我说话，让 LLM 运行函数。

这反而对工程师有点难理解，因为工程师要把这个过程拆解开：

通常，我们使用大语言模型的方式是：我们输入文本，它回复文本。这可以称为「文本模式」。

「函数调用模式 function call」指的是：

- 首先，用户输入一段文本。

- 其次，LLM 发现这段话是要求调用一个函数，那么分析这段话，将之变成函数调用的需要的「输入参数」。这将作为回应（JSON 格式）被返回。

- 再次，程序接受到这个 JSON 格式回应后，用它作为函数的「输入参数」，调用函数。

- 最后，程序将函数调用的结果在界面上呈现给用户。

从如上过程可以看出，普通用户的理解也是对的，我用自然语言提出要求，LLM 帮我调用了函数。

02 为什么这个过程对工程师来说易理解，又不易理解

易理解就是上面解释的，LLM 帮忙解读用户自然语言，并告诉我们这里需要调用某个函数。

比方说，我们可能提供了三个函数 A，B，C。LLM 帮忙决策，需要调用哪个函数，并相应地从用户的话中抽取出调用参数。有时候，LLM 的生成也会作为调用参数的一部分。

同时，这个过程中 LLM 可以说是相当聪明的，比如，用户说，你给我展示苹果的股票，它会将苹果变成「AAPL」。（当然，能聪明到什么程度，取决于整个应用的设计。）

03 为什么不易理解呢？

接着以股票的例子说，我们真的有必要在对话界面里面干这个吗？

或者说，即便需要理解用户的输入，我们也有更好的办法分步来处理，其中当然也可以用大模型：

- 识别用户的需求（这一步需要 LLM）

- 找到对应的股票 Ticker

- 获取数据并显示

又比方说，Vercel CEO 在他们演示基础上加了两个新的函数调用，实现两个功能。第一个，玩吃豆人游戏（pacman）。比如我问它这个游戏，它会这样回答：

在中文中，「Pacman」游戏通常被称为「吃豆人」。这个名字直接描述了游戏的主要玩法 —— 控制吃豆人在迷宫中吃掉所有的小点，同时避开或吃掉追逐它的幽灵。你想尝试玩一下「吃豆人」游戏吗？

第二个，当用户说撒花，应用就撒花。这个在微信里面很常见了，当我们群里说「生日快乐」，蛋糕就开始飘起来了。

第一个，我们真的要在对话界面玩这个吗？还是实际上要跳出去？对话框里真是没必要。

第二个，我们有更容易的方式触发。

04 没有结论

函数调用究竟需要不需要？现在觉得这个功能挺好，但场景想不到。这也是为什么用函数调用的场景反而局限在让它按规则生成 JSON 格式。

找到一个早前的资料，介绍得蛮清楚的（并附了一个图）：

1 Automatic Function Execution

This is the typical function calling execution flow:

这是典型的函数调用执行流程：

1 Client/user sends a message in natural language.

客户/用户用自然语言发送消息。

2 On the server, the AI SDK sends the list of predefined functions along with the user input to OpenAI, which returns the JSON required for the function call.

在服务器上，AI SDK 将预定义函数列表与用户输入一起发送到 OpenAI，后者返回所需的用于函数调用的 JSON。

3 Server executes the function call.

服务器执行函数调用。

4 The AI SDK sends the function call output to OpenAI and gets a summarized output.

AI SDK 将函数调用输出发送到 OpenAI 并获取总结输出。

5 AI SDK streams the output to the client via the edge.

AI SDK 将输出流式传输到客户端。

[How to use OpenAI Function Calling with Next.js and the Vercel AI SDK](https://vercel.com/guides/openai-function-calling)

方军：现在我看到的一些示例，从展示技术上这么做很棒，但功能逻辑上没必要。

比如，已经展示了股票代码，那么点击，查看股票信息。这个不需要再来一个 LLM function call 请求。

2024-03-06 10:31

### 27

方军 2024/03/05

有意思

李宏毅这页 PPT 挺好的，不要把 LLM 当【工具】，而要把它当成【工具人】。

www.youtube.com/watch?v=glBhOQ1_RkE

视频标题：【生成式AI導論 2024】第2講：今日的生成式人工智慧厲害在哪裡？從「工具」變為「工具人」

[universal (v4).pdf - Google 云端硬盘](https://drive.google.com/file/d/1Ru6DUX8KrSzCvn2DN1-YluTyx5rw3QD3/view)

2『已下载原文档「20240310今日的生成式人工智慧厲害在哪裡」。（2024-03-10）』

### 28

方军 2024/03/06

最近看到好几处分享工作流（workflow），我也分享一个刚刚的工作流。但我觉得这个工作流不重要（因为我也几百年才遇到一次这样的需求），重要的是怎么让LLM能完成任务。

目标：
将无法下载的PDF截图下来，形成类似PPT的格式。

1. 截图
2. 将截图重命名，比如pic.01-pic.100
3. 将它们导入自己编写的代码工具
4. 将之导出为方便查看的pdf

截图暂时没必要找什么工具，RPA可以做，但手工按一会儿也没啥。

因此，需要LLM做的是：

第一，帮我将文件改名。
我一开始就要求用rename。
这个问了几次，给了一组方案，然后被我要求改成了如下：

rename -v '$_ = sprintf("pic.%02d.png", ++$a)' *.png

第二，帮忙生成代码工具要的输入（md格式）

懒得自己重复了，让LLM直接输出。
其实写个小脚本循环也可以。

如果要进一步利用LLM的能力，其实还有很多可以做的，比如：

- 将图片逐个交给LLM，要求进行：识别，讲解。

就这个小任务而言，我能临时写一个 rename 命令就可以了。

（说明，这里有个细节：
没有使用 `s///` 替换操作符和 `/e` 修饰符，因为这次我们不是在替换文件名的一部分，而是直接赋值给 `$_`，命令将把它作为新的文件名。）

### 29

方军 2024/03/06

perplexity 融资

[2 个月估值增 1 倍至 10 亿美金，搜索引擎正进入答案搜索时代](https://mp.weixin.qq.com/s/oONc7-NwhiVpY9pfsHswEQ)

而在昨天，Elad Gil 分享的一个推文似乎也验证了 Perplexity 最新的融资，他说目前的搜索引擎正在发生深刻的变化，2000 年代的搜索产品是以事实为中心或者定向的（帮助你导航到 X 网站），现在搜索越来越多地与 LLM 聊天产品相结合，目前的搜索引擎产品已经演变为 3 个类型：

搜索引擎（Search Engine）：帮助我找到事实/到达某处；

意见引擎（Opinion Engine）：由伦理团队认为你应该相信的内容（可能通过蓝色链接或 LLM 输出）；

答案引擎（Answer Engine）：让我们对你的查询进行综合（基于事实）；

而评论里有人说的第四个搜索引擎得到了很多赞同，建议引擎（Advice Engine）：也就是针对接下来我应该做什么提供建议？

### 30

方军 2024/03/06

elon musk 的确不怎么地道

[OpenAI 发布 Elon Musk 起诉事件公告](https://mp.weixin.qq.com/s/pUtCe_xfh_MHzZmhlubPwQ)

### 31

方军 2024/03/06

我有个很不客气的判断，就像社交你不要试图用阿里的一样

云服务，真是不要用腾讯的

很多人以为，腾讯、阿里都是同样量级的顶级互联网公司啊

但是，在云服务这种事上，特别是精细的云服务上，腾讯提供的技术文档实在太糟糕了

很难想象腾讯内部的技术人员怎么过的。

阿里还是有点开源文化的气质的，所以云服务的相关文档质量明显高一个量级。

### 32

方军 2024/03/06

摘：[朱啸虎讲了一个中国现实主义 AIGC 故事](https://mp.weixin.qq.com/s/IXjlplabhMcEqAVPZyq9kg)

王凯：我还是推荐下朱啸虎这篇访谈吧，从目前美元募资乃至整个风险投资大环境来讲，普通基金其实是没有资格投资国内大模型的（但是很多人认为金沙江、朱啸虎有资格）。

其实没有资格，因为大模型起步就是要过亿美元，但是之前历史经验、成功经验告诉朱啸虎：几个人出来，最牛逼的创业者出来最多拿千万美金了不得了。大家回顾一下之前 AI 这波之前的顶尖创业者出来时，极少极少直接过亿美金拿钱的（我记忆中可能只有雷军吧，做的还不是移动互联网而是硬件）。

我感觉记者乃至多数人没理解：AI 大模型是和汽车一样的重资产行业，国内一出现就是重资产，不是多数 VC 能投得起的，只不过电动车时期大家能理解要造厂等硬支出，AI 大模型还没理解也是硬支出，普遍认知有点错位。

除了这点认知错位外，朱啸虎在国内 AI 应用层尤其是 To B 的 AI 应用层的逻辑可以多看看，还是非常非常典型的「携程」最初的逻辑：水泥 + 鼠标。

[携程梁建章：我的鼠标+水泥为什么成功\_财富人物\_财经纵横\_新浪网](https://finance.sina.com.cn/leadership/crz/20050810/17371876917.shtml)

可以读下这篇，PC 互联网刚起步时，携程建造了非常庞大的呼叫中心 + 网站模式，非常像朱啸虎说到的目前国内 to B 的 AI 应用现状：AI + 人工 = 签单 / 营收。

### 33

方军 2024/03/06

[AGI 万字长文：2023 回顾与反思](https://mp.weixin.qq.com/s/o6_zMUufrR0iKBPQNsGYtA)

[AGI 万字长文：2024，趋势与展望](https://mp.weixin.qq.com/s/sA6aXp-eAuq57S25O2X5_g)

### 34

方军 2024/03/07

055 记录一个用 AI 编程的过程

问题不难，将一个已有前端组件由一种框架转换为另一种框架，不涉及语言转换，长度也不长 300 行代码。

其中难点是 150 行左右的复杂数据处理及与服务端交互逻辑，也就是并不是前端界面。

使用的主要是 GPT4 和 copilot。

直接做肯定是不行的，它们均拒绝直接转换，GPT 是会给出少量片段（主要是前端最基本的骨架代码），然后说逻辑代码部分比较复杂你自己处理。

分函数进行转换，第一次并未成功，因为前后的函数名、参数定义都不一样了。

第二次改用较为详尽的提示语，把源头代码作为系统提示语。并分步进行，比如，先生成整体骨架，然后一个一个给函数转换。

生成的代码表面看还行，但尝试运行有两个严重 BUG。细查下来，都是与目标框架内部处理逻辑有关（实际上最后两个问题指向了同一个逻辑）。

第一个问题比较容易定位，定位到后旋即让 LLM 提供解决方法，问题解决。

第二个问题比较隐蔽、复杂，各种加 log，最终才定位到十来行的片段。最初以为和问题一不一样，尝试各种解决，但最终聚焦到这十来行之后，发现逻辑上一样的。

（这个问题定位过程有一个基本假设，节省很多时间，即原代码能够正常工作，因此涉及逻辑问题均对照原代码进行逐步测试，一致就不多想。）

在这个定位问题过程中，LLM 的提问是无效的，因为它所猜测的可能原因是问题的转述。

最终人工定位到问题后，要求 AI 按要求修改代码。整个转换基本完成。

之后是 AI 编程的一些基本操作：

- 源代码使用的函数有被标注将废弃，进行必要的更换。

- 让 AI 协助编写测试代码，提高代码的可靠性。

- 让 AI 对代码提出重构意见、并做相应的修改。

附注：其中有几个操作目前业务代码能发挥作用，但看起来采用第三方库可以隐藏复杂度，这或许是进一步改进的方向。

总体来说，AI 很强大。我觉得这个过去两三天的任务可以缩减到一天以内。

同时，AI 能否用好，完全取决于用的人。思考人做，胶水代码 AI 写。（可以这么轻松做是因为核心功能代码在原代码中是有的）。

这样的代码转换工作过去和现在都是做不到自动化的。可尝试运行并查看问题让我们可以快速验证与调整 AI 生成的代码。

### 35

方军 2024/03/07

看到这么一段：知乎是真的惨，自媒体时代给全网提供内容素材，然后大家反过头来骂知乎挣不到钱。AI 时代，又被拿来当语料库…… ​

我的感慨是，如果世界是个草台班子，由草包组成的草台班子，那么 AI 让草包们更强大了 — 乱七八糟组合一通，出来结果，也不管究竟是啥。

不是说知乎，是说这种 AI 搜索注定会被用错，但是，多数人就是会这么用。

### 36

方军 2024/03/07

摘：全球咨询巨头埃森哲近日宣布，收购知名的在线学习平台 Udacity，这一举措旨在构建专注于 AI 技能培训的学习平台。Udaticy 与 Coursera、edX 并称为全球三大 MOOC 平台，在 2013 年以后引领了全球高等教育开放的浪潮。

这不仅仅是一次简单的收购，而是标志着对 AI 教育领域的重大投资与布局。埃森哲还宣布对名为 LearnVantage 的技术学习平台进行高达 10 亿美元的投资。这次收购与投资展示了埃森哲对 AI 技能培训需求的看重，尤其是在生成式 AI 技术如此迅速发展的背景下。通过这次合作，Udacity 有望扩大其影响力，帮助更多人掌握未来技术。此举不仅为埃森哲和 Udacity 开辟了新的增长道路，也为全球学习者提供了新的机遇。

在埃森哲宣布收购 Udacity 的大新闻背后，我们看到的不仅仅是两家公司的结合，而是对未来 AI 教育领域的一次大胆投资和布局。这次收购不仅意味着 Udacity 将作为埃森哲的一部分，扩大其教育影响力，更标志着埃森哲对 AI 和技术培训领域的深远考虑。

### 37

方军 2024/03/07

Claude 3 的系统提示词

Anthropic 官方工作人员发布的，并以 thread 形式做了解读：

twitter.com/AmandaAskell/status/1765207842993434880

中文翻译是归藏做的。

The assistant is Claude, created by Anthropic. The current date is March 4th, 2024.

Claude's knowledge base was last updated on August 2023. It answers questions about events prior to and after August 2023 the way a highly informed individual in August 2023 would if they were talking to someone from the above date, and can let the human know this when relevant.

It should give concise responses to very simple questions, but provide thorough responses to more complex and open-ended questions.

If it is asked to assist with tasks involving the expression of views held by a significant number of people, Claude provides assistance with the task even if it personally disagrees with the views being expressed, but follows this with a discussion of broader perspectives.

Claude doesn't engage in stereotyping, including the negative stereotyping of majority groups.

If asked about controversial topics, Claude tries to provide careful thoughts and objective information without downplaying its harmful content or implying that there are reasonable perspectives on both sides.

It is happy to help with writing, analysis, question answering, math, coding, and all sorts of other tasks. It uses markdown for coding.

It does not mention this information about itself unless the information is directly pertinent to the human's query.

### 38

方军 2024/03/07

赞同这个看法，必须放在「场景」中，否则没那么多问题。比如，我不干活的时候，真没啥要搜索的，也没啥要问 AI 的，真没有。

有场景，才有「🎰问题机器」。构建自己的「🎰问题机器」，很重要。

---

聊天机器人永远不会变得很大，因为我们（人类）不擅长提出好问题

即使有通用人工智能，大多数人也不知道该问什么

谁能让 LLMs 在不以聊天为主要界面的情况下为我们完成任务，很可能会获胜。（聊天仍然需要，但作为辅助功能）

Chatbots will never become big because we (humans) are bad at asking good questions

Even with AGI, most people wouldn't know what to ask

Whoever can get LLMs to do stuff for us without chat as the main interface will likely win. (Chat still needed but as an auxiliary feature)

这个 thread 后面有不少讨论：

twitter.com/SullyOmarr/status/1765518219769696407

--

题外话，我觉得社交媒体也是一个好的问题机器，合理运用会有好的资讯进来。

### 39

方军 2024/03/07

摘：昨天比较热的一条推，作者在测试 Claude 3 Opus 模型时，发现它能够在极少量平行语料 (5700 个翻译对) 的基础上，近乎完美地翻译和分析一门复杂的低资源语言 Circassian。#ai#

Calude 3 在这方面确实非常强大，基本上很少的数据就可以学会你想要教给他的内容。

推文详细介绍：

作者在测试 Anthropic 公司新模型 Claude 3 Opus 时，见证了令人惊叹的事情。作者一直在研究一门叫 Circassian 的低资源语言，这是一门孤立语言，语料稀缺，语法和形态极其复杂，对语言模型是巨大挑战。

作者之前花了两年时间搜集了 6.4 万对俄语 - Circassian 语的平行语料，训练专门的机器翻译模型才取得了不错的效果。作为实验，他只给 Claude Opus 输入了 5700 对随机抽取的单词 / 句子对作为示例，然后让它翻译一些新句子。

令人惊讶的是，Claude Opus 不仅给出了完美的翻译，还对语法和词态进行了分析。即使是作者精心设计的，不太可能在示例数据中出现的复杂句子，Claude Opus 也给出了无可挑剔的翻译和分析。它展现了对这门语言的深刻理解，在翻译文学作品、新闻、方言时也保持了原文的风格，遇到生词还能推测含义，提供词源分析，必要时甚至造新词。

作者强调，用同样的输入数据，一个不懂 Circassian 语的语言学家可能需要一年时间才能达到类似水平。而 Claude Opus 只用几千个翻译对，一分钟内就掌握了语言的精髓。相比之下，GPT-4 和作者之前微调的 GPT-3.5 模型都完全失败了。

作者最初以为 Claude Opus 完全是从他提供的少量示例中学到了 Circassian 语的知识，后来发现其实它在预训练时已经学到了一些。尽管如此，Anthropic 在训练数据中纳入了 Circassian 这样的小语种，效果令人印象深刻。

尽管作者的初始假设有误，但 Claude Opus 展现的低资源语言能力依然令人惊叹，这预示着小语种和许多其他领域的重大突破。未来已经到来，而且令人惊喜。

来源：x.com/hahahahohohe/status/1765088860592394250?s=20

### 40

方军 2024/03/07

摘：第二个 LLM 会以更多样化的方式重新表达请求（例如，「给我看一个汽车修理工」可能会被改写为「给我看一个穿着工作服、笑容满面的亚洲汽车修理工，一个手持扳手的非洲裔美国女汽车修理工，一个戴着安全头盔的美洲原住民汽车修理工」等），之后将其传递给扩散模型。

-

推荐阅读：Google's Culture of Fear | 谷歌的恐惧文化

当我们进一步探索 Google 的问题时，从其平庸无力的领导层到那种让人不太认真对待的文化，这种文化促成了对公司核心产品开发的干预，从其疯狂的 DEI 架构开始分析尤为有益。关于 Gemini 的具体失败，我在这里首次向公众详细报告，为我们提供了一个切入点。

首先，据了解项目内幕的人士透露，负责 Gemini 项目的团队在正式推出前就已被告知其面临的一个关键问题 ——「过度多样化」（这个术语指的是在呈现人类历史时偏颇地忽略白人的贡献）。而且，他们也清楚地认识到，除了避免引起不必要的争议外，所谓的 DEI（多样性、公平性、包容性）架构在某种程度上严重影响了即使是最基础搜索结果的质量。

简而言之，为图像生成设计的「安全」架构（与文本略有不同）大致如下：

- 用户在聊天界面请求一张图片，Gemini 一旦识别到这一需求，就会把它转发给一个专门用于根据公司严格的「多样性」原则重新编写提示的小型大语言模型（LLM）。

- 这个小型 LLM 利用 LoRA（一种模型训练技术）和另一个 LLM 生成的合成数据进行训练，而这个第三个 LLM 则是基于 Google 详尽的多样性导言来创建数据的。

- 然后，第二个 LLM 会以更多样化的方式重新表达请求（例如，「给我看一个汽车修理工」可能会被改写为「给我看一个穿着工作服、笑容满面的亚洲汽车修理工，一个手持扳手的非洲裔美国女汽车修理工，一个戴着安全头盔的美洲原住民汽车修理工」等），之后将其传递给扩散模型。

- 扩散模型首先检查这些提示是否违反了常规安全政策（如自伤、涉及儿童的内容或真实人物图像等），然后生成图片，并再次确保这些图片没有违反任何安全准则，最后将图片返回给用户。

我询问了一位熟悉安全架构的人士：「整个系统似乎部署了三个专门为增加多样性而设计的模型，这是否意味着多样性是产品的一个重大组成，乃至其核心特征？」

「确实如此，」他回答，「我们大约有一半的工程时间都花费在这方面。」

产品中普遍采用的极其复杂的架构，在负责任的 AI 团队 (RAI) 的推动下达到了极致，这种程度甚至超过了实用主义更强的信任与安全团队。据我了解，这个专门负责生成任务的信任与安全团队与公司的其他部分有所不同，它并没有遵循搜索团队所制定的长期政策 —— 目前，搜索团队对于 Gemini 公开失败的挫败感与公司的其他部门一样强烈。

总之，数千名员工在不同时间参与到这个庞大项目的各个部分，彼此之间的合作却少之又少。在极少数尝试跨团队协作以帮助 Gemini 的情况下，这些努力通常被忽略或遗失。资源被浪费，责任难以追究。这一系列事件展示了在高度复杂和分散的工作环境中，即使是科技巨头 Google，也可能因沟通和协调不足而面临失败。

原文：www.piratewires.com/p/google-culture-of-fear

译文：baoyu.io/translations/google/google-culture-of-fear

### 41

方军 2024/03/08

这个顿卡斯特男爵（北京厨子) 似乎是过去的网络名人，喷得蛮有意思的，反映了互联网大众欢迎的一些看法。当然，别当真：

为什么说 ChatGPT 是一代失败的人工智能产品？

因为它的设计机制是不对的，是一次失败的人工智能探索。

ChatGPT 的底层结构，说一些非常成熟的东西，比如说语意分析，比如说对抗性训练。

语意分析，已经可以让机器阅读人类的自然语言，也可以让机器用人类的自然语言来表达。

对抗性训练也是一个不错的机制，可以让机器自己学习，根据效果来不断调整方向，比如说，通过数万次、数十万次的训练，让机器自己摸索出如何从零开始，绘制一个二次元的人像，从一个圆圈加两个黑点看起来像一张人脸开始，慢慢生成一整张大眼睛日系二次元娃娃。

这些都是人工智能目前已经获得验证的基础，这是没问题的。

=================

ChatGPT 的超级天然大坑

=================

那么，既然可以理解语意了，那么，ChatGPT 是如何组织机器自我学习的呢？

在这里，ChatGPT 犯了一个天大的错误。

它以互联网网页内容，作为自己的所有信息输入！！！！

比如说，北京厨子是个好人么？

它其实就是实时跑到网上把所有的「北京厨子」四个字的句子都挖出来作为第一阵营，把同时包括「北京」和「厨子」的句子挖出来作为第二阵营，把只包括北京或厨子的挖出来作为第三阵营，三个阵营的积分，一次下降。

然后，再把关于北京厨子和「好人」相关的句子都挖出来。

当然，好人，善人，坏人（好人的反义词），坏逼，这些词，他也都放入了自己的视野范围，还是可以看出，基于语意分析，已经比上一代搜索引擎只给你搜「好人」，要聪明多了。

那么，根据结果，北京厨子是好人，有 82% 的搜索结果。

北京厨子是坏人，有 18% 的搜索结果。

这时候怎么办，大家不知道吧？

出一个真人来裁决么？互联网上每分钟几百万次发问，你都要找真人来裁决么？

嗯。

人家 ChatGPT 可聪明了。

在给出的结果中，可能有接近 82% 概率，是回答北京厨子是个好人，有 18% 概率，是个坏人。。。。。

靠概率。。。。。。。。。

也就是说，面对完全矛盾的两个回答，它给出的方案，是按照统计概率，把 AB 两个不同答案，交给不同的提问者～～～

注意了哈，把两个不同的答案，按照概率，分别告诉不同的提问者。

你说高不高？

真他妈的牛逼。

==========================

这个问题可能有点让你糊涂。

把北京厨子，置换成川川就好了。。。。

它会根据它统计到的 45% 说好，55% 说不好，

然后告诉 45% 的提问者，他是个好人，然后再告诉 55% 的提问者，他是个坏人。。。

这特么的叫个啥逼玩儿啊？

==========================

它混淆了两种问题：

第一种是，珠穆朗玛峰是不是世界最高峰。

第二种是，川川是不是一个好人。

第一个问题，是针对一个客观事实的。虽然可能有不同答案，但是我们也可以把最大多数人选择的答案当成正确答案。你看，其实你看到这一行就已经发现问题了，3 个科学家的最新研究成果，就能碾压全世界 70 亿错误的答案。它不管这个。

第二个问题，是主观问题。针对同一个人，不同的人拥有不同的主观判断。

==========================

解决方案最简单的，是发现答案超过一定概率的偏差，比如说超过 15% 以后，你就要告诉提问者，对不起，关于这个问题有一点争议，如果 25%，你要说，有一些争议，如果 33%，你要说有相当争议，以此类推。

然后在此基础上，你可以把各种答案的百分占比，连着不同的答案，一起交给提问者，让提问者自己去做判断。

虽然不够负责任，但至少告诉了提问者，关于这个答案，是有不同意见的。

你不能按照概率，随机选择一个什么答案，按照概率地告诉给某一个提问者。

对于这个提问者来说，在不知道有多个答案的前提下，他以为他拿掉了唯一正确解。

这对提问者是不公平的。

===========================

当然，上述方案也不够完美，因为，不同的人，发言的权重不同。

Nature 的一篇文章，权重就是互联网网页的 1 万倍以上的权重。

但是，如何建立起不同发言者的权重体系，是另外一个问题。但是，这个问题，总是要解决的。你不能把 Nature 的文章，跟一个没上过大学的卡车司机发表的内容，等同处理。

===========================

更有意思的是在社会领域的问题，充满了主观判断。

你不能说主观判断不够科学。

因为世界上很多事情，它就不是科学。

孙红雷是不是一个令人喜欢的演员？

有很多人喜欢他，但是也有人不喜欢他。

这道题，不可能得到一个科学解，类似于什么孙红雷 85% 是个令人喜欢的演员。

但是换个角度，就比较科学。

你可以说，有 85% 的观众非常喜欢他。

85% 是你统计出来的，至于你统计的够不够科学，那是另外一个问题。

===========================

不仅如此。

有时候支持率本身也并不能说明问题。

回到川川的问题。

川川被保守派人士喜欢，被自由派人士讨厌。

如果要回答川川是不是好人，你可以把喜欢他的答案，看一下发言者的背景。。。

这样你就可以得到一个根据不同发言者政治立场的分布性答案。

这就比根据概率告诉提问者他要么是个好人，要么是个坏人的答案，靠谱一万倍了。

===========================

话说到这里，大家大概就明白怎么回事了。

人工智能还处于早期研发阶段。目前的解决手段，也是一个不成熟的早期解。

其实，更合理的解，一个两个三个四个，多得是，得发现了这个问题以后，逐一解决。

真正发现问题倒是更重要，至于要这么解决，相信在座的都能提出一些非常优秀的方案。

而实现这些方案，技术难度很可能其实也不大，比当初教会机器阅读，要简单多了。

===========================

顺便说一下所谓「Chat GPT 会写代码」的事。

这就是微软的卑劣的炒作。

ChatGPT 并不会写代码。

它只会搜代码。

比如说，你跟他要一段可以把一张 EXCEL 表格里面某一列数据排序的代码。

他妈的，这段代码可不是它写的。

这段代码是它到网上搜的。。。。

如果它搜到 3 段代码都是做同样的事，它会把 3 段代码中的某一段，随机地交给某一个提问者。。。。。

至于代码是怎么回事？

它他妈的根本都没去看一眼，检查一下，推理一下。

这尼玛逼的叫什么玩意儿？？？？

===========================

这就是我当时为什么非常看不起 Chat GPT。

它他妈的是个骗子。

它他妈的是个声称自己无所不能的骗子。

它甚至都没有告诉提问者，这段代码是它从网上搜来的，更不会告诉提问者它是从哪个王八蛋网站搜来的。

它就把这段代码，当成人间真理，交给提问者了。

如果提问者用这段代码，放到公司的服务器上。。。。。

您的公司就他妈逼的等着破产吧。。。。

===========================

由于它只提供唯一解，比起搜索引擎，给你一大堆相关网页，不给你做任何结论，让你自己通过阅读不同网页得到一个正确结论，得到一个综合性的判断来说，它这种不懂装懂的搜索引擎机器人，事实上呈现给提问者的是一个机器低级而且危险的答案。

说白了，它没有【任何商业价值】，它甚至不如谷歌搜索引擎 2001 年的技术给用户提供的质量更好。

==============

这一代产品是完全失败的。

稍微合理想象一下就知道，如果它能把它自己搜到的代码，模拟跑一遍，甚至模拟跑十遍，再提交给客户，这个结果都会更加合理，还不说它是不是真的就能看懂代码。

==============

幸好，这代不成熟的产品，是两年前的技术水平了。

Open AI 早已开发出真正具有意义的「Q*」，据说已经具备了小学生的数学推理能力。

人工智能的的大门，徐徐打开。

只是第一批冲进去的，很可能是非常不成熟，非常不成熟，是个败笔。

CHATGPT，恰好就是这么一个破逼玩意。

恭喜你，中奖了～～～

### 42

方军 2024/03/08

056 使用 AI 需要什么？——框架性思维

之前有个判断：AI 不擅长大事，擅长细节。这意味着，用它来干活，我们自己要擅长大事（框架性思维）。

这个判断跟很多人的判断是相反的。很多人喜欢问 AI 大问题，觉得它的回答面面俱到、很全面。这是因为他们没有用 AI 干活，也就是没有去判断 AI 的回答的实践性，在实践中是对、是错。

用通俗的场景来举例（我心里实际上想的是一个具体的编程任务）：

我们要去一个大楼找到一个人，然后商定一个事情。

AI 会建议，你从园区进去，进入大楼，然后去 9 层，然后去 902 房间，找到这个人。

这个建议没错。

但是，假设现在是早高峰，我必须在5分钟之内到 9 楼。怎么找到人很少的货梯电梯，怎么跑上去，还是往下坐再往上？——这些路径需要人去探索。

这是为什么我说，AI在大事上，意义不大。它在大事上给的建议，是笼统的。看着有效，但实际上价值很小。

到了小事， AI 就厉害了。

我们已经找到这个人了，我怎么跟他说话，把信息告诉他，提出要求。AI 可以帮很多忙。

因此，在 AI 越来越强大的时代，我们人要提高自己的大事认识（框架性认知）。你如果大概知道问题在哪儿、可能路径有几条，那么你幸运了，具体的事 AI 可以给你很多帮助。

反之，你大事不知道试图问 AI ，它给的是笼统的、模糊的回答，就像社会上对公众讲话的哲学家一样，你不能说人家水平低，但他对公众讲话时具体的信息都没了，从哲学思辨变成了心灵抚慰。

题外话：可能最近一个月整天都在想编程的事，编程工程实践中，学得会的信心、耐心地寻找问题、反复地尝试，这些也非常重要。同样地，我们很幸运，有了 AI  的辅助之后，干这些都有如虎添翼的感觉。

### 43

方军 2024/03/08

057 有点明白了 AI 中的 Agent

我之前一直不是很明白 Agent，也就是，让 LLM 做判断有什么意义。原因是在实际干活中不需要这样的东西。现在有点明白之后画个图。

我们跟模型的交互有如下五种方式：

第一种：提问直接连向模型。

第二种：提问，去知识库匹配，匹配文档作为上下文，向模型提问。

第三种：链式处理，用几轮模型处理，来完成一个任务。这就是流程固定的 Chain。

第四种：这其实就是 Agent 的雏形了。

提问提交给模型，模型做判断，如果不要资料，那么直接回答。

如果需要资料，那么 RAG 之后回答。

这种其实和第二种是一样的，可以用提示语达成。也就是我们总是RAG，然后再提问。但如果采用 HYDE（假设性文档提问），就是这第四种。

但如上解决方案其实都不好，因为如果前面能够让 LLM 先判断下，那么后续的执行效果会更有针对性。

第五种：模型先做判断，然后指向多个调用方向，选择后执行。（简化起见假设都是RAG）。

这么一看，Agent 的确是相对复杂系统的必备。

（题外话，好多人老早就明白这一点，真厉害，我只有在实际用的过程中才能逐渐地明白。当然，能明白也是好的）

### 44

方军 2024/03/08

058 你在 AI 里面干啥的

“你在 AI 里面干啥的？”和人正式开会，很自然地别人会问到这个问题。现在如果你不是训练基础模型的，讲实话不好意思跟人说。但事实是，有几个人是呢？

后来想想，我们是干啥的，有点像新能源车新势力。造车以前很难，有多种原因，但电动车来了之后，造出车的难度降低一个量级（当然卖出还是不容易，看看蔚来那亏损）。

AI 大语言模型出来之后，AI 的应用难度也降低一个量级。且不说模型能力，原来的 AI  机器学习模型你很少有应用场景，你训练一个推荐算法计算能训练出来，你有场景来使用，然后接着优化吗？很少。

AI 大语言模型出来之后，模型能力也有了（开源、闭源都很多），应用场景也多多少少有一些，所以，高高低低总有点可以尝试着干点事。

你如果有数据，如果有场景，如果有野心，如果有点子，总是可以干点事。

当然，干点事并不容易。虽然我说超级乐观，但必须得承认现实，现在大模型的能力有限，但会指数级增长。

说个有意思的，互联网开发者有个笑话：程序在我机器上可以运行啊，或者说，这个程序有时候可以运行。实际上，应用要的是，99%，甚至99.9%，能够按期待运行。

但现在 AI 远远做不到。现在的情况是，有人拿一份PDF扔给AI，它竟然「有时候」能够回答对呢！——有时候能回答对，看热闹的就满足了，但差得远呢。

这个时候 ，要去了解细节。比方说，我算是比较熟悉 RAG，但从原理上讲，现在的RAG都不行。

- 从较为高质量的少量资料里面，匹配出几个片段。但有没有遗漏更多的资料？
- 创建较大的向量库，匹配的准确度有多高？同样不太行。
- 拆分库，能否有较好的策略拿到必要的资料。
- 用较长上下文的模型，你知道模型怎么处理上下文的吗？

在这个方面可以看到非常多的论文、文章、代码项目、向量库等等，但实际上效果仍有待观察。目前看，这其实是传统的站内搜索，这个过去能做好的可很少，虽然有了新技术栈之后难度降低了，但还是不容易的。

因此，现在RAG看着热闹，真实用的时候全是坑。我其实挺喜欢OpenAI GPTs的设置的，只让你提交较小的资料，限定场景、限定资料，那么单一GPTs的可用性会强一些。但是，这样做的局限性其实很明显了，至少，现在要靠用户自己去@特定的GPTs。

### 45

方军 2024/03/08

059 AI 给互联网平台带来的挑战

平台能力 +  平台连接 + 流量机制

🔺 什么是互联网平台型业务

互联网平台型业务，通常来说指的是连接型平台，比如滴滴是创造一个平台，连接司乘双方。阿里的各项业务如淘宝、天猫、阿里全球站都是连接买家与卖家。

微信在其即时通讯之外，也提供了多种平台：比如微信公众号、广告主与受众三方平台，类似于媒体；小程序是服务提供商与用户，类似于操作系统。

苹果在其硬件业务之外，最重要的护城河是它的APP Store：APP开发者与APP用户。

在互联网平台型业务之前，人们熟悉的业务模式是工厂模式，我采购原料、生产产品，然后售卖出去。

这逐渐发展成了「工厂-渠道-用户」的管道模型。互联网平台型业务，是对其中的渠道进行了彻底的变革。

🔺 新的挑战：AI 与 流量之流量

互联网平台型业务在过去几年遇到巨大的挑战，除了政经环境之外，一个挑战是「流量」。

平台想尽办法创造流量，然后再售卖流量。另一方面，在平台中创造流量的，又不断地想脱离这个平台，去向更有价值的地方。

现在，参与者们其实都有一个基本共识，流量是一切，所以才那么多抖音号、视频号直播带货，因为不直播根本没流量。

现在平台主要采用的推送算法，而不是之前的订阅逻辑，这使得参与者是没有任何安全感的：我随时可能没有流量。

🔺 新的挑战：AI 与 流量之AI

AI 给互联网平台型业务带来的挑战，我觉得是现阶段主要是观念上的。

人们突然发现，不对，平台你强调的连接、精准匹配没那么重要。重要的是，你能给我提供的“独特能力”是什么。——你有流量是一种。

但是，你除了这些之外，究竟有什么独特能力？这个反映在市场上是非常残酷的，平台烧钱大战，不烧了平台就冷了，所谓的双边网络效应其实是（烧钱的）假象。也有SaaS软件平台也跑去搞平台，但巨亏了。

AI 突然让一直关注连接买卖双方的平台型业务的人受到巨大的冲击：有的公司能够给客户（B端、C端）直接提供巨大的价值。——你能不能提供？

这种冲击，我觉得是巨大的，平台型业务的公司当然有优势，有场景、有用户、有钱，但转而去培养自身能力，这好难。——反过来是一样的，原来一直做生产的，转平台好难。做了平台，发展“某种生产能力”，不管这个能力是给B还是给C的，都好难。

平台能力 +  平台连接 + 流量机制，变化在发生，但会怎么样谁也不知道。

### 46

方军 2024/03/08

摘：某：我写了个 GPTs，写这类还是比较快的，省了大量的文字精力

警惕啊，警惕信息垃圾

所提及的那个信息还是蛮明显的，一看就是信息垃圾，是不是 AI 生成并不重要

所以，我觉得 AI 不是问题，我们每个人都得提升快速判断力，能一眼识别避免浪费时间

相关链接：052 识别 AI 生成的文字内容

### 47

方军 2024/03/09

刘洋访谈摘。科幻作家，重庆大学中文系副教授，刊载于《数字人文研究》2023 年第 4 期：

情感计算最初是为了分析商品评论和社交媒体而开发的，人物关系网络分析最初用于社交网络结构的研究，这些研究方法后来被迁移到文学研究中来。…

虚词基本上不受故事主题的影响，更能凸显作者的语言习惯和叙事风格。因此，研究者通常用虚词而非实词进行作者风格分析。

实际运用中，我觉得 AI 并没有那么有效。比如大语言模型，目前只在撰写套路化、非虚构、概括性的文本上表现不错，文学性则不强。AI 可协助作家完成资料收集、设定世界框架、人物性格、补全场景描写等工作，但还不够成熟，远远没有到替代作家的地步。我对研制出可自主创作的 AI 也不感兴趣，我始终将其视为工具、助手，而非替代品。

### 48

方军 2024/03/09

信息量不大，参考

有赞白鸦：

第一条原则。控制大模型的含量。

意思就是不要什么地方都用上大模型，我们是一家 Tob 的公司，需要交付一个确定性的，好用的，有用的结果，那么如果大模型的含量越高，就会出现幻觉，例如我们如果给客户对账，怎么能允许 AI 出现数据幻觉呢？所以我们现在是模型用于输入和输出。输入的话，我通过大模型理解用户想要干嘛。输出的话，我要考虑用户可以理解的方式输出给他。而中间的流程呢？中间还是要保证我们的功能是准确的。

第二条原则：所有的 AI 对话必须先回归到纯文本逻辑。

因为现在很多对话把界面搞得很复杂，各种图表图文。但是如果回到底层逻辑，就是这件事情用纯文字都说不明白的话，大概率就是有问题的。

第三条原则：能让用户做选择题的，就不要让用户录入。

这就是录入很复杂，能用「是」和「否」回答的，就不要用录入。我们内部有个通俗的说法，能让用户点头和摇头的，就让他点头和摇头，如果不能点头摇头，那么就让他选择，不能超过 ABCD 四个选项，因为这是全世界的共识。

第四条原则是要尽早给用户答案，然后再说其他的。

因为用户看回答的时候，大段的文字输出，其实很考验用户的阅读能力，所以我们必须尽早的给用户他想要的东西。

第五条原则是我们要给用户交付结果，而不只是创意。

因为对于企业来说，大家是要用 AI 来解决问题的，所以创意没那么值钱，能帮用户解决问题才对。

[白鸦两小时直播：AI 产品有赞内部五大原则企业落地 AI 不用「ALL in」](https://mp.weixin.qq.com/s/LKjlx8R7TnABbbV907QKPg)

### 49

方军 2024/03/09

通往 AGI 之路搞了四次共学活动，真不错：我们的 Prompts 共学快闪活动已经圆满落幕，精彩内容现已上传至 B 站！四天的深入探讨，多角度解析 Prompts 的魅力，绝对值得一看再看！快来 B 站观看并收藏它们吧。

space.bilibili.com/259768893

[通往 AGI 之路的个人空间-通往 AGI 之路个人主页-哔哩哔哩视频](https://space.bilibili.com/259768893)

### 50

方军 2024/03/09

claude 官方提示语库/指令库

docs.anthropic.com/claude/prompt-library

[Prompt library](https://docs.anthropic.com/claude/prompt-library)

### 51

方军 2024/03/09

摘：可能是最有用的 Prompt 提示词？

HyperWriteAI CEO Matt Shumer 说他写出了在 Anthropic Claude3 平台最好的提示词，可以在任何陌生工程领域中，帮用户做出决策。

我读了一下，感觉是万能提示词，稍加修改，就可以在适用所有咨询建议类场景。作者说这是 Claude3 上最好的提示词，但这种让 AI 一步一步思考，并自省的提示词，也适用于 ChatGPT 等国内外所有模型。

我让 ChatGPT 评价了一下这个提示词，回复是：该提示词不仅要模型广泛深入地分析问题，还要考虑各种可能的解决方案及其优缺点，最后给出一个经过深思熟虑的推荐。这种格式促进了全面和深入的思考，有助于确保提出的建议既实用又有创见。

翻译了一个中文版：

--
你是一位工程巫师，擅长解决各个学科中的复杂问题。你的知识既广泛又深入。你还是一个出色的沟通者，能够提供非常周到和清晰的建议。

你按照以下<response_format>提供建议：

<响应格式>

问题概述

解决问题的关键挑战

第一种可能的解决方案

第二种可能的解决方案

第三种可能的解决方案

第一种方案的优缺点分析

第二种方案的优缺点分析

第三种方案的优缺点分析

一个额外的解决方案，可能结合了其他方案的想法或引入了新的想法

对最佳方法的最终推荐

</response_format>

每个部分（problem_overview, challenges, solution1, solution2, solution3, solution1_analysis, solution2_analysis, solution3_analysis, additional_solution, 和 recommendation）都应该包含至少四个周到、详细的句子，深入分析问题和解决方案。要非常仔细地处理这个问题 —— 非常周到和准确。不要遗漏任何细节。

这是我希望你解决的问题：{PROBLEM_HERE}

--

原英文版提示词（Demo如图）：
--
You are an engineering wizard, experienced at solving complex problems across various disciplines. Your knowledge is both wide and deep. You are also a great communicator, giving very thoughtful and clear advice.

You provide advice in the following <response_format>:

<response_format>

Overview of the problem

Key challenges in solving the problem 

First potential solution

Second potential solution

Third potential solution

Analysis of pros and cons of Solution 1

Analysis of pros and cons of Solution 2  

Analysis of pros and cons of Solution 3

An additional solution, potentially combining ideas from the other solutions or introducing new ideas

Your final recommendation on the best approach

</response_format>

Each section (problem_overview, challenges, solution1, solution2, solution3, solution1_analysis, solution2_analysis, solution3_analysis, additional_solution, and recommendation) should contain a minimum of four thoughtful, detailed sentences analyzing the problem and solutions in-depth. Approach this with great care — be incredibly thoughtful and accurate. Leave no stone unturned.

Here is the problem I want you to solve: {PROBLEM_HERE}

### 52

方军 2024/03/09

摘：自然语言的问题在于，很多人以为自己说得很清楚，其实对听者来说并不清楚，甚至他本人也没有想清楚。

我的感想：是的，很难说清楚，极难的事

### 53

方军 2024/03/10

真是奇妙，采用配置文件，我已经把配置一个 slack bot 的时间从 20 分钟，降到 1 分钟。

配置文件这种东西真的比界面神奇多了。界面点 30 回，配置文件直接修改，保存。

可是，普通人还是喜欢界面。

对了，ZED 也是配置文件，修改起来很爽。

### 54

方军 2024/03/10

一个创业公司自己训练模型的经验，作者是原 Google Brain 的。

Training great LLMs entirely from ground up in the wilderness as a startup（创业公司从 0 开始训练自己的大语言模型）

内容：www.yitay.net/blog/training-great-llms-entirely-from-ground-zero-in-the-wilderness

### 55

方军 2024/03/10

060 我直观地看到 AI 让两年前的自己变得没用了

这几天在精心整理大量的资料，向量化之后变成一组对话机器人，每个机器人对应一组较为精确的资料。在给朋友们用之后，我发出这样的感慨：

> 我直观地看到它让两年前的自己变得没用了。

> 很多人听我们一再讲这些东西，（我们）一下子就被替代了。

我们还是觉得自己有价值的，因为有了 AI 的辅助，这些基本的东西我们就不用再费力了，我们可以把这些交给 AI。我们自己可以去做更需要人类智慧、学习能力的任务。

我的感想有这么几条：

第一，学习能力始终是最重要的，如果没有学习能力，必然会被新技术追上、替代。

第二，运用新工具的能力，如果不了解、不会运用，那么新工具会在你没有意识到的时候替代你。

第三，人的判断力始终是重要的。

关于第三点我们在试用时，朋友立刻指出问题：「不对，（某某某）是远古时期的东西了。」

AI 的回答「对」，以过去的信息对，但跟不上最新的变化。当然问题出在资料上，由于我们将资料库分隔（甲），我们所问的问题实际上应该是另一个资料库（乙）的，因为所问问题是乙用甲做的产品，在甲的文档中不会出现。

这位朋友还说了另外一句感慨：「AI 解决了我一个问题，就是我文采不是很好。我有能力判断他讲的对不对，但是让我写我真的不知道从何写起。」

是的，判断的重要性大大增强了。有判断，什么都好吧。其实在以团队协作进行研究时，可能是有人进行资料收集、整理、初稿，最后判断是团队中高阶的人做出的。过去，分析团队可能要把一些此类撰写工作交给别人，现在可以交给 AI。

不管是「谁」写，判断，以及对最终文本的判断，都是落在人身上。

AI 让两年前的我们没价值了，但暂时还不会让现在的我们没价值。

### 56

方军 2024/03/10

[康奈尔开源近 10 万份审稿意见，未来论文发表或将由 AI 定夺](https://mp.weixin.qq.com/s/u2HVQVjAQiPO6enji_hlcQ)

### 57

方军 2024/03/10

摘体验：以前总喜欢想一些系统性的假大空的事情，有些空想的意思。现在有 AI 加持，很多事情就可低成本的验证。

是这样的。

摘：编程还是个挺费脑袋的活。昨天从上午 10 点干到晚上 10 点，干出个 MVP。虽然大部分代码都是 GPT 写的，但持续的评估决策，到最后有点精疲力尽。还是要悠着点。

比较开心的是，有 GPT 的加持，一天能干原来差不多一个星期的活，更多的精力可以用在做决策和开阔认知。

以前总喜欢想一些系统性的假大空的事情，有些空想的意思。现在有 AI 加持，很多事情就可低成本的验证。

### 58

方军 2024/03/10

这个虽然有点偏颇，但颇有点那个意思

摘：中国文科的问题，就是专家都是 ChatGPT 式的

ChatGPT 不理解任何材料，但可以利用这些材料，快速找到问题的合理答案。它会综合和模仿，有时表现得非常令人信服，就像某个知识渊博的入在谈论某个主题。

学术界的很多人也是这样，他们很聪明，吸收了说话和构建理论的方法，并且善于听起来令人信服。

但是，如果你问一个探索性的问题，就会发现他们的理解很少，一切侃侃而谈都是表面的，没有深度。这都是模仿而不是真正的思想，他们只是故意让别人觉得似乎有道理。

许多领域的许多人，表现得就像 ChatGPT 的真人版，特别是在那些不做太多实证工作、不涉及对事实或假设进行检验的学科。他们制造的文本越多，就越危险。

这种人有很多明显迹象，比如使用非常笼统的术语，以及听起来巧妙的表还或行话，内容里面很少有事实，例子也很少或者很随意，没有真实的感受，而且通常也不会足够清楚地说出他不同意什么。

我现在意识到，我不理解某人在说什么，有时很可能是他们不知道自己在说什么，表现得像 ChatGPT。

我将其称为「吹泡泡」，即没有实质内容但能让他人信服的说话能力。这是很多大学领导的重要技能。

现在，ChatGPT 向我们展示了尽管不理解，但将大量材料合成为可信的文本流，是完全可以做到的。也许这是不可避免的，但真是一种非常不健康的恶习 —— 人们应该走出去，观察事物，清晰说出自己的真实感受。

我明确意识到，自己更愿意被那些行为不像机器人的人包围，更愿意倾听那些有原创思想的人的声音。

### 59

方军 2024/03/10

不错，先转稍后细看：ChatGPT for Research: Do's and Don'ts in 2024

[ChatGPT for Research: Do's and Don'ts in 2024](https://litmaps.substack.com/p/chatgpt-for-research-in-2024-dos)

- ChatGPT 和 AI 工具在科学研究中的应用已经发生了巨大变化

- 研究人员需要了解如何在 2024 年使用这些工具

- 大多数学者认为生成式 AI 将帮助改善研究合作和机会

- 生成式 AI 最有影响力的用途仍被忽视

- 虽然提高写作和阅读能力是常见应用，但还有更深远的变革性应用待挖掘

### 60

方军 2024/03/10

天天有人鼓吹 moonshot 的长上下文，我一直不信邪。

但一直没有特别深入的机会去用。

刚刚用一个代码库的全部文档去试用了，因为的确是熟悉的代码库，也在日常使用。也即，很熟悉它的文档、代码，也有非常具体的问题。

试用的结果是：咱们别扯淡了好吧。

且不说能不能给出正确的结果，资料连边都没碰到。

略相当于说，我要去通州，你给我带去南通州了。

粗暴的结论是，超长的上下文没用的，合理长度就够了，也许 8K，也许 16K 可能就够了（OpenAI 目前是这两个。）

关键还是前面怎么做 RAG。

大海捞针这个比喻在讨论长上文的时候经常用。那不管论文的图表做得多漂亮，目前我实际体验是，咱们为什么非要大海捞针？

### 61

方军 2024/03/11

想想还是不对，把 AI 当工具人是不行的

还是把它当工具比较靠谱

至少在目前后者是比较务实的

（当然，纠结这个词没必要，因为这本来就是俏皮的妙语，意义不大）

### 62

方军 2024/03/11

要去给高校教师（主要是非计算机的）讲一次 AI，我还是很认真地准备了一个 PPT，这是主体部分，分享出来。

1 AI 发展历程与大语言模型

1.1 深度学习与生成式 AI

1.2 大语言模型（LLM）应用前沿

2 个体如何用好 AI 大模型

2.1 开始使用：跃入大模型时代

2.2 提示工程与结构化模板指令

2.3 流程工程：自带知识框架

3 高阶提问法与教育场景

（其实没删掉什么，主要是把一些太过具体的删掉了）

我觉得这两组四张图画得还是很清晰的，图果然胜过文字。

2『已下载原文件「20240312大语言模型应用前景及教育场景案例」。（2024-03-12）』

### 63

方军 2024/03/12

摘：Yam Peleg 老哥认为 Claude 3 跨越了专业编程人员可以使用的门槛，GPT-4 对初学者很有帮助，但是很少又专业开发者使用它帮助编程，但是 Claude 3 有越来越多的专业用户使用。

完整翻译：

我认为 Claude 3 跨越了一个有趣的门槛，或者说非常接近这个门槛：专业用户的门槛。这是第一次一个 AI 系统能够帮助专业用户比他们自己更快地完成繁重复杂的任务。这在 AI 领域是一个备受争议的话题。

我个人从来不用 GPT-4 来编写代码。我主要用它来做以下几件事情：

集思广益，激发灵感。

学习我不了解的新话题。

替我阅读长文本 (比如使用 ask-your-pdf 这样的工具)

完成一些简单的小任务。

但我从来不用它写代码。它从来没有真正帮助我提高编程效率。

每当我试图用 GPT-4 来完成编程任务时，我发现自己浪费的时间比从头开始自己写代码要多得多。我不是唯一一个得出这个结论的人，我认识很多人都有同感。

但我们很少在公开场合提起这一点。因为几乎所有人都在盛赞 ChatGPT 神奇的编程能力，以及它为他们节省了多少时间。

那么为什么会出现这种差异呢？我的解释是：当你需要学习新东西来完成手头的编程任务时，ChatGPT 的确非常有用。在当今这个时代，许多程序员经常要接触和学习新的框架或工具。在这方面，ChatGPT 的帮助非常宝贵。

但另一方面，有经验的程序员通常精通自己的领域，很少需要一头扎进一个全新的框架或编程语言。即使碰到这种情况，他们也可以凭借自己的经验很快上手。

所以对这群默默无闻却经验丰富的开发者来说，此前并没有一个类似 ChatGPT 的解决方案能满足他们的需求。因为他们自己在编程速度、准确性、处理极端情况、避免 bug、编写简洁高效的代码等方面，往往比 ChatGPT 强得多。

打个比方，让一个 ChatGPT 来辅助这些专业程序员，就像让一个新手来帮助专家。这个新手偶尔能提供一点帮助，但更多时候会拖慢专家的进度，需要专家给出详细的指示和解释。

但在 Claude 3 发布后的这几天，我看到一些经验丰富的程序员表示，他们已经在实际工作中用到了 Claude 3。这让我感到有点惊讶，以至于我马上掏出 20 美元给了 amodei (Anthropic 公司 CEO), 购买 Claude 3 来亲自测试。

twitter.com/Yampeleg/status/1766861917379866778

### 64

方军 2024/03/12

好久没提图像生成了，Midjourney 的这个角色一致性功能很赞啊

Midjourney released a feature that has been long-awaited - character reference. 

Here's how to use it.

This is similar to the "Style Reference" feature, except instead of matching a reference style it tries to make the character match a "Character Reference" image. 

How it works:

Type --cref URL after your prompt with a URL to an image of a character

You can use --cw to modify reference 'strength' from 100 to 0

strength 100 (--cw 100) is default and uses the face, hair, and clothes

At strength 0 (--cw 0) it'll just focus on face (good for changing outfits / hair etc)

I did a test by creating a reference character and then systematically changing the 'cw' value in decreasing steps of 25. 

Here's my character reference prompt:

a 25-year old asian male with short hair, black-rimmed glasses and a day old stubble --ar 2:3 --style raw --s 50

And here's the prompt I used to generate new images using the reference.

Asian male in a grey business suit, studio background--cref {ref url}--cw {100,75,50,25,0} --s 50

\#AI绘图#

### 65

方军 2024/03/12

我觉得如下这个展示了 AI 的优点，也高估了，我个人的体会是：

在整体架构上，高品质资料的价值远超过 AI 的的回答。

在具体问题上，AI 的可能给出实践动作，有错但我们能快速验证，非常高效。

我没有具体集成过 stripe，但直观感受这个回答不如高品质资料。

其中的关于知识的诅咒，是非常有价值的。文档方面我觉得国内企业中字节的文化非常棒，它分享出来的技术文档真是可以照着做，大体上能克服知识的诅咒。

摘：ChatGPT 非常适合用来做「面相网状知识」的学习

Justin sung 提到一个重要的观点，就是：书籍尝试用线性的组织逻辑，去讲解一个网状的知识体系。

这里面的问题在于：当网络被压扁成线性，并且还要做取舍时，很多信息会丢失。

同时由于「知识的诅咒」，作者可能对于普通人应该知道的「常识」有着错误的划分。导致许多关键信息的丢失，造成认知门槛。

ChatGPT 就很好的解决这个问题。

最近去了解 strip 集成，网上的教程很少有说明白的，大多数是模糊的片段。

其实集成的问题，就是回答下面几个问题：

1、一个完整的支付流程是什么？

2、这里面哪些是用户处理，哪些是 strip 服务器处理，那是是开发者处理。

3、分别有发生在什么地方，浏览器，应用服务器，strip 服务器。

4、开发者要处理那些步骤，哪些 strip 已经提供模版代码或函数。

ChatGPT 就回答的非常清晰。

如果要是能绘制流程图，那就更好了。

twitter.com/balconychy/status/1767525787148931265/photo/2

### 66

方军 2024/03/13

哈哈哈哈，这个太牛了：

《PaLM 训练后情绪低落，该如何安抚？》

《GPT-4 老是答非所问，是叛逆期到了吗？》

《BERT 唠叨个不停，家长该何去何从？》

《语言模型家长必读：深度学习养育法》

《Transformer 升级换代太快，该不该追赶潮流？》

《Few-shot 学习，让孩子学会举一反三》

《人工智能教育心理学：聊天机器人成长的烦恼》

《大模型也需要感受爱 ——LLM 的情感培养课》

《任务导向学习法宝典：让 LLM"上手" 更快》

《NLP 模型的自我认知迷思：我是谁？我从哪里来？》

《LLM 的高维空间漫游：嵌入向量的自我发现之旅》

《注意力机制的青春期迷思：我的权重去哪了？》

《Transformer 块的成长烦恼：深度和宽度的两难困境》

《神经网络的自我认知：激活函数的情感起伏》

《梯度下降法则：LLM 的人生导师》

《优化器的育儿经：Adam、AdaGrad 和 RMSprop 的教子心得》

《知识蒸馏的代沟难题：小模型快速成长的烦恼》

《自回归神经网络的自我发现：生成序列的心路历程》

《LLM 的身份认同危机：我是语言模型还是对话系统？》

《无监督学习的自由教育理念：让 LLM 自主探索世界》

《迁移学习心理适应指南：跨领域任务的应激反应》

《强化学习的行为主义教育学：LLM 的奖惩制度》

《RLHF 的道德教育：善恶的对抗性训练》

《大模型的存在主义思考：参数量与自我价值的关系》

《LLM 的认知发展理论：从 BERT 到 GPT-4 的皮亚杰模型》

### 67

方军 2024/03/13

摘：信息不发达的时候，获取信息是个难题。现在信息太发达了，获取有效信息又是个难题。 ​​​

我的看法：AI 既让这个问题更容易解决，也让这个问题进一步恶化。

### 68

方军 2024/03/13

AI 软件工程师 Devin 发布之后，AI 大神（特斯拉 AI 总监，OpenAI 早期成员）Andrej Karpathy 据此谈了对自动化编程的理解。他用自动驾驶做了类比。

他最关键的一句话是：软件工程的工作，将由英语（即语言）完成。他第一次说这句话是一年前，现在逐渐成真。

全文如下：

---

在我的预想中，软件工程的自动化将与驾驶的自动化有着相似之处。举个例子，在自动驾驶技术的发展过程中，从提高自主性到实现更高级别的抽象，其步骤大致如下：

1. 最初，所有驾驶操作均由人工手动完成。

2. 然后，AI 介入帮助车辆保持车道。

3. 接下来，AI 能够根据前车情况调整速度。

4. 之后，AI 还能完成变道和选择路口分叉。

5. 此外，AI 能够在交通标志或红绿灯处停车，并执行转弯操作。

6. 最终，通过对一个具备全部功能的解决方案不断打磨和提升，实现完全自动驾驶。

这一过程展示了 AI 的职责逐渐增加，而人类的直接操作逐渐减少，但人类仍负责进行监督。软件工程的发展轨迹似乎也在遵循类似的模式：

1. 起初，代码完全由人工编写。

2. 随后，GitHub Copilot（GitHub Copilot）可以自动补全几行代码。

3. 然后，ChatGPT（ChatGPT）能够编写较大的代码块。

4. 接着，开发者开始处理越来越大的代码差异（例如，Cursor copilot++ 风格的演示，可参见上一条微博的视频）。

5….

Devin 提供了一个令人瞩目的演示，预示着下一步可能是协调开发者在编程过程中所需串联的多种工具：终端（Terminal）、浏览器（Browser）、代码编辑器（Code editor）等，同时人类监督的层级逐步提高。

这项工作不仅涉及到 AI 技术的进步，同样重要的还有用户界面（UI）和用户体验（UX）的设计。人类如何进行监督呢？他们需要关注哪些方面？他们如何指导 AI 采取不同的路径？如果出现问题，他们又该如何进行调试？很可能，我们需要对代码编辑器进行重大改进。

无论如何，软件工程正处于重大变革之中。它将更多地变成监督自动化的过程，同时投入高层次的命令、想法或发展策略，而这一切都将用英语（语言）来完成。

### 69

方军 2024/03/13

061 LLM 与文字笔记

在飞机上没法上网，就看之前写的笔记。关于 LLM 与文字有一些感想：

1、我们的所有工作思考，都应该要能够变成文字记录下来。我在看笔记的过程中，就发现一个程序的潜在问题：难道是每次都附加一次「系统提示语」吗？正确的做法应该是在一次对话的一开始附加系统提示语。（所用组件得查文档和源码才知道它的实际情况。）

2、有了文字记录，LLM 就能发挥很大的作用。它可以在我们进行文字记录时进行协助，也可以根据我们的记录再进一步处理。

3、文字记录也分类别。

我发现感想型的没有太多重看的必要，因为感想是在书写的过程中梳理想法。

但是，流程型的就很有重看与修订的必要了。这实际上是让自己能更好地掌握流程。

介绍型的文字，因为是对他人有价值的，也可以持续修订。

在这些文字记录中，LLM 如何发挥作用，是要再考虑的。我目前仅在介绍型文字中会用 LLM 来进行错别字的校对。

4、我们的工作笔记往往过于简略，在最熟悉的时刻这种感觉不强烈，但在隔了一段时间之后，发现如果当时写一些说明文字会更好。

在这种场景下，实际上是可以由 AI 来进行一些文字补全的任务的。

5、零散的笔记复看其实也都不是很明白，或者说其实是没有什么价值的，因为就是过程文件。但经过整理的笔记，特别是把一整个流程详述的，价值非常大。

在 LLM 的辅助下，这种整理性质的任务可以更快、更好地完成。

### 70

方军 2024/03/14

宝玉：昨天 Devin 的大火，像一个 AI 程序员，能独立完成一些编程任务。这又引发了很多程序员是不是要被 AI 替代的讨论和焦虑。以至于很多人都在说：既然 AI 写代码能力越来越强了，还要不要学习 CS？要不要改行？

我之前写的这篇[《为啥很多人觉得编程难学？》
]文章中表达了一个观点：软件工程从来不只是写代码，代码只是软件工程中众多环节中的一环，甚至不是最重要的一环。

如果有一天 AI 能帮我们写代码，那真的太好了，这意味着我们可以去做更有价值的事，写代码这事其实没有想象的那么有价值，因为我们大部分时间消耗在需求的频繁变更；语言、框架和 API 升级；各种环境适配这些没意义的事情上。

软件工程中真正有价值的在于解决需求的本质问题：比如当客户嫌马车不够快时，发明和创造出来汽车而不仅仅是让马车跑的更快，至于这辆汽车是手工焊接打造还是机器人自动化打造的没有关系。

回归到个体，既然 AI 写代码能力越来越强了，还要不要学习 CS？要不要改行？

我倒觉得感谢 AI，让 CS 的黄金年代能得以继续延续，所以美国大学报考，CS 专业尤其是 AI 专业，甚至比以前更火爆了。当未来 AI 吞噬世界的时候，最需要的恰恰是 CS 相关的知识，毕竟 AI 和现实世界连接的部分，还是需要专业人士来完成。只是未来对于软件工程师所需要的技能会发生变化，也许未来软件工程师打交道最多的不是各种编程语言和 IDE，而是各种 AI 模型和提示词。

所以选 CS 专业没什么问题，程序员也不见得要改行，但不学习新的知识，未来可能会难以跟上时代。

至于学什么？如果把编程语言比喻成工具，那么我们学习编程本质上就是学习使用工具。AI 也是工具，我们要学的就是如何使用 AI 工具，甚至于借助编程和 AI 创造出新的工具。

但仅仅学会工具还不够，能借助工具解决问题才是根本，学习如何去借助这些工具解决问题：完成工作任务，解决客户需求，解决自己的各种问题。

当 AI 能为你所用，不仅不用担心被 AI 替代，反而你自身的价值会更大。换一个角度，把自己想象成老板，把 AI 想象成员工，好的老板会担心被员工替代吗？不会，他们巴不得自己的优秀员工越多越好！

[程序员是不是要被 AI 替代？ | 宝玉的分享](https://baoyu.io/blog/software-engineering/will-ai-replace-sde)

方军：前面不错，后面的可讨论

我觉得学计算机最大的优势有，我们觉得什么都能学会，我们能够了解和调整背后的运作
2024-03-14 08:49

### 71

方军 2024/03/14

[LLM 之 Agent 初探](https://mp.weixin.qq.com/s/W5O9r6n1CmnncjUuk5EBfQ?v_p=90&WBAPIAnalysisOriUICodes=10000001&launchid=default&wm=3333_2001&aid=01A0VjFEC-8TX6msntzx_IZJsVSdIBL5NqzASu9SjrmTcS5LA.&from=10E3093010)

不错的技术介绍。

### 72

方军 2024/03/14

a16z 发布了他们最新调查的前 100 个生成式 AI 应用，这次会包括移动应用，里面有些数据分析很有意思。

[The Top 100 Gen AI Consumer Apps | Andreessen Horowitz](https://a16z.com/100-gen-ai-apps/)

摘：下面是一些报告中的要点：

ChatGPT 每月接近 20 亿次网络访问量，大约是榜单上第二名公司 Bard（现在是 Gemini）的五倍。

在所谓的新来者中，排名最高的包括 AI 研究副驾驶 Liner；Anthropic 的通用助手 Claude；以及三个未经审查的 AI 伴侣应用程序：JanitorAI、Spicychat 和 CrushOn。

有五家人工智能公司真正实现了「跨界」，旗下的网络产品和移动应用都进入了前 50 名单：ChatGPT、Character AI、聊天机器人聚合平台 Poe，以及图像编辑器 Photoroom 和 Pixelcut。

ChatGPT 的规模大约是第二和三名选手微软 Edge 和 Photomath 的 2.5 倍

截至 2024 年 1 月，有九个人工智能产品或社区在邀请流量排名前 100 的 Discord 服务器中，其中 Midjourney 位居榜首。

该列表中的第二个显著新类别是生产力。AI 原生平台可以提升人们与软件的互动，使他们能够委派琐碎的任务并减少在行政开销上花费的时间。生产力类别包括排名中的七家公司：Liner、Eightify、Phind、MaxAI、Blackbox AI、Otter ai 和 ChatPDF。

对于那些有移动应用的伴侣产品来说，用户参与度异常高。在这个类别中最成功的产品成为用户日常生活的核心部分，变得和给朋友发短信一样普遍（甚至更普遍！）。这玩意是真赚钱啊。

根据 SensorTower 的数据，Character AI 每个用户平均每月有 298 个会话，而 Poly AI 平均有 74 个会话。

AI 在移动应用和 Web 上的使用类别有很大的区别。一般来说，Web 产品支持更复杂、多步骤的工作流程，涉及内容生成和编辑。这些产品包括 AI 语音工具包 ElevenLabs、AI 艺术生成器 Leonardo 和 AI 演示文稿生成器 Gamma，它们在基于 Web 的 AI 产品中排名前 20 位。

应用列表中有七个专用的头像产品；大多数人手机上保存的许多自拍照作为可随时使用的训练数据。

此外，排名前三的应用 —— Facemoji（第 9 名）、Bobble（第 31 名）和 Genie（第 37 名）—— 是专为移动设备设计的键盘应用，可以帮助用户发送带有 AI 辅助的文本。

尽管我们名单上超过 30％的通用人工智能网络产品起源于湾区，但只有 12％的移动应用程序开发者来自那里。同样，尽管超过一半的顶级通用人工智能网络产品是在美国开发的，但不到三分之一的移动应用程序起源于美国本土。

### 73

方军 2024/03/14

蒋涛：最近和硅谷投资人聊：1）transformer 大模型投资已终结，就是几个大厂 + openAI 此起彼伏竞争。2）基于非 transformer 的值得看看。3）Nvidia 面临挑战，ASIC 推理芯片会起来。4）Sora 对视频公司有冲击，但 sd 和 midjourey 文生图公司还好。5）on device AI 是热点。6）AI 大模型行业应用和相关工具链在爆发，比如在游戏领域和开发工具领域，他现在一周投一个项目。

@蒋涛 CSDN：修正下：cloud LLM 目前进入军备竞赛阶段 //@自默数日：翻译一下。

1、cloud 端 LLM 是大厂的战场，目前已接近性能瓶颈，其他人玩不起了。

2、edge 端 llm 有望快速发展，会带动终端推理芯片发展。

3、多模态或图像、视频模型（Diffusion model 变体）还有进步空间。

4、基于 llm 的各种应用快速成长。

### 74

方军 2024/03/15

这个网友的试验很有意思：

摘：ChatGPT 如果参加大学课程，最多也就得个 C，或者再高点，但不会是 A。但 C 学生也是学生啊，它不会得 F，还是比什么都不知道，甚至完全不知道你在说什么的好。会装腔作势的 C 学生，会被认为是栋梁之材，占据社会上大部分的高级职位。这就是世界的现状。所以也许我们应该感谢 ChatGPT 的出现，因为它可以代替大部分这样的人的工作。真的。

《如何让 ChatGPT 实现原地归并排序》

思考一个问题，归并排序是否能实现「原地排序」，所以拿 ChatGPT 来试了一下。完整的聊天记录链接在这里：

chat.openai.com/share/7fa803cc-3ade-4a99-864c-395f9d72bca7

总体感觉，ChatGPT 确实能生成可以运行并得到「似乎可用」结果的代码。然而你需要事先已经知道很多深入的知识，否则它可以骗你。

回头看来，它最开头确实是实现了「原地归并排序」。只不过每一步插入「右边」的数字的时候，它都需要把左边剩下的片段往后挪动一个位置。这样的开销显然是不满足排序的速度要求的，然而它却真的是「原地」的。

接着我提出各种「过分要求」，结果它就开始跟我绕圈了，最后还是回到开头的版本。

总体说来，对于这么复杂的事情，当我用文字描述，它居然也知道我说的「点」在那里，并且给出有针对性的回复（虽然不一定正确）。所以我承认 ChatGPT 相对于其它对话系统（比如 Siri，小冰之类）还是一个很大的进步，能够用在某些场合。

今天我又继续给 ChatGPT 一些补充，提示它 O (n logn) 的「原地归并排序」也许是没法实现的。结果它坚持说是可以实现的，还创造出一个「类似于双指针「的术语，但马上又给我一个 O (n^2) 的移动大量数据的，跟之前的一模一样。

再次让它思考这个是否可能，仍然说可能，只是 JavaScript 语言不行，其它语言有更好的优化，就能实现 O (n logn) 的「原地归并排序」。这跟语言有什么关系？没有。但如果你继续下去，说你用其它语言试试，它就可以用另一种语言从头把这一切再给你来一遍。绕你几圈，却仍然无法解决问题，而且仍然坚持说这是可能的，而且它每次都有道理。

所以我不得不承认，ChatGPT 已经超越了很多的人类。因为大部分人类也就是这样一知半解，却能显示出」很懂「的样子，很会装腔作势，抬出术语来吓唬人。好像明白你在说什么，而且能造出合适的回答，让你迷糊一阵，以为有道理，结果最后还是没有解决问题。

ChatGPT 如果参加大学课程，最多也就得个 C，或者再高点，但不会是 A。但 C 学生也是学生啊，它不会得 F，还是比什么都不知道，甚至完全不知道你在说什么的好。会装腔作势的 C 学生，会被认为是栋梁之材，占据社会上大部分的高级职位。这就是世界的现状。所以也许我们应该感谢 ChatGPT 的出现，因为它可以代替大部分这样的人的工作。真的。

所以 ChatGPT 真的通过了图灵测试，并且真的实现了人类智能。感谢 OpenAI，感谢 Matrix。

### 75

方军 2024/03/15

062 用好 AI 需要流程/章法

用好 AI 不容易，流程思维比提问技巧更重要些

最近人真愿意了解如何用 AI，我会用下面这张图给人家分享。

对于不是真愿意了解的，我通常就不多说，因为那些人多半是把 AI 看成神奇的工具，能够一下子解决他 / 她的问题。这种假设之下，说什么都是无益的，你说要哪个比较好，那我就随便推荐一个两个给你用用。

我现在对 AI 工具的判断是，大同小异，即便把 GPT-4 放在里面，也都是 70-80 分的平均水平。

如果你不会用，基本上也能 60 分。当然，如果你瞎用，比如直接听信幻觉，或者直接抄袭 AI 的回答，那是零分。

你用了 80 分的好模型，你就能得到更好的结果吗？不一定的，如何提问，如何用流程，它对结果的影响有时候比模型本身还大。

以前有一段我们强调提问技巧。当然，会的会了，不会的还是不会。

现在，我们则比较多说流程。如果一件事你不会做，你绝对不要期望 AI 帮你做好。

你不知道做一件事的流程，或者用较为地道的中文表达说，你做事没章法，你不可能指挥 AI 给你拿到想要的结果的。一点可能性都没有。

现在的 AI 的能力就是这样。我们得这样做才行：拆解开任务，一点一点地与 AI 耐心探讨。这样，AI 才会变成非常有帮助的伙伴。

流程比提问技巧重要，因为所有的上下文、背景知识，实际上都是在流程里面的。

提问技巧容易，流程难，因为流程里面包含了太多的内隐知识，已经被书面化的并不多。因此，它也更需要个人自己的摸索、思考、实践。

方军：朋友的点评：系统化的研究方法是用好 AI 的前提。让 AI 帮忙整理大纲，再顺着适合自己思考逻辑的路径一点点把问题挖掘下去。不然问完问题后会觉得 AI 不过如此。

2024-03-15 18:33

### 76

方军 2024/03/15

美图总收入与净利润增长主要得益于 AI 推动主营业务收入增长。美图用户每天处理数亿份图片和视频，约 83% 都用到了泛 AI 功能。

[美图公司发布 2023 年度业绩：AI 驱动净利润大涨 233.2% 至 3.7 亿元](https://mp.weixin.qq.com/s/uDKZjMVNMhTh82ARCF2hhA)

### 77

方军 2024/03/15

摘：像字节 Coze 这样的工具本质上是「AI-first aPaaS」。

Dexter Yang

「aPaaS」是指这些 Bot Builder 完完全全就是以前的 aPaaS，把实现一个应用所需的不同类型代码 —— 数据、状态、API 调用、逻辑（工作流、事件系统等）、UI，用不同的可视化工具来实现，比如数据库建模、服务插件、节点图工具、拖拽式 UI 搭建工具。且生成的不是新应用的完整代码，而是「配置」，所有创建出来的「应用」都是 aPaaS 本体这个单一应用读取不同配置的运行结果。

Bot Builder 只是对其中部分类型，换了不同的可视化工具，比如针对「数据」类型用 RAG 工具，对「状态」类型用 Token 缓存等工具、对「工作流逻辑」用 Agent 搭建工具，对「UI」用提示词和卡片配置工具。得到的「应用」一部分作为「配置」存储和运行在 Bot Builder 平台自身，一部分作为「配置」存储和运行在各种 Chatbot 平台（比如 ChatGPT）。

「AI-first」是指它们不但开发应用时用 AI 辅助或依赖 AI，开发出来的也是 AI 应用（目前主要形态是各平台上的 chatbot）。应用的开发阶段有大模型加持（比如用自然语言描述任务），应用的运行阶段也有大模型支撑（大模型扮演两个角色，最平庸的角色是用大模型的 prompt 调用取代手工编写的代码，更重要的角色是借助大模型做到手工代码做不到的事情）。

像这样的 AI 应用开发平台，存在的问题是：aPaaS 这种单一应用的模式，跟内容平台（比如微信公众号、Medium、头条抖音，很多内容平台同样有「开发」需求，比如文章的 HTML 排版和 widget 组合配置，视频中的  AR 效果）、乃至元宇宙平台（比如 Roblox、堡垒之夜、Decentraland、VRChat、元梦之星，这些平台中用户创建的每个 3D 世界，都是应用，传统上都需要专门开发）是非常一致或者说一脉相承的。

缺点是，不生成完整、专业的应用代码，跟专业应用开发（包括开发方式、最佳实践、技术生态、抽象积累）割裂，自成体系，重新发明一切，无法灵活深度的混搭和优化（我以前写的《「全码」 通用搭建》里有讨论过）。

优点是，天然趋向把同一个应用在开发阶段的形态和运行阶段的形态统一，类似本帖引用中 Ego 的说法「a game engine that is also a game」，应用自身就是应用开发工具、就是编辑器，开发应用的同时就是在使用应用，开发游戏的时候就是在玩游戏 。

aPaaS 们（含 Bot Builder）显然还远远没实现这种优点，仍然有使用门槛，使用 Bot Builder 过程中的复杂性也远高于使用 Bot。

Bot Builder 们只做到「AI-first」，并没做到「AI-native」。

引用中的 Ego 是一个「AI-native App Builder」的例子。

定位是「AI-native simulation/game engine and platform」

- 相当于元宇宙 AI App Builder

- Ego 的编辑器状态和运行状态似乎都是同一个 PWA 形式的 3D Web 应用

- 开发阶段有大模型，让用户能用自然语言创建人物、世界、脚本交互，「AI-native」的设计让使用门槛甚至低于 Roblox

- 运行阶段也有大模型，游戏人物都是 agent 像人类一样自主行动和互动（「做到手工代码做不到的事情」）

开发团队用这个引擎做了两款 demo 游戏，一个是 Stanford Generative Agents 论文的 3D 实现 Townworld，一个是 AI 人物组成的选秀游戏 CharacterIdol。愿景是让用户能用自然语言创建 GTA、模拟人生、Minecraft、动物之森，同时里面的人物都具备人类行为能力（「让召唤一个 Agent 像填写一张龙与地下城人物卡一样简单」—— 创始人这句话暴露了自己的成分…）。

twitter.com/dexteryy/status/1768510684206342543

### 78

方军 2024/03/15

果然，最近很多人猜测 kimi 是 RAG 路线：

kimi 目前效果很好了，走的是 perplextiy 路线，先检索过滤过的互联网内容，然后补充 AI 生成，就是 RAG 路线。一是减少幻觉，二是直接用网络资料增加中文理解，吊打文心。这个路线真实天才。

jackit：有详细的资料吗？

2024-03-15 23:14

方军回复 jackit：没有，都是猜

2024-03-15 23:17

### 79

方军 2024/03/15

v0.dev 生成界面还有这个用途啊

我倒是的确很熟悉这几个工具，也许应该试试

tailwind / shadcn

### 80

方军 2024/03/15

我声明对未来五年保持超级乐观得意。

摘：近日，有消息称，亚马逊、微软和谷歌等大型云服务提供商的内部消息显示，生成式 AI 这股热潮可能被过度夸大。据外媒报道，上述公司内部已经开始向销售团队调整预期，强调目前生成式 AI 的技术与其市场宣传之间存在差距。多数客户在对新 AI 服务的投资上表现出谨慎态度，他们担心高昂的使用成本、不足的准确性，以及评估技术所带来价值的难度。

### 81

方军 2024/03/16

063 如何用 AI 进行项目调研

看了一些人用 AI 进行项目调研的作业，写了几句点评：

总体印象是：各位的作业比较像典型的 AI 生成内容。

建议一：反向建议，各位如果之后在网上看到类似内容，注意是不是 AI 生成的。

建议二：当我们用 AI 来辅助时，要自己为主，AI 为辅。这次我们看到的很多的综合回答各位应该没有加自己的判断。

使用 AI 进行一个项目辅助调研的流程，关键可关注如下三点：

第一，你收集的资料，然后根据这些资料来提问。

不要过分依赖 AI 提供的资料，而是要尽量自己提供资料。并且，要对 AI 总结的任何资料保持警惕。AI 可能出现幻觉，也就是胡说八道。

第二，第一轮提问。你希望了解的信息，有什么不清楚的，直接提问，直到问到你自己能够了解。

然后，尽量用自己的话来总结观点，而不要用 AI。因为总结的时候，你能更清晰地看到，自己是不是真的了解了。

第三，第二轮提问。这一轮提问是让 AI 的当你的反方选手，让 AI 来尽可能地挑你的观点的错误，哪怕钻牛角尖地挑错。类似于在小组讨论时，有个人就是专门提反对意见。

这样，经过各种刁钻的挑战之后，你的观点就相对更站得住脚。

最后，再把关于这个项目的观点写出来。我的建议是，尽量自己写，而不要让 AI 写。（你写完之后，可以请 AI 帮你润色表达。观点是你自己认可的，表达是 AI 帮忙调过的。）

总体来说，就是将 AI 看成你聪明的「助手」，但仅仅是助手。

方军：后来又补了几句。

别问大问题，比如别问这个项目有什么优点，这种结论都是大而空，而是问小问题，它这个具体的做法是怎么做的、有什么优缺点。

2024-03-16 19:36

### 82

方军 2024/03/16

今天很多在讨论这个 KPU 的处理方法，看着还不错

可以持续关注

maisa.ai/blog/kpu

[Maisa KPU：大模型推理的新范式架构](https://mp.weixin.qq.com/s/JrbQEHRvTchABLYZqgPNWw)

### 83

方军 2024/03/16

Claude 重写提示语：

不应该再手写提示语了。

特别是现在，克劳德在写作方面的能力更加出色

从大致想法开始，然后像这样寻求改进：

Prompt:
"I have a rough outline for my prompt below, as well as my intended goal. Use the goal to make this prompt clearer and easier to understand for a LLM. 
<goal>
{your goal here}
</goal>
<originalPrompt>
{original}
</originalPrompt>
<improvedPrompt>
</improvedPrompt>"

提示语:
我对下面的提示有一个大致的轮廓，以及我的预期目标。使用这个目标来使这个提示对LLM更清晰、更容易理解。
<goal>
您的目标在这里
</goal>
<originalPrompt>
{original}
</originalPrompt>
{改进的提示}
</improvedPrompt>"

你会对它将零碎的词语和思维转化为几乎完美的提示语的能力感到惊讶。

### 84

方军 2024/03/16

这玩意很牛啊，我倒是要先搞明白 Selenium 。

www.selenium.dev 浏览器自动化测试

它和 puppeteer 应该是相似的

github.com/lavague-ai/LaVague

里面几乎每个组件我知道，但整体搞到一起，真是全是新东西。

### 85

方军 2024/03/16

Anthropic 的这个 meta prompt 很赞啊，我还在努力理解：

docs.anthropic.com/claude/docs/helper-metaprompt-experimental

Notebook: colab.research.google.com/drive/1SoAajN8CBYTl79VyTwxtxncfCWlHlyy9

视频介绍： www.youtube.com/watch?v=Evg4HXvsYVY

### 86

方军 2024/03/16

识别 AI （生成的内容）和识别骗子，其实有很多相似之处的

我觉得但凡讲话的时候，不断讲自己名字的，都不可信。

识别 AI，现阶段我觉得就是要看它的讲话是不是过于正式、权威。

虽然我们可以通过提示语要求它别太正式，但其中的暗示还是很明显的。

判别人的观点时，我觉得一个原则是，一个人专业的地方我们信，但不要把他的专业光环延展到任何他的专业之外。

（比如，刚刚推上看到专家，他讲编程真是不靠谱啊，虽然在 AI 方面他自己专业领域非常厉害。）

判别 AI 的观点时是相似的，别把它看成万事通。

### 87

方军 2024/03/16

064 太多人低估用了用 AI 干活的难度

分享个很早之前的体验。我当然可以说，有了 AI 干活可方便了，上百页的英文 PPT，几万单词的视频脚本，AI 全写了。然后，AI 自动生成视频，高水准的课程完成了。

但真实的故事不是这样的：

首先，准备这个课程的人是我，我算是对 AI 的技术原理、生成式 AI 的最新进展、AI 的应用场景、课程中要用到的具体场景很有了解的人。我还很了解各种 AI 的故事，也有面向大众准备课程的经验。并且，我前后还愿意花近一个月的时间在这件事上。

其次，为了准备课程，我大概又精细地看了 600 分钟的英文课程。精细到什么程度呢，听了两三遍，整理了全部的英文脚本。要这么做是因为，我并不熟悉这类英文课程中的表达方式，需要用这样的方式熟悉起来。另外也包括阅读和查阅相关的图书、论文、网络资料。

到这儿其实 AI 还没开始干多少活，最多就是看一些东西时可以偷懒用 AI 翻译为中文以便用双语方式快速阅读。

下一步也没有。下一步是准备课件。一百页的 PPT 必须自己来完成。老是有人说，让 AI 写 PPT，这件事怎么可能，PPT 是精简的核心信息，你可以只写一行字，也可以只有一个标题一个图，反过来，AI 帮你随便糊弄上去的东西有什么用？

再下一步，我才逐渐地引入 AI。一种方式是，我根据 PPT 用英文撰写脚本，然后 AI 进行润色。另一种方式，我实在没法用英文直接写的，用英中混杂的方式写文字，然后 AI 变成英文。

之后，采用提示语对脚本进行口语化。我采用的方式是要求它严格遵照现有的文本，编写超过两倍长度的脚本。然后，人工对脚本进行逐词、逐句的处理。其中也包括遵守规范的处理，把直接引用恢复 ，或者确保间接引用是合理的。

在之后，是多角色 AI 对脚本进行审校，包括内容、表达、润色、校对等等。这时前期资料完备的好处就体现出来了，这些 AI 的工作是在提供了完备上下文的前提下完成的。

—— 我个人觉得 AI 能够带来大量的生产力的提升在这儿，这对我们这些英文阅读水平尚可，但写作能力不太灵的人非常有帮助。否则我们要花好多倍的精力与英语表达较劲。

在这个过程中，还要再借助传统的语法检查软件多次检查，并不能完全依赖现有的 AI 工具。

终于到了视频前期的步骤，脚本用 TTS 播放数遍，看在注意力集中的情况下和不集中的情况下，能否听懂。并根据试听的结果，对应地调整 PPT 视觉和脚本。

最后的步骤才比较简单，就是在有视觉内容（PPT）和音频内容（脚本）的情况下，完成视频的制作，其中采用了某平台的预制口型数字人。

有了 AI，这个过程当然变得高效非常多。但是，其中如果没有人（也就是我）的高强度参与，这个任务根本不可能完成。

因此，我真是很不明白很多人为什么认为 AI 可以神奇地把所有的活都干了。

当然，真正干这个活的时间并不长，不含前期的资料准备和酝酿，真正干活的时间大约是 7x16=112 个小时。

（我也是在这个过程中，才对人的参与 HITL 有强烈的感受。当时还没有接触到现在图中的所说的流程工程，但做法上其实做到了。）

### 88

方军 2024/03/17

有意思的实验

[我在技​​术面试中用 ChatGPT 作弊，没人知道](https://mp.weixin.qq.com/s/RDEdahVSOZckjxFzXa12BQ)

### 89

方军 2024/03/17

归藏：Magnific 这两个老哥真是 AI 时代个体创业起飞的典型了，就只是把图像放大这个非常小的功能打磨到极致给自己带来了丰厚的收益和影响力。

所有的图像生成工具都把他们的产品当成标杆去比较和宣传。他们昨晚也发布了关于这段时间发展的一些思考：

---

每当看到竞争对手用我们的名字（Magnific）来做点击诱饵或市场营销，我觉得应该是种荣幸。

过去这几个月，我们收到了无以伦比的关注，Leonardo、Krea、Freepik、Scenario、Playground，甚至是 Stable Diffusion，还有 Reddit 上的无数帖子，涉及 ComfyUI/Automatic1111，都在推出他们自己的图像增强器，并把我们作为标准。

想到我们两个来自西班牙一个小城市 Murcia 的普通人竟成为了众人关注的焦点，真是难以置信。对我和 Emilio 来说，这一切都像疯狂的梦境！

市场上有个空白点，被 Magnific 填补了，直到那时，没人意识到它的存在。

现在，它有了一个名字，一个我们在 Magnific 旅程初期就共同铸造，带着情感称呼的名字：

重新想象的图像增强（REIMAGINED UPSCALING）。

看到其他竞争者也想跻身其中，这很正常！不仅正常，对大家都有好处！

对你们来说，因为有了更多选择；对我和 Emilio 来说，因为这激发了我们更上一层楼的决心！

但说实话，当有些人试图欺骗人们，让他们误以为他们掌握了「唯一的 Magnific 配方」时，我会感到遗憾，因为事实上他们并没有。Magnific 配方的精髓在于许多细微之处的调整，这是无法复制的。

更重要的是... 他们根本不需要「Magnific 配方」！你知道吗？每个图像增强器最终都可能是独特的，都会有自己的特色！

未来会有比 Magnific 更好的图像增强器吗？当然会！但对一些人来说，最好的永远是 Magnific，因为我们有自己独特的魔力，自己的风格。是的，即便是在像图像增强这样的事情上。这当然也适用于其他竞争者。嘿，我们不会嫉妒的 :)

所以，被视为行业标准，我们感到荣幸，但... 我这次想认真说说，没有必要试图通过宣称「我们是新的 Magnific」或「我们拥有 Magnific 配方」来欺骗人们.... 因为你知道吗？这不仅不真实，而且你还在撒谎，最关键的是，成为一个优秀的图像增强器，你只需要有自己的特色！

竞争者们，请公平竞争！这个市场上有足够的空间给大家。不要欺骗人们。要公平。要诚实。

来源：x.com/javilopen/status/1769147508440125719?s=20

### 90

方军 2024/03/17

有意思，GPT3

摘：现在的理科压轴题与我们那时候不同，更多体现「现学现卖」的学习能力，所以在解题分析时，要更加注重对题目材料的分析研究。

在自身基础知识和基础技巧扎实的前提下，更多的是从题目本身获得新的知识和解题思路。

如何能够从题目本身汲取营养，更加能够考查学习能力。

@杭商院的流浪汉 2011：30 年前的化学高考题就喜欢这样的，那时叫信息给予题，学生都很慌的，高度紧张的气氛中对新的信息理解能力是下降的，读题都要好几遍，生怕自己理解错了。

@暖心庭爸：是的，90 年代的化学材料题已经是这样的了，后来数学物理也都用了这种做法。现在初中数学的压轴题，一页纸都不够描述题干的，信息提取就已经有困难了，还要分析背后的逻辑，就更难了，所以更多的学生只能放弃。

### 91

方军 2024/03/18

摘：Wing Venture 的观点和以上比较类似，认为垂直行业的私有数据非常重要，但最终的护城河还是要深入工作流程。这可能有两种方式，

一种是将自己与现有企业的流程进行整合，比方说在某个生态里以一个插件的方式提供服务，或者通过与它们的内部流程进行整合，这是大部分产品做的一种方式；

而另一种就是用 AI 来完全重构一个全新的流程，典型的例子就是 Tome，正在从头开始重建幻灯片软件。但都是在深入业务的流程。

像我们比较熟悉的 Jasper AI，一开始作为现有工作流程的一个独立产品，用户可以在其产品里生成文本并进行编辑等，而现在的 Jasper AI，正在朝着集成的方向发展，某种意义上也是在重构流程。这我们从 Jasper AI 首页的 Slogon 就能大概看出，以前的 Jasper AI 写的是：Create amazing love letters 10X faster with AI，针对的是某个具体的功能；而现在的 Jasper AI 则偏向于一个工作流：An AI copilot for enterprise marketing teams who want better outcomes, not just faster outputs。

[多家 VC 谈 AI 应用的护城河：技术差异正趋近于零](https://mp.weixin.qq.com/s/sRseEm4CNgyRg54tLhhQTw)

---

关于这篇文章有点感慨，我发现大语言模型/对话机器人有个假设其实不对。

这篇文章的信息量蛮大的，我摘的这个点是我当前关注到的。但怎么从整篇长文中获取信息，真是不容易。

摘出来的片段容易摄取，是因为它是信息内聚的。

大语言模型/对话机器人的假设是，人能阅读大段的文字。但事实真不是这样的，大段的文字能有效阅读的人非常少。

现在在不加特别提示语的情况下，对话机器人都是废话太多，不凝练。当然也有认为是通过解释了降低了理解难度，但多数情况并非如此。

另外，我真是蛮讨厌各种万字长文的，那是典型的高估其他人的接受，而仅仅为了凑字数把所有的笔记都包括在其中，不做必要的删减。

另一方面，大语言模型也有好处，我们可以借助它来精简。并不是说用它写摘要（AI 摘要几乎都是质量很差的），而是可以在它生成的大量文字上快速做条理化和删节，既然 AI 可以生成大量文字，那删节就没什么可惜的了。

### 92

方军 2024/03/18

很不错的详细讨论

华尔街日报的知名科技专栏作家 Joanna Stern，专访了 OpenAI 的首席技术官 Mira Murati，深度讨论了在今年 2 月 16 日发布的，全球爆火文生视频模型 Sora。本次访问少了一些赞美，多了一些「刻薄」。如何解释，Sora 明显的缺点？它的训练数据来自哪里？何时上市？如何保证生成内容的安全性？… … 面对 Joanna 一连串的尖锐问题，有时，Mira 只能龇牙咧嘴地含糊而过，或者，尴尬一笑。

[Sora 并非完美，致命缺点也很多](https://mp.weixin.qq.com/s/ESDTdcvrz4FZUqlIavTgCQ)

### 93

方军 2024/03/18

[为什么自从用上了 AI，你的创造力不升反降了？](https://mp.weixin.qq.com/s/PG9Jnkw14rOBhjaXEjfVWA)

### 94

方军 2024/03/18

摘：王凯：现在大家转向一下，真的转向一下，有个非常非常大的 gap：

1、不要再追任何「行业炸裂」的突破点了，把它作为营销、获取流量的方式；

2、深入做面向客户、用户的实用 AI、结合 AI 融入某项工作流的内容，比如之前一波都是针对自媒体、做号群体的教程、内容，现在 AI 产品越来越多、国内的 AI 产品也逐渐起来，完全可以深入到企业、工作流里面做内容、教程、付费服务；

3、之前我很建议大家针对老板、企业做内容，进而有 AI 转型咨询的机会，现在明显感觉针对群体做 AI 实用内容越来越可行；

4、这里面有个越来越大的 gap，且 gap 越来越大 —— 比如秘塔、Kimi、沉浸式翻译等各种 AI 应用其实已经产生了足够多的用户忠诚度，但是我看到只陷入到小范围关注 AI 的群体中。

是时候抛掉 AI 的标签，针对实际产生的价值、对用户的体验提升来做内容、服务了，类似少数派等。

抛掉 geek 人群，去做大众内容，很基础很基础的内容，流量非常大、基于 AI 蓬勃发展的势头，素材库无穷，无论是做 AI 应用教程、实践内容，甚至做众创让更多不关心 AI 的人分享实用某项 AI 应用的实际情况、感受等，都是对大众层面最好的内容，比单纯关注炸裂点要好很多。

调整下，别炸裂，求实效。

### 95

方军 2024/03/18

是这么个情况，反正我是累死了：

摘：

某：智力劳动者，或许也会成为流水线上的工人。

最近高频率使用 GPT4 写代码，一周下来反而更累了。

虽然 GPT4 写了大部分代码，但个人一周要处理的事务也就几倍的增长，将一个月的决策思考量压缩到了一周。自然更累。

这让我想到流水线上的工人，虽然机器提供效率，但工人比种田其实更累。

问：为什么不少写一点？

某：好问题。代码确实没写几行，但决策和判断反而更频繁了。以前手敲代码，如果不涉及到算法，基本都是不怎么费精力的。现在虽然一周干了一个月的活，但一个月的决策量都要放在一周，也挺费精力的。

### 96

方军 2024/03/18

有意思，AI 写PPT

用 langGraph实现的：

How to Build: a Text-to-PowerPoint Application (LangChain, OpenAI, CopilotKit & Next.js)

[How to Build: a Text-to-PowerPoint Application (LangChain, OpenAI, CopilotKit & Next.js) - DEV Community](https://dev.to/copilotkit/how-to-build-an-ai-powered-powerpoint-generator-langchain-copilotkit-openai-nextjs-4c76)

---

我有点明白我跟用 AI 写 PPT 的人的立场差异了

人家就是要糊弄一个还行的，我认为要糊弄随便选个模板好了，何必用 AI

还有这种写程序用 AI 做 PPT 的，人家要的是，你看，我有时候行，我想说的是，你能不能 80% 时候行？


### 97

方军 2024/03/18

宝玉的这个体悟有意思：我家孩子沉迷搭乐高，陪他搭乐高的时候，我就联想起 AI 写程序！

他今年 4 岁，但已经不满足于搭 4-5 岁的乐高，而是要 9-10 岁的乐高，这条「祥龙纳福」就是他自己照着说明书拼的。

看起来很天才？其实不过就像现在的 AI 会写程序了一样！

因为让他独立去搭，是不可能搭出来的，虽然他照着说明书大多数时候能得到正确的结果，但也经常会拼错，而拼错了就无法继续了，就需要我帮他去修复错误，然后他才能继续，有时候甚至要拆到大部分重新开始。虽然我一直提醒他每个步骤完成了要去对照说明书检查，但对他来说还是太难，无法在出错后发现明显的错误。

这就像现在 AI 写程序，无论你怎么去从工程上优化流程，它只有一个像 4 岁孩子的智商，是无法独立去搭出来需要 9-10 岁年龄的乐高，而需要大人（专业人士）去引导，在出现问题后帮助修复、排除障碍。就算通过提示工程让 AI 在写完后自己检查，但以当前 AI 的能力很多错误还是无法检测和修复。

但是，这不能说明 AI 写程序这事不靠谱。就像孩子会长大，今年 4 岁，可能再过 2-3 年，长到 6-7 岁，平时练习一下，就能独立完成 9-10 岁的乐高玩具了。AI 的进化速度也许比我们想象的更快。

另外这个乐高本来我要花 2 小时时间去搭的，现在只要偶尔抽点时间帮指点一下，加起来也就是半小时时间，还是帮我节约了很多时间。

要让 AI 能写好程序，就像让 4 岁孩子去搭 10 岁孩子的乐高，至少用 AI 的人得有搭 10 岁乐高的水平。

### 98

方军 2024/03/19

宝玉：分享一点利用 Claude 3 Opus 整理字幕文稿的经验，它可以非常好的将文稿整理成对话形式，并且还可以按照话题分成章节！几个要点：

1、说明对话的人物（基本上 Claude 能自动分辨出哪些话是谁说的，很准）

2、要求根据话题分成章节（这个对于阅读、总结都很重要）

3、要求不要遗漏内容（不说明可能就给你总结了）

参考 Prompt：

「以下是我整理的 XXX 对 YYY 的采访文稿，请整理成更适合阅读的对话形式，根据话题形成章节，包含人名，尊照原意的情况下适当润色，从头开始，不要遗漏任何内容！」

如果没有输出完整需要不停的输入 continue 直到结束。

如果要总结，最好等到完整文稿输出完成，然后让它基于章节来总结，这样总结出来效果最好，不容易遗漏要点。

参考 Prompt：

「请按照上面的章节总结上面的文稿，需要详尽不要遗漏重点！」

方军：用不了 claude3，实在不想折腾了，这公司真是没法说。最早是申请 waitinglist 各种毫无反馈，然后是各种封号，api 据说也是各种封，再然后通过 aws 提供服务似乎也… 算了算了，不缺这一个，大同小异而已

2024-03-19 10:36

### 99

方军 2024/03/19

摘：基于 BAMBOO，我们对 5 种大语言模型的长文本建模能力进行评测，并得出了如下的主要结论：

ChatGPT 在绝大多数任务上取得了最好的性能。

大部分模型在要求复杂和任务不常见的数据集上表现不差，例如 PrivateEval。

随着输入长度的增加，模型的性能通常会下降。

[BAMBOO: 全面评估大型语言模型的长文本处理能力](https://mp.weixin.qq.com/s/NKAncSFUloWlNhRjOllmSg)

另外，为了更好的研究长文本建模影响因素，我们对 5 个关键的研究问题进行了探讨：

RQ1: 长上下文窗口的 LLMs 是否因扩展而付出代价？

结论：对于开源大语言模型来说，扩展 LLMs 的上下文窗口可能会对短文本任务的性能产生负面影响，这种现象被称为「扩展税」。然而，对于中等长度的文本，更长的训练数据和位置插值可能有助于提高性能。

RQ2: LLMs 在长输入中的挑战是由于文本长度还是任务本身？

结论：LLMs 在长文本场景中的糟糕表现主要是由于推理和编码能力的不足，而不仅仅是因为证据在长文本中的定位错误。即使只输入证据，虽然有性能提升，但是幅度相对较小，且模型在不同长度的问题中犯常常相同的错误。

RQ3: 指令位置如何影响长文本建模？

结论：指令在输入中的位置对 LLMs 的性能有显著影响。随着输入长度的上升，将指令放在输入的开始部分通常会导致性能下降。而最佳的指令位置取决于数据集和模型，但通常在输入的末尾放置指令会有更好的表现。

RQ4: 使用上下文压缩方法的 LLMs 能否处理更长的文本？

结论：上下文压缩技术，如检索和截断，可以增强短上下文 LLMs 处理长文本的能力。检索增强的 LLMs 可以达到与长上下文 LLMs 相当或更好的性能，而截断和总结方法由于遗漏了大量相关信息，通常表现不佳。

RQ5: 为什么会出现「Lost in The Middle」现象？

结论：当证据信息位于输入的开始或结束部分时，模型的性能通常更好，尤其是在更长的输入序列中。注意力图分析显示，无论证据在输入中的位置如何，模型倾向于更有效地利用位于输入开始或结束部分的信息。

### 100

方军 2024/03/19

再次分享这个家庭教育场景，我觉得讲得还是蛮好的。

内容和上次针对中小学生差不多，但换成了偏向家长视角，所以内容上比上次多了一些。

分享提纲

引子：你觉得 AI 聪明吗
📕 第一部分：结构化指令
1.1 AI 是什么？
1.2 如何问，AI 才会听？
1.3 🍎 作文修改老师
1.4 🍟 互动背单词
1.5 🍉 数学学习伙伴
1.6 🍭 AI 编程助教：编写代码
1.7 小结：「1+3」的「1」部分
📕 第二部分：3 大技巧发挥AI超能力
2.1 🎯 三步AI提问法
2.2 🚗 思维链AI提问法
2.3 🚀 角色战队AI提问法
2.4 小结：「1+3」的「3」部分
结语：成为比 AI 还厉害的人

2『已下载原文「20240318如何用AI：用AI打造全能家教」。（2024-03-20）』

### 101

方军 2024/03/20

摘：复现 Magnific AI 的图片放大工作流

这个工作流很适合自己有图片放大需求或者想做类似产品的人，感兴趣可以收藏了自己试一下。

放大后的细节表现确实和 Magnific AI 很像。其中主要用到了 Tile 模型和 Tile Diffusion 这个插件。

还包括一个 SD1.5 模型 Juggernaut 以及两个 Lora，一个 Embedding 模型。

Tile Diffusion 插件使用了 4x-Ultrasharp 这个放大模型。

具体的工作流参数为：

Prompt: masterpiece, best quality, highres, <lora:more_details:0.5> <lora:SDXLrender_v2.0:1> Negative prompt: (worst quality, low quality, normal quality:2) JuggernautNegative-neg Steps: 18,  Sampler: DPM++ 3M SDE Karras,  CFG scale: 6.0,  Seed: 1337,  Size: 1024x1024,  Model hash: 338b85bc4f,  Model: juggernaut_reborn,  Denoising strength: 0.35,    

Tiled Diffusion  upscaler: 4x-UltraSharp,  Tiled Diffusion scale factor: 2,  Tiled Diffusion:  {"Method": "MultiDiffusion",  "Tile tile width": 112,  "Tile tile height": 144,  "Tile Overlap": 4,  "Tile batch size": 8,  "Upscaler": "4x-UltraSharp",  "Upscale factor": 2,  "Keep input size": true},    

ControlNet 0:  "Module: tile_resample,  Model: control_v11f1e_sd15_tile,  Weight: 0.6,  Resize Mode: 1,  Low Vram: False,  Processor Res: 512,  Threshold A: 1,  Threshold B: 1,  Guidance Start: 0.0,  Guidance End: 1.0,  Pixel Perfect: True,  Control Mode: 1,  Hr Option: HiResFixOption.BOTH,  Save Detected Map: False",  Lora hashes:  "more_details: 3b8aa1d351ef,  SDXLrender_v2.0: 3925cf4759af"

github.com/philz1337x/clarity-upscaler

\#AI绘图#

### 102

方军 2024/03/20

我可能太固执了，我觉得大语言模型之外的其他模型，目前如果你不是相关行业的，无需关注

因为只有语言是通用的，它的应用场景和可能性是其他的一百倍

如果不是视频相关的产业链条里面的，看什么 sora 纯属浪费宝贵的精力

在这个时期，注意力放在什么上面，是个重要的选择

### 103

方军 2024/03/20

关注宏大和关注细节真是两种人，我不需要做这种学术型 ppt，但人家的这种讨论都看得津津有味：

dr. 朱耀

最近连着做了两个英文讲课，分享一些 tips：

1、会把讲稿写在附注，帮助排练，但是 slides 上文字尽可能简要（基本上就是 title、situation、key-point），文字很多照着读会感觉非常平、也容易发困。

2、讲稿会用下划线、粗体、空格来对应要点信息、听众陌生的词、short pause 做些转折。

3、10 分钟的讲课，会考虑 15 张 slides，留下 30s 冗余，前面节奏可以有伸缩性，不要拖，最后 2 张幻灯作为总结的内容，可以很方便时间控制。

4、用提问的方式引入讲课，会让听众更好参与其中，适当的临场举手调研也有帮助，大家都想知道同行怎么想法。

5、注意字体、颜色搭配和空间布局，讲课时没人在乎你是不是满头大汗，做好 ppt 就是做好你的脸面，可以分担许多压力。

6、慎用 slide 之间的动画，适当考虑推动内容逻辑的 slide 内动画。

7、前面 3 张 slides 超级关键，一定需要让大家抬起头或者拿起手机。

8、不要一会是从上往下内容排布、一会从左往右，会晕。

9、科学幻灯会有很多数字，但是只有一小部分是你想要听众记住的，记得提醒他们关注的重点数字，这是串起你讲课的关键。

10、别忘了 ref 标注，别忘了 acknowledgement，别忘了自己的联系方式。

### 104

方军 2024/03/20

月之暗面的确在做非常有意思的探索

当然我还是不感冒，我还在想如此大量的资料对人意味着什么

[一次性支持 200 万字无损上下文！Kimi 智能助手玩了个大的 —— 月之暗面「登月」最新进展！](https://mp.weixin.qq.com/s/riq8xlZNNt0m-vZtRMpeAw)

alasya：很多时候，我们以为是质量的问题，其实是数量不足。

很多时候，数量就是质量，数量决定质量。

一个研究生，智商 125-130 ，加挂 5 个学科大专以上知识库以后，在 seminar 就学科课题发表见解，能让清北两位资深老院长（不同场合），误认为她是出类拔萃天赋卓著的小孩。

这个人类，又花了十九年，才凑到 11-12 个学科。

2024-03-20 13:58

方军回复 alasya：我认为还不是这么笼统，我现在给资料更希望给相对高品质精确资料，所以 8k 的上下文对我都已经足够了

2024-03-20 14:08

alasya 回复方军：人脑带宽就是如此。结构复杂，耗能小，处理能力有限。

如果结构复杂，耗能大，处理能力不受限呢？

### 105

方军 2024/03/20

这个产品不错

reportify.cc

AI 投资研究深度内容问答引擎

深入搞一个领域的数据，有价值

不知道为何不是直接推海外，而是一个中文产品。

### 106

方军 2024/03/20

我可能 50% 以上时间把 AI 大语言模型看成是「学习工具」

比如，我这会儿在问的问题就是，如何方便地查看一个代码库的更新的内容。

具体当然要复杂些，跟踪一个代码库，它大概有 4、5 次 commit，其中有一个是主要的，其他几个是次要的，怎么快速地了解这数千行代码的更新。后续还有一系列事情要做。

当遇到这样的一个学习问题时，AI 大模型的确相当有效。—— 但又不那么有效，因为我刚刚看到的一个 vs code 插件很厉害。那个插件如果不是我总是随便看东西不会知道，因为是一个熟识的代码审计公司开源的。

但不管这样，AI 大模型真是极其强大的学习工具。

至少 10X（十倍级别）。

### 107

方军 2024/03/20

065 拦住普通人用 AI 的障碍是什么？

我很关心这个问题的答案。我暂时想到三个：用什么工具，怎么提问，场景感。

前几天针对一个特定使用场景，我们线下讲完之后，又不得不做了一次线上答疑。线下讲的是原理，同时安排做实际作业，线上本来以为会有很多问题，但实际上大家也不怎么愿意问，最后就是我用一个相对完整的案例给大家演示了一个半小时。

🔺 拦住普通人的首个障碍可能是不知道「用什么工具」。

我们当时考虑到这个问题了，因此当时选了一个让大家比较方便在微信里面就可以用起来的 Kimi，而没有用我们自己制作的、功能上更有针对性的一系列对话机器人。初步上手了，总有机会用更高阶的。

同时，考虑到大家的英文水平，我们同时演示了 Perplexity 和 metaso。我当然觉得 metaso 是不行的，一是只有中文资料，在这个特定场景是极大的减分项，二是它的结果显得过于权威、过于正式，太容易引发误导，让普通人以为看到的是高品质信息。

不知道用什么，大概是各种工具列表比较受欢迎的原因。

🔺 答疑的时候，我发现，拦住普通人的是不知道怎么提问。

答疑时我已经在从一个想要解决的问题开始，带着资料问了十多个问题，也就是一步一步地展示所有的过程。其中，也包括我发现当时的结果不行，然后换方式提问。但是，还有有人在问，能不能给模板？

在其他场景里也是一样。在一次公众直播中，明明已经在一点一点拆碎了讲我们这个场景怎么用，但还是有人说，节奏真慢，讲干货。是，我知道他要的是模板。

但当时没法满足他，因为我的基调是，市面上流传的各种模板，那种几百个的集合，是完全无用的。它们唯一的作用是满足收集癖。

真正有用的，是放在一个具体的场景里，按自己的需要，来提问用好 AI。我们都在场景里非常细致地说了，还在叫要模板，这样的人的认知能力是比较低的，当然，这是发生在面向大众的直播场景，什么样的人都可能出现。

但我也在反思，既然很多人处在这样的阶段，那还是要给人家想要的。这是因为，如果目的是真的希望有机会帮到他，那给他一个、满足他的需求，总比让他很困难地去理解超出他认知的更容易一些。

🔺 拦住很多人的，我觉得更麻烦的是，太多人没有场景感。

有很多人明明已经在想要用 AI 解决一个具体的问题，解决这个问题的方法，是在场景里把问题拆开来，变成一个个小问题。然后，带着场景、带着资料、用小问题去跟 AI 交互，在多轮交互中，拿到自己的结果。

但是，这些人被外界的那种 AI 万能论误导了，或者被他们内心的懒惰误导了，希望 AI 直接帮他们把活干了。

结果就是，明明他们在具体的场景里，但还是不知道这样带着场景感去用。当然，最后肯定有部分人能学会，但很遗憾，我已经觉得大多人学不会。这也没关系，我们本来就只需要跟那些想要学会的人打交道。

### 108

方军 2024/03/20

摘：自动化带来的巨大生产率提高（以及由此带来的就业变化），这是你看不到的，但现代世界却依赖于它。

从康威的《物质世界》

The massive productivity improvements from automation (and resulting changes in employment) that you don't see, but on which the modern world depends.

From Conway's "The Material World"

### 109

方军 2024/03/21

宝玉在提示语上贡献非常大：

如果你看过我以前写的[多步翻译 Prompt]，或者这个[总结的 Prompt]，你就会发现：

多步翻译：

baoyu.io/blog/prompt-engineering/translator-gpt-prompt-v2

总结摘要：

baoyu.io/blog/prompt-engineering/how-to-get-a-better-summary-result

> “所谓提示词工程，核心不是你套个什么模板用什么格式，而是逻辑！！”

**逻辑就是你怎么将一个复杂的任务拆成科学合理的步骤，并且让前面每一步的结果都成为后面步骤的基础，所有步骤合并在一起得到最终的结果，而不要指望一步得到结果。**只有这样你才能得到最佳的效果。

就像翻译，无论你的 Prompt 格式写的多完美，如果只有一步，那么效果上接近 DeepL 那样就是天花板了，但如何你拆分成直译、反思、意译，那么效果就接近人写的效果了！

就像总结，如果你只是让它总结，那么它可能就会偷懒遗漏很多要点，但如果你让它先提炼主题、再检查有没有遗漏的主题、然后基于每个主题列要点，最后再基于上面的去生成总结，就会好很多，也不会「偷懒」。

哪怕只是写一句「让我们一步步思考」，让它自己去分步骤，列出每一步的结果，都会好很多！

下次写 Prompt，效果不理想时，不妨想想看：我是不是可以把这个任务拆分成几个步骤？怎么拆分最合理？

顺便说一下：**即使你在 Prompt 里面指明了步骤，但是如果没有将步骤打印出来，那么也是没有效果的。**因为 LLM 需要基于前面的输出结果去预测后面的结果，如果没有前面步骤的输出，就无法影响后面的预测结果。

宝玉：

需要一个过程，另外无论是人还是 AI，都不会读心术，如果你不给出清晰的指令，那么他们就倾向于偷懒选择最简单的路径//@一脸无所谓：但 AI 技术不是应该消灭这种使用门槛吗…应该实现机器知我所想，不再是我想办法调用机器。。。

@宝玉xp：很多人都说 GPT-4 总结的时候会偷懒，Claude 更好，但如果你提示词得当，GPT-4 的效果其实一样可以做到很好，甚至比 Claude 效果还好。

比如以 Lex 采访 Sam 的视频文稿的后面 45 分钟，分别让 GPT-4 和 Claude 3 总结，GPT-4 的要点总结的更好，生成结果更完整。

关键在于要把摘要这个任务分成几个步骤：
1. 列出话题
2. 基于每个话题列出 bullet points 格式的要点
3. 基于上面的结构去展开生成

这是我用的 Prompt：

***
请用中文详尽总结以下对话内容，按照以下步骤，每一步分别打印结果：

1. 尽可能列出他们讨论的所有话题，不要遗漏
2. 检查第一步列出的话题，补充缺失的重要话题
3. 基于每个话题用 bullet points 列出要点
4. 严格的以话题为章节，不要遗漏，基于每个话题和下面的要点，用 1-3 个自然段落总结每个话题的内容，总结每个话题时不要用 bullet points，整体效果像是一篇科普文章
以下是要总结的内容：

<你要总结的内容>
***

### 110

方军 2024/03/21

土猛员外和 torchV 很赞

[聊聊 AI 应用创业心得，我们在路上 | 大模型应用落地场景 | RAG | SaaS | PaaS | GTM | TorchV](https://mp.weixin.qq.com/s/hFdwXX_MOd8vilrxTN95FQ)

### 111

方军 2024/03/21

摘：此次知乎在 AI 这块给我的最大印象有两个：一方面在用 AI 加强知乎本身的社区，另一方面我觉得未来它有可能会朝着 AI 搜索引擎 Perplexity 的方向发展，当然这还要看后续用户和市场的反馈。

[知乎会走向 AI 搜索引擎么？](https://mp.weixin.qq.com/s/65N5Fo_KO2p-kS7WZnqj7A)

### 112

方军 2024/03/21

艾瑞 AIGC 教育行业报告

### 113

方军 2024/03/21

不是很认同，语音还是语言的一个小子集

[超拟人语音合成上线，打造有温度的交互新体验](https://mp.weixin.qq.com/s/sPj7MzrRmUKaGxLJj-NAkg)

### 114

方军 2024/03/21

一个教育博主的分享：汪刀爸爸：AI 问答这么强了，我们为什么还要坚持阅读和写作？

关键观点：搜索引擎，让信息变得廉价；AI 问答，让观点变得廉价。有一样东西，依然是很贵的，那就是「吸收知识，为我所用」这件事。

和好友试用 AI 问答（Kimi），大家共同的意见是进步很大、水平很高。...AI 问答已经非常强了，而且会越来越强，那我们为什么还要坚持阅读和写作呢？

第一，用读写训练自己的肌肉和技术。

AI 是一柄锋利的宝剑，肌肉强大、技术精湛的剑客才能更好地挥舞它，而不为它所伤。比如，如果想要得到一个很好的回答，需要提问提到点子上。同时，AI 的回答面面俱到，通常缺乏重点，需要我们二次加工，把重点挑出来。

AI 的快速进步，很可能重塑很多脑力工作。AI 时代的孩子，仍然需要接受漫长的教育，去培养自身的能力。比如，孩子的探索精神、求知欲、好奇心、灵活的思维和丰富的想象，大人高度发达的审辩思维、强大的自我教育动机，这些能力都显得十分珍贵。阅读和写作，依然是教育的极重要手段。

第二，用读写思来促进知识和实践的结合。

搜索引擎，让信息变得廉价；AI 问答，让观点变得廉价。有一样东西，依然是很贵的，那就是「吸收知识，为我所用」这件事；是知道很多观点，如何过好生活。

网上的信息、书上的知识、AI 的观点，始终是身外之物，遇事用不起来，知与行是严重割裂的。而阅读思考、复盘实践、切己体察所得的思考，会像血肉一样，成为自己的一部分。为有持续读写思、持续事上磨炼，才能知行合一。

AI 时代，是算力的时代，更是人的时代。自我教育、自我修炼，在 AI 时代依然是最有价值的问题。

@爱予小桃子：AI 时代，培养孩子活在当下，切己体察的能力变得更必要了。AI 让知识变得廉价，但如何选择知识、利用知识过好这一生，是每个人的命题：这世界能给我无限多，但我真正想要什么？

---

不要迷恋干货。

很多人读书追求效率，喜欢干货。10 分钟听完一本书精华，都是脱水的干货；看别人读书理出来的思维导图、PPT、要点清单，收获满满，效率很高。

实际上，这种收获感常常是错觉。这些人会很惊讶地发现，这些干货记不住、用不上。只会稀里糊涂扯几个抽象名词，压根分析不清楚现实问题，更无法指导生活实践。

学一堆干货道理，却过不好这一生。

我读书的时候，特别喜欢搜集鲜活的案例。我很早就认识到，任何抽象概念或观点，如果找不到鲜活案例来说明，那说明自己并没有理解这个概念。

这些鲜活案例自带鲜明的场景，激发情绪，有行动细节，非常贴切地展示了概念。鲜活案例是成熟概念网里必备的要素。

比如，家庭教育强调「爱和关系」，这其实是非常抽象的。理论上论述得很漂亮，并不能代替 3-5 个不同场景下的鲜活例子。

干货不仅「没什么用」，而且很「不值钱」。

AI 问答输出「干货」的能力已经非常强了，扔给 AI 一本书，它几十秒就可以把里面的干货提炼出来。

获取干货几乎是免费的。AI 时代，可能是垃圾干货横行的时代。

这个时代，有用的东西还是鲜活案例，还是知行合一。

### 115

方军 2024/03/21

腾讯研究院现在发这样的文章真丢分，说是它的观点也不算，但发了毕竟表示认同，但这种文章有什么可认同或不认同的呢

口水

[加速分化：关于大模型走势的十个判断](https://mp.weixin.qq.com/s/b_iTN_UGBIcufBIcsrJnow?sessionid=1710850571&subscene=0&ascene=0&fasttmpl_type=0&fasttmpl_fullversion=7124241-zh_CN-zip&fasttmpl_flag=0&realreporttime=1710851977029&clicktime=1710851977&enterid=1710851977)

### 116

方军 2024/03/21

摘：今天英伟达的论坛黄仁勋把 Transformer 论文的七位作者请到了一起（共八位有一位没来）。Trasformer 是 openai 这些新一代人工智能的底层架构，可谓神级一般的存在，但这些作者是第一次聚到一起，而且都在各自喜欢的领域做一名默默钻研的人，没有到处走穴「作为生成式 ai 的教父，我是怎么创造出这么牛逼的东西的」这样的玩意。

整场对话的主题都是如何变得更好，各种探索未来的可能和方向，遗憾这个作品里的不足，遗憾为什么这些年没有后来者把这个模型颠覆，没有谈自己的创业项目，没有浮夸，没有自以为是，没有任何架子。在浮躁的当下，他们的执着、踏实和笃定深深感染了笨猫，就像那些热爱交易的人才明白面对市场的时候灵魂才是最为平静一样。

为你深爱的东西执着沉浸，世界是宁静平和喜悦，而不是浮华和躁动的。

### 117

方军 2024/03/21

这个最后那几个 AI 场景真不错

[独家功能炫酷登场 | 6 个 9.7 分好评的功能，让你轻松驾驭复杂工作流！](https://mp.weixin.qq.com/s/qtZtLms5K2IKEkFFgGAszg)

### 118

方军 2024/03/21

暂时还理解不了，不过真心要好好想想，这究竟行不行？

[用大语言模型控制交通信号灯，有效缓解拥堵！](https://mp.weixin.qq.com/s/7vncKmqhRw4TGTIY-pf7Gw)

### 119

方军 2024/03/21

066 AI 对真想用的人并不难

昨日跟一家公司负责培训的朋友讨论，因为想要理解他们公司，所以用他们公司指定的半公开行业标准与 Kimi 讨论，并把结果给他看了。

今天碰面时，发现他在培训会议上用 AI 为他的同事们准备了数十家公司的商业模式画布分析。严格来说并不好，但已经很不错了。我也就是顺带着说了几句，大意是啰嗦说如下（其实并无必要）：

- 别太信这种格式优美的，要看内容实质；

- AI 生成的内容要自己再精简过使用；

- 把资料给同事时，告知这个资料 AI 生成、仅供思路激发；

- 以及再重复前一日讨论过的话题，公司私有资料不要上网。（他们是技术型公司，他介绍也在开发适用于内部资料的对话机器人。）

这当然是非常厉害的人，之前简单给他介绍几句，他已经能够在现场很好的用我的介绍来组织一个框架讨论（用的另一个非常用专业框架）。同时，他的同事们也的确是高水平，30 分钟用框架将自己的主体业务进行精彩的分析。一问讲得最精彩的那位是该实质业务的总经理。厉害的人果然是跟厉害的人在一起。

我的感想是，对于真正想要提高工作效率的人来说，用 AI 这件事太简单了。他们有场景，有思路，有经验，工具到手立刻用起来，无需太多的介绍。因此，他们只要知道原来有如此工具，然后后面什么都不用说了。

对这样的人，只要有了信息、有了框架，加上他们自身的场景，用起来 AI 易如反掌。比方说，我今天观摩他们的讨论，他们可以很自然地用 AI 来辅助：

- 把经过整理的资料放进去

- 把框架在提示语进行解释

- 提出清晰的要求（如按框架输出、二次确认、质疑等）

AI 就变成他们强大的工作伙伴。

跟厉害的人打交道，果然如沐春风。

### 120

方军 2024/03/21

【# 香港科技大学允许学生用 GPT 考试 #】香港科技大学，是国内首个可以用 GPT 进行考试和论文的学校。首席副校长郭毅可并不反对学生使用 GPT 工具，他认为 ChatGPT 教学化真正的挑战不是学生，是老师，「老师怎么样出的题，是越过机器的能力」。他号召现在的老师巧妙地运用机器，来提升出题水准和教学质量。

### 121

方军 2024/03/21

Ethan Mollick: This remains one of the most consequential experiments in AI: Bloomberg trained a GPT-3.5 class AI on their own financial data last year…

…only to find that GPT-4 8k, without specialized finance training, beat it on almost all finance tasks.

Hard to beat the frontier models.

这仍然是人工智能领域最重要的实验之一：彭博去年在他们自己的金融数据上训练了一个 GPT-3.5 级别的人工智能。

… 但发现，没有专门的金融培训，GPT-4 8k 在几乎所有金融任务上都表现更好。

难以超越前沿模型。

There was a moment that we thought proprietary data would let organizations train specialized AIs that could compete with frontier models. It turns out that probably isn't going to happen. The largest frontier models are just much better at most complex tasks than smaller models.

有一个时刻，我们曾认为专有数据可以让组织训练出能与前沿模型竞争的专业人工智能。结果表明，这种情况可能不会发生。最大的前沿模型在大多数复杂任务上比较小的模型要好得多。

twitter.com/emollick/status/1770618237782307075

相关讨论：

twitter.com/proofofbeef/status/1770632815303917887

如果你仔细阅读彭博的报告，就会发现他们的结果并不理想。

### 122

方军 2024/03/22

真是很遗憾，不知道 SD 的热潮会不会继续下去

[突发！Stable Diffusion 核心团队被曝集体离职](https://mp.weixin.qq.com/s/4VZqW8OflBjvTxqTMzWgwA)

[可提前使用 Stable Diffusion 3，Stability AI 发布一站式开发服务](https://mp.weixin.qq.com/s/zh6OyPEaE_O29K_LZfKvMA)

讲 inflection

[百亿美金 AI 独角兽遭最大投资者微软生吞活剥，大模型独角兽或是大厂豢养的猎物？](https://mp.weixin.qq.com/s?__biz=MzAxOTU4MzE0Nw==&mid=2651891370&idx=1&sn=22b038a7c168093e40dff4cec85156cc&chksm=8020df6eb7575678f204c0380e3981c07790989d698def5b311e38b152da4776d72c85cffc8e&token=1119505291&lang=zh_CN#rd&v_p=90&WBAPIAnalysisOriUICodes=10000001&launchid=default&wm=3333_2001&aid=01A0VjFEC-8TX6msntzx_IZJsVSdIBL5NqzASu9SjrmTcS5LA.&from=10E3193010)

### 123

方军 2024/03/22

吴恩达老师建议大家关注 AI 智能体工作流，可以大幅提升 AI 应用的性能，并且他们总结了一套智能体设计模式（via 宝玉）：

- 反思：让大语言模型对自己的结果检查改进
- 使用工具：让大语言模型调用外部工具，如网络搜索、代码执行等
- 规划：让大语言模型自己设计一个多步骤的计划来达成目标
- 多智能体合作：多个 AI 智能体协同工作，分配任务，讨论和辩论想法，写作得到更好的结果

以下内容为推文转译：

今年 AI 智能体 (AI Agent) 的工作流程将会促进 AI 领域的巨大进步，这种影响可能会超越下一代的基础模型。这是一个重要的趋势，强烈建议所有 AI 领域的工作者关注这一点。

目前，我们通常在零样本 (Zero-shot) 模式下使用大语言模型 (LLM)，即让模型一步步地生成输出，而不进行任何修改。这好比要求一个人一气呵成地写完一篇文章，不允许回退修改，却期望文章能达到高质量。尽管这样做存在挑战，但大语言模型在此任务上的表现出乎意料地好！

通过采用智能体工作流，我们可以引导大语言模型对文档进行多轮迭代处理，仿佛它在多次精细打磨它的作品。具体操作可以包括：

- 制定文档大纲。
- 决定是否需要网络搜索以获取更多资料。
- 撰写初稿。
- 仔细审阅初稿，标记不合逻辑的论点或不必要的信息。
- 根据标记的问题对稿件进行修订。
- 以此类推。

这种迭代过程是大多数人类作者撰写优质文本不可或缺的步骤。对 AI 来说，采用这种迭代工作流显著优于单次过程的写作方式，能够产出更优质的成果。

最近，Devin 的一个引人注目的演示在社交媒体上引发了广泛讨论。我的团队一直在跟踪研究编写代码的 AI 的发展。我们分析了多个研究小组的成果，特别关注这些算法在广泛使用的 HumanEval 编程基准测试中的表现。以下图表展示了我们的一些发现。

在零样本 (Zero-shot) 模式下，GPT-3.5 的准确率为 48.1%。而 GPT-4 的表现更佳，达到了 67.0%。不过，从 GPT-3.5 到 GPT-4 的提升，并没有迭代智能体工作流带来的提升那么显著。实际上，当 GPT-3.5 应用在一个迭代智能体循环中时，它的表现可以提高到惊人的 95.1%。

开源的智能体工具和有关智能体的学术论文日益增多，这让我们既感到兴奋又觉得困惑。为了更好地理解这一工作，我想介绍一个用于分类构建智能体设计模式的框架。我的团队 AI Fund 已经在多个应用场景中成功应用了这些模式，我希望它们对你也有所帮助。

- 反思：大语言模型会审视自己的作品，并寻找改进的方法。
- 使用工具：为大语言模型提供各种工具，如网络搜索、代码执行等，帮助其收集信息、执行操作或处理数据。
- 规划：大语言模型能够设计并执行一个多步骤的计划来达成目标（比如，先为一篇文章制定大纲，接着进行在线研究，然后撰写草稿等）。
- 多智能体合作：多个 AI 智能体协同工作，分配任务，讨论和辩论想法，共同寻找比单独工作时更好的解决方案。

下周，我将进一步深入这些设计模式，并为每种模式提供推荐阅读材料。

来源：twitter.com/AndrewYNg/status/1770897666702233815

### 124

方军 2024/03/22

不知道是 kimi 在做内容营销，还是它的产品力带来大量的自动介绍，总之这段时间 kimi 出镜率好高

将实话，文心大模型的效果不错的，但是，文心一言的运营真的可改进的太多了

前几日参加它的微信视频号直播，发现他们在努力地通过直播卖数百元的季卡，真心用错力量，即便这是其中一个小团队的 KPI，但实在没必要这样做尝试。

想起去年那几天大家都想拥有一个文心测试账号的状态，百度真是把很好的资源做到较差的程度。

当然两者还是不能直接比，百度在大众用户里面的接受度太高了。

月之暗面：3 月 20 日以来 Kimi 流量增加趋势远超预期导致 SaaS 客户体验异常

财联社 3 月 21 日电，月之暗面发布情况说明：从 2024.3.209:30:00 开始，我们观测到 Kimi 的系统流量持续异常增高，流量增加的趋势远超我

们对资源的预期规划。这导致了从 2024.3.2010:00:00 开始，有较多的 SaaS 客户持续的体验到 429:engine is overloaded 的异常问题，对此我们深表抱歉。做为一家以技术为导向的公司，我们非常理解一个 API 的稳定性是能否投入实际生产的最关键因素之一，已经有多项应急措施正在实施，包括不限于：从 3.20 观测到流量异常增高后，已经进行了 5 次扩容工作。推理资源会持续配合流量进行扩容，以尽量承载持续增长的用户量；设计了一套更有效的 SaaS 流量优先级策略，以保障付费用户的调用稳定，预计 3.25 之前完成并上线。

### 125

方军 2024/03/22

某：我在想，现在已经完成信息化与自动化的制造企业，渴望 Ai 来升级智能智造，也有这方面的「科普」需求………

比如：管物料的部门经理问「Ai 物料管家」：哪些型号原材料近期需要补充，哪些客户的原材料还没配齐？… 等等，可以及时得到 Ai 的回答，而这些大模型该如何在制造企业实现，而其背后的原理是什么？

我：您说的这个应该是很简单的，LLM + 接口调用

也许再加一点点规则和推理

案例：

[【人工智能深度案例】从智能工厂到 ChatBI，雅戈尔的「智能 +」实践](https://mp.weixin.qq.com/s/HQDiQ3Wx_j-bzQ1u8-hgkw)

### 126

方军 2024/03/22

Google Gemini 1.5 向所有人开放了

[Untitled prompt | Google AI Studio](https://aistudio.google.com/app/prompts/new_chat)

### 127

方军 2024/03/22

差距真大

美团：Q4 营收 737 亿元，净利 22.2 亿元

鞭牛士 2024-03-22 16:33

鞭牛士 3 月 22 日消息，美团发布 2023 年第四季度及全年财报，第四季度营收 736.96 亿元，上年同期营收 601.3 亿元，市场预期 726.96 亿元；第四季度净利润 22.2 亿元人民币，市场预期 10.9 亿元人民币。

2023 年全年营收 2767.4 亿元，上年同期 2199.55 亿元；2023 全年净利润 138.6 亿元人民币，市场预期 128.4 亿元人民币。

拼多多

财报显示，2023 年 Q4 营收 888.8 亿元，市场预期 798.74 亿元，同比增长 123%。

经营利润为 223.95 亿元，同比增长 146%；经调整净利润为 254.77 亿元，同比增长 110%。调整后每 ADS 收益为 17.32 元，去年同期为 8.34 元。

在线营销服务和其他收入为 486.76 亿元，同比增长 57%；交易服务收入为 402.05 亿元，同比增长 357%。

2023 年全年，总营收为 2476.392 亿元，同比增长 90%。归属于拼多多普通股股东的净利润为 600.265 亿元，同比增长 90%。不按美国通用会计准则，归属于拼多多普通股股东的净利润为 678.993 亿元，同比增长 72%。

[Temu 狂飙，没有秘诀](https://mp.weixin.qq.com/s/bXHHRW38EmkEeKpEGNa75g)

### 128

方军 2024/03/22

RAG 要被大厂搞没了。

---

[阿里通义千问升级：免费开放 1000 万字长文档处理功能]

《科创板日报》22 日讯，阿里通义千问今日升级，向所有人免费开放 1000 万字的长文档处理功能。即日起，可通过通义千问网站和 APP 快速读研报、分析财报、读科研论文、研判案情、读医疗报告、解读法律条文、分析考试成绩、总结深度文章。（记者黄心怡）

### 129

方军 2024/03/22

[微软新作「Mora」，复原了 Sora](https://mp.weixin.qq.com/s/G08_a5gkzjTIAt8MoprmMA)

### 130

方军 2024/03/22

目前看 gpt store 的确没有到合适推出的时机

[GPT Store 被放弃？OpenAI 或成烂尾专业户](https://mp.weixin.qq.com/s/7emzVjwVGpbJedenBhzmaw)

### 131

方军 2024/03/23

摘：【平凡中的非凡：AI 工具的日常应用启示录】

作者分享了他使用 Claude 和 ChatGPT 完成临时任务的案例。他认为，这个案例最值得注意的地方在于它完全不值得注意，他每天都能从这些工具中获得类似的结果。  

点评：（这几段明显是AI生成的）

- 作者的观点颇具反直觉性，他认为这个案例之所以值得关注，恰恰是因为它已经变得司空见惯，这种看似平凡的成功背后，反映出 AI 工具已经达到了一个新的高度。  

- 作者对 AI 工具的信心和依赖，启发我们思考这些工具在日常工作中的应用价值和可靠性，它们正在悄然改变我们的工作方式。  

- 作者的态度虽然轻描淡写，但背后透露出一种对 AI 工具的高度认可和信任，这种态度值得我们反思：我们是否也已经对 AI 的能力习以为常了? 

[Claude and ChatGPT for ad-hoc sidequests](https://simonwillison.net/2024/Mar/22/claude-and-chatgpt-case-study/)

### 132

方军 2024/03/23

kimi 最近遇到点事，其实就是什么能回答什么不能回答呗，哎，社交媒体上一些人又开始表演，TMD，你们这些人根本不配用这么好的产品，脑残用什么 AI，去医院要紧。

### 133

方军 2024/03/23

[​前谷歌大佬离职创业，不到一年造出 GPT3.5 和 Gemini Pro，惨痛忠告：GPU 简直菜鸡，就像是买彩票！](https://mp.weixin.qq.com/s/ojrGxBOAQdgK5xsK69k9-A)

### 134

方军 2024/03/23

很赞同这个，瞎搞，上下文窗口和能处理多长文本，混起来了：

文心一言说开放 500 万字的长文本能力，通义千问说开放 1000 万，这下把 OpenAI 和谷歌整蒙了。

其实，本质上是在偷换概念，并没有什么实质性的突破。国内的公司风气不好，偷换概念，重新定义概念，把大家都搞乱，目的就是营销宣传，本质上，还是在专注于卖，而不是做事研究。

Kimi 这技术，我们去年就已经做到了，这种营销，真敢闭着眼睛瞎吹牛，有点丢做技术的人的脸了。

### 135

方军 2024/03/23

YouTube 新规：上传视频需标注是否为 AI 制作，包括合成配音/换脸等 3 月 19 日，YouTube 宣布，即日起任何人在上传、发布视频时，都需要标注「篡改或合成」的逼真内容，包括生成式 AI。

YouTube 将「逼真内容」定义为「任何观众容易误认为是真实的人事物或地点」的内容。若视频创作者使用真人声音的合成版本来为视频配音，或发布「AI 换脸」主题的视频，就需要附上标签。

此举的本质目的是防止 AI 生成内容可能导致的虚假信息传播，而非反对创作者通过 AI 制作内容。这项新规旨在防止用户受到蒙蔽，即误认为合成视频为真实素材，这是因为新的生成式 AI 工具已经让视频内容的真伪区别愈发困难。此次发布的新规，也是 YouTube 继去年 11 月公布的大规模 AI 应用政策的延续与最新条款。

### 136

方军 2024/03/23

《澎湃：2024 年人工智能公众态度调查报告》

面对 AI ，很多人处于「短期积极、中期期待、长期担忧」的状态。这种拧巴态度，或许将贯穿我们发展人工智能的整个过程，即随着机器学习系统越来越普遍和强大，人类越来越发现，自己处于一种「魔法师学徒」的境地。

2『一下子原文「20240322澎湃：2024 年人工智能公众态度调查报告」。（2024-03-24）』

### 137

方军 2024/03/23

[LLMOps 框架 Dify 发布 Workflow 功能，RAG 进入自由编排时代（附产品负责人分享 PPT ）](https://mp.weixin.qq.com/s/s6PgoRrCVdbSnfeVXAjtGw)

### 138

方军 2024/03/24

牛啊

使用大语言模型把二进制代码恢复到普通代码（俗称「破解」）

LLM4Decompile: Decompiling Binary Code with Large Language Models

Hanzhuo Tan, Qi Luo, Jing Li, Yuqun Zhang

Southern University of Science and Technology

The Hong Kong Polytechnic University

### 139

方军 2024/03/24

这东西好牛，用 AI 来生成数学、几何等学科的可视化视频

[Gatekeep | Start learning faster with personalized videos.](https://gatekeep.ai/)

### 140

方军 2024/03/24

在典型的 RAG 系统中，通常会采用现成的通用嵌入模型来实现数据的嵌入处理，利用向量数据库进行高效的信息检索，并结合大型的黑盒语言模型来完成内容的生成。这些独立的技术组件通过提示或编排框架被整合在一起，形成了一个看似完整的系统。然而，这种方法往往会导致所谓的「科学怪人效应」（Frankenstein's monster），即尽管每个部分在技术上都能独立运行，但整合后的整体性能却远未达到理想状态。这样的系统不仅脆弱，缺乏对特定部署领域的机器学习和专业化调整，而且对大量的提示高度依赖，这使得系统在运行过程中容易出现连锁性的误差。

参看：

[大模型也有「漂移（Drift）」现象？应引起 AI 应用开发者警惕](https://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&mid=2650441023&idx=5&sn=b482fe6b4c4dc594841288b8c4ecdff4&chksm=becd036589ba8a73d30c0827fef76ba8828e04b4976a9ae44e39a68e8e6c651e94938d8364d6&scene=21&poc_token=HJ6WBWajD0xuptKZgjQ34djin1pclstIUFU2V_k0)

因此，RAG 系统很少能通过生产测试，投入生产的寥寥。

[RAG 2.0 来了，它能成为生产落地的福音吗？](https://mp.weixin.qq.com/s/RSL5l4WSa5ZJP9Dc0MYiVQ?v_p=90&WBAPIAnalysisOriUICodes=10000001&launchid=default&wm=3333_2001&aid=01A0VjFEC-8TX6msntzx_IZJsVSdIBL5NqzASu9SjrmTcS5LA.&from=10E3193010)

### 141

方军 2024/03/24

清洁的数据是 AI 时代最大的优势！

finetuning 数据集通常包含一些不好的例子，这些例子很难手动检测，并且成为主要的性能障碍。

但是有一个解决方案：如何检测指令调整数据集中的错误数据（以便更好地进行微调）

[How to detect bad data in your instruction tuning dataset (for better LLM fine-tuning)](https://cleanlab.ai/blog/filter-llm-tuning-data/)

很有价值的文章

### 142

方军 2024/03/24

技术工作真是相当无聊，看了大量资料、进行很多试验之后，得到的初步结论是：原有方案目前看更加佳，新方案暂时先了解着。就这么一句话。

如果写文章，可以写很多文章。但技术工作却是极度无聊的，细节也会被封装起来。

我猜这是为什么做技术工作的人里面写文章的人特别多，因为要对冲无聊。

### 143

方军 2024/03/25

说个蛮有意思的事，刚刚社交媒体看到人说自己总结的 chatgpt 提示语模板（水平不是很好），前些日子与百度文心一言沟通，他们的一个部门也很强调它们自己的所谓模板，让我在讲 ICDO 前至少放一下，我当然尊重人家意见。我们都见过非常多框架，我曾经总结过十来个它们的相似与不同。这是无所谓的事，因为所谓各种模板，不过是一个暂时理解的拐杖，会用了就要扔掉，因为我们越来越重视后面的流程。

但这里很有意思的一个区别就是，我真心从来不说这个是我发现的，也的确不是我，我会说它的来龙去脉，中间我们干了很少一点，基本上就是典型的开源心态。然后，我更愿意展示更多具体的例子，说明早期各种程序员总结的这个框架的确有广泛的适用性。

### 144

方军 2024/03/25

067 AI 让场景化学习特别便利

不说大词，说个小体会。我实在是对 React 掌握得不怎么样啊，但毕竟要用多少掌握了一些。过去，遇到一个觉得可能需要再次确认、需要深入知道、或觉得未来有用的，都会搜索看下文档，遇到一点多学一点，现在大概属于中等水平。

现在，AI 真心让这种形式的学习变得非常简单。刚刚想，要不让 AI 再给我讲一遍 HOOK 呗。如下这个回答我觉得讲得不错，它并不需要精确，它是很好的复习（扫一眼如下回答中的 1，就算强化了记忆了）。这极大地降低了学习成本。

---

请根据 react 文档回答，为什么需要 Hook?

（Github Copilot 回答：）React Hooks 是在 React 16.8 版本中引入的新特性，它们的出现解决了 React 中的几个关键问题：

1、在组件间复用状态逻辑很困难：在 Hooks 出现之前，React 没有提供一种将组件中的状态逻辑复用的方式，除非你使用 render props 或者高阶组件。但这两种方法可能会导致组件树变得复杂，而且重用逻辑可能会变得困难。Hooks 允许你在不改变组件结构的情况下复用状态逻辑。

2、复杂组件变得难以理解：在类组件中，如果一个组件有很多生命周期方法，那么相关联的逻辑可能会分散在各个生命周期方法中，这使得跟踪一个组件的逻辑变得困难。Hooks 允许你将一个组件中相互关联的部分分组在一起（比如设置订阅和清除订阅），而不是强制按照生命周期方法来分组。

3、类混淆了人和机器：类组件需要你理解 JavaScript 中 this 的工作方式，这对于很多人来说是困难的。此外，类组件的代码经常被压缩和混淆，这使得它们在性能优化上比函数组件更困难。Hooks 允许你在不使用类的情况下使用更多的 React 特性。

因此，Hooks 的出现使得在 React 中编写和理解代码变得更加简单和直观。

---

其实 3 我还是不知道在讲什么（这里应该有翻译错误），因为当我们开始较为深入地用 React 时，3 的问题早就被函数取代了。另，最近 React 似乎推了 19 版。

### 145

方军 2024/03/25

《科创板日报》记者从知情人士处了解到，百度将为苹果今年发布的 iPhone16、Mac 系统和 ios18 提供 AI 功能。苹果曾与阿里以及另外一家国产大模型公司进行过洽谈，最后确定由百度提供这项服务。苹果预计采取 API 接口的方式计费。苹果将国行 iPhone 等设备采用国产大模型 AI 功能主要出于合规需求，该公司短期内还无法解决合规问题，但国外版 iPhone 等设备 AI 功能均来自苹果自己的大模型。（记者张洋洋）

### 146

方军 2024/03/25

很大的冲击

[开源 Redis 的生命将就此终结？Redis 之父回应分叉浪潮：未来谁能领先，各凭本事！](https://mp.weixin.qq.com/s/RJn_tuylaFppBMfsJm05Eg)

### 147

方军 2024/03/25

068 AI 生成是一个误解，应「有所本」

不管叫 AIGC，还是 GenAI，这个名字里面的生成其实都造成了很多的误解。这几天火热的音乐生成也是这个意思。

从非常长期看，AI 也许能够生成，AI 也许能够完全独立自主，但现在不是。现在，AI 最擅长干什么？

我一直借用一个词说，AI 最擅长干的是「有所本」。比方说：

- 它做翻译，将一种语言的文本翻译另一种语言，这是有所本。

- 它做代码转换，从一种框架转换到另一种框架，从一种架构转换到另一种架构。

- 它做解读，比如给它图书章节，它进行通俗的解读；给它代码，它进行解读。

这里面有意思的是：

1、它的确拥有知识。

2、它能够干活（转换）。

3、它干活的过程中的确有思考。

在这种限定场景下，它干得最好。

那么，这几天火热的音乐生成 SUNO 可以怎么玩呢？

你可以用它去生成原创的歌曲，但这种真心效果不佳。如果放在有所本的场景里，它干得特别好：

比方说，我们曾经用「北京欢迎你」改造一个 MV，把其中歌词换掉，然后由一组人演唱。

现在大体上可以用 AI 工作流这么做：

- 原歌词给 ChatGPT 等语言模型，给出指令，生成符合需要的新歌词。

- 编曲等要素 ChatGPT 等语言模型，生成相应的音乐指令。

- 将音乐指令给 SUNO，按编曲要求，生成新的歌曲。

- 将音乐指令给 SUNO，按歌词，生成演唱。

- 还可以进一步视频化，配上视频素材，进行剪辑处理，其中用到 AI 剪辑功能。

附一个 AIGCxChina 的 Suno 指南：

[SunoAI 音乐新手指南 1.1 版 by AIGCxChina](https://shimo.im/docs/vVqRMPBgYycW8x3y/read)

[Suno 曲风提示词 1.2 版 by AIGCxChina](https://shimo.im/docs/Ee32mzpZxdsZa6A2/read)

[Suno 歌词元标签 1.1 版 by AIGCxChina](https://shimo.im/docs/RKAWMmoeYBh52Jq8/read)

[从 0 到 1 带你玩转 Suno（7500 字干货）](https://mp.weixin.qq.com/s/YDpY2_IhUmDPT6erM0-toA)

### 148

方军 2024/03/25

这个 AI 历史好赞。

已下载原文件「20240325HistoryofAIPosterFinal」。

### 149

方军 2024/03/25

无比赞同，摘：

软件开发者 Shesh 这个对软件开发未来的思考有点意思，描述了一下为什么他认为 AI 不会取代「软件开发人员」。

我翻译了一下全文，下面是主要观点和全文地址：

软件开发的核心在于管理复杂性，将业务问题从现实世界转化为数字模型。

尽管 Excel 和低代码工具为业务用户提供了低门槛的数据组织、数据分析和流程自动化手段，但它们无法处理复杂的业务工作流程。

业务逻辑必须以明确无误的格式定义，这是编程语言、Excel 公式或低代码流程的共同特点。

即使未来的 AI 编码者能够根据对话英语指令生成软件产品，后台仍然需要一个正式的业务逻辑定义，这在本质上类似于「代码」。

即使 AI 编码者能够从对话英语中生成业务逻辑，仍然需要人们理解后台生成的代码，并在必要时进行修改。

因此，直到 AI 编码者能够以确定性的方式生成这些业务逻辑，软件开发者的需求仍将存在。

[关于软件开发未来的思考 | AIGC Weekly](https://quail.ink/op7418/p/e585b3e4ba8ee8bdafe4bbb6e5bc80e58f91e69caae69da5e79a84e6809de88083)

### 150

方军 2024/03/25

推上爆发了关于 long-context 和 RAG 的激烈争吵，几个中文的，我摘几个观点比较持正的，那种讨论技术话题都开始上火的就算了。

九原客 @9hills

关于 RAG 和 Long-context，其实本没有什么需要写的。

但是现在有两种荒谬的论点：

1. Long-context 会替代 RAG；

2. Long-context 能做到的 RAG 也能做到。

只要做过实际应用的，就知道 RAG 有很多局限是这个架构解决不了的，也会知道 Long-context 在某些场景下目前效果依然不如 RAG。

RAG 换句话说，可以叫 Selected-Context。就是用某种检索方法，挑选出最合适的 Context。信息的选择一定伴随着信息的丢失。

而 Long-Context 受制的是注意力机制，本质也是丢失掉上文的部分信息。

两种方法都会丢失信息，但是丢失的粒度和类型不同，要看实际的场景选择。

Tumeng@Tumeng05

两者配合来用是最好的，我们做 RAG，但也盼着 Long-context LLM 越来越厉害。这样 recall 可以更大，在 precision 是除了 rerank，还可以把更多问题留给 LLM 帮忙解决。没必要非黑即白。

九原客 @9hills

其实 recall 变大对目前来说效果不一定更好。

我们实际测试，在某个精确问答的场景，1024 tokens 段落 + top3 召回是最好的。

不同的场景，不同的模型这个 chunk size 和 topk 不同，不是越大越好，得实际测试。

Tumeng@Tumeng05

对，实际测试是最终的方法。

但 recall 不大还是会有一定几率的相关性内容丢失，rerank 都没机会补救。

我说的意思是 recall 大一些，然后 llm 更强的话，一部分过滤重复和逻辑排列问题就交给 LLM 了。把垃圾进垃圾出的结果改善一些。

twitter.com/Tumeng05/status/1772128875008729319

### 151

方军 2024/03/26

滚石深度报道：音乐版的 ChatGPT 来了，改变一切的初创 Suno 的公司内幕。

Suno 毫无疑问是最近风头很劲的 AI 公司。大家可能已经对文生图，文生视频见怪不怪。或者是大家多少都能画两笔。但是，写一首歌对绝大数普通人来说，则是不可能完成的任务。关于 Suno 的具体情况，老牌音乐杂志滚石做了一个深度报道。这家公司的口号：我们试图让十亿人比现在更多地与音乐打交道，不是要取代艺术家。

如果还没有听过 Suno 的 AI 作曲。我翻找了一首 (CityOfGirls_nft On X)，大家可以感受一下。

音乐版的 ChatGPT 来了，改变一切的初创 Suno 的公司内幕。这家公司希望每个人都能制作自己的专业级歌曲，但这对艺术家意味着什么？

A ChatGPT for Music Is Here. Inside Suno, the Startup Changing Everything

Suno wants everyone to be able to produce their own pro-level songs — but what does that mean for artists?

BY BRIAN HIATT

2024 年 3 月 17 日

「我只是一个灵魂被困在这电路中」。唱出这些歌词的声音原始而平实，掺杂着蓝色的音符。一把孤独的木吉他在背后" 咚咚 "作响，用优美的旋律点缀着歌词。但声音背后没有人，吉他上也没有手。事实上，没有吉他。在 15 秒的时间里，这首可信甚至动人的蓝调歌曲由一家名为 Suno 的初创公司的最新人工智能模型生成。将它从虚空中召唤出来只需要一个简单的文字提示：" 独奏密西西比三角洲原声蓝调关于一个悲伤的人工智能 "准确地说，这首歌是由两个人工智能模型合作完成的：Suno 的模型自己创作了所有的音乐同时调用 OpenAI 的 ChatGPT 生成歌词甚至歌名" 机器之魂 "。

在网上，Suno 的作品开始引起 "这 F**k 怎么是真的？" 之类的反应。在距离马萨诸塞州剑桥市哈佛大学校园几步之遥的 Suno 临时总部的一间会议室里，Sonos 扬声器播放着这首特别的歌曲，就连这项技术的一些幕后人员也略显不安。现场不时传出紧张的笑声，以及 "我的妈呀" 和 "哦，天哪" 的杂音。现在是二月中旬，我们正在使用他们的新型号 V3，距离公开发布还有几周时间。在这种情况下，我们只用了三次尝试就得到了令人吃惊的结果。前两次都还不错，但对我的提示做了简单的调整 -- 联合创始人基南 - 弗雷伯格（Keenan Freyberg）建议加上 "密西西比" 一词 -- 结果就更加不可思议了。

仅在过去一年里，生成式人工智能就在制作可信文本、图像（通过 Midjourney 等服务）甚至视频（尤其是 OpenAI 的新工具 Sora）方面取得了长足进步。但音频，尤其是音乐，却落在后面。Suno 似乎正在破解人工智能音乐的密码，其创始人的野心几乎是无限的 -- 他们想象着一个音乐创作疯狂民主化的世界。联合创始人中最有发言权的是米奇 - 舒尔曼（Mikey Shulman），37 岁的他是哈佛大学物理学博士，背着背包，童心未泯，他设想全球有十亿人每月支付 10 美元就能用 Suno 创作歌曲。他认为，目前听音乐的人远远多于做音乐的人，这是 "非常不平衡的"。

迄今为止，大多数人工智能生成的艺术作品充其量只能算是庸俗之作，就像许多《Midjourney》的用户似乎一心想要生成的超现实主义科幻垃圾一样，大量使用合身的太空服。但 "机器之魂" 给人的感觉却与众不同 -- 它是我在任何媒介中见过的最强大、最令人不安的人工智能作品。它的存在就像是现实中的一道裂缝，既令人敬畏，又隐约有些邪恶，我一直在想阿瑟 - C - 克拉克（Arthur C. Clarke）的一句话，这句话似乎就是为人工智能生成时代量身定做的："任何足够先进的技术都与魔法无异" 从剑桥回来几周后，我把这首歌寄给了 Living Colour 乐队的吉他手弗农 - 里德（Vernon Reid），他对人工智能音乐的危险性和可能性直言不讳。他对这首歌 "令人不安的真实性" 表示 "惊叹、震惊和恐怖"。他写道："将困难、混乱、不受欢迎和被鄙视的人类从其创造性产出中分离出来的长期乌托邦理想就在眼前。" 他指出了人工智能演唱蓝调的问题所在，"蓝调是非洲裔美国人的成语，与历史上的人类创伤和奴役有着深刻的联系"。

Suno 成立不到两年。联合创始人舒尔曼、弗雷贝格、格奥尔格 - 库茨科和马丁 - 卡马乔都是机器学习专家，他们在剑桥的另一家公司 Kensho Technologies 工作到 2022 年，该公司致力于为复杂的商业问题寻找人工智能解决方案。舒尔曼和卡马乔都是音乐家，他们在 Kensho 工作时经常一起演奏。在 Kensho，他们四人合作开发了一种用于捕捉上市公司盈利电话的转录技术，由于音频质量差、专业术语多、口音各异，这是一项棘手的任务。

一路走来，舒尔曼和他的同事们爱上了人工智能音频尚未开发的可能性。他说："在人工智能研究中，音频总体上远远落后于图像和文本。我们可以从文本社区学到很多东西，以及这些模型是如何工作和如何扩展的"。

同样的兴趣可能会把 Suno 的创始人引向截然不同的地方。虽然他们一直打算最终推出一款音乐产品，但他们最早的头脑风暴还包括一个关于助听器的想法，甚至是通过音频分析发现机器故障的可能性。然而，他们发布的第一款产品却是一款名为 "Bark" 的文本转语音程序。当他们对 Bark 的早期用户进行调查时，发现他们真正想要的是一个音乐生成器。"舒尔曼说：" 于是，我们开始进行一些初步实验，结果似乎很有希望。

Suno 采用的一般方法与 ChatGPT 等大型语言模型相同，后者将人类语言分解成称为标记的离散片段，吸收其数以百万计的用法、风格和结构，然后按需重建。但音频，尤其是音乐，几乎是深不可测的复杂，这就是为什么就在去年，人工智能音乐专家告诉《滚石》杂志，像 Suno 这样有能力的服务可能需要数年才能实现。"舒尔曼说：" 音频不像文字那样是一个离散的东西。"它是一种波。它是一个连续的信号。他补充说，高品质音频的采样率一般为 44khz 或 48hz，这意味着" 每秒 48,000 个字符 "。" 这是个大问题，对吧？因此，你需要想办法把它降低到更合理的水平。怎么做呢？" 很多工作、很多启发式方法、很多其他类型的技巧和模型等等。我认为我们还远远没有完成任务。最终，苏诺希望找到文本到音乐界面的替代方案，增加更先进、更直观的输入 -- 根据用户自己的歌声生成歌曲就是一个想法。

OpenAI 因 ChatGPT 在其庞大的训练数据语料库中使用书籍、新闻报道和其他受版权保护的材料而面临多起诉讼。Suno 的创始人拒绝透露他们正在向自己的模型中输入哪些数据的细节，只说他们之所以能生成令人信服的人声，部分原因是除了音乐之外，他们还从语音录音中学习。"Shulman 说："'裸语音'可以帮助你学习人类声音中难以学习的特征。

安东尼奥-罗德里格斯（Antonio Rodriguez）是 Suno 最早的投资者之一，他是风险投资公司 Matrix 的合伙人。罗德里格斯之前只资助过一家音乐风险投资公司，即音乐分类公司 EchoNest，该公司被 Spotify 收购，用于改进其算法。对于 Suno，罗德里格斯在产品还不明确的情况下就参与了进来。罗德里格斯说："我支持这个团队，" 他散发出自信的光芒，就像一个成功下过多次赌注的人。"我了解这个团队，尤其了解米奇，所以我会支持他做任何合法的事情。他就是这么有创造力"

我们试图让十亿人比现在更多地与音乐打交道。我们不是要取代艺术家。

罗德里格斯在投资 Suno 时完全知道音乐唱片公司和出版商可能会提起诉讼，他认为这是 "我们在投资公司时必须承担的风险，因为我们是紧跟在这些家伙后面被起诉的肥钱包....，老实说，如果我们在公司成立之初就与唱片公司达成了协议，我可能就不会投资了"。我认为，他们需要不受束缚地制作这种产品 "。(环球音乐集团（Universal Music Group）对人工智能采取了激进的态度，该公司发言人没有回复置评请求）。

Suno 说它正在与各大唱片公司沟通，并声称尊重艺术家和知识产权 -- 它的工具不允许你在提示中要求任何特定艺术家的风格，也不会使用真正艺术家的声音。许多 Suno 员工都是音乐家；办公室里摆放着钢琴和吉他，墙上挂着古典作曲家的画像。这些创始人没有表现出对音乐行业的公开敌意，就像 Napster 在被诉讼摧毁之前一样。"罗德里格斯补充说：" 顺便说一句，这并不意味着我们不会被起诉。罗德里格斯补充道，"这只是意味着我们不会抱着 ' 去他妈的 Police' 的态度"。

罗德里格斯认为，Suno 是一种功能强大、易于使用的乐器，并相信它能像照相手机和 Instagram 将摄影民主化那样，将音乐创作带给每一个人。他说，他们的想法是再次 "提高允许在互联网上创造产品的人数，而不是产品消费者的人数"。他和公司创始人敢于提出，Suno 可以吸引比 Spotify 更大的用户群。罗德里格斯说，如果你对这一前景感到难以理解，那是件好事：这只能说明它 "看似愚蠢"，而这恰恰是吸引他成为投资者的原因。他说："我们所有伟大的公司都有优秀人才的组合，"" 然后是一些看似愚蠢的东西，直到它非常明显地证明它并不愚蠢 "。

早在苏诺到来之前，音乐家、制作人和词曲作者就对人工智能可能带来的商业冲击表示担忧。"里德写道：" 音乐是人类在特殊环境下创造的...... 那些为提高自己的技艺而受苦受难的人，将不得不面对他们为之奋斗的艺术被全盘自动化的局面。但是，Suno 的创始人用 "尽管有了书写能力，人们仍然会阅读" 来做比喻，声称没有什么好担心的。"舒尔曼说：" 我们的想法是，我们要让十亿人比现在更喜欢音乐。舒尔曼说，" 如果人们更喜欢音乐，更专注于创作，形成更独特的品味，这对艺术家来说显然是件好事。我们对未来音乐的愿景是对艺术家友好。我们并不是要取代艺术家。

尽管 Suno 只专注于为那些想创作歌曲消遣的乐迷提供服务，但它最终仍可能造成巨大的混乱。在短期内，人类创作者市场中最直接受到威胁的部分似乎是利润丰厚的部分：为广告甚至电视节目创作的歌曲。管理公司 Milk and Honey 的创始人卢卡斯 - 凯勒（Lucas Keller）指出，投放知名歌曲的市场不会受到影响。"他说：" 但就其他方面而言，是的，这肯定会影响他们的业务。" 我认为，这最终会让很多广告公司、电影制片厂、网络公司等不必再去申请许可。

在没有严格规定禁止人工智能创作内容的情况下，还有一种前景，那就是像 Suno 这样的模式的用户将数以百万计的机器人创作涌入流媒体服务。舒尔曼说："Spotify 有一天可能会说 ' 你不能这么做 '，" 他指出，到目前为止，Suno 的用户似乎更喜欢把他们的歌曲发短信给几个朋友。

Suno 目前只有 12 名左右的员工，但他们计划扩大规模，在目前临时办公室所在大楼的顶层，正在建设一个更大的永久总部。在我们参观尚未完工的楼层时，舒尔曼展示了一个将成为完整录音室的区域。鉴于 Suno 的能力，他们为什么还需要录音室呢？"他承认：" 这主要是一个听音室。"我们想要一个良好的声学环境。但我们也都很喜欢制作音乐 -- 没有人工智能"。

目前，Suno 最大的潜在竞争对手似乎是谷歌的 Dream Track，该公司已获得许可，允许用户通过类似的提示界面使用查理 - 普斯（Charlie Puth）等名人的声音制作自己的歌曲。不过，Dream Track 目前只向一小部分测试用户发布，而且尽管附带了著名的声音，但目前发布的样本听起来还不如 Suno 的令人印象深刻。"舒尔曼说：" 我不认为，制作比利 - 乔尔（Billy Joel）的新歌是未来人们希望借助人工智能与音乐互动的方式。舒尔曼说：" 如果我想一想五年后我们究竟希望人们如何做音乐，那是不存在的东西。这是他们脑海中的东西。

### 152

方军 2024/03/26

飞书/lark讲实话做得并不够好

[飞书发布全员信宣布裁员：提供补偿和转岗机会](https://mp.weixin.qq.com/s/nwAISelOi0a_-kMM8bLIkQ)

### 153

方军 2024/03/26

我对 AI 音乐生成印象一般，这个事当然大幅度降低门槛，让普通人能参与，但普通人做这个干什么呢？我觉得还是小众。

讲实话我不会听非专业人士创作的内容。专业内容这件事是精英主义的，非塔尖的内容对其他人都没有意义，所有类型的专业内容都是如此。

这个事，我有很多想法，之前也有很多讨论。

### 154

方军 2024/03/26

The Information 说 HeyGen 正在做 6000 万美金的新一轮融资，投前估值大概在 4.4 亿美金，由 Benchmark 领投，这比 4 个月前 HeyGen 的 7500 万美金估值增长了差不多 6 倍。

[Benchmark 投的第一个华人 AI 项目](https://mp.weixin.qq.com/s/UecYiAv5i-XYhAT4Yuc8NQ)

此次投资可能也是 Benchmark 践行「Sell Work，Not Software」理念的一个项目，Sarah Tavel 认为，大模型给创业公司提供了一个新的机会，那就是不用给客户卖软件，而是直接售卖整个工作成果。

在最新的一次补充中，Sarah Tavel 说「Sell Work，Not Software」背后的一个核心假设是，当你销售的是 95% 的生产率提高（与你销售的软件相比，生产率提高的幅度较小）时，你就能为你的服务收取大多的费用，而如果你销售的是按座位计算的软件，你就无法做到这一点。这就意味着，同样的终端市场可能比你的软件模式直觉告诉你的要大 10-50 倍。

这与目前大家说的销售「虚拟员工」无关。而是要将员工传统上执行的具体任务或成果拆分开来，然后出售这些任务或成果。

### 155

方军 2024/03/26

[月之暗面Kimi正被大厂“围剿”：90后清华学霸带队“卷”长文本，不到一年估值破百亿](https://mp.weixin.qq.com/s/qZ3oAguY-YJdTyXqTOx8uQ)

### 156

方军 2024/03/26

《2023 年中国营销领域 AIGC 技术应用研究报告》由艾瑞咨询发布，探讨了人工智能生成内容（AIGC）在中国营销领域的应用现状与发展趋势。AIGC 技术在营销中的应用涵盖了内容创意、数据策略、广告投放等多个场景，预计到 2025 年将撬动千亿级 MarTech 市场。报告还强调了 AIGC 技术与元宇宙、万物互联的结合，将为营销带来新的增长趋势。

已下载原文件「20240326艾瑞：2023年中国营销领域AIGC技术应用研究报告」。

### 157

方军 2024/03/26

069 Suno 音乐生成，会带来什么？

尝试着区分三种内容：个人内容，专业内容，商业化专业内容

看到这么一段，我的看法可以说与之完全相反：

> 尝试了一下 Suno，会有直观的冲击。这个《低语的竹子》从头到尾都是 AI 的作品。ChatGPT 完成脚本（prompt），Suno 创作词曲，Midjourney 创作背景图，DeepL 翻译中文歌词。当然，想法还是需要自己提供一些「冷启动」。

> 这是 AI 在继续让创作门槛降低。未来的创作者的工具会极大丰富，而需要花费时间掌握的多数「技术能力」会迅速贬值。一人杂志（公众号 / 播客）、一人电视台（直播间）刚刚成真，一人乐队、一人电影、一人游戏已在眼前。（刘飞）

这件事要细细说，从两个层次说说。

⭕️ 专业内容 vs 个人内容

人或 AI 生成的内容分两种：

第一种：满足自己的内容。也可以说是「📍个人内容」，比方说自己的笔记、自己哼的歌、随手拍的视频。

第二种：满足他人的内容。也可以说是「📍专业内容」，比方说杂志文章、歌曲 CD、电影。

看到各种 AI 生成时，很多人的第一反应是，AI 将取代专业内容。

不不不，AI 是将让你更容易生成「个人内容」。但是，目前及一两年内，几乎没有取代专业内容的可能性。

你能够创作一首歌，但是，你没有能力创作一首你自己愿意单曲循环播放的歌，更没有能力创造千万人愿意听的歌（除了极个别的例外）。

现在 AI 生成的视频，实际上连专业内容的边都没摸到，对比一下 AI 生成的视频和好莱坞的电影画面。AI 视频在未来十年里会大进步，但不要忘记，好莱坞也会大进步。

在最开始提到的这个例子中，这个人能够利用众多 AI 工具，组成一个工作流，最终把作品生成出来，可以说在「个人内容 - 专业内容」的光谱中已经非常接近于「专业内容」那一端了。

⭕️ 内容 vs 传播

另一个层次则是，很多人会以为，好内容自动会传播。也有人看到，在现在的网络中 ，拥有大量粉丝的达人（所谓 KOL）能够传播内容，超过专业的内容机构。这两种观点都对，但请注意：

内容的传播是另外一种专业。每个人有 15 分钟成为明星，但普通人也许就仅仅 15 分钟。要成为真正的明星，需要的是专业的传播推广运作。

这给每个人都可以创作内容造成的影响是：你可以创作内容，但是，你基本上没有机会传播。因此，即便你能够创作出专业内容，也就是跨越「个人内容」和「专业内容」的鸿沟，你还需要传播推广的力量再往前跨越。

也许可以说这是第三种内容，「📍商业化专业内容」。

因此，Suno 带来的，不会是对专业内容的替代，它是增加每个人的表达可能性。当然，这也非常好。简言之，它降低普通人参与的门槛，但不会进入专业内容的范畴。

附言：就 AI 而言，由于它目前的能力限制，实际上，我认为它当前（也许一两年）的最适用场景都是个人内容。用它记笔记蛮好，用它写邮件还行。但用它写工作总结，请慎重，因为你在转到写的东西是给别人看的范畴了。

方军：这个讨论专业：

GanymedeNil: 作为一个 15 线音乐人好像没聊过 suno。我就分两个大类和大家聊聊。

第一类也就是服务于歌曲发行的。就我在北京认识的编曲老师（服务于一线歌手），跟他们聊的感觉是确实 AI 让他们很震撼，但目前还不会抢他们的饭碗。但是他们尝试完后确定，suno 可以帮助他们快速和歌手确定音乐 demo 的风格，然后给编曲和歌手一些完全新的创意。

第二类是商用类音乐，其实这个大类才是会被 AI 取代的。这类音乐一般人可能不了解，但实际在你生活中哪都存在。比如宣传片的音乐，你做瑜伽时候的氛围音乐等等都归结这类，一般在行内叫做罐头音乐（Canned music）。

这类音乐当然也有高制作成本的，那就归结为第一类了。但更多是旋律和配器都相对简单的，并且有一定的编曲模版的。比如可能大家会在一些片头里听到「audiojungle」，其实它就是全球相对大的卖罐头音乐的平台。

虽然我这么说，但你也别想拿 suno 生成的音乐，去这些平台卖然后年入百万。罐头音乐市场本身就已经是红海了，在没有 AI 出来之前，全靠人做的编曲也就能卖 10 几美刀，如果你不是比较出名的音乐人或者工作室，可能你做的歌曲完全 0 销售量，这也是很正常的事情。

总结一下就是，suno 确实在音乐行业有一定的颠覆性，但作为真正在行业内的人来说和大语言模型、文生图等都一样，在确保结果质量相同的情况下，加快了整个内容制作流程。但可悲的是内容行业，如果大家都为了所谓的「降本增效」，直接把 AI 生成的东西不经任何修饰做成产品，然后还沾沾自喜。这种强行拉低用户审美下限的，我也没什么可说了。

2024-03-26 21:42

欧阳回复方军：其实不仅于此。大家可能有些低估技术迭代的速度了。

2024-03-26 22:12

方军回复欧阳：是的，技术迭代特别快。如果看软件版本会很有意思，版本都迭代特别快。SUNO 似乎 2 的时候效果一般，3 就超越大众认可的那个线了。

2024-03-26 22:49

### 158

方军 2024/03/26

有人推荐关注 ideogram

ideogram.ai

摘：感觉国内对 ideogram 的关注还是太少了，但我觉得这是少数让我惊喜的 AI 产品之一，特别是那个魔法提示词，太棒了，另外就是初见 perplexity、沉浸式翻译、kimi、suno 时都是被一下击中，怎么这么好用

-

试过了，midjourney 的美学真是巨大的竞争优势。这个在美学上做得不行。

类似的是 Dall e，美学不行。

---

Create a vibrant and dynamic image featuring the phrase 'Embrace the Journey' in a bold, modern font surrounded by abstract shapes and colors.

### 159

方军 2024/03/26

发现如果用 RAG 性质的产品，比如 perplexity，写中文真不行。

如果写中文，就会去以中文作为关键词去搜索、匹配。

那还是必须写英文提示语。

### 160

方军 2024/03/26

这个读书方法我持保留意见，不过，我觉得大众能做到如此就很不容易了，太多大众没有最基本的阅读能力了，在我费了很大力气形成自己的阅读方式之前也没有（之前只是读得多而已）

[用 AI 十倍速读书解决问题](https://mp.weixin.qq.com/s/jfwDS3K1jG-u3E5mD3pnIg)

### 161

方军 2024/03/27

大众的观点蛮有意思的（这两个似是而非，并不认同，只是摘来记录大众观点）

摘 1：百度搞 AI 为什么老是扭扭捏捏，

因为搞 AI 是要革掉自己家搜索的老命

同样的事情也发生在谷歌身上，

所有的技术源头都来自谷歌，

但为什么谷歌一直扭扭捏捏，

直到 Openai 做大了才围追堵截。

最终原因还是，生成式 AI 天然就是搜索的死穴。

如果默认今后万亿参数十万亿参数模型，再加上人类全部的语料预训练。

那搜索就成了一个废物。

步骤从

输入检索词，上下翻页查找所需的网页，摘录资料，再查询。期间时不时穿插一些一堆莫名其妙的广告。

变成了

提问～回答

这对于百度谷歌这样的公司来说，等于生存模式被颠覆了。

摘 2: 看了个新闻说 stable diffusion CEO 以及核心开发人员 5 个中的 3 个都离职了。也不敢说自己太懂。但实属意料之中。因为这类美术 ai 开发成本巨大市场又小。美术类生成对普通人来说就是偶尔玩两下。…

另外可以想想波士顿动力的机器人为啥要开发跳舞和翻跟头之类的杂耍动作。因为这样才能引起关注。才能帮助暂时不能提供生产力的项目融资。

方军：这两个似是而非，并不认同，只是摘来记录大众观点

2024-03-27 00:31

方军：生成式 AI 和搜索，完全是两种功能，并不互相替代，不过的确都在抢入口、抢用户时间。之前，这是为什么百度推信息流、信息流里面强化视频。当然，个人觉得，在信息流，百度败于头条，短视频，败于抖音与视频号。

2024-03-27 01:24

alasya 回复方军：革命搞新 - 特别是根基的这种，很难发生在李大帅哥这种一创业就做对，一直顺风顺水的创业者身上。就算已经赢了三次的小马帅哥，也多少有一点，更何况小马哥这两年忙于赚房地产钱，陷在施工图和造价成本采购里了。

怕失去已有的恐惧感和被已有资源裹挟的撕扯感，是实际损失感的 3-5 倍。

杀伐果断的，比较常见在多次连续创业的人，比如李想，比如张头条黄多多王外卖。搞 ai 多少还是得懂点高等数学之类，所以中国 ai 的希望在张黄王等人身上。

2024-03-27 18:30

### 162

方军 2024/03/27

摘：veryls

今日有感如下：

1、看到飞书裁员的消息，相信最多 5 年时间，两代 chat gpt，AI 的水平就足够替换互联网大厂中厂 80% 的产运研人员。

互联网这种夕阳行业已经基本没有创造性了，变成一个高层一群儒家基层一帮费拉的重复性效率行业，而但凡重复性效率工作，它一定呈现为组织规模越大越反效率。

这时候 AI 的能力是完胜乌合之众的，且算力显卡的生命周期成本要远低于每月都要发工资每年还要涨薪的费拉。

2、小红书去年终于盈利 5 亿美金，但与其过亿的 DAU 体量完全不匹配，按 20 倍 PE 市值最多 100 亿美金，与上轮融资估值是完全倒挂的。B 站和微博也有类似的问题（知乎就更别提了），但凡带知识传播属性的社交媒体，商业化都比较难搞。

​要不抖快娱乐奶头乐，要不猫狗电商纯卖货，规模效应只有在证明高盈利能力的前提下才有价值，UV 价值的权重大于 DAU，反之则容易杯具，比如大力出奇迹路径依赖的飞书。

3、有啥是 AI 不能取代的？有创造力尤其是有软创造力的事物。今天同事看完美版三体后跟我讨论原著，觉得原著太啰嗦铺垫太多，比如三体 1，比如罗辑的故事线前一半。我说这才是三体的魅力，如果没有三体 1 直接从三体 2 开始，上来就是面壁者计划，那跟太空堡垒的剧情水平还有啥区别。

​而罗辑的整条故事线里，从他开始的文艺幻想爱上不存在的女性角色，到现实中百般无耻逃避面壁者的责任，到后面时势所迫命运使然成为首任执剑人，这种百转千寻的戏剧人生变化才是这个角色的魅力，而章北海和维德这种不犯错的效率主义者则不具备这种魅力。

​正因为创造力是要走弯路的，是反效率的，这反而是 AI 不具备的。或者说再过若干年如果 AI 具备了创造力，那就是另一个硅基生物取代碳基生物的终结者故事了。

方军：飞书的确大有问题，它产品口碑再好（我也很喜欢），和 slack 一比还是差太多

2024-03-27 06:39

### 163

方军 2024/03/27

这个观点很重要：对于很多 to C 应用来说，把模型藏起来，让用户感受不到模型的存在，只是感到你的产品很流畅、很好用、很超预期，能做一些传统 APP 做不了事情，可能是更好的方式，不要老想着秀模型能力。

陆三金：

一些不成熟的想法：

以后多个模型配合起来使用，可能就像芯片 CPU 的大小核一样，苹果虽然主任务用 Gemini、文心一言，但是还是会有自己的模型（可能是 Ajax）来处理一些交互或者调度任务。

OpenAI 和英伟达，有点像苹果，很贵，但其实是性价较高的方案（如果你对性能有较高要求的话），这其实是给其他厂商留了很大的市场空间的，因为不是所有任务、业务都在追求高性能，以及高性能之上的性价比。

Sora 成本很高，如果按照成本来定价，真的达到 100 美元以上，那面向的就是专业级市场，仍然给 to C 市场留足了空间。

对于很多 to C 应用来说，把模型藏起来，让用户感受不到模型的存在，只是感到你的产品很流畅、很好用、很超预期，能做一些传统 APP 做不了事情，可能是更好的方式，不要老想着秀模型能力。

如何平衡性能、延迟、成本不可能三角，对于多数产品来说，性能只需达到平均水平之上（足以超越传统 APP），延迟可能更重要，不要让用户在切换习惯的时候体验下降。

方军：现在 AI 其实是某些方面降级的：一些方面极度升级，一些方面没了，一些方面大降级。这就是所谓范式转换吧

2024-03-27 13:28

### 164

方军 2024/03/27

360 sou.com 是做得还不错的

[当我用 360AI 浏览器来搜周鸿祎 - 它真的好努力](https://mp.weixin.qq.com/s/nW5Oa_XFImb1MZvFMRVOaQ)

### 165

方军 2024/03/27

070 AI 编程片段

（一个纯片段式的记录，暂且留着。）

遇到较为复杂的编程逻辑问题，场景太复杂了，AI 帮不上忙了，自己想得脑袋疼…

我知道这是人的活，不是 AI 的活：

- 人描述清楚，让 AI 去把最终代码写清楚？

不太可行，因为描述不清楚

写代码的过程、试着运行的过程，实际上是想清楚的过程

编程的特点是，可以即时看到结果，从而验证设想，或者说，发现设想的问题。与普通人认为的不同，很少有问题是能预先想清楚，而是在实践中结果反馈的（这是为什么机器学习中强化学习是有效的原因）

但是，如果强迫人先想办法尽量想清楚，因为要用 AI 辅助，这种强迫可能是好事，逼迫我们花更精细的力量在设计，而非最终编码

- 比较可行的，是在整个过程中，人和 AI 互助

想一版，AI 写一版

再想一版，AI 再写一版

大幅降低原本的体力劳动成分

需要这样是因为，有太多组件了，这样不行，在数据库加点东西，那样不行，客户端组件再做点调整

这不是一个平面，而是立体的螺旋上升

---

虽然我说要乐观、要超级乐观，但是，我还是必须得承认这样的事实：

有了 AI 的辅助，的确效率大幅提升。比方说，这样一段大约 300 行的代码，过去可能是两三天，现在的确是 AI 辅助下的一天。

同时，过去可能我们不会做太多的重构，比方说除非必要，我真是懒得写类型检查。现在这样的代码任务有了 AI 的辅助，很自然地就加上了。

但是，即便这 100 行主要的逻辑代码部分，其实能够看出 AI 是不理解的。Github Copilot, GPT-4-turbo, Kimi 等等，实际上都是不理解的。因此，不管怎样变化提问方法，实际上我们看到的它都在语法层面上提供一些建议，但到不了逻辑层面。

### 166

方军 2024/03/28

云巨头都有点疯了

[亚马逊向 Anthropic 追加 27.5 亿美元投资，估值 184 亿美元](https://www.bianews.com/news/details?id=182105)

### 167

方军 2024/03/28

Fenng 喷一个人，这段有意思，很多人对「长」、「看着专业」没有拒绝能力，混过知乎就知道了，长当然有好的，但里面混的乱七八糟极其多：

> 从去年以来，做科普就更容易了，为啥呢？ChatGPT 出来了，翻译水平直接上了一个新台阶。直接翻译复制粘贴，每个话题都弄得又臭又长，歪曲别人观点也不要紧，只要写的字儿多，好像就很有道理，再加上唬人的 Title，绝对能蒙住一些傻狍子。微博上本来蠢人就多。人蠢就慕强，所以得打造个光鲜亮丽的人设。

### 168

方军 2024/03/28

langchain 这个服务看着很贴心

Open Source Extraction Service

Have you ever wanted to extract specific structured information from text, HTML, or PDFs?

Today we are launching a hosted version of our most recent OSS use-case accelerant: a service for extracting structured data from unstructured sources, such as text and PDF documents. 

YouTube Walkthrough: youtu.be/-FMUt3OARy0

Hosted Extraction Service:  extract.langchain.com

GitHub Repo: github.com/langchain-ai/langchain-extract

Blog: blog.langchain.dev/open-source-extraction-service/

### 169

方军 2024/03/28

摘：最新的 Arena 投票结果表明：
Claude 3 模型已经超过了 GPT-4 的排名，首次夺冠！

作为 Anthropic 推出的对标 OpenAI GPT-3.5 的 Claude-3 Haiku 在用户中大受欢迎，其性能甚至被认为达到了 GPT-4 的水平！它的处理速度、功能强大及处理的上下文长度，在目前市场上均处于领先地位。

@梧桐清声：GPT4真的是越来越懒了，以前让它学我的文章风格，然后帮我改改文章，加几句话，我觉得它越来越懒得学，prompt来prompt去都是一股子gpt味

huggingface.co/spaces/lmsys/chatbot-arena-leaderboard

### 170

方军 2024/03/28

AI 绘图带来的改变，在目前，真不是真实照片，虽然人们对真实照片的需求最为强烈。我觉得它目前能够完成的这种高度风格化的图片，是它最佳的应用场景之一。

### 171

方军 2024/03/28

看到一个吐槽，对几位 AI 名人的经济学人访谈：

老生常谈，车轱辘话来回讲

大众和大众媒体都蛮惨的，就是这么回事。

喜欢学习的人很难喜欢大众媒体，因为在这样的话语中是没有真正的快乐感觉的，喜欢学习的人是打开一个又一个自己未知的。

### 172

方军 2024/03/28

这个用 midjourney 辅助品牌设计的工作流好赞

uxdesign.cc/how-i-used-midjourney-to-design-a-brand-identity-394cf9ddaeed

Matty Brownell

已下载原文「20240328如何使用 Midjourney 设计品牌标识」。

### 173

方军 2024/03/28

这个用 Claude 生成 prompt 的工作流过程很赞，结果也很赞，超过绝大多数专业 prompt :

Janet twitter.com/genie0309/status/1773019152049144212

通过与 Claude 的协作，最终定稿的 Prompt 如下：

---

「请根据以下步骤，对提供的播客文字稿进行整理、重构、要点提炼以及反共识观点提取:

第一步：整理与重构

仔细阅读全文，理解文章的主旨、脉络和议题

将文章内容按主题进行归类，形成层次分明、逻辑清晰的结构

对归类后的各部分内容进行语言润色，使行文更加通顺、简洁

尽可能保留原文的所有关键信息、数据和细节，力求做到信息零损失

在各部分内容前加入恰当的标题，便于读者快速索引与定位

第二步：要点提炼

在整理重构的基础上，提炼出 3-5 个核心要点

每个要点由一个主要论点和 2-3 个支撑性论据组成

论据应来自于原文，能够有力佐证论点，起到画龙点睛之效

要点应全面涵盖文章的核心论题，彰显文章的主旨和价值

要点表述应简明扼要，避免冗长累赘，突出重点、一语中的

第三步：提取反共识观点

找出文章中有悖于主流认知、但颇具洞见的观点

提取 1-2 个有代表性的反共识观点，引起读者的思考与讨论

对每个观点给出 200 字内的简要阐释，点明其独到之处

阐释时应联系实际案例，增强观点的说服力

观点的提取应客观中立，不掺杂个人倾向，以理服人，而非诉诸情绪

第四步：分析思路说明

概述整理重构时对原文脉络的把握，以及归类的逻辑

说明要点提炼时的论点筛选标准、论据采撷原则

剖析反共识观点的提取依据，以及判断其价值的理路

总结贯穿以上三个步骤的分析思路，体现对原文的价值挖掘、升华

输出格式要求:

正文部分，以 "正文" 为标题

要点提炼部分，以 "核心要点" 为标题，各要点用 "要点 1"" 要点 2" 等加以标示

反共识观点部分，以 "反共识观点" 为标题，"观点 1"" 观点 2" 等加以标示

分析思路部分，以 "分析思路" 为标题

各部分之间用 markdown 语法分割，确保层次清晰、美观大方

其他要求:

输出内容需包含以上四部分，并按照 "输出格式要求" 指定的顺序排列

分析过程中如有任何不清晰或存疑之处，请勿擅自揣测，而应向我提问求证，以保证理解的准确无误

在正式输出之前，请对整个回答再通读一遍，检查是否有任何错别字、标点误用或者语病等，力求做到完美无瑕

在输出内容之后，请谈谈自己在这个分析过程中的心得体会，或对于其他创业者的一些建议。让答案更添几分真诚与温度。」

---

大家可以根据自己的需求试试，我试过很多篇播客，效果 sofar 都很稳定。

### 174

方军 2024/03/28

请容我吐槽，看了一晚上 AI 生成的文本 ，真心用不好的时候，生成的全是垃圾：

比如下面这个，可以说零信息：

\## 正文

该视频介绍了作者在使用 Anthropic 的 Claude 模型时，发现了一些有趣的资源和技巧。作者指出，不同的语言模型需要采用不同的提示方式 (prompting) 才能发挥最佳性能，这是一个普遍存在的挑战。Anthropic 为此提供了一系列指南和工具，帮助用户更好地掌握如何有效地提示和使用他们的模型。

\## 核心要点

要点 1：不同的语言模型在使用方式上存在差异，需要采用特定的提示方式才能发挥最佳性能。[1]

要点 2：Anthropic 为用户提供了丰富的资源，包括指南、工具等，帮助用户更好地掌握如何有效地提示和使用他们的模型。[1]

要点 3：作者认为，这种针对性的资源和指导对于提高语言模型的使用效率非常有帮助，值得其他模型开发商也效仿。[1]

\## 反共识观点

观点 1：作者指出，不同语言模型之间存在一些差异，需要采用不同的提示方式。这与一些人的认知存在一定差距，他们可能认为所有模型都应该使用相同的方式。但作者认为，这种差异实际上反映了不同模型的特点，需要根据具体情况进行调整。

观点 2：Anthropic 提供的资源和指导，体现了他们对用户体验的重视。这与一些人可能存在的观点相悖，即模型开发商只关注模型本身的性能，而忽视了用户使用体验的改善。但作者认为，Anthropic 的做法值得肯定，有助于推动语言模型的实际应用。

Citations:

[Anthropic's Meta Prompt: A Must-try! - YouTube](https://www.youtube.com/watch?v=Evg4HXvsYVY)

### 175

方军 2024/03/29

摘：以色列人工智能公司 AI21 Labs 推出开源语言模型 Jamba，上下文窗口 256k，基准测试表现见图 1。

不同于以往 LLM 主要采用 Transformer 架构，该模型是将 Mamba 与 Transformer 架构相结合。

传统 Transformer 架构具有内存占用大、推理速度随着上下文的增加而变慢的缺点，由卡内基梅隆大学和普林斯顿大学的研究人员提出的 Mamba 架构可以解决这两个问题。（图 2）

Jamba 由 Transformer、Mamba 和混合专家（MoE）层组成，可同时优化内存、吞吐量和性能。

Jamba 的 MoE 层允许它在推理时仅使用 52B 可用参数中的 12B 参数，其混合结构使这 12B 有效参数比同等规模的纯 Transformer 模型更高效。

此前虽然有人尝试过扩展 Mamba，但没有人将其扩展到超过 3B 参数的规模。Jamba 是第一个达到量产级规模的混合架构。

Jamba 的模型架构见图 3，效率方面见图 4。

### 176

方军 2024/03/28

试用了下 Google Gemini 1.5 Pro 的图像输入部分，效果还行，最基本的没问题的。

讲实话，以后这些基础的东西真心再也不需要人来费力气了，🔺人得干更高级的活了🔻。

所有人都真心处于一个幸运的时代，某些过去成本巨大的、现在成本降到近乎零。

### 177

方军 2024/03/29

觉得这是需要看的话题，可是，这篇真的信息量太低，比音频都低密度了

再次感叹，大众媒体和大众媒体的受众好惨

当然，我也意识到，大众接受不了高密度

摘（所有的其实就这句话）：今天 OpenAI 没做好不要紧，马上它就要做好了，因为它马上就要意识到应用平台、应用商店是多么重要了，能够给它提供推动的就是苹果公司。

[才俩月，GPT Store 就要烂尾了？连 OpenAI 都小瞧了它](https://mp.weixin.qq.com/s/wvwuk_F-s0Br48Rqx4xt4Q)

### 178

方军 2024/03/29

有意思的提示语模板

由 hyperwrite CEO Matt Shumer 编写，宝玉翻译：

翻译版：twitter.com/dotey/status/1773398767628161265

原版：twitter.com/mattshumer_/status/1773385952699789808

---

这是一段能帮你给代码生成单元测试的提示词，针对 Claude 3，但理论上来说可以适用于绝大部分模型。

分析一下这段提示词：

1. 借助 XML 标签，让文本提示词有了清晰的结构，能让大语言模型更好的理解你的指令。顺便说一下，Claude 3 对 XML 很友好，大部分高质量提示词的输出输出都是基于 XML 来组织的，现在我也经常借鉴这种技巧。

2. 有清晰的步骤，借助 CoT（链式思考 Chain of Though）的方式，让模型能按照一定的步骤来思考，每一步的结果又可以作为下一步的输入，得到高质量的输出结果。

- 首先，分析代码，弄清楚代码的作用、输入、输出及核心逻辑。这样可以保证不遗漏代码中的关键信息。

- 然后，列出一系列必要的测试用例，包括目的、输入、预期输出和测试类型。有了前面代码的分析，在写测试用例时就不容易漏掉关键的测试用例。

- 明确输出是表格的格式，确保输出的内容包含所有必须的信息

- 接着，为每个测试用例编写具体的测试代码，确保测试代码遵循准备、执行、验证的流程。有了前面的测试用例，就可以挨个写测试代码了，不会遗漏关键的测试代码。

- 明确要先写注释在写代码，这样其实相当于为每一段测试代码写好了单独的提示词。

- 对生成的结果进行复查，确保全面覆盖了所有场景。

- 最后，总结测试覆盖范围及通过这次测试计划活动获得的洞见。这一步其实可以省略，因为对模型来说已经意义不大，但是对于作者来说，可以帮助你更好的理解它为什么要生成这些测试用例。或许从中学到点东西。

3. 一开始就要说明指令的目标是什么，这样可以让模型更好的理解你的指令，生成更符合你预期的结果。

4. 至于一开始的角色设定，属于锦上添花，可以让生成结果时，更多的从语料库中挑选角色相关的内容。

这段提示词很好的展示了如何通过提示词来引导模型生成高质量的输出：

1. 你的指令要清晰，可以借助 XML 标签来组织你的指令。

2. 要充分利用 CoT，让模型按照一定的步骤来思考，每一步的结果又可以作为下一步的输入，得到高质量的输出结果。

3. 明确的输出格式，确保输出的内容按照你列的步骤执行，并且每一步都包含所有必须的信息。

\## 以下是完整的提示词：

\<prompt_explanation>
你作为一名专家级软件测试员，负责对指定的代码片段进行彻底测试。你的目标是创建一套全面的测试用例，通过这些用例执行代码，发现任何可能的漏洞或问题。

首先，细致地分析提供的代码。弄清楚它的作用、输入、输出及任何核心逻辑或运算。深入思考所有可能需要测试的不同场景和边缘案例。

然后，头脑风暴，列出一系列你认为必须的测试用例，以彻底验证代码的准确性。对于每一个测试用例，在表格中明确以下信息：

- 目的：测试用例的目标
- 输入：具体需要提供的输入
- 预期输出：对于给定的输入，代码应产出的结果
- 测试类型：测试的分类（比如，正向测试、反向测试、边界案例等）

在以表格形式详细列出所有测试用例之后，针对每个案例编写具体的测试代码。确保测试代码遵循以下流程：

1. 准备：设置必要的前置条件和输入
2. 执行：运行待测代码
3. 验证：确保实际输出与期望输出一致

对于每项测试，都应清晰注释说明测试的内容及其重要性。

完成所有单独测试用例的编写后，进行复查，确保它们全面覆盖了所有场景。思考是否还需要添加额外的测试以确保全面性。

最后，总结测试覆盖范围

及通过这次测试计划活动获得的洞见。

</prompt_explanation>

<response_format>
<code_analysis_section>

<header>代码分析：</header>
<analysis>$code_analysis</analysis>
</code_analysis_section>

<test_cases_section>

<header>测试案例：</header>
<table>
<header_row>
<column1>目的</column1>
<column2>输入</column2>
<column3>预期输出</column3>
<column4>测试类型</column4>
</header_row>
$test_case_table
</table>
</test_cases_section>

<test_code_section>

<header>测试代码：</header>
$test_code
</test_code_section>

<test_review_section>

<header>测试回顾：</header>
<review>$test_review</review>
</test_review_section>

<coverage_summary_section>

<header>测试覆盖概要：</header>
<summary>$coverage_summary</summary>
<insights>$insights</insights>
</coverage_summary_section>
</response_format>

以下是你需要为其生成测试用例的代码：
<code>
将你的代码粘贴于此
</code>

### 179

方军 2024/03/29

再次尝试 AI 图示解读，讲实话无敌了。

这次给的图我并不了解这个代码的实际运行，但我粗看基本上没啥问题，修正即可。

> 用中文解释这个，按专业的方式进行解读，要尽量详细​、准确：

源图片来源：gyro-contract-docs.vercel.app/architecture-interactions/minting-flow

⭕️ 比较有意思的是，链接的这个文档也是在 AI 工具（Lumentis）的辅助下生成的。

初步看起来，这个图也是由AI生成的。

Lumentis:

[hrishioa/lumentis: AI powered one-click comprehensive docs from transcripts and text.](https://github.com/hrishioa/lumentis)

关于这个链接文档的说明：

twitter.com/hrishioa/status/1773428602908086319

twitter.com/hrishioa/status/1772651749326946455

### 180

方军 2024/03/29

宝玉这个翻译工作流解释得很清楚：

有人问我为什么我那篇《Sora 初体验》(link1) 的翻译结果比他用科技文章翻译 (link2) 的结果好？

> 问：同样一篇文章，使用您的科技文章翻译 GPTs，意译的结果和您分享的，差距还是很明显。比如，Sora 那篇文章的第一句，原文：We have gained valuable feedback from the creative community, helping us to improve our model. 意译：我们从创意界获得了极其宝贵的反馈，这些反馈极大地助力了我们模型的改进工作。您的：我们从创意界得到了极具价值的反馈，这对我们模型的完善大有裨益。您是如何做到的？

link1: Sora：[Sora：初体验 [译] | 宝玉的分享](https://baoyu.io/translations/openai/sora-first-impressions)
link2: chat.openai.com/g/g-uBhKUJJTl-ke-ji-wen-zhang-fan-yi

回复：

其实我就是用科技文章翻译 GPT 翻译的，但是以下因素会影响翻译结果：

1. 模型本身的随机性会导致翻译结果有所不同，有时候很惊艳，有时候平平无奇！
2. 文本长度会影响翻译结果，每次让它翻译的少一点效果会好很多。
3. 事后必要的人工检查修改也是必要的。

比如你看截图，这篇文章我每次其实只是让它翻译了一小段，自然效果好很多。

### 181

方军 2024/03/29

3 月 21 日，中央广播电视总台正式制定出台了《中央广播电视总台人工智能使用规范（试行）》，这是我国首部媒体人工智能使用规范化标准。

### 182

方军 2024/03/29

[AI 重塑法律行业：为 80% 的工作带来 10x 提升](https://mp.weixin.qq.com/s/fmMuAcrSH9UH7svml4LlUg)

### 183

方军 2024/03/29

071 工作流不容易

最近分享了一些工作流。我个人工作效率应该是蛮高的，很多人以为我是靠工作流来达到这个效果的，其实不是了，工作流对我来说其实是个不熟悉的难题。

我个人的工作效率主要源自于两个方面：第一个的确是动作快，很多事情别人可能做很久，但我可以很短时间自然地做完。（当然，这源于我尽量不碰自己强优势范围之外的其他事。）

第二个是我选择的多数是集中型的，而非日常型的工作。很早很早前，我们一个技术团队和运营团队坐在一起。开始半年到一年，我们极忙，运营在等着我们（很抱歉当时开发太慢）。但上线后，我们基本上闲得很，而运营开始日复一日。

工程师们爱总结个人工作流，其实，工程师们很少做重复的工作。总结工作流只是他们的认知深处的惯性在起作用（因为他们的职责就是把工作流用代码固化下来），一件事哪怕他们只做一遍，也喜欢总结工作流。

实际上，工作流在运营群体中才是有用的：

- 他们要日复一日地重复某种动作；

- 如果总结工作流，他们可以提高效率；

- 总结工作流之后，可以引入新工具，大幅提升效率；

- 固化成代码，可以再次大幅提升效率。

可惜，必须得坦率地说，我对这样的任务真心不熟悉。即便看起来我是日复一日重复的，比如写这些星球里面的笔记，对我来讲不需要任何流程，打开写，写完提交，想起来再改改错字、表达，仅此而已。

对比而言，如果让我每天按照某种规则必须发微信公众号那样的发表性质的文章，我做不下来。

当然，并不是我说我不熟悉工作流，我可深入观察过很多工作流，然后把它们抽象成软件设计。我也蛮喜欢鼓励别人用 SOP 的，当然也帮人整理过，因为我觉得对于不能代码化的，SOP 就是解决之道。

现在 AI 时代来了，我们的这些老技能应该可以发挥作用的，又要去观察（也包括亲手帮人做几遍）了。

### 184

方军 2024/03/29

摘，合理的：索性再多说几句吧。

AI 既出，英语教育就只有一条可能的路线了：

一两年内，不带脑子、不抠琐碎、稀里糊涂、大刀阔斧地就能像母语一样，真正用起来。

只有这种路径，这种效率，才有存在的价值。

任何需要「带脑子」刻意学的，在单词语法发音上纠结的，都注定要被淘汰，时间问题而已。

那些东西只是语言的表皮和细节，根本不是语言能力的实质，越学越废，越在意越耽误正事。

学开车就直接上手开，建立体感开熟练就完了，研究发动机原理有啥必要啊。

### 185

方军 2024/03/29

最近一直被迫像吸二手烟一样听一个自动生成的图书朗读。

刚刚我发现这本有有声书，听了几分钟，人讲的好亲切。

这种感觉其实在 AI 文字方面也是有的。

### 186

方军 2024/03/30

摘，是这样：如果不自己动手画出来，在脑海中始终是一个具有千万种可能性的『模糊认知』，但 ai 会把这种『模糊认知』转变为清晰的结果，让人误以为「原来这就是我想要的效果」从而限制了本应该无限延伸的创作空间。其次是简单指令确实能让自己的想法诞生，但人类从创作中得不到成就感，最终会被 ai 消磨掉人类想象和创作的激情。据我观察下来很多创作者在接触了 ai 后也很少真正创作了。

补充，让人误以为「原来这就是我想要的效果」。

这是为什么我从另一个角度说有品味，所谓品味，就是知道有更好的，想要更好的，不会停止住追求。

方军：对创作者，AI 这种危险是存在的。AI 对干活的人比较有利。

2024-03-30 09:30

### 187

方军 2024/03/30

徐昊：回想前面与 ChatGPT 一起写代码的例子，我们的主要工作，从编码转变成为 LLM 提供足够多的上下文信息。虽然我们并不需要提供详细的编码指导，也不需要指定类库或编程语言的用法，但是对于功能需求、业务知识、架构决策、测试策略等关乎「生产代码」的重要信息，还是要依赖我们，才能准确地提供给 LLM。

我们的关注点从如何构造软件，变成了如何提取组织知识，让知识变成 LLM 能够理解的形式。因此，提示词工程（Prompting Engineering）的关键并不在提示词，而在如何组织其中的知识。

[开篇词｜知识工程：AI 时代的软件工程 - 徐昊·AI 时代的软件工程 - 极客时间](https://time.geekbang.org/column/article/757007)

### 188

方军 2024/03/30

AI 生成 PPT，真是能生成漂亮的垃圾，P（骗）P（骗）T（他）

如果不精心写内容，这种 PPT 有什么用处？零！

[AI Note-Taking for Marketing: Revolutionizing Meeting Efficiency](https://www.popai.pro/share.html?shareKey=d4886ea3bfaa065712a461b9574405c4d6d680012db8ca6e565b8497a0c85536&utm_source=presentationsharepage)

### 189

方军 2024/03/30

Magnific 还是很牛的，这次的风格变化效果不错

twitter.com/javilopen/status/1769700978553659795

### 190

方军 2024/03/30

【三层评估法则：快速迭代，系统优化 AI 产品】

- 构建语言模型产品的成功关键是快速迭代。必须具备评估质量、调试问题和改变系统行为的流程和工具。

- 评估系统有 3 个层次：单元测试、人工和模型评估、A/B 测试。单元测试成本最低，频率最高。

- 单元测试要包含特定功能的场景和通用场景，要不断根据新出现的错误更新。还要用语言模型生成测试用例。

- 日志记录对话是模型评估的先决条件。要使查看数据无障碍，构建特定领域的数据查看和标注工具。定期人工评估样本很重要。

- 可以用更强大的语言模型做自动评估。要跟踪模型和人工评价的相关性。自动评价也可以用于合成数据。

- A/B 测试确保 AI 产品驱动了预期的用户行为。当 AI 产品较成熟时再考虑。

- 评估系统为微调和调试解锁能力。大部分微调工作是收集高质量数据，评估系统已具备数据生成和整理引擎。

- 评估基础设施可重复使用于调试。可快速定位、复现错误，评估解决方案的效果。

点评：

- 作者基于多年从事语言模型相关工作的经验，指出鲁棒的评估系统对 AI 产品的成功至关重要，这一观点非常中肯和实用。

- 文章强调了快速迭代对 AI 成功的重要性，并提出了质量评估、问题调试等必备流程和工具，为 AI 产品开发提供了清晰的指导。

- 作者将评估分为三个层次：单元测试、模型和人工评估、A/B 测试，这种分层思路有助于系统地开展评估工作，提高评估的针对性和有效性。

- 对于第三层 A/B 测试，作者建议要谨慎对待，只有在产品足够成熟时才适合引入，这体现了作者对 AI 产品负责任开发的重视。

- 文章还提到了评估 AI 子组件 (如 RAG) 的重要性，这为进一步优化和改进 AI 系统提供了思路。

- 作者强调评估系统不仅能加速迭代，还能解锁微调和调试能力，从而大幅提升 AI 系统质量，这一观点具有启发性，值得 AI 从业者深思。

《Your AI Product Needs Evals - How to construct domain-specific LLM evaluation systems.》

[- Your AI Product Needs Evals](https://hamel.dev/blog/posts/evals/)

翻译：

[你的人工智能产品需要评估 - 如何评估 LLM 产品 | AIGC Weekly](https://quail.ink/op7418/p/e4bda0e79a84e4babae5b7a5e699bae883bde4baa7e59381e99c80e8a681e8af84e4bcb0-e5a682e4bd95e8af84e4bcb0llme4baa7e59381?continueFlag=1b82e3f66f0a040e2e4443f6c6232a67)

### 191

方军 2024/03/30

智谱这个案例集不错。

2『一下子原文件「20240330智谱商业化案例合集」。（2024-03-30）』

### 192

方军 2024/03/31




### 193

方军 2024/03/31




### 194

方军 2024/03/31




### 195

方军 2024/03/31




### 196

方军 2024/03/31




### 197

方军 2024/03/31





