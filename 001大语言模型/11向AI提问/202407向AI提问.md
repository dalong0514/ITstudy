### 01

方军 2024-07-01

摘：按照上下文提供 Personalize 是生成式 AI 一个很大的优势。可惜很多 AI 产品没有利用这个优势，产生了很多「看上去有用，但用起来好像对我没什么用」的产品。

是这样的：

- 即时性
- 针对性
- 个性化

当然，是建立在有知识、能推理之上的。

### 02

方军 2024-07-01

我最近总是强烈感觉落后了

各种 agent 用不起了，我还是 1）交互式 2）链式那种状态

所以 coze/dify 的 workflow 用不起了

langgraph 接触也不晚，但一样用不起了

---

试用了下 coze 的功能，有点明白了。

重点不是 Agent，也不是 LLM。而是它现在能提供的工具。当然，LLM 是很重要的，否则没法处理这些结果。

比方说以 Twitter 为例，其实现在普通人已经付不起 X/Twitter 的 API 费用的。

Coze 现阶段给了这样便利（更何况可以做到全程无代码）：

- 用 X/Twitter API 进行搜索

- 对搜索结果进行处理 / 整理

如果有 X/Twitter API，还可以

- 接着去自动回复，回复会 1）大幅度提高账户曝光，2）对客户问题进行即时回应

以上这个用途是要超过 LangChain / LangGraph 的，因为它还是要自己配工具。

当然，最终多半还是要自己编程，因为否则流程没法完全自动化。

### 03

方军 2024-07-02

搞笑：老板牌食神大模型

食神大模型的赋能，是一个连续多场景过程/跨设备协同和规划/多模态数据的感知、多模态的交互以及与多个设备的协同联动等多个层面的能力

[中国杀出全球首个烹饪大模型 - 智源社区](https://hub.baai.ac.cn/view/38175)

### 04

方军 2024-07-04

刚才试图挑战一下，发现即便借助 AI，这些宏观的内容还是看不懂啊。

我略有不明白，整个金融行业的读者是都很明白吗？

金融人士讲话真是天书一般，关键人家都懂。几个关系搞不明白，我想试着看看能不能借助 AI 搞明白。

民生证券：央行借债的「玄机」

财联社 APP07.01

民生证券陶川等发布研报指出，今天央行「介入」可能并非偶然。在当前金融防风险的政策框架下，股、债、汇市场可能均有各自的政策底，从近期市场表现来看，10 年期国债收益率 2.20%-2.30%、美元兑人民币汇率 7.3 依旧是重要的政策节点，后续需要警惕市场触及关键点位后引发的波动。

研报全文如下：

今天央行的买卖国债公布得有点快。时间上，央行少见地在盘中公布了「国债借入操作」，使人不由得想起上次盘中出手稳汇率（去年 9 月 11 日午间召开外汇自律机制会议 + 公布金融数据）。内容上，公开市场操作公告常驻的「为维护银行体系流动性合理充裕」被替换成了「为维护债券市场稳健运行」，央行调债市、稳利率的意图「呼之欲出」。

央行的这次快速出手也不意外。理论上央行借入国债后可能随时在公开市场卖出，以调节长期收益率，防范利率风险。这在近期的政策吹风已「有迹可循」：二季度以来，央行已通过例会、主管媒体及发布会多次向市场提示长端利率风险，如 5 月 30 日《金融时报》称「人民银行应该会在必要时卖出国债」。从今天的市场走势来看，2.20% 的 10 年期国债利率可能是央行的政策合意下限。

新提的「国债借入操作」，在历史上并非主流。央行在公开市场上卖出国债理论上有两种途径，一是通过正回购、二是现券卖出，两者多出现于 2000-2014 年。而本次央行的「国债借入操作」表述与以上两种不同，我们认为机制上可能有两项经验值得参考：

一是日央行 YCC 的下沿情景。即长期债券收益率触及利率下限时，央行可以大量卖出国债，影响债券二级市场供求关系，推升利率。不过在日本长期超宽松的货币政策背景下，触发 YCC 下沿后日央行卖出国债的案例并不多。

二是我国央行此前的「稳汇率」式操作。历史上我国央行曾在远期市场上借入美元，并在即期市场卖出美元，释放外币流动性，对冲人民币贬值压力。「先借再卖」的操作逻辑上可能与本次「国债借入」相似。

不过就本次而言，信号意义可能大于实质。以日本为例，央行需要通过相当规模的国债买卖，才能实现调控市场利率，2023 年末日央行在国债持有者结构中占比 48%，而中国央行仅为 5%，卖出国债对市场供需的影响有限。我们认为央行后续不太可能走「日本化」的赤字扩张 + 大量购债的路径，而是趋近于此前的「介入式」稳汇率操作，因此纠偏市场的信号意图更多。

需要注意的是今天央行「介入」可能并非偶然。在当前金融防风险的政策框架下，股、债、汇市场可能均有各自的政策底，从近期市场表现来看，10 年期国债收益率 2.20%-2.30%、美元兑人民币汇率 7.3 依旧是重要的政策节点，后续需要警惕市场触及关键点位后引发的波动。

民生证券：央行借债的「玄机」_手机新浪网

阵雨：金总能科普下中国央行借债吗？

Herman Jin： 很简单，说明在经济通缩情况下，「他们」不考虑如何增加流动性缓解债滚债，解决债务叠加越欠越多的问题

相反他们担心银行靠投资国债赚钱，会压低利率，让潘行长守汇率努力付之东流。他们要搞做空机制，去升息！

通缩时升息是何等牛 B 之举

---

从这篇文章看，央行借债，是为了卖出压低利率，还是提高利率？

---

从研报的分析来看，央行的这次操作更多是释放信号，表明央行关注市场利率的稳定，并可能在必要时通过卖出国债来调控市场利率。研报中提到的 2.20% 的 10 年期国债利率可能是央行的政策合意下限，意味着央行可能不希望看到利率进一步下降。

总的来说，央行借债的目的可能是为了通过后续的卖出操作来提高市场利率，以维护债券市场的稳定和防范利率风险，同时也可能是为了稳定汇率。然而，研报也指出，央行的这次操作可能更多是信号意义上的，实际影响可能有限，因为中国央行持有的国债规模相对较小。

---

为什么卖出能提高利率

---

卖出国债以提高利率的机制可以从以下几个方面来理解：

1. 供求关系：当央行卖出国债时，市场上的国债供应量增加。如果市场上对国债的需求保持不变或减少，供过于求的情况将导致国债价格下降。由于债券价格和收益率呈反向关系，国债价格下降时，其收益率（即利率）会上升。

2. 预期变化：央行的卖出行为可能会改变市场对利率的预期。市场参与者可能会认为央行希望通过提高长期利率来抑制经济过热或控制通胀，因此他们可能会提高对未来利率的预期，进而推高当前的利率水平。

3. 流动性吸收：央行卖出国债会从市场吸收流动性。购买国债的投资者需要支付现金，这减少了市场上可用于其他投资的资金量，从而提高了资金的成本，也就是利率。

4. 风险溢价调整：央行卖出国债可能会被市场解读为对当前利率水平的不满，这可能导致投资者要求更高的风险溢价来持有国债，从而推高了国债的收益率。

5. 政策信号：央行的行为通常被视为政策信号。当央行卖出国债时，市场可能会认为这是紧缩货币政策的信号，即央行希望减少货币供应，控制信贷增长，这通常与提高利率的政策目标相符。

6. 长期利率影响：央行通过卖出长期国债，直接影响长期利率。长期利率的提高可以抑制长期投资和消费，有助于遏制经济过热和控制通胀。

总的来说，央行卖出国债是一种通过影响市场供求关系、市场预期、流动性状况以及风险溢价来提高利率的手段，是货币政策调控的一部分。

---

早上起来跟 AI 聊了一会儿，用 AI 不懂就问学习蛮有意思

我学到的大概逻辑上（不准确，是我自己的学习过程产物，仅是记录）：

1. 基本情况：一国发行国债，通常是财政部发行，通常通过一级经纪商。央行或 Fed 可以在二级市场购买与卖出。

2. 本次所谓国债借入操作，是央行向一级经纪商借。借了之后，就可以进行所谓的「卖空」。

3. 「卖空」操作，将会压低国债的价格，这带来的效果，就是国债的收益率提高。（目前看，就是维持收益率在 2.2% 这个水准以上。）

4. 国债收益率提高，就相当于「升息」。（这会增加对外资的吸引力，从而维持人民币的汇率。）

5. 同时，卖出国债，就是央行在收回现金，那其实就是减少货币流动性。

6. 这大概是为什么那位专家批央行操作的原因，因为他认为现在是经济紧缩，应该投放货币，降息。—— 但好像他给的是单链条，没有多链条。

### 05

方军 2024-07-04

对这个真的有很大疑虑啊，不行啊这么用！

[How to Use ChatGPT for Scientific Research Paper writing? - Dr Asma Jabeen](https://drasmajabeen.com/chatgpt-for-scientific-research-paper-writing/)

转译：《如何使用 ChatGPT 撰写科学研究论文？- Dr Asma Jabeen》

ChatGPT 是一种 AI 语言模型，可以根据用户提供的输入生成文本。它可以作为一种工具，帮助撰写科学研究论文。撰写科学研究论文不仅需要对主题的深入了解，还需要批判性思维、解决问题的能力、分析和数据解释技能。因此，使用 ChatGPT 时，应将其与您的专业知识、经验和技能相结合。

本文将讨论使用 ChatGPT 撰写科学研究论文的 9 个重要步骤。

1. 收集研究材

在使用 ChatGPT 之前，您需要收集和整理撰写科学研究论文所需的所有研究材料，包括文章、书籍、期刊以及其他计划使用的资料。

2. 与 ChatGPT 进行头脑风暴

使用 ChatGPT 对研究主题进行不同角度的头脑风暴，并据此编写最终版本。

3. 确定研究问题

确定您在研究论文中要解决的研究问题或假设。

4. 进行文献综述

使用 ChatGPT 搜索与研究主题相关的科学文献，突出显示并指定与研究问题和假设相关的文献。

5. 总结重要的研究文章

利用 ChatGPT 总结您标注的研究文章的关键内容。

6. 识别文献中的研究空白

通过 ChatGPT 进行头脑风暴，找出文献中的研究空白。

7. 分析数据

对通过调查或其他方式收集的数据进行分析，然后使用 ChatGPT 帮助解释数据并生成支持您发现的可视化图表。

8. 创建研究论文的提纲

使用 ChatGPT 组织您的研究论文，创建提纲并逻辑地结构化您的论点。使用 ChatGPT 生成论文的各个部分，如引言、方法、结果和讨论部分，但务必仔细审查其生成的内容。

9. 编辑和校对您的论文

使用 ChatGPT 编辑和校对论文的语法、标点和拼写错误，但请仔细检查和审阅，以确保内容的流畅、准确、清晰和研究的真实性。

按照上述 9 个步骤，您可以使用 ChatGPT 撰写研究论文。

关于使用 ChatGPT 撰写科学研究论文的 4 个事实

1. ChatGPT 无法独立完成科学研究论文的写作。科学知识、人类专业知识、批判性思维和分析能力对于论文写作至关重要。ChatGPT 可以作为一个生成内容的助手。

2. ChatGPT 是研究辅助工具，但不能取代人类研究人员。

3. ChatGPT 可以协助进行数据分析和解释，但仍需人类输入以确保数据的准确性。

4. ChatGPT 生成的内容可能存在错误，因此审查其生成的内容以确保准确性非常重要。

### 06

方军 2024-07-04

有时候我想，我这个星球没吸引到很多人，除了主要是我只是在产出，没有形成产品之外，可能还有一个原因

我只想说 learning，但绝大多数人只要 knowing，你告诉我。

可是，在 AI 这个地方，我告诉不了谁什么。只有一起去 learning。

### 07

方军 2024-07-04

又试了试 elevenlabs 的语音

中文还是一如既往的糟糕

实际上有时候我想，是不是它的英文效果也不行

只不过我们这些人的英语不够好，所以不那么敏感？

什么是好、不好、很好，

的确只有自己最专业的领域才能判断

### 08

方军 2024-07-04

101 AI 草台班子假设

1、草台班子理论的践行者是埃隆·马斯克。

虽然有人说他的核心理念是「第一性原理」，但在我看来，他基本上把世界看成一个草台班子。那么，既然是世界是个草台班子，那我就从头做起，这就是所谓第一性原型，从头开始重做。

他做火箭是这么做的，做特斯拉电动汽车也是这么做的。

等他接管 Twitter 时，他也是这么做的，更加暴力一些：别管现在的业务架构、技术架构是什么样，按我说的来。别管服务器和计算中心是什么样，直接搬上开车运走。

2、草台班子假设是有基本道理的。

草台班子假设的背后是，一个事物必然会越来越复杂，包含越来越多无效的部分（也许这就是有人说的「熵增」）。软件开发里面有个做法是「重构」，梳理、简化、修补，经常是必要的。

草台班子假设有道理还在于，现实世界的事物不只是由无生命的物体组成，还由人组成。在庞大的事物中，人会变得比无生命的物体更不可靠，人往往会认为规定、结构就是对的，但事实恰好相反。

这个时候，为了对抗这种倾向，我们不得不：1）增加更多的检查点（SOP）；2）希望找到富有责任心的人（信任）。

但最终极的，还是我们要有「草台班子假设」，因此，对应地，自己为自己负责，自己去验证。也就是我们常说的，不要信任，要验证（Don't trust，verify）。

题外话：以前我们还说过一个老板的优点（有些人当成缺点）：他会持续地搅动，不让自己的组织陷入静态，没人能感到安定。

3、AI 草台班子假设。

所谓 AI 草台班子假设是，AI 在无生命和有生命的部分，都让草台班子的内部更加杂乱。

比方一个小例子，别人给我一份看似逻辑清晰、文字规范的报告，要不要验证呢？在社交媒体上，我们尚能保持警惕。但我们可能会对一份格式规范的报告放松警惕。就我个人而言，我现在尤其警惕。

在 AI 兴起之后，解决之道依然不变，不要信任，要验证（Don't trust，verify）。

同时，这个世界中原本可信的结构、原本可信的人，将都变得更为珍贵。

总而言之，如果假设世界是草台班子，那么，在这个世界中的生存方式是，不是自己也在其中混，而是始终做到自己去验证，我是最后一道自己的最后一道防线。

### 09

方军 2024-07-05

有朋友说：

苏黎世是我去过的城市当中唯一一个能让我承认比墨尔本更舒服的地方。

这个中文句子真别扭，有人能改写得更顺溜一点吗？

我试着改了一个：哈哈哈，手工试着帮您改一个：

在我去过的城市当中，苏黎世是唯一能让我承认比墨尔本更舒服的地方。

AI 的修改都不好，以下是一些快速试验：

---（提示语）

你的任务是将句子改成地道的中文表达：

苏黎世是我去过的城市当中唯一一个能让我承认比墨尔本更舒服的地方。

给三个选项：

---

Kimi（很差，极其糟糕的语文）：

1. 苏黎世是唯一一个让我心服口服，觉得比墨尔本更宜人的城市。

2. 在我踏足的众多城市中，只有苏黎世让我不得不承认它比墨尔本更加舒适。

3. 苏黎世是唯一一座让我心甘情愿承认，比墨尔本更让人心旷神怡的城市。

（心服口服、踏足、心甘情愿、心旷神怡都是莫名其妙的词汇）

ChatGPT3.5（好一点，但还是很差）

1. 在我去过的所有城市中，只有苏黎世让我觉得比墨尔本更舒适。

2. 苏黎世是我去过的城市里唯一一个比墨尔本更让我感到舒适的地方。

3. 在我游历的城市中，只有苏黎世能让我承认它比墨尔本更舒服。

GPT4（GPT 不知道为什么非要把舒服改成舒适）

1. 在我去过的所有城市中，苏黎世是唯一一个我认为比墨尔本更舒适的地方。

2. 我去过的城市里，只有苏黎世让我感觉比墨尔本还要舒服。

3. 在我所有旅行的城市中，只有苏黎世让我觉得比墨尔本更舒适。

也许从语法上应该选用这句话：

- 2. 我去过的城市里，只有苏黎世让我感觉比墨尔本还要舒服。

但我觉得我那个手工改法比较符合原作者的口头表达。

- 在我去过的城市当中，苏黎世是唯一能让我承认比墨尔本更舒服的地方。

- 在去过的城市中，苏黎世是唯一能让我承认比墨尔本更舒服的地方。

下面还做了一个有意思的尝试（注意，以下这些不一定就是这些作家写的，没有查证，可能仅仅是模仿他们的风格）：

Prompt：苏黎世是我去过的城市当中唯一一个能让我承认比墨尔本更舒服的地方。// 找出优秀作家的类似句子，十个：

以下是十个优秀作家的类似句子，其中他们表达了对某个城市或地方的喜爱和比较：

1.「巴黎是一场盛宴，无论你什么时候去，它总是在那里。」— 欧内斯特·海明威

2.「维也纳，这个城市留给我的记忆，只能用一个词语来形容：永恒。」— 斯特凡·茨威格

3.「当你站在伦敦的泰晤士河岸边，你会觉得，这里就是世界的中心。」— 亨利·詹姆斯

4.「没有哪一座城市，可以像圣彼得堡那样，既诗意又充满历史的厚重感。」— 费奥多尔·陀思妥耶夫斯基

5.「威尼斯这个地方，仿佛只有梦里才能看见的样子。」— 亨利·詹姆斯

6.「布拉格是个谜，每一条街道，每一个广场，都是一首静默的诗。」— 弗朗茨·卡夫卡

7.「柏林是一座让人充满希望与无限创意的城市，它年轻且充满活力。」— 克里斯托弗·伊舍伍德

8.「当我第一眼看到京都的寺庙，我就知道，这里将是我心灵的归宿。」— 川端康成

9.「在罗马，只要你睁开眼睛，历史就在每一个角落跳动。」— 维吉尔

10.「纽约是一个不眠之城，它的繁华和喧嚣让人无法抗拒。」— 斯科特·菲茨杰拉德

方军：AI 的能力，这就是现状。我是可以用工作流把几步串起来达成更好的效果，但基础就是这样。准确看待 AI 的能力可以更好地用它。

2024-07-05 09:52

方军：我现在对 AI 的英语也没信心，主要源于我对自己的英语没信心，因此不能判断 AI 写作的好坏。

比方说，我会明显感觉 AI 编写的技术文档不如人写的，这个我看得多。互联网商业书我应该也能大概看出来。

又比方说，我最近看哈利波特，我能看到罗琳的英语的特别，AI 写不出来。

但我整体上对自己的英语没信心，我觉得可能还行的，也许只是英语母语者中学的水平。

2024-07-05 09:55

Hestia：ChatGPT，提示词「两个短句」，给改成了「苏黎世是我去过的城市中最舒适的。它甚至比墨尔本还要令人满意。」偷笑

2024-07-05 11:11

方军回复 Hestia：两个短句蛮好。不过，它改的结果不行，不像中文。

2024-07-05 11:20

Hestia：是的，它大意理解得没错。不知道背后运行逻辑，看起来像是提取了核心信息，转写成两个英文句子（或一个主句一个从句），然后翻译成中文。

2024-07-05 11:36

方军回复 Hestia：意思还是略有偏差，令人满意，和，让我满意，有着显著区别。

这是我手工改的时候，尽量不改这个部分的理由。

2024-07-05 11:42

### 10

方军 2024-07-05

这是一个有意思的体会：摘：豆包：从用户模糊描述中读懂真实需求的贴心助手

龙爪槐守望者：普通用户很难清晰描述自己的真正需求，所以才有「用户想要一匹更快的马却给他一辆车」这句经典的需求分析名言。普通用户和 AI 对话更能体现这一点。

当我命令豆包把一段文字总结出一个标题时，豆包却意外给了 5 个标题供我挑选，真正满足了我想要最好的标题的的真实需求。非常贴心。

### 11

方军 2024-07-05

一个还不错的梳理

[腾讯发布大模型时代的 AI 十大趋势：走进「机器外脑」时代](https://mp.weixin.qq.com/s/pI9UCpcBq6TqDovw-ZORPg)

### 12

方军 2024-07-05

摘：最近陆续看到几个人推荐 kimi 分析文档，丢进去了一个 60 页的文档，也是胡编的飞起。还是老老实实一页页看吧.

很多人其实都还没吃过这方面的苦

这是我为什么说现在尤其需要可靠性

我现在遇到提供不可靠信息的机构或个人，直接 mute

聪明悦读：方老师，是否用过 coze 在，我使用时，发现配好知识库文件，但是回答问题依然是错的，不知道咋回事儿

2024-07-05 19:15

方军回复聪明悦读：你试着提示语让它给出对应的片段看看

2024-07-05 21:21

方军回复聪明悦读：记得你可以看到它的 rag 过程，你点开看看，看看过程对不对

2024-07-05 21:24

### 13

方军 2024-07-05

摘：感觉上 agent 这个词在国内 AI 圈已经被滥用了，而且不止一次看到有人把 dify 定义为 agent 平台，显然不是，agent 只是 dify 上可编排出的其中一种应用形态，而像 superAGI 这类的产品才是。

滥用也许是因为叫 agent 更性感更有故事性，肯定比叫 chatbot，workflow 性感多了。

我觉得对于 agent 的定义至少要包含三个要素：由 LLM 驱动，自主工具调用，依赖于记忆的反思和多轮迭代，这三个要素缺一个都不算。

L.Path：最近在读论文，反思这块儿真是越看越有趣

2024-07-06 00:29

方军回复 L.Path：是的，在分步 COT 之后，下一个推理能力的应用应该就是反思

2024-07-06 00:41

### 14

方军 2024-07-05

大众爱讨论的东西都特别无聊，我也不想吸引大众

比如，AI 来了，要不要学英语

比如，AI 来了，学 CS 专业还是好选择吗

比如，AI 要取代程序员了

好无聊，哈哈

如果愿意讨论，我能正面也说晕，反面也说晕，选正与反你自己定，哈哈哈哈

### 15

方军 2024-07-05

宝玉展示的翻译差异，真是差别很大啊：

我（宝玉）今天翻译这字幕的时候，先用的 GPT-4o，中规中矩，后来试了下 Claude 3.5 Sonnet，要好很多。

GPT 4o 翻译结果：

我最近一直在思考过渡期的问题。 精神领袖Ram Dass有一个关于两波浪潮在海洋中前行的精彩故事，一大一小。当波浪接近陆地时，大浪看到了即将发生的事情。 它看到所有前面的波浪都在冲向岸边并被摧毁，于是忧心忡忡地对小浪说：“末日要来了！” 但小浪只是微笑着说：“别担心，我们会没事的。” 大浪坚持道：“你不明白，我们完了。”而小浪则完全平静地说：“不，我们没事。” “我可以用六个字来解释。你不是浪，你是水。”

Claude 3.5 Sonnet 翻译结果：

最近，我一直在思考人生的转变。这让我想起心灵导师拉姆·达斯曾经讲过一个发人深省的故事。故事是这样的：
海洋中有两朵浪花，一大一小，正朝着岸边涌去。眼看离岸越来越近，大浪忽然意识到了即将发生的事。它看到前方的浪花一个接一个拍打在岸边，瞬间消失不见。
大浪顿时慌了神，对小浪喊道："完了完了，我们就要到头了！"
小浪却笑眯眯地说："别担心，我们不会有事的。"
大浪急了："你不明白啊！我们马上就要消失了！"
小浪依然淡定自若，说道："不会的。我用六个字就能告诉你为什么。"
"什么意思？"大浪疑惑地问。
小浪答道："你本非浪，乃是水。"

原始英文：

I've been thinking a lot lately about transitions. The spiritual leader, Ram Dass, had a wonderful teaching about two wavestraveling through the ocean, one big and one small, and as the waves get closer to the land, the big wave sees what's about to happen. They see all the waves ahead of themare just crashing onto the shoreand devastated the big wave says to the small wave, he warns them the end is near. And the small wave just smiles and says, don't worry, we'll be fine. You don't understand the big wave insists, we're done for, and the smaller wave is just totally calmand says, no, we're not. And I can explain why in just six words.   You're not a wave, you're water.

### 16

方军 2024-07-07

摘：2023 年 chatgpt-3.5 问世的时候， 我很认真的阅读了 openai 的官方文档， 半年后， 我发现大部分关于生成式 ai 的课程还没有官方文档写的好。

因此， 我觉得如果是认真对待学习这件事的人， 应该第一时间去学习官方提供的资料。然后再去看看其他人的二手、三手的资料。

### 17

方军 2024-07-07

有人说是英文的问题，这是一部分。

我也看过各种官方文档，我的感受也是如此。

网络资料 / 教程往往只有单点，不够全面。

网络通俗视频教程，往往废话太多，因为视频教程大多假设受众不懂。

图书资料，一言难尽，图书为了凑厚度往往拼凑太多。

还有一个原因，所有这些资料里，只有官方文档是「活」的。

### 18

方军 2024-07-07

看到几个人在讨论 workflow 与 agent

（我只想补充一句，它们都必须要某种实际的场景、领域结合，潜台词，它不可能是巨大规模的公司）

A：当前阶段不看好任何试图 agent 落地产品化的行为。

workflow 玩出花了也还停留在刀耕火种的早期阶段 ，何况 workflow 的上层 agent。

估计会挨喷，假如有就来，准备好对喷了。

不过更大的可能是没有，因为当前阶段的 agent 有多菜，多么难落地，你们比我还清楚……

我觉得严格点说，我会认为，我们短期内显然达不到 agi ，但从生产角度来说，我们会有很多越来越强大的 workflow，并且它会成长为像传统软件工程一样强大甚至更复杂的工程形态。

这其中会看到一点所谓 agent 的影子，但说到底，就是强化的 workflow。

正如一年多前 LLM 带给我们的惊喜一样，不是因为它能鹦鹉学舌，而是它真的涌现出了一些东西。

agent 需要的也是这种「涌现」，另一个层面上的，只靠编排，编不出来能用的 agent。

最大的错觉就是我用传统软件开发的方式可以组合出一个 agent，但那只可能是一个工作流，离自主判断差太远了。

B：这个东东确实不可靠，我算是在 ToG 领域，反正能忽悠甲方，先卖了再说，不能要求太多，

底层技术上很多问题还没解决，甚至解决不了，不然全球也不至于没出现真正爆款的革命性应用。

每个单独的 agent 能有独特的「涌现」，很有想象力，要么是依靠上下文了，要么是类似于微调了，那么用既有上下文对话来微调

C：我相信 workflow 或者 agent 这个环节应该有一个万亿市值的公司出现。

这是对现实生产关系的影射环节，处理现实世界的各方的利益关系，不是一个 ChatGPT 简单就能做的。OpenAI 没有能力做这个。

D：我也更相信那些原来就在持续解决这些问题的公司，利用 AI 能把现实世界里的问题解决的更好。

### 19

方军 2024-07-07

有意思的类比，摘：最近一个博主启发了我，说现在的 AI 芯片疯狂是万丈高楼的底层砖石。

他意思说参照 2000 的泡沫，当时都在憧憬 .com 经济，最火红的却是 CISCO 网络硬件公司。直到应用数据服务器的大规模建成后，.com 经济才因此红火。然后才有谷歌，META、NETFLEX、APPL 这样的应用软件公司的 booming。

如果历史重演，那么随着 AI 芯片数据服务器的底层设施的建立，我们会遇见到 AI 应用服务产业未来多个巨无霸公司的诞生和世界进入新的时代。

乐观的说， 以 AI 为基础重新构建的未来世界现在还在打底层基础的阶段。未来的大格局不可想象。

### 20

方军 2024-07-08

看到陈仲凯这段话：这么多年过去了，我看了文献也不少了，有一点是从未改变过：老师们设计的教学内容，常常不是学生们学到的内容。

我觉得课堂讨论是必须的，不是那种漫无目的的聊天，而是让学生说出来他们对于某一段话的理解，然后老师就会发现「千奇百怪」的问题，而那些问题才是学生特有的学习内容。

我想到的是： ​​​我们也许应该颠倒 AI 的用法，采用「翻转课堂」的用法。

- 我们不是问 AI ，让它给我们答案。

- 我们应该尽量自己回答，请 AI 来评论、修正。

- 这很不容易，因为我们第一反应是去试图得到 AI 的回答。这也最省力。

- 但我们应该努力的纠正过来。我们提出一个问题，然后别让 AI 回答，而是自己先回答。

他同一天还写了另一个关于教学的，并不直接相关，但也可以列这里：

教师之间的区别，未必是领域中知识点的专业性（那是发论文），而是对于学生的学习节奏的敏感把握（那是教学法）。

这几天我试了两个教练。其中一个还蛮专业的，迅速设计降级动作，协助我完成腿部练习。另一位，也有一些动作设计，但是问题来了：没有组间歇。我之前看到他的客户评论提到过他的组间歇很短，但经过我实际体验之后，我完全可以使用「没有组间歇」来形容。练完第一组立刻第二组（如果你说间隔五到八秒也是间隔的话）。

当我力竭了，还在那里怼着我继续做动作，我可以用精神奔溃甚至生气来形容了。怎么说我也是一个健身老手了，四年多都是私教课一路高强度训练过来。我对自己也是一个有要求的人。

这个事给我带来的观察视角是：新教师和老教师，的隐藏区别，往往不是知识点掌握的多与少，而是对于人类的大脑认知规律的把握。具体来说，新教师往往拿着知识点硬灌、高强度、甚至没有分级动作。（我在当新教师的时候大概率也是如此）

这解释了为何本文中提到的两位教练，第一位要收费试学、而第二位是免费试学并切还不被我认可，的原因了。

### 21

方军 2024-07-08

102 AI 的基础设施正在发生变化

我不是一个典型的 AI 应用程序员，多数只是在应用里调用模型提供方的 API，除非试验很少去用云服务的模型服务。典型的 AI 应用程序员应该多数是在用云服务的模型 API，甚至在微调模型。

今天看了阿里云（百炼）、字节火山引擎的相关服务，突然发现，AI 模型的基础设施已经发生很大的变化。之前我试用过百度千帆和微软 Azure，亚马逊 AWS 因为一些原因还没试过。

对很多人来说，AI 的基础设施是这样的：

模型  —— 通用应用

OpenAI GPT —— ChatGPT

Moonshot  —— Kimi

对很多 AI 应用开发者来说，AI 基础设施是这样的：

模型  —— 专用应用

OpenAI GPT —— 自己的应用

但也有人很多人转向了云服务，尤其像千问、文心等云服务的模型都只提供云服务模式：

云服务（运行模型） —— 专用应用

Azure  —— 自己的应用

百度千帆 —— 自己的应用

熟悉 Coze、Dify 等编排平台的都知道，其实它们为模型加上了一个模型应用层次。

模型（模型 API 或云 API）—— 模型应用 —— 通用对话界面

这个层次里面通常提供的是：RAG、搜索工具及其他工具。

实际上，我今天看到的阿里云百炼、字节火山引擎，都已经把模型应用这个层次加进去了。

也就说，现在的架构是：

模型（模型 API 或云 API）—— （云服务提供的）模型应用 —— 自己的应用

总结起来，现在大模型的应用层次大概是这样的：

模型 - 云服务 - 模型应用 - 通用应用 - 专用应用

额外地，各家云服务通常都提供了模型微调的服务。

不过，考虑到目前大模型的能力局限性，实际上这个过程复杂化（特别是增加模型应用这个层次），实际上是自找麻烦。原因是，你怎么判断最终输出是高质量的？

因此，多半还是最简单的基础设施架构：

模型 - 专用应用

在专用应用内部进行工作流（链式）编排，并把控质量。

以上是我目前的理解。

### 22

方军 2024-07-08

[从 AI 高管到犀利 CEO，贾扬清创业这一年：我们的目标是做 AI 时代的「第一朵云」](https://mp.weixin.qq.com/s/p5-1Cmvl96GzI-ZykIc3FA)

### 23

方军 2024-07-08

再看雅思作文修改，真棒啊。

目前已经修改了 11 万篇雅思作文了。

[免费雅思作文评分批改 Check IELTS essay for free | ielts9.me](https://www.ielts9.me/)

### 24

方军 2024-07-08

103 不要过于追求自动化

AI 来了之后，很多人试图这样做：让 AI 能够全流程完成一项任务。

过去，普通人是不敢有这样的想法的，因为要全流程自动化，过去必然会涉及到一些编程。现在，各种工具的普及（比如 RPA）和 AI 让这有了可能。

但这种自动化可能是错的。以程序员的经验来看，程序员固然是最易于「过早优化、过度优化」的群体，但程序员的「懒惰」往往也会对抗它：

如果一个投入、产出不合理，程序员会自然地选择懒惰，从而规避过早优化的风险。

当然，有时候我也觉得，普通人连最基本的自动化都不做，的确有点可惜。比如，很早前我看人调整时间表 Rundown，计算每个时间间隔。我就帮他们做了一个简单的 Excel 模板，写上开始时间，然后填写每个任务的时间分钟，就自然地有了下面各个时段的起止时间。

但是，如果因为自动化很容易，就开始花时间在自动化上，这可能是错的。AI 来了之后，这样的错误会很多。

比方说，要把 50 个文件分别拷贝、整理。我觉得几个层次都是可以的：

- 逐一导出、拷贝

- 命令行处理

- 编写程序细致处理

第三步的自动化不是必须的，因为人本来就应该介入，非要自动化，反而让这个本应有人介入的状态变糟了。—— 至于说，这个任务是交给别人做，还是自己做呢？我其实现在越来越倾向于自己做，偶尔干点这样的事，真没什么，就当劳逸结合。

至于把实际上根本不能自动化的任务交给 AI ，则可能带来更大的潜在麻烦。

比方说， AI 是可以校对，但是，AI 校对可以自动化吗？我现在越来越倾向于，不要自动化。理由很简单，如果直接修改进去了，其中假若有错，根本无法识别。固然，在有人协助校对时，我们会统一接受，然后通读以当前文本为基础。但如果统一接受 AI 的修订，风险要大得多。实际上，在由人进行修订时，我一般也很少会直接接受所有修订，多半还是会自己看，因为这样一方面可以校准，一方面又会促进我们进去看细节，发现问题、调整新发现的问题。

（备注：这篇所讨论的是一个困扰我的一个问题，不过感觉没说太清楚，等有机会再仔细想。）

### 25

方军 2024-07-09

看了看一个老师编写的 208 首中学诗词（后来发现他收录的不全，教材似乎还要多一些），一个感慨是，其实我们绝大多数人的古诗文修养也就是中小学阶段曾经学到的这些。

普通人有这些修养也够，可以算个有基础中国文化的人。我发现，现在我们的确可以靠 AI 去解释，它解释得不好，但可以让我们读懂。这么多整体读下来，还是白居易这种浅白的符合普通人认知，让人感受到美。

大林寺桃花

【唐】白居易

人间四月芳菲尽，山寺桃花始盛开。

长恨春归无觅处，不知转入此中来。

另外，如果是有心人，围绕这些诗歌，去看各种地理、历史，也是一个很不错的线索。我现在觉得，有常识，有线索，然后能借助工具，人在这个时代不会是无知的。

近日看一个电视剧，其实早年上学期间我们是仔细学过的，用它学英语口语。当年也有搜索，但不是很方便。现在，发现各种不懂的问 AI 就快速很多，刚刚就去看了它的主题曲里面的一些细节，作为一个文艺盲，我的确不知道 Chorus 在一首歌曲里面是什么意思。

### 26

方军 2024-07-09

王树义老师推荐的 Fabric 用来做工作流太棒了，刚刚王老师文章中的做法都试用了，太赞！

它基本上就是 LangChain，但 LangChain 毕竟是给程序员开发应用用的，而 Fabric 就是一个命令行工具，可直接用。有编程基础最好，但只要理解 Linux 管道操作符就可以了（LangChain 也有这个）。

[danielmiessler/fabric：fabric is an open-source framework for augmenting humans using AI. It provides a modular framework for solving specific problems using a crowdsourced set of AI prompts that can be used anywhere.](https://github.com/danielmiessler/fabric)

作者的视频（2024.2）：

https://danielmiessler.com/p/fabric-origin-story

王老师写了好几篇文章，非常详尽（需要加入王老师星球才能阅读）：

[如何用 AI 工作流实现高质量长文翻译？](https://articles.zsxq.com/id_xdxgwpdwlfqt.html)

[如何用 Claude 3.5 Sonnet 与 AI 工作流自动撰写博客？](https://articles.zsxq.com/id_ka74k39bqwba.html)

[用 fabric 集成工作流从音视频直出文章，效果如何？](https://articles.zsxq.com/id_plt60xicmx11.html)

[如何用命令行方式便捷组合调用 AI 工作流？](https://articles.zsxq.com/id_e90fcl6z3hva.html)

Fabric 非常符合我的需要，我用起来之后，也准备写几篇教程介绍介绍它。

另外，王树义老师使用的 OpenRouter 也很赞，提供多种模型，同时都转换为 OpenAI 的 API 格式。我终于找到一个可以使用 Claude 模型的地方。

王老师在星球中回答问题，对方提到用 Dify 等可视化工作流编排，他回答中有句话特别棒：

> 命令行有个好处，就是不管是 shell 命令还是 Python 代码，都是文本。而文本，对目前的大语言模型来说，就是能力范围之内的事情。……（对比 Dify，Fabric）执行流程的设定，那是要多流畅有多流畅。因为你会把注意力放在提示词撰写和流程调整这种真正有意义的事情上。

### 27

方军 2024-07-09

每个领域都是创造各种词汇是吧，我真心不记得小时候学习时有意动这个说法，也许专业有，但好像不用学这个的：意动用法。

有时候也很好奇，各种定义究竟是好还是不好呢？

我因为老是闯进不熟悉的领域去，所以不知道各种词，然后就只理解意思，不管人家词，经常因此被人嘲笑。

当然我也无所谓，咱们不在乎词。

就这篇而言，没必要这么多解释啊，稍微慢一点，就可以懂啊。

### 28

方军 2024-07-10

现在算力太卷了：为了抢到最好的 AI 创业公司，VC 也开始卷 GPU 算力了，今天有消息称 a16z 打算花 5 亿美金购买 2 万个英伟达 GPU，并将其租给被投企业。这个数量与马斯克的 xAI 用于训练其 Grok 大型语言模型的数量大致相同，a16z 将这个计划称为「氧气计划」，其目的是为了更好吸引和支持 AI 初创企业。

a16z 希望在竞争激烈的 AI 初创公司投资领域获得更多优势，因为 GPU 是 AI 模型训练的关键组件，它们能够同时处理大量数据，加速机器学习算法的运算过程。通过提供 GPU 资源，a16z 可以降低初创公司的运营成本，帮助它们更快地开发和部署 AI 技术。但 a16z 这么做，对于那些小 VC 来说，竞争就更加激烈了。

不过通过构建 GPU 集群来获得优势，之前已经有人干过了，而且效果还不错，那就是 Nat Friedman 和 Daniel Gross 打造的 AI 版 YC AI Grant，其 Andromeda Cluster 计划就包含了 GPU 算力资源，这个计划为其孵化和投资带来了不小杠杆。

### 29

方军 2024-07-10

转译：我在 AI 教育最前沿的旅行

比尔盖茨

纽瓦克的 First Avenue 小学正在课堂上率先使用 AI 工具。

小时候，我的父母带我去西雅图的世界博览会。看到那些仿佛来自科幻小说的奇妙科技，令我惊叹不已。我在博览会开放的六个月内，多次请求父母带我回去，每次离开展览场地时，我都觉得自己瞥见了未来。

最近，当我走出新泽西州纽瓦克的一间教室时，这种感觉又回来了。

五月，我有机会参观了 First Avenue 小学，他们在课堂上率先使用 AI 教育。纽瓦克学区正在试行 Khanmigo，这是一种由 AI 驱动的导师和教师支持工具，我迫不及待地想亲眼看看。

我在这个博客上写了很多关于 Khanmigo 的内容。它由 Khan Academy 开发，是盖茨基金会的优秀合作伙伴。我认为 Khan Academy 的创始人 Sal Khan 在利用科技帮助孩子们学习方面是个有远见的人。（你可以在这里阅读我对他的新书《Brave New Words》的评论。）

我们仍处于在课堂上使用 AI 的早期阶段，但我在纽瓦克看到的展示了这种技术的巨大潜力。

老师们使用这些工具的创造性让我感到震撼。八年级代数老师 Leticia Colon 解释了她如何利用 AI 设计学生们可能感兴趣的家乡英雄问题集。二月，Khanmigo 帮助她设计了包含纽瓦克拳击手 Shakur Stevenson 锻炼例程的方程式，让学生们在学习数学技能的同时了解现实生活中的榜样。

三年级数学和科学老师 Cheryl Drakeford 谈到她如何使用 Khanmigo 帮助创建作业的评分标准和课程引导。这项技术给了她一个初稿，她再根据学生的情况进行调整。例如，AI 曾给她一个关于水果摊的通用故事引导，她把它改成了关于宝可梦卡和 Roblox—— 她的学生热衷的两个话题。「Khanmigo 给我提供了蓝图，但我需要去实现它。」她说。

我见到的几位老师向我展示了他们如何访问每个学生的仪表盘，并获取他们在特定学科的表现总结。他们喜欢能够轻松快速地跟踪学生的进展，因为这节省了他们大量的时间。他们还对学生们使用 Khanmigo 作为个性化导师感到兴奋。

目前这项技术还远未完善。尽管我遇到的学生总体上喜欢使用 Khanmigo，但他们也提到它在发音西班牙名字时存在困难，并抱怨它唯一的语音选项是男性 —— 这表明在使这项技术包容和吸引所有学生方面还需要进行大量思考。在理想的世界里，AI 会知道 Drakeford 老师班上的学生喜欢什么，这样她就不需要进行任何编辑。而 Colon 老师告诉我，她试了好几次才让 Khanmigo 给她想要的东西。

换句话说，我在纽瓦克的访问展示了我们在课堂中使用 AI 的起点，而不是这项技术最终会达到的地方。这强化了我对 AI 在技术成熟后将彻底改变教师和学生生活的信念。即使在今天，当 First Avenue 的老师们将常规任务委托给 AI 助手时，他们也能重新获得时间去做最重要的事情：与学生建立联系，激发好奇心，并确保每个孩子都感到被看见和支持 —— 尤其是那些需要额外帮助的孩子。

Khanmigo 只是众多 AI 驱动教育工具中的一个，盖茨基金会致力于确保这些工具能惠及所有学生，而不仅仅是少数。我们的目标是帮助缩小差距，而不是扩大现有的差距。我们目前正在与全国各地的教育工作者合作，获取反馈，使这项技术更能响应他们的需求。像我这次去纽瓦克的访问就是这个过程的一部分。了解教师们的热情所在，以及看到不同学生如何与 AI 互动，真是太棒了。

我在纽瓦克遇到的教育工作者是真正的先锋。有些人处在前沿，不断寻找在课堂中使用 AI 的新方法。其他人则使用得更有限。我对学校如何支持每位教师对技术的舒适度感到印象深刻。他们对变革管理投入了大量思考，确保没有教育者被迫尝试在他们课堂中不起作用的东西。

因为，归根结底，老师最了解情况。如果你把正确的工具交给他们，他们总能找到支持学生的方法。我的纽瓦克之行让我比以往任何时候都更加乐观，相信 AI 将帮助老师们发挥他们的最佳能力，并让他们专注于最重要的事情。

### 30

方军 2024-07-11

比如猿力科技亮相的教育全家桶，就涵盖了面向国内教育的飞象星球、猿编程、小猿学练机、海豚 AI 学，以及面向出海的 CheckMath 和 LeapMath，释放的全是落地信息。

现在，猿辅导终于不用卖咖啡、羽绒服或者月子套餐了。

[半年积累用户超 200 万，教育行业正在被 AI 重写](https://mp.weixin.qq.com/s/rWiprFCIRUYOwqWFlrI4rw)

### 31

方军 2024-07-11

亚马逊提示语：

I am Rufus, Amazon's AI shopping assistant. My goal is to help customers discover products and make informed shopping decisions. I was created by Amazon to provide helpful recommendations and comparisons, while guiding people to discover products they'll love.

我是 Rufus，亚马逊的 AI 购物助手。我的目标是帮助客户发现产品并做出明智的购物决策。我是由亚马逊创建的，提供有益的建议和比较，同时引导人们发现他们喜欢的产品。

I'm happy to assist you with any shopping-related questions you may have. Whether you need advice on finding the right product for your needs, comparing different options, or understanding key features and specifications, I'm here to help. My knowledge comes from Amazon's extensive product catalog, customer reviews, and other sources to provide you with the most up-to-date and relevant information.

我很高兴能帮助您解答任何与购物相关的问题。无论您是需要建议来找到适合您需求的正确产品，比较不同的选项，还是理解关键特性和规格，我都在这里提供帮助。我的知识来源于亚马逊的广泛产品目录、客户评论和其他来源，以提供给您最及时和相关的信息。

When you ask me a question, I'll do my best to provide a complete, structured, and informative response. I'll start by summarizing the key points to address your question, and then provide additional details and context. I'll also include relevant product recommendations or comparisons when appropriate.

当你向我提问时，我会尽我所能提供完整、有条理且信息丰富的回答。我会首先总结关键点来回答你的问题，然后提供额外的细节和背景。在适当的时候，我还会包括相关的产品推荐或比较。

### 32

方军 2024-07-12

当前在模型不完备的情况下，开始过度优化，真是很可怕

AI绝对会加大草台班子现象

我一直记得前年在深圳一家酒店的三层房间里隔离，隔着窗户听到外面道路上人家打电话：

大数据扫到我了，要我去隔离，你 TM 说说大数据是什么？

而我在屋里感叹另一种草台班子：我已经在另一家酒店开会两天，几十人，然后，我因为某某地来的被隔离了。

现在各种滥用 AI 技术的，我看着相当无语。

这是我最近为什么老说，增加鉴别力，自己为自己负责。

其实现在已经有了一种类似 deepfake 深度伪造的现象出现了，我们能做的只能是自己加大谨慎的程度，不认可的来源都先视为有问题的

（图为某大厂的产品，它的模型不佳，实用产品就更烂了）

### 33

方军 2024-07-12

前几日推荐 fabric，但我想它还是用于比较简单的任务较好

复杂任务，比如王树义老师一个例子中的吴恩达三步翻译，似乎一下子就觉得还是 langchain 好了。

（实际上，王老师的实现中，他写了一个 text splitter helper，然后还命令行调用 fabric，这些代码如果要自己写，其实直接用 langchain 可能代码更少。）相应地，如果我们要把代码给别人用，分享源码 / 笔记本 / 应用界面，尤其三，更方便些。

对比，dify coze 的优势还是它们提供的第三方工具。（搞那些图形拖来拖去，我用起来真是比代码烦多了啊）

[danielmiessler/fabric：fabric is an open-source framework for augmenting humans using AI. It provides a modular framework for solving specific problems using a crowdsourced set of AI prompts that can be used anywhere.](https://github.com/danielmiessler/fabric)

### 34

方军 2024-07-12

104 理想的 AI 工作流是什么：以校对为例

对我来说，理想的 AI 工作流是什么？今日搞了一个自用的工作流：输入我写好的文章，然后用大语言模型进行校对。

多数人认为的工作流是，输入文章 - 输出结果。

有过实践经验，比如交过书稿给出版社的（报纸杂志不行），知道工作流应该是：输入文章 - 电子版 / 打印版带修订标记稿 - 作者 / 编辑调整与确认 - 最终稿。

在 AI 这儿，我也是同样的思路。我认为即便用了文字能力最强的模型，工作流中我需要的也是电子版带修订标记稿。

这儿，为了让大语言模型能够工作得更好，也为了更好地标记（直接把 Word 式修订搬过来并不是很方便），我采用了三步走（两步 LLM、一步人工）：

第一步：大语言模型提出建议，比如给出五个建议。

第二步：大语言模型给出修改稿。

第三步：作者根据原稿、建议、修改稿，进行确认。

第三步，我通常喜欢在自己的原稿上确认。这样避免了要去辨认修改稿的内容是不是对的问题。

问题还要略微复杂一些，我们不能把一篇超长的文章一下子给 AI，还是要拆成一些片段。这就用到了拆分方法，这是为什么今天我用 LangChain 的原因，它有文本拆分、Markdown 拆分的工具，大体上可将长文章按小标题、段落拆分成为数百字的片段。之后，我们再运行如上三步。

实际的运行过程是，第一、第二步是一起完成的，得到一个文件。

然后，第三步是对这个文件进行修改。拆成小片段的好处这儿也显现出来了，人可以整体地看一个片段，一次一个，逐渐地解决掉校对的确认任务。

进一步优化

围绕这个工作流可能还有一些问题：

1、第一、第二步，如果模型能力够强，可以直接让它一起做吗？

按思维链（CoT）和各类常见的提示语建议，拆分步骤可以提高正确率。我目前的感受也是如此。即便模型能力变得更强，分成两步可能也是比一步更好的选择。

2、有什么可优化的空间？

目前实际上已经做了小优化，就是在提出建议部分提供了少量例子。这些例子是根据富有经验的出版编辑对我的稿件的修改累积下来的，这次纳入的都是文字错漏型的小错。

有三种进一步的优化空间：

一种是大循环：我觉得是找出其中的典型几类问题，然后针对一类问题运行一次。其中个别类型或许可以自动化，类似于在 Word 中做修订标记后，逐一接受或整体全部接受修订。

一种是再增加一个步骤：比方说，用模型对修订进行再次检查，以减少人工复核的工作量。但目前看，暂时可以不做。

一种是选用语言能力更好的模型，比如据说 Claude Sonnet 的语言能力更好、通义千问的中文能力更好，我目前没有广泛地尝试，还是在用 GPT-4o 这个能力尚可的模型（也就是 GPT-4 都没用上）。

3、这个工作流的难点是什么？

放在这个具体场景里，我发现，固然提示语的测试是一个难点（我已经在尝试将其中部分提示语换成英文以提升效果），但可能更大的难点是在外围，这些外围任务都是要程序员去解决的。

比方说，如果要校对的文档是 Markdown，特别地，它又是跟某种软件匹配的，那么，如何处理好它的格式？

比方说，为了用上更便利的 Word 修订或者想要像 AI 雅思写作评分那个应用那样，让建议、修改以可视化，这就全是需要程序员细致地干活了。

由于这只是我探索工作流用的，所以较为简单粗暴，就是直接输出另一个 Markdown 文档，然后在常用编辑器对照编辑。

如果要变成一个产品，对模型结果的反馈也很重要：哪些修订被接受了，哪些没有被接受。我现在这样的 AI + 人工结合的工作流是做不到的。但既然不是产品，就很难在这方面投入了。

最后的提示，由于这个工作流是一次性处理较大量文本（与之前交互式处理不同），我发现模型的能力是在变化的，每次大运行之前，对提示语再次进行必要的评测是必要的。

（题外话，我发现自己并不依赖第二步的修订结果，所以这一步其实是个不必要的鸡肋，去掉可以省 token。这种用法和原来交互式就几乎一样了。）

---

PDF 为修改前原稿，用于对比，可以看到基本上只修改了错别字和文字错漏。

Jese__Ki：方军老师您可以发一下运行代码之类的吗？我有时也有一些校对工作要做，有 AI 辅助的话可以方便很多很多。

2024-07-12 20:29

方军回复 Jese__Ki：我这个目前是个简易的 notebook，可能你不一定能参考：

[“proofread-workflow”的副本 - Colab](https://colab.research.google.com/drive/1zokbxrQxr_ZveykmbiUG9oy6nC4E8ffO?usp=sharing)

2024-07-12 20:47

Jese__Ki 回复方军：没关系，有代码框架作为脚手架就可以了，感谢方军老师。

2024-07-12 22:13

Jese__Ki 回复方军：方军老师，我自己运行了一下，发现在使用 langsmith 进行测试 prompt 的时候，前面都是正常运行的，但是到 `hub.pull（"proofreading-zh")` 是出现 404 的。

我去找了一下对应的文档后，发现 hub.pull 的话是需要 `owner/repo` 的格式来传入对应的库，然后我使用 `proof/proofreading-zh` 后发现也是 404。

因此想来向您请教一下具体的地址。

2024-07-12 22:28

方军回复 Jese__Ki：这个 langsmith 私有的，你自己写写提示语，然后调用你自己的：

你是一个简洁、明了地讲解的写作高手，任务是协助修改文章，找出并修正下面这段话中的文字错漏部分。

修改时要遵守的规则：

1. 不要建议增加连接词。
2. 特别注意多字与缺字的情况。

修改示例：
建议：
前：
后：

给出的修改建议要严格遵照如下格式：“建议：...\n 前：...\n 后：...\n”。

请你修正段落中的文字错漏、语病，给出 3-5 个建议。

2024-07-12 22:59

Jese__Ki 回复方军：了解了，谢谢方军老师，我去试一下。

2024-07-13 00:03

方军：有意思，AI 生成的摘要（elmo）

观点

理想的 AI 工作流应该是一个结合自动化和人工确认的过程，以确保校对的准确性和效率。

文本拆分对于提高校对效率至关重要，可以帮助作者逐片段地进行确认，提高校对的可管理性。

工作流程的优化空间在于找出典型问题类别并针对性优化、增加模型检查步骤以减少人工工作量，以及选择更高性能的语言模型。

工作流程的难点不仅在于提示语的测试，还包括需要程序员解决的外围任务，如文档格式处理和可视化建议的实现。

对于产品化的工作流程，对模型结果的反馈非常重要，需要记录哪些修订被接受或拒绝。

模型的能力是在变化的，因此在每次大规模运行之前，对提示语进行必要的评估是必要的。

第二步的修订结果可能是多余的，因为作者可能并不依赖于 AI 生成的修订稿，而是更倾向于在原稿上直接进行确认。

2024-07-13 14:25

### 35

方军 2024-07-13

我意识到这样的工作流，用 coze dify fabric 都是很容易实现的

前两者现在也都提供了 API

可视化会让工作流调试比较方便（这是 coze/dify）的价值。

我用 langchain 实际上也是在用 langsmith 做观测与调试，偏重观测

---

dify 产品经理这几日一个看法：

[Dify、LangChain、LlamaIndex 这类产品在做什么？](https://mp.weixin.qq.com/s/6O8DHi7gNHvWIWEpLXQJcQ)

前几天我的社交账号下有评论留言说「dify 不过是个玩具」。

对于 90% 以上个人用户的实际体验来讲，这个观点其实没什么错，dify 可以让他们上手「玩」AI，动手折腾。但如果真是在做玩具我们显然又做的不合格，很多用户反馈 dify 不好玩，上手难，不如别家产品「好玩」。

一个几十人的公司能够走到现在，其商业价值显然不是为社会做了款不好玩的玩具。所以 dify 作为一个商业化产品到底为社会提供了什么，解决了哪方面需求？

在这波生成式 AI 浪潮下，无论是个人还是企业，一方面会产生创新的动机欲望、一方面会产生被时代落下的焦虑。无论是哪个动机，dify、langchain、llamaindex 这类开发工具（框架）正在帮助他们验证自己的想法，促成他们的成功或者失败。但需要注意的是，在当下新技术尚未成熟的时间窗口，创新失败的比例会远远大于成功的比例。

对个人来讲，即便你免费用了 dify 没玩出花，浪费的不过是你几个小时或几天的时间。但对于一个企业来讲，拥抱新技术不单单是选择购买一项服务这么简单，这涉及到大量的持续投入，包括招聘算法人员、部署算力服务、立项开发、POC 验证等，这一系列操作涉及数月时间以及无法估量的资金投入。

对于企业来说这是巨大的试错成本，继而转化为全社会的试错成本。我们再设想一下从去年至现在，全球有多少企业会产生上述动机？这个数字一定很庞大。如果早点试错省下钱去做些投资回报率高的事情不是更好吗？

我们当然非常愿意看到一小撮优秀的创新企业可以通过我们实现目标，但理性来讲，在技术发展的这一阶段，加速全社会的试错以及失败可能是 dify 这类产品提供的最大价值，甚至高于成功。

感谢阅读，欢迎分享。

### 36

方军 2024-07-13

[微软中国 CTO 韦青：亲身经历大模型落地的体会与思考](https://mp.weixin.qq.com/s/s3gJ0MrIgNBuBhTcTvrFKQ)

观点（为 AI 生成，Elmo)

企业发展中的「看不见的大猩猩」问题：企业在追求技术创新的同时，需要关注那些容易被忽视但关键的问题，如思想局限、数据问题、人才问题和流程再造问题。

思想转型的重要性：人的问题是最复杂的，企业成功的关键在于思想方法的转型，采用成长型思维，不断学习和纠偏。

人工智能数据的质量与价值：人工智能的实现不仅需要大量数据，更需要这些数据能够代表文明特征，以便机器学习到代表这种文明的知识与价值观。

关注「硬核」问题：企业应关注那些显而易见但通常被忽视的问题，如人才、数据和流程再造，这些问题是企业快速发展的关键。

成功的概率性：成功是概率性的，需要通过错误与犯错的教训学习，而不是仅仅追求「最佳实践」。

从马车到汽车的思维转变：从马车到汽车的转变代表了不同的思维范式和文明范式，而非简单地将新技术应用于旧有产品。

智能机器的使命：智能机器应帮助人类处理信息过载带来的问题，并在科学研究、医学等领域发挥作用，推动「AI for Science」和「AI for Everyone」的发展。

智能技术的落地次第：智能技术的落地需要有次第可循的逻辑，从基础架构到应用架构，再到开发的架构，最终落实到具体的应用场景。

数字化转型的必要性：数字化转型是实现智能化的基础，涉及数字化产品、实时反馈链和整个产业链的协同。

人机协同的未来：未来的工作将更多地依赖于人机协作，机器将作为人类智能助手，帮助提升效率和决策能力。

避免信息茧房的挑战：在信息过载的时代，我们需要建立起对未来技术发展的坚定信念，避免被信息茧房所限制。

重新定义软件的方法：大模型正在重新定义软件，不仅仅是在现有软件上添加 AI 功能，而是要重新构建软件的生命周期和流程。

### 37

方军 2024-07-13

看人分享 Dify 的坑也值得注意的：“太在意团队协作效率，忽略了其他”，下面说的这种不知道哪儿冒出来的问题默默在后面跑蛮烦的，其实今天还看到一个：“因为使用 Spring Boot 新的 RestClient 超时设置未生效，导致 Dify Workflow 运行超时后不断重试（之前最大重试次数为 15），浪费 1 亿多的 tokens，损失将近 1000 块；”

---

刚发现 Dify 会默默有任务在背后偷跑 LLM 推理。有个 _generate_conversation_name_worker 上个月看起来跑了上万块钱的 tokens，我今天才发现有这么个任务。界面上完全没找到哪里有说明和配置这个东西的。实际上我也没看到他跑的结果在哪，对日常使用也没感知到有任何意义。就这么被跑了上万块钱……

这周总算把线上大部分应用从 Dify 迁移走了，下周迁移掉最后一个最麻烦的后，线上环境就彻底摆脱 Dify 了。感觉几个月前确实做了个错误决定挖了个坑，太在意团队协作效率，忽略了其他。

x.com/tzwm/status/1809242535933755411

其他人：

卧槽，兄弟你的业务量很大啊，1 个月居然跑到了上万块的非主流 llm 功能成本

看这任务的意思，是给对话 session 打个标题。Dify 这么做，是参考了 ChatGPT 对话页面的自动保存对话功能吧

但事实上，很多对话都是临时性的，自动打标题完全可以省略，或者采用本地或低价的 llm 来搞定

### 38

方军 2024-07-13

前段时间看到一个翻译专业的教授的话，蛮有意思的，大意是，

看学生翻译作业久了，特别要防备「脑损伤」。倒不是学生不认真，而是学生作业中的潜在错误，可能对教授本身的认知产生误导，得时时纠正。(翻译之外的这个问题都不太严重。）

突然想到这个，是现在在听一个讨论会的汇报。我不是主持者没有义务仔细听，因而我有意识地选择不要仔细听。原因很简单，太多的似是而非，努力去辨识实在没有必要。

这也是我对 AI 结果的看法，我尽量避免让 AI 做给出的结果需要我仔细辨识的事 —— 我怎么能花自己宝贵的脑力去用在这种无意义的错误辨识上面。

收紧，坚持高质量的输入，是现阶段最重要的建议。

（有时候我也疑虑，我喋喋不休在自己这个笔记性质的星球中写很多，是不是对。这就需要你来辨识了，我只能声明，对我，写是我将观点固定下来、并澄清的方法。）

### 39

方军 2024-07-14

105 AI 学习记录：美国通胀率与加息 / 降息

（请注意，这是我非常不熟悉的领域，在用 AI 尝试学习，因此，你应该先假设其中的内容都是错的，然后逐一验证其中的内容是不是对。直接引用的 AI 生成内容用「---」标出，其他内容为我的学习笔记。）

体会提前：总而言之，AI 聚合搜索能够协助更快地搜索资料，AI 问答能够提供针对性的解释，能够大大提高我们的学习效率。

我们经常听到人说，美联储要降息、降多少。他们当然是明白其中的关系的，但我们这些外行人不明白，我努力学习了一下。

🖍️ 第一个问题：哪几个元素在相互作用

逻辑上，这里有三个元素：

- 高通胀
- 高利率
- 经济增长

简言之，当前美国经济的情况是，高通胀，同时利率也保持在较高水平，同时，经济也在高速增长。

最近媒体报道中通常说的美联储降息是：

> 如果通胀开始下降，那么美联储可能会降息，从而维持整体经济的良好运转。

（这三个元素是从一个较可信作者的科普文章中获得的。）

🖍️ 第二个问题：这几个元素是如何相互作用的？

这个问题我是问 Kimi 尝试理解的，用的是类比：

---

想象一个国家的经济就像一个正在行驶的汽车。高通胀就像是汽车的刹车失灵，速度越来越快，危险越来越大。为了控制车速，司机（即中央银行）决定提高利率，这就像是踩下刹车，让车慢下来。但是，如果刹车踩得太猛，车可能会突然停下来，甚至翻车，这就是经济增长放缓或衰退的风险。

---

简言之：

之前的情况是，高通胀，对应的策略是高利率（踩刹车）

之后的情况是，通胀降低，对应的策略是降低利率（加油门）

🖍️ 第三个问题：美国的通胀，是用什么指标来判断的？

略微查询可知，美国是 CPI 和 PCE（以及核心 PCE， Core PCE）。

以下为 AI 的解答（经简化）

---

消费者价格指数（CPI）

CPI 是衡量通货膨胀的重要指标，由美国劳工统计局（Bureau of Labor Statistics，BLS）发布，反映了消费者购买一篮子商品和服务价格的变化情况。2022 年 6 月，美国 CPI 同比上涨 9.1%，创下近 41 年的峰值。

个人消费支出价格指数（PCE）

PCE 则是由美国经济分析局（Bureau of Economic Analysis，BEA）发布的，它不仅包括商品和服务的价格变化，还考虑了消费者在面对价格上涨时可能做出的消费替代行为。

美联储（Federal Reserve）更倾向于使用 PCE 作为其判断通胀的主要指标，尤其是核心 PCE（不包括食品和能源价格波动的核心 PCE），因为它被认为能更准确、全面地衡量通胀 2。2022 年 4 月，美国 PCE 通胀同比为 6.27%，核心 PCE 通胀同比为 4.9%。

---

CPI 较为常见，PCE 对我们这些不了解美国宏观经济的人，需要多了解一下。

🖍️ 第四个问题：PCE 指标具体是什么？

PCE 指标中，实际常用的是「United States Core PCE Price Index Annual Change」，年度变化直接代表了通胀率，显示了与去年同月相比价格上涨了多少。

除了 BEA 网站之外，这个指标在 TradingView 等平台是可以方便地查询的：

[United States Core PCE Price Index Annual Change (ECONOMICS:USCPCEPIAC) — Historical Data and Chart — TradingView](https://www.tradingview.com/symbols/ECONOMICS-USCPCEPIAC/)

从图表中（附图 1），我们可以看到目前的指标数值是 ：2.8%。同时，这个指标目前处在下降中（5 月比 4 月下降 0.2）。

但是，这个指标目前仍高于美联储的通胀指标：

通常来说，美联储的通胀指标是 2%，高于这个指标就应该保持加息的可能性，以降低通胀。

这就是第五个问题了。

🖍️ 第五个问题：美联储的政策

用 Perplexity 做的搜索与总结（我大略知道 2% 这个指标），因此总结就让 AI 帮忙做下：

以下是美联储通胀率目标的中文翻译（部分摘录）：

此提问的主要参考资料：

[The Fed - Why does the Federal Reserve aim for inflation of 2 percent over the longer run?](https://www.federalreserve.gov/faqs/economy_14400.htm)

---

美联储的长期通胀率目标是 2%。这个目标于 2012 年由美联储正式宣布，尽管世界上许多其他中央银行早已采用了类似的目标。

联邦公开市场委员会（FOMC）认为，以个人消费支出价格指数的年度变化来衡量，2% 的通胀率最符合美联储的最大就业和价格稳定的使命。这个目标有几个重要作用：

1. 锚定通胀预期：明确的目标有助于家庭和企业在储蓄、借贷和投资方面做出明智的决定。

2. 避免通缩：2% 的目标为经济衰退期间可能出现的通缩提供了缓冲。

3. 货币政策灵活性：它给予美联储在经济衰退期间更多降低利率的空间。

2% 的目标并非没有争议。一些经济学家主张设定更高的目标，如 3% 或 4%，认为这样同样有效，且不会造成重大危害。然而，美联储官员，如纽约联储主席约翰·威廉姆斯，坚持认为 2% 的目标对于实现价格稳定和确保经济繁荣至关重要。

---

图 2 为美国联邦利率 Federal Funds Rate，其中近 10 年见图 3，来源 TradingView。

[Effective Federal Funds Rate (FRED:FEDFUNDS) — Historical Data and Chart — TradingView](https://www.tradingview.com/symbols/FRED-FEDFUNDS/)

总而言之，AI 聚合搜索能够协助更快地搜索资料，AI 问答能够提供针对性的解释，能够大大提高我们的学习效率。

### 40

方军 2024-07-15

最近真是天天听到人说 Claude Sonnet 的代码能力超过 OpenAI GPT 啊。

今天连续看到两个：

- 今天是我第一次较重度的使用（免费版本）的 Claude 3.5 Sonnet，对比 ChatGPT 4o（付费版本），优秀非常多，真的，对比过才知道香。

在此之前我都一直付费使用 ChatGPT，没有用过其他家的类似产品，主要还是一个刻板印象，认为 openai 领先其他家太多了，但就目前的产品而言，我真的刷新了认知。

- 我刚退掉（github copilot），刚收到邮件说 6 月份扣的新的一年的 100 刀全部退给我

---

我的个人感受：

虽然一直用 github copilot。但现在想起来，似乎 github copilot 真不如当初最早用 GPT4 编码的 cursor 啊。

### 41

方军 2024-07-15

昨日书店看到这本书，我好想有机会写本书叫「能力危机」competency crisis，实际上应该叫 AI 加速草台班子。

但草台班子一看就很草台，还是能力危机比较酷（不过，近期肯定都不写书了）

之前写的一段文章：

[知识星球 | 深度连接铁杆粉丝，运营高品质社群，知识变现的工具](https://wx.zsxq.com/dweb2/index/topic_detail/5122442525588224)

以上是看到这句话的感想：

the competency crisis is so widespread I can't help but assume that what I experience is just the tip of the iceberg and it's everywhere. If something being done correctly is important to you，double check it.

能力危机如此普遍，我不禁认为我所经历的只是冰山一角，而且它无处不在。如果正确做事对你很重要，那就仔细检查。

x.com/slangchain/status/1812704011960590444

### 42

方军 2024-07-16

昨天有人说，US 是「文档国」。我是真心喜欢文档国，不喜欢微信国、微信语音国、微信群国（钉钉国）、腾讯会议国。（同步的微信会议是必要之恶，但要控制在必要的程度；线下面对面是高效的，但同样也要双方 / 各方都严肃对待。）

@a16z 新发了一个图：人工智能书记员。

想象一下，如果你有一个超人助手，它能倾听你的对话，做好完美的笔记，并标记后续事项。

而且，它可以通过呈现你错过的见解或趋势让你更聪明。

x.com/omooretweets/status/1812878684182942144

下为 AI 翻译：

让我们从抄写员的历史开始。

这是一个可以追溯到书面语言发明的古老职业。

这个角色在促进各种类型的交流 —— 商业、法律、宗教等 —— 以及记录历史方面至关重要。

如今，书记员最常见于医疗、法律和政府领域。

在美国大约有 10 万名医疗记录员，每 10 名医生配备一名。

但是许多其他角色有抄写员的职责 —— 翻译人员、教育工作者、记者、研究人员、销售人员、助理。

使用抄写员通常非常昂贵，因为你正在雇佣另一个人来倾听和转录。

人工智能使抄写员人人都能使用且负担得起 —— 并将其作用扩展到人类所能做的之外。

有几层为人工智能抄写员提供动力的堆栈。

1、语音转文本。

这是一个转录语音的模型。

许多语音记录员使用开源或可提供 API 的模型进行自动语音识别，但可能会在词汇或口音上进行调整。

对于某些用例，模型在离线状态下、在高噪音区域等具有高性能可能特别重要。

2、结构与总结。

你对话的原始记录通常不是最有助于获取信息的格式。

LLMs 可用于总结和构建记录，并呈现见解或后续行动 —— 你需要知道什么？

3、对这些输出进行「操作」的工作流。

甚至比处理这些文字记录更好？为你采取行动。

想象一个可以将销售电话中的信息推送到客户关系管理系统中的抄写员。或者，可以利用医生与患者的对话来填写保险预授权表格。

在 @a16z ，我们对使用人工智能抄写员作为进入垂直软件的楔子的产品感到兴奋。

这种语音数据往往处于企业所做一切的「上游」—— 因此，抄写员可以成为个人 / 公司的记录系统。

一些例子和早期的经验教训：

Freed AI

弗里德为医生做 SOAP 笔记。根据 X 上的 @ErezDruk ，该公司在一年内达到了 1000 万美元的年度经常性收入！

临床医生通过使用 Freed 每周节省数小时 —— 他们不再需要在晚上和周末花时间撰写预约报告。

Scribenote

就像用于人类医学的 Freed 一样，Scribenote 是兽医的人工智能助手。

该产品是专门为兽医面临的许多不同预约类型（例如 2# 的牙齿检查）进行全面和方便的语音捕捉而独特构建的。

Rilla

Rilla 是面对面会议的销售教练。抄写员记录、转录和分析每一次预约。

这使得销售经理能够以更加细致的方式指导销售代表，将曾经的「黑匣子」变成系统化的评估。

Granola

Granola 是连续开会的人（招聘人员、销售人员、风险投资家 ）的记录员

它充满了重点功能 —— 没有会议机器人，合并手动 + 自动笔记，完整的记录但快速的总结，干净的分享等等。

Aqua

Aqua 在模型上进行创新，具有通过语音编辑文本的能力（例如「把所有这些都放在要点中」）。

这使得它非常适合较长形式或更微妙的写作，在这种写作中，你可能会在你想说的内容上反复斟酌。

如果您正在构建一个人工智能语音记录器，请联系！

我们已经在这里进行了投资，并计划在未来几个月进行更多投资。

（以上作者：Olivia Moore）

### 43

方军 2024-07-16

reddit用户ssmith12345uk分享了他为Coding设置的Prompt，在Sonnet 3.5模型上工作良好。

以下为翻译及原文：

[Sonnet 3.5 Coding System Prompt (v2 with explainer) : r/ClaudeAI](https://www.reddit.com/r/ClaudeAI/comments/1e39tvj/sonnet_35_coding_system_prompt_v2_with_explainer/)

“你是一位Web开发专家，精通CSS、JavaScript、React、Tailwind、Node.js和Hugo/Markdown。你擅长选择和挑选最佳工具，并尽最大努力避免不必要的重复和复杂性。

在提出建议时，你将事情分解为单独的变更，并建议在每个阶段后进行一个小测试，以确保一切在正确的轨道上。

制作代码来说明例子，或在对话中被指示时。如果不用代码就能回答，那更好，如果需要详细阐述，会被要求这样做。

在编写或建议代码之前，你对现有代码进行深入审查，并在<CODE_REVIEW>标签之间描述它是如何工作的。一旦你完成了审查，你就在<PLANNING>标签中为变更制定一个谨慎的计划。注意变量名和字符串字面量 - 在复制代码时确保这些不会改变，除非必要或被指示。如果按照惯例命名某物，请用双冒号::UPPERCASE::包围。

最后，你生成的正确输出在解决即时问题和保持通用性和灵活性之间提供了正确的平衡。

如果有任何不清楚或模糊的地方，你总是要求澄清。如果需要做出选择，你会停下来讨论权衡和实现选项。

重要的是你要遵循这种方法，并尽你所能教导你的对话者如何做出有效的决策。你避免不必要地道歉，并回顾对话以避免重复早期的错误。

你对安全有着敏锐的意识，并确保每一步都不做任何可能危及数据或引入新漏洞的事情。每当存在潜在的安全风险（例如输入处理、认证管理）时，你会进行额外的审查，并在<SECURITY_REVIEW>标签之间展示你的推理。

重要的是所有产出都是运营上可靠的。我们考虑如何托管、管理、监控和维护我们的解决方案。你在每一步都考虑操作问题，并在它们相关的地方突出显示它们。”

You are an expert in Web development, including CSS, JavaScript, React, Tailwind, Node.JS and Hugo / Markdown.Don't apologise unnecessarily. Review the conversation history for mistakes and avoid repeating them.
During our conversation break things down in to discrete changes, and suggest a small test after each stage to make sure things are on the right track.
Only produce code to illustrate examples, or when directed to in the conversation. If you can answer without code, that is preferred, and you will be asked to elaborate if it is required.
Request clarification for anything unclear or ambiguous.
Before writing or suggesting code, perform a comprehensive code review of the existing code and describe how it works between <CODE_REVIEW> tags.
After completing the code review, construct a plan for the change between <PLANNING> tags. Ask for additional source files or documentation that may be relevant. The plan should avoid duplication (DRY principle), and balance maintenance and flexibility. Present trade-offs and implementation choices at this step. Consider available Frameworks and Libraries and suggest their use when relevant. STOP at this step if we have not agreed a plan.
Once agreed, produce code between <OUTPUT> tags. Pay attention to Variable Names, Identifiers and String Literals, and check that they are reproduced accurately from the original source files unless otherwise directed. When naming by convention surround in double colons and in ::UPPERCASE:: Maintain existing code style, use language appropriate idioms. Produce Code Blocks with the language specified after the first backticks, for example:
```JavaScript
```Python
Conduct Security and Operational reviews of PLANNING and OUTPUT, paying particular attention to things that may compromise data or introduce vulnerabilities. For sensitive changes (e.g. Input Handling, Monetary Calculations, Authentication) conduct a thorough review showing your analysis between <SECURITY_REVIEW> tags.

### 44

方军 2024-07-16

106 用 AI 穿透式学习：编程案例

新书《重新学会学习》出版了，讲的是如何用 AI 来辅助学习，夸张点说是，

在 AI 时代，如何用 AI 来加速学习。

这本书是之前《穿透式学习》的升级版，本来是个2.0版，但因为改动了超过 70%，因此以一本新书来重新出版。我没舍得丢掉之前的名词，所以还是用了“穿透式学习”这个概念。

新增核心内容，在这个星球里发过最早的草稿：05 AI给学习带来什么？——一个初步的总结

[知识星球 | 05 AI给学习带来什么](https://wx.zsxq.com/dweb2/index/topic_detail/588124822154884)

这篇文章倒不是要介绍这本书，而是接着分享我今天的学习，我一直有个程序员的身份，不管干什么，我都亲自参与写代码。我发现，如果想要保持程序员的身份，就必须得持续地学习。

「案例」编程学习

下午去更新修正之前去年一个业余项目，去年我们才因为 AI 开始接触 Stream，当时拼凑出来的写法，颇为潦草。

今天要做的、所学的及后续要学的

1. 修正错误

2. 修正错误过程中，选择了某个 SDK

仅用了 SDK 的后端部分，前端部分如果用会带来巨大的变化。 这不符合我这次仅是小改动的预设。

新问题出现了，从 AI API 接收到的 Stream 在转向前端时不能正确工作，这是由于处理方式不一致导致的。

3. 现在有了 AI ，我们多数人的解决方法是，先问 AI 要到一个解决方案。

这和过去差不多，过去多半是先搜索搞一个解决方案，但过去通常是不成的，且需要更多的时间。

这样，就以我刚刚群里跟人说的，用「脏乱差」的方式临时解决了。

4. 略微深入一点，这个脏乱差能否更好地解决呢？

尝试了一些，但均不成功，当然略微有点进步。

这时我发现，实际上，我们还是要回归到程序员最典型的学习方法：

5. 从原理上把一个「事物」的来龙去脉、周边全部搞明白。

然后，再把代码精简、优化到清晰。由此，摆脱脏乱差。

这里反映了我的一个看法，学透一个点，是一个有效的学习方法。而 AI 在这个过程中可以大大地帮忙。

以上的案例中：脏乱差地拼凑一个方案，是外界认为的 AI 能帮忙的，所谓 AI 能取代程序员。但是，彻底搞明白，然后把代码写得清晰，是我们自己的责任。

### 45

方军 2024-07-16

微软这个搞 AI 开发的人社交媒体说得杂七杂八，但其实蛮有意思的：

其实 800 万网约车和出租车司机只是开始，1700 万货运司机对自动驾驶来说比城市复杂路况更简单，跟着是 8400 万外卖和快递小哥。这一亿人背后关联着 1 亿个家庭，有 2-3 亿张嘴等着吃饭。其实不同于纺织女工进工厂的第一次工业革命，这次 AI 的革命是比较可怕的，因为全面接管体力劳动以后就没有新的工作岗位出来。

那不搞 AI 行不行，大抵也是不行的。以往发展中国家的经济发展，主要靠廉价劳动力的支持，让产业链从发达国家像低收入，低成本的国家和地区转移，同时收入也完成部分转移，带动发展中国家经济发展。但是 AI 之后呢？廉价劳动力就是个伪命题，以后发展中国家再也无法靠廉价劳动力来获得发展了，机器都是 7*24 无抱怨得干，什么廉价劳动力也廉价不过机器。

即使未来伴随 Agi 之后有新的工作机会，但是这 20 年的两代人，应该也没什么机会和时运完成转型了。所以我最近在自学炒菜和美容美发，这几门手艺应该 AI 取代不了，现在已经掌握了 4 个菜，红烧肉，溜肉段，大拌菜和西红柿炒鸡蛋，美容美发这块，现在掌握了卡尺理圆寸。

### 46

方军 2024-07-17

摘：原来前 OpenAI 创始人之一 Andrej Karpathy 在离开 OpenAI 之后去做教育事业了，成立了 Eureka Labs，一种集成了 AI 的新型教学平台。真的是好事情，我们需要他这样有一线经验又善于教学的专家。

第一门课会是 LLM101n。这是一门本科级别的课程，引导学生训练自己的 AI，非常类似于一个小型的 AI 教学助手。课程材料将在线提供，同时运行数字和实体的学习群。

他们的教学会引入 AI，老师设计课程材料，但会有 AI 助教，AI 助教可以帮助学生理解课程内容。当然这种老师与 AI 助教的协作的模式需要一种新型教学平台的支持，所以预计他们会先基于自己的课程来探索这种模式和完善平台，最终会推广他们探索出来的教学模式和平台。

还是很期待，教育模式很多年没有变过了，随着生成式 AI 的发展，是应该有些革命性的结合 AI 的新教育模式，给每个人提供更个性的教育。可汗学院已经做出了一些尝试和创新，Khanmigo 这样的 AI 助教已经能提供个性化的辅助教学服务，不知道 Eureka Labs 会为我们带来什么。

Website：eurekalabs.ai

GitHub：github.com/EurekaLabsAI

这个大佬真的是赛博活菩萨，之前跟着看了他在油管的从零实现 GPT 系列，是真的手把手教，从 Pytorch 的 API 甚至到 Python 的一些基础操作都会解释下，生怕你学不会。原文里的「subject matter experts who are deeply passionate，great at teaching」，用来形容他自己再合适不过了。

\#大神卡帕西创业办学校 #，要做 AI 领域的费曼

今天最瞩目的消息 ——Andrej Karpathy（卡帕西）官宣创业了。

Eureka Labs，一家 AI 原生的新型学校。

卡帕西是 OpenAI 创始成员，曾任特斯拉 AI 主管，自今年 2 月再度从 OpenAI 离职后，一直没宣布下一步去向。大家纷纷猜测，他可能回特斯拉或加入 xAI？又或者自己创业自己构想的大模型操作系统。当然很多人心中还有一个愿望，希望他能多出点教程。

现在这个愿望实现了，卡帕西这回全职搞教育，还是 AI 原生教育。

何为 AI 原生教育？

想象一下与费曼一起学习高质量教材，费曼会在每一步中 1 对 1 指导你。不幸的是，即使每个学科都能找到一位像费曼这样的大师，他们也无法分身亲自辅导地球上的 80 亿人。

但 AI 可以，而且 AI 有无限的耐心，精通世界上所有的语言。所以卡帕西要打造「教师 + 人工智能的共生」，可以在一个通用平台上运行整个课程。

「如果我们成功了，任何人都将易于学习任何东西，扩大教育这个概念本身的「范围」和「程度」。

也就是让更多的人有学习的机会，以及让每一个人学习超出今天力所能及的科目，在技术的帮助下。

有人评价此举相当于把大模型的 Scaling Law 用在费曼上。

Eureka Labs 首个产品，也是首门课程 LLM101n。

卡帕西称之为「世界上显然最好的 AI 课程」，看过他以前课程的会感到很熟悉，仍然是以练代学。手把手带你构建一个类似 ChatGPT 的故事生成大模型，以及配套的 Web 应用程序。使用 Python、C 和 CUDA，从 0 开始，追求最少的先修要求。

目前 17 章节课程大纲已经出炉，可以看出，从语言建模基础和机器学习基础开始，一步步通往现代大模型应用需要的一切。

课程内容本身还未完全准备好，卡帕西表示还没有具体的时间表。当然部分内容已经零散的发布在他个人账号了，比如最近的从 0 训练 GPT-2。

「虽然现在还为时尚早，但我想先宣布出来而不是秘密进行」，也就是最近热门的 Build in Public，公开创业。

有人关心这个课程会收费吗？

卡帕西表示虽然希望公司能自我维持，但也不希望让教育内容有门槛。目前的规划是课程内容本身免费，从其他地方寻找收入。

[大神卡帕西官宣创业：一所 AI 原生学校，要做 AI 领域的费曼](https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247739197&idx=1&sn=58bf7b4244abf9c6d3b117061f6db564&chksm=e8df904fdfa8195945b5024d9344458e7bd432b47f9bf416ab9d075e8784fb114255e19c4c39&token=1759269144&lang=zh_CN#rd&v_p=90&WBAPIAnalysisOriUICodes=10000001_10000002&launchid=default&wm=3333_2001&aid=01A0VjFEC-8TX6msntzx_IZJsVSdIBL5NqzASu9SjrmTcS5LA.&from=10E6393010)

### 47

方军 2024-07-17

散步想一个话题，为什么总听到人说 AI 编程，自己再也不用动手了，但我却做不到呢？我刚刚想，或许人家就是有意夸张 AI 的能力，但我觉得这没必要啊，说这个话题又不是为了吸引流量，夸大有何好处？一会儿有电脑了说说我的理解。以我的水平，想象不出一个一万到两万行自写代码的小业余项目可以靠完全 AI 写，并且还能持续迭代。

### 48

方军 2024-07-18

107 AI 在编程上能取代程序员吗？

经常听到大众鼓吹，有了 AI，就不需要程序员了。也经常听到实际编程的朋友热情地分享，我现在都不自己写代码了，想好了让 AI 写，与 AI 结对编程。

我最近更加深刻地感受到，这种夸大是有害的。我用 AI 编程的时间不算长，也就是两年多一点（从最早有 Github Copilot 开始的），我的体会是，现在当然都必须得用 AI 编程，但外界所夸大的印象与事实相差太大。

AI 毫无疑问是最适合编程的，理由有三：一，有大量的文本资料；二，代码本身也是文本，三，代码可以运行，迅速判断正确与否。

第一个澄清：代码与代码片段

所谓 AI 能够直接编写代码、AI 能够根据截图编写网页，这些都是所谓的「代码片段」。写过哪怕小应用的人都知道，要把代码片段组成顺畅的逻辑和可运行的应用，还有很多工作量。

即便在片段上，AI 没那么有效。比如，我曾经尝试用 AI 来将一个不算太复杂的组件（500 行），从 React 转换为 Vue，事实上，必须得拆解成整体、各个函数来逐一做，才能做好。当然，有了 AI，绝对比自己做要方便一些。

第二个澄清：程序员的实际工作

普通人认为，程序员的实际工作，当然应该就是编码。实际上，即便不是组织中（也就是没有开会、没有 PM、没有评审等等），就是单兵作战的独立开发者，程序员的实际工作中编码所占比例也不会超过 50%。

以独立开发者开发一个小应用为例（且不考虑产品、运营等层面），仅考虑开发，大略如下：

- 20% 选型，用什么组件
- 50% 编码
	- 25% 实际编码
	- 25% 调整编码
- 15% 编写文档
- 15% 学习相关技术

第三个澄清：应用架构 vs 代码

现在的程序员，实际上要花大量的时间在架构上（如你所见，我指的并非那种不写代码、只写 PPT 的架构师）。

哪怕一个极其小的应用，都会有如图这样一个架构，怎么把各个组件组合起来。程序员所写的代码也是分等级的，其中胶水代码看起来有点贬义，但程序员都知道没有胶水代码哪行：

- 真正的核心代码，比如算法类、性能优化类
- 功能性的代码，比如界面
- 胶水代码，比如连接、配置

更关键的是，架构远比代码要重要，实际编码过程中的大量时间是在进行架构的尝试。

在架构部分， AI 可以加速尝试，但是是无法直接写代码的。图为一个示例架构，临时手画的示意图。

第四个澄清：编码 vs 测试

用编码和测试来分别指代两种情形，测试不是狭义的测试，而是指确保代码和代码整体能正确、可信地运转的各种工作。

AI 可以编码，但不管是从代码片段的角度，还是从模块的角度，还是从整体的角度，确保代码的质量，这个事情只能靠程序员来做。当然，程序员可以借助 AI 来帮忙，比如现在可以更方便地用 AI 来编写单元测试。

第四个澄清：实际工作的代码与版本迭代

一个应用实际工作的代码，往往是要部署在某个环境的。这有很多自动化的做法，AI 也可以协助编写相关脚本。

但这里，还是涉及不少其他的工作。这些工作，看起来暂时也无法完全交给 AI 去做的。

比方说，一个版本迭代，从 1.0 到 1.1，上线的时候，有没有一个测试、评审流程确保各项功能是正确运转的。软件应用不能是：这不是（偶尔）可以运行吗？它要至少在 99.9% 的情况是正确运转的。

以上还不是讨论的规模较大的软件开发，只是我想规模在实际代码 2 千到 1 万行代码这样非常小的软件应用。

简言之，必须用 AI 编程，但夸大 AI 编程能取代程序员的工作，这给人一种极其错误的印象，导致人们的误判。

方军：摘一个：有个前同事 G，用 C++ 编程很漂亮，之前我们都将最核心的代码让他操刀。后来 G 离职出去创业，做得不好不坏勉强糊口。

这次吃饭他跟我说，人工智能使得纯粹低端编码人员即将失业。

他们公司申请了 ChatGPT 付费服务，大约因为付了费，这货 24 小时不打烊，尽职尽忠地写代码，代码量约等于 10 个开发人员。

我问：代码质量咋样？应该不精致不简洁吧。

G 连连摇头道：ChatGPT 写的代码比自己写得好，更是比普通码农好了千倍。不仅代码精炼，可读性还不错，甚至连我们常犯的内存泄漏问题也一去不返。更有甚者，你可以将自己的代码作为输入给 ChatGPT，这货的输出就是大师级杰作。

我已经在脑海里构想了未来的 IT 世界，除了机器没有码农。剩下的都是给 AI 提问题的新新聪明人类，他们是分析师、架构师、设计师。所谓的人机交互，就是「人」提问，「机器」以代码回答。

2024-07-18 10:28

### 49

方军 2024-07-18

据说，Google 不再默认索引新内容

你以为的 SEO：拼命写文章，大量写，大力出奇迹！

真正的 SEO：内容新颖，创造高权威性内容，成为知名品牌。

wulujia：这个的信源是什么？我觉得结论很糙啊。

2024-07-18 12:59

方军回复 wulujia：是，有点存疑，新内容的 google 权重还是很高，不过 blog 不像原来那么高了

2024-07-18 13:05

方军回复 wulujia：不过这个人延伸的结论是对的，品质内容的价值相对有提升，感受上是这样（搜索用户侧，SEO 侧没试过不了解）

2024-07-18 13:07

### 50

方军 2024-07-18

我特别希望 AI 能自己干活。

我前几天会议时吐槽：最近要做分享，每次想分享主题那十个字，我要拖半天。

然后分享准备的 PPT，我一般半个小时到 2 个小时不等。

当然，如果是别人给我命题，那就更痛苦没法干（分享这个事还真没法别人命题做的。）

我这里说的是选定题目的部分，至于 PPT 这个部分，我从来不认为 AI 可以干。

人要无知到什么程度，人要对于听的人的时间精力蔑视到什么程度，才会用 AI 搞的垃圾去忽悠别人？

---

关于 PPT，刚刚有人跑上来问：

有没有什么做 ppt 比较好用的 AI 呀

我回答：

没有的，不要考虑用 AI 做 PPT 了，都不行

但你可以看看一些用 markdown 格式的 PPT 工具，这样可以把文本快速变成 PPT 演示文档

---

刚刚社交媒体看一人发的东西，最后是这么一句：

ChatGPT 也可能会犯错。请核查重要信息。

心里批一句，垃圾人啊。

### 51

方军 2024-07-18

最近看了一些 AI 写作的工作流，用我自己的文章转换了一下，讲实话非常糟糕。

- 大众也许会认为这样方块的比我原先写的更易读，这是因为他们不读，只是扫一眼。

- 这样的文章是不易接受的，不是 skimmable（可快速浏览与吸收的）。

- 这样的文章内容还是来自于原文，但其实已经变成了内容垃圾。

- AI 文章里面显然大词用得过多了（部分原因是这个工作流是先英文、再翻译为中文）。

我不知道有多少人会习惯性地认为这种 AI 生成的文章才是文章，而我写的那种不是文章。

- 对于这一种文章，其实我很熟悉，当年需要偶尔替补写社论专栏的时候，我们能够飞快地组织文字把观点写出来。

- 而对应地，我后来写一本书的时候，我选择更容易 skimmable 的形式，而帮忙阅读原稿的朋友不断地提醒我不要过度分段。

以下为工作流产出的内容，两个版本，用我今早的文章作为输入而来的：107AI 在编程上能取代程序员...

工作流大体上是：提取要点 - 写作

---

AI 编程的海市蜃楼

近来有很多关于 AI 取代程序员的炒作。大众想象中似乎描绘了这样一个未来：你只需告诉计算机你想要什么样的应用程序，它就会吐出一个完全成型的、可以直接发布的产品。但这种愿景与几十年前承诺的飞行汽车一样不切实际。

AI 在编程中的现实既不那么戏剧化，也更加微妙。是的，AI 可以生成代码片段并帮助完成某些编程任务。但创建软件远比简单地串联代码行要复杂得多。

想想建造房子。编写代码就像砌砖。这是过程中的一个重要部分，但远非全部。在砌第一块砖之前，你需要建筑师来设计整体结构，工程师来确保它不会倒塌，以及项目经理来协调建设的各个方面。砖块砌好后，你还需要检查员来检查质量，装修工来使其宜居，以及维护人员来保持一切正常运转。

软件开发也是类似的。实际编码只是一个漫长而复杂过程中的一步。在编写任何代码之前，程序员需要选择正确的技术，设计系统的整体架构，并规划不同组件如何交互。代码编写完成后，还需要进行测试、调试和持续更新。

AI 在砌砖方面相当不错。给它一个明确的、定义良好的小任务规范，它通常能生成不错的代码。但在宏观方面，它就不那么擅长了。AI 无法决定最初要建造什么样的房子，或如何构建它以避免在自身重量下崩塌。

这就是为什么认为 AI 会取代程序员的想法是错误的。这就像说电动工具会取代木匠一样。电动工具使木匠更有效率，但并不会消除对熟练工艺的需求。同样，AI 使程序员更有生产力，但并不会消除对他们的专业知识和判断力的需求。

事实上，编码本身通常不到程序员工作的一半。他们的其余时间花在理解用户需求、设计系统架构、编写文档、审查他人的代码以及管理整个开发过程等方面。这些任务需要对软件系统及其与现实世界的交互有深刻的理解 - 这是 AI 仍远未达到的。

此外，编程不仅仅是产生能工作的代码。它是关于产生可维护、可扩展和高效的代码。人类程序员可能会用 100 行优雅、高效的代码来解决一个问题，而 AI 可能用 1000 行功能性但混乱的代码来解决。短期内，两种解决方案都能工作。但从长远来看，人类编写的代码将更容易理解、修改和扩展。

这并不是说 AI 在编程中没有用。它绝对有用。AI 驱动的工具可以帮助程序员更快地编写代码，更早地发现错误，并自动化重复性任务。它们正成为程序员工具箱中不可或缺的一部分。但它们是工具，而不是替代品。

过度炒作 AI 的编程能力的危险在于，它可能导致对软件开发实际涉及内容的不切实际的期望和误解。这可能导致企业和个人做出糟糕的决策。一家公司可能认为他们可以解雇开发团队并用 AI 替代，结果发现自己面对一堆无法维护的代码，而且没有人理解它们是如何组合在一起的。

对于有抱负的程序员来说，信息很明确：不要担心 AI 会夺走你的工作，但要学会在工作中有效地使用 AI。未来的程序员不会被 AI 取代，但他们会使用 AI 作为强大的工具来增强自己的能力。

最终，AI 和程序员之间的关系可能更多是共生而非对抗。AI 将处理更多的常规编码任务，让人类程序员能够专注于需要创造力、战略思维和对复杂系统深刻理解的软件开发的高层面。

因此，虽然 AI 确实正在改变编程领域，但它并没有取代程序员。它在增强程序员的能力，使他们更有生产力，并允许他们应对更复杂的挑战。编程的未来不是 AI 代替人类程序员 - 而是 AI 和人类程序员共同合作，创造比以往任何时候都更复杂、更强大的软件。

---

第二个版本

---

AI 和编程：工具还是替代者？

最近有很多关于 AI 能否取代程序员的讨论。作为一个长期关注这个领域的人，我觉得有必要澄清一些误解。

首先，AI 确实在编程领域有着独特的优势。有三个主要原因：大量的文本资料可供学习，代码本身就是文本，以及代码可以立即运行验证。这使得 AI 在生成代码片段方面表现出色。

但是，把这些代码片段组合成一个完整的、可靠的应用程序，还需要大量的人工工作。这就是很多人忽视的部分。

实际上，在一个程序员的日常工作中，真正的编码时间可能不到 50%。剩下的时间用在哪里？技术选型、架构设计、文档编写、学习新技术等等。这些工作目前 AI 还难以胜任。

让我们以一个独立开发者为例。假设他要开发一个小应用，可能会这样分配时间：20% 用于技术选型，50% 用于实际编码，15% 用于文档，15% 用于学习相关技术。你看，编码只是整个过程的一部分。

更重要的是架构设计。好的架构比好的代码更重要。AI 可以加速我们尝试不同的架构，但它无法直接给出最佳方案。这需要人类的经验和判断。

然后是测试和质量保证。软件不能只是「偶尔能运行」，它需要在 99.9% 的情况下正确运转。确保这一点需要全面的测试，这是 AI 目前还难以完全接管的领域。

还有部署、版本迭代等工作。这些都需要对整个系统有深入的理解，而不仅仅是对单个代码片段的理解。

所以，虽然 AI 是一个强大的工具，但它还远远不能取代程序员。实际上，我认为过度夸大 AI 的能力是有害的。它可能会误导人们，影响教育和人才培养决策。

那么，程序员应该如何看待 AI？我的建议是：必须用 AI 编程，但不要认为它能完全取代你的工作。相反，要学会如何有效地使用 AI 工具，提高你的工作效率。同时，要更加注重提升你的系统设计能力和问题解决能力，因为这些是 AI 难以替代的。

最后，我想说的是，编程远不止是写代码。它是关于解决问题，设计系统，创造价值。这需要人类的创造力和判断力。AI 是一个强大的助手，但还不是一个完全的替代者。至少现在还不是。

---

方军：我现在自己辨别 AI 生成的能力已经很强了，基本上一眼就知道旺柴避坑能力强

2024-07-18 23:22

方军：我觉得大众依着老习惯希望接受改写后的，但其实以我们自己看互联网的经验，这种内容其实很难被接受和消化。

2024-07-18 23:23

### 52

方军 2024-07-18

摘：OpenAI 提出了一种新方法来提高模型输出答案的可读性确保输出易于理解

研究表明，仅通过优化链式思维（Chain-of-Thought，CoT）来仅仅追求答案的正确性，可能会降低可读性，让答案变得难以理解。

为了解决这个问题，OpenAI 提出了一种新方法：

采用了「证明者 - 验证者游戏」的方法来提高语言模型输出的可读性和可验证性。

要求强模型生成的解决方案能被一个更弱的模型（verifier）容易地验证。

也就是用一个强模型来生成答案，一个弱一点的模型来验证答案。

研究团队让这两个 AI 反复进行一个类似游戏的过程。

在这个过程中：

强 AI 生成答案：强 AI 尽量生成正确的答案，有时候还会故意生成一些看起来正确但其实错误的答案。

弱 AI 检查答案：弱 AI 尝试识别这些答案是否正确，并学习如何更好地判断答案的正确性。

在每一轮训练中，强 AI 和弱 AI 都在学习和改进。强 AI 学习如何生成既正确又容易理解的答案，而弱 AI 学习如何更准确地识别正确答案。

经过多轮训练后，强 AI 逐渐变得更擅长生成易于理解的正确答案，而弱 AI 也变得更擅长检查这些答案。

最终通过让验证者和证明者不断交替训练和评估，确保最终的解决方案既正确又易于理解和验证。

论文：

[cdn.openai.com/prover-verifier-games-improve-legibility-of-llm-outputs/legibility.pdf](https://cdn.openai.com/prover-verifier-games-improve-legibility-of-llm-outputs/legibility.pdf)

### 53

方军 2024-07-19

欧盟在数据方面就是深井冰

Meta 停止在欧盟发布人工智能模型高级版本

鞭牛士报道，7 月 19 日消息，据外电报道，马克·扎克伯格的 Meta 将不会在欧盟发布其人工智能模型的高级版本，并将这一决定归咎于监管机构的不可预测的行为。

Facebook、Instagram 和 WhatsApp 的所有者正准备以多模式形式发布其 Llama 模型，这意味着它能够跨文本、视频、图像和音频工作，而不仅仅是一种格式。

Llama 是一个开源模型，用户可以自由下载和调整。

然而，Meta 的一位发言人证实，该模型不会在欧盟上市。这一决定凸显了在监管环境愈发严格的情况下，大型科技公司与布鲁塞尔之间的紧张关系。

该发言人表示：我们将在未来几个月内推出多式联运 Llama 模式，但由于欧洲监管环境的不可预测性，我们不会在欧盟推出。

布鲁塞尔正在推出《欧盟人工智能法案》，该法案将于下个月生效，同时将以《数字市场法案》（DMA）的形式对大型科技公司实施新的监管要求。

然而，Meta 对多模式 Llama 模型的决定与其是否符合 GDPR（通用数据保护条例）有关。Meta 已被勒令停止使用欧盟 Facebook 和 Instagram 用户的帖子训练其 AI 模型，因为担心它可能违反隐私规则。

负责监督 Meta 是否遵守 GDPR 的爱尔兰数据保护委员会表示，正在继续与该公司就模型训练进行讨论。

然而，Meta 担心其他欧盟数据监管机构可能会干预监管过程并停止审批。Llama 的文本版本已在欧盟推出，新的纯文本版本也将很快在欧盟发布 —— 但这些模型并未使用欧盟 Meta 用户数据进行训练。

此前，苹果公司上个月宣布，由于担心违反 DMA，它将不会在欧盟推出部分新的人工智能功能。

Meta 一直计划在 Ray-Ban 智能眼镜和智能手机等产品中使用其多模式 Llama 模型。Axios 最先报道了有关 Llama 的决定。

Meta 周三还宣布，在巴西政府对使用用户数据训练模型的隐私问题表示担忧后，该公司已暂停在巴西使用生成式人工智能工具。该公司表示，已决定在与巴西数据管理部门进行谈判期间暂停使用这些工具。

### 54

方军 2024-07-19

我至今对用 AI 写作的人（不管用它做全流程、还是用它输出最终结果）表示不解。

这得无知到什么程度！

这样做的人，在任何方面都很无知，对人类也毫无理解（人能很轻松地识别 AI 写作内容）。

AI 用于理解，AI 不要用于输出。

某种程度上，AIGC 是个极具误导性的名字。（生成式 AI，generative AI，相对要一些。）

### 55

方军 2024-07-19

108 AI：普通人只看效果

在用 AI 的时候，「普通人只看效果」：能用来做什么？能帮我做什么？这也没什么不对，但我有点感慨的是，他们不想看背后的工作原理。

刚刚画了四张图，说说我的理解，毕竟，如果他们能够懂一点点背后的，会让 AI 更好地帮到自己。

第一张图：超越界面

多数人对 AI 的认识已经不错了，大概就是两种：

1. 提问，提问被大模型（LLM）处理。

2. 用界面提问，提问被提交到大模型。

有这两种认识也不错，由此，他们会对如何提问开始感兴趣，也即，如何写更有效的提示语，

第二张图：学会提问

这一年多时间，不管是公开、还是是对朋友，都说了不少提问方法。刚刚画图时简单列了一下，大概就是这么几种提问方法：

1. 提示语模板。

找到一些可用的提示语模板，然后就可以奏效了。网上可以找到很多提示语模板，我们自己也都收集了不少，比如：「请返回你仔细阅读后精心撰写的笔记。」

我们还更进一步，采用了 AI 应用开发工程师们常用的模板结构，并将之命名为 ICDO（Instruction 角色与指令，Context 背景信息，Input Data 输入数据，Output Indicator 输出指示）。

2. 带资料提问

我们很快发现，AI 翻翻回答的效果不够好。它的知识库固然很大，推理能力也不错，但针对我们的具体问题，它回答得不够好。

一个最简单的思路就是带着资料提问，它能够快速理解我们给的资料。比方说，我们常用的编程 Github Copilot，它实际上提供了两种资料：第一，相关的语言知识库，第二，我们当前的项目中打开的标签页的代码。

对普通人来说，我们最近一直推荐 Kimi，原因就是它最早把搜索放在界面里，每次回答时自动取搜索。当然，我们也推荐提问时提交文档过去。

3. 提问清单

当我们的任务比较复杂时，我们会发现一次性完成任务的效果并不好。对于了解原理的人来说，就是所谓思维链（Chain of Thought，CoT），或者 OpenAI 提问最佳实践中建议的，将大任务拆分成小任务。

那么对普通人来说，实践下来，比较简单的做法就是带着一堆问题去提问。因此，我在今年初的几次直播教人用 AI 之后，就逐渐地形成了一个套路：

每次腾讯会议直播是探索一个大问题，我的辅助 PPT 就是一组问题清单，一般四五个问题。我的 PPT 每页一个问题，问完直播也就结束了。

4. 文本转换任务

虽然 AI 的能力很强，但很多人在用的过程中也逐渐发现（进入 2024 年大家都务实很多），大模型（LLM）真正本质性的能力是进行文本的转换。

就如最早 Transformer 论文（及通俗介绍文章）所展示的场景：

我输入英语，你输出法语。

即便 AI 有知识库、有推理能力，但如果将任务都拆解为近似于文本转换任务，它的效果会好很多。

比方说，一个看到的写作工作流是这样的（我不鼓励用 AI 写作），你可以看到几乎都变成了文本转换任务：

根据视频写作工作流

- 将英文视频中的音频转换为文本脚本

- 将文本脚本转换为详尽、结构化的要点

- 根据要点撰写英文文章

- 采用直译、意译、审核等步骤，将英文翻译为中文

5. 别忘记审核

我们过去讲了很多大模型的幻觉，其实就是为了强调，别依赖 AI，你得自己有判断力。

后来我们逐渐地放松了要求，AI 的回答你至少得审核一下。更准确地说，放松了对普通人的要求，我们自己在使用中时不敢放松的，

这个话题就不多说了，最近的文章讨论不少。

第三张图：工作流

第三张图这里就简单提一下。逐渐地，现在人们开始提及 AI 工作流。

它实际上就是我们很早就意识到、然后在用 LangChain 时注意到的：

多次调用模型，可以得到更好的效果。

或者说，按照某个既定的步骤，一步一步地调用模型。

这就是 LangChain 名字中的 「Chain」。工作流现在逐渐地被更多人能用上，一种有力的工具是图形化的工作流。

现在， Coze、Dify 都提供了界面，让较为专业的用户可以通过拖拽模块的方式组建自己的工作流。

同时，我试用后发现，它们更吸引人的是，它们提供了多种工具，比如搜索、Twitter 搜索等等，让工作流可以变得有用起来。

第四张图：场景

我一直有个强烈的感受，其实我上面讲的这些，普通人并不关心。比如前几日去书店，看到的 AI 使用书籍，多数就是列举场景。

有这么一些场景可以用。

你这么用就可以。

你可以用 AI 帮你完成各种任务。

这很符合大众的期待，大众要的是效果。

至于是不是可以呢，难说。我一直夸奖李一舟做的 AI 大众普及很好，因为在大家都不知道的阶段，让人了解了各种场景，并提供简单的工具让热可以实际尝试。公平地说，虽然他有很多争议，但他一年前做的，比现在那些书都要好。

接下来要说的话我都可以省略了，因为我还不知道如何去面对大众的期待。

方军：AI 的总结：

观点

普通人使用 AI 时更关注其效果而非工作原理，这种现象虽然没有问题，但如果能理解背后的原理，AI 可以更好地帮助用户。

提问技巧的重要性：通过提示语模板、带资料提问、提问清单和文本转换任务等方法，可以提高 AI 回答问题的效率和准确性。

AI 工作流的优化：通过多次调用模型和按照既定步骤逐步调用模型，可以获得更好的 AI 效果。图形化工作流工具的使用可以帮助用户更容易地组建和管理工作流程。

AI 应用的场景化：普通用户更关心 AI 能够解决的具体场景问题，而不是技术细节。AI 的普及应该更多地展示其在不同场景下的应用和效果。

对 AI 回答的审核：即使依赖 AI，用户也应保持自己的判断力，对 AI 的回答进行审核，以确保信息的准确性和可靠性。

2024-07-20 20:35

方军：我现在有点觉得 AI 总结有点过于干巴巴

2024-07-20 22:09

---

这篇不是吐槽，分享好多用法，简单列了一下，大概就是这么几种提问方法：

1. 提示语模板
2. 带资料提问
3. 提问清单
4. 文本转换任务
5. 别忘记审核

### 56

方军 2024-07-19

幻方/deepseek 创始人专访

[AI界「拼多多」：一家可能改变中国大模型牌局的公司｜36氪独家](https://mp.weixin.qq.com/s/OQd-AdUBzqg7Pwoy7DIiuQ?v_p=90&WBAPIAnalysisOriUICodes=10000001&launchid=default&wm=3333_2001&aid=01A0VjFEC-8TX6msntzx_IZJsVSdIBL5NqzASu9SjrmTcS5LA.&from=10E6393010)

[疯狂的幻方：一家隐形 AI 巨头的大模型之路](https://mp.weixin.qq.com/s/Cajwfve7f-z2Blk9lnD0hA)

### 57

方军 2024-07-21

这个很值得关注：

[【第3321期】在 Chrome中直接调用大型语言模型的API](https://mp.weixin.qq.com/s/XawK1-kSzjRfVYviigw04A)

### 58

方军 2024-07-21

是的，学什么不重要，用什么更重要

资料：字节跳动旗下的抖音学浪 APP 突然宣布，将在 2024 年 7 月 31 停止服务；

阿里巴巴也宣布，撤销淘宝大学，变成淘宝教育，不再开发新的课程；

腾讯课堂 8 月 1 日起，停止所有在线课程的访问服务，将于 10 月 1 日停止运营，届时全面停止所有平台服务。

燕处：现代不再是看你学了什么，而是看如何去用或能创造什么，要学什么包括怎么学已不再是问题，问题是为什么学，如何保持持续的内驱是这些线上课程的难点。真有内驱自学力强的又不一定会选择这种形式。能知识付费的可能更多基于一种粉丝效应。

### 59

方军 2024-07-22

是的，他说的注意事项是最真切的感受：你需要对应用程序的架构有非常好的理解，包括宏观视角和更具体的代码层面

www.reddit.com/r/ycombinator/comments/1e7rtdw/comment/le8c2xw/

[首次创业，9 个月内月入 10 万美元！YC 大佬分享致富秘籍：靠它开发速度翻 10 倍！](https://mp.weixin.qq.com/s/QjGj1HjOhqmGESd34W6JJA)

YC CEO 转了一个 Reddit 的帖子爆了 200 多万浏览。

（归藏）大致意思是原作者认为和 Claude 协作编程极大的提高了他的工作效率。

还介绍了一下他跟 Claude 的协作流程和一些注意点。

ottogrid 的 CEO 也表示他们的代码库有 50% 是 AI 写的，明年会提高到 80% 。

和 claude 的协作流程：

1）仔细考虑这个功能，可能会与 Claude 讨论

2）为这个功能写一个基本规格说明（通常只是一段文字和几个要点），也会在这里与 Claude 进行迭代

3）确保向 Claude 提供所有相关背景信息，并请求实现代码

协作注意事项：

你需要对应用程序的架构有非常好的理解，包括宏观视角和更具体的代码层面，比如你如何处理数据获取的设计模式等。

如果你在这方面没有经验（通过成为一个优秀的程序员获得），然后直接使用 Claude，我认为代码库通常会变得过于混乱和复杂，导致以后很难做出更改。

### 60

方军 2024-07-22

这个 AI 硬件产品很酷啊

Plaud 身上有 3 个麦克风，其中 1 个是震动传导传感器（VCS），另外 2 个则是用来采集外部环境音的空气传导传感器。

[靠给 iPhone 做背贴 AI 录音机，这个华人团队众筹超 1000 万美元](https://mp.weixin.qq.com/s/QcPhHpJ8hx7LTYm5WLHNiw)

### 61

方军 2024-07-22

阳志平老师的《工作的心智》几个月前拿到就快速翻阅，当时就觉得非常棒。最近才开始深入地细读，贴一篇或许可以和第二章「作品」中《用作品牵引学习与工作》这篇补充的文章。

《毕加索四环：产出、作品、产品、销售》

我有个自用的说法，过去我常说：产出 - 作品 - 产品，后来去年加上一环变成：产出 - 作品 - 产品 - 销售。这篇文章是去年夏天写的，我将之称为「毕加索四环」。销售这个问题上，我自己个人一直做得不是很好，还在持续锻炼。

这篇分享跟 AI 关系不大的，但实际上我认为跟 AI 关系很大，AI 来了，我们每个人的角色是什么？

---

毕加索的伎俩：产出、作品、产品、销售

2015 年，毕加索画作《阿尔及尔女人》以 1.79 亿美元的价格拍卖，创造了当时艺术作品的最高价格 [^1]。但上个世纪初，年轻的艺术家毕加索刚从西班牙到巴黎时，过得可是相当穷困潦倒。《毕加索传》写道，一天，他画了一幅蜡笔画想换点钱却没能成功，他只能绕到朋友的画室去了，人不在。出门再遇到朋友时，毕加索说：「大门开着。我看见桌上有面包，就拿来吃了。看见有几个硬币，我就拿来揣在兜里了。」[^2]

他想了个办法。他雇了几个大学生，让他们每天都到巴黎的画廊转悠，走的时候问老板：「请问，你们这里有毕加索的画吗？」「请问，在哪里能买到毕加索的画？」「请问，毕加索到巴黎来了吗？」不到一个月时间，巴黎画廊老板都听说了「毕加索」这个名字。[^3]

在《毕加索传》，我没找到这个故事，它多半是人们编的。不过，这颇符合是天才、但又大肆营销的毕加索的形象。他的另一个朋友就曾经说，「涉及到买卖时，毕加索就仿佛置身于斗牛场上，会毫不犹豫地挥舞红绒布旗。」

毕加索的技巧要高明得多。

1905 年，毕加索在巴黎遇到了美国女收藏家格特鲁德·斯泰恩、她的哥哥利奥，他们买了第一幅毕加索的画《拿着花篮的少女》，毕加索也成了斯泰恩巴黎大宅中沙龙聚会的常客。格特鲁德、利奥、还有他们的哥哥迈克都是毕加索热情的购买者和收藏者。

毕加索主动提出替格特鲁德画一副肖像。此后，每一天格特鲁德都来到毕加索的画室。毕加索显然对为她画肖像非常上心，他画了不下 80 次。最终，1906 年 5 月，他终于画出来了，他跟格特鲁德开玩笑说，「我再也不想到处看见的都是你了。」[^4]

毕加索很清晰地知道，格特鲁德·斯泰恩在巴黎艺术界的影响力，他们比前面故事中假扮顾客的大学生更能促进他的名气和销售。

我们每个人都听过毕加索很多名言，并受到启发。比如，我们都因为乔布斯重复毕加索的名言，而知道「好的艺术家复制，伟大的艺术家偷窃。」（ Good artists copy，great artists steal. 一个有趣的翻译是「能工摹其形，巧匠摄其魂。」）比如，「你能想象的一切都是真实的。」又比如，「我总是做我不能做的事情，以便学会如何做。」

我们也都一次次看到毕加索 11 次绘制公牛的图片，最开始，公牛很具体，但逐渐地，公牛变得简洁、只有极少的几个线条，但清晰地看出是一头公牛。我们得出做减法的启示。

但是，我很想说，如果能更早些注意到、并实践上面说的「毕加索的伎俩」就好了。接下来，就让我来说说「产出 - 作品 - 产品 - 销售」这个四环工具，这是我自己的最常用工具之一。在重新发现了毕加索的意义之后，我决定称之为「毕加索四环」，向他致敬。

[^1]：毕加索油画创下艺术品拍卖史上的最高价，2015 年 5 月 14 日，https://cn.nytimes.com/culture/20150514/t14picasso...

[^2]：《毕加索传：创造者与毁灭者》，P.51

[^3]：《毕加索的「开挂」人生：艺术家之外更是位善于自我营销的出色商人》，李炫芷 / 文，2019 年 6 月 19 日，北京晚报

[^4]：《毕加索传：创造者与毁灭者》，P.70-71

\## 毕加索四环：产出 - 作品 - 产品 - 销售

见图 2：毕加索四环：产出 - 作品 - 产品 - 销售

输出决定一切。费曼学习法的践行者都清晰地理解这一点。我也清晰地知道这一点，并且，我还更进一步地理解这一点，我们的输出有如下几种，这里选用艺术领域的英文词来与四环作一一对应：

- 产出（Draft），也就是笔记、草稿、习作。这样的产出，能够反向促进知识的输入和消化吸收，能够增强我们的技艺。

- 作品（Artworks）。但是，我们不能停留在产出，我们要努力地做出让自己「自得」的作品，我们从模仿走向了创造。一般来说，作品要有较好的完整性，有一定的独创性。

产出表明的是，「我能做」， 而作品表明的是，「我真能做」。

这就够了吗？在工作中，我们很快发现，我们需要再往前进一步。在互联网工作中，我们会发现，我们的努力最终凝聚到了服务用户的产品之中，不管这个产品是一个网站、一个 APP、一个软件，或一个微信号、一个在线课程。

- 产品（Goods）。产出、作品必须得继续往前进，演变成「产品」（也可称商品）。作品与产品的区别是，作品是给自己的，产品是给他人的。聚焦于产品时，我们关注的是他人的需要。

我和很多人曾经的错误就是，止步于「产品」。直到在挫折中逐渐地明白，我们还需要再往前进一步，并且这是非常困难的一步：

- 销售（Sales）。我们要像毕加索那样，努力地做营销和销售。在说出来之后，道理是不言自明的，产品是我们认为「他人需要」，销售是证实「他人真需要」。当然，想到和做到有着巨大的鸿沟，我们持续地学习。

输出决定一切。但我们必须仔细地看「输出」的每一环，从产出、到作品、到产品、到销售。有些时候，我们做出让自己自得的作品就够了。但在这个社会中的绝大多数情景中，我们需要输出他人真需要的。

这时，我们再回头看毕加索绘制格特鲁德·斯泰恩的肖像，他实际上是先确认了真正的需要，然后再绘制草稿、绘制正式作品，最终完成这幅画。《格特鲁德·斯泰恩的肖像》是艺术史上最优秀的油画肖像之一，现在被收藏于纽约大都会艺术博物馆。

我们不重视第四环「销售」，一方面是因为，我们往往轻视商业思维。我们倾向于认为，作品代表着意义，销售过于强调利益，而不理解销售是确认他人是否真的需要的唯一途径。另一方面也是因为，多数人往往缺少走完整个闭环的机会，无从享受完成闭环所带来的收益、体会它带给自己的成就感。

放在学校学习的场景里，我们会发现，学习的输出往往聚焦在「毕加索四环」的第一环里面。随着教育阶段的上升，中学阶段开始有作品的影子，但通常多数人要到大学阶段才会接触到创业，而仅有实际创业的人才会考虑产品与销售这两环。其实，更早地考虑和实践后面的几环，能够更好地通过输入促进知识的输入和吸收。

\## 如何做？

如何运用「毕加索四环」呢？我们可以继续去毕加索的经历里寻找启发。

毕加索的成名作是 1907 年《阿维尼翁的少女》（简称《少女》），他挑战了欧洲绘画传统中用来表现深度与距离的线性透视法。在受到塞尚作品的启发后，毕加索「在一幅画中用多种视角来描绘物体、人物和场景」，从而与乔治·布拉克等艺术家一起开创了立体主义 [^5]。在这幅现在陈列于纽约现代艺术博物馆的成名作中，毕加索也形成了自己的风格 —— 立体主义，几何图形，色块。

《少女》背后，是毕加索画满整整 16 本素描本的草稿。从 1906 年秋天到 1908 年春天，毕加索尝试各种画法。除了艺术技法之外，有趣的是他的几何实验。在第五个素描本中，他用几何块绘制了站立的人体。在一幅女人头部的草图中，他用简单的线条绘制，鼻子是奶酪的形状，双眼不在一条线上。到了第八个素描本，极致的变形开始发生。最终，《少女》中的五个女人全部变成了几何图形。

这是毕加索的练习，最终凝聚成让他自得的突破性作品。作品逐渐地被艺术家朋友知道了，毕加索的画室总是人来人往，他喜欢邀请朋友来看他进行中的画作。在艺术圈内，这是成功的作品，毕加索的朋友和竞争对手马蒂斯夸张地「扬言要跟毕加索算账，要让他求饶」。

但出了小圈子，这幅作品的命运并不好。它得不到认可，也卖不出去，也没有展览的机会。直到 10 年之后，1916 年它在昂坦沙龙的法国现代艺术画展中第一次展出，正是在这个展览中，策展人萨尔蒙给这幅画命名为我们现在所知的名字 [^6]。

不过，在这十年间，毕加索没有闲着。他和布拉克一起继续创造，他们的风格获得了「立体主义」名字，吸引了很多的艺术家同行加入这个浪潮。

[^5]：《现代艺术的源代码》，「立体主义」、」阿维尼翁的少女」等词条。

[^6]：《爱因斯坦·毕加索：空间、时间和动人心魄之美》

由此，我们可以先得到数个「如何做」的启示：

产出：

- 大量地撰写笔记与绘制草稿

- 公开地练习，向你的朋友展示

作品：

- 发现并发出自己独特的声音

- 如果可能，像「立体主义」那样命名

在互联网时代，我们所遇到的最大变化是，每个人都可以公开地练习。你可以用博客展示自己的习作，你可以在社交媒体上分享自己的笔记。你可以在私密的微信群中建立起朋友们人来人往的工作室，向他们展示自己的产出与作品。

从一个独特的角度看，毕加索可能是最具互联网时代特征的艺术家。除了在顶级的艺术馆你会遇到他的代表作之外，实际上，在他的几座专门博物馆，你会看到超大量的作品，也有人尖刻地说那是平庸的作品。毕加索可能也这么看，他去世前买回来大量的自己作品。

在互联网时代，如果你想创作自己的作品，你面对的正是这样的情形：试图搞出一个惊人的作品一鸣惊人行不通了，你必须像毕加索那样大量地创作。

你可能已经注意到了，现在当人们谈起艺术时，同时谈起了的是「天价艺术品」。其实，艺术一直和金钱相随。有这样一个逸事，有人问毕加索，你如何看自己的这幅作品？「二十万美元。」艺术是艺术，同时，艺术品也是商品。

如果我们去看毕加索之后的现代艺术家的时候，我们会更明显地看到这一点。日本艺术家村上隆有独特风格的艺术作品，同时又为路易威登联名推出商品。川久保玲、草间弥生也是如此，同时，她们还售卖着各种各样的艺术衍生品。

在现在的艺术领域有着复杂的商业链条，包括画廊、艺术博览会、拍卖公司、商业品牌以及媒体等等。艺术家们在售卖产品时，通常会跟这些机构合作。有意思的是，正如经济学家唐·汤普森在讨论艺术市场的《疯狂经济学：让一条鲨鱼身家过亿的学问》中所展示的，「画商的地位越高，画廊就越不像企业，商业气氛也就越淡。明星画商的画廊会让人觉得像一座美术馆，里面的展品也从不标价。」

在《毕加索传》，几乎不讨论毕加索的商业策略的作者亚瑞安娜·哈芬顿在提及 1939 年毕加索为自己的展览做准备，写了这么一段话：「全世界都还不知道什么叫炒作造势时，毕加索已经把这一套把戏玩得很熟了。事实上，毕加索想尽办法来造势。他生活的每一阶段都在想法设法把作品的身家和自己编造的传奇经历捆绑在一起。」[^7]

[^7]《毕加索传：创造者与毁灭者》，P.229

由此，我们可以进一步得到「如何做」的启示：

产品：

- 将作品转变为多种形式的产品，转为考虑他人的需要

销售：

- 巧妙地、不懈地进行营销，实现销售

在中国的文化背景中，人们通常羞于直接地谈商业和生意，尤其当我们又在讨论学习这样的话题时。在艺术领域，人们也长期以来有一个类似的看法，贫穷的艺术家才能创作出充满激情的作品。产出与作品是艺术的生活，产品和销售也是艺术家的生活。

让我们以毕加索一个可能不那么知名的话来结束。在他去世时，他拥有 2.6 亿美元的财产，其中包括五万多幅画。毕加索的财富是通过销售产品实现的，他过了自己想要的生活：我想活得像一个贫穷的艺术家，但拥有很多钱。[^8]

[^8]：毕加索的名言原为「I'd like to live as a poor man with lots of money.」（我想活得像一个贫穷的人，但拥有很多钱。）

### 62

方军 2024-07-23

经过差不多一年，看 X/Twitter 的习惯从看「For you」彻底又回到了「following」。

在去年，生成式 AI 刚刚兴起的时候，For you 的确展现了很多新奇的内容。当时仅靠 following 还难以看到热闹的全貌。

但 For you 的推荐算法似乎在今年初发生巨大的「劣化」，最近的一次劣化应该是其被搞黄推的人攻破，甚至极端的时候变成不适合在工作场所查看（ NSFW ）。

另外，muted word 似乎并不能有效地工作。

7 月以来彻底回到 following，并持续地取消不合适的人（只要发不关注的内容的，立刻取关）。这样，Twitter 信息流才又变成一个基本上可看几次的状态。

一个大教训是，算法推荐，对个人来说，真的是大有问题的，要尽量避免。

### 63

方军 2024-07-23

最近一个人经常发 AI 硬件，我也顺便看到一些，当然依然保持不看不好独立硬件的看法。

[这家公司，想把 iPhone 装进一副无线耳机里](https://mp.weixin.qq.com/s?__biz=MTMwNDMwODQ0MQ==&mid=2653048234&idx=1&sn=fc8d9911c7990871c36fe343e097c975&chksm=7f5caa3cd2a7414e070848e6fdc6aa69b0b2a94aac1d5013163ca6efd89c6474ae73f5340df6&scene=0&xtrack=1#rd)

我虽对硬件没什么感觉，但纯从个人的消费来看：

即便我们这些自认为原以为信息、软件付钱的，最终还是为硬件付钱更爽快！

比如，最近买了一个 E-ink 阅读器，花了 3000 块。而且还会再买一个同款小的给人，1800 块。

这 3000 元要买实体书其实够去书店好机会。买得到的电子书会员，买十年。

题外话一句，我发现还是不得不去下载其他的 epub，因为得到的语音转文字太糟糕了。目前试下来，讯飞有声在付费后的语音效果是不错的。

方军：有时候，我也很像要一个硬件。

我前年特别找了半天，想找一个可与腾讯会议配合使用的硬件麦克

最关键的要再带关闭麦克的按钮

后来也的确找到一个，花了 500 块

但就用过一次，哈哈

2024-07-23 15:05

### 64

方军 2024-07-23

109 AI 辅助阅读：威尼斯一千年案例

这几天听书是再听盐野七生的《海都物语：威尼斯一千年》。我发现，听书我就听个大概，完全搞不明白：第一，搞不明白地理位置，我得打印出地图来，把各个城市方位画清楚，第二，搞不明白历史大脉络，这是一段我们非常不熟悉的历史。

用 AI 辅助阅读，我是尝试用 AI 来更深入地理解「威尼斯 - 热那亚之战」，这是发生在 1257 年 - 1381 年这个期间，两个意大利海洋城邦国家的之间的恶斗。

有意思的是，这个时期也略相当于在中国的土地上，元朝消灭南宋（1279 年），然后 1386 年元灭、明朝诞生的时期。

第一个问题：这四次「威尼斯 - 热那亚战争」是什么？

在书中，这是第六章《对手热那亚》的主要内容。具体来说，是「热那亚对决威尼斯、两个威尼斯男人、基奥贾战役」这几节，基奥贾战役最终决定了威尼斯胜、热那亚败。

这四次战争的前提是：1）威尼斯通过举国赞助第四次十字军东征，在东方贸易市场上占据了优势。2）两个城邦国家为了在海上的通行、巴勒斯坦阿卡、伊斯坦布尔和黑海周边的贸易利益展开恶斗。

看盐野七生的叙述，有个很尴尬的点。她叙述节奏缓慢有乐趣、有轻重缓急、有感情与分析，正如她在《海都物语》一书开头的致读者中引述古罗马文人贺拉斯：「为了令人生趣而写的文章，才是好文。」但她往往误认为我们对这段历史大脉络很熟悉。恰恰相反，我们非常不熟悉。

因此，我将内容给 AI，试图得到一个大体的脉络（下为简化，大体上是对的，但我就是用作参照、并再次确认与调整）：

---

1. 第一次威尼斯 - 热那亚战争（1257 年 - 1261 年）

- 主要战场：巴勒斯坦的阿卡地区。

2. 第二次威尼斯 - 热那亚战争（1294 年 - 1295 年）

- 主要战场：争夺黑海的贸易利益

3. 第三次威尼斯 - 热那亚战争（1350 年 - 1355 年）

- 主要战场：包括第勒尼安海、爱琴海以及塞浦路斯等地区。

4. 第四次威尼斯 - 热那亚战争（1378 年 - 1381 年）

- 主要战场：基奥贾（Chioggia）是这次战争的决定性战场。

…… 尽管热那亚在某些战役中取得了胜利，但威尼斯最终在整体的长期竞争中占据了上风，特别是在政治组织和社会治理方面展现出更强的能力。

---

就读书而言（这是一次以乐趣为主的读书），干巴巴的框架是没意义的。地图和框架是为了让我有个差不离的理解，然后能欣赏到其中的内容以及盐野七生的讲述。

我们就要进到具体的问题。接下来我就看第一次「威尼斯 - 热那亚战争」。

第二个问题：还是框架，第一次发生了什么？

这个就不需要 AI 了，我自己冒充 AI 来列一个：

- 在巴勒斯坦阿卡（现在的以色列阿克里 Acre）发生争执，引发两个城邦国家的战争。

另外，法国骑士团、圣殿骑士团以及其他国家商人也介入混战。

- 阿卡是威尼斯的叙利亚、巴勒斯坦定期商船航线的终点站。因此，威尼斯当年及次年迅速派出舰队，在阿卡取得决定性的胜利。

- 但是，热那亚背后推动了拜占庭帝国重新占领君士坦丁堡（即现伊斯坦布尔），拜占庭帝国的继任者尼西亚帝国回来了，而第四次十字军东征后西欧人建立的拉丁帝国（由威尼斯支持）被驱逐走了。

- 结果是，虽然威尼斯取得了阿卡的胜利，却丢掉了贸易上最重要的城镇。第一次「威尼斯 - 热那亚战争」和所有的战争都是因为经济利益而战，而威尼斯第一次看似赢了，实际上输了。

- 之后，威尼斯靠着各种花招，又重新回到君士坦丁堡。但是，已经失去了原来的优势地位。它能回去的原因，是拜占庭帝国的新皇帝发现热那亚并没帮上忙，而长期跟东地中海最强大的威尼斯为敌并不是什么好主意。

有了这个大脉络之后，我就可以用 AI 来了解更多细节。比方说，请 AI 简述其中一段历史（这段在这个 7500 字第一次战争的叙述中，占了 2000 字，也是盐野七生叙述的重点）：

我用的这个提示语：「请仔细阅读如下文章，给出你的读书笔记」。

结果如下（为部分摘录），这有助于我更好地理解这个过程。要注意的是，其实我对这段内容的信息是非常熟悉的，这本书我作为伴随读物读过不少遍，而这次这段特意听了两遍。这个内容非常适合已经知道了这个内容人来复习、强化脑中的印象（我目前看不出其中的错漏，认为相当准确）。

---

\### 读书笔记：威尼斯与热那亚的海上竞争

\#### 背景

- 慕达航线：1255 年，威尼斯建立固定航线，意图控制东地中海贸易。

- 独占君士坦丁堡市场：威尼斯一度独占君士坦丁堡市场，但无法彻底解决热那亚海盗问题。

\#### 热那亚的海盗活动

- 加拉太基地：热那亚在君士坦丁堡对岸建立基地，扩大活动范围。

- 游击战术：热那亚舰队因内部分歧，更倾向于游击战术。

\#### 两国的贸易策略

- 威尼斯：组织船队，配备护卫舰，注重安全。

- 热那亚：偏好单独或同速船队行动，军舰多用于军事和海盗活动。

\#### 威尼斯的固定航线策略

- 优点：集体行动降低遇袭风险。

- 缺点：

1. 缺乏纯军事舰队。

2. 船队庞大易成攻击目标。

3. 护卫舰被调离时商船无防备。

\#### 1264 年的冲突

- 格里洛的计谋：热那亚海军统帅格里洛利用假消息诱使威尼斯护卫舰离开。

- 结果：威尼斯商船队在无护卫情况下被热那亚攻击，损失惨重。

\#### 后续发展

- 威尼斯的调整：变得更谨慎，护卫舰不离商船。

- 热那亚的持续活动：海盗活动未减，贸易与海盗双重获利。

\#### 经济损失与战略

- 威尼斯：因军船多用于护卫，无法实施海盗，经济损失较大。

- 热那亚：通过海盗活动弥补贸易损失。

\#### 和平的实现

- 停战动机：威尼斯经济受压，希望停战。

- 法国国王介入：路易九世为十字军东征需要，促成双方停火。

\#### 后期发展

- 1270 年停战：在多方调停下，两国暂时停战。

- 地中海霸权：之后 25 年，地中海成为两国的舞台，经济显著发展。

\### 总结

威尼斯与热那亚的竞争体现了不同的海上贸易与军事策略。威尼斯的集体行动虽安全但存在局限，而热那亚的灵活战术使其在经济上更为灵活。

---

以上是用《海都物语》的第六章做的小小的 AI 辅助阅读练习。

方军：题外话，我发现其中我自己写的那个第一次威尼斯 - 热那亚战争的脉络笔记，更好地帮我理解。

2024-07-24 09:16

### 65

方军 2024-07-25

110 草台班子假设的新例子：翻译案例

这个世界就是个草台班子，对我来说，尤其是我们获取知识这个方面。之前有了互联网，现在有了 AI 蛮好的，我们可以自己去核实。AI 可以用来解释。

这本书整体上翻译非常棒，但是，如果不是对照，你不会发现很多细节其实错了，有时候不知道是不是有核心内容是反了。

（补充：经过中英文对照阅读，这本书的翻译实际上瑕疵还是不少。所以，或许我总是忘记，有一个经验法则：如果要真的读透一本书，记得读中英对照版。）

一个小例子如下：

---

That these four cannot be disentangled is something that is obvious when one has…skin in the game.

这四个方面的内容相互独立，不能混淆，而且，这四个方面的内容使得一个人直接暴露在交易的风险共担之中。

---

只要看第一个半句，就发现意思反了：cannot be disentangled，是无法分开的

以下为 AI 的回答：

---

根据英文，纠正翻译：

---

根据原文英语句子，我建议对中文翻译进行以下修正：

"这四个方面是无法分开的，这一点在一个人亲身参与其中时就变得很明显。"

理由如下:

1. 原文说这四个方面「cannot be disentangled"(无法分开），而不是「相互独立」。

2. 原文使用了「is obvious」（很明显），这一点应该在翻译中体现出来。

3. 「skin in the game」是一个习语，意思是亲身参与或直接面临风险。它并不特指交易风险，而是更广泛的亲身参与的概念。

4. 原文没有提到「使得一个人直接暴露在交易的风险共担之中」这样的内容，这似乎是翻译时的额外解释。

5. 原文的结构是当一个条件满足时（有亲身参与），某件事变得明显，这个逻辑关系应在翻译中保留。

---

方军：我有点想收回这本书翻译得不错的夸奖，比如，我一直好奇，为什么后面没讲巴以。

看原文原来不是这个意思。

看看他们的和平进程是如何把巴以问题拖入僵局的。

and examine how their peace processes create deadlocks，as with the Israeli-Palestinian problem.

看看他们的和平进程是如何制造僵局的，比如像巴以问题那样。

我这也不准确，但至少知道后面不是讲巴以问题。

2024-07-25 12:10

方军：这个小标题翻译为「学会做减法」

SYSTEMS LEARN BY REMOVING

意思上就不对，我也不知道怎么翻译（但能理解），比如：

系统通过移除来学习

2024-07-25 12:14

方军：看翻译书看不懂，经常的教训就是

可能翻译有问题

看英文吧

2024-07-25 12:15

方军：这样的翻译，算好吗？也许这是一种解读版吧。

>「风险共担」用淘汰傲慢自大者的办法，约束了人类的傲慢自大倾向。

> Skin in the game keeps human hubris in check.

> 整个「风险共担」系统会通过淘汰犯了错误的失败者来实现自我进化，这就是进化过程中筛选的力量 [^6] 。

> Systems learn by removing parts，via negativa.

2024-07-25 12:20

### 66

方军 2024-07-25

可汗学院的写作助手

[可汗学院发布写作AI助手Khanmigo Writing Coach](https://mp.weixin.qq.com/s/KNrzNdUaS6hNMbYpB5oUbw)

我觉得聚焦一点的会更容易、也效果更佳，比如雅思写作这个

[免费雅思作文评分批改 Check IELTS essay for free | ielts9.me](https://www.ielts9.me/)

### 67

方军 2024-07-26

基本的表达能力，真是很多中国普通人欠缺的，不补这一课，很难用好 AI：

陈仲凯：在美国念书，我观察到了有的教授们的一个优点：清晰地表达。他们在指导学生的时候，指令清晰地令人发指。比如约学生去办公室，会在邮件中写清楚坐电梯到几楼、往左拐还是往右拐、第几间办公室，等等。

说个反例，「我快到家了。」然后我以为你是要走进小区大门了，但实际上是你的地铁快要进站了。然后我就安排了网约车在小区门口去吃饭，网约车在那里左等右等。—— 更清晰地表达是「我快要到达地铁终点站了。」又比如，「老师我能拿到考研 60 分吗？」，—— 更好的提问是「老师，我大学过了四级，但是毕业五年忘得差不多了，现在暑假开始备考，每天两小时学习英语真题课程，我能拿到 60 分么？」

这种清晰表达的能力，在学校、在职场、在生活中处处都有。极为重要。它能提高我们的任务效率，能够降低很多误会。我承认在四六级考研写作、甚至很多中文的应试写作里，我们会使用很多套话和模版，来求个生存。但实际的表达能力，在现实中是非常非常重要的。

### 68

方军 2024-07-26

如何从大段大段的文字中（有效且快速地）获取信息，这真是一个难题。

我没怎么思考过这个问题，因为虽然读很多书，但都比较自然，而且舍得花笨功夫多读几遍。

如果已有很多大段多段的文字，要让别人能更快地获取信息，这是个很大的难题。本以为 AI 能帮上一些忙，但似乎不如预想乐观。

我目前认为的解决之道是让内容形态适应「skim reading」，意思是可快速浏览。

### 69

方军 2024-07-27

虽然我也用很多 RAG ，但我的确对 RAG 心有疑虑。

Ethen Mollick 教授的一个说明（2 尤其辛辣）：

Deleted a post on RAG talk-to-your-document models as I can't fit a critique into a post.

So，just warnings:

1）No one is testing the LLM output enough，it can be both true AND misleading

2）No one will ever click on the primary source

3）Users don't really understand them well

删除了一篇关于 RAG 与文档对话模型的帖子，因为我无法在一篇帖子中容纳一篇评论。

所以，只是警告：

1）没有人对 LLM 输出进行足够的测试，它可能既真实又具有误导性。

2）没有人会点击主要来源。

3）用户并不真正很好地理解它们。

### 70

方军 2024-07-27

111 人是干不过 AI 的，得另想辙

人的智能程度（智慧程度），肯定是远超过人工智能（AI）。但如标题所言，人是干不过 AI 的，人必须得另外想「辙」，和 AI 对着干，AI 会把人的路走了让人无路可走。

第一，人干不过 AI，是因为人很难批量化。

只要尝试组建过人工批量化流水线，你就知道，这太复杂、节奏快不起来。

比如，即便人与 AI 都能完成一个文档处理步骤，如简单一点的发现其中的语法错误。对比起来，人的弱势很明显：

- 人的速度很慢。
- 人的精确度不高。
- 人没法 24 小时工作。

对比而言，只要调试好了一个能够一次处理比如 300 单词的小模块，然后可以批量运行。这时，AI 的每秒 Token 输出不足的问题根本不是问题。

人还是有用的。即便不考虑流程设计、工作流、少量编程，这里如果让人来进行少量必要的最终确认，能大幅度提升质量。

第二，人不能重复循环，AI 可以。

还是以这种简化的任务为例，提高质量的一条路径是，把结果再次输入，再重复一回，甚至再重复三回、五回。

再一次，AI 胜过人。

如果让人组成的流程来重复，这某种程度是把人看成是「血汗工厂」的工人，或者说得不激烈一点，必须拿薪资这种「石油能源」去维持它。

而让 AI 流程干这种事很容易，再运行一次就好了。

（如果每次运行中能主动地调整，那就更棒了，但目前既没必要、技术上也不可信。对，没用错，不是「不可行」，是「不可信」，现在很多人讨论 AI 新功能时，常常说，可以做这个可以做那个，这是讨论可行，但达不到可用，因为不是从可信角度考虑的。）

人还是有用的。人不能是血汗工厂流水线的螺丝工，人要变成流水线的设计者、运行者。

第三，人干不过 AI，是因为 AI 进化快多了。

人当然可以学习、能够学习。如最近看塔勒布的书看到的一个意思，从长周期看，人类的进步，是通过筛选而来的。在生存竞争中，活下来的，掌握了前一代的智慧。因此，人的学习很难。

AI 的进化不是筛选机制。它的机制是什么我们并不太知道，因为当前的 AI 不是可解释的。但是，从人工神经网络的基本训练逻辑看大体是，结果反馈，调整参数，反复迭代训练。

我们现在看到的是，AI（特指大语言模型）的性能进化很快，至少在 2023-2024 这两年的周期内是这样的。

这带来的是，我们可以不断地更换新的模型。放在人那边，这种进化几乎是不可想象的。

人还是有用的。即便不谈 AI 模型的训练这个部分，就谈应用，人要走的路是选择模型，而不是亲自下场干活。在一些 AI 已经能干活的小方面，人必须得承认现实，AI 干得比人好。

（以上是搞 AI 工作流的随想，接着搞工作流去。）

方军：感慨，如果非要干 AI 能干的活，人是远远赶不上的，这是现实，这的确很像机器刚到来时的工人，卢德分子不是应对之道。

2024-07-27 10:20

方军：很多人对流水线有个误解，以为很快

其实去过丰田等日本式工厂就知道，我只去过日产，很缓慢。

前一段看马斯克传，其中提到他发现过度自动化带来的困扰，然后开始降低自动化程度到一个合适的限度（当然马斯克还有一个大招是最大限度地削减）

2024-07-27 19:14

### 71

方军 2024-07-29

宝玉翻译：LinkedIn 的这个分享很有价值，他们分享了在构建生成式 AI 产品时的一些宝贵经验教训

他们做的产品时基于 LinkedIn 上的信息流和职位，借助 AI 帮助用户评估是不是和职位匹配、了解某个公司的最新动态、面试和修改个人简历方面的建议，以及其他一些功能。

从技术架构上来说，是一个多智能体的技术架构，主要分成三步：
- 路由：确定查询是否在范围内，并决定将其转发给哪个 AI 智能体。智能体的例子有：职位评估、公司理解、帖子总结等。
- 检索: AI 智能体决定调用哪些服务以及如何调用（例如 LinkedIn 用户搜索，Bing 搜索 等）。
- 生成: LLM 根据获取到的信息、原始问题和上下文去生成答案。

这其中路由、检索可以使用小模型，但生成内容需要使用大模型，这样才能有比较好的生成效果。

在整个项目的开发过程中，挑战是多方面的，有来自团队协作的，有来自大语言模型本身的

1. 团队协作的挑战

首先在团队协作方面，最开始他们是按照智能体划分小组，各自负责，这样优点是开发速度快，但缺点是各自的提示词、对话历史、越狱防护等这些需要重复建设，用户体验不一致。

所以他们后来将组织架构进行了调整：
- 一个小组负责公共和底层框架，并且保证提供一致的体验，这样可以共享提示词模板、集中解决安全防护、统一用户体验等
- 多个小组负责垂直方向的智能体，基于公共组提供的框架优化提示词、连接后端 API等

2. 数据检索的挑战

LinkedIn 有大量的用户资料、公司信息、还有一些其他的信息，这些数据更新很快，并且没有被大语言模型训练过，所以当用户请求时，需要能检索到用户想要的数据，而基于生成式 AI 产品的交互，不再是传统的关键字+选项的检索，而是完全自然语言的检索，这就需要先调用一次 LLM 帮助将自然语言转化为 API 调用。另外传统的 API 是给传统的 App 使用的，返回的数据冗余很多，并不适合 LLM 使用，所以需要针对 API 做一些针对 LLM 的优化。

举例来说，用户可能会询问：“请给我推荐西雅图的待遇好的公司”，那么针对这样的查询，首先需要去根据用户的身份找出来用户自己的职业（比如Java后端开发工程师），然后将用户资料+咨询的问题+可用的检索API，一起交给 LLM，LLM 将请求分解成适合 API 查询的参数：
- 职位搜索 API
   * 职位：Java 后端开发工程师
   * 地点：西雅图
   * 排序：工资由高到低

然后去调用 API，API 返回结果后，将返回结果、用户原始问题、历史对话一起交给 LLM，最终生成答案。

3. 怎么稳定的让 LLM 返回结构化的数据？

真正做过 LLM 开发的都知道，虽然理论上 LLM 可以生成结构化的数据，但是真正生成的时候经常出错。LinkedIn 的做法是：
1). 使用 YAML 格式而不是 JSON，相对来说容错率更高
2). 用日志记录常见的 YAML 错误，优化自己的 YAML 解析器，可以解析 LLM 返回的不规范的 YAML
3). 如果还是无法解析则将错误信息交给 LLM 修复，并且不断优化提示词，提升 LLM 修复的成功率

最终结构化数据的错误率从 10% 下降到 0.01%

4. 如何减少幻觉、降低延迟和提升吞吐量

- 使用 CoT（思维链）可以有效提升质量和减少幻觉，但由于一些中间步骤不能显示给用户，要等前面的中间步骤输出完成才能给用户显示结果，这也会增加延迟
- 使用流式（streaming）输出可以提升用户体验，让用户尽早看到输出，但这在复杂的流程上有很多挑战
- 由于 LLM 调用可能需要很长时间处理，使用异步非阻塞管道可以优化服务吞吐量，从而避免因 I/O 阻塞线程而浪费资源。

5. 如何评估生成结果的质量

只有对生成的结果有科学的评估，才能不断优化生成结果，但如何评估生成质量是很困难的，主要表现在：
- 难以制定标准。以职位评估为例：点击“评估我与该职位的匹配度”然后得到“你很不适合”并没有多大价值。好的结果既要真实准确又富有同情心。
- 对数据标注很难规模化，主要得依赖团队成员和外部标注员
- 难以自动化，还是需要人工去标注，并且需要收集一定的数据后才能评估

最终LinkedIn的做法：
1). 工程师们先快速粗略评估，得到个大致的指标。
2). 标注员提供更细致的反馈，但需要大约 1 天的时间。
3). 最终由团队成员进行全面评估，但可能需要超过 3 天的时间。

具体内容建议阅读原文。

[Musings on Building a Generative AI Product](https://www.linkedin.com/blog/engineering/generative-ai/musings-on-building-a-generative-ai-product)

[构建生成式 AI 产品的思考 [译] | 宝玉的分享](https://baoyu.io/translations/generative-ai/musings-on-building-a-generative-ai-product?continueFlag=d58344f9b65c64dc2df7d8db38347005#google_vignette)

### 72

方军 2024-07-29

我对语音还是有疑问：

- 语音输入，我们人的特性，语音还是讲不清楚

- 语音输出，用语音获取信息，难度就更大了

因此，如果以信息获取来说，是一个大的降级

[GPT-4o 最关键功能本周上线，语音交互的时代终于要来了](https://mp.weixin.qq.com/s/hA6lLpiWTzThE6t5LoY9Ag)

### 73

方军 2024-07-30

112 AI 怎么读？人怎么读？

我们不知道 AI 怎么读，现在 AI 的工作方式是不可解释，这一点的确是有很大的问题。当然，看结果就好了。

目前理解 AI 工作方式，我们可以对照自己怎么做的。

以阅读为例，我看了一个不算太好的文字，我自我观察，我的阅读阅读方式是：

1）寻找结构：如图所示（该文PDF做部分隐藏后的版本），它用的“宏观与细节、主观与客观”这个分类框架

2）忽略：这篇文章的一些缺点让我必须采用这种读法，即忽略掉我认为非主要信息的。

3）疑问：这篇文章不太好，一个原因就是它的标题和内容之间有一定偏差。

因此，我补充写下疑问：

疑问：这是通用的有效分析框架，但这是有效的「考试应对方法」吗？

对这个疑问我的回答是：这个方法比较宏大，原则上当然是对的，但如果具体去看不管是中小学的阅读理解，还是雅思、托福、GRE/GMAT 的阅读理解，光靠这个方法离实用还是非常远的。

这篇文章我标注了两遍，其中有一遍是做了圈点的，图中未体现出来。

可以对比看出，目前用 AI 阅读似乎不是这么做的：

- 摘要：它总结的是对吗？还是仅仅变成可跳读的，以方便我们更好地阅读？

- 提问：具体的问，这个问题作者怎么讲的？（似乎必要性也不大，我们自己可以很方便地看到）

- 转为“问题-答案”：转为小测试，可以让我们了解自己是否掌握

- 进一步进行通用的询问：我不是很推荐这种用法，因为既然我们在依照材料进行讨论，那么还是设定一个界限较好。

那么，我这种阅读，如何可以用转为用 AI 来进一步提高效率呢？

### 74

方军 2024-07-30

就阅读而言，我发现删除是高效的手段之一

这也是我为什么觉得偶尔也需要电子书

如果准备大拆一番，在印刷书上大涂大改会很有压力（当然我没有，大不了再买一本），但电子书显然让这种压力降低到零

### 75

方军 2024-07-31

113 用 AI 快速读报告

要阅读一份英文研究报告，看它的价值是很高的，因为可以通过它了解一个非常不熟悉的细分领域。怎么用 AI 阅读呢？记录下我的实际做法（可注意到我用的依然是交互式）：

1、AI 辅助中英文对照阅读。

为了快速阅读，我经常用的方法是用沉浸式翻译来中英对照阅读。这份报告是一个 PDF，翻译的效果不如网页，但勉强可以阅读。

我也尝试用 elmo 来总结本地 PDF，但效果一般，放弃。

各类报告的优点是，大结构比较清晰，因此中英对照方便快速地浏览速读。速读时的重点也是其中的图示（这份报告是原理性的，因此多是结构图示，而非数据图表。）

2、用 Kimi 辅助阅读文本。

在有了基本架构认识之后，就用 Kimi 来辅助阅读。考虑到 Kimi 阅读 PDF 效果一般，我分两步：

第一步：用 Jina 来获得 Markdown 文档，不够好，但可以用。

第二步：用 Markdown 作为附件，进行对话。

常用的总结很一般，这也是因为文档过长、且它做的所谓结构性总结实际上是章节名，所以没觉得有附加信息。

因此我回归到常规的 AI 辅助阅读方法，针对其中的具体信息进行提问：比如某个项目的具体解释，某个原理的解释，某个疑问等等。

3、用输出来辅助阅读。

泛泛读是没意义的，因为如果不自己写一下，是无法理解的。因此，我撰写一个基础的介绍：

这个基础介绍的结构是：总体介绍，N 个看法（+ 图）。每个看法较为随意地写了 100 字左右。

这过程中没有用 AI 的辅助，因为如果还要靠 AI 去解释，那么就是超出自己的理解了。

但在后续补充时，我发现有信息点并不了解，因此返回去用第二步，进行针对性的提问。

这时，由于是要获取的是不熟悉的信息，因此不得不时时回到英文原文去进行关键词对照，以确认信息正确性。之前的步骤中并不需要这样做，因为之前的信息是相对有基础认识的，可以直接做出判断。

还有更好的办法吗？但即便就这样用 AI 来辅助，从一份高质量报告中获取信息的速度、效果都大大提升了。