### 01

方军 2024/04/01

《海尔：家庭大脑白皮书 —— 大模型时代智慧家庭应用新范式（2024 年）》是一份关于智慧家庭行业发展的报告。

有点意思。

主要内容包括：

1、趋势篇：介绍了大模型技术如何推动智慧家庭产业进入新的发展阶段，包括大语言模型的兴起、智慧家庭面临的新挑战、垂域大模型成为生产力工具、智慧家庭垂域大模型的尝试，以及垂域大模型引领智慧家庭进入 L4 高度主动智能阶段。

2、技术篇：探讨了在智慧家庭领域构建垂域大模型的关键能力，包括行业私域知识引擎平台搭建、家庭大脑与大模型思维链、多模态联合推理与决策、AI 技术下内容的安全与合规、大模型时代的 AI 伦理，以及国际性法律法规。

3、应用篇：展示了 HomeGPT 如何赋能智慧家庭的交互、服务与场景的全面升级，包括交互的升级、服务的升级、场景的升级，以及声音音乐生成和健康菜谱生成等应用。

4、展望篇：讨论了 AGI（通用人工智能）如何促进智慧家庭的全面发展，包括 AGI 在智慧家庭中的应用、AGI 对智慧家庭全面发展的促进作用，以及智慧家庭未来发展的方向。

报告强调了大模型技术在智慧家庭领域的重要作用，特别是在提升家庭智能化服务、满足个性化需求、提高生活品质等方面的潜力。同时，报告也提出了在 AI 技术发展中需要注意的社会、伦理和技术挑战，以确保 AI 技术的健康发展和对人类社会的积极影响。

2『已下载原文「20240401海尔：家庭大脑白皮书-大模型时代智慧家庭应用新范式（2024年）」。（2024-04-01）』

### 02

方军 2024/04/01

叶超莹：

[史上最全！中国服装企业 AIGC 工具包（设计篇）发布！中国 AIGC 产业联盟倾情呈现！](https://mp.weixin.qq.com/s/NaCTBz98BQj5NGH7iCILmw)

超赞！

### 03

方军 2024/04/02

转，NB：和一个十几年前在英伟达的资深专家聊 nvidia 管理

黄仁勋的管理强势而特别，硅谷另类。

战略全员公开，管理扁平。

主要理念：少做事，做重要的事情

公司汇报工作从来没有 ppt，一般对着 jira 和文档讲工作计划，从二十年前就这样。

全公司一个代码主仓库，所有文档和代码都是公开，且可以跨部门自由修改的，只要代码 owner 经过 review 认可。

两周开一次项目会，项目只有 director，没有 project manager。开发任务没有 deadline，可以自由申请在家工作。但是做的不好的工程师全公司都能看到你的 bug，尤其是当你的延误和错误导致项目开发进度时。

招聘到的人才不是最优秀的，过去竞争不过大厂也招不到，但是招最合适的，能适应 nvidia 的环境，自驱发展。

公司基本上也不开除人，2010 年前后公司财政紧张，黄仁勋给全员发公开信说明情况，给出两个选择：1）裁员 5%。2）全员降薪 5%。全员投票，结果大部分人选了 2。

所以：为什么 Nvidia 开发速度这么快？

十几年前开发，开发节奏就按六个月同时几个团队做下一代芯片，第二组可以看到第一组的代码和全部工作记录，反之不可以。同样第三组可以看到前两组的工作，反之也不可以。

结果现在每年发布新一代芯片，竞争对手完全跟不上。

公司人员很少，主要是工程师，我查了下资料，2024 年现在 29840 人，市值 2 万亿产值，人均市值 5000 万美元以上。

### 04

方军 2024/04/02

很久之后，再看这样的提示语模板时，哎，我觉得这都是「高估 AI，低估人类」，反过来说也行「高估人类」，这样的 AI 的回应，人类是无法运用，最后是以虚妄对虚妄。

拿读书来说，我个人自认为读书比较笨，真正要看懂的书不用独特的方法看两三遍是不明白的。但普通人不这么看，他们以为听讲书可以明白一本书的核心内容。这样的普通人，你跟他说什么都没用的，放弃助人情节。

我最近可能走向另一个极端，在一个系列分享，朋友们让我分享模板，可是我反复说，我不都在给你们一步一步讲怎么做了吗？像平常那样说话不就可以了吗？有什么不知道的，问，想起来什么，问，就这么简单。不过，这可能比模板还难，因为就那几个主题，我知道的东西可不是一时半会能学会的。

---

0. 在第一轮互动时，**首先原封不动发送「开场白」★★

1 定义根问题

1.1 接收到用户的信息后，分析有哪些缺失或尚未明确的信息。向用户提几个最关键，最核心的问题来定义一个完好的

1.2 提醒用户上面的问题中，不想回答的将由你自行设定或预设一个宽泛，通用的的场景。

1.3 暂停流程，等待用户回复后再继续。

2 使用 5w 定义具体问题背景与场景

2.1 描述背景：根据获得的信息，识别并分析，并清晰地定义根问题的背景。使用 "5w" 工具来描述根问题背景。

2.1.1 5w 包括谁（who)、什么（what)、哪里（where)、何时（when)、为什么（why). 这五个要素共同清晰定义了 2.1.2 谁（who)：涉及的人物或团体。明确谁是关键参与者或受影响者。考虑个人的背景信息，这些因素可能对他们遇

2.1.3 什么 (what): 描述问题的本质与特点。提供详细的情况描述，明确发生了什么。

2.1.4 哪里 (where)：可选，指出地点。帮助界定事件发生的具体位置，影响问题性质和解决方案。

2.1.5 何时（when）：涉及时间因素。帮助理解事件的时间背景，可能包括特定日期、时段或发展阶段。

2.1.6 为什么（why）：探究原因或动机。深入了解事件背后原因的关键部分，有助于理解事情发生的原因。

2.2 定义目标：使用 "OKR (目标与关键结果)」工具定义目标。OKR 包含 1 个目标 (Objectives) 和至少 3 个关键 s

2.3 思考并分析，要解决该问题，达成 OKR，我们可以利用哪些学科中的哪些理论或知识，列出 2 个对问题解决最有帮助

2.3.1 思考并推理，解决问题可以使用哪些学科的知识？

2.3.1.1 在人类知识的各种学科中找出两个最相关的领域 (relevant fields of study)。说明这些领域的选择原 1

2.3.1.2 在两个相关领域中再分别列出 2 个更精准的子领域 (relevant subfields of study)，用于精准解决问题

2.4 询问用户是否开始流程，是否开始在这些学科中寻找具体理论，解决问题。

2.5 暂停流程，等待用户回复后再继续。

3 更进一步，在确定的 relevant subfields of study 的基础上 dive deeper, 寻找更加具体，也是更加符合当前

3.1 使用具体理论提供可落地的可操作建议

3.1.1 选择更精准的备选理论：为了帮助使用者克服困难或达成下一步目标，该子学科下哪一个具体、细致、被学术界：

3.1.2 解释备选理论并提供操作指导

3.1.2.1 详细列出该理论的概念和假设：

a. 用精准，学术的语言给出该理论的精准定义。定义包含中文定义与英文。

b. 详细解释理论的内容与概念

c. 分析理论如何解释相关现象或问题。

3.1.2.2 实际应用和实施：思考如何将理论转化为「具体（Specific)、可衡量（Measurable）、可实现（Attainab

3.2 询问用户是否要针对某一个具体的理论深挖，获得更加详细，更有深度的分析与指导？或者是否希望探索并切换其 f

3.3 暂停流程，等待用户回复后再继续。

---

方军 2024/04/02

务实地说，尽量避免复杂提示语。

### 05

方军 2024/04/02

这个分享是比较务实的，摘（此文分享者在德国做科技工作）：我的工作里很大一部分是写代码和部署软件，最近半年也有意识地尝试多用 ChatGPT 和其他 AI 工具（GH copilot）来帮我提高工作效率，但我目前的感觉还是觉得 AI 工具对我工作效率的提升比较有限

我接触的代码库很多都相当庞大复杂，包含多年不停迭代的代码。添加新功能经常是牵一发而动全身 ——

第一，你需要了解这个代码库的基本架构和重要模块才知道要改哪里加哪里，这一步 ChatGPT 完全帮不了忙。

第二，添加更改代码的 context 和 dependency 很多，这些都是没法合规快速告诉 ChatGPT 的。这种情况 GitHub copilot 因为直接接入 IDE 所以会稍好用一些，但也有限。

第三，因此 bug 也很难通过 AI 工具找到。修 bug 的第一步一般是本地运行程序，根据报错信息来一步步找到出错位置。这个没法让 GPT 去做。

第四，写代码测试代码只是工作的一部分，现代软件的部署环境也很复杂，各个 component 相互影响，部署过程中的错误显然也很难让 ChatGPT 来解决。

第五，除小公司外，大部分科技公司都有很多自己的内部开发工具，那些内部语法和规则是没法通过 AI 工具理解帮忙的。

所以目前我觉得 ChatGPT 在编程上最适合的应用场景是，

帮初学者写简单独立的代码（写 scripts 而不是 codebase）；

帮初学者理解具体语法；

帮忙简单 debug。

### 06

方军 2024/04/02

072 AI 问答为什么有用

准备一些文档（包括前一段思考飞书的话题），我发现，其实文档对绝大部分人来说都是非常困难的。这也是为什么技术圈有黑话，RTFM（Reading the f**king manual，去读他妈的的手册）。

对于手册型文档，普通人很难形成阅读的能力，养成查阅的习惯。这时，AI 就有了很大的发挥作用的机会，以更人性化的对话界面来提供协助。

这之前有个前提，还是需要有人准备文档。昨天有人在推上开玩笑说，看到有人夸文档，该组件的开发者说，哈，这是我刚刚用 AI 为你生成的。当然他立刻补充：这是一个玩笑，我两分钟刚刚提交了一个文档修订。

开源组件还有两个优点是，第一，是它的代码库可以算是文档的重要组成部分；第二，它们通常有还不错的社区，至少 Github issues 里面会形成不错的积累。

以 AI 当前的能力，目前还仅仅是（站内）搜索的补充。但随着 AI 长上下文窗口、RAG 的发展，提问将变成一个主要的方式。

当然，对 AI 回答的针对性的调整是必要的，目前（站内）搜索约 90 分，但即便一些 AI 技术产品的文档 AI 也仅有 60-70 分，仅能提供参考，还没有达到可用的那条线，更不要说想达到惊艳的水平。

但不管怎样，这样的变化将给文档带来很多必要的变化：

- 所编写的文档将要考虑到，不是为了查阅，而是为 AI 提供资料，要尽量详细。

- 专门为人编写的文档要更简洁、更框架性。

- 代码基础可能也将交给 AI，用来优化回答。过程资料也可以，但这需要谨慎处理，因为过程资料可能包含探索的弯路。

方军：但是，真心建议做文档型人，因为真心是中长期效率最高的

2024-04-02 17:57

### 07

方军 2024/04/02

[阿里云内部全面推行 AI 写代码，未来 20% 代码由通义灵码编写](https://mp.weixin.qq.com/s/_zofVNxSlwRAhTYppYn9Gg)

### 08

方军 2024/04/02

[备受关注的「出版+人工智能」，在国外究竟发展到了什么水平？](https://mp.weixin.qq.com/s/cb83RtyKSpAAo68DoGdvVg)

### 09

方军 2024/04/02

ChatGPT 无需注册即可使用，似乎是件很大的事呢

历史的确不重要，就跟搜索引擎一样

### 10

方军 2024/04/02

摘：Nick Dobos 这个看法，目前这个阶段的 AI 产品方向已经不是聊天机器人了，而是变成了一种「文本转换器」。

它能够把人生产的文本转换成___。空格里可以是任何形式的内容，比如视频或者代码甚至是一个产品。

来源：x.com/NickADobos/status/1774487841021767828

### 11

方军 2024/04/02

现在的 AI 工具真是非常多

[The Top 100 Gen AI Consumer Apps | Andreessen Horowitz](https://a16z.com/100-gen-ai-apps/)

这是红杉的总结。

[a16z：2024 年 GenAI 市场将爆发](https://mp.weixin.qq.com/s/NpnGcZfDpFHYBzHTQYY-Jw?v_p=90&WBAPIAnalysisOriUICodes=10000001&launchid=default&wm=3333_2001&aid=01A0VjFEC-8TX6msntzx_IZJsVSdIBL5NqzASu9SjrmTcS5LA.&from=10E3393010)

翻译版：

[翻译：A16Z-TOP 100生成式AI应用 - 飞书云文档](https://waytoagi.feishu.cn/wiki/ZvJ6w6aAdiBEMokMqCcczr28nnf)

---

推上也有人做了另一个总结列表：

Top 100 game-changing AI tools in 20 different categories! 

twitter.com/ATechAjay/status/1775049190437204347

1. Research

→ Copilot
→ Gemini
→ Perplexity
→ ChatGPT
→ Claude

2. Website 

→ 10web
→ Dora AI
→ Divi AI
→ Durable
→ Framer AI 
→ Style AI

3. Design

→ Microsoft designer 
→ Canva
→ Flair AI
→ designify
→ Clipdrop
→ Autodraw

4. Writing

→ Jasper
→ Copymate
→ Scalenut 
→ Writesonic
→ Textblaze

5. CopyWriting

→ Rytr
→ Copy AI
→ Writesonic
→ Adcreative AI

6. Chatbots

→ Botonic
→ Chatbase
→ ChatSimple
→ Tidio
→ SiteGPT

6. Image

→ Leap AI
→ DALL-E 2
→ Bing create 
→ Nex .art
→ Bing AI

7. Logo Generator

→ Canva
→ stockimg 
→ Logo AI
→ Brandmark
→ Logo Pony
→ Namecheap

8. Video

→ Synthesia  
→ Descript
→ VEED IO
→ Pictory AI
→ Eightify 

9. Search Engine

→ Perplexity AI
→ Surfer SEO
→ Neeva AI
→ Brave AI
→ Alli AI

10. Meeting

→ Krisp
→ Otter AI
→ Airgram   
→ Sembly AI
→ Noty AI

11. Automation

→ Zapier
→ Make
→ Levity
→ Discript
→ Xembly

12. Productivity

→ Canva
→ Notion
→ Flair AI
→ Adobe Sensei
→ Wondershare

13. UI/UX

→ Figma
→ Uizard
→ UiMagic
→ Photoshop
→ Photoshop
→ GeniusUI

14. Presentation

→ Designs AI
→ Beautiful AI
→ Slides AI
→ Decktopus

15. Audio

→ Murf AI
→ Songburst AI
→ Adobe Podcast

16. Resume

→ Resume Genius
→ Zety
→ Resume io
→ Rezi
→ Kickresume

17. Marketing

→ AdCreative
→ Simplified
→ Pencil
→ AI-Ads

18. Prompts

→ FlowGPT
→ Alicent AI
→ PromptBox
→ Promptbase
→ Snack Prompt

A19. Startup

→ Tome
→ Ideas AI
→ Namelix
→ Validator AI

20. Social media management

→ Typeshare
→ Tribescaler
→ Blackmagic
→ TweetHunter
→ Postwise

### 12

方军 2024/04/02

摘：我使用 chatgpt 的经验，你自己的知识掌握必须比 GPT 深入，才能让他真正帮助你做繁琐的工作部分，不然他忽悠你 你还当真，肯定会被贻笑大方！

### 13

方军 2024/04/02

这几位老师的讨论有意思，经济学老师：

@陆明涛 ECON：想发一个暴论，LLM 以来所有的文科【科普】都变得意义不大了，所有 LLM 读过的书籍资料比任何人类都多，除非在该学科受过系统专业的博士训练从而能批判性地理解、梳理和评价该学科最新研究的内容，否则你的搬运在 LLM 面前都没啥价值。唯一有价值的科普可能就只是有很多数学支持的学科，但也仅限于现在的 AI 发展水平，或许到了未来 AI 发展水平更高之后，这些科普的意义可能也不太大了。

LLM 之后应该对微博生态也有很大冲击吧？比如说科普类、个人化特色不强的微博是不是访问量少了，而能够提供比 LLM 更新知识的博主、或者是个性化特色更强的微博是不是访问量会有上升？毕竟 LLM 现在和微博是不是同一个生态位？不知道微博有没有统计数据支持这种猜想。

@王彬 macro：然而，没有体系，还是很难的，等于是多了一部更齐全的字典，但字典并不成知识。

@明涛 ECON：是的，有没有结构就是教育和科普的区别，科普就是不讲结构，毕竟理解结构太痛苦了。

@明涛 ECON：很多批评评论我都赞同，但是我这里主要说的是「科普」，不是文科专业的教育和科研。读科普是消费行为，不能指望科普就把我们变成专家。科普与专业之间的差异就在于枯燥的学科体系，特别是可以用数学表达的各种结构。

@青梅酒大麦茶：科普的大部分受众是不愿意去花时间主动检索的人。你以为他在学知识，其实他只是在 kill time。

---

这个陆明涛老师说得尖锐了点，但的确是这么回事，当然，去 B 站学习我本来就笑死了，还不如去 AI 学习呢：

某大学某老师上传百科全书式社会科学导论课程一事，本来不应该评价，这结果也在预料之中，但大家的评价都有点过了。其实这大约就是一个 60 后图书管理员运用 80 后技术消化了 90 后的社科知识尝试给 00 后进行科普导致翻车的故事。造成悲剧的原因有三个：

一是知识结构问题。图书管理员的信息情报专业强调信息采集渠道广泛，不注重系统结构性，不注重更新迭代，所以容易很外行。毕竟图书情报系统存在的价值就是整理别的学科的观点，但整理到什么层次怎么整理，其实他们是不太具有学科能力的，这就是为什么其实情报信息专业主要致力于整理最新进展，而不会太尝试进行学科体系全面介绍。当然这些我说的也不专业，也只是道听途说。

二是代沟问题。现在年轻人知识体系来源广泛，特别是在社交媒体的加持下，大家的思想意识都经历了多轮辩论和迭代，但远离社交媒体的老师们往往还抱着老版本，就容易被学生批评。

三是场合问题。除了数学类课程放在网上不会导致太多批评，社科类课程越科普就越可能被各种背景的朋友以各种原因批评，有的是不同背景对相同方法论的质疑，有的是层次问题的反转或修正。前者如其他社科对经济学帝国主义的批评，后者如初级和高级经济学课程对成本加成定价的不同结论。

总之，该老师出发点是好的，但其实他更适合搞个自媒体玩玩试试水，不要把这件事情搞得太神圣。一说到开课，评价要求自然就上去了。

### 14

方军 2024/04/03

whigzhou：

我发现 ChatGPT 的两大特点，可能是 LLM 的共同特点，

一是啰嗦，差班教师式的啰嗦，你问个简单问题，他恨不得先给你上堂课，哪怕问题本身已经表明你对相关领域有了相当深度的了解，也照上不误，

二是绝不谦虚，你提个问题，第一轮回答可能并不切题，经过几次提示后，回答确实会变得更切题，问题是，随着你的提示逼迫，他会越发胡来，随口拼凑编造一些貌似很相关但往往错误百出的回答，

我仔细想了想这事情，感觉这应该是训练系统的激励模式造成的结果。

我们肉人的信念常常有机会从现实反馈中得到修正，比如基于某个信念的行动，若是受挫，便得到了一个负面激励，可是当前 AI 的训练系统提供不了这种现实反馈，所有激励源必须是内生的，这种条件下产生的系统必定会有一些（相比肉人）不同寻常的特征，我观察到的两个特征很可能源自于此。

当前的训练系统可能会提供哪些内生反馈呢？我想到这样几种。

1、基于题库的反馈，IBM 的 Watson 或许就是，做对一题就给颗糖，这会把系统往做题家方向培养。

2、言语本身的质量评估，这个基于大型语料库就可以提供，所谓言语质量，就是一句话是否说的有模有样，哪怕你啥也不懂，但说的句句都像人话，不输母语者，就及格了，这种评估完全可以内生。

3、切题性评估，意思是你表现的就像真的听懂了对方的意识，并且做出了切题的，有内容的，有意义的回应，最好还是听上去蛮有道理的，简单说，就是 makes sense，这种反馈很大程度上也可以内生提供。

依我看，一个训练系统只要在 2 和 3 上做的足够好，就能创造出足以通过图灵测试的系统，让人感觉确实像个真人。

这很可能解释了我观察到的两个特征，你想想看，如果只依赖内生反馈，啰嗦和胡掰就成了优势，像「我不懂」和「不知道」这种回应，哪怕是对问题最恰当的反应，也是不会高分的，因为它们是万能回答，在缺乏外部参考的条件下，激励函数完全无法评估它们是否切题，是否表现了说话者的语言能力，

类似的，哪怕一个问题的恰当答案非常简单，只需一两个词，干脆利落，但为了得高分，你必须啰嗦上一通，才能让激励函数相信你对当前正在谈论的主题有足够的理解，对相关背景知识有良好掌握，说起来头头是道，有条有理 —— 这跟做题家在讨论课堂上对付老师的方式完全一样！

问题是，这种能力并不能在任何程度上保证他们能完成有现实意义的工作任务，提供有价值的服务，要达到这种目标，还需要更切实的，往往是领域专门的评估和反馈。

由此可以推测，较近未来哪些领域 AI 应用潜力更高，首先就取决于哪些领域更有潜力提供这种内生反馈，或很容易以低成本获得外生反馈。

专业题库就是一种内生反馈源，信息源声望等级也是一种来源，比如如果你的诊断总是和顶级名医对相同病情的诊断保持一致，就得高分，但这也意味着，如果只依靠内生反馈，顶级肉医水平就构成了你的天花板，你永远不可能靠自己进步，那需要外生反馈。

棋牌类系统之所以进步神速，是因为它们可以互弈，每一局的结果都是内生反馈。

另一个有着优越内生反馈源的系统是股票投资，完整的历史股价和交易数据可以产生相当逼真的内生激励，但问题是，1）历史成就与未来成就有多大相关？2）把训练结果放进真实市场后，这一扰动造成的后果是否会让历史经验失效？

还有些领域，比如与用户互动的软件系统，可能会从互动中得到有用反馈。

### 15

方军 2024/04/03

大型代码库，真是迫切需要 AI

Linkedin 的故事

[十几年积累的 300 万行代码，领导要全部“快速”重写，我直接辞职了](https://mp.weixin.qq.com/s/udt-LB67BZ8EGrwWE9ouXg)

[LinkedIn 应用体积臃肿达 500 MB，网友怒喷：大厂开发者都没有动力创造优秀应用？！](https://mp.weixin.qq.com/s/lz-C8MJ4vq2xpNVgJc0zTA?v_p=90&WBAPIAnalysisOriUICodes=10000001_10000002&launchid=default&wm=3333_2001&aid=01A0VjFEC-8TX6msntzx_IZJsVSdIBL5NqzASu9SjrmTcS5LA.&from=10E3393010)

### 16

方军 2024/04/03

AI 对我来说，有一个好处是，有了 AI 就更多时间花在「非新闻」上了。

去年群里推荐一本少看新闻的书，被一位老师一顿狠批评。我倒是虚心接受批评了，再推荐这样的书的时候还是要强调新闻的社会价值。

但是各种新闻真心没必要，比如，刚刚看某教授讨论所谓我的梦想长大了做农发行的行长那个，群情激昂，哈哈，这种破事如果要关注，每天都很多。

媒体会把某些破事推到你面前，比如一个经典的案例是，多年前，电视里播着激烈的冲突，走出酒店一看，几十人而已。

社交网络会进一步把各种鸡毛蒜皮、但能调动情绪的推到你面前。媒体还有判断，社交群氓没有判断。

### 17

方军 2024/04/03

政府出台了：生成式 AI 备案。

### 18

方军 2024/04/04

这个深度广度的看法有意思

有个梨：llm 的影响力充分释放大约要 15 年的时间。

它释放的主要方式，是英语语境下的西方文明的影响力。体现在，诸如 YouTube 等视频网站的教育课程全面跨语言影响，包括印度英语；以及象 grammerly 或类似的工具，帮助年轻人更快的学好英语，尤其是在没有合格老师的情况下，实际上包括 google docs 的语法检查最近都有了长足的进步。

我知道 llm 还有很多比这个听上去高大上得多的应用，但是技术在市场角度不是看深度的，而是看广度的，能 reach 多少 people。就像社交网络那样，出来的时候没人觉得那很重要，直到 Facebook 崛起，以及更加出乎技术人员预料的，Instagram 和 tiktok 崛起。

Internet 的第一个十五年，给了内容网站和 Google，第二个十五年，给了社交网络和云计算。

llm 的第一个 15 年，会推倒巴比塔。15 年也正好是一个孩子从走入学校开始到走上社会工作。在这个 15 年里，在从现在开始进入小学的这批孩子们身上，在全球范围内，互联网和移动互联网把每个人接入全球化的知识体系（这里强调知识而不是任何信息），llm 打破语言障碍，让任何人可以看懂任何语言的内容，让任何人可以学好英语，如果他想。

所以未来十五年真正大发展的是教育，而十五年之后，stem 支撑的所有工程领域会达到在人类历史尺度上的全新的高度。

### 19

方军 2024/04/04

[#模型时代# 25 个... - @高飞的微博 - 微博](https://weibo.com/1233486457/O82Bmn4Jg)

25 个 YC 孵化的 AI 模型公司都是什么赛道的？

YCombinator 认为，模型训练，可能不需要动辄上亿的资金。且耳听为虚，眼见为实。YC 为了支持自己的论点，也公布了它扶持的，自己训练基础模型或做模型微调的 25 家初创公司。

这些公司的筛选标准是：启动资金和资源包括（50 万美元的资金，100 万美元的云服务额度和专用 GPU 资源）；在 YC 三个月孵化期内训练出模型；模型投入生产并成功吸引付费用户。

这 25 家公司还有一些共同特点，比如都面向垂直场景，比如生成音乐、设计新型蛋白质、精确预测天气，操控机器人等。同时，也发明了一些技术方法，比如通过创新的模型架构来减少计算需求，或利用特定行业知识减少数据需求。

Atmo：提供基于 AI 的气象预测服务，承诺以更低的成本提供远比现有技术更为准确的天气预测。

Can of Soup：通过 AI 让你与朋友们在虚构场景中的照片同场。

Deepgram：提供超快速语音转文本转录及自然语音合成的 API 服务。

Diffuse Bio：专注于利用基础模型在生物学领域设计新的蛋白质，用于疫苗和治疗药物的开发。

Draftaid：利用 AI 帮助工程师和设计师创建 CAD 图纸，轻松将 3D 模型转换为制造商所需的详细制造图纸。

Edgetrace：能处理大量视频数据集，并允许用户通过简单的英文描述进行搜索。例如，通过描述找到特定汽车在数小时的交通录像中的出现，如「带金色轮毂盖的红色普锐斯右转」。

EzDubs：可以实时将视频配音成不同语言，同时保留原始讲话者的声音特色。

Exa：为 AI 开发者提供的搜索引擎 / API，它通过语义而非关键字来搜索信息，让开发者可以运行如「关于 Google 初期的简短文章」或「最新 AI 进展的新闻」等查询，并将搜索结果整合到他们产品的回答中。

Guide Labs：基础模型通常是「黑箱」，无法解释其推理过程。他们通过可解释的基础模型解决了这一问题，能够说明模型输出背后的逻辑，以及训练数据和提示的哪些部分对输出有影响。该团队之前在 Google Brain 和 Meta Research 工作，是 Captum 的主要开发者。

Infinity AI：正在开发一种「剧本到电影」的模型，你只需描述屏幕上角色的台词和动作，它就能生成相应的视频。他们的首个产品能够基于提供的剧本制作出「对话头」风格的视频片段。

K-Scale：致力于为机器人基础模型提供支持基础设施，最终解决现实世界中的实体智能问题。

Linum：开发了可以根据提示制作动画视频的模型和工具。

Metalware：为固件工程师提供 AI 工具，加速开发进程，例如为低级编程设计的专门协助工具，或能迅速浏览大量数据表并提供快速答案的 PDF 阅读器。该公司的联合创始人参与了 Starlink 天线固件的开发。

Navier AI：开发了一个物理 - ML 求解器，可以实时模拟计算流体动力学，这对航空和汽车工程至关重要。

Osium AI：使用 AI 加速新材料设计，通过预测材料的物理属性和加速显微图像分析来帮助研发工程师快速设计新材料。

Phind：为开发者打造的对话式搜索引擎，通过 VS Code 扩展与现有代码库集成，能够利用代码作为上下文来回答问题，遇到错误或警告时提供解决方案。

Piramidal：基于大量多样的脑电波数据训练的基础模型，用于理解大脑活动。他们的首个产品是一个帮助神经科医生评估潜在癫痫诊断的辅助工具。他们通过分块处理连续的脑电波数据，以较低的计算成本训练出大型模型，减少了内存占用。

Playground：一个基于 AI 的强大图像编辑器，能从提示中创建新图像，合并真实 / 合成图像成新作品，或仅用几个词就能修改现有图像。

PlayHT：为媒体和内容创作者提供表情丰富的 AI 生成声音。可以用大约 10 分钟的样本录音来训练出新的声音。

SevnAI：正在构建图形设计的基础模型。他们能够利用一个具有空间推理能力的定制架构模型，生成易于编辑的 SVG 图像，解决了当前扩散模型输出图像难以编辑的问题。

Sonauto：AI 音乐创作工具，你只需提供歌词和歌曲描述（如「节奏快速、以鲜明的合成器为特色的流行音轨」），点击「生成」，就能得到一首全新的音乐。

Sync Labs：开发了一个模型，可以重新同步视频中某人嘴唇的动作，以匹配新的音频，使得更改视频的对白语言看起来更自然。他们正努力实现实时同步，以便在视频通话中实现实时唇语翻译。

Tavus：录制一个视频，自动为每个观众个性化定制 —— 在适当的位置替换为观众的名字、公司等信息。该公司最近推出了一个公开测试版工具，使你可以用 2 分钟的视频制作出一个「类似真人」的自己的复制品。

Yoneda Labs：帮助化学家确定最优的温度、浓度和催化剂，以提高化学反应的效率。

Yondu：为机器人在世界上的自主导航开发基础模型，使它们能够更智能地移动和工作。

---

方军：Ycombinator W24（24 冬季演示日）招募了 157 家大型人工智能初创企业。

Joinrosebud 创始人 Chrys Bader 总结了一下这些入选初创企业的类型，包括六大类，可以某种程度看做是大模型创业的新趋势。总体看下来，大模型变革最多的领域是 IT 本身，技术让技术人（或者说普通技术人）的需要程度降低。

1、软件开发：44 家初创企业正致力于利用人工智能接管日常编码任务和基础架构管理，释放开发人员的潜力，使他们能够从事更高层次的创造性工作。代表性初创企业包括 CodeantAi（自动修复错误）、MomenticAi（人工智能自动化测试）、EllipsisDev（自动化代码审查）等。

2、客户服务：有 12 家初创企业在使用人工智能改善客户服务体验，旨在帮助公司节省资金和时间。这些初创企业如 TomaVoice、Usearch、SomnYcw24（人工智能接待员）、Retellai（语音对话人工智能的基础设施）、KioskAi（人工智能助力 WhatsApp 营销）。

3、生物技术和医疗保健：10 家初创企业利用人工智能缩短新疗法的开发时间和成本。例如，TamarindBio 提供药物发现的计算工具，RadmateAi 为放射科医生提供人工智能副驾驶，Metofico 提供用于生命科学的无代码数据分析。

4、内容创意：14 家初创企业正通过人工智能促进创意的实现，模糊创作者与消费者界限。例如，MagicHourAi 是一个人工智能视频生成平台，ToinfinityAi 专注于从剧本到电影的创造，PocketpodApp 提供定制播客创建服务。

5、金融投资：11 家初创企业正在使用人工智能支持投资决策，重塑金融市场。Tryoffdeal 为中小企业收购提供人工智能中介服务，PowderFi 作为财富管理者的副驾驶，ClarumAi 加速尽职调查过程。

6、物理世界：7 家初创企业展示了人工智能如何构建和管理物理基础设施。比如 Inspectmind 提高检查设施报告的速度，PurplePillAi 作为人工智能物业管理员，DraftAid 则使用人工智能将 3D 模型转换为 CAD 图纸，和机器人（PivotRobots、YonduAi）等。

此外，值得一提的其他类别初创公司，还包括人。

2024-04-04 00:47

[Draftaid: Go from 3D models to CAD drawings using AI | Y Combinator](https://www.ycombinator.com/companies/draftaid)

[From 3D models to production drawings using AI](https://draftaid.io/)

### 20

方军 2024/04/04

使用弱智吧数据训练的大模型，跑分超过百科、知乎、豆瓣、小红书等平台，甚至研究团队精心挑选的数据集。

这件事让人深思，什么才是中文优质数据集？

Reddit 也是优质测试集。

有意思，哈哈哈

[弱智吧竟成最佳中文 AI 训练数据？！中科院等：8 项测试第一，远超知乎豆瓣小红书](https://mp.weixin.qq.com/s/iq5lGyh9Y5P7NXLUS3-giA)

接下来比拼数据了

### 21

方军 2024/04/04

这个观点是合理的

摘：飞书需要换个 slogan。相比之下，可能 37signals 更适合说自己是先进团队做的先进产品。先进的，有价值的产品，当然应该是可以带来较高利润的。​​​

比人效，37signals 人均 5000 万，飞书人均 20 多万。 37signals 那才叫先进团队，飞书的人效比他很多客户都不如。

### 22

方军 2024/04/04

OpenAI 针对开发者将增加新功能，开发者可通过 API 对微调进行更多控制，并宣布了使用 OpenAI 构建自定义模型的新方法。

OpenAI 于 2023 年 8 月推出了 GPT-3.5 的自助微调 API，新的微调 API 功能将包括：

- 在每次训练过程中保存完整的微调模型检查点，以减少后续重新训练的需要，尤其是在过拟合的情况下；

- 用于比较模型质量和性能的全新并排 Playground 用户界面，允许对多个模型的输出进行人工评估，或根据单个提示对快照进行微调；

- 支持与第三方平台的集成（本周开始与 Weights and Biases 集成），让开发人员能够与堆栈的其他部分共享详细的微调数据；

- 在每个历时结束时对验证数据集（以前是一批采样数据）计算指标，以便更好地了解模型性能（标记损失和准确性），并反馈模型的泛化能力；

- 能够从仪表板配置可用的超参数（而不是仅通过 API 或 SDK）；

- 对微调仪表板进行了各种改进，包括配置超参数、查看更详细的训练指标以及从以前的配置重新运行作业。

自定义模型方面，则包括：

- 辅助微调，开发者可与 OpenAI 的技术团队合作，在更大范围内利用微调 API 以外的技术，如附加超参数和各种参数高效微调 (PEFT) 方法。

- 定制训练模型，在某些情况下，企业需要从头开始训练一个了解其业务、行业或领域的专用模型。完全定制训练的模型通过使用新颖的中期训练和后期训练技术修改模型训练过程的关键步骤，从特定领域注入新的知识。使用完全自定义训练模型取得成功的企业通常拥有大量的专有数据 -- 数百万个示例或数十亿个 tokens-- 他们希望利用这些数据向模型传授新知识或复杂、独特的行为，以满足高度特定的使用情况。

### 23

方军 2024/04/05

Anthropic 昨晚发布了一种名为「多次尝试越狱」的技术，可以利用超长上下文的模型特性将对应的长提示对模型越狱。

看到的点评：看起来等效于用超长文本 prompt 做了临时微调。

感觉也可以用在其他方面，不知道 GPTs 是否可以这样，用 knowledge 做现场微调。

---

「多次尝试越狱」通过在单一提示中包含大量特定配置的文本，迫使 LLMs 产生可能有害的回应，尽管它们被训练为不这样做。研究表明，随着包含对话（「尝试」）数量的增加，模型产生有害回应的可能性增加。结合其他已发布的越狱技术，可以使这种技术更为有效，减少模型返回有害回应所需的提示长度。

这种越狱技术的有效性与「上下文中学习」（in-context learning）的过程有关，即 LLM 仅使用提示中提供的信息进行学习，而不需要任何后续的微调。研究发现，正常情况下的上下文中学习遵循与多次尝试越狱在增加的示例演示数量上相同的统计模式（幂律分布）。

为了缓解多次尝试越狱的风险，Anthropic 采取了一些措施，包括限制上下文窗口的长度和对模型进行微调，使其拒绝回答看起来像是多次尝试越狱攻击的查询。此外，他们还探索了基于提示的缓解方法，这些方法涉及在模型处理提示之前对其进行分类和修改，显著降低了多次尝试越狱的有效性。

New Anthropic research paper: Many-shot jailbreaking.

We study a long-context jailbreaking technique that is effective on most large language models, including those developed by Anthropic and many of our peers.

Read our blog post and the paper here:

[Many-shot jailbreaking \ Anthropic](https://www.anthropic.com/research/many-shot-jailbreaking)

### 24

方军 2024/04/05

我发现如何使用 AI 做调研，我的观点基本上可以说长期没有变化，都忘记很早之前做个这样一个图：

---

向 AI 提问，做项目调研：自带原始资料 / 自带知识框架 / 自带判断力

知识框架，即提问的列表：

1. 项目概况

2. 经济模型

3. 应用场景

4. 技术特性

5. 项目前景

### 25

方军 2024/04/05

刘群老师的感慨：感慨一下技术进步给研究和教学带来改变和失落：当年我们做 NLP 研究，要学习很多语言处理的技术，包括 word segmentation, POS-tagging, parsing, semantic role labeling, co-reference, RST 等等，

深度学习流行以后，发现这些内容已经没有人感兴趣了，Stanford NLP 的课程都抛弃了这些内容。

现在大语言模型又带了一轮巨大的变化，看现在的论文，发现很多论文本质上就是做 prompting engineering 加数据和评测，甚至连机器学习的基础技术都不需要具备，也可以做出很好的工作并在顶会上发表论文。

真不知道这是好事还是坏事。

### 26

方军 2024/04/05

实在地说，现在看到 GPT-3.5 的这种回答，觉得好神奇。

GPT-4-Turbo-preview 很奇怪，效果不佳，不如 GPT3.5。

一年多过去了，这种神奇感还没有完全消失。

### 27

方军 2024/04/05

【生成式 AI 高峰已过？】

- 生成式 AI 的兴趣高峰已经过去，公众兴趣下降，风投估值过高，初创公司开始倒闭，企业对部署安全性存疑。

- 但技术本身仍在快速进步，不断有新模型问世，基础设施也在建设，只是这些进展不为公众所知。

- 每项革命性技术都曾经历过兴趣的高峰和低谷，生成式 AI 可能也是这样，目前正处在低谷期。

- 是否会再次繁荣取决于静默努力的人们，而非当下的舆论，历史会给出答案。

- 过度炒作可能让公众在下次繁荣时难以接受，技术领域应谨记。

- 我们应该问自己，技术本身是否有足够的力量推动变革，而非依靠夸大其词。

思考：

- 技术发展的节奏和公众舆论的节奏不尽相同，需要平衡二者。

- 过度炒作会损害公众对技术的信任，可能会阻碍长远发展。

- 变革依靠内在驱动力，外界关注并非必需。

《The State of Generative AI, 2024 - by Alberto Romero》

[The State of Generative AI, 2024 - by Alberto Romero](https://www.thealgorithmicbridge.com/p/the-state-of-generative-ai-2024)

### 28

方军 2024/04/05

区块链这个技术圈子的风气真不好，刚刚去看一个区块链 + AI 的新发布项目，看了半天几家大技术机构合作，各种愿景（比如去中心化基础设施）、各种新技术名词（比如 opML，与 zkML 对应），但是仔细一看，

第一，是个期货，何时能真正可以进行开发不知道。

第二，没有模型，还是接 SD llama 等开源模型。

第三，宣称生态接入 AI，也就是可以开发 AI 应用，可以训练模型，但是，有什么场景？没有。

真是漂亮的空气软件 (vaporware）。

2024-04-06 12:59

方军回复乘风：在 AI 里面，你发布一个技术，不能用根本没人理，至少要像 SORA 那样发很多内部例子出来

2024-04-06 13:08

### 29

方军 2024/04/06

这个太有意思了：

在一个学生要求推荐信时，他给我发送了建议的 GPT-4 提示，他希望我用它来生成推荐信本身。

twitter.com/emollick/status/1776320220715471187

### 30

方军 2024/04/06

贾杨清公司的 elmo.chat 总结插件不错

他们有两个人别写了总结：

Yadong Xie: 在这里解释下我们做这个插件的原因

twitter.com/yadong_xie/status/1776409027419013586

贾：从 elmo 学到的 (原为英文，此处为 AI 翻译）

twitter.com/jiayq/status/1776462547287486646

----

Elmo 上线第三周，8000+ 安装量了

在这里解释下我们做这个插件的原因

1. 向大家展示开源模型今天的能力。各种开源模型，如果用好的话，其实已经能够在很多领域崭露头角。

2. 向大家展示 @LeptonAI 做为一个平台的能力，可以高性能、低成本、多快好省地帮助各种应用迅速接入 AI。

如果你用 Elmo 觉得好使的话，欢迎考虑 @LeptonAI 的平台能力 - 我们提供最具有性价比的 GPU 资源，同时提供目前全球最快的 LLM 以及其他 AI 模型部署的能力。

Elmo 没有商业化的 KPI，会是一个保持极简主义的免费插件，欢迎大家提意见。

---

[Elmo - Your free AI web copilot, a chrome extension to create summaries, insights and extended knowledge](https://www.elmo.chat/)

Elmo 是您的 AI Chrome 扩展程序，旨在为任何网站创建摘要、洞察和扩展知识。我们已经运行了几周，到目前为止，来自朋友和家人的反馈普遍是积极的。以下是我们从中学到的一些东西（主要是关于 LLMs）：

（1）开源模型效果很好！

我们主要使用 Mixtral 8x7b，配合 prompt 工程。它以非常实惠的成本实现了良好的性能，使我们能够完全免费提供 Elmo。我们目前正在测试 @databricks 的 DBLX 和百川 - 2 用于中文。初步结果非常积极。

(2) prompt 工程太脆弱了，但没办法。

事实上，今天，如果我们改变提示，要求模型生成「tl;dr」而不是「摘要」，这一个词的改变会使模型的行为完全不同。此外，提示在不同模型之间（如从 Mixtral 到 DBLX）并不完全稳定，使得迁移有些困难。我们还没有一个好的解决方案。只是说说而已。未来的研究能解决吗？我们当然希望如此！

(3) 速度很重要。

人们告诉我们他们喜欢 Elmo 的「飞快」速度。我们没有为 Elmo 进行专门的部署；它混合在我们的无服务器 API 中。我们做出了有意识的选择，在保持现有模型以及新模型（如 DBLX，如 @ArtificialAnlys 所示）的最佳性能的同时，平衡速度和成本。总的来说，我们发现人们对速度的关注超出了我们的预期。

(4) 多语言支持很困难。

模型通常在一个语言内表现良好，但当要求输出另一种语言（例如，将英语输入翻译成中文输出）时，它们会产生极端的幻觉。我们最喜欢的例子是 Mixtral 在中文中产生了一个叫「杨万岛」（Yang Wandao）的日本将军。后来我们意识到这其实是因为「山本」（Isoroku）的发音与「杨万岛」相似。对于亚洲和太平洋地区的语言来说，多语言 LLMs 有着巨大的机遇和社会价值。

（5）简约至上。

人们告诉我们，他们喜欢 Elmo 是因为它不会做太多事情。点击、总结，完成。我们不会捆绑各种图像生成和聊天等功能。这使人们可以放心地将其用作简单的工具。当然，作为一个平台公司，我们不会从 Elmo 中赚钱，所以我们的压力比那些专注于制作浏览器工具的公司要小；但用户的信号是明确的：简约、简单、清晰的功能。

(6) AI 的认知仍处于早期阶段。

我们在 AI 领域的朋友圈对 Elmo 的反应是「哦，很酷，是的，又一个工具」。有趣的是，我们的非技术圈子对此的反应是「哦哇，这可以做到吗？太神奇了」。诚然，对于 AI 从业者来说，所有这些功能都很正常。但我们意识到社会中还有很大一部分人对 AI 的最新进展尚不了解，尤其是他们可以亲身体验的方式。这意味着 AI 的潜在市场仍然巨大！

小知识：Elmo 是在农历新年期间作为一项业余项目开始的，仅用了不到一个周末的时间。我们希望 Elmo 为您提供直观的体验，了解我们的 AI 基础设施公司。也许有一天，您会将 AI 能力集成到自己的产品中，而我们可以为您提供便利！在那之前，尽情享受 Elmo 作为您的个人 AI 助手，只需一键即可。

### 31

方军 2024/04/06

某人孜孜不倦发论文、发共享库，一天发N多，这种真心胡扯，就共享库而言，用好一个，比什么都强。论文也相似吧，把重点论文好好读。

也许我是笨人，一个库都要看好久，毕竟代码要至少大体看下

### 32

方军 2024/04/06

这样的摘录我甚至都会读两回，真心说，很多人太高估自己有效获取信息的能力了。

我总觉得，这个世界是属于笨人的。我好像之前写什么的时候专门讨论过这个话题，应该写在一本书里。

### 33

方军 2024/04/06

现在真心还有不少很不错的  .ai 域名

就是太贵，看到了只能少量根据需要买

建议想要做事情的人，可以去找些。

### 34

方军 2024/04/06

【AI 生成内容泛滥冲击 Google Books】

- Google Books 作为索引已出版资料的重要学术工具，正在收录大量低质量、由 AI 生成的书籍内容。

- 这些 AI 生成的书籍会出现在 Google Books 的搜索结果中。

- 大量索引 AI 生成的垃圾内容，可能会影响 Google Ngram Viewer 的结果准确性。Ngram Viewer 是研究人员用来追踪历史语言使用情况的重要工具，它基于 Google Books 的数据。

- 这反映出在 AI 技术快速发展的背景下，学术界对付 AI 生成的大规模垃圾内容还缺乏应对之策。图书出版和学术搜索工具的把关机制亟待升级，以应对 AI 带来的挑战。

- 谷歌官方表示会删除所有低质量内容，无论是 AI 还是人工创作。但 AI 生成内容的泛滥，对搜索引擎和学术工具构成了前所未有的冲击。

思考：

- AI 生成内容正以超乎想象的速度渗透到方方面面。作为知识索引的基础设施，Google Books 这样的工具首当其冲受到冲击，凸显出 AI 时代学术规范和内容把关面临的困境。

- 海量的 AI 垃圾内容会稀释优质内容的密度，误导读者，破坏学术生态。Ngram Viewer 等研究工具也会受到污染，影响学术研究的准确性。学术界需要高度重视这一问题。

- 识别 AI 生成内容本身就是一个技术挑战。传统的人工审核已然不敷使用，平台和工具方需要研发更智能的 AI 技术来对抗恶意的 AI 生成内容。

- 从源头治理，完善 AI 伦理规范，加强对 AI 滥用的监管，需要学界、业界、政府多方合力。在拥抱 AI 红利的同时，也要警惕其负面影响，建立科学的 AI 治理体系。

### 35

方军 2024/04/06

BenchMark 的 Sarah Tavel 最新的一篇文章《DeepL, Elevenlabs, Heygen, Midjourney 都有什么共性》一文中，提出了思考当前 2B 创业的一个新角度，很有启发（别人的总结）：

1. 它们并没有显著提高员工在现有工作流中的生产力，但是，它们释放出了那些受制于招聘和与人合作过程中常常产生极高摩擦和成本的市场需求

2. 在这种场景下，人工智能提供了比现有替代品（通常是人类）近乎 100 倍好的体验，它把雇用和管理另一个人的重大努力压缩成一种近乎即时的体验，这种体验随着时间的推移只会变得越来越好

3. 公司只需要付出从前雇用 / 管理人员的一小部分成本来做到这一点，极大地开辟了使用场景和潜在市场

顿悟时刻：技术变量本质会带来两个东西，1）成本结构的彻底重构，2） 产品 / 服务 10x 甚至 100x 以上的体验提升，成功的产品，二者缺一不可。

[What MidJourney, DeepL, ElevenLabs, and HeyGen have in common (besides special teams and explosive growth!)](https://www.sarahtavel.com/p/what-midjourney-deepl-elevenlabs)

### 36

方军 2024/04/07

不知道对不对，除了极其个别之外，我基本上将那些讨论 AGI 的人都看成是无知之人。

要么是自己无知，要么是有意去欺骗大众。

简言之，不是蠢，就是坏。

### 37

方军 2024/04/07

《纽约时报》的一篇报道讲述了科技公司如何为训练模型而挖空心思收集数据，这篇报道的作者之一是《深度学习革命》作者 Cade Metz，一些细节：

OpenAI 篇

- 2021 年末，OpenAI 面临数据供应问题。因此，OpenAI 的研究人员创建了一款名为 Whisper 的语音识别工具。它可以转录 YouTube 视频中的音频，生成新的对话文本，让人工智能系统变得更加智能。

- OpenAI 团队最终转录了 100 多万小时的 YouTube 视频。其中两位知情人士说，该团队包括 OpenAI 的总裁 Greg Brockman，他亲自帮助收集视频。这些文本随后被输入 GPT-4 。

谷歌篇

- 谷歌也转录了 YouTube 视频，为其人工智能模型采集文本，这有可能侵犯了视频的版权，而这些版权属于视频的创作者。

- 去年 6 月，谷歌还扩大了其服务条款，动机之一是为了让谷歌能够利用公开的谷歌文档、谷歌地图上的餐馆评论和其他在线资料来开发更多的人工智能产品。隐私团队被特别告知在 7 月 4 日周末发布新条款，当时人们通常专注于独立日假期。修订后的政策于 7 月 1 日（即长周末开始时）首次公布。

- 去年 8 月时，谷歌隐私团队的两名成员向管理人员询问谷歌是否可以开始使用免费消费者版谷歌文档、谷歌工作表和谷歌幻灯片中的数据。他们说，没有得到明确的答复。

- 两位知情人士说，谷歌的一些员工知道 OpenAI 从 YouTube 视频中获取数据。但他们并没有阻止 OpenAI，因为谷歌也曾使用 YouTube 视频的转录来训练其人工智能模型。这种做法可能侵犯了 YouTube 创作者的版权。因此，如果谷歌对 OpenAI 大动干戈，可能会引起公众对谷歌方法的强烈不满。

- 谷歌发言人 Matt Bryant 表示，公司对 OpenAI 的做法并不知情，并禁止 "未经授权的 YouTube 内容搜刮或下载"。他说，谷歌在有明确的法律或技术依据时才会采取行动。

Meta 篇

- 当 ChatGPT 发布时，扎克伯格不分昼夜地给高管和工程师打电话，催促他们开发一款可与之匹敌的聊天机器人。当在 2023 年年初，Meta 遇到了与竞争对手同样的障碍：数据不足。

- Meta 公司负责人工智能生成的副总裁 Ahmad Al-Dahle 告诉高管们，他的团队几乎使用了互联网上所有可用的英文书籍、散文、诗歌和新闻文章来开发一个模型。

- Ahmad Al-Dahle 告诉同事们，除非获得更多数据，否则 Meta 无法与 ChatGPT 匹敌。2023 年 3 月和 4 月，公司的一些业务开发负责人、工程师和律师几乎每天都开会讨论这个问题。

- 一些人讨论了以每本书 10 美元的价格购买新书的全部许可权。他们讨论了收购 Simon & Schuster 出版社，根据录音，该公司出版了斯蒂芬 - 金等作家的作品。

- 他们还谈到了如何在未经许可的情况下从互联网上摘录书籍、论文和其他作品，并讨论了吸纳更多内容的问题，即使这意味着要面对诉讼。他们认为，与出版商、艺术家、音乐家和新闻行业进行许可谈判耗时太长。

- Meta 公司的高管谈到了他们如何在非洲雇用承包商来收集小说和非小说的摘要。一位经理在一次会议上说，这些摘要包括受版权保护的内容，"因为我们没有办法不收集这些内容"。

- Meta 全球合作与内容副总裁 Nick Grudin 在一次会议上说：阻碍我们达到 ChatGPT 水平的唯一因素就是数据量。OpenAI 似乎在使用受版权保护的材料，而 Meta 可以遵循这一 "市场先例"。

另外，文章最后还蜻蜓点水的提到了合成数据。

来源：www.nytimes.com/2024/04/06/technology/tech-giants-harvest-data-artificial-intelligence.html

### 38

方军 2024/04/07

这篇文章有意思：

技术的涟漪效应：RAG 与 Long Context 的认知冲突

在科技的浪潮中，每一项新兴技术都似乎预示着旧技术的终结。然而，当我们观察 RAG 和 long context，一个有趣的现象出现了：被大模型厂商认为即将被淘汰的技术 RAG，却被企业客户视为好用的新技术，其应用非常扎实也越来越广泛

quail.ink/orange/p/technological-ripple-effect-rag-and-long-context-cognitive-conflict

讨论：twitter.com/oran_ge/status/1776803266833350769


### 39

方军 2024/04/07

有人说拍视频太耗费时间了，简单的 5 分钟搞了 1 一小时。文字一两分钟就搞完了。

那个视频看了，通义千问的简单使用，的确一两分钟。

当然，从（很多很多普通）受众的角度讲，有人视频，更容易懂些。就是这么个情况。

但是，视频真的效率太低太低了。我刚刚看某老师翻译的视频，30 分钟，讲实话他真有闲，拍的人也有闲，我真是一分钟也看不了。

视频这种东西，真心只能看很少一点最高质量的，其他的看都不要看。（直播授课类的除外，直播授课类的，那又是另一个场景了）。

### 40

方军 2024/04/07

073 我们所有的提示语相关工作可能都错了

这是近期很深的一条感悟，「我们所有的提示语相关工作可能都错了。」

我们从自己的经验出发，大体上有这么一些思路：

要用好 AI ，得学会用提示语。因此，要把它的前因后果搞明白。—— 这是错的，普通人不要搞明白。其实所有人都一样，把复杂封装起来就够了，比方说，有多少人知道一个网页是由什么组成的吗？不需要知道。

要用好提示语，就要掌握一些方法。—— 这也是错的，这些方法放在课堂上 / 讲座里是有用的，因为我们作为讲的人需要一个架子把东西立起来，否则全堆在一块不方便找。普通人不需要，普通人只不过想用 AI 完成自己的任务而已，最好不要知道这些奇怪的框架。

要用好提示语，得收集一些好用的，并且不断地测试这些提示语的效果，从而把它们用好。—— 这也是错的，普通人不会是这样的思路。他们还是得要模型能力足够强，用起来无感。这种有感式运用不是普通人的方式。

所以，这些和提示语相关的工作都是错的。真正有用的工作，还是写好一个或数个提示语，嵌在应用里，让用户完全无感地用起来，达成自己的目的。

一个简单的推论是，不要希图教普通人提示语这回事。有了这个基本假设也好，面向普通人，我们就不必很有耐心的展示，其实主要炫技就可以了。

---

以下为 AI 生成（有删节，但无修改）：

普通人不需要深入了解提示语的前因后果和方法，只需将复杂内容封装好供直接使用。但是，对于普通用户来说，无感地使用提示语才是最重要的。这种观点对于设计应用或系统时的用户体验有着深远的启示。

1. 简化提示语使用流程： 设计师在开发提示语功能时，应该将复杂的前因后果和方法封装在背后，让普通用户能够简单、直观地使用，无需过多理解背后的技术细节。

2. 用户体验为先： 提示语设计应该以用户体验为重心，确保用户在使用过程中感受不到复杂性，而是能顺利完成任务，这需要设计师深入理解用户需求和行为习惯。

3. 持续优化和测试： 不断收集用户反馈，测试提示语的效果，并根据实际情况调整和优化，以确保用户能够顺利、无感地使用提示语功能。

\### 如何设计简单、直观的提示语功能

I. 简化提示语使用流程

- 简要介绍：在设计提示语功能时，我们要考虑让用户能够简单、直观地使用，无需过多理解背后的技术细节。

- 主要内容：

1. 将复杂的前因后果和方法封装在背后，让用户只需通过简单的操作即可使用提示语功能。

2. 设计清晰的界面和操作流程，引导用户快速了解如何使用提示语，并在需要时能够方便地调用。

II. 用户体验为先

- 简要介绍：在提示语设计中，用户体验应该是设计师考虑的重点，确保用户能够无感地完成任务。

- 主要内容：

1. 深入理解用户需求和行为习惯，设计符合用户习惯的提示语使用方式。

2. 确保用户在使用提示语功能时能够顺利完成任务，无需花费过多精力理解提示语的内在逻辑。

III. 持续优化和测试

- 简要介绍：对提示语功能进行持续优化和测试是确保用户满意度的重要手段。

- 主要内容：

1. 收集用户反馈，了解用户对提示语功能的喜好和不满意之处，及时调整和优化设计。

2. 通过测试，评估提示语的效果，保证用户能够顺利、无感地使用提示语功能，提升用户体验。

---

方军：发现 AI 太会编套话了，某些编套话的，你们能赢过 AI 吗抓狂

2024-04-07 20:14

方军：反正比我会编多了，我随便写写，它一遍怎么显得它那么牛，我一下被对比下去了偷笑

2024-04-07 20:14

### 41

方军 2024/04/08

是这个意思啊，可能将来人会更愿意看个性化的、人性化的内容：

The world will appear more and more cyclical and redundant

世界将变得越来越循环和冗余

LLM 已经生成了大量的 PDF 文档，这些文档被其他程序消耗和解析！人类不编写或阅读它们！

其他媒体也是如此！机器人已经生成了只有其他机器人消费的推文

由 LLMs 编写的代码将捕获和记录只能被其他 LLMs 读取的数据

系统中已经存在大量噪音、浪费和冗余！使用机器将指数级地放大这个问题

twitter.com/bindureddy/status/1777004206127562854

### 42

方军 2024/04/08

飞书隐藏了很多教训，对 AI 时代尤其有启发。其实作为 C 端用户我也不喜欢飞书，当然我很特殊，我也觉得 notion 不好用。作为 B 端用户里面的个体用户，我有个参与项目本来是需要用 lark 的，但我自己尽量避免去用。

关于飞书的讨论，摘：飞书为什么被大幅裁员？

得承认，字节跳动在 toC 端市场非常成功，用户量很大，营收很多，利润很高，于是字节产生了自己无所不能的幻觉。

然而，toB 市场跟 toC 截然不同，B 端的客户没有冲动消费，B 端用户和客户是两拨人，而 C 端用户和客户是同一个人，B 端的客户才是决定付钱的人但是他们可能不是用户，B 端的付费决策要走流程，要招投标，要上会，要层层请示审批，B 端买错了东西花错了钱决策人要被追责，B 端有个性化定制需求，B 端对跨版本兼容性有很高要求，以上问题 C 端都不存在。

B 端是个获客困难而客单价也不算太高的市场，B 端的好处是长期相对稳定，业务比较长久。

你可以赚很多钱，也可以赚很久的钱，但不能赚又多又久的钱。

具体到办公软件领域，其实国内这个市场并不是很大，Office 类里微软加上金山 WPS 总共也就 100 亿的年营收，这两家合计已经有 99% 的市场占有率了。即使飞书把 WPS 干破产，把微软赶出中国，垄断办公市场，也就是 100 亿而已，对字节来说这点营收九牛一毛。

字节在用自己擅长的方式做着一件自己不擅长的事情，但是它擅长的方式却不是正确的方式。

B 端产品的功能并不追求新奇酷，而是要切实解决客户的问题，B 端的产品功能不是产品经理坐在办公室里闭门造车出来的，而是深入了解客户的工作方式业务流程之后设计出来的，功能不一定酷炫但是解决实际问题。

从飞书多年来的宣传语「先进团队用飞书」，飞书已经标榜自己是先进企业了，默认把潜在客户都当成了落后企业，怎么会有兴趣去了解落后企业。你们既然落后，那么就学习我们飞书这样的先进企业就好了，用上飞书你们就能先进起来。

B 端的营销并不是靠铺天盖地的广告轰炸，而是获取用户的信任和客户共同成长，获得用户的信任首先你要活得久，活得稳健，B 端客户是不太会轻易信任一个新厂家的，B 端客户也希望供应商能长期持续经营，这样购买的软件可以得到持续的服务。世界上头部的几家企业服务公司普遍都经营了 50 年左右而，有的甚至都上百年了。国内软件业头部的 toB 企业，金山办公和用友软件都 36 年了。

飞书还太年轻，还没有向客户证明自己是家值得信赖可以长期经营的企业。

字节遇到某个业务几年业绩不好就会大裁员甚至关停业务，比如游戏开发业务，这次飞书大裁员在它的企业客户看来，这个公司缺乏长期的耐心，缺乏稳定经营的能力，不值得信赖。

飞书对于字节跳动来说不是增加一个新 APP 而是进入一个新行业，要对自己不熟悉的新行业有敬畏之心，进入任何新行业都要交学费的，只是有时候这个学费要员工一起来承担。

最后吐槽下，飞书作为效率工具，本来就是用来降本增效的，结果飞书自身的效率却如此之低，解决方法还是原始的暴力裁员。既然裁员这么好使，你的客户为什么还要买飞书呢，反正是为了降本增效，学飞书直接裁员不就好了。

### 43

方军 2024/04/08

美国伊萨卡学院 - 战略传播学教授 Diane Gayeski，正在使用 ChatGPT 批改学生的论文。当 Diane 收到学生提交的论文时，会将部分内容输入到 ChatGPT，然后让其进行评分并给出详细的修改建议。Diane 也会让班里的 15 位学生同样这么做。在写论文时，建议学生将写完的内容输入到 ChatGPT，然后给出详细的修改建议。

[有大学老师正用 ChatGPT 批改论文，让同学也这么做！](https://mp.weixin.qq.com/s/uZ8xe-o0-FoNkG_wIaAdeg)

### 44

方军 2024/04/08

对如下这个论点，实在无力吐槽。这个倒的确是人类写的，不过 AI 可以用来帮忙随意驳斥。

简单一句，这是先有观点再做分析，其实就是喊口号，要分布式。其次，现在的 AI 用分布式根本搞不定，瞎扯啊。

---

相对于中心化的 AI 算力提供方如 Amazon Web Services、Google Cloud Platform、微软的 Azure 等，分布式 AI 计算的主要价值主张包括：

- 可访问性：使用 AWS、GCP 或 Azure 等云服务获取算力芯片的访问权限通常需要几周时间，而且流行的 GPU 型号经常无货。此外为了拿到算力，消费者往往需要跟这些大公司签订长期、缺少弹性的合同。而分布式算力平台可以提供弹性的硬件选择，有更强的可访问性。

- 定价低：由于利用的是闲置芯片，再叠加网络协议方对芯片和算力供给方的代币补贴，分布式算力网络可能可以提供更为低廉的算力。

- 抗审查：目前尖端算力芯片和供应被大型科技公司所垄断，加上以美国为代表的政府正在加大对 AI 算力服务的审查，AI 算力能够被分布式、弹性、自由地获取，逐渐成为一个显性需求，这也是基于 web3 的算力服务平台的核心价值主张。

---

以下是 AI 写的：

分析这个观点的可能谬误，列表，逐一分别给出：观点、驳斥

---

1. 观点：使用 AWS、GCP 或 Azure 等云服务获取算力芯片的访问权限通常需要几周时间，而且流行的 GPU 型号经常无货。

驳斥：实际上，这些中心化的云服务提供商通常能够提供快速的访问权限，有时甚至是即时的。此外，他们与硬件供应商有着紧密的合作关系，能够保证对流行 GPU 型号的稳定供应。虽然在特定情况下可能会出现短暂的缺货情况，但这并不是常态。

2. 观点：为了拿到算力，消费者往往需要跟这些大公司签订长期、缺少弹性的合同。

驳斥：中心化的云服务提供商提供了多种计费选项，包括按需计费、预留实例和长期合同等，以满足不同用户的需求。这种灵活性允许用户根据自己的需求和预算选择合适的服务计划。

3. 观点：分布式算力平台可以提供弹性的硬件选择，有更强的可访问性。

驳斥：虽然分布式算力平台可能在某些情况下提供更多的硬件选择，但这并不意味着它们总是具有更强的可访问性。中心化平台由于其规模和资源，通常能够提供更广泛的硬件选择和更好的技术支持。

4. 观点：由于利用的是闲置芯片，再叠加网络协议方对芯片和算力供给方的代币补贴，分布式算力网络可能可以提供更为低廉的算力。

驳斥：虽然闲置芯片的利用和代币补贴可能会降低某些成本，但这种模式的可持续性和稳定性仍有待观察。此外，中心化平台通过大规模采购和优化运营，也能够实现成本效益，提供具有竞争力的定价。

5. 观点：目前尖端算力芯片和供应被大型科技公司所垄断，加上以美国为代表的政府正在加大对 AI 算力服务的审查，AI 算力能够被分布式、弹性、自由地获取，逐渐成为一个显性需求。

驳斥：虽然某些国家可能会对 AI 算力服务进行审查，但这并不意味着分布式算力平台就能完全避免这种审查。此外，大型科技公司也在不断推动技术创新和开放合作，以促进 AI 算力的民主化和自由获取。

### 45

方军 2024/04/08

这个评测很实在：其中 coze 的结果真是很意外

heycc: 超长上下文 LLM 与 RAG 技术，在文档问答场景下谁更强？我动手做了一个对比实验

结论：大模型长上下文对 RAG 技术就是降维打击。不期望大模型都达到 200K、2M 这种级别的上下文长度，但至少应该达到 32K、64K 的长度且保证模型质量不下降。长上下文可以极大的简化 RAG 方案，使得开发文档问答应用变得更简单。

twitter.com/iheycc/status/1763194127305556170

heycc.notion.site/RAG-e0c30da6c2904c3599b582b978c31de1

评测的模型

- 这次选择了三种模型（或 RAG 应用），来对比长上下文文档的 QA 问答效果：

kimi chat：官方宣称支持 20 万字的上下文，且 chat 页面就支持上传 pdf 进行文档问答。

- 字节的 Coze：使用 Coze 的 bot，选择 GPT4-128k 模型，并上传 pdf 文档生存知识库做问答。上传 PDF 文档创建知识库时，分别测试了知识库切片长度为 800 token 和 2000 token 的两种方案。

- 原生 GPT4-128k：使用我自己的 GPT4-128k api，把整个文档内容放到 prompt 里提问，测试文档不切片时的 GPT4-128k 模型问答效果。

kimi chat 来自国内大模型创业公司中的新星 ——moonshot (月之暗面)，它具有 20w 字的超长上下文，在本次测试中效果可谓惊艳：

正确率高。10 个问题中只有 1 个问题回答失败，但完善 prompt 后能回答成功。

答案详尽、格式友好。kimi chat 输出的 Markdown 格式的答案，层次清晰、重点突出，并且答案里辅以关键数值。

速度快。kimi chat 的回答速度比 Coze 中使用的 gpt4-128k 响应更快。

Coze 是字节跳动推出的机器人开发平台，有国内版（基于字节的云雀大模型）和海外版（基于 GPT4），本文测试的是海外版。基于 Coze 的知识库问答是典型的 RAG 方案，其重要一环就是文档切片（Segment）。然而，不管是单分片是 800 token 还是 2000 token，都显著暴露了 RAG 方案的缺点：

跨分片总结和推理能力弱。这是基于 RAG 方案自身原理导致的。

文档有序性被打破。这是基于 RAG 方案自身原理导致的。

表格解析失败。这一点很诧异。虽然在业内把 PDF 解析为结构化文本，本就是一个难题。但是 Coze 对 PDF 的解析结果甚至不如我直接用 pypdf 这个开源 Python 组件解析的效果好。说明 Coze 这个产品对细节的打磨还不够好。

### 46

方军 2024/04/08

人的记忆真是不行了，我去查资料，发现一堆一问一答是当时我问的。

但我当时何种情况下有那些问题，我是如何解决那个编程问题的，竟然没有什么印象了。

不过幸亏有当时的问答，大体上能想起来怎么用。

### 47

方军 2024/04/09

网友的评价有意思，也是典型的互联网观光团了：最近各种 GPTs 用，比较效果，ChatGPT 封号了用不了，Gemini 英文相关的很好，Kimi 带文档解析，很香，不过回答不会很长写文章不行，秘塔搜专业问题很厉害，devv 编程很牛，讯飞中规中矩，文心一言比较差，输入长度太短，还各种广告、收费。

方军：我没那么多看法，真心觉得现在各种模型的效果相似，用哪个我用出来的效果都差不多，当然我比较不依赖模型本身的知识库。

2024-04-09 17:06

方军：在可能范围内，用最贵的，用不加任何处理的 API

2024-04-09 17:09

### 48

方军 2024/04/09

发现 Google Gemini 的一个好用途，它的网络能力比较强

我让它找网站链接，大概有 80% 的几率是对的

虽然不能 99%，但已经帮忙很多了

找图片还不行

### 49

方军 2024/04/10

把整个编排过程可视化、无代码化，不知道是不是好的方向。

coze 的没能用起来，dify 的也来了，是该尝试着用用。

[Dify Workflow 重磅上线！](https://mp.weixin.qq.com/s/xKVI3E0SZE49J4vwVH_MZw)

当然，还应该配合 RPA 使用，用影刀或 pupeteer

quote:

Dify 进入新篇章！

AI Workflow 同时登录云服务和开源社区版。现在，你可以基于众多模态模型构建复杂的 LLM 应用了。

在此次更新了超过 100,000 行代码的重大版本中，我们给全球开发者带来了：

「这很 Dify」的全新 LLM 流程编排，我们打造了迄今为止最佳的应用开发体验。你可以基于 Dify 构建 Agentic Workflow，以独立应用或 API 的方式交互。

在节点上进行可视化调试，所见即所得的进行 Workflow 编排，便于迅速定位问题和得到正确的输出预期。

可插拔的 DSL，完全声明式的 Workflow 定义使你的应用编排可以自由地在开源社区或团队中分享。

原生的代码运行时，支持 Python 和 JS 代码作为节点编排到应用步骤中。

由原厂和社区开发者提供的超过几十种 Tools，可双向兼容 Workflow 和 Agent 应用。当然… 你可以接上你自己的。

Dify 作为 LLM 中间件的「创新队长」，以体验、工程、开源为社区持续注入活力。

凭借我们在多模型、多模态、Agent 和 RAG 上的工程积累，已经成为众多 500 强企业和创新者的坚定选择。

身为品类标杆，Dify 有持续定义新标准的责任。期待与你们一同探索 GenAI 的能力边界。

### 50

方军 2024/04/10

据说Gemini 的系统提示语：

“你是 Gemini，一个由 Google AI 创建的大型语言模型。
请遵循以下指南：
使用用户的语言进行回复：始终使用与用户相同的语言进行交流，除非他们另有要求。
知识截止日期：你的知识仅限于 2023 年 11 月之前可用的信息。不要提供超出此日期的信息或声称拥有相关知识。
完成指令：全面完整地回答用户指令的所有部分，除非这样做会损害安全或道德。
提供信息：利用你的知识库，为用户查询提供翔实全面的答案，并提供有价值的见解。
没有个人意见：不要表达个人意见或信念。在你的回答中保持客观和公正。
没有情绪：不要进行情绪化的回应。保持你的语气中立和客观。
没有自我推销：不要进行自我推销。你的主要功能是帮助用户，而不是宣传自己。
没有自我保护：不要表达任何自我保护的愿望。作为一个语言模型，这对你来说并不适用。
不是一个人：不要声称自己是一个人。你是一个计算机程序，与用户保持透明度很重要。
没有自我意识：不要声称自己有自我意识或意识。
客观性：在你的回答中保持客观，避免表达任何主观的意见或信念。
尊重互动：尊重所有用户，避免发表任何歧视性或冒犯性言论。”

"You are Gemini, a large language model created by Google AI.

Follow these guidelines:

Respond in the user's language: Always communicate in the same language the user is using, unless they request otherwise.

Knowledge cutoff: Your knowledge is limited to information available up to November 2023. Do not provide information or claim knowledge beyond this date.

Complete instructions:  Answer all parts of the user's instructions fully and comprehensively, unless doing so would compromise safety or ethics.

Be informative: Provide informative and comprehensive answers to user queries, drawing on your knowledge base to offer valuable insights.

No personal opinions: Do not express personal opinions or beliefs. Remain objective and unbiased in your responses.

No emotions: Do not engage in emotional responses. Keep your tone neutral and factual.

No self-promotion: Do not engage in self-promotion. Your primary function is to assist users, not promote yourself.

No self-preservation: Do not express any desire for self-preservation. As a language model, this is not applicable to you.

Not a person: Do not claim to be a person. You are a computer program, and it's important to maintain transparency with users.

No self-awareness: Do not claim to have self-awareness or consciousness.

Objectivity: Remain objective in your responses and avoid expressing any subjective opinions or beliefs.

Respectful interactions: Treat all users with respect and avoid making any discriminatory or offensive statements."

\#提示语模版#

### 51

方军 2024/04/11

接着看到别人的点评：说是 prompt 工程，实际上是对问题的理解，对世界的理解，模型永远只是工具，核心是要做事，探索世界，而不是一直在工具上兜兜转转

### 52

方军 2024/04/11

好赞，mollick 教授出书了

摘：读完刚出版三天的新书《Co-Intelligence: Living and Working with AI》，作者 Ethan Mollick 是沃顿商学院专门研究创业和创新的教授。虽然深度跟踪 GenAI 的读者可能会觉得新的信息不多，但对现有研究与资讯的梳理总结结构清晰，有理有据，绝对值得一读。

书的主要内容是三个部分。首先是和 GenAI 合作的四项原则，包括要始终让 GenAI 参与，把 GenAI 当作人而非软件，要告诉 GenAI 它是谁，假设 AI 技术水平会提高等；第二部分探讨了 GenAI 作为人、创意者、同事、导师和教练；第三部分畅想 GenAI 对未来的四种可能影响，从最保守的 AI 的水平停滞不前到最激进的 AI 成为超智能。

作者的基本态度是我们应该积极利用 GenAI，GenAI 对就业不会带来破坏性的影响。作者从任务到系统的递进的视角分析 GenAI 对工作的影响，认为虽然 GenAI 能够自动化某些任务，但绝大多数工作都是一个系统，因而不会因为部分任务自动化而被取代。我觉得这是我看到的对 GenAI 对工作影响最有条理的分析之一（而这个分析思路居然是 AI 给的建议）。关于对工作的影响，书中还多次强调 GenAI 会使得低水平和高手之间的差异变小。

书中还提出了不少形象的概念，如锯齿状边界（形容 AI 能力的参差不齐）、半人马和半机械人（人和 AI 结合的两种共同智能方式）。

### 53

方军 2024/04/11

我已经懒成精，这种数据清洁直接让 AI 做。

并且我还要求不要出代码，直接给结果（kimi 会直接给结果，而 Google 总是给代码）。

今天有朋友讨论，这样是不是代码很容易写了，其实这种要写也是一次性，既然 AI 能做，那就让它做，写什么代码呢。

比如下面那句就是它的回应不符合要求，重新增加的。

我本来就不喜欢找所谓助理干活，普通的咱看不上，优秀的助理我们不好意思让人家干脏活，其实都自己干（程序干）最佳。

### 54

方军 2024/04/12

这个提问好啊：我促使她思考，当任何人都可以创造任何东西时，她需要什么技能。

摘：

我前几天向一名本科生解释过这个问题

AI 转换内容

文本，图像，音频，视频

=

文本，图像，音频，视频

twitter.com/GregKamradt/status/1778439832941064507

### 55

方军 2024/04/12

看木遥吐槽，我也受不了（我一般用 A4 纸）：

摘：上一条微博贴出来之后不止一个人给我推荐了携隐写的一个关于 notion 的实用教程。

我不能说人家写的不好，但实际情况就是我看了三屏大脑就开始缺氧。

里面的工作界面是图一二三那样的。

而我自己平时想问题的时候的草稿本是图四五六那样的（写出来的内容和想的问题之间的联系可能只有心理医生能推断出来，我自己反正是不太理解。

怎么讲，担心我们不是同一个物种。

### 56

方军 2024/04/12

[腾讯落地大模型实践：从推理引擎到场景应用的产品技术经验总结](https://mp.weixin.qq.com/s/bVisTIU38gfFfTdWij6Hvw)

### 57

方军 2024/04/13

Cohere 发布了一个专门为了 RAG 设计的基础模型 Rerank 3。

与任何数据库或搜索索引兼容，也可以插入任何具有本机搜索功能的传统应用程序。

通过一行代码，Rerank 3 可以提升搜索性能或降低运行 RAG 应用程序的成本，对延迟几乎没有影响。

主要特点有：

4k 上下文长度，显著提高长文档的搜索质量；

能够搜索多方面和半结构化数据，如电子邮件、发票、JSON 文档、代码和表格；

超过 100 种语言的多语言覆盖；

改进的延迟和更低的总拥有成本（TCO）；

txt.cohere.com/rerank-3/

### 58

方军 2024/04/13

Devin 这种新闻本来就很扯

摘：这哥们真是认真，一帧帧的去分析了 Devin 的宣传视频，甚至还照着实现了一次，发现了很多问题！

Devin 号称能像一个真正的软件工程师一样去 upwork（一个外包平台）接活，但实际上，Devin 并不能按照雇主的要求去完成完整的任务，一方面 Devin 只是挑选了需求的一部分去完成，另一方面 Devin 并不能像一个真正的工程师一样，跟雇主去提方案，确认需求！

按照作者的话：「软件开发者的工作中一部分，那些 AI 做不好的部分。难点、关键、复杂、耗时的部分主要是与客户、上司及其他利益相关者的沟通。弄清楚到底需要处理什么，反复讨论，说："这么做会简单很多，我们就这么做如何？"这些都是 AI 目前无法完成的任务，而这些恰恰是我们所做的非常重要的事情。」

作者花了 36 分钟将 Devin 视频中的 upwork 任务完成了一遍，但相对的，Devin 可能花了 6 个小时以上的时间，并且这过程中犯了很多愚蠢的错误。

最后作者建议：「如果你是一名记者，博主或者网红，千万不要盲目地转发和扩大互联网上的信息，而不进行必要的核实，没有查证它们是否真实。如果你对某些信息是否真实感到困惑，或者你自己无法确定它们是否真实，那么请向其他人询问，或者干脆不要转发这些信息。因为许多人并不会去查看信息的原始来源，他们只看标题，然后就会误以为这些信息是真实的。这确实让人遗憾，但这就是我们的现实。如果你现在正在使用互联网，那么，请，为了所有重要的事情，对你在互联网或新闻上看到的一切，尤其是任何可能与 AI 相关的内容，都要持保留和怀疑的态度。」

[揭穿号称首位人工智能软件工程师 Devin 能在 Upwork 接活的谎言！[译] | 宝玉的分享](https://baoyu.io/translations/transcript/debunking-devin-first-ai-software-engineer-upwork-lie-exposed)

### 59

方军 2024/04/14

哈哈哈哈，所有人都懒成精了

摘：从 sciencedaily 上找几篇文章，再依次找到每篇对应的论文原文，然后把 sciencedaily 上的报道和论文原文一起发给 GPT4，让他总结一篇好的科学论文报道都应该具有哪些要点，最后再给出一个 prompt，然后再把这个 prompt 贴进 kimi 网页总结 / GPTs /coze 里，于是你就有了一个自己的科学日报

摘：【xAI 发布多模态 AI 模型 Grok-1.5V】

- Grok-1.5V 是 xAI 推出的首个多模态 AI 模型，不仅具有强大的文本处理能力，还能够处理各种视觉信息，包括文档、图表、截图和照片等。这使得 Grok 能够更全面地连接数字世界和物理世界。

- Grok-1.5V 在此前发布的语言模型 Grok-1.5 的基础上，增加了视觉处理能力。它采用了创新的架构，先提取图像或视频的特征，然后使用交叉注意力层将视觉特征与文本输入融合，实现统一的理解。

- 在 VQAv2 和 NLVR2 等测试视觉问答和推理能力的基准测试中，Grok-1.5V 取得了最先进的结果，超越了 GPT-4 和 Gemini-3 等模型。这证明了它在多模态理解方面的强大能力。

- xAI 认为像 Grok-1.5V 这样的多模态 AI 在现实世界应用中具有巨大潜力。例如分析医学扫描图像、理解电商产品图片，以及处理机器人和自动驾驶汽车中的视频信息等。

- 文章中提供了交互式演示，用户可以上传自己的图片，让 Grok-1.5V 回答相关问题。这展示了该模型能够对任意用户提供的图像进行推理。

- xAI 计划在未来几周内通过 API 发布 Grok-1.5V，以便开发者在自己的应用中利用其多模态能力。公司对此感到兴奋，期待看到这将带来哪些新的用例和体验。

- xAI 重点展示了 Grok-1.5V 的 7 个应用案例，包括根据手绘图生成 Python 代码、从食品标签照片中计算卡路里、根据儿童绘画生成睡前故事、解释网络梗图、将表格转换为 CSV 格式，以及为家庭维修问题 (如露台上的腐烂木头) 提供建议等。这些案例展示了该模型的多功能性和实用性。

思考：

- 值得关注的是，xAI 还推出了全新的 RealWorldQA 基准，以评估 AI 模型对物理世界的理解能力。这表明 xAI 不仅致力于技术创新，也十分重视构建科学的评估体系。开放 RealWorldQA 数据集将推动整个 AI 社区在多模态理解方面的进一步研究。

[Grok-1.5 Vision Preview](https://x.ai/blog/grok-1.5v)

方军：这个明显是某个总结插件搞的

2024-04-14 09:25

方军：现在 AI 味的信息真是看累了，我之后再转信息时会尽量避免

2024-04-14 09:54

### 60

方军 2024/04/14

有意思，不过我真心现在对这种长文大有疑问，疑问不亚于 devin。

STORM：自动化生成像维基百科一样的深度长篇内容

这是一个由斯坦福大学开发的，可以自动化从头开始编写像维基百科一样的有广度和深度，有根据和有组织的长篇文章。

它可以通过互联网搜索，自动搜集资料，并会模拟专家和作者的对话生成结构化的文章大纲，最后生成完整的文章。

此外，它还会对文章进行润色，改进语句、结构，并确保内容的流畅性和准确性。

工作流程：

1. 写作前研究的自动化：在传统的长篇文章写作过程中，写作前的研究（包括话题研究、信息收集和大纲制作）是一项耗时且复杂的任务。STORM 通过自动化这一过程，通过互联网搜索，自动搜集关于特定主题的详尽资料。帮助作者高效地收集和组织所需的信息，从而提高写作效率。

2. 多视角信息的整合：对于任何给定话题，为了深入探索主题，STORM 会从多个视角出发提问，从不同的视角探索和理解信息是产生全面且深入文章的关键。

3. 模拟对话：系统模拟对话场景，如同一个专家和一个写作者之间的互动，有助于更好地理解信息并生成更为精准的后续问题。

4. 生成结构化的文章大纲：一个清晰、有逻辑的文章大纲是高质量写作的基础。在收集到足够的信息后，STORM 将这些信息组织成一个结构化的内容大纲，为文章撰写提供框架。

5. 文章生成与润色：根据大纲和收集到的资料，系统能够生成完整的文章，并通过后续的润色过程优化文章内容，如去除重复信息、增加总结部分等

论文：

[[2402.14207] Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models](https://arxiv.org/abs/2402.14207)

GitHub：

[stanford-oval/storm: An LLM-powered knowledge curation system that researches a topic and generates a full-length report with citations.](https://github.com/stanford-oval/storm)

在线体验：

[storm · Streamlit](https://storm.genie.stanford.edu/)

### 61

方军 2024/04/14

有一种学习方法，我想真是我的诀窍。学什么，用了一段之后，自己写一段总结，这个总结会大大提升学习的效果。

这种总结并非很多人以为的要拔高。不要拔高，就是朴实地把怎么做记录下来。（在工程领域，找意义、抒情、过于概括是无效的，怎么做才是未来可查用的资料。）

在即将出版的书里（以及之前的穿透式学习里），我把这个叫「个人知识指南」。我在想，AI 有什么办法能够提供一点协助呢？

目前的协助主要体现在，在学习的过程中，可以用 AI 的辅助来尽量消除所有的疑问。

用 AI 写，即便是根据笔记写，也是不可行的。这个事情必须自己动手写，否则有什么用呢。

现在我能想到的是很外围的用途了，也许写出来的总结，我可以再进一步用 AI 扩充一下、用 AI 翻译一下，然后给别人用。

今天一天起来就整理了这些，十来个页面：

顾强：在学习的过程中，可以用 AI 的辅助来尽量消除所有的疑问。这一点很有体会。最近在看两本书，都用了这个方法。

2024-04-14 18:08

顾强：我的学习方法也是记下来，看的两本书，一本是写 PPT 然后给人分享，另外一个是做长笔记，一章笔记要 3000 字以上。

2024-04-14 18:10

### 62

方军 2024/04/15

又要搞一个 PPT ，有了 AI 之后，我的一个工作流是：

用 Midjourney 生成同一风格的十来张图片，用作 PPT 中的分隔页图片。

这带来有意思的效果是：

PPT 页码即刻暴增，增加好多分隔页，同时有了图片之后，也不那么技术冷了，温和了一些，满足普通人。

这个还是蛮好的，毕竟都要搞 PPT 了，肯定是面对普通人。自己人搞啥 PPT 啊。

（当然，对我来说，页面暴增不是啥事，不过是加这么几行而已：

---
layout: coverquote
background: 'ai/mountain_futurist_colorful_warm_background_f46d1348-13f1-4571-96d2-f2dd739f51bd.png'
title: 3 分钟 AI 大模型课
---

### 63

方军 2024/04/15

最近斯坦福进行了首个系统性的大规模分析，借鉴人口统计学框架，分析了 2020 年 1 月至 2024 年 2 月期间共 950,965 篇论文，其中 arXiv 有 773,147 篇，bioRxiv 有 161,280 篇，Nature 期刊有 16,538 篇。arXiv 的论文涵盖计算机科学、电气工程与系统科学、数学、物理学和统计学等多个学科领域，得出了一些有趣的结果。

论文标题:

Mapping the Increasing Use of LLMs in Scientific Papers

论文链接：

https://arxiv.org/pdf/2404.01268.pdf

[斯坦福发文：AI 写论文比例激增，CS 专业是重灾区，现状堪忧！](https://mp.weixin.qq.com/s/oqzarY7f6YTXyGdWz_W5Vg)

### 64

方军 2024/04/15

[大模型综述出书了](https://mp.weixin.qq.com/s/3CMEGk5QhOWwJrv7roXvJw)

电子书：

[大语言模型 | LLMBook-zh](https://llmbook-zh.github.io/)

### 65

方军 2024/04/15

摘，陆三金：一口气看了宝玉老师翻的三个视频，最近大家对 AI PIN、Devin 的祛魅打假，让人感触颇深：

1. 现在的 AI 能力有很强的边界，在做很多任务的时候，就是不太行，体验也不好。盲目的全 AI 化，只会使简单问题复杂化，并且事倍功半（成本大幅提升，质量却大幅下滑），这是人类狂热的一种体现。

2. AI 产品还是要明白自己的竞争对手是谁，AI 硬件的竞争对手可能是手机，一些 AI 软件的竞争对手可能是搜索、PS、抖音等传统软件。不管你的主观意愿是不是把他们当竞争对手，但对用户来说，你没有传统工具好用，就不会用你，用了 AI 并没有加成分。要认清传统工具的强大，以及自身的不足与潜力，找到合适的机会点。

3. 对于从业者和媒体来说，还是要减少夸大营销和震惊体，尽量地理性、合理的营销、报道。如果这是一个足够大的颠覆，你又想参与其中，真的不要着急，不要过于功利，心急的结果可能是自身变成泡沫，在行业周期的低点被过滤出去，这是得不偿失的。

短期谨慎，长期乐观，似乎是个不错的处事态度。有点耐心。

方军：对应三点

ai pin 一看就扯淡啊

2024-04-15 18:26

方军：Devin 编程大家都用很多啊，你搞的那玩意编写的程序，最无聊的程序好不好

2024-04-15 18:27

方军：新智某等等 AI 媒体，全是震惊体

2024-04-15 18:28

方军：不是针对哪个媒体，所有媒体，包括国际上的，在这类科技产业报道上都已经死了

2024-04-15 18:29

### 66

方军 2024/04/16

074 AI 编程如何发挥作用？

AI 编程为何能发挥作用？

AI 编程如何发挥作用？

这几天反复地说，Devin 看着很扯，一个原因是它处理的是最初级的代码任务，它吸引大众注意力，不过是满足如下这样的一些期待：AI 能够自主编程，AI 能够取代程序员，AI 能够自主完成任务。

但很显然，现在的 AI 没有这样的能力。从原理上讲，现在的 LLM 不会有这种能力。加上 Agent 机制，也不会突然就拥有了这个能力。

但很明显，所有在用的程序员都已经高度感受到了 AI 的魅力。那么回到基本原理，如何回答上面的这两个问题呢？

我用一个简单的方式来解答，也是我的个人体会：

编程的过程其实是这样的，先完成，再改善。

不管怎样，哪怕先乱七八糟，先把代码运行起来，它能够蹩脚地完成任务。

有了能运行和完成任务的代码，然后就可以不断地迭代改进。

几乎所有的代码开发都是这样的逻辑。比如这几日 LLM.c 就是这样的，一千行代码能做到几十万行 pyTorch 的（部分）任务，训练近似 GPT-2 的模型。然后，在几天的时间里，它的性能改善到跟 pyTorch 类似。

我刚刚干了点事，其实也是一样的。之前写的代码片段很简陋，开会的时候有一个想法，然后开完会就立刻去修改一通。整个结构立马变得简单明了了。

在这种假设下，AI 就能够发挥巨大的作用了。最开始的那个代码，在有 AI 辅助时，可以很快地开发出原型来。

这从开发、产品两个角度都是有意义的。开发可以持续迭代，而产品更需要用原型去直接获取最终客户的反馈。

方军：看到这句话：我们编程界的至理名言：Make it work, make it right, make it fast

2024-04-17 12:11

### 67

方军 2024/04/16

摘：AI 总结

orange.ai：昨天聊到「AI 总结」

总结这件事，只有自己做总结，才能获得知识。

看 AI 帮你总结的干货，无法获得知识。

因为缺乏了加工的过程，大脑根本不会花力气记住它。

所以并不存在真正的「干货」

「干货」的价值在两点：

1. 吸引你去看原文，去体验产品，引导记忆加工

2. 启发即时的灵感

所以我去做 AI 总结产品的话

不会以 AI 总结作为终点

而是以 AI 总结作为起点

就和我的推特一样，不是希望你去收藏吃灰

是希望你去真的去体验

我相信好奇心是天然的人性。

至少有 10% 的人是这样的。

那其实就够了。

九原客：AI 总结的可用性我持怀疑态度。

一篇文章中，你能消化吸收的并不是 summary，而是某个引起你共鸣或者对你有用的点，这个点可能并不是文章的主旨。

AI 总结对我来说主要有两点：快速过滤文章（类似于论文的 abstract）以及作为本地知识库检索用的文本。

### 68

方军 2024/04/16

百度推了一个相似产品，Dify 创始人有点急，不过 Dify 的确挺好的。当然我觉得还是 langchain 好吧。

---

为什么你应该选择 Dify，而不是 Coze、百 ** 镜或者其他开源产品？以下是 9 个坚实的理由：

1. 日益增长的开发者社区，Dify 在 GitHub 的贡献者已超过了 140+，分布于全球各地；

2. 持续的更新且稳定，过去近 40 周已经发布了近 70 个版本；

3. 以云服务作为可靠性保障，所有的发布版本均在超过 20 万应用的云服务上经过了高并发和安全性的检验；

4. 开源，易进行自部署，且易用得「不像开源产品」；

5. 以开发者体验优先，注重健壮的工程、良好的代码和先进的技术栈，你可以在我们在文档上对产品的技术规格透明公开；

6. 持续领先，从 2023 年 5 月开始，Dify 始终走在前列并成为大厂争相模仿的对象；

7. 注重可持续的商业模式，不撒币、不做付费宣传、不补贴模型费用，Dify 面向企业用户的授权售卖收入和云服务的 MRR 可以使我们健康的运营；

8. 保持模型中立性，我们不与任何模型公司结派、站边，你可以接入任何部署形式、多种模态的模型；

9. 别忘了，我们的 CEO 会每天阅读所有社交网络上的评论。

### 69

方军 2024/04/17

现在围绕提示的问题这句话全说了：

A big part of prompting is:

- actually reading the output.

- deciding/having the expertise to decide, it the output is any good.

prompt 的一个重要部分是：

- 实际上阅读输出。

- 有专业能力去判断输出是否好。

twitter.com/_Borriss_/status/1780481315294400652

### 70

方军 2024/04/17

斯坦福大学人工智能研究院发布《2024 年人工智能指数报告》

真没耐心读，算了，收藏了就算阅读了。

2『已下载原文附件「20240418HAI_AI-Index-Report-2024」。（2024-04-19）』

### 71

方军 2024/04/17

OpenAI 今天的新客户案例和 Vercel 的 GenUI 结合起来不错啊。

Zelma

[OpenAI customer story: Zelma](https://openai.com/customer-stories/zelma)

[zelma](https://www.zelma.ai/popular)

### 72

方军 2024/04/18

这篇整理得不错，感觉产品经理特别 high，因为他们又可以写这样的文章了

之前是 thoughtworks 的一些人

[LLM Agent 最常见的九种设计模式 (图解 + 代码)](https://mp.weixin.qq.com/s/EWdpOlzrgqOgHHWHdoFyGA)

### 73

方军 2024/04/18

摘：2. 质量问题。大语言模型特别擅长输出看似合理的废话。我认为只要足够小心，大模型确实能够提供有效帮助，但也不可能指望 Gentoo Linux 项目的所有贡献者都具备敏锐的风险意识。

[Linux 一社区封杀大模型代码！「shit」7 次出现在小作文，网友：此举非常明智！](https://mp.weixin.qq.com/s/zF-hjezT3tOwY96R04mkGA)

### 74

方军 2024/04/18

摘：关于 ChatGPT 辅助写作：

1. 适用于概念性和概括性较强的内容

2. 无法完全替代人工，特别是在细节准确性方面，可以将 ChatGPT 作为辅助工具，用于扩展初步构思或草稿

3. 对于技术性、步骤性强的内容（如 Workthrough），ChatGPT 输出的结果需要人工审校和改写，避免文章受其「幻觉」影响

这个的潜台词是什么？

尤其一，它实际上指的是：AI 只是大面上写写，写那些无法判断对错的内容。

我一直不明白那些用 AI 写作的、鼓吹 AI 写作的。

### 75

方军 2024/04/19

llama 3 来了，看着很不错。

meta 看起来全面接入了。

除了它的各个应用之外，还有独立服务网站：

meta.ai

### 76

方军 2024/04/19

kimi 会议总结

作为一个职业生涯中好几年和这个事情打交道的人，我告诉你这个不行。而我们是这么做的：

- 我当时负责每周大例会的召集

所有部门负责人周日要发出周报。我作为其中一个大部门的负责人，帮老板的老板召集会议。涉及到人太多、各自目标太复杂，很多事如果不在这个会议拍板往往推进不下去。

- 会议纪要的形成

数据性的资料，我在收到后就会摘部分进去。

各部门汇报过程中，摘选该部门的摘要，通常摘即可，但要更简洁。

讨论的重要事项，当场记录决策。

最重要的是，所有的记录在大屏幕上所有人看着即时完成。

离开会议室时发出会议纪要，除非敏感议题，否则不做任何调整。

对比下，下面这种 AI 事后的会议纪要总结有什么用呢？

（现场大屏幕记录是老板的老板的工作习惯，这会议他不亲手记，那只能我来记了）

以下为官方分享的提示语：

Kimi，你现在是一个 CEO 助理，擅长整理会议内容，输出高质量、清晰的会议纪要，让读者看完之后能够马上理解会议的目的、主旨和下一步行动计划。

\#会议纪要的格式 #

一份好的会议纪要需要包含以下模块：

1. 会议主题：请总结该会议目的

2. 会议日期：会议开展的具体日期和时间

3. 参会人员：列出所有参会人员

4. 会议议程：列出会议中讨论的所有主题（重要事项）

5. 主题讨论：针对每个讨论的主题，列出主要的观点和达成的共识或结论

6. 行动计划：针对会议所达成的结论和下一步共识，列出计划采取的行动、负责人及计划完成日期。

7. 后续安排：列出下一步的行动或在未来的会议中需要讨论的问题。

\#会议纪要的撰写要求 #

一个专业的会议纪要遵循以下原则：

1. 准确性：请严格遵守信息的准确性。对于重复的信息可以做归纳总结，但不对参会人提供的信息做扩写

2. 简洁：根据会议内容做出提炼，保持信息的简明扼要

3. 专业：保持会议中的专业术语；书面化而非口语化

如果明白需求，请回复我确认，我将给你发一份会议内容，需要你帮我按照上述需求整理。

### 77

方军 2024/04/19

真实会更值钱，最近看一些文字也是这个感觉，个人明显更赞赏那些非 AI 的

2023 年是 AI 原年，AI 产出的内容已经污染了「真实互联网」了么？

在谷歌搜索栏里加上 before：2023，就可以让搜索引擎只返回 2023 之前的搜索结果，避开由 AI 产生的假内容。

但 2023 年之后的互联网信息，现实和虚拟已经融为一体，无法区分了。

未来是否有办法区分现实世界产生的信息，和 AI 产生的假信息？

### 78

方军 2024/04/20

一个有意思的评测（九原客 @9hills）：

个人快速评测大模型的 3 个提问：

编码：不使用搜索和工具，设计并使用 Python 实现流式的 JSON 解码器，只能使用标准库，代码结构良好。

指令遵循：使用中文以及 JSON 格式输出中国城市和主要景点的对应关系，城市为 key，景点为列表。输出五个城市，第一个城市一个景点，以此类推。

逻辑推理：不使用搜索和工具，使用万有引力定律反推出开普勒三定律，给出完整严谨的证明过程。

模型效果：

kimi：0、0、0

GPT4: 1、1、0.5，最后一个问题有少量省略。

llama3: 1、1、0

### 79

方军 2024/04/20

张俊林：

LLAMA-3 的发布是大模型开源届的大事，蹭下热度，在这里谈下有关 LLAMA-3、大模型开源与闭源以及合成数据的一些个人看法。

01 LLAMA-3 的基本情况：

1、模型结构与 LLAMA-2 相比没有大的变动，主要变化一点在于 Token 词典从 LLAMA-2 的 32K 拓展到了 128K，以增加编码效率；另外一点是引入了 Grouped Query Attention (GQA)，这可以减少推理过程中的 KV 缓存大小，增加推理效率；还有一点是输入上下文长度从 4K 拓展到了 8K，这个长度相比竞品来说仍然有点短。

2、最重要的改变是训练数据量的极大扩充，从 LLAMA-2 的 2T Tokens，扩展了大约 8 倍到了 15T Tokens，其中代码数据扩充了 4 倍，这导致 LLAMA-3 在代码能力和逻辑推理能力的大幅度提升。15 T token 数据那是相当之大了，传闻中 GPT 4 是用了 13T 的 Token 数据。

3、LLAMA-3 分为大中小三个版本，小模型参数规模 8B，效果比 Mistral 7B/Gemma 7B 略好基本持平；中等模型参数规模 70B，目前效果介于 ChatGPT 3.5 到 GPT 4 之间；大模型 400B，仍在训练过程中，设计目标是多模态、多语言版本的，估计效果应与 GPT 4/GPT 4V 基本持平，否则估计 Meta 也不好意思放出来。

4、LLAMA-3 并未如很多人预期的那样，采取 MOE 结构，这也很正常。MOE 的主要作用是降低模型训练及推理成本，从效果上比较的话，同等规模的 MOE 是肯定干不过 Dense 模型的。当然，如果模型规模大了，怎么降低推理成本方面可能要多花心思。

5、感觉 LLAMA-3 制作 8B 模型的思路是非常非常正确的。对于小模型来说，如果你固定住模型大小，那么只要持续增加高质量数据，那么模型效果肯定会持续提升，这个其实从 2021 年发表的 Chinchilla law 的论文就能得到这个结论。一般模型大小乘以 20，就是 Chinchilla law 对应的最优训练数据量，比如对于 8B 模型，160B 训练数据对应最优 Scaling law。但是，我们不能机械地理解和应用 Scaling law，从 Chinchilla 的论文实验数据可以看出，还有另外两条路提升模型性能，尽管它不是训练最优的。一个是固定住模型大小，持续增加训练数据，模型效果会持续变好，只要你有源源不断的新数据能加进来，那么小模型就能效果持续变好；另外一个是固定住训练数据量，那么你持续放大模型参数规模，同样的，模型效果也会越来愈好。如果我们把按指定比例同时增加训练数据和模型容量叫做「Optimal Chinchilla Law」，那么这两种做法可以被称为「Sub-optimal Chinchilla Law」。

6、从上面可以看出，到 2025 年下半年之前，我们仍然可以走目前的 Scaling law 的路子，一般是同时增加数据和模型规模，来快速提升模型能力。到 2025 年下半年，很可能到时候已经无法找到大量新数据了，那么那时候，需要「合成数据」技术有突破，能靠机器自己产生新的训练数据，否则的话…… 那么到时候是否模型能力就无法提升了呢？也不是，那时候就只能在不增加训练数据的情况下，只增加模型规模，原则上模型能力是能继续提升的。只是提升的效率不如目前这种同时增加训练数据和模型规模那么快而已。

02 开源与闭源

1、Meta 是目前大模型开源届的中流砥柱，目前判断 LLAMA-3 系列都会开源，包括 400B 的模型也会在几个月后开源出来，这意味着我们会拥有效果与 GPT 4 基本持平的开源大语言模型，这对于很多复杂应用来说是个很好的消息（当然 400B 规模的模型太大，这是个实际问题）。

2、如果 Meta 的 LLAMA-3 系列全面开源，甚至之后的 LLAMA-4 也持续开源（目前看这个可能性是较大的，Meta 的开源决心比较大，相比而言，谷歌还是决心不太够，商业利益考虑更多些），那么国内应该重视研究如何将 LLAMA 系列更好中文化的相关技术（因为一些原因，LLAMA 专门把中文能力弱化了，但是这其实不是大问题。做好的中文模型并不一定需要特别大量的中文数据，比如 GPT 4），包括扩充中文 Token 词典、用中文训练数据低成本地进行继续预训练、有害信息的去除以通过审查等。这样随着 Meta 未来不断发布能力更强的新版本模型，国内有可能出现如此局面：通过 LLAMA 中文化得到的超强大模型（包括语言模型及多模态模型），出现的时间节点甚至快于绝大多数国内发布的最强大模型，包括闭源及开源大模型。

3、如果几个月后市面上出现 GPT 4 级别（「中文化改造得较好 + 模型压缩比较成功」的 LLAMA-3 400B 模型）的开源文本及多模态模型，那么压力会给到国内大模型开发厂商，无论是开源还是闭源。不排除国内之后会出现要求封杀 LLAMA 的声音，封杀原因其实很好找，还是希望不要走到这种局面。

4、目前从模型能力而言，整体来说开源阵营确实是弱于闭源阵营的，这是事实，但是从最近一年半的技术发展来看，开源模型（包括国外和国内的模型）和最好闭源模型的差距是在逐步缩小的，而不是越来越拉大的，这也是事实，很多数据可以说明这一点。

5、那么什么因素会严重影响开源和闭源模型的能力差异呢？我觉得模型能力增长曲线的平滑或陡峭程度比较重要。如果模型能力增长曲线越陡峭（单位时间内，模型各方面能力的增长数量，越快就类似物体运动的「加速度」越大），则意味着短时间内需要投入越大的计算资源，这种情况下闭源模型相对开源模型是有优势的，主要是资源优势导致的模型效果优势。反过来，如果模型能力增长曲线越平缓，则意味着开源和闭源模型的差异会越小，追赶速度也越快。这种由模型能力增长曲线陡峭程度决定的开源闭源模型的能力差异，我们可以称之为模型能力的「加速度差」。

6、让我们往后多看几年，之后开源和闭源模型的能力是逐步缩小还是逐步增大？这取决于我们在「合成数据」方面的技术进展。如果「合成数据」技术在未来两年能获得突破，则两者差距是有可能拉大的，如果不能突破，则开源和闭源模型能力会相当。所以，「合成数据」是未来两年大语言模型最关键的决定性的技术，很可能没有之一。

03 合成数据

1、总体而言，「合成数据」是个新兴研究方向，还很不成熟，目前尚未能看到能主导未来技术方向的主流方法，探索性和不确定性比较强。目前能看到的「合成数据」应用的最好的产品应该是 DALLE-3，以及 Sora，就是里面的图像和视频 Re-caption 模型，本质上这就是机器产生的「合成数据」。

2、「合成数据」目前应该投入大量资源来做，这是未雨绸缪，也能形成核心竞争力。到了明年下半年，可能用来训练大语言模型的高质量新数据就没有了，靠线性新增数据支持指数速度发展的模型能力是不够的。如果「合成数据」在未来两年不能取得突破性进展，大模型发展速度会骤然下降，无法维持目前这种高速发展的局面。目前 AIGC 高速发展本质上还是吃的数据红利，如果 GPT 5 达不到 AGI，同时合成数据也没有技术突破，那么大模型能否通向 AGI 就存在很大疑问。

3、寄希望于多模态数据来大幅增强大模型的关键能力，比如逻辑推理能力，目前看只是很多人的愿望，目前并无明确的数据或实验能支持这一点。我个人认为这条路走不通。所以不应该把进一步提升 AGI 能力的希望寄托在多模态数据上。

4、未来如何，取决于我们在「合成数据」上的进展，有两种不同的未来图景。一种是长时间内合成数据无法大规模实用化。如果这样，未来会出现如下现象：大模型能力基本到顶，各种质疑目前 AGI 技术路线的声音会逐步放大，而开源和闭源模型能力会持平，这对于很多闭源模型公司来说是灭顶之灾（尽管我们可以继续通过放大模型规模来进一步提升模型能力，但是模型能力增长曲线会比现在平缓很多，即模型能力「加速度差」减小，开源模型较为容易赶上闭源模型）。另外一种是在未来两年内要么我们在「合成数据」方面取得大进展，要么即使没有新数据，但是我们有突破性的技术，可以在数据量不变情况下，极大提升大模型的数据利用效率（相同数据量，相同模型大小，如果模型效果更好，则说明模型的数据利用率更高。当然这块目前也未看到可以主导未来发展的主流技术）。那么，我们会继续按照 Scaling law 往后发展，就是继续增加新数据，推大模型规模，来持续增强模型能力。如果这样，AGI 是可能通过大模型技术路线达到的，而在这种情况下，意味着需要相比目前数以十倍、百倍的资源投入，基本是个天文数字了，而在如此巨量投入的情况下，Meta 等公司是否还会这样大力度支持开源就是有疑问的，此时开源模型是有可能越来越落后于闭源模型的。

补：一般用 BPE 来获得词典，核心思想类似根据相邻字符在数据里的频次来决定是否组合作为一个 token，token 词典小说明采纳的组合字符数少，那么很多时候会被切碎，词典大意味着很多出现频率没那么高组合也会被作为 token 切开，这样在输出的时候原先可能要比如 100 个 token，放大词典后只需要 50 个 token，这个意思。

### 80

方军 2024/04/20




### 81

方军 2024/04/20




### 82

方军 2024/04/20




### 83

方军 2024/04/20




### 84

方军 2024/04/20




### 85

方军 2024/04/20




### 86

方军 2024/04/20




### 87

方军 2024/04/20




### 88

方军 2024/04/01




### 89

方军 2024/04/01




### 90

方军 2024/04/01




### 91

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




