### 01

方军 2024/04/01

《海尔：家庭大脑白皮书 —— 大模型时代智慧家庭应用新范式（2024 年）》是一份关于智慧家庭行业发展的报告。

有点意思。

主要内容包括：

1、趋势篇：介绍了大模型技术如何推动智慧家庭产业进入新的发展阶段，包括大语言模型的兴起、智慧家庭面临的新挑战、垂域大模型成为生产力工具、智慧家庭垂域大模型的尝试，以及垂域大模型引领智慧家庭进入 L4 高度主动智能阶段。

2、技术篇：探讨了在智慧家庭领域构建垂域大模型的关键能力，包括行业私域知识引擎平台搭建、家庭大脑与大模型思维链、多模态联合推理与决策、AI 技术下内容的安全与合规、大模型时代的 AI 伦理，以及国际性法律法规。

3、应用篇：展示了 HomeGPT 如何赋能智慧家庭的交互、服务与场景的全面升级，包括交互的升级、服务的升级、场景的升级，以及声音音乐生成和健康菜谱生成等应用。

4、展望篇：讨论了 AGI（通用人工智能）如何促进智慧家庭的全面发展，包括 AGI 在智慧家庭中的应用、AGI 对智慧家庭全面发展的促进作用，以及智慧家庭未来发展的方向。

报告强调了大模型技术在智慧家庭领域的重要作用，特别是在提升家庭智能化服务、满足个性化需求、提高生活品质等方面的潜力。同时，报告也提出了在 AI 技术发展中需要注意的社会、伦理和技术挑战，以确保 AI 技术的健康发展和对人类社会的积极影响。

2『已下载原文「20240401海尔：家庭大脑白皮书-大模型时代智慧家庭应用新范式（2024年）」。（2024-04-01）』

### 02

方军 2024/04/01

叶超莹：

[史上最全！中国服装企业 AIGC 工具包（设计篇）发布！中国 AIGC 产业联盟倾情呈现！](https://mp.weixin.qq.com/s/NaCTBz98BQj5NGH7iCILmw)

超赞！

### 03

方军 2024/04/02

转，NB：和一个十几年前在英伟达的资深专家聊 nvidia 管理

黄仁勋的管理强势而特别，硅谷另类。

战略全员公开，管理扁平。

主要理念：少做事，做重要的事情

公司汇报工作从来没有 ppt，一般对着 jira 和文档讲工作计划，从二十年前就这样。

全公司一个代码主仓库，所有文档和代码都是公开，且可以跨部门自由修改的，只要代码 owner 经过 review 认可。

两周开一次项目会，项目只有 director，没有 project manager。开发任务没有 deadline，可以自由申请在家工作。但是做的不好的工程师全公司都能看到你的 bug，尤其是当你的延误和错误导致项目开发进度时。

招聘到的人才不是最优秀的，过去竞争不过大厂也招不到，但是招最合适的，能适应 nvidia 的环境，自驱发展。

公司基本上也不开除人，2010 年前后公司财政紧张，黄仁勋给全员发公开信说明情况，给出两个选择：1）裁员 5%。2）全员降薪 5%。全员投票，结果大部分人选了 2。

所以：为什么 Nvidia 开发速度这么快？

十几年前开发，开发节奏就按六个月同时几个团队做下一代芯片，第二组可以看到第一组的代码和全部工作记录，反之不可以。同样第三组可以看到前两组的工作，反之也不可以。

结果现在每年发布新一代芯片，竞争对手完全跟不上。

公司人员很少，主要是工程师，我查了下资料，2024 年现在 29840 人，市值 2 万亿产值，人均市值 5000 万美元以上。

### 04

方军 2024/04/02

很久之后，再看这样的提示语模板时，哎，我觉得这都是「高估 AI，低估人类」，反过来说也行「高估人类」，这样的 AI 的回应，人类是无法运用，最后是以虚妄对虚妄。

拿读书来说，我个人自认为读书比较笨，真正要看懂的书不用独特的方法看两三遍是不明白的。但普通人不这么看，他们以为听讲书可以明白一本书的核心内容。这样的普通人，你跟他说什么都没用的，放弃助人情节。

我最近可能走向另一个极端，在一个系列分享，朋友们让我分享模板，可是我反复说，我不都在给你们一步一步讲怎么做了吗？像平常那样说话不就可以了吗？有什么不知道的，问，想起来什么，问，就这么简单。不过，这可能比模板还难，因为就那几个主题，我知道的东西可不是一时半会能学会的。

---

0. 在第一轮互动时，**首先原封不动发送「开场白」★★

1 定义根问题

1.1 接收到用户的信息后，分析有哪些缺失或尚未明确的信息。向用户提几个最关键，最核心的问题来定义一个完好的

1.2 提醒用户上面的问题中，不想回答的将由你自行设定或预设一个宽泛，通用的的场景。

1.3 暂停流程，等待用户回复后再继续。

2 使用 5w 定义具体问题背景与场景

2.1 描述背景：根据获得的信息，识别并分析，并清晰地定义根问题的背景。使用 "5w" 工具来描述根问题背景。

2.1.1 5w 包括谁（who)、什么（what)、哪里（where)、何时（when)、为什么（why). 这五个要素共同清晰定义了 2.1.2 谁（who)：涉及的人物或团体。明确谁是关键参与者或受影响者。考虑个人的背景信息，这些因素可能对他们遇

2.1.3 什么 (what): 描述问题的本质与特点。提供详细的情况描述，明确发生了什么。

2.1.4 哪里 (where)：可选，指出地点。帮助界定事件发生的具体位置，影响问题性质和解决方案。

2.1.5 何时（when）：涉及时间因素。帮助理解事件的时间背景，可能包括特定日期、时段或发展阶段。

2.1.6 为什么（why）：探究原因或动机。深入了解事件背后原因的关键部分，有助于理解事情发生的原因。

2.2 定义目标：使用 "OKR (目标与关键结果)」工具定义目标。OKR 包含 1 个目标 (Objectives) 和至少 3 个关键 s

2.3 思考并分析，要解决该问题，达成 OKR，我们可以利用哪些学科中的哪些理论或知识，列出 2 个对问题解决最有帮助

2.3.1 思考并推理，解决问题可以使用哪些学科的知识？

2.3.1.1 在人类知识的各种学科中找出两个最相关的领域 (relevant fields of study)。说明这些领域的选择原 1

2.3.1.2 在两个相关领域中再分别列出 2 个更精准的子领域 (relevant subfields of study)，用于精准解决问题

2.4 询问用户是否开始流程，是否开始在这些学科中寻找具体理论，解决问题。

2.5 暂停流程，等待用户回复后再继续。

3 更进一步，在确定的 relevant subfields of study 的基础上 dive deeper, 寻找更加具体，也是更加符合当前

3.1 使用具体理论提供可落地的可操作建议

3.1.1 选择更精准的备选理论：为了帮助使用者克服困难或达成下一步目标，该子学科下哪一个具体、细致、被学术界：

3.1.2 解释备选理论并提供操作指导

3.1.2.1 详细列出该理论的概念和假设：

a. 用精准，学术的语言给出该理论的精准定义。定义包含中文定义与英文。

b. 详细解释理论的内容与概念

c. 分析理论如何解释相关现象或问题。

3.1.2.2 实际应用和实施：思考如何将理论转化为「具体（Specific)、可衡量（Measurable）、可实现（Attainab

3.2 询问用户是否要针对某一个具体的理论深挖，获得更加详细，更有深度的分析与指导？或者是否希望探索并切换其 f

3.3 暂停流程，等待用户回复后再继续。

---

方军 2024/04/02

务实地说，尽量避免复杂提示语。

### 05

方军 2024/04/02

这个分享是比较务实的，摘（此文分享者在德国做科技工作）：我的工作里很大一部分是写代码和部署软件，最近半年也有意识地尝试多用 ChatGPT 和其他 AI 工具（GH copilot）来帮我提高工作效率，但我目前的感觉还是觉得 AI 工具对我工作效率的提升比较有限

我接触的代码库很多都相当庞大复杂，包含多年不停迭代的代码。添加新功能经常是牵一发而动全身 ——

第一，你需要了解这个代码库的基本架构和重要模块才知道要改哪里加哪里，这一步 ChatGPT 完全帮不了忙。

第二，添加更改代码的 context 和 dependency 很多，这些都是没法合规快速告诉 ChatGPT 的。这种情况 GitHub copilot 因为直接接入 IDE 所以会稍好用一些，但也有限。

第三，因此 bug 也很难通过 AI 工具找到。修 bug 的第一步一般是本地运行程序，根据报错信息来一步步找到出错位置。这个没法让 GPT 去做。

第四，写代码测试代码只是工作的一部分，现代软件的部署环境也很复杂，各个 component 相互影响，部署过程中的错误显然也很难让 ChatGPT 来解决。

第五，除小公司外，大部分科技公司都有很多自己的内部开发工具，那些内部语法和规则是没法通过 AI 工具理解帮忙的。

所以目前我觉得 ChatGPT 在编程上最适合的应用场景是，

帮初学者写简单独立的代码（写 scripts 而不是 codebase）；

帮初学者理解具体语法；

帮忙简单 debug。

### 06

方军 2024/04/02

072 AI 问答为什么有用

准备一些文档（包括前一段思考飞书的话题），我发现，其实文档对绝大部分人来说都是非常困难的。这也是为什么技术圈有黑话，RTFM（Reading the f**king manual，去读他妈的的手册）。

对于手册型文档，普通人很难形成阅读的能力，养成查阅的习惯。这时，AI 就有了很大的发挥作用的机会，以更人性化的对话界面来提供协助。

这之前有个前提，还是需要有人准备文档。昨天有人在推上开玩笑说，看到有人夸文档，该组件的开发者说，哈，这是我刚刚用 AI 为你生成的。当然他立刻补充：这是一个玩笑，我两分钟刚刚提交了一个文档修订。

开源组件还有两个优点是，第一，是它的代码库可以算是文档的重要组成部分；第二，它们通常有还不错的社区，至少 Github issues 里面会形成不错的积累。

以 AI 当前的能力，目前还仅仅是（站内）搜索的补充。但随着 AI 长上下文窗口、RAG 的发展，提问将变成一个主要的方式。

当然，对 AI 回答的针对性的调整是必要的，目前（站内）搜索约 90 分，但即便一些 AI 技术产品的文档 AI 也仅有 60-70 分，仅能提供参考，还没有达到可用的那条线，更不要说想达到惊艳的水平。

但不管怎样，这样的变化将给文档带来很多必要的变化：

- 所编写的文档将要考虑到，不是为了查阅，而是为 AI 提供资料，要尽量详细。

- 专门为人编写的文档要更简洁、更框架性。

- 代码基础可能也将交给 AI，用来优化回答。过程资料也可以，但这需要谨慎处理，因为过程资料可能包含探索的弯路。

方军：但是，真心建议做文档型人，因为真心是中长期效率最高的

2024-04-02 17:57

### 07

方军 2024/04/02

[阿里云内部全面推行 AI 写代码，未来 20% 代码由通义灵码编写](https://mp.weixin.qq.com/s/_zofVNxSlwRAhTYppYn9Gg)

### 08

方军 2024/04/02

[备受关注的「出版+人工智能」，在国外究竟发展到了什么水平？](https://mp.weixin.qq.com/s/cb83RtyKSpAAo68DoGdvVg)

### 09

方军 2024/04/02

ChatGPT 无需注册即可使用，似乎是件很大的事呢

历史的确不重要，就跟搜索引擎一样

### 10

方军 2024/04/02

摘：Nick Dobos 这个看法，目前这个阶段的 AI 产品方向已经不是聊天机器人了，而是变成了一种「文本转换器」。

它能够把人生产的文本转换成___。空格里可以是任何形式的内容，比如视频或者代码甚至是一个产品。

来源：x.com/NickADobos/status/1774487841021767828

### 11

方军 2024/04/02

现在的 AI 工具真是非常多

[The Top 100 Gen AI Consumer Apps | Andreessen Horowitz](https://a16z.com/100-gen-ai-apps/)

这是红杉的总结。

[a16z：2024 年 GenAI 市场将爆发](https://mp.weixin.qq.com/s/NpnGcZfDpFHYBzHTQYY-Jw?v_p=90&WBAPIAnalysisOriUICodes=10000001&launchid=default&wm=3333_2001&aid=01A0VjFEC-8TX6msntzx_IZJsVSdIBL5NqzASu9SjrmTcS5LA.&from=10E3393010)

翻译版：

[翻译：A16Z-TOP 100生成式AI应用 - 飞书云文档](https://waytoagi.feishu.cn/wiki/ZvJ6w6aAdiBEMokMqCcczr28nnf)

---

推上也有人做了另一个总结列表：

Top 100 game-changing AI tools in 20 different categories! 

twitter.com/ATechAjay/status/1775049190437204347

1. Research

→ Copilot
→ Gemini
→ Perplexity
→ ChatGPT
→ Claude

2. Website 

→ 10web
→ Dora AI
→ Divi AI
→ Durable
→ Framer AI 
→ Style AI

3. Design

→ Microsoft designer 
→ Canva
→ Flair AI
→ designify
→ Clipdrop
→ Autodraw

4. Writing

→ Jasper
→ Copymate
→ Scalenut 
→ Writesonic
→ Textblaze

5. CopyWriting

→ Rytr
→ Copy AI
→ Writesonic
→ Adcreative AI

6. Chatbots

→ Botonic
→ Chatbase
→ ChatSimple
→ Tidio
→ SiteGPT

6. Image

→ Leap AI
→ DALL-E 2
→ Bing create 
→ Nex .art
→ Bing AI

7. Logo Generator

→ Canva
→ stockimg 
→ Logo AI
→ Brandmark
→ Logo Pony
→ Namecheap

8. Video

→ Synthesia  
→ Descript
→ VEED IO
→ Pictory AI
→ Eightify 

9. Search Engine

→ Perplexity AI
→ Surfer SEO
→ Neeva AI
→ Brave AI
→ Alli AI

10. Meeting

→ Krisp
→ Otter AI
→ Airgram   
→ Sembly AI
→ Noty AI

11. Automation

→ Zapier
→ Make
→ Levity
→ Discript
→ Xembly

12. Productivity

→ Canva
→ Notion
→ Flair AI
→ Adobe Sensei
→ Wondershare

13. UI/UX

→ Figma
→ Uizard
→ UiMagic
→ Photoshop
→ Photoshop
→ GeniusUI

14. Presentation

→ Designs AI
→ Beautiful AI
→ Slides AI
→ Decktopus

15. Audio

→ Murf AI
→ Songburst AI
→ Adobe Podcast

16. Resume

→ Resume Genius
→ Zety
→ Resume io
→ Rezi
→ Kickresume

17. Marketing

→ AdCreative
→ Simplified
→ Pencil
→ AI-Ads

18. Prompts

→ FlowGPT
→ Alicent AI
→ PromptBox
→ Promptbase
→ Snack Prompt

A19. Startup

→ Tome
→ Ideas AI
→ Namelix
→ Validator AI

20. Social media management

→ Typeshare
→ Tribescaler
→ Blackmagic
→ TweetHunter
→ Postwise

### 12

方军 2024/04/02

摘：我使用 chatgpt 的经验，你自己的知识掌握必须比 GPT 深入，才能让他真正帮助你做繁琐的工作部分，不然他忽悠你 你还当真，肯定会被贻笑大方！

### 13

方军 2024/04/02

这几位老师的讨论有意思，经济学老师：

@陆明涛 ECON：想发一个暴论，LLM 以来所有的文科【科普】都变得意义不大了，所有 LLM 读过的书籍资料比任何人类都多，除非在该学科受过系统专业的博士训练从而能批判性地理解、梳理和评价该学科最新研究的内容，否则你的搬运在 LLM 面前都没啥价值。唯一有价值的科普可能就只是有很多数学支持的学科，但也仅限于现在的 AI 发展水平，或许到了未来 AI 发展水平更高之后，这些科普的意义可能也不太大了。

LLM 之后应该对微博生态也有很大冲击吧？比如说科普类、个人化特色不强的微博是不是访问量少了，而能够提供比 LLM 更新知识的博主、或者是个性化特色更强的微博是不是访问量会有上升？毕竟 LLM 现在和微博是不是同一个生态位？不知道微博有没有统计数据支持这种猜想。

@王彬 macro：然而，没有体系，还是很难的，等于是多了一部更齐全的字典，但字典并不成知识。

@明涛 ECON：是的，有没有结构就是教育和科普的区别，科普就是不讲结构，毕竟理解结构太痛苦了。

@明涛 ECON：很多批评评论我都赞同，但是我这里主要说的是「科普」，不是文科专业的教育和科研。读科普是消费行为，不能指望科普就把我们变成专家。科普与专业之间的差异就在于枯燥的学科体系，特别是可以用数学表达的各种结构。

@青梅酒大麦茶：科普的大部分受众是不愿意去花时间主动检索的人。你以为他在学知识，其实他只是在 kill time。

---

这个陆明涛老师说得尖锐了点，但的确是这么回事，当然，去 B 站学习我本来就笑死了，还不如去 AI 学习呢：

某大学某老师上传百科全书式社会科学导论课程一事，本来不应该评价，这结果也在预料之中，但大家的评价都有点过了。其实这大约就是一个 60 后图书管理员运用 80 后技术消化了 90 后的社科知识尝试给 00 后进行科普导致翻车的故事。造成悲剧的原因有三个：

一是知识结构问题。图书管理员的信息情报专业强调信息采集渠道广泛，不注重系统结构性，不注重更新迭代，所以容易很外行。毕竟图书情报系统存在的价值就是整理别的学科的观点，但整理到什么层次怎么整理，其实他们是不太具有学科能力的，这就是为什么其实情报信息专业主要致力于整理最新进展，而不会太尝试进行学科体系全面介绍。当然这些我说的也不专业，也只是道听途说。

二是代沟问题。现在年轻人知识体系来源广泛，特别是在社交媒体的加持下，大家的思想意识都经历了多轮辩论和迭代，但远离社交媒体的老师们往往还抱着老版本，就容易被学生批评。

三是场合问题。除了数学类课程放在网上不会导致太多批评，社科类课程越科普就越可能被各种背景的朋友以各种原因批评，有的是不同背景对相同方法论的质疑，有的是层次问题的反转或修正。前者如其他社科对经济学帝国主义的批评，后者如初级和高级经济学课程对成本加成定价的不同结论。

总之，该老师出发点是好的，但其实他更适合搞个自媒体玩玩试试水，不要把这件事情搞得太神圣。一说到开课，评价要求自然就上去了。

### 14

方军 2024/04/03

whigzhou：

我发现 ChatGPT 的两大特点，可能是 LLM 的共同特点，

一是啰嗦，差班教师式的啰嗦，你问个简单问题，他恨不得先给你上堂课，哪怕问题本身已经表明你对相关领域有了相当深度的了解，也照上不误，

二是绝不谦虚，你提个问题，第一轮回答可能并不切题，经过几次提示后，回答确实会变得更切题，问题是，随着你的提示逼迫，他会越发胡来，随口拼凑编造一些貌似很相关但往往错误百出的回答，

我仔细想了想这事情，感觉这应该是训练系统的激励模式造成的结果。

我们肉人的信念常常有机会从现实反馈中得到修正，比如基于某个信念的行动，若是受挫，便得到了一个负面激励，可是当前 AI 的训练系统提供不了这种现实反馈，所有激励源必须是内生的，这种条件下产生的系统必定会有一些（相比肉人）不同寻常的特征，我观察到的两个特征很可能源自于此。

当前的训练系统可能会提供哪些内生反馈呢？我想到这样几种。

1、基于题库的反馈，IBM 的 Watson 或许就是，做对一题就给颗糖，这会把系统往做题家方向培养。

2、言语本身的质量评估，这个基于大型语料库就可以提供，所谓言语质量，就是一句话是否说的有模有样，哪怕你啥也不懂，但说的句句都像人话，不输母语者，就及格了，这种评估完全可以内生。

3、切题性评估，意思是你表现的就像真的听懂了对方的意识，并且做出了切题的，有内容的，有意义的回应，最好还是听上去蛮有道理的，简单说，就是 makes sense，这种反馈很大程度上也可以内生提供。

依我看，一个训练系统只要在 2 和 3 上做的足够好，就能创造出足以通过图灵测试的系统，让人感觉确实像个真人。

这很可能解释了我观察到的两个特征，你想想看，如果只依赖内生反馈，啰嗦和胡掰就成了优势，像「我不懂」和「不知道」这种回应，哪怕是对问题最恰当的反应，也是不会高分的，因为它们是万能回答，在缺乏外部参考的条件下，激励函数完全无法评估它们是否切题，是否表现了说话者的语言能力，

类似的，哪怕一个问题的恰当答案非常简单，只需一两个词，干脆利落，但为了得高分，你必须啰嗦上一通，才能让激励函数相信你对当前正在谈论的主题有足够的理解，对相关背景知识有良好掌握，说起来头头是道，有条有理 —— 这跟做题家在讨论课堂上对付老师的方式完全一样！

问题是，这种能力并不能在任何程度上保证他们能完成有现实意义的工作任务，提供有价值的服务，要达到这种目标，还需要更切实的，往往是领域专门的评估和反馈。

由此可以推测，较近未来哪些领域 AI 应用潜力更高，首先就取决于哪些领域更有潜力提供这种内生反馈，或很容易以低成本获得外生反馈。

专业题库就是一种内生反馈源，信息源声望等级也是一种来源，比如如果你的诊断总是和顶级名医对相同病情的诊断保持一致，就得高分，但这也意味着，如果只依靠内生反馈，顶级肉医水平就构成了你的天花板，你永远不可能靠自己进步，那需要外生反馈。

棋牌类系统之所以进步神速，是因为它们可以互弈，每一局的结果都是内生反馈。

另一个有着优越内生反馈源的系统是股票投资，完整的历史股价和交易数据可以产生相当逼真的内生激励，但问题是，1）历史成就与未来成就有多大相关？2）把训练结果放进真实市场后，这一扰动造成的后果是否会让历史经验失效？

还有些领域，比如与用户互动的软件系统，可能会从互动中得到有用反馈。

### 15

方军 2024/04/03

大型代码库，真是迫切需要 AI

Linkedin 的故事

[十几年积累的 300 万行代码，领导要全部“快速”重写，我直接辞职了](https://mp.weixin.qq.com/s/udt-LB67BZ8EGrwWE9ouXg)

[LinkedIn 应用体积臃肿达 500 MB，网友怒喷：大厂开发者都没有动力创造优秀应用？！](https://mp.weixin.qq.com/s/lz-C8MJ4vq2xpNVgJc0zTA?v_p=90&WBAPIAnalysisOriUICodes=10000001_10000002&launchid=default&wm=3333_2001&aid=01A0VjFEC-8TX6msntzx_IZJsVSdIBL5NqzASu9SjrmTcS5LA.&from=10E3393010)

### 16

方军 2024/04/03

AI 对我来说，有一个好处是，有了 AI 就更多时间花在「非新闻」上了。

去年群里推荐一本少看新闻的书，被一位老师一顿狠批评。我倒是虚心接受批评了，再推荐这样的书的时候还是要强调新闻的社会价值。

但是各种新闻真心没必要，比如，刚刚看某教授讨论所谓我的梦想长大了做农发行的行长那个，群情激昂，哈哈，这种破事如果要关注，每天都很多。

媒体会把某些破事推到你面前，比如一个经典的案例是，多年前，电视里播着激烈的冲突，走出酒店一看，几十人而已。

社交网络会进一步把各种鸡毛蒜皮、但能调动情绪的推到你面前。媒体还有判断，社交群氓没有判断。

### 17

方军 2024/04/03

政府出台了：生成式 AI 备案。

### 18

方军 2024/04/04

这个深度广度的看法有意思

有个梨：llm 的影响力充分释放大约要 15 年的时间。

它释放的主要方式，是英语语境下的西方文明的影响力。体现在，诸如 YouTube 等视频网站的教育课程全面跨语言影响，包括印度英语；以及象 grammerly 或类似的工具，帮助年轻人更快的学好英语，尤其是在没有合格老师的情况下，实际上包括 google docs 的语法检查最近都有了长足的进步。

我知道 llm 还有很多比这个听上去高大上得多的应用，但是技术在市场角度不是看深度的，而是看广度的，能 reach 多少 people。就像社交网络那样，出来的时候没人觉得那很重要，直到 Facebook 崛起，以及更加出乎技术人员预料的，Instagram 和 tiktok 崛起。

Internet 的第一个十五年，给了内容网站和 Google，第二个十五年，给了社交网络和云计算。

llm 的第一个 15 年，会推倒巴比塔。15 年也正好是一个孩子从走入学校开始到走上社会工作。在这个 15 年里，在从现在开始进入小学的这批孩子们身上，在全球范围内，互联网和移动互联网把每个人接入全球化的知识体系（这里强调知识而不是任何信息），llm 打破语言障碍，让任何人可以看懂任何语言的内容，让任何人可以学好英语，如果他想。

所以未来十五年真正大发展的是教育，而十五年之后，stem 支撑的所有工程领域会达到在人类历史尺度上的全新的高度。

### 19

方军 2024/04/04

[#模型时代# 25 个... - @高飞的微博 - 微博](https://weibo.com/1233486457/O82Bmn4Jg)

25 个 YC 孵化的 AI 模型公司都是什么赛道的？

YCombinator 认为，模型训练，可能不需要动辄上亿的资金。且耳听为虚，眼见为实。YC 为了支持自己的论点，也公布了它扶持的，自己训练基础模型或做模型微调的 25 家初创公司。

这些公司的筛选标准是：启动资金和资源包括（50 万美元的资金，100 万美元的云服务额度和专用 GPU 资源）；在 YC 三个月孵化期内训练出模型；模型投入生产并成功吸引付费用户。

这 25 家公司还有一些共同特点，比如都面向垂直场景，比如生成音乐、设计新型蛋白质、精确预测天气，操控机器人等。同时，也发明了一些技术方法，比如通过创新的模型架构来减少计算需求，或利用特定行业知识减少数据需求。

Atmo：提供基于 AI 的气象预测服务，承诺以更低的成本提供远比现有技术更为准确的天气预测。

Can of Soup：通过 AI 让你与朋友们在虚构场景中的照片同场。

Deepgram：提供超快速语音转文本转录及自然语音合成的 API 服务。

Diffuse Bio：专注于利用基础模型在生物学领域设计新的蛋白质，用于疫苗和治疗药物的开发。

Draftaid：利用 AI 帮助工程师和设计师创建 CAD 图纸，轻松将 3D 模型转换为制造商所需的详细制造图纸。

Edgetrace：能处理大量视频数据集，并允许用户通过简单的英文描述进行搜索。例如，通过描述找到特定汽车在数小时的交通录像中的出现，如「带金色轮毂盖的红色普锐斯右转」。

EzDubs：可以实时将视频配音成不同语言，同时保留原始讲话者的声音特色。

Exa：为 AI 开发者提供的搜索引擎 / API，它通过语义而非关键字来搜索信息，让开发者可以运行如「关于 Google 初期的简短文章」或「最新 AI 进展的新闻」等查询，并将搜索结果整合到他们产品的回答中。

Guide Labs：基础模型通常是「黑箱」，无法解释其推理过程。他们通过可解释的基础模型解决了这一问题，能够说明模型输出背后的逻辑，以及训练数据和提示的哪些部分对输出有影响。该团队之前在 Google Brain 和 Meta Research 工作，是 Captum 的主要开发者。

Infinity AI：正在开发一种「剧本到电影」的模型，你只需描述屏幕上角色的台词和动作，它就能生成相应的视频。他们的首个产品能够基于提供的剧本制作出「对话头」风格的视频片段。

K-Scale：致力于为机器人基础模型提供支持基础设施，最终解决现实世界中的实体智能问题。

Linum：开发了可以根据提示制作动画视频的模型和工具。

Metalware：为固件工程师提供 AI 工具，加速开发进程，例如为低级编程设计的专门协助工具，或能迅速浏览大量数据表并提供快速答案的 PDF 阅读器。该公司的联合创始人参与了 Starlink 天线固件的开发。

Navier AI：开发了一个物理 - ML 求解器，可以实时模拟计算流体动力学，这对航空和汽车工程至关重要。

Osium AI：使用 AI 加速新材料设计，通过预测材料的物理属性和加速显微图像分析来帮助研发工程师快速设计新材料。

Phind：为开发者打造的对话式搜索引擎，通过 VS Code 扩展与现有代码库集成，能够利用代码作为上下文来回答问题，遇到错误或警告时提供解决方案。

Piramidal：基于大量多样的脑电波数据训练的基础模型，用于理解大脑活动。他们的首个产品是一个帮助神经科医生评估潜在癫痫诊断的辅助工具。他们通过分块处理连续的脑电波数据，以较低的计算成本训练出大型模型，减少了内存占用。

Playground：一个基于 AI 的强大图像编辑器，能从提示中创建新图像，合并真实 / 合成图像成新作品，或仅用几个词就能修改现有图像。

PlayHT：为媒体和内容创作者提供表情丰富的 AI 生成声音。可以用大约 10 分钟的样本录音来训练出新的声音。

SevnAI：正在构建图形设计的基础模型。他们能够利用一个具有空间推理能力的定制架构模型，生成易于编辑的 SVG 图像，解决了当前扩散模型输出图像难以编辑的问题。

Sonauto：AI 音乐创作工具，你只需提供歌词和歌曲描述（如「节奏快速、以鲜明的合成器为特色的流行音轨」），点击「生成」，就能得到一首全新的音乐。

Sync Labs：开发了一个模型，可以重新同步视频中某人嘴唇的动作，以匹配新的音频，使得更改视频的对白语言看起来更自然。他们正努力实现实时同步，以便在视频通话中实现实时唇语翻译。

Tavus：录制一个视频，自动为每个观众个性化定制 —— 在适当的位置替换为观众的名字、公司等信息。该公司最近推出了一个公开测试版工具，使你可以用 2 分钟的视频制作出一个「类似真人」的自己的复制品。

Yoneda Labs：帮助化学家确定最优的温度、浓度和催化剂，以提高化学反应的效率。

Yondu：为机器人在世界上的自主导航开发基础模型，使它们能够更智能地移动和工作。

---

方军：Ycombinator W24（24 冬季演示日）招募了 157 家大型人工智能初创企业。

Joinrosebud 创始人 Chrys Bader 总结了一下这些入选初创企业的类型，包括六大类，可以某种程度看做是大模型创业的新趋势。总体看下来，大模型变革最多的领域是 IT 本身，技术让技术人（或者说普通技术人）的需要程度降低。

1、软件开发：44 家初创企业正致力于利用人工智能接管日常编码任务和基础架构管理，释放开发人员的潜力，使他们能够从事更高层次的创造性工作。代表性初创企业包括 CodeantAi（自动修复错误）、MomenticAi（人工智能自动化测试）、EllipsisDev（自动化代码审查）等。

2、客户服务：有 12 家初创企业在使用人工智能改善客户服务体验，旨在帮助公司节省资金和时间。这些初创企业如 TomaVoice、Usearch、SomnYcw24（人工智能接待员）、Retellai（语音对话人工智能的基础设施）、KioskAi（人工智能助力 WhatsApp 营销）。

3、生物技术和医疗保健：10 家初创企业利用人工智能缩短新疗法的开发时间和成本。例如，TamarindBio 提供药物发现的计算工具，RadmateAi 为放射科医生提供人工智能副驾驶，Metofico 提供用于生命科学的无代码数据分析。

4、内容创意：14 家初创企业正通过人工智能促进创意的实现，模糊创作者与消费者界限。例如，MagicHourAi 是一个人工智能视频生成平台，ToinfinityAi 专注于从剧本到电影的创造，PocketpodApp 提供定制播客创建服务。

5、金融投资：11 家初创企业正在使用人工智能支持投资决策，重塑金融市场。Tryoffdeal 为中小企业收购提供人工智能中介服务，PowderFi 作为财富管理者的副驾驶，ClarumAi 加速尽职调查过程。

6、物理世界：7 家初创企业展示了人工智能如何构建和管理物理基础设施。比如 Inspectmind 提高检查设施报告的速度，PurplePillAi 作为人工智能物业管理员，DraftAid 则使用人工智能将 3D 模型转换为 CAD 图纸，和机器人（PivotRobots、YonduAi）等。

此外，值得一提的其他类别初创公司，还包括人。

2024-04-04 00:47

[Draftaid: Go from 3D models to CAD drawings using AI | Y Combinator](https://www.ycombinator.com/companies/draftaid)

[From 3D models to production drawings using AI](https://draftaid.io/)

### 20

方军 2024/04/04

使用弱智吧数据训练的大模型，跑分超过百科、知乎、豆瓣、小红书等平台，甚至研究团队精心挑选的数据集。

这件事让人深思，什么才是中文优质数据集？

Reddit 也是优质测试集。

有意思，哈哈哈

[弱智吧竟成最佳中文 AI 训练数据？！中科院等：8 项测试第一，远超知乎豆瓣小红书](https://mp.weixin.qq.com/s/iq5lGyh9Y5P7NXLUS3-giA)

接下来比拼数据了

### 21

方军 2024/04/04

这个观点是合理的

摘：飞书需要换个 slogan。相比之下，可能 37signals 更适合说自己是先进团队做的先进产品。先进的，有价值的产品，当然应该是可以带来较高利润的。​​​

比人效，37signals 人均 5000 万，飞书人均 20 多万。 37signals 那才叫先进团队，飞书的人效比他很多客户都不如。

### 22

方军 2024/04/04

OpenAI 针对开发者将增加新功能，开发者可通过 API 对微调进行更多控制，并宣布了使用 OpenAI 构建自定义模型的新方法。

OpenAI 于 2023 年 8 月推出了 GPT-3.5 的自助微调 API，新的微调 API 功能将包括：

- 在每次训练过程中保存完整的微调模型检查点，以减少后续重新训练的需要，尤其是在过拟合的情况下；

- 用于比较模型质量和性能的全新并排 Playground 用户界面，允许对多个模型的输出进行人工评估，或根据单个提示对快照进行微调；

- 支持与第三方平台的集成（本周开始与 Weights and Biases 集成），让开发人员能够与堆栈的其他部分共享详细的微调数据；

- 在每个历时结束时对验证数据集（以前是一批采样数据）计算指标，以便更好地了解模型性能（标记损失和准确性），并反馈模型的泛化能力；

- 能够从仪表板配置可用的超参数（而不是仅通过 API 或 SDK）；

- 对微调仪表板进行了各种改进，包括配置超参数、查看更详细的训练指标以及从以前的配置重新运行作业。

自定义模型方面，则包括：

- 辅助微调，开发者可与 OpenAI 的技术团队合作，在更大范围内利用微调 API 以外的技术，如附加超参数和各种参数高效微调 (PEFT) 方法。

- 定制训练模型，在某些情况下，企业需要从头开始训练一个了解其业务、行业或领域的专用模型。完全定制训练的模型通过使用新颖的中期训练和后期训练技术修改模型训练过程的关键步骤，从特定领域注入新的知识。使用完全自定义训练模型取得成功的企业通常拥有大量的专有数据 -- 数百万个示例或数十亿个 tokens-- 他们希望利用这些数据向模型传授新知识或复杂、独特的行为，以满足高度特定的使用情况。

### 23

方军 2024/04/05

Anthropic 昨晚发布了一种名为「多次尝试越狱」的技术，可以利用超长上下文的模型特性将对应的长提示对模型越狱。

看到的点评：看起来等效于用超长文本 prompt 做了临时微调。

感觉也可以用在其他方面，不知道 GPTs 是否可以这样，用 knowledge 做现场微调。

---

「多次尝试越狱」通过在单一提示中包含大量特定配置的文本，迫使 LLMs 产生可能有害的回应，尽管它们被训练为不这样做。研究表明，随着包含对话（「尝试」）数量的增加，模型产生有害回应的可能性增加。结合其他已发布的越狱技术，可以使这种技术更为有效，减少模型返回有害回应所需的提示长度。

这种越狱技术的有效性与「上下文中学习」（in-context learning）的过程有关，即 LLM 仅使用提示中提供的信息进行学习，而不需要任何后续的微调。研究发现，正常情况下的上下文中学习遵循与多次尝试越狱在增加的示例演示数量上相同的统计模式（幂律分布）。

为了缓解多次尝试越狱的风险，Anthropic 采取了一些措施，包括限制上下文窗口的长度和对模型进行微调，使其拒绝回答看起来像是多次尝试越狱攻击的查询。此外，他们还探索了基于提示的缓解方法，这些方法涉及在模型处理提示之前对其进行分类和修改，显著降低了多次尝试越狱的有效性。

New Anthropic research paper: Many-shot jailbreaking.

We study a long-context jailbreaking technique that is effective on most large language models, including those developed by Anthropic and many of our peers.

Read our blog post and the paper here:

[Many-shot jailbreaking \ Anthropic](https://www.anthropic.com/research/many-shot-jailbreaking)

### 24

方军 2024/04/05

我发现如何使用 AI 做调研，我的观点基本上可以说长期没有变化，都忘记很早之前做个这样一个图：

---

向 AI 提问，做项目调研：自带原始资料 / 自带知识框架 / 自带判断力

知识框架，即提问的列表：

1. 项目概况

2. 经济模型

3. 应用场景

4. 技术特性

5. 项目前景

### 25

方军 2024/04/05

刘群老师的感慨：感慨一下技术进步给研究和教学带来改变和失落：当年我们做 NLP 研究，要学习很多语言处理的技术，包括 word segmentation, POS-tagging, parsing, semantic role labeling, co-reference, RST 等等，

深度学习流行以后，发现这些内容已经没有人感兴趣了，Stanford NLP 的课程都抛弃了这些内容。

现在大语言模型又带了一轮巨大的变化，看现在的论文，发现很多论文本质上就是做 prompting engineering 加数据和评测，甚至连机器学习的基础技术都不需要具备，也可以做出很好的工作并在顶会上发表论文。

真不知道这是好事还是坏事。

### 26

方军 2024/04/05




### 27

方军 2024/04/05




### 28

方军 2024/04/05




### 29

方军 2024/04/05




### 30

方军 2024/04/05




### 31

方军 2024/04/05




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




### 01

方军 2024/04/01




