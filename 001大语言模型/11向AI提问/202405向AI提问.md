### 01

方军 2024-05-01

Globe 这个AI聚合搜索引擎似乎把搜索又上了一个大台阶

当前看到它的特点主要是：

左侧的多级分类

右侧的以图片为主的展示

（右侧这个，会用搜索进行知识学习的人都知道吧，这是最有用的搜索形态）

https://explorer.globe.engineer/

有点贵，我在考虑要不要充值一个月试试，一年肯定不充了，谁知道一年后什么更酷的产品出来。

### 02

方军 2024-05-01

摘：模型即数据
要舍得在数据上投入
这是最本质的事情

人脑的模型也是如此
在学习优质数据上投入时间、金钱和注意力

原文：

The “it” in AI models is the dataset.
AI 模型中的“it”是数据集。

Posted on June 10, 2023 by jbetker

I’ve been at OpenAI for almost a year now. In that time, I’ve trained a lot of generative models. More than anyone really has any right to train. As I’ve spent these hours observing the effects of tweaking various model configurations and hyperparameters, one thing that has struck me is the similarities in between all the training runs.
我现在已经在 OpenAI 工作将近一年了。在这段时间里，我训练了许多生成模型。比任何人都有权利训练的还要多。当我花了这些时间观察调整各种模型配置和超参数的影响时，有一件事让我印象深刻，那就是所有训练运行之间的相似之处。
It’s becoming awfully clear to me that these models are truly approximating their datasets to an incredible degree. What that means is not only that they learn what it means to be a dog or a cat, but the interstitial frequencies between distributions that don’t matter, like what photos humans are likely to take or words humans commonly write down.
对我来说，这些模型确实以令人难以置信的程度逼近它们的数据集。这意味着它们不仅学会了什么是狗或猫，还学会了不重要的分布之间的插值频率，比如人类可能拍摄的照片或人类常常写下的单词。
What this manifests as is – trained on the same dataset for long enough, pretty much every model with enough weights and training time converges to the same point. Sufficiently large diffusion conv-unets produce the same images as ViT generators. AR sampling produces the same images as diffusion.
这种表现形式是 - 在相同的数据集上进行足够长时间的训练，几乎每个具有足够权重和训练时间的模型都会收敛到相同的点。足够大的扩散 conv-unets 生成与 ViT 生成器相同的图像。AR 采样生成与扩散相同的图像。
This is a surprising observation! It implies that model behavior is not determined by architecture, hyperparameters, or optimizer choices. It’s determined by your dataset, nothing else. Everything else is a means to an end in efficiently delivery compute to approximating that dataset.
这是一个令人惊讶的观察！这意味着模型行为不是由架构、超参数或优化器选择决定的。它是由你的数据集决定的，没有别的。其他一切都是为了有效地将计算交付给逼近该数据集的手段。
Then, when you refer to “Lambda”, “ChatGPT”, “Bard”, or “Claude” then, it’s not the model weights that you are referring to. It’s the dataset.
然后，当你提到“Lambda”、“ChatGPT”、“Bard”或“Claude”时，你指的不是模型权重，而是数据集。

nonint.com/2023/06/10/the-it-in-ai-models-is-the-dataset/

### 03

方军 2024-05-01

蛮有意思的，好像 kimi 没用智能体这个词，用的是普普通通的「私人助理」，后者要更友好些

我一直很好奇，为什么有个圈子特别喜欢智能体这个词？ 智谱也喜欢这个词。

### 04

方军 2024-05-02

OpenAI 发布一个 Next.js 的模板，用于 assistant api

OpenAI Assistants API Quickstart

github.com/openai/openai-assistants-quickstart

粗看起来，这个还是远不如 vercel 开源的 Vercel AI Chatbot

github.com/vercel/ai-chatbot

Vercel 这个背后是它的 AI SDK (现在3.1.0)

sdk.vercel.ai/docs

不过，这个 AI SDK 的社区可以说不是特别活跃，使用也是要谨慎的。

### 05

方军 2024-05-04

跟了一年多，讲实话有时候还是觉得openai这个公司的产品定力不行

我始终觉得它的优势在模型，超强优势，但被各种外部影响做了好多分叉之外的事

事后看，function call很赞

assistant api一般

而去搞什么搜素，没戏啊

小弟弟 ppx 可以搞，你搞就有点…

[OpenAI下周将发布ChatGPT搜索引擎，挑战谷歌搜索！](https://mp.weixin.qq.com/s/kXHHXtVBJIOGIg1KZ9PO7A)

### 06

方军 2024-05-04

扬清对 OpenAI 搜索进行了评测，他认为这超过搜索 + RAG 的做法。

有兴趣可查看具体讨论：

twitter.com/jiayq/status/1786208795720593789

网友的争论：twitter.com/idoubicc/status/1786605308330000429

摘（为 AI 翻译）：

尝试用「今天黑客新闻中最受欢迎的帖子说了什么？」进行搜索，你会看到区别。

如果你简单地将其翻译为谷歌查询，比如「黑客新闻中最受欢迎的帖子」，它不会给你有用的总结结果。你必须真正理解它，将其翻译为有意义的行动（比如实际获取 https://news.ycombinator.com/best ），获得结果，然后理解它。

Bing AI - 搜索能够访问页面并给出一些结果，但答案略有偏差（它还伴随着太多的截图）。

基于搜索，http://gemini.google.com 无法解决它，只是说「因为它在一天之内会发生变化」。

http://perplexity.ai 和 Lepton Search 无法解决它。至少目前还不能。顺便说一句，Lepton 搜索旨在提供一个开源示例，展示如何构建一个搜索增强型对话模型，因此结果在没有一些基于代理的设计的情况下是合理的。

方军：idoubi

@idoubicc

twitter.com/idoubicc/status/1786605308330000429

关于贾扬清老师评论 ChatGPT 做 Search 会杀死大部分 Wrapper 型 AI 搜索引擎的这个帖子，我有一些不一样的看法👇

1. AI 搜索引擎的第一要义是准确度。

准确度的决定性因素主要是两个：问答底座模型的智能程度 + 挂载上下文的信息密度。

做好 AI 搜索引擎的关键，选用最智能的问答底座模型，再对 RAG 的检索结果进行排序去重，保证信息密度。

第一个步骤容易，第二个步骤很难。所以现在市面上大部分的 AI 搜索引擎，包括 Perplexity，准确度也就 60% 左右。

2. ChatGPT 自己做搜索，首先保证了问答底座模型的智能程度。……

3. 我并不觉得大模型厂商自己做 AI 搜索就一定会比第三方做的好。……

4. 做好 AI 搜索引擎，最重要的三点是准 / 快 / ……

5. AI 搜索引擎是一个持续雕花的过程。……

6. AI Search + Agents + Workflows 是趋势。

AI Search 做通用场景，通过 Agents 做垂直场景，支持个性化搜索需求。

通过 Workflows 实现更加复杂的流程编排，有机会把某类需求解决的更好。

使用 GPTs 做出的提示词应用或知识库挂载型应用，价值点还是太薄。

7. 我个人不是太看好垂直搜索引擎。

一定程度上，垂直搜索引擎可以在某个场景做深做透，但是用户的搜索需求是非常多样的，我不太可能为了搜代码问题给 A 产品付费，再为了搜旅游攻略给 B 产品付费。

垂直搜索引擎自建 index 索引，工程投入比较大，效果不一定比接 Google API 要好，而且接入的信息源太有限。

8. AI 搜索是一个巨大的市场，短时间内很难形成垄断。……

9. AI 搜索引擎需要尽早考虑成本优化。……

以上是我个人做 http://ThinkAny.AI 一个多月以来的一些经验和思考。欢迎交流探讨。

2024-05-04 19:27

### 07

方军 2024-05-04

有人推荐了这个项目：github.com/reorproject/reor

Reor is an AI-powered desktop note-taking app: it automatically links related notes, answers questions on your notes and provides semantic search.

当你在撰写新的笔记时可以显示从语料库中 "检索" 到的相关的笔记。这是一种通过将当前笔记中的想法与语料库中的相关想法进行交叉参考来 "增强" 用户的思维的强大方式。

不过，我对这样的笔记写作是有极大疑虑的，个人的想法是：

有效的写作应该不是借助笔记，（最多或借助事先准备好的几张卡片 / 少量条目）。

只有这样，才能有效地利用自己的大脑，对知识进行梳理。

这也是我对各类所谓的双链笔记没什么特别印象的原因。那些链接最终是一团乱麻，对我，仅仅是视觉上吸引人（但我又恰巧不喜欢那样的视觉冲击）。

### 08

方军 2024-05-04

摘：最近崔娃和微软一起合办了一个 AI 相关的视频节目，叫：《The Prompt with Trevor Noah》。它的口号是：「You can't find answers without asking the right questions」。这正是我们日常使用 Prompt（提示词）使用 AI 的关键所在 —— 如果你不能提出正确的问题，就无法找到答案。

有意思啊，但有点过于严肃了，不像他

www.microsoft.com/en-us/research/group/ai-for-good-research-lab/the-prompt/

### 09

方军 2024-05-05

虽然我知道前面的这部分不是全部的事实，而是更多的情绪，但是的确引发感慨，后面的那段很棒（补充，如果不是要看科普，而是要看文档手册和开源，互联网和 AI 会更有用，还有阅读长文 / 最好是文档手册的能力），摘：

大约在十几年前网速不咋快、也没有短视频大流行的时候，我会去一些科学杂志网站蹭免费文章看，那里有很多专业作者写的高质量报道，还有各种精美插图。但是随着社交自媒体兴起，这些网站迅速被边缘化了，被淹没在大量无来源的污染信息和所谓的头条热搜里。这是数字时代的真正悲剧。

以下是一部分杂志的名字和他们今天首页的模样，怀念我还能在路边摊偶然买到其中一些杂志纸质版的时候：…

现在是互联网最好的时代，因为机器翻译质量已经快把巴比伦塔削平了，和 99.9% 的历史时间相比，今天你获得任何一种陌生语言载体的优质信息的难度几乎是零。现在也是互联网最糟的时代，所有媒体平台都在流量利益驱动下一起摔进下水道了，信息壁垒比以往任何时候都低，又比以往任何时候都高。这是个碾压在亚历山大图书馆头上的震耳欲聋的垃圾场，在神圣的万维网书架前人类只有一种堕落就是自甘堕落。

方军：接着摘另一个相关的：现在 mind hacker 占据了互联网绝大多数的内容，随着 AI 技术的进步情况将会更失控。香农信道定律将会是对你最大的保护，例如回到线下生活、学习主要靠读书读论文、通讯主要靠打电话，这样可以确保外部环境的信息量与你自身频带宽度相符，因此信噪比可以保持在合适比例。如果放任 mind hacker 无限制地占用你有限的认知带宽，那么你的大脑必须要用极好的滤波器来保证极高的信噪比，长期看大脑可能会被冲垮（失去滤波功能、进而失去认知功能）。

2024-05-05 10:43

方军：想起以前一个朋友的故事，她作为时尚和艺术行业中人，从来不买大牌，人问为什么，她答，我天天造这些… 当然她自己用的那些其实比大牌价格上几乎是一样的，只是没牌而已

2024-05-05 10:44

---

这位名叫 haiwenliu 的网友颇有意思：

智能的一大标志是：寻找结构。在寻找前所未知的结构方面，古希腊以来数学家和科学家携手取得了巨大的成功，Ta 们发展的数学语言成了目前所知的这个世界最精准的描述方式。这就是皮尔士 / 庞加莱的结构实在论的内核。

然而，随着人工智能的不断发展，（除了数学之外）似乎存在另外一种精准描述世界的方式。这个方式就是丹尼尔丹尼特喜欢说的 capability without comprehensibility（相关过程发展进程中，人从中心地位逐步被边缘化了）。在这个意义上，达尔文的深刻思想是结构实在论最可匹敌的对手。

可惜在丹尼特的大作《达尔文的危险观念》中针对这个议题仅有浅显地涉及。相信随着人工智能的发展，这个议题会变得越来越重要。

方军：这段话是他的：现在 mind hacker 占据了互联网绝大多数的内容，随着 AI 技术的进步情况将会更失控。香农信道定律将会是对你最大的保护，例如回到线下生活、学习主要靠读书读论文、通讯主要靠打电话，这样可以确保外部环境的信息量与你自身频带宽度相符，因此信噪比可以保持在合适比例。如果放任 mind hacker 无限制地占用你有限的认知带宽，那么你的大脑必须要用极好的滤波器来保证极高的信噪比，长期看大脑可能会被冲垮（失去滤波功能、进而失去认知功能）。

2024-05-05 10:48

### 10

方军 2024-05-05

精彩的学习工具创意啊：马大哈翻译

在浏览中文网站时，马大哈会挑选一些词汇转成英文单词，营造中夹英的效果。在浏览英文网站时，马大哈在把网站翻译成中文时会刻意略过一些字句，又称沉浸式漏翻。

通过上下文线索，引导大脑猜测中文里夹杂的英语单词，在语境中锻炼加深记忆，效果显著。

[马大哈翻译安装向导](https://yiu45q2746h.feishu.cn/docx/E2K1dnJTXosqWIxxKh3ccrS4nzb)

### 11

方军 2024-05-05

基于 AI 的照片地理定位工具

1、使用计算机视觉和 AI 进行地理位置推断。拍照或选择现有照片。GeoSpy 将尝试找出照片的拍摄地点。

2、无需登录，免费使用

[geospy.ai](https://geospy.ai/)

相当可怕

### 12

方军 2024-05-05

有意思：

什么是技术思维？什么是产品思维？一个例子让你明白。

某：搞两份这个是真的简单粗暴，我之前也陷入这个循环里出不来

[论技术思维和产品思维](https://mp.weixin.qq.com/s/Rc3vZ_qaS6Vj9ILYw05Gug)

欧阳：这个例子太经典了，我最近也这么建议同事：嫌弃 AI 翻译效果不好；一份英文版，一份中文版不就可以了嘛哈哈

2024-05-05 18:30

方军回复欧阳：可不，我喜欢沉浸式翻译就是因为它可以中英对照

2024-05-05 18:40

### 13

方军 2024-05-05

076 我们不得不学很多东西

有什么好方法呢？

说点跟学习相关的话题，跟 AI 有关的（结论在后面）。我拖了两天，才终于打开一个技术工具文档开始看。我之前的逃避是对的：

虽然看似是比如从 5.0 到 5.1 的小升级，实际上是整个架构、接口全变了的大升级。

做技术的人都不得不面临这样的困境：

1、自己从零开始做，当然是一种选择，但明显效果不佳（前些日子有人用 CSS 举例说，用 Tailwind UI 之后，立刻觉得自己 SaaS 产品界面比自己从头搞的高大上了）。

2、选用框架/组件是必须的。打个比方说，没人从头造汽车引擎，造整车的你必须去选用市场上专业的人提供的引擎。但如果选用框架，那么框架的升级将不断地让我们不得不对自己的代码进行变更。

AI 对于这种级别的学习，我觉得目前还都帮不上忙。这是因为，这不是对文档进行检索生成提问之类的，而是必须对组件全面的了解。

面对这样的情况，怎么办呢？

我个人一直认为，一个可行的方法是，如果一个工具要反复地用，那么，根据自己的需要，重新写一个文档手册。

1、官方的文档手册，往往务求全面，因为它要适配组件的多种使用场景。

2、我们自己撰写的手册，可以单一视角（「我就这么用了」，它是高度限定性的），并增补一些自己不熟悉的（官方手册会认为这谁不会？）。当然，有思考也可以纳入，有自己定制的、新增的小组件也正好把说明放在里面。

这看起来很累赘，因为我们一下子要维护两个东西：

- 实际工作的代码/产品

- 一个看似没啥用的手册

但这可能是必要的。我觉得手册带来的思路梳理、内部知识传递、以及承担把一些想法纳入（而不是堆积在产品里），是非常有效的。

好了，不说了，我接着看官方文档，重写之前只有极简大纲的这份手册。

---

今天有朋友微信给我们之前撰写的 Langchain 101 抓虫提建议，那个文档就是一个这种做法的很好展示。也好久没更新了，得继续迭代，跟上官方的步伐。

[Langchain 入门教程 | alang.ai](https://www.alang.ai/langchain/101/)

langchain core 现在是 0.1.50 了，两个半月前当时的版本是 0.1.0。

### 14

方军 2024-05-06





### 15

方军 2024-05-06





### 16

方军 2024-05-06





### 17

方军 2024-05-01





### 18

方军 2024-05-01





### 19

方军 2024-05-01





### 20

方军 2024-05-01





### 21

方军 2024-05-01





### 22

方军 2024-05-01





### 23

方军 2024-05-01





### 24

方军 2024-05-01





### 25

方军 2024-05-01





### 26

方军 2024-05-01





### 27

方军 2024-05-01





### 28

方军 2024-05-01





### 29

方军 2024-05-01





### 30

方军 2024-05-01





### 31

方军 2024-05-01





### 32

方军 2024-05-01





### 33

方军 2024-05-01





### 34

方军 2024-05-01





### 35

方军 2024-05-01





### 36

方军 2024-05-01





### 37

方军 2024-05-01





### 38

方军 2024-05-01





### 39

方军 2024-05-01





### 40

方军 2024-05-01





### 41

方军 2024-05-01





### 42

方军 2024-05-01





### 43

方军 2024-05-01





### 44

方军 2024-05-01





### 45

方军 2024-05-01





### 46

方军 2024-05-01





### 47

方军 2024-05-01





### 48

方军 2024-05-01





### 49

方军 2024-05-01





### 50

方军 2024-05-01





### 51

方军 2024-05-01





### 52

方军 2024-05-01





### 53

方军 2024-05-01





### 54

方军 2024-05-01





### 55

方军 2024-05-01





### 56

方军 2024-05-01





### 57

方军 2024-05-01





### 58

方军 2024-05-01





### 59

方军 2024-05-01





### 60

方军 2024-05-01





### 61

方军 2024-05-01





### 62

方军 2024-05-01





### 63

方军 2024-05-01





### 64

方军 2024-05-01





### 65

方军 2024-05-01





### 66

方军 2024-05-01





### 67

方军 2024-05-01





### 68

方军 2024-05-01





### 69

方军 2024-05-01





### 70

方军 2024-05-01





### 71

方军 2024-05-01





### 72

方军 2024-05-01





### 73

方军 2024-05-01





### 74

方军 2024-05-01





### 75

方军 2024-05-01





### 76

方军 2024-05-01





### 77

方军 2024-05-01





### 78

方军 2024-05-01





### 79

方军 2024-05-01





### 80

方军 2024-05-01





### 81

方军 2024-05-01





### 82

方军 2024-05-01





### 83

方军 2024-05-01





### 84

方军 2024-05-01





### 85

方军 2024-05-01





### 86

方军 2024-05-01





### 87

方军 2024-05-01





### 88

方军 2024-05-01





### 89

方军 2024-05-01





### 90

方军 2024-05-01





### 91

方军 2024-05-01





### 92

方军 2024-05-01





### 93

方军 2024-05-01





### 94

方军 2024-05-01





### 95

方军 2024-05-01





### 96

方军 2024-05-01





### 97

方军 2024-05-01





### 98

方军 2024-05-01





### 99

方军 2024-05-01





### 100

方军 2024-05-01





### 101

方军 2024-05-01





### 102

方军 2024-05-01





### 103

方军 2024-05-01





### 104

方军 2024-05-01





### 105

方军 2024-05-01





### 106

方军 2024-05-01





### 107

方军 2024-05-01





### 108

方军 2024-05-01





### 109

方军 2024-05-01





### 110

方军 2024-05-01





### 111

方军 2024-05-01





### 112

方军 2024-05-01





### 113

方军 2024-05-01





### 114

方军 2024-05-01





### 115

方军 2024-05-01





### 116

方军 2024-05-01





### 117

方军 2024-05-01





### 118

方军 2024-05-01





### 119

方军 2024-05-01





### 120

方军 2024-05-01





### 121

方军 2024-05-01





### 122

方军 2024-05-01





### 123

方军 2024-05-01





### 124

方军 2024-05-01





### 125

方军 2024-05-01





### 126

方军 2024-05-01





### 127

方军 2024-05-01





### 128

方军 2024-05-01





### 129

方军 2024-05-01





### 130

方军 2024-05-01





