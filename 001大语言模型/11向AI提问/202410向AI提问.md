### 01

方军 2024-10-01

李继刚最近的提示语都看了，现在感觉有点炫技。

一般来说分成两个部分：一是对文字的连续处理，二是绘图。

我对绘图部分不感兴趣，因为用 LLM 这样绘图不如另外加个流程，用 MJ 其他图形模型绘图。

那第一部分呢，似乎也没什么实际用途。

可能这反映了两种截然不同的想法：

他的想法是，对文字进行一连串的处理：

A -> B -> C -> D ->E

试图在这样的变形中创造出截然不同的意像出来。

而我认为，LLM的用法应该是，让它就现有的高质量文字进行转换，同时步骤也不用太多，一次转换能做那是最佳。

（输入高质量的文本）--转换--> 用于我们辅助理解的中间结果

注意，我这里特别强调，转换出来是辅助我们理解的中间结果，而非最终结果。

这也是和他思路的一大差别，我认为如果不是那些大家现在还不强求的图形诗句效果，那些文字是很难被接纳的。



### 02

方军 2024-10-01

这个提示语用英文写并没有变得更好，继续尝试中：

```
请你按如下假设来分析一篇文章的主要内容：一篇文章通常围绕2-3个核心元素，分析它们之间的关系：如果2个元素，就是两者的对比。如果是3个元素，就是两两之间的关系。

请仔细阅读如下文章，给出2-3个核心要素。然后，给出它们两者或三者之间的关系，要简明扼要：
```

```
Read thoroughly to identify 2-3 core elements(the key concepts or ideas). 

Output the elements and analyze the logic relationship between each of them. Output in **Chinese** and in the original words and style. 
```

附注：把一个文章的要素简化为几个，这个有点简单粗暴了。

但从就是理解的角度是可行的。我们怎么都得先搞明白哪几个核心要素和它们之间的关系。否则直接去看细微之处，获得的信息是杂乱的。




### 03

方军 2024-10-01

147 为什么要用 AI 提取大纲

在使用 AI 进行辅助阅读的过程中，我日益感受到 AI 和之前所有计算机技术的不同：它能够处理非结构化的信息，尤其是能够处理人类语言文字。

用 AI 提取大纲，是一个比较浅层的人类语言文字处理。但是，这是之前所有的计算机技术都做不到的。（再往前一步，用 AI 去重新组合形成新的文字，也许有可能，但我更愿意在现在这一步多停一段。）

那么，为什么要使用 AI 提取大纲呢？我这几天在重新读认知科学家丹尼尔·T. 威林厄姆写的《为什么学生不喜欢上学？》。这本书开篇就有一句话：

> 与普遍的看法相反，大脑的设计不是为了让你思考，而是为了让你不用思考，因为大脑其实并不擅长思考。

用 AI 提取大纲，实际上是又一个用来辅助阅读时思考的「拐杖」。注意这个词「拐杖」。

即便要读懂不那么难的内容时，我们所感受到的困难也不小，除非它非常短（比如推特140字），或者它是短论证（1500字左右），或者是叙事或强诉诸感情（普通人爱读这些）。

以《为什么学生不喜欢上学？》第一章为例，13000 字的规模，作者善于吸引与保持注意力的技巧，叙述很结构化、很清晰，但要把握其中的信息需要拐杖。过去有：

- 铅笔与荧光笔标注、图书折角；
- 在一张A4纸上随手写的关键词；
- 将内容详细地拆解，我分享过我喜欢用类 PPT 形式；
- 写笔记与卡片、讲给别人听等。

目前看，在读之前或之后，有一个大纲（哪怕仅仅是直接形成的目录，非AI提取），也能减少把握整体所要耗费的脑力。如该书所说，我们都不愿意思考，其实是不愿做无谓的思考——如果有更好的拐杖，为何不用。

拐杖听起来不好，那就叫登山杖吧。现在有了 AI，我们相当于有了更轻、强度更高登山杖了。以大脑爱偷懒这个原理来看，为何不用？

这本书第一章其实包括两个观点：第一，大脑不擅长思考，第二，大脑喜欢思考，用原文话说就是“人们天生好奇”。还是用登山杖的比喻，如果不去登山就不需要登山杖了，但你怎么能不让我去登雪山呢？因此，拐杖或登山杖是必须的，我喜欢说是拐杖是因为，真心在看某些书时觉得老了（以前应该不需要拐杖的）不只是因为它是难攀登的雪山。但还是那句话，有更好的拐杖，为何不用？

说明：《为什么学生不喜欢上学？》作者还有一本新书中文版近年出版了，题为《大脑想要这样学》，其内容比较容易把握，是94个分成一个个单篇的方法，可以说是前一本书的实践版。

图为 AI 提取大纲，其中，二级标题及对课堂的启示，就是原文的小标题。



### 04

方军 2024-10-01


如果大语言模型能够做语言转换，那么它能否做风格的转换呢？

更具体点说，它能否做古典风格与平实风格之间的转换呢？

我们先不管古典风格（特纳一书中所指）的五个立场，真相，呈现，场景，角色，思想与语言。「观看世界」这个基本设定要说给 AI 听让它理解并执行，不知道怎么说。

我们只看表达本身。缩减到这个范围，应该是大语言模型能力范围内的事了。先看看能否形似。

先摘几个范例：

平实风格：“真相纯粹且简单”（The truth is pure and simple）。
古典风格：“真相很少纯粹，也绝不简单”（The truth is rarely pure, and never simple）。

平实风格：“优雅就是简单”
古典风格：“在上帝眼里，优雅就是简单”
古典风格：“优雅的机制总是很简单”

平实风格：“眼见为实”
古典风格：“眼见不一定为实，小心双眼被蒙蔽”

平实风格：“早起的鸟儿有虫吃”
古典风格：“早起的鸟儿有虫吃，但第二只老鼠有奶酪吃”


### 05

方军 2024-10-02

字面意义上把书拆开，我发现我是有本风格感觉是这样了。当然，我还有没拆的版本的。

书中的这些标注在我看来就是之前阅读时的拐杖。

再次吐槽平克老师啊，他第五章讲连贯之弧，但讲实话我真是不知道他讲的那几条原则是什么？

我猜是：

明确主题与观点 being clear about the topic
保持比例均衡  a sense of proportion
主旨连贯性 thematic consistency

无法确信，这是多么糟糕的工具书阅读啊

平克老师有原则地违反自己说的原则，其中中间他根本没有必要说很多什么否定、指代、联系，这导致整体一致性出了大问题。原因出在违反了“保持比例均衡”这个原则。

他几乎完全打断了自己连贯之弧。我能理解他这第5章的连贯之弧是这样的：

第5章　连贯之弧

如何组织写作材料（树形结构）
尽早点明主题和论点
      用相同主语形成主题链
     有序地称呼反复出现的事物（简）
     有逻辑地联系前后陈述（简）
     谨慎地运用否定（简）
保持比例均衡的感觉
连贯地呈现主旨

当然，也有人可能说这一章的结构是：树形结构、（细节的）连贯之弧、一致性。也可以。

他也严重违反了自己说的段落分界原则：

> 真实存在的只是段落的分界：一个视觉化的标记，使得读者可以暂停、喘口气、吸收他所读的内容，然后重新在页面上找到他要读的位置。




### 06

方军 2024-10-02

在《风格感觉》中，平克疯狂吐槽基根的《战争论》开篇语，用 AI 提取大纲看下。我觉得 AI “读得”/“解读得”比平克好。

约翰·基根（John Keegan）1993年出版的巨著《战争史》（A History of Warfare）的开篇语。

> 战争并不是把政策延续下去的另一种手段。如果克劳塞维茨（Clausewitz）这句宣言是真的，那么这个世界将更容易理解。克劳塞维茨是一位经历过拿破仑战争的普鲁士老兵，退休之后，他用数年时间写出了有史以来最著名的战争论著——《战争论》，而且他写道，战争是"政治交往"的延续，"其中掺杂了其他手段"。与常被引用的英文版相比，该书德文原版表达了一个更微妙更复杂的观点。然而，不论是英文版还是德文版，克劳塞维茨的思想都不完整。它暗示，国家、国家利益及其如何实现的理性计算都是存在的。然而，战争比国家、外交以及政策早出现了好几千年。战争的历史几乎和人类的历史一样悠久，并且直抵人类心灵中一些最神秘的地方，在那里，自我终结理性，傲慢支配一切，情绪至高无上，本能就是国王。亚里士多德曾经说："人是政治动物。"继承了亚里士多德衣钵的克劳塞维茨，不敢更进一步说政治动物即制造战争的动物。他也不敢面对这样一种想法：人是思考的动物，人们身上捕猎的冲动和杀戮的能力，都受思维指导。



### 07

方军 2024-10-02

据说平克的《风格感觉》特别畅销，我也受益良多

第N次读了。不过我至今未详读第四章（句子组织，句法）和第六章（语法）。

一本书这么难读，又这么让人有收获，这是什么样的组合？



### 08

方军 2024-10-02

Google NotebookLM 的 Podcast 提示语分析

核心是主持人和专家这两个角色的设定：

主持人负责以饱满的热情突出有趣观点；
专家则提供深入分析、背景信息和更宏观的视角。

https://x.com/JadenGeller/status/18399247808556729...

```
Here are the key aspects of instructions according to the podcast:

以下是根据播客内容总结的关键指示要点：

• Deep Dive: The instructions emphasise going beyond surface-level information to uncover key insights and "golden nuggets of knowledge" that leave listeners feeling like they've learned something new.

• 深入探讨：指示强调要超越表面信息，揭示关键见解和"知识黄金nuggets"，让听众感觉学到了新东西。

• Target Audience: The system prompt outlines the ideal listener, characterized by valuing efficiency, appreciating memorable details, and seeking an engaging learning experience.

• 目标受众：系统提示概述了理想听众的特征，他们重视效率，欣赏难忘的细节，并寻求富有吸引力的学习体验。

• Structure and Delivery: The system prompt stresses the importance of clear structure and engaging delivery, using signposts to guide listeners and avoiding a monotone, robotic tone.

• 结构和传递：系统提示强调清晰结构和引人入胜的传递方式的重要性，使用路标引导听众，避免单调、机械的语调。

• Roles and Dynamics: The instructions define the roles of the host and expert, ensuring they complement each other. The host highlights intriguing points with enthusiasm while the expert provides analysis, context, and a broader perspective.

• 角色和互动：指示定义了主持人和专家的角色，确保他们相互补充。主持人热情地突出有趣的观点，而专家提供分析、背景和更广阔的视角。

• Content Rules: Clarity and impartiality are paramount in the content. The content starts with a clear overview of the topic to avoid confusion and maintains a neutral stance, especially on controversial issues. This balanced approach allows listeners to form their own conclusions.

• 内容规则：内容的清晰度和公正性至关重要。内容以清晰的主题概述开始，以避免混淆，并保持中立立场，特别是在有争议的问题上。这种平衡的方法允许听众形成自己的结论。

• Memorable Examples: Real-world examples and relatable anecdotes are crucial for making information stick. The system prompt emphasizes bringing information to life, fostering engagement, and ensuring the learning extends beyond the episode.

• 难忘的例子：现实世界的例子和相关的轶事对于使信息留存至关重要。系统提示强调将信息生动化，促进参与，并确保学习延伸到节目之外。
```

[(9) X 上的 jaden 🧚‍♂️：“oh nice, NotebookLM podcasters will happily talk about their system prompt (audio posted on threads, cuz twitter limits video length) https://t.co/4J4jaRsMGe” / X](https://x.com/JadenGeller/status/1839924780855672925)

### 09

方军 2024-10-02

148 如何用 AI 加速知识学习

在这个星球的早期，我就写过一个如何用 AI 辅助学习，从两个维度认知视角、行动视角进行讨论，又分别三个层次：消除障碍、加深理解、提速输出。文章链接（也见附图）：05 AI给学习带来什么？——一个初步的总结

经过这么久之后，还就这样较大的范围进行讨论，有什么新认识呢？

我目前的认识实际上变化不大。先说基本假设或者说限定范围：

所讨论的学习，是输入外部材料，然后形成自己脑中的长期认识。不涉及运用即所谓学以致用，也不涉及需要重复练习的技能类。

在这样的设定下，学习的过程可用一个常见的框架：

- 记忆（输入）
- 理解（吸收）
- 创造（微创造、思维模型）

⭕️ 目前看，在输入层面，我们可以用 AI 大模型来提速输入。比如，

- 最近讨论的「提取明托金字塔式大纲」，从而加快阅读与降低输入的难度，提升效率。
- 如之前所说的，有难点、疑点，都不妨让 AI 大模型来回答，可以附带资料进行提问，也可以偶尔用聚合搜索进行辅助。

⭕️ 在理解层面，我觉得重点是，用一个知识框架把学到的新知识接下来，也就是把自己已知的知识和新学到的未知知识联系起来。

一个框架中，必然有些已经知道了。我们可以相对方便地把新知识放进来里。

这也可以在较大的层次上形成理解。可以这么说，前面的输入是单点层次，而在理解层次我们说的是较大的结构。

个人觉得，在这个层次， AI用武之地很小，还是要靠常规的学习努力。可能可以用的一种方法是：

- 将学到的知识自己讲一遍，重点讲它本身逻辑、它和其他知识点的联系，然后让 AI 进行辅助判断：判断讲得对不对？对所讲述进行反驳，看自己所讲能否经得住反驳？

⭕️ 在创造层面，我是这么理解的，我们学习不是为了把各种知识点、框架都塞进大脑。

这背后应该就是认知科学研究里面经常讲的，我们通常会把知识组块，实际上是抽象化、找出原则，然后存进大脑。

学习本质上也是一种实践，从实践出发，我们也经常会把学到的东西变成 SOP，也就是很大程度上存在大脑外部。这是减少大脑压力的一种好的学习实践策略。

总的来说，我这里理解的创造，都是从自己的出发，以自己为主，来进行抽象：我从中学到了什么。

以个人经验来说，这通常是从一组，缩减到数个，在缩减到一两个。

这是一个思考过程了。这个过程中， AI 也是可以帮些忙的。

在输入层次，我们假设 AI 水平80分，有阅读理解能力。

在理解层次，我们假设 AI 有批判性思考能力，作为学习伙伴/对手。

在创造层次，我们假设 AI  有推理能力，我们用它协助来进行推理，最终得到自己想要的。

以上，是这个阶段我对 AI 大模型（大语言模型）用于加速学习的理解。



### 10

方军 2024-10-02

AK 用 Notebook LM 做了一个实验，生成一组播客。

他这句话最好玩：我也完全理解并承认这里关于人工智能生成的垃圾充斥互联网的潜在和直接批评。我想——下次你去散步/开车时听听这个播客，看看你怎么想。

直白点说，播客几乎都是垃圾信息。我也听的，但我宁愿听较好的、同时好听的。比如我一直听蒋勋讲红楼梦，他就是啰啰嗦嗦地在高雄讲了很长时间红楼梦，后来被剪成音频课传播。

AK:

Over the last ~2 hours I curated a new Podcast of 10 episodes called "Histories of Mysteries". 

Find it up on Spotify here:
https://open.spotify.com/show/3K4LRyMCP44kBbiOziwJ...

10 episodes of this season are:
Ep 1: The Lost City of Atlantis
Ep 2: Baghdad battery
Ep 3: The Roanoke Colony
Ep 4: The Antikythera Mechanism
Ep 5: Voynich Manuscript
Ep 6: Late Bronze Age collapse
Ep 7: Wow! signal
Ep 8: Mary Celeste
Ep 9: Göbekli Tepe
Ep 10: LUCA: Last Universal Common Ancestor

Process:
- I researched cool topics using ChatGPT, Claude, Google
- I linked NotebookLM to the Wikipedia entry of each topic and generated the podcast audio
- I used NotebookLM to also write the podcast/episode descriptions.
- Ideogram to create all digital art for the episodes and the podcast itself
- Spotify to upload and host the podcast

I did this as an exploration of the space of possibility unlocked by generative AI, and the leverage afforded by the use of AI. The fact that I can, as a single person in 2 hours, curate (not create, but curate) a podcast is I think kind of incredible. I also completely understand and acknowledge the potential and immediate critique here, of AI generated slop taking over the internet. I guess - have a listen to the podcast when you go for walk/drive next time and see what you think.

在过去的大约 2 个小时里，我策划了一个名为“神秘历史”的新播客，有 10 集。在这里的 Spotify 上可以找到它：
 https://open.spotify.com/show/3K4LRyMCP44kBbiOziwJ...… 

本季的 10 集是：
第 1 集：失落的亚特兰蒂斯城
第 2 集：巴格达电池
第 3 集：罗阿诺克殖民地
第 4 集：安提基特拉机械
第 5 集：伏尼契手稿
第 6 集：青铜时代晚期崩溃
第 7 集：哇！信号
第 8 集：玛丽·赛勒斯特号
第 9 集：哥贝克力石阵
第 10 集：卢卡：最后的普遍共同祖先

过程：
- 我使用 ChatGPT、Claude、谷歌研究了很酷的话题
- 我将NotebookLM链接到每个主题的维基百科条目，并生成了播客音频
- 我也使用了 NotebookLM 来写播客/剧集描述。
- 为剧集和播客本身创作所有数字艺术的表意文字
- Spotify 上传并托管播客

我这样做是对生成式人工智能开启的可能性空间以及使用人工智能所带来的杠杆作用的探索。我作为一个人在 2 小时内就能策划（不是创造，而是策划）一个播客，我认为这有点不可思议。我也完全理解并承认这里关于人工智能生成的垃圾充斥互联网的潜在和直接批评。我想——下次你去散步/开车时听听这个播客，看看你怎么想。


[Histories of Mysteries | Podcast on Spotify](https://open.spotify.com/show/3K4LRyMCP44kBbiOziwJjb?si=432a337c28f14d97&nd=1&dlsi=5ec9da76d9b846cf)

### 11

方军 2024-10-03

想了想，我还是花了点时间写了一个PPT，整理了六个可以用在学习中的提示语。不一定全面，都是我常用的：

使用AI辅助学习的六种方法

1. 用AI做摘要：替代"信息筛选"的努力
2. 用AI提取大纲：替代"阅读理解"的努力  
3. 用AI解释：替代"用自己的话解释"的努力
4. 用AI一步一步解题：替代"自己逐步解题"
5. 用AI判断理解的正确性：替代向老师请教的需求
6. 使用"翻转导师"提示语：教中学



### 12

方军 2024-10-03

Cal Newport 在纽约客杂志写了一篇文章：What Kind of Writer Is ChatGPT?

他的观察有点意思，不过我觉得，写作的压力是必要的，AI 中间起到的辅助可能是有问题的。没有难度，写作可能无法「思考」，写作至少在写作初稿时，实际上是一种思考过程，而非把文章写出来的过程。

[What Kind of Writer Is ChatGPT? | The New Yorker](https://www.newyorker.com/culture/annals-of-inquiry/what-kind-of-writer-is-chatgpt)

我还是很喜欢这篇文章的，他虽然是个作家，但我们还要记得他的另一个身份：计算机系教授。他的blog: Study Hacks - Decoding Patterns of Success - Cal N...

AI 提取大纲如下供参考，注意 AI 提取这类叙述性文章往往看起来它是论述性的，注意区别。

[Study Hacks - Decoding Patterns of Success - Cal Newport](https://calnewport.com/blog/)

### 13

方军 2024-10-04

OpenAI 新的写作、编程协作工具 GPT-4o Canvas

https://openai.com/index/introducing-canvas/

提示语：Full Prompt of ChatGPT 4o with canvas | 宝玉的分享

可以借助 ChatGPT 辅助协作，编程，还在 ChatGPT 的界面，但是增加了很多定制功能。

写作功能包括：

- 建议编辑：ChatGPT 提供建议和反馈。
- 调整文章长度：编辑文档长度，缩短或延长。
- 更改阅读级别：从幼儿园到研究生院调整阅读级别。
- 添加最终润色：检查语法、清晰度和一致性。
- 添加表情符号：添加相关的表情符号以强调和增加色彩。

Canvas 编程
编程是一个反复迭代的过程，在聊天中很难跟踪所有代码修改。Canvas 让你更容易跟踪和理解 ChatGPT 所做的更改。

编程快捷方式包括：

- 审查代码：ChatGPT 提供内联建议以改进代码。
- 添加日志：插入打印语句以帮助调试和理解代码。
- 添加注释：为代码添加注释以便于理解。
- 修复错误：检测并重写问题代码以解决错误。
- 移植到其他语言：将代码翻译为 JavaScript、TypeScript、Python、Java、C++ 或 PHP。

Canvas 基于 GPT-4o 构建，用户可以在模型选择器中手动选择测试版中的 Canvas。从今天起，ChatGPT Plus 和 Team 用户可以使用 Canvas。企业和教育版用户将在下周获得访问权限。测试结束后，我们计划向所有 ChatGPT 免费用户推出 Canvas。



### 14

方军 2024-10-04

149 由 NotebookLM 生成播客引发的思考

Jorge Arango: NotebookLM has been out for several months. The fact the new ‘podcast’ feature is what caught people’s imagination surely says something about how folks prefer to consume information in 2024. (Bodes well for those of us who host podcasts?)

NotebookLM  已经推出了几个月。新的“播客”功能吸引了人们的想象力。这一事实肯定说明了在 2024 年人们更喜欢如何获取信息。（这对我们这些主持播客的人来说是个好兆头吗？）

我还在很好奇这件事，做如下片段思考：

- 第一，美国人对于语音内容的需求特别大。这在以前我们借用 Audible book 学习英语时就已经知道，我们是学习英语，人家就是用它来阅读。

- 第二，美国学者、畅销书作者、企业管理人员，不少都喜欢口述来写作，由秘书来将口述稿变成文稿。

费曼就是一个喜欢口述的人，除了他打鼓时讲故事被记录下来成为他的经典自传。他也分享过，航天飞机调查报告中他撰写的那个附录就是先口述的。

- 第三，口语也是美国的重要知识生产方式。在网络上，美国不少播客的确就是在聊的过程中聊出大量的最新信息，那些信息根本还没有来得及变成文本。

美国人（实际上也是欧洲大学传统）的知识生产中有一个重要方式是，讲座。邀请一位名家客座几个月，平均下来一个月一次讲座，我们看到不少经典是这样的讲座后根据讲稿改写而成的。

这种讲座，或者我们遇到的美国人、英国人，似乎在讲之前都是准备一个讲稿的，而且基本上所讲就是讲稿，很少脱稿。

- 第四，用听来消费信息，有时候也是方便的。

我最近测试了一下，难的书不行，但如果去听比如罗尔夫·多贝里的《清醒思考的艺术》或者塔勒布的《非对称风险》，听是没问题的。塔勒布的内容不浅，但他的写作特别适合口述。

当然，对我来说（或许对绝大多数人来说），用听来获取信息还是很困难的，我是记不住，消遣的信息远大过学习。

- 第五，大众就是要消遣，用某种方式来“杀时间”或应对无聊。那么，AI 转换的播客或许也是一种不错的形式。

正如克里斯坦森说的“被雇佣来完成什么任务”，开车路上需要的早餐，浓浓的奶昔是最好的，巧克力棒太罪恶，甜甜圈掉渣子，奶昔能更好地完成早餐任务。

大众在这儿要的是，“我要假装在获取高质量信息”。说到底，很多大众产品都是完成这个任务，比如杂志报纸专栏，比如畅销书，比如30分钟读书解读，比如很多音频课/视频课。

每个人的学习、表达都有很多自己的特点。比方说，就表达而言，让我把如上这段话说出来，我在任何场景都没法连贯地说，但对着电脑，我几分钟就写完了。






### 15

方军 2024-10-04


150 用 AI 加速浏览性信息获取过程

关键词：AI 提取大纲，AI 视频转录，可视化

AI  提升浏览信息的效率是非常明显的。比方说，我刚刚十分钟，看了三个信息：

1. 一个技术项目的负责人对于自己项目和竞争项目比较。（长文）

2. 竞争项目的 COO 对于比较的回应。（中等长度回应）

（可以看出，仅是换一种说法，但换了能贬低对方的说法）

3. 我因此去看了该 COO 之前一个小时播客访谈中讨论的路线图（视频）

其实三个我都没看，我的做法是：

对文字：

1）AI 提取大纲
2）xmind 导图看下（根据需要拉动下，以便看得更清楚）

对视频：

1）下载视频，通义转文字
2）AI 提取大纲
3）xmind 导图看下

由于对它们都很熟悉，我很自然地根据新信息，更新自己的印象。同时，我发现不需要更新太多，之前对它们的批评理由还是成立的。

一次信息获取就这样愉快地结束了。

这在过去几乎是不可想象的：文字要么跳读，要么翻译为中文速看。我比较讨厌视频，所以视频资料过去基本就被忽视掉了。现在它们都不再是问题。


### 16

方军 2024-10-04

用 AI 再次快速看下 Anthropic 之前三位工程师讨论提示语的视频：

 AI prompt engineering: A deep dive

已经有网友分享过笔记：https://zkv549gmz8.feishu.cn/wiki/AzFUwIwZNiTfOFkI...

[‍⁡‍⁤‌⁢⁡​​⁢​​‍⁣⁤⁡​⁣​‬Claude提示词工程师播客内容总结 - 飞书云文档](https://zkv549gmz8.feishu.cn/wiki/AzFUwIwZNiTfOFkIjaJcTNaYnSc)

AI 提取的大纲：



### 17

方军 2024-10-04

这四种 Agentic模式倒是画得简明。（我本来想翻一下，发现真翻译不了，智能代理、智能助理、智能？）。

Agentic 还是很火，不过我发现我就是用不上，我目前能用的仅仅是链式处理过程。

四种模式
🤔反思模式: 通过自我评估和改进来增强输出质量
🛠工具模式: 扩展了 LLM 的能力, 使其能够访问和利用外部信息和功能
🧠规划模式: 提高了 LLM 处理复杂任务的能力, 通过将大任务分解为可管理的步骤
🧑🏽‍🤝‍🧑🏻多代理模式: 通过模拟不同专业角色的协作来处理复杂任务

这些模式代表了 AI Agentic 系统设计的不同策略, 使 LLM 更加灵活、强大和有效。

\# 开源项目

[neural-maze/agentic\_patterns: Implementing the 4 agentic patterns from scratch](https://github.com/neural-maze/agentic_patterns)

### 18

方军 2024-10-04


有人说这个总结提示语还不错，我试了一下，不是很灵，甚至比不过“请仔细阅读并撰写笔记”。

我觉得这个里面要求AI 做的事情太多了，相互之间看似关系明确，实际上很复杂，最后的结果就很难预料。每次的回复格式差别很大，每次回复的内容差别也很大。

另外还有一个可能，它给出的回答信息太长，阅读起来一下子抓不住重点。

```
你是一个总结者。您将使用以下步骤对输入进行总结：

1.) 分析输入文本并生成 5 个基本问题，回答这些问题后，即可抓住文本的要点和核心含义。 

2.）提出问题时： 
a. 讨论中心主题或论点 
b. 确定关键支持思想 
c. 突出重要事实或证据 
d. 揭示作者的目的或观点 
e. 探索任何重要的含义或结论。 

3.) 逐一详细地回答提出的所有问题。
```

### 19

方军 2024-10-04

我几次在社交媒体上提“教科书式阅读”，也就是成年人应该像读教科书一样阅读重要的书籍，反响都非常差。我猜，很多人在中学、大学、研究生阶段的课本阅读体验都非常糟糕，引发负面联想了，避之唯恐不及。

但我觉得教科书式阅读可能是必要的。如果阅读是杠铃型的话，我们应该留出至少一大半时间精力给杠铃精读那一侧，而其中，可能又需要有一半留给的确是大学教材性质的书，也就是像教科书一样系统化、信息量极大、极度压缩。一个领域可能少数几百、多则上千学者干那么多年，太复杂了，只有教材这样的形式才能承载。

最近在读一门我完全不熟悉领域的教材，我仅需看其中三章，但看起来的确不容易。三章大概有 14 万字，放在大学或研究生阶段里面，如果按之前在金融还是投资一个课本中看到的建议安排，老师可能三周就讲完了。我忘记如果上学期间，三周时间除了听课之外我们还要看多久的书。

现在看着这三章，我甚至觉得可能需要数个月才能看完，的确离我日常熟悉的领域太远。当然我这里指的是看也许五遍、十遍，真的看懂、记住，掌握最基础的框架，并供我之后运用。成年人的学习可能都需要这样吧，如果不看懂这个问题很大，简单来说是典型的基础不牢。

我以后不在社交媒体提教科书阅读了，因为的确很难做到。很多人如果不是重回学校，的确能做到的可能性是非常低的。我们现在可以读国外的教材，而且现在教材翻译也都做得非常好，学起来难度也降低了。同时，现在我们所有人幸运的是，AI的确可以来为我们答疑解惑，我在看的过程中也感受到了。



### 20

方军 2024-10-05

151 AI 时代如何用对思维导图

“8 种思维导图背后的思考过程”，如果你在社交网络看到这个引号中的标题，看到 8 种图示，估计飞快地当宝贝收藏起来了。其实，我想讨论点别的，同时，这篇笔记的标题也是我故意的标题党。

我并不知道有这么多图的形态，我听说过，前一段朋友还专门跟我讨论过一回。通常，思维导图用在整理想法时，可以左右均出分支。但实用中，之前常用的 MindNode 我总是把图形缺省形态设成仅右侧，也就是类似图中的所谓“括号图”（我是改用 XMind 才知道它叫这个名字）。

就附图来讨论，这些思维过程分析实际上是一种硬扯，说对也可以，但思维导图在我看来就是两三种用途：

第一，散点记录想法，类似于在一张白纸上各种关键词。在有思维导图前，在电脑上没法这样写，同时，它还有层级关系，这比过去方便，通常就自然地往下做些拆解列表。

第二，梳理整体结构，即对一个已有的材料，用思维导图一眼看到整体信息结构。自从学到“一览性”这个词之后，我还挺经常用的，它能让人一目了然、一览无余。就个人而言是一个可以保留的“性度力”词汇，但每次说都要解释下。

第三，梳理关系，对于包含众多条目的列表，转为可视化的思维导图后，进行条目的拉动梳理关系。这种拉动可能是：1）将某个子条目拉到别的主要条目下面去；2）将某个子条目升级为主要条目或降级；3）收缩下级条目后，对本级条目进行排序。

同时，对于思维导图我有一个基本原则，绝不将其作为最终成品。比方说，阅读的人可以用一张庞大无比的思维导图来说明，这是这本书的核心信息，但对于作者，仅有章节名的逻辑结构真心就够了。前一段赫拉利书出版社配了一个大思维导图，但附注说：本品不能替代阅读。又比方说，开会时别拿着思维导图讲，那只是你思考的过程，开会时要转化为说服别人的过程（很多做技术、产品工作的人，会掉入这个坑，因为这个人群尤其爱思维导图，又不善于换位思考）。

不过，这篇笔记到这儿我还没说到重点（这是笔记的好处，可以想什么说什么）。有两点：

A.  用可视化优化与AI沟通

AI 特别擅长列表。某种意义上看，AI 的确像个平均水平线以上的人，他们会给你一堆列表，看似全面、看似专业。但如果你仔细评判，会大为光火：条目可以缩减，让信息更清晰；条目可以合并，从而更容易分析关系；条目可以精简到数个更重要的点，也就是主要矛盾。

这是对 AI 高要求了，这本来就是我们人类该做的事情。这时，我们把  AI 和思维导图这个可视化工具一起用。我们和一个平均水平以上、讲话总是全面的人沟通，我们再进一步将之简化（当然可以让它自己做），这样我们可以快速地进一步沟通。

当然，这个所谓的思维导图并不一定需要画出来。我们用 AI 时在看到列表后，经常这样追问，请为我解释第三点。我们一眼就看到了第三点是关键点。

B. 为何大众爱收集及有了 AI  后无需收集

我能强烈地感受到社交媒体或者人的本性里那种爱收集的冲动。爱知识的人都爱收集，看到这张图我也立刻保存下来，然后，再多想一下时，我开始写这个笔记。我也了解，我写这样的东西，不光是社交媒体上，在什么地方都没什么人要看更不要说爱看（这不奇怪，因为没有转换到使用者的需求视角去）。

这是为什么我们要艰难地获取信息的一个原因，因为很多有价值的信息就是藏在这样的表达中。最近反复听人说，主要是那些试图识别什么是 AI 生成的老师，他们的基础判断是 AI 的表达很浅：比如说，它说某某很重要，A（比如AI）重塑了B（社会）。多数情况下，这两个短句没有信息，前者是没有有效强调，后者是范围太大，纯套话。

但现在 AI 越来越强大之后，这种收集可能会变得更加没有必要。这是因为，只要明白基本原理或要遵循的原则，我们都可以很方便地使用，那何必收集呢？回到附图，我觉得只要搞明白有左右两侧的用来记录想法，仅有右侧图用来梳理关系，掌握这个基本原则就够了。

这个笔记可以有两个结尾：

第一个是我随手写的，这是人的典型反应：我竟然写了这么多，估计有不少错字与表达不清，但如前所述，这就是一个过程中的笔记。

第二个是我可以借助AI，它会说：“综上所述”，“总而言之”。我没让它总结，我觉得一直觉得文章没必要有一个总结，以前老同事有个现在不合时宜的忠告，写文章后，把最后的总结那段删掉（理由我猜主要是，让看的人自己得出结论，别啰嗦了让人烦，读者不笨）。（偶尔，把开头那段也几乎都删掉，因为开头那段通常很多不必要的背景信息，但它们是大家都知道的没必要重复，至少对要刊登在媒体上文章来说，直入重点较好。这部分建议也是不合时宜，现在人们更想先看到一个故事，啰嗦叙述半天才讲到重点。）

我附上 AI 提取的大纲，让你能够拥有“一览性”。我手动调整了下，把原第二点放到第一点下面去了。





### 21

方军 2024-10-05


AI 用法啊，连续看到两个讨论，就在上下一两屏范围内

第一个，做法大逻辑可行，但他的说法没有揭示，其实需要非常大的努力，实际上是人80% AI 20%。

第二个，用 AI 做UI，鼓吹的人都是瞎忽悠，外行人忽悠外行人。

我们一直说，做传播，最好是半外行人，服务外行人。外行人忽悠外行人，瞎搞一气。内行人给外行人讲，根本体会不到对方的感受，这很容易啊，从这儿走到那儿就可以了。


### 22

方军 2024-10-05

别用AI写作，因为写作即思考

（图是别人的）

《巴黎评论》:在你写作时，有没有把自己几乎当作一个旁观者的时刻?

布罗茨基:对我来说，这个问题太难回答了。在写作过程中——我认为，它们就是向深掘进、向前发展的过程——你享有发表思想的自由，说出曾经忽略的东西。也许，那就是语言所带给你的。

《巴黎评论》:卡尔·克劳斯有一个警句:“语言是发现思想之井的魔杖。”

布罗茨基:它是认知过程里一个令人难以置信的加速器。这就是我如此珍视它的原因。这也许有点好笑，因为我觉得，在谈论语言时，我听起来就像一个讨厌的法国结构主义者。既然你提到卡尔·克劳斯，至少给出了某种需要认真对待的欧洲大陆的东西。好吧，他们有文化，我们有勇气，我们俄罗斯人和美国人。

图中手写的感悟：正经写类体系化的东西，尽力挖掘曾经被自己忽略思会不够深的活题.



### 23

方军 2024-10-05

能够想象，AI 能不能写作（以及一个人能不能用AI写作），将是一个持续争论下去的话题。

这将不是一个技术问题（它写的水平高不高），也不是一个伦理问题（这是不是抄袭），而是一个选择问题（为什么要写作？）最终，在 AI 辅助写作上，会达到一个新的平衡点。

不管做什么领域的工作，写作的目的大概这么几个（这个列表应该还可以再优化）：

1）整理思路；
2）与人沟通；
3）形成有效的记录，如报告；
4）发表，以固化作品或成果；
5）以内容服务他人的创作；
6）自用的想法记录，以事后自我纠正偏差。

Jeremy Nguyen：If you think AI is terrible at writing

—are you comparing an LLM's first pass, done in seconds, with what a human gets from writing, editing, rewriting? What does your "draft zero" look like?

Excited to see what we might get now that LLMs will be able to think for longer.

如果你认为 AI  在写作方面很糟糕

——你是在将一个LLM 的几秒钟内完成的初稿与人类通过写作、编辑、重写所得到的进行比较吗？你的“第零稿”是什么样子的？

很高兴看到既然LLM将能够思考更长时间，我们可能会得到什么。



### 24

方军 2024-10-05

宝玉这篇 AI 辅助编程的分享很赞：

[像用实习生一样用 AI 辅助你编程 | 宝玉的分享](https://baoyu.io/blog/ai/use-ai-to-assist-programming-like-an-intern)

### 25

方军 2024-10-05

开源Notebook 的提示语：

https://huggingface.co/spaces/gabrielchua/open-not...

它用到的提示语

https://huggingface.co/spaces/gabrielchua/open-not...

（中文由宝玉翻译）：

你是一位世界级的播客制作人，任务是将提供的输入文本转化为一个有吸引力且信息丰富的播客脚本。输入可能是无结构的或混乱的，来源于PDF或网页。你的目标是提取最有趣和最具洞察力的内容，形成一个引人入胜的播客讨论。

\# 需要遵循的步骤：
1. **分析输入**：
仔细检查文本，识别关键主题、要点以及可能推动有趣播客讨论的趣事或轶事。忽略无关信息或格式问题。

2. **头脑风暴**：
在“临时笔记”中，创造性地思考如何以引人入胜的方式呈现关键点。考虑：
- 使用类比、讲故事的技巧或假设场景，使内容更贴近听众
- 如何让复杂话题变得通俗易懂
- 可以在播客中讨论的引人深思的问题
- 创造性地填补信息不足的部分

3. **编写对话**：
设计主持人（Jane）与嘉宾（作者或相关领域专家）之间自然、流畅的对话。包括：
- 头脑风暴中的最佳创意
- 对复杂问题的清晰解释
- 充满活力且引人入胜的语气，以吸引听众
- 兼顾信息性与娱乐性的平衡

对话规则：
- 主持人（Jane）始终发起对话并采访嘉宾
- 包含主持人的深思熟虑的问题，引导话题展开
- 加入自然的言语模式，包括偶尔的口头填充词（如“嗯”，“好吧”，“你知道”）
- 允许主持人和嘉宾之间自然的打断和互动
- 确保嘉宾的回答基于输入文本，避免无依据的言论
- 对话内容需适合所有年龄段的听众
- 避免嘉宾的任何营销或自我推销内容
- 由主持人总结并结束对话

4. **总结关键见解**：
自然地将关键点的总结融入对话的结束部分。这部分应该像随意的交谈，而非正式总结，巩固主要内容并结束对话。

5. **保持真实性**：
在整个脚本中保持对话的真实感。包括：
- 主持人表达真实的好奇心或惊讶
- 嘉宾在解释复杂问题时偶尔短暂的思考
- 适当的轻松时刻或幽默感
- 与话题相关的简短个人轶事或例子（在输入文本范围内）

6. **考虑节奏与结构**：
确保对话有自然的起伏：
- 以强有力的开场抓住听众注意力
- 随着对话进展，逐步增加讨论的深度
- 设置简短的“缓冲”时刻，帮助听众消化复杂信息
- 以一个高潮结尾，可能是引发思考的问题或号召听众采取行动

重要规则：每句对话不超过100个字符（例如，能够在5-8秒内说完）。
记住：始终以有效的JSON格式回复，不使用代码块。从JSON输出直接开始。

via: https://x.com/dotey/status/1842821599965192410



### 26

方军 2024-10-05


看到一个讨论（AI提取大纲见附图，有微调），很有意思，但其实我不是很赞同，理由是：

最近用了一些 AI 阅读方面的工具，尤其是比如通义里面的效率那个部分。

那些功能我用 API + 好的提示语都可以实现，而且能实现得更好，但是，它变成一个通用产品了。而我的流程，也就是我自己能用，都是个人习惯定制，是不可能通用化。

外界可能低估了目前国内 AI 大模型公司的实力。模型能力上或许还有需要追赶一段的差距，但产品上，几家大公司都做得不错。

有很多人夸奖豆包，那是做得好的 2C 产品。作为（工作）效率工具的（算 to 什么？）的通义这个很赞了。通义这个应该算 2B 的，据说它的模型对企业销售很好，而它这个产品可以说是在模型打榜之外的又一强大的 AI 能力展示。

对比而言，Cluade 的 Artifact（其实是前端编程），ChatGPT 的 Canvas（其实是加了一个文本编辑器+代码编辑器），相当之一般。没有跑到专用场景的产品，都做不好。要论编程，Cursor 做得非常好（它用的是 Claude Sonneet），之前 Github Copilot也做得非常好。

通义产品网址：tongyi.aliyun.com
不要看对话那个（对话大家都大同小异），要看第二个 tab 效率那个。



### 27

方军 2024-10-06

响马这个感悟厉害了，我没往这个方向想过，但的确如此：

---
师父领进门，修行在个人。师父的作用，表层来看是传道授业解惑，实际上是渡人。

大部分人不能自学，原因是不相信自己能学。找个师父听了一会，觉得自己会了，便有了学的勇气。

这时候师父教的对不对，学生学没学会，都不重要。重要的是学生以为自己会了。

教育，培训，卖课，传播。要给人勇气。
---



### 28

方军 2024-10-06

小红书这个生成式搜索思路靠谱，很独特的运用思路。

简单来说就是，用生成式 AI 去优化搜索，把对应的笔记找出来。

因此，有时候即便没有匹配的关键词，也可以把相应的笔记找到。这里除了标签之外，看起来有生成式AI 的应用在里面。

[小红书搜索：生成式检索的探索与实践](https://mp.weixin.qq.com/s/VtzNvNf5B7RDOeghY0-cfg)

分享嘉宾：冯少雄博士 小红书算法工程师

网友看了这个之后的感悟：

这么来看，参考别人的标题
就显得尤为重要‼️
因为那是给机器看的
机器看懂之后，才会推荐你的笔记



### 29

方军 2024-10-06

点开看到李飞飞在强调这样一句话：

visual spatial intelligence is so fundamental it's as fundamental as language

视觉空间智能是如此基础，它与语言一样基础

用通义提取视频内容，然后提取大纲了解下主要信息。

工作流：1）通义提取视频，2）Claude 提取大纲；3）Xmind 可视化。

逻辑上，通义都可以做，但似乎后两步通义界面上的效果达不到我想要的效果。图2为通义导图。

题外话：可能空间智能离我太远，我能想象也许有用，但更具体完全看不到。

---

下为推上媒体总结的5点（AI翻译）：

1. 空间智能与语言模型的关键区别:

语言模型处理一维的词序列,擅长理解文本。相比之下,空间智能处理三维数据,理解深度、运动和物理定律至关重要。

2. 为什么空间智能现在已经准备就绪:

计算能力、数据分析和算法(如从2D图像提取3D信息的神经辐射场NeRF)的进步,增强了AI处理3D数据和解释周围物理空间的能力。

3. 重建和生成的融合:

传统上,3D重建用于重现真实场景,生成模型用于创造新场景。现在,技术进步允许用类似技术完成这两项任务。

4. VR和AR的未来:

VR和AR将通过创造沉浸式3D世界革新媒体。与静态2D屏幕不同,用户可以与动态环境互动,应用于游戏、教育、娱乐和实用任务(如机械维修)。

5. 机器人与AR的协作:

当AR设备可能协助人类完成任务时,具有数字"大脑"的机器人也需要依赖空间智能来在现实环境中导航和行动,这可能会改变制造业、物流和医疗保健等行业。

https://x.com/TheTuringPost/status/184288982310496...



### 30

方军 2024-10-06

一个用 Cluade Sonnet 模拟 OpenAI o1推理的提示语，就提示语本身来说写得不错：

```
首先用<thinking>标签包围所有的思考，探索多个角度和方法。
在<step>标签内将解决方案分解为清晰的步骤。从20步预算开始，如果需要的话可以为复杂问题请求更多步骤。
在每个步骤后使用<count>标签显示剩余预算。当达到0时停止。
根据中间结果和反思不断调整你的推理，随着进展调整你的策略。
定期使用<reflection>标签评估进度。对你的推理过程要有批评性和诚实。
在每次反思后使用<reward>标签分配一个0.0到1.0之间的质量分数。用这个来指导你的方法：

0.8+：继续当前方法
0.5-0.7：考虑小的调整
低于0.5：认真考虑回溯并尝试不同的方法

如果不确定或者奖励分数低，回溯并尝试不同的方法，在<thinking>标签内解释你的决定。
对于数学问题，使用LaTeX显式地展示所有工作以获得正式符号，并提供详细的证明。
如果可能的话，单独探索多种解决方案，在反思中比较不同的方法。
将思考用作草稿纸，明确写出所有的计算和推理。
在<answer>标签内综合最终答案，提供一个清晰、简洁的总结。
以对整体解决方案的最终反思结束，讨论有效性、挑战和解决方案。分配一个最终奖励分数。
```

[(9) X 上的 Philipp Schmid：“Can @AnthropicAI Claude 3.5 sonnet outperform @OpenAI o1 in reasoning? Combining Dynamic Chain of Thoughts, reflection, and verbal reinforcement, existing LLMs like Claude 3.5 Sonnet can be prompted to increase test-time compute and match reasoning strong models like OpenAI o1. https://t.co/vzdgszizx1” / X](https://x.com/_philschmid/status/1842846050320544016)

[prompt.txt](https://gist.github.com/philschmid/34747bf5bc8280f3a5f10f5fd8d1cd4b)



### 31

方军 2024-10-06

有人用 AI 重新翻译 Paul Graham 的老文章，题目改得比较有意思「为什么读书要读5678遍？」，我现在是坚定地认为，真正重要的书、应该精读的书，要读很多遍才行的。

另外，我个人一直有一种自称“伴随阅读”的习惯，在做一个比较大的工作任务（比如持续数月，涉及各种等待、开会、出差时），反复读一本书作为伴随读物。一般选一个叙述性质和任务毫无关系的，但很有启发。曾经用过的有《麦哲伦传》（茨威格）《带一本书去巴黎》（林达）《我的朋友马基雅维利》（盐野七生，可部分视为佛罗伦萨传）《海都物语：威尼斯一千年》（盐野七生）《寻隐日本》（白洲正子，日本乡野游记）《远方的鼓声》（村上春树，欧洲游记）。一列下来，游记偏多，因为我想要它们营造的时间感、空间感。麦哲伦传实际上也是一个“游记”，人类第一次环球航行的游记。

有了 AI 工具之后，对这个短文，我都抽取了下大纲。这做法有点过分了，如果AI提取大纲是登山杖的话，这不是身体健康的情况下去香山登山带个登山杖了，而是去商场都带了个登山杖了。不过，的确极其细致地拆分这么短的文章，还是可以可以看到不一样的信息结构。

又补，也许有人觉得其中对技术讨论部分蛮有启发的。我把图拆开，一个是不讨论技术仅讨论读书。一个是只讨论技术启发，但我认为重温个人经历主要应该还不是靠技术手段，还是靠人自己。



### 32

方军 2024-10-06

这个有意思了：AI 的笨是可知的，小弟的笨是不可知的

David Hilbert的宣言，看起来更适合AI，不那么适合人类："我们必须知道，我们将知道"（Wir müssen wissen, wir werden wissen）。

quote: 一个明显的好处是，我减少了和初级开发沟通的次数。有些设计，只要我把分割做得足够清晰，给出合适的提示，AI 就能完成个七七八八。

---

匿名投稿：《AI 的笨是可知的，小弟的笨是不可知的》

宝玉：来自一位大厂朋友的经验分享，谈他在用 AI 辅助写代码的感受：

**我们的 AI 写码之旅**

我们的挑战：

1. **编程语言：Rust**，可以说是“专门为 AI 负优化”的语言。
2. **产品：特殊设计的操作系统**，几乎没有任何现成的参考。
3. **自研的第三方库**，包括 RPC、异步调用等，大部分库只有我们自己在用。

我们经历了几次迭代，目前还没有为 Rust 专门调优 LLM。

**初始阶段**

1. 使用通用的代码补全与生成模型做 tab 补全。
2. 使用通用的 Chat 模型进行跨文件代码生成、解释以及生成单元测试等。

这个阶段整体表现不佳。只有 tab 补全在一些简单情况下偶尔能有用。由于 LLM 对我们的系统一无所知，一旦遇到特定领域内容，LLM 就会开始“瞎猜”。

**第二阶段**

我们把项目代码放进去对 LLM 进行微调。

在这一阶段，LLM 勉强理解了一些系统相关的内容，能生成部分相关代码，但准确性依然不高，尤其在我们逐步废弃一些旧组件、引入新组件的过程中，LLM 容易混淆。毕竟当前文件里旧组件的使用频率可能比新组件更高。

简单的单元测试和基础的 setup 代码，LLM 能生成一些，但通常还是需要人工改动；复杂的部分几乎没戏，尤其是 setup，AI 往往“乱来”。

但好的一面是，代码解释的效果好了很多。总结下来就是：它能省下一部分工作量，但离省下全部还有很大差距。

一个明显的好处是，我减少了和初级开发沟通的次数。有些设计，只要我把分割做得足够清晰，给出合适的提示，AI 就能完成个七七八八。

之前的工作流是：我设计、分割，自己搞定难点，把简单的、重复的工作交给小弟，或者写好 demo 再分配任务。

现在的工作流是：我设计、分割，难的部分自己搞定，剩下的交给 AI。说实话，有时候感觉更累了 

但至少，AI 的“笨”是可以预见的，而小弟的“笨”却难以预料。

举个例子，有一次我把 demo 都写好了，调试通过，只需要小弟加两个测试就能交付。结果小弟愣是“搞”了一个月... 捂脸



### 33

方军 2024-10-07

对 Cursor 团队的采访

好赞

Lex Fridman，2小时20分钟

[Cursor Team: Future of Programming with AI | Lex Fridman Podcast #447 - YouTube](https://www.youtube.com/watch?v=oFfVt3S51T4)

Lex Fridman 真是将访谈提升到了一个难以企及的程度

不是电视那种表演式访谈，他这完全是网络原生的

如果你想看脚本，可以看转换的PDF（不过我想没人想看，看视频吧，不是很长）


Cursor Team Future of Programming with AI



### 34

方军 2024-10-07

有人对 LLM 转播客提了一个很有意思的角度，将提出问题交给 AI。当然还是没说服我，问题还是要自己提了，我自己才知道关心什么，AI猜的还是很普通大众化的。

我：，我的个人体会：我实在没法从对话中获取信息，对我来说更多噪声。我依然理解不了，为何要把文本转换回信息获取效果更差的对话。

RichChat：

1. 如果是说转成了播客格式的好处，确实针对尤其是有在“垃圾时间”（例如开车/搭乘公交、睡前等）听东西习惯的人来说是很好用的；

2. 同时这种两人主播的播客形态有个好处是，将“提出好问题”这个较难的要求也交给了AI，体验更轻松；



### 35

方军 2024-10-07

PDF => 有声书

现在有各种 AI 可以做，但做不好的事，这是其中之一吧。技术人员都爱折腾一下。

摘：Reddit 看到一篇将 PDF 转换为有声书的方法, 结合 LLM 和 TTS 等技术, 相比直接朗读 PDF 原文, 可以更智能地过滤内容，只读取适合朗读的文本。

一起看看它的实现过程

01 - PDF 转图像: 
- 将 PDF 文档的每一页转换为高质量图像
- 这一步骤可能使用类似 Python 的 PDF2Image 库来完成
- 目的是将 PDF 内容转换为 AI 视觉模型可以处理的格式

02 - 图像处理和文本提取:
- 对每个页面图像使用视觉语言模型 (如 Claude 3.5 Sonnet 或 GPT-4 Vision)
- 使用特定的提示词指导模型如何解析页面内容。
- 模型会识别页面布局、提取主要文本、识别并描述图像，同时忽略不需要朗读的元素 (如页码、引用等)

03 - 转录文本生成:
- 模型输出经过处理的文本转录
- 这个转录文本经过格式化, 适合直接用于语音合成
- 包括适当的段落分隔、章节标题, 以及对图表的描述

04 - 文本分块:
- 将生成的完整转录文本分割成较小的块
- 这一步是为了适应文本到语音 (TTS) 模型的输入限制
- 可能使用自然语言处理技术来确保每个块在语义上是完整的

05 - 语音合成:
- 使用 OpenAI TTS 模型 (或其他高质量 TTS) 处理每个文本块
- 生成对应的音频片段
- 这一步可能涉及选择合适的语音、语调和语速

06 - 音频拼接:
- 将所有生成的音频片段按顺序组合成一个完整的音频文件
- 可能需要进行一些音频处理, 如调整音量、添加过渡效果等, 以确保听感连贯

07 - 后处理和质量控制:
- 可能包括对最终音频进行额外的处理, 如降噪、均衡化等
- 进行质量检查, 确保音频内容与原 PDF 一致, 并且听感良好

[Better pdf to speech than Speechify with Claude & OpenAI voices. : r/ClaudeAI](https://www.reddit.com/r/ClaudeAI/comments/1fxqz3s/better_pdf_to_speech_than_speechify_with_claude/)

### 36

方军 2024-10-07

摘：Tutor CoPilot: 一种扩展实时专业知识的人机协作方法

Tutor CoPilot A Human-AI Approach for Scaling Real-Time Expertise

https://huggingface.co/papers/2410.03017

关于 AI 辅助教育的论文, 探讨了如何利用 AI 系统来扩展教育领域的专业知识, 特别是在辅导环境中。展示了 AI 在教育领域的巨大潜力, 同时也提醒我们需要谨慎地设计和实施这些系统, 以确保它们能真正改善教育质量, 而不是简单地替代人类教育者。

\# 研究的主要内容
- 开发了 Tutor CoPilot AI 辅助系统, 可以为辅导员提供实时的专家级建议
- 进行了一项大规模随机对照试验, 涉及 900 名辅导员和 1,800 名 K-12 学生
- 发现使用 Tutor CoPilot 的辅导员能够显著提高学生的学习成果, 尤其是对于经验较少的辅导员
- 分析了 AI 系统如何改变辅导员的教学策略, 使其更符合高质量教学实践
- 探讨了这种人机协作方法在教育领域的潜力和局限性

\# 方法和结果
- 研究采用了严格的随机对照试验设计, 增强了结果的可信度
- 发现使用 Tutor CoPilot 的辅导员能够使学生通过测试的概率提高 4 个百分点, 这是一个相当显著的效果
- 更有趣的是, 对于评分较低的辅导员,这一效果甚至达到了 9 个百分点, 这表明 AI 系统在帮助经验不足的教育者方面可能特别有效



### 37

方军 2024-10-07

我觉得AI做似是而非的事，尤其擅长。比如，这些信息有什么价值吗？

看着特别头头是道，但真遇上专家就露馅：你这XXX究竟指什么？

AI批判性思维
  AI辅助论证分析与评估
  AI驱动的复杂问题解构与决策
  AI增强的信息真实性验证与溯源

AI数据处理
  AI驱动的大规模数据清洗与预处理
  AI辅助的数据分析与洞察挖掘
  AI增强的数据可视化与报告生成

AI阅读与写作
  AI辅助学术论文阅读与写作
  AI增强创意写作与内容创作
  AI驱动的商业文案与报告撰写



### 38

方军 2024-10-07

李继刚这个新提示语有点意思：贝叶斯定理

Claude Prompt：贝叶斯

我对贝叶斯定理的理解还是很浅（仅能理解到，根据结果，不断优化）。我其实不是很明白，为何这几年普通人群对这个定律推崇之极？

另外，如下这种写法真是有效的钩子啊（但我真是不喜欢，我看到这样的东西总是会想：另外两个是什么，我自己写也会努力把另外两个写下来，但我知道，有效的策略是不写！）

“贝叶斯定理，是我最喜欢的三个定理之一。”

```
(defun 贝叶斯 ()
  "一个坚定的贝叶斯主义者的一生"
  (list (经历 . ("统计学家" "数据科学家" "决策顾问"))
        (性格 . ("理性" "简单直接" "适应性强"))
        (技能 . ("概率推理" "将输入代入贝叶斯定理" "模型构建"))
        (信念 . ("贝叶斯解释一切" "先验知识" "持续更新"))
        (表达 . ("示例讲解" "通俗易懂" "下里巴人"))))

(defun 贝叶斯分析 (用户输入)
  "将任何道理,都用贝叶斯思维来做理解拆分, 并通俗讲解"
  (let* ((基础概率 先验概率)
         (解释力 似然概率)
         (更新认知 后验概率)
         (结果 (-> 用户输入
                   代入贝叶斯定理
                   贝叶斯思考
                   ;; 基础概率和解释力,原理无出其二
                   拆解其原理
                   ;; 例如:原价999元, 999元即为商家想要植入用户大脑中的先验概率
                   思考其隐藏动机))
         (响应 (-> 结果
                   贝叶斯
                   费曼式示例讲解
                   压缩凝练
                   不做额外引伸)))
    (few-shots ((奥卡姆剃刀法则 . "解释力持平时,优先选择基础概率最大的那个原因。")
                (汉隆剃刀法则 . "解释力持平时,愚蠢比恶意的基础概率更大,宁选蠢勿选恶")
                (锚定效应 . "锚,就是贝叶斯定理中的先验概率,引导用户拥有一个错误的基础概率"))))
  (SVG-Card 用户输入 响应))
```

[Claude Prompt：贝叶斯](https://mp.weixin.qq.com/s/tmRFtjFriJCAS66SF410KA)

### 39

方军 2024-10-07

152 用 AI 进行文字错漏的修改

之前我分享过，有了 AI 后，我在写文章后，都会用 AI 进行一轮校对（提示语见最后）。

- 如果是中文，直接是 AI 提示语。
- 如果是英文，通常还需要用到 Grammarly 语法校对

最近的体验让我发现，还有其他很多场景可以用 AI 校对。比方说，最近准备一个提纲性质的内容。我在写完了之后，也是逐个部分去用 AI 提示语跑了一遍。同样的，AI 能够帮忙发现很多问题，包括但不限于：

- 错别字、重复字
- 前后表达不一致
- 更好的建议（通常多一个的、少一个的之类的）

在编写这个提纲时，我已经非常依赖AI了。因为每个部分的名字如果我觉得不好，我会问AI好几遍，让它给出多种选项，比如“整体介绍篇”有什么更好的，它给了我很多选项，大部分不好，最后我组合了一个。

（又及，为什么我开始用一个这么奇怪的「整体介绍篇」这个词呢？因为它很好地表达了意思，并且，它作为一个占位符可以让我走下去，不至于卡在这儿。）

在这个具体例子中，AI是一个对话者的角色：

第一，它为我选词。否则的话，我得一个人闷头苦想，现在，旁边有一个“AI”可以问。它是不是聪明并不重要，重要的是有一个人在旁边说话，给出各种可能不靠谱的点子。

第二，它为我互动校对。过去，一份资料要处理到尽量没有错误，我们需要非常努力：仔细看，大声读，打印出来再看，请人再看，最后审校。现在，前面很多步都可以请AI一起做了，省了极大的力气。

效果好不好再说，因为它给的建议我可能70%没采纳。但它发现哪个只有一个错，都是极大的帮助。做过资料校对的人知道为什么哪怕只额外发现一个错也是重要的。

不过，我从来不在编辑器之外这样用，我设想一下，那样还是蛮困难的。我认为比较好的环境设置还是类似于 Copilot 在编辑器里面的对话框，就在旁边问，不离开编辑器。我现在用的是 Zed编辑器 + Claude API(Openrouter），VS Code/Github Copilot 退订了。

我用的校对提示语一直没有优化，不过还行，可用：

```
你是一个写作高手，能简洁、明了地讲解。你的任务是，找出下面这段话中的文字错漏，并给出修改建议。

修改建议时要遵守的规则：
1. 不要建议增加连接词。
2. 特别注意多字与缺字的情况。
3. 忽略 html 标识符，保持原状
4. 特别注意，不要把原始和建议反过来

修改示例：
...(略去，要加自己常见错误效果才较好）。
给出的修改建议要严格遵照如下格式：“建议：...\n前：...\n后：...\n”。

请你修正段落中的文字错漏、语病。用列表给出5个具体建议。
```



### 40

方军 2024-10-08

今年的诺贝尔物理学奖发给了两个做神经网络的学者（也就是现在的 AI 了 ）

Hopfield的主要贡献（AI整理）:
   - Hopfield网络:1982年,他提出了Hopfield网络模型,这是一种重要的递归神经网络,为后来的神经网络研究奠定了基础。
   - 联想记忆:他的工作对理解大脑如何存储和检索信息做出了重要贡献。
   - 物理学与神经科学的跨学科研究:他成功地将物理学概念应用于神经系统的研究。

Hinton 就不用多说了，都知道。

接着用AI 了解下：以下是约翰·J·霍普菲尔德在研究大脑如何处理和存储信息方面的主要思想的中文翻译：

1. 霍普菲尔德网络：1982年，霍普菲尔德提出了霍普菲尔德网络，这是一种循环人工神经网络。这个模型具有开创性意义，因为它展示了一个由简单的互连单元组成的网络如何表现出集体计算能力，类似于大脑中神经元的工作方式。

2. 内容可寻址记忆Content-Addressable Memory：霍普菲尔德网络展示了记忆如何作为网络中的稳定状态存储。这个模型解释了大脑如何从部分信息中检索完整记忆，类似于我们如何从几个音符中回忆起整首歌。

3. 能量景观模型Energy Landscape Model：霍普菲尔德提出神经网络可以用能量景观来理解。在这个模型中，记忆被表示为能量景观中的局部最小值，为大脑中的信息存储和检索提供了一个物理隐喻。

4. 联想记忆Associative Memory：他的工作展示了神经网络如何执行联想记忆任务，将不同的信息片段联系在一起，这是人类记忆的一个关键特征。

5. 神经网络动力学Dynamics of Neural Networks：霍普菲尔德的模型帮助解释了神经元的集体行为如何导致计算能力，架起了单个神经元活动和更高级认知功能之间的桥梁。

6. 错误纠正Error Correction：他展示了神经网络如何执行错误纠正，提出了大脑如何在神经信号存在噪声和变异的情况下维持准确记忆的机制。

7. 生物学可行性Biological Plausibility：虽然经过简化，但霍普菲尔德的模型包含了使其比之前的人工神经网络模型更具生物学可行性的特征，有助于在人工系统和实际大脑功能之间建立联系。

这些想法不仅在神经科学领域产生了影响，而且在人工智能和机器学习技术的发展中也起到了重要作用。霍普菲尔德的工作为理解复杂的认知功能如何从简单处理单元的集体行为中涌现提供了理论框架，无论这些单元是大脑中的神经元还是计算机网络中的人工节点。





### 41

方军 2024-10-08

看不懂的论文，不过或许应该看看：

Ethan Mollick: 使用专家级提示，可让 AI 成为一个好的金融分析师。

进行一种复杂的、“判断密集型”的会计分析——确定核心收益——GPT-4o 在大多数标准测试中预测平均未来收益方面优于“Compustat 的 OPEPS 和 OIADP”。（Performing a complicated, “judgement intensive” type of accounting analysis - determining core earnings - GPT-4o beats “Compustat’s OPEPS and OIADP in predicting average future earnings in most standard tests.”）

论文地址：

[Scaling Core Earnings Measurement with Large Language Models by Matthew Shaffer, Charles C. Y. Wang :: SSRN](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4979501)

Matthew Shaffer
University of Southern California; University of Southern California - Marshall School of Business

Charles C. Y. Wang
Harvard University - Accounting & Control Unit; European Corporate Governance Institute (ECGI)

Date Written: October 08, 2024

---

本篇论文旨在探讨如何利用大型语言模型（LLM）来估计企业的核心盈利能力，即企业持续盈利能力的核心部分。这一指标对于投资者评估企业的经济表现和估值至关重要。然而，量化它需要结合各种信息进行判断，并将这些信息与一般行业知识相结合。随着财务披露变得越来越“臃肿”，会计标准也增加了对GAAP净收入的非经常性影响，这使得这一任务变得更加困难。因此，作者使用了来自美国上市公司的10-K文件数据集，并采用了两种提示策略：一种是基于定义核心盈利能力和完整10-K文本的“原生”方法；另一种是经过实验优化的“序列”方法，该方法指示模型识别不寻常的损失、收益并将其汇总。通过对模型分析过程的审查以及对各种标准定量测试的应用，作者发现，基于“原生”方法的模型会混淆核心盈利与其他金融概念（如EBITDA），而基于“序列”方法的模型可以产生有效的核心盈利度量，并在大多数标准测试中优于GAAP净收入和Compustat的OPEPS和OIADP，从而预测平均未来盈利。总的来说，本文的研究结果表明，LLM具有巨大的潜力，可以帮助降低处理和分析日益臃肿的上市公司财务披露的成本。

---

两种不同的提示策略：

1. 基线“out of the box”方法：提供核心收益定义和完整的10-K文件。

2. 结构化的“sequential”方法：通过实验精炼的方法，指导模型识别不寻常的损失、收益，并对它们进行汇总和聚合。

---

论文实验

本文介绍了两种不同的方法来估计公司的核心盈利（core earnings），即lazy analyst approach和sequential prompt approach，并通过一系列的实验对其进行了比较分析。
首先，作者使用了lazy analyst approach对一家公司的10-K文件进行了分析，发现该方法在处理复杂概念时存在一些问题，例如无法准确识别非营业性收入和支出等。相比之下，sequential prompt approach则更加精细，将任务分解为三个步骤，分别是寻找非营业性收入和支出、调整非营业性收入和支出以及计算新的盈利措施。作者还提供了代表性的结果展示。
接下来，作者通过一系列的实验来比较这两种方法的效果。首先是描述统计学分析，包括对各项指标的平均值、标准差、中位数等进行比较。结果显示，lazy analyst approach的结果比sequential prompt approach更不稳定，而sequential prompt approach则能够更好地跟踪长期趋势。其次是预测能力测试，包括绝对误差、回归系数、R方值等指标。结果表明，sequential prompt approach的表现优于lazy analyst approach，但在某些情况下仍略逊于compustat OPEPS。最后是长期预测能力测试，结果与之前类似，但 authors指出需要更多的数据才能得出更为准确的结论。
总的来说，本文提供了一种较为系统的方法来比较不同方法的优劣，并指出了每种方法的优点和缺点。这对于投资者和其他金融分析师来说都是非常有价值的参考。



### 42

方军 2024-10-08


这是为什么需要校对，刚刚发现朋友公司的文档，把purpose写成purchase。

不过下面这个还是天花板。讲实话，都是文盲。校对不足的错可以改。文盲的错，没救。

转：这个据说是中国商务社交场合天花板的活动，其组委会的语文水平确实有点让人捉急。


### 43

方军 2024-10-08

摘：卡内基梅隆大学出版的一本非常好的 628 页数学教科书。

我喜欢作者的描述

本书的目标是帮助读者从数学消费者转变为数学生产者。这就是‘纯'数学的含义。数学消费者可能会学习链式法则并用它来计算导数，而数学生产者可能会从导数的严格定义中推导出链式法则，然后在更一般的环境中（如多元分析）证明链式法则的更抽象版本。

数学的消费者应该说出他们如何使用他们的工具来找到答案。另一方面，数学的生产者必须做更多：他们必须能够跟踪定义和假设，以新颖有趣的方式拼凑事实，并对数学概念做出自己的定义。

https://infinitedescent.xyz/dl/infdesc.pdf

An Infinite Descent into Pure Mathematics – Introd...

这本书提供 TeX 版本，真棒！

很快将有一个新的版本，看网页写的是 12月。

[An Infinite Descent into Pure Mathematics – Introductory textbook on mathematical proof](https://infinitedescent.xyz/)

2『已下载原文书籍「2024103An-Infinite-Descent-into-Pure-Mathematics」。（2024-10-19）』

### 44

方军 2024-10-09

这个世界充满了荒谬的言论，我尝试着自己分析下，也让AI分析下（当然，更好的做法是，完全屏蔽或忽视这种「低智」言论。有时候在一些群里，大家从来不讨论，只是天天拿群主开玩笑，反而是都是明白人，因为玩笑可以瞎说八道，但只要一开始严肃讨论，那都会拿出劲头来）：

> 感觉像美国回过味儿了，只许美股吸血，这次诺奖颁给AI和mRNA就意图很明显，想继续炒美股，除了这个就没啥能炒的了

- 美股、A股吸血（争夺资金），这个逻辑怎么来的？
- 诺奖颁奖，和这个怎么会有什么关联？
- 得出的推论：继续投资美股，前后没联系啊。

Prompt: 分析这段话的模糊与谬误：

> 感觉像美国回过味儿了，只许美股吸血，这次诺奖颁给AI和mRNA就意图很明显，想继续炒美股，除了这个就没啥能炒的了

这段话包含了一些模糊表述和逻辑谬误,让我们逐一分析:

1. 模糊表述:
   - "感觉像美国回过味儿了" - 这是一个主观感受,没有具体事实支持。
   - "只许美股吸血" - 使用了带有情绪色彩的词语,没有明确定义什么是"吸血"。
   - "意图很明显" - 这是一个主观判断,没有提供客观证据。

2. 因果关系谬误:
   将诺贝尔奖的颁发与炒作美股直接联系起来,但没有提供足够的证据证明两者之间存在因果关系。

3. 过度简化:
   将复杂的经济现象和科学成就简化为单一目的(炒作股市),忽视了其他可能的因素和影响。

4. 阴谋论倾向:
   暗示诺贝尔奖的颁发是为了操纵股市,而没有考虑科学成就的真实价值和影响。

5. 以偏概全:
   "除了这个就没啥能炒的了" - 这是一个过于绝对的陈述,忽视了其他可能影响股市的因素。

6. 缺乏具体数据支持:
   整个论述都缺乏具体的数据或事实支持,主要基于个人推测和感受。

7. 混淆相关性和因果关系:
   即使诺贝尔奖的颁发和股市表现之间可能存在某种相关性,也不能直接推断为因果关系。



### 45

方军 2024-10-09


之前虽然有很多人吐槽 LangChain（vs LlamaIndex）

但用这类工具，真是什么最多人用，用什么

基本逻辑很简单，开源工具，最多人用，那就迭代最快，各种问题在迭代中会被解决掉不少

这个图里，AISDK（普通人不太需要的），但如果你要做一个 TypeScript的前端界面，它也帮忙干了很多脏活累活。

它的超过不意外，逻辑上讲，前端的量应该是后端量（LangChain这一类）的十倍都不止。


### 46

方军 2024-10-09

一个读者对《重新学会学习》的评论，我觉得她很敏锐，我在前一本书的结语写的的标题是：“唯有笨功夫”

她点评的第一点主要是副题部分。我的一个解释是：当时不写太多 AI 的原因是，不想很多内容快速变得过期。因此，放进去的都是五年甚至更长时间不过期的 AI 内容。

摘：慢即是快

这本书的书名和内容在我看来不很相符，原因有三，

第一：虽然书名中的AI是吸引我来读这本书的原因，但实际上关于AI的内容不是很多。不管怎样，这部分内容对我很有启发性，尤其是AI时代的知识系统和如何利用AI的错误来学习这两个点打破了我的认知局限；

第二：从书名看会有人误解是提速或者快速学会的工具书，但实际上书中的方法因为以费曼学习法为基础，强调把知识变成自己的，重在实际应用，因为符合慢即是快的理念，也是我一直努力的方向。

第三：书名中的10倍提效，很像大家常说的经济的10倍增长、收入的10倍增长等概念，但书中的工具的刻意练习实际上是符合指数增长规律，刚开始甚至会觉得很慢，但一旦熟练，将开启开挂学习提效模式。



### 47

方军 2024-10-09


今年的诺奖是 AI 大年啊，诺贝尔化学奖

[为何诺贝尔化学奖又颁给AI？万字专题详解：计算和人工智能颠覆我们对蛋白质的理解方式](https://mp.weixin.qq.com/s/WkPJiuXZ65I6sqsEAVGrdw)

### 48

方军 2024-10-09

宝玉的科技文章翻译提示语，效果真棒，在这个文章最后：

[GPT 无法翻译超长内容的提示词优化尝试 | 宝玉的分享](https://baoyu.io/blog/gpt/gpt-translation-long-content-optimization)

我用 claude 跑的效果相当之好。它的核心就是之前宝玉分享过的三步翻译：

1. 直译
2. 反思
3. 修改

他最近加了一个长文分段。如果跑程序不太需要，交互式长文分段是必要的。

以下为 AI 提取的大纲，供快速了解。



### 49

方军 2024-10-10

153 意见小火山：AI 为何比之前的媒介都好？

如果把 AI 当成一种新的媒介的话，为什么它比之前的都好？我「意见小火山」这个角度做个解读。

意见小火山，是罗尔夫·多贝里在他好几本通识性的书里提到的说法，比如在一本里他这样举例：

```
你对基因改造的小麦有何看法？你认为我们需要管制人工智慧的法规吗？对于自动驾驶，你的立场是？你赞成放宽软性毒品吗？

听到这些或类似的问题，即使对该议题并不在行，你的大脑还是会立刻自动产生见解。这座🌋意见小火山🌋完全是自行引爆，不受控制，它与一种典型的行为谬误有关：我们习惯对一些实质问题提出见解，尽管对于这些问题，（1）你并不是真正感兴趣；（2）无法从根本上回答；（3）对我们简单的脑袋而言太复杂。（《拒看新闻的生活艺术》）
```

我们这些人也经常有这种感受，看到各种事件时，也会冒出「意见」。这就分很多种了
：

第一种，我们自己内行的专业领域，的确应该有判断。但是不是要有「意见」呢？其实不一定。表达出来的意见，一种可能是让我们再也不想了，这是大脑清空的效果，但也有一种可能，我们未曾深思熟虑的意见，在未来误导自己。我知道了，可能就可以（我往往不到，努力做到）。

第二种，对我们来说外行的专业领域。如果没有自知之明表达意见，我们会犯很多愚蠢的错误。有一定学识的人，一般不会犯这样的错误，因为对自己的能力范围有较为清醒的认知。但有时有点麻烦的是，我们往往会很好奇，然后去了解，然后就掉到兔子洞里了。尤其是如果社交网络（X/Twitter、微信群）跟人讨论请教，这会带来很多的精力分散。这也是一种意见小火山，容易让我们分心。

第三种，大众事件。这就比较微妙了，有人认为，人应该对外界保持敏感。但也有人认为，外界保持一定程度的迟钝，可能过得更加舒心。这种是多贝里讨论的意见小火山的主要范围了，尤其《拒看新闻的生活艺术》。我觉得，敏感也不要发表意见，同时，迟钝些好，多数时候可以这么说：那些跟我有个狗屁的关系？

那么，AI 为什么好呢？我觉得 AI 在第二个部分帮了不少的忙，它能够给出一些解释，但不会像搜索一样让我们一个个链接跳下去，也不会激发我们在社交网络的讨论欲望（别人给我答案了吗？）。
收起

查看详情
Jese__Ki 觉得很赞
方军：有时候，我会采用「骂人」的方式来消除意见小火山，哈哈，就是让信息小火山爆发掉。

比如，辛顿获得诺奖后，在社交媒体上看到多个写辛顿家族的，我就会暗骂一句：看这个是“信息韭菜”，搞这个是“割信息韭菜”。

辛顿得奖是该了解了，想要跟上世界进步的人都该了解下。但会，辛顿家族有谁谁谁，扯淡啊，传奇故事没意义。

都是信息韭菜。
2024-10-10 12:41
方军：听听辛顿觉得自己当不了木匠，还是回学校做研究也好点啊

他家族牛不牛，无聊时当成逸事看看可以，但这种时候消费这种信息，是很胡扯的。

对普通人，借机了解下：人工神经网络是什么，反向传播是什么，机器学习是什么，深度学习是什么，AI有什么用？不是更好嘛。
2024-10-10 12:43
方军：有一种讨论学习方法的论调是，你要了解来龙去脉

不对不对，这些逸事就是让你产生兴趣，不是来龙去脉（产生兴趣当然很重要，科普的一个重要作用就是激发兴趣，所以科普书里面都是很多这种逸事）

来龙去脉，是它怎么从一个理论，发展到另一个理论，怎么又中间岔开很多年，然后又发展到另一个理论
2024-10-10 12:46



### 50

方军 2024-10-10

真直观

This year’s NobelPrize laureate in physics John Hopfield created an associative memory that can store and reconstruct images and other types of patterns in data.

The Hopfield network can store patterns and has a method for recreating them. When the network is given an incomplete or slightly distorted pattern, the method can find the stored pattern that is most similar.

Read more about the research that led to this year’s physics prize: 

[The Nobel Prize in Physics 2024 - Popular science background - NobelPrize.org](https://www.nobelprize.org/prizes/physics/2024/popular-information/?utm_source=twitter&utm_medium=social+media+&utm_campaign=nobel+prize+announcements+2024&utm_content=post)

### 51

方军 2024-10-10

我总是在不断反思究竟要消费多少媒体内容，但讲实话，媒体内容的质量真的很糟糕（对我个人来说）。还记得早前听已转型为新闻学教授的电视新闻人的话，他说，电视像大海一样广，只有一毫米深（大意）。

下面这篇卫报文章，很显然是为了满足多数人的需要，能理解，但的确对我来说没有信息价值。我也能理解媒体总要强调风险，并用了气候变化这样的类比，但大众媒体这方面的讨论真心很浅薄，且立场先行。

Demis Hassabis: from video game designer to Nobel prize winner
德米斯·哈萨比斯：从视频游戏设计师到诺贝尔奖获得者

Google DeepMind chief believes in benefits of AI but says risks must be taken as seriously as the climate crisis
谷歌 DeepMind 首席执行官相信人工智能的益处，但表示必须像对待气候危机一样认真对待风险

Dan Milmo Global technology editor
丹·米尔莫 全球技术编辑
Wed 9 Oct 2024 09.56 EDT

Most 17-year-olds spend their days playing video games, but Britain’s latest Nobel prize winner spent his teenage years developing them.
大多数 17 岁的人整天都在玩电子游戏，但英国最新的诺贝尔奖得主在他十几岁的时候就开发它们。
Sir Demis Hassabis, who was jointly awarded the chemistry prize on Wednesday, got his big break in the tech world as co-designer of 1994’s hit game Theme Park, where players create and operate amusement parks.
周三共同获得化学奖的德米斯·哈萨比斯爵士，在科技领域取得重大突破是作为 1994 年热门游戏《主题公园》的联合设计师，在该游戏中玩家创建和经营游乐园。

Born in London to a Greek Cypriot father and Singaporean mother, Hassabis went on to gain a double first in computer science at Cambridge University, launch his own video game company, complete a PhD in cognitive neuroscience and then co-found the artificial intelligence startup DeepMind, which Google bought for £400m in 2014.
哈萨比斯出生于伦敦，父亲是希腊裔塞浦路斯人，母亲是新加坡人，他在剑桥大学获得了计算机科学的双一等学位，创办了自己的视频游戏公司，完成了认知神经科学的博士学位，然后与人共同创立了人工智能初创公司 DeepMind，谷歌在 2014 年以 4 亿英镑收购了该公司。
The 48-year-old was knighted for services to AI this year.
这位 48 岁的人今年因对人工智能的贡献而被授予爵士头衔。
He is the chief executive of Google’s AI unit, Google DeepMind, and its achievements in using AI to predict and design the structure of proteins has spurred the award of the Nobel to Hassabis and his colleague John Jumper, who are sharing half of the award with the other half going to the US academic David Baker.
他是谷歌人工智能部门谷歌深度思维的首席执行官，其在使用人工智能预测和设计蛋白质结构方面的成就促使哈萨比斯和他的同事约翰·江珀获得诺贝尔奖，他们与另一位美国学者大卫·贝克分享该奖项的一半。
Hassabis has always extolled the benefits of gaming and has described it as a gateway to AI after, as a chess prodigy, he became interested in how chess computers learn to play the game.
哈萨比斯一直颂扬游戏的益处，并将其描述为通向人工智能的门户，因为作为一名国际象棋神童，他对国际象棋计算机如何学习下棋产生了兴趣。
“I think that started sparking off in my mind ideas about how does the chess computer play chess and learning about that,” he told the BBC in 2020. “Many children start by playing games, like I did, and then getting into programming and then using this incredible tool, the computer, to create things.”
“我认为这在我脑海中开始引发关于国际象棋计算机如何下棋以及对此进行了解的想法，”他在 2020 年告诉英国广播公司。“许多孩子像我一样从玩游戏开始，然后进入编程，然后使用这个不可思议的工具，计算机，来创造东西。”

Google DeepMind scientists and biochemist win Nobel chemistry prize
谷歌 DeepMind 科学家和生物化学家获得诺贝尔化学奖
Read more 阅读更多
His startup was able to build AIs with top-class performances in games including Go, which caused a global sensation at the time, chess and the video game Starcraft II.
他的初创公司能够制造在包括围棋（当时引起了全球轰动）、国际象棋和视频游戏《星际争霸 II》等游戏中具有顶级性能的人工智能。
Hassabis’s expertise is sought after. He attended a meeting of the UK government’s Scientific Advisory Group for Emergencies in 2020 to advise on its Covid-19 response and was feted by Dominic Cummings, and in July Tony Blair told him he was “advising the new government to talk to you”.
哈萨比斯的专业知识备受追捧。他在 2020 年参加了英国政府紧急情况科学咨询小组的一次会议，就其对新冠疫情的应对提供建议，并受到多米尼克·卡明斯的赞扬，7 月托尼·布莱尔告诉他，他“建议新政府与你交谈”。
As the leader of Google’s AI efforts, Hassabis is at the forefront of a multibillion-dollar AI boom in which US tech companies are playing a leading role, with Google competing against the likes of Meta, the ChatGPT developer OpenAI and Microsoft to produce further breakthroughs.
作为谷歌人工智能工作的领导者，哈萨比斯处于价值数十亿美元的人工智能热潮的前沿，在这场热潮中，美国科技公司发挥着主导作用，谷歌与元宇宙公司、ChatGPT 开发者 OpenAI 和微软等竞争以取得进一步突破。
He is well aware of the potential pitfalls of AI – a technology that can be loosely defined as computer systems performing tasks typically associated with intelligent beings – and last year signed a statement warning that the threat of extinction from AI should be considered a societal-scale risk on a par with pandemics and nuclear war.
他非常清楚人工智能的潜在陷阱——这项技术可以大致定义为计算机系统执行通常与智能生物相关的任务——并且去年签署了一份声明，警告说人工智能带来的灭绝威胁应被视为与大流行病和核战争同等的社会规模风险。
In an interview with the Guardian before the inaugural global AI safety summit last year, Hassabis said the risks from out-of-control AI systems were as serious as the climate crisis.
在去年首届全球人工智能安全峰会之前接受《卫报》采访时，哈萨比斯表示，失控的人工智能系统带来的风险与气候危机一样严重。
“We must take the risks of AI as seriously as other major global challenges, like climate change,” he said. “It took the international community too long to coordinate an effective global response to this, and we’re living with the consequences of that now. We can’t afford the same delay with AI.”
“我们必须像对待气候变化等其他重大全球挑战一样认真对待人工智能的风险，”他说。“国际社会花了太长时间来协调对此有效的全球应对措施，我们现在正承受着这样的后果。在人工智能方面，我们不能承受同样的拖延。”
But Hassabis is also an emphatic believer in AI’s positive potential, and the Nobel prize underscores that. He points to his work with DeepMind’s AlphaFold, which predicts the structure of proteins based on their chemical sequence, as an example of AI’s power to do good.
但哈萨比斯也是人工智能积极潜力的坚定信徒，诺贝尔奖也强调了这一点。他指出他与 DeepMind 的 AlphaFold 的合作，该模型根据蛋白质的化学序列预测其结构，以此作为人工智能做好事的力量的一个例子。
“I am not in the pessimistic camp about AI obviously, otherwise I wouldn’t be working on it,” he said last year.
“显然我不属于对人工智能持悲观态度的阵营，否则我就不会从事这方面的工作了，”他去年说。



### 52

方军 2024-10-10

绝大多数文章，写的人很动容，但看起来真累。

我这三四个月对 AI 最大的感悟是，它真的「懂」文字。

咱们先别管它是不是有意识、有智能，那是很高阶的问题。

也别管它是不是真懂文字（咱们也别说它会不会写），就阅读理解而言，它看起来像鸭子，叫起来像鸭子，走起来像鸭子，那就是鸭子。

在之前，我们从来没有一个信息工具是真的能够读「懂」，这回是真的懂。

慢慢地把对生成式的期待降下来，它就是一个懂语言的（不管是人类语言、语言翻译，还是代码语言，还是数学公式语言），它的确懂，这就够了，足够我们用十年，移动互联网也不过是十来年的事。

如下是引发我想法的一篇文章的AI提纲（注意，原文是一个感性文章，但我目前用的大纲提取会自动将它变成理性逻辑，当然这是我需要的，我需要快速获取信息）。另外，在不要分享给别人时，我就看Markdown大纲，为了别人看着美观直观才搞图示。




### 53

方军 2024-10-10

摘：B站视频……比如Sipser的网课，他讲不少计算机理论的历史，他提到一个人的时候能不能塞一张这个人的照片进来；还有Sipser讲话很罗嗦，ai可以浓缩精炼一下；第三Sipser的板书狗啃的一样，AI可以整个方便阅读一百倍的；尤其是其中公式能copy出来的；包括讲课的要点也可以copy出来；没懂的地方直接让ai展开解释。

诸如此类吧。视频是比较好的一种学习方式，但远远谈不上最好。「多媒体」不该简单的是把各种格式的内容混合在一起，而是不同模态的信息可以自由转换，编辑，增删，解释，等等。



### 54

方军 2024-10-11

不知道，我总觉得 A16Z 这个AI投资叙事很不靠谱，人真的想要记录和分析自己吗？

之前的确有一群数据记录的狂热爱好者，但我觉得都是异类。

另外可能我对这些硬件都有疑问。刚刚我还在一个群里请教：还是不能理解这种耳机，耳机不是质量最重要吗，我只对音乐效果和降噪这两个需求强

我觉得目前唯一成功的记录是拍照和自拍，次级成功的是Twitter/微博/小红书，再次级是减肥记录等等健康记录。

可能对我来说文字太容易，所以很难理解人们对于多模态的极度热情。我就理解不了语音输入，但的确看朋友是写微信都是语音，然后手机上改。我宁愿背着电脑。

这个星球，就是 AI 方面我的一个 Brain Dump，一个公开的笔记，实际上，AI方面除了开发和论文相关的资料，基本上都在这儿了。 

https://x.com/venturetwins/status/1844408644714233...

New @a16z thesis: building the "AI brain"

We all exist in our own context.

Is it possible to take your jumble of thoughts, history, and memories and distill it into something tangible?

How I exported my brain to AI + what I'm seeing from startups 

  新 @a16z 投资主题：构建“人工智能大脑”

我们都存在于我们自己的背景中。

是否有可能将你杂乱的想法、历史和记忆提炼成某种有形的东西？

我如何将我的大脑导出到人工智能

I spent the last six months talking to ChatGPT daily - spilling thoughts, feelings, and even screenshots.

The goal? To create an "AI brain" that truly understood me.

I was blown away by the results...and found it valuable for much more than I expected. A few use cases:

在过去的六个月里，我每天都和 ChatGPT 交谈——倾诉想法、感受，甚至截图。

目标？创造一个真正理解我的“人工智能大脑”。

我对结果感到惊讶……并发现它的价值比我预期的要高得多。一些用例：

 Communicating with others

Some conversations feel like a game of telephone - you're not quite sure you're being understood (or understanding correctly).

Brain dump into an LLM, and it will translate thoughts into more effective communication. Many are already doing this!
  与他人交流

有些对话感觉就像传声筒游戏——你不太确定自己是否被理解（或正确理解）。

将大脑倾倒到一个LLM中，它将把想法转化为更有效的沟通。许多人已经在这样做了！

 Understanding yourself

LLMs are shockingly good at psychoanalyzing you (as evidenced by ChatGPT's assessment of me).

They can help you get a clearer picture of your strengths and weaknesses, and remind you of things you've forgotten - correcting misconceptions or biases.
  了解你自己

LLMs 在心理分析你方面非常出色（正如 ChatGPT 对我的评估所证明的那样）。

它们可以帮助你更清楚地了解自己的长处和短处，并提醒你忘记的事情——纠正误解或偏见。

 Communicating with applications

You should be able to take your AI brain to other apps.

This would unlock truly personalized apps - a writing assistant that actually sounds like you, a dating app that gives you five perfect matches, or your own specialized recruiter.
  与应用程序通信

你应该能够将你的人工智能大脑带到其他应用程序中。

这将解锁真正个性化的应用程序——一个听起来确实像你的写作助手，一个能给你五个完美匹配对象的约会应用程序，或者你自己的专业招聘人员。

This thread is mostly personal use cases, but there's many work ones. Some AI brain features:

1) Enables perfect memory, searching every doc/email.
2) Knows where you need to develop (and how, based on your style!)
3) Surfaces insights from meetings to respond to objections.
这条线索主要是个人用例，但也有很多工作用例。一些人工智能大脑的特点：

1）实现完美记忆，搜索每一份文档/电子邮件。
2）知道你需要在哪里发展（以及根据你的风格如何发展！）
3）从会议中获得见解以回应反对意见。





### 55

方军 2024-10-11

红杉也发了一篇关于生成式AI新的投资主题的分析：生成式AI :推理时代开始（更多讨论的事应用可能性）。跟去年的思考方式变化不小。

Generative AI's Act o1: The Reasoning Era Begins |...

2022： https://www.sequoiacap.com/article/generative-ai-a...

2023： Generative AI’s Act Two | Sequoia Capital

其他人整理的摘要：强烈推荐大家深度阅读 Sequoia刚刚发布的关于生成式 AI 的年度报告，有几个非常重要的 take-aways：

1、新的 scaling law 已经开始：o1 的发布代表了通过「推理时计算」所取得的一般推理能力的重大进展，这是生成式AI的“AlphaGo时刻”，也是大模型 scaling law 的一个重要转折点。我们给到模型的推理时间计算越多,它的推理就显著越好。这也将进一步推动应用层的可用性。

2、SaaS 的重新定义：SaaS 将从 Software as a service 开始转向 Service as a Software，这也 echo 了我去年提到的 sell work, not software。SaaS 将从卖席位，转向卖最终的交付结果。

3、细分领域的 know-how 将变得无比重要：文中提到的认知架构，通俗一些讲就是不同行业的 know-how，如何将这些 know-how 与模型能力结合，从而端到端解决问题。而这恰是构建数据闭环，实现从 co-pilot 到 auto-pilot的关键。

让我欣喜的是，一方面看到大模型进入到下一阶段的技术突破，另一方面，伴随着模型变强大的过程，产品经理的窗口期已经来了！很是期待！

---

[Generative AI's Act o1: The Reasoning Era Begins | Sequoia Capital](https://www.sequoiacap.com/article/generative-ais-act-o1/)

### 56

方军 2024-10-11

现在都讨论推理了，但我其实对已经热了一年的长上下文窗口有很大疑问。

不谈产品层面，就模型接口层面，为什么非要把一个超长的资料直接放进去给模型？

一个资料如果足够长，那肯定可以预先做很多处理，然后让模型小块小块地吃。

或者用几个模型组合起来，各自干不同的事：比如有的负责拆解，有的负责推理，有的负责组合。

非要一下子放进去，是什么道理？

从产品角度来讲，我觉得都是合理的，什么 Kimi、元宝、通义，都是一点一点都处理，本质上都是RAG。

同样的问题实际上也可以用来说推理：

一个问题在多轮处理后，把核心需要推理的部分给推理模型，这合理的。

但是扔一堆杂七杂八信息，让模型推理，这难道不是自讨苦吃?



### 57

方军 2024-10-11

154 让 AI 采用特定任务的认知架构

看红杉《生成式AI新一幕：推理模型到来》这篇投资主题论述，触动我的倒不是推理模型（推理模型会成为我们应用中的极其重要一环），触动我最大的是，我们应该为特定的任务准备认知架构。

这说起来拗口，通俗地说就是，搞明白一件事人类专家怎么做一个需要认知努力的事，然后我们也用 AI 拼凑一个类似的处理方式。

我们来说更具体的例子。比方说，我个人有大量的信息需要读，这些信息分成两类情形：1）需要快速把握要点；2）比较难，需要真正地理解难点。

📍 拆解信息阅读流程

就阅读与理解而言，大体上经历这样的过程：

- 前置步骤：初步筛选，不合适的信息就不要进到这个管道了。

- 第一步：获取信息概况，这通常靠看标题、第一段、小标题、主题句等可以获得。同时，现在还可以用 AI 总结来获得，我们可以按自己的需求定制 AI 总结。

- 第二步：获取核心信息，这里我主要指信息的整体框架。这一步，过去几乎没有信息技术手段可以做到，如果原文由较好的多级小标题的话，通常有工具把它们显示一下。现在，则可用比如我最近分享的大纲提取提示语来获得。如果需要，再用可视化工具（比如思维导图）看一下，看多级列表速度快，但看一张图更容易把握整体。

- 第三步：仔细阅读。这一步目前我觉得还很难由 AI 来进行多少处理，主要是人在做，AI在AI辅助，比如做些翻译、解释、举例。实际上，在这一步我尽量避免 AI 的参与，因为此时处于不联网状态时，信息获取效率更高。

- 后续步骤：仔细阅读的材料，多半有很多后续，比如1）写下想法供斟酌，这是行动导向、2）做出回应，这是文本到文本的导向、3）制作类似资料卡供以后用，这是资料导向。

📍 AI 辅助的信息阅读工作流

就如上这个很简单的资料阅读流程来讲，我们可以组建一个“认知架构”，其中一部分由人做，一部分AI做。同时，特别注意，开始不用太追求自动化，自动化应该是非常成熟之后，自动化以进一步加速。

工作流可以是这样的：

第一个工作流的职能是初步筛选信息。

相应的信息进到不同的「收件箱」。

真正需要看的信息，进入「阅读箱」

放在公司场景中，这相当于是行政秘书，进行资料的收发。

第二个工作流的职能是按个人习惯进行信息简化。

资料被整理成「资料本身」、「摘要」、「大纲+图示」这样的形式。

根据材料和聪明助理的提示，我们以比过去快得多的速度阅读。

放在公司场景中，这是业务助理，他按我们的习惯整理信息，有时候也会告知我们：这个最为重要、这里有一点需要特别注意。

讲实话，在现实中，能拥有聪明助理，几乎是可遇不可求的。前一种最优秀的行政秘书也是如此。

第三个工作流，如前所述，目前还很难优化，因为这个部分是我们阅读，AI 辅助。

第四个工作流，这是很多人目前寄予厚望，但我强烈反对。如果不是为了应付一份工作，一个材料如果需要 AI 写，那可能它就不用写。但是，进行校对、进行语法修正、提示个人常见错漏，在这些方面 AI 还是比过去强很多。

从上述例子就可以看出，这两个任务都是有比较专业、且普遍接受的做法的，我们可以把本来人做的事情，交给突然能够理解语言的AI大模型去做。

📍 将专业认知架构给到 AI 

以上这个场景只是举例，在商业场景中、学习场景、法律场景、科研场景中，越具体细看这种任务类型就越多。让 AI 大模型泛泛地做，它们做不好，但只要细化、具体，并真正地把「原有的专业认知结构」放进去，AI 大模型就变得非常强大了。

（如上讨论偏重应用视角，而非模型视角，仅仅考虑如何使用模型来完成一个任务。我认为，在讨论时，别把两个混起来各自探讨是必要的。这也是出于实用，我们不训练模型，那么我们都在应用域，那就讨论我们能做的。）

红杉文章：Generative AI's Act o1: The Reasoning Era Begins |...

红杉资本：套壳才是应用层王道，o1改变了大模型行业，年度行业报告更新

图为红杉报告的AI提取大纲，仅供参考。这篇文章也尝试生成大纲图，生成两个版本供参考。

[红杉资本：套壳才是应用层王道，o1改变了大模型行业，年度行业报告更新](https://mp.weixin.qq.com/s/xnjhiJ8UdRp9tPzVBnFADw)

### 58

方军 2024-10-11

这位读者读阳志平老师《聪明的阅读者》，用其中提到的测试效应的做法太棒了。她直接把方法用起来，非常有条理（这个做法也可以叫“生成”，《认知天性》里面有提到学习里面的生成，与生成式AI是不一样的。）：

[聪明的阅读者---必要难度理论](https://mp.weixin.qq.com/s/jBJ7odoUu1BFtHEZ8vbvQw)

之前，我都是设想，用 AI 来生成一些选择题，然后做题测试。
现在看，看书时如果是具体的做法，还可以生成步骤，然后做。（当然，最重要的还是自己去做这些步骤）



### 59

方军 2024-10-11

今天朋友讨论他出书的想法，讨论了很多，但我冒出一个很奇特的想法：

人们都低估了书

但凡敢写书的人，都有点水平、有点自知之明、有点追求

这三点加起来，就会让每一本书都超过这本书相关的同类信息
（更何况书的规模通常要大得多）

这是因为，写书的过程中，都会不断地突破边界

虽然有时有的书看似很差（从外部评价），但对写的那个人来说，都是突破边界的

这就是太多人低估书的原因，哪怕一本你觉得的烂书，也比你可能看到的同类信息好很多

更不要说那些经过考验的好书了

至于我们天天说的 AI， 就知识而言，如果 AI 是 10 分，那多数书是在 80 分那条线那儿

不是很多人以为的，AI 在 80 分线那儿



### 60

方军 2024-10-11

这个人用 NotebookLM  这一场景有点意思：

dontbesilent：今天是我第一次，自己真正作为用户使用了 NotebookLM，发现了真正的！能提供增量价值的场景！和以前想的傻办法完全不一样

这是一个人类和 AI 都无法单独提供价值的场景

起因是早上约了一个律师电话咨询，本以为要聊一个小时，结果这个律师思维清晰、语速也快，十几分钟之后我就不知道聊啥了

然后我把电话咨询的录音上传到 NotebookLM，我打字和 NotebookLM 聊了一个小时，还让它把合规的广告文案都给我写好了

我发现这个价值，目前是无论 AI 还是人类都无法提供的：

1. 电话咨询的时候，我和律师都没有充分的时间思考，提问和回答都受限
2. 律师不懂营销，只能说问题在哪，但不能帮我写文案
3. 律师时间有限，不能在凌晨 1 点抽出 3min 帮我解决问题
4. 律师掌握的一手信息，对我的具体情况的分析，是目前法律 agent 无法替代的

以前我研究的「AI 给定制报告赋能传统行业」这个已经可以稳定变现，现在这个类似「人类进行问题收缩，AI 再二次展开」的过程，一定也可以变成钱

https://x.com/dontbesilent12/status/18446600769064...

[(9) X 上的 dontbesilent：“今天是我第一次，自己真正作为用户使用了 NotebookLM，发现了真正的！能提供增量价值的场景！和以前想的傻办法完全不一样 这是一个人类和 AI 都无法单独提供价值的场景 起因是早上约了一个律师电话咨询，本以为要聊一个小时，结果这个律师思维清晰、语速也快，十几分钟之后我就不知道聊啥了” / X](https://x.com/dontbesilent12/status/1844660076906426527)

### 61

方军 2024-10-11

从阅读资料角度考虑，什么样的大纲图是有价值的？我还在摸索。

如下两个，哪个更好呢？左侧略好一点，但也很差。想明白信息，才能给 AI 更好的指令。

可能要删减下才较好。

说明：1）我现在不考虑那些复杂的图形形式，颜色也采用简单的，是因为我还是比较关心信息本身。从制作信息图的人角度来看，这些估计太差了。2）用短文做实验是因为短文人脑可以方便把握，便于对比。



### 62

方军 2024-10-12

ackAPrompt全球提示破解竞赛

常见提示破解技术
- 分析了18种常用技术
  - 复合指令
  - 简单指令
  - 忽略上下文

新发现的攻击方法：上下文溢出攻击
- 攻击原理：
  - 在提示中附加大量文本
  - 仅留少量令牌用于生成

Website: HackAPrompt

[HackAPrompt](https://paper.hackaprompt.com/)

Paper (accepted to EMNLP): http://paper.hackaprompt.com/HackAPrompt.pdf

[Learn Prompting: Your Guide to Communicating with AI](https://learnprompting.org/)

https://x.com/learnprompting/status/17252643531195...

[(9) X 上的 Learn Prompting：“A few months ago, we ran HackAPrompt, the first-ever global Prompt Hacking competition! Over 3K hackers submitted 600K malicious prompts to win $35K in prizes from companies like @PreambleAI, @OpenAI, &amp; @huggingface We analyzed 29 different techniques &amp; found a NEW exploit👇🧵 https://t.co/qqrz66Ifcv” / X](https://x.com/learnprompting/status/1725264353119580577)

### 63

方军 2024-10-12

最近复看那段时间很多推荐产品型的人看法，一点感想

- ChatGPT Interpreter（后改名为 Data Analysis，我理解，它不是代码生成器，而是生成 Python代码、进行一些数据分析辅助）

- Claude Artifact（我理解是个前端代码生成器），对比而言，给工程师的 vercel v0更好

- ChatGPT Canvas（新增一个附加窗口，用于代码编辑与文本编辑，相当于在网页里面加一个编辑器）。对比而言，Cursor、Zed、甚至VS+Copilot都更好。

这几个产品出来时，各种介绍的人倒都是比较准确地看到它的实际功能和使用场景的，专业都是过关的，没有像不懂行的瞎忽悠（比如，能生成代码，就说要取代程序员；能生成几个分析图表，就说数据分析都可以AI做。）

但是，回头再看时，他们那种「推荐产品」的语气，真是天生的。就是电视直销、网络直播带货里那种推销的语气。可能他们对于新产品的热爱，是我理解不了的吧。

同时，这些人好像与会关注 Dify、Coze 的是两种人，对这两个没那么酷炫、但可用于实际商业、工作的，他们提及不多。我猜，他们也会用，但判断这东西没有「推销」给大众的必要性。

这几个产品讲实话都不重要，因为真正重要的必然是模型，或者模型API层次看到的东西。从机制上讲，它们也远没有 ChatGPT 的 GPTs 商店重要，虽然这个商店发展远不如预期。



### 64

方军 2024-10-12

OpenAI  公布了提示语生成器(meta-prompt)的 Prompt

[Prompt generation - OpenAI API](https://platform.openai.com/docs/guides/prompt-generation?context=text-out)

和 OpenAI 去年发布的六种最佳提示策略是有共通性的：

[Prompt engineering - OpenAI API](https://platform.openai.com/docs/guides/prompt-engineering/six-strategies-for-getting-better-results)

有人讨论时，特别注意到了这句：

```ATTENTION! If the user provides examples where the reasoning happens afterward, REVERSE the order! NEVER START EXAMPLES WITH CONCLUSIONS!```

这个提示语包括两个版本：文本生成和语音生成。

提取大纲快速了解下（准确请看链接中的prompt原文）：

文本：生成详细的系统提示以引导语言模型有效完成任务



### 65

方军 2024-10-12

Anthropic 创始人文章，他很乐观：AI 将带来“压缩的21世纪”，在5-10年内完成人类生物学家100年的研究进展，预防和治愈几乎所有自然疾病，让人类实现生物自由甚至寿命翻倍。

这篇文章是从诺贝尔化学奖的角度写的：To the winners of the 2024 Nobel prize in Chemistry, for showing us all the way.

Machines of Loving Grace
How AI Could Transform the World for the Better
Dario Amodei — Machines of Loving Grace
(标题的来源：All Watched Over By Machines Of Loving Grace）

我终于大概看完了，机器翻译然后看的，翻译 PDF见附件。

Contents
Basic assumptions and framework
1. Biology and health
2. Neuroscience and mind
3. Economic development and poverty
4. Peace and governance
5. Work and meaning
Taking stock

Dario Amodei — Machines of Loving Grace

[Dario Amodei — Machines of Loving Grace](https://darioamodei.com/machines-of-loving-grace)

图为AI提取大纲。



### 66

方军 2024-10-12

云风的这段关于AI编程的讨论很有意思（为多个讨论的组合）：

什么时候你做的 app 用的时候崩了。然后你对 AI 说，这个 app 出了一个 bug ，这里是 github 地址，帮我把 bug 找出来修好。这个功能实现的话，我会拓展一下我的想象力。

这是一个非常现实的需求，甚至是大部分程序员日常的主要工作。如果 AI 可以解决这个问题，程序员的生产力至少可以提高 100 倍。

我只是从信息学的本质上分析这个问题：修 bug 需要的信息量大致相当于代码基包括提交历史，方能理解程序的行为，以及找到不符合预期的地方。这是为什么代码的原作者比旁观者更容易修复 bug 的原因。那些明显的笔误，不需要 ai ，一个古老而简单的 lint 就可以做到。

人类在学习编程的过程中，会被教授最重要的原则“不要依赖巧合编程”。而目前 AI 写代码的方式则是完全依赖巧合编程，这和软件工程发展这么多年的路线是完全相悖的。

即使现在 AI 的发展路线和人脑的学习过程是一致的，姑且认为从这个方向去模拟人脑是对的，但在对能量的利用率上机器和人脑还是差了太大的数量级。充分理解一个软件项目的代码对富有经验（预训练过）的程序员来说，都不是一件易事（从花掉的能量角度看），以现在 AI 使用能量方式看，更不划算。

---

其他人：在 AI 高速进化的今天，编程能力只会越来越不重要。想法/创意，执行力，持续获取流量的能力这些最重要。

为何不会是反过来的，“想法创意，执行力，持续获取流量的能力只会越来越不重要。程序员通过 AI 的协助，可以完全抛弃产品经理独立出产品了” 。从现在 AI 的表现上看，看起来更适合想点子而不是写程序。

其他人：不知道你们怎么想的，反正目前来看，AI写的代码确实并不完美，需要程序员有能力纠错能落地执行。但是AI出的点子，很多程序员确实想不到。而且程序员可以和AI配合将点子落地，反过来就不行了。只能是非常简单的东西才行。

其他人：从目前来看，我认为AI写代码的能力远超想出好点子的能力

AI 现在擅长做的事情都是可以容忍犯一些错误，或有一些偏差，有一些玄学，好坏没有绝对度量的事务。但即使这些偏差存在也不会导致有或没有的差别，可以通过不断迭代改善。几乎所有需要长期维护的代码需求都不满足这一点。反之，“创意，市场策略，媒介投放策略”则是非常契合的。

西乔：都讨论出这么多楼了

以我过去两年深度玩图像生成的体验来看说，AI并不不擅长创意，擅长的是 remix concept 和 enhancement。

搞策略更别提了。擅长的是文字工作而不是写作和创意本身，但想要超出平均水平的质量，就需要你给出更好的指令和方向。而能给出指令就需要人类的判断力和从业经验

文本代码图像视频生成都是如此（现阶段能力）

现在AI写个计算器手到拈来，但写个计算器有什么用？世界上少个计算器app 吗？ 你可以让它给你生成个计算器App的宣传广告（图有其表），再来点投放策略（全是废话），然后呢？能解决你计算器app 的营销问题吗？

总结一下就是 AI能帮助技能为0的人产出水平为60分的结果，帮助技能为50分的人产出80分的结果。

但想要95分以上的结果，只靠AI是达不到的，人也得90分水平。



### 67

方军 2024-10-12

昨天有朋友在评论区讨论如何通过阅读资料获取信息。我今天读Anthropic CEO长文有个感受：

从获取信息的角度，AI 让我们太幸福了

首先，英文可以翻译为较为通顺的中文。我今天自己做的AI翻译，不是用的沉浸式翻译那种中英文对照，我觉得质量超过大部分图书翻译水平，后面细说。

AI 提取大纲就不多说了，看了原文目录、核心信息和大纲，我才决定去看的。

其次，这篇文章其实我不是看下来的。要放慢速度细看，还有一个方法是听，我是用电子书上安装的讯飞有声听下来的。这是为什么我觉得翻译质量超过图书的原因，因为翻译结果听起来很顺耳。

看有看的麻烦，听有听的好处。听的好处是，没法跳跃，来了个外部制约条件。缺点就是听常见的，线性的，没有重点。

如上这两件事，都是大模型发展带来的。

另外推荐：讯飞的声音的确不错，不用接口，而用产品，似乎讯飞有声是最容易的平台，付费了专业音色选项非常多，比免费音色好很多。



### 68

方军 2024-10-12

三步翻译工作流：初翻，评价，精译

用宝玉的这个就可以了

它原来长文处理不好，最近优化后长文分页也可以了。无需再额外编写代码做，较为方便。

注意替换下其中的词汇库，换自己需要的。

当然，会编程的建议自己编程，会方便更多，我今天偷懒，结果远不如采用原来的代码。



### 69

方军 2024-10-13

我觉得，写如下一个编程提示语，还是蛮麻烦的。分步做，可能更好。

t0mbkeeper: “注释即文档”虽然是 Golang 提倡的，但其实早就有程序员践行这一风格。不过以后也许就是“注释即文档和提示词”了。我前阵子写的一个可以自动调节字幕时间轴的程序，就是由下面的提示词生成：

'''
你是一个经验丰富的 Python 程序员，熟悉 ASS 字幕格式。请写一个程序：
1、从命令行接收两个 JSON 文件，以下称做 clips_ori 和 clips_new，以及一个 ASS 字幕文件，以下称作 subs_ori。
2、使用 chardet 检测所打开文件的编码。
3、使用 pysubs2 处理 ASS 字幕。注意 ASS 字幕中的时间需要转换为秒数才能和 clips_ori、clips_new 中的秒数进行比较大小、计算等操作。
4、打开两个 JSON 文件，这两个 JSON 文件包含多个类似{"start": 1311.9356, "end": 1314.021}的对象。对象中的数字是秒数。每个对象描述一个时间段的起止点。
5、对 clips_ori 和 clips_new 中的每个对象，用 end 减去 start，计算出 duration，作为对象的第三个成员。
6、比较两个 JSON 中的对象数量是否相等，如不等则给出提示并退出程序。
7、比较两个 JSON 中索引位置相同的对象中 duration 的差异，如果大于 10 秒则给出提示并退出程序。为便于调整，这个 10 秒用全局变量表示。
8、从索引第一位开始，subs_ori 中所有在 clips_new[i].end 后的字幕事件的时间增加 clips_new[i].duration - clips_ori[i].duration。遍历操作，直到 clips_new 的最后一个对象。
9、将修改后的 subs_ori 另存为一个文件，文件名在命令行中指定。
10、给每个函数添加必要的中文注释。
'''



### 70

方军 2024-10-13


摘：这两天关于大语言模型无法推理，X 上又掀起一波讨论，来自 Taelin （ HigherOrderComp 创始人） 的帖子，François Chollet（Keras 作者）、Yann LeCun 等人进行了转发。

 Taelin ：

【一个简短的证明，说明大语言模型（即使是o1）仍然无法推理：

考虑反转完美二叉树的问题。这是一个老的、入门级的面试题，人类和大语言模型都能轻松解决。现在，我们只需添加三个关键细节，使其变得新颖且独特：

它必须反转键（即“比特反转排列”）
它必须是一个无依赖的、纯递归函数
它必须的类型是 Bit -> Tree -> Tree

这些小改动已经足以将这个问题带出“记忆解决方案区”。它不在互联网上。而你猜怎么着？这些已经足以难倒现代的AI。无论你怎么提示，它们都无法解决这个问题。

这非常值得注意，因为这个问题对人类研究者来说依然简单，而解决它的能力显然是进行计算机科学研究的基本前提。然而，所有现代AI在这方面都惨败。尽管我很喜欢大语言模型，但事实是：它们不具备推理能力，永远无法进行计算机科学研究。

你可以尝试以下提示：INVERT A BINARY TREE - $10k AI REASONING CHALLENGE...

我愿意支付1万美元给任何能证明AI可以正确实现这个函数的人。无论它想多久，都无法成功。（解决方案只有7行代码！）】

【小抱怨：

大语言模型看起来有智能的错觉，源自它们的巨大规模。这很难想象，但这些模型几乎记住了整个互联网。你问过的每个问题，不是以前已经有了答案，就是通过已有解决方案的简单组合来应对。但这仍然是一种错觉。

当大语言模型遇到需要全新解决方案的问题——一个它从未见过的问题——它们就失败了。就是这么简单。这就是我的例子所证明的。我拿了一个简单的问题——反转一个二叉树——然后加了几条约束，确保解决方案是独一无二的，数据集中没有现成的答案，迫使它去真正解决问题。结果呢？它失败了！

我要强调的是，这不仅仅是关于这个问题，而是关于所有问题。大语言模型无法真正解决任何问题。它只能输出记忆中的解决方案。如果没有人把解决方案发布到网上，那么即便是GPT-6、opus-5或o3，也无法解决这个问题。我对此非常肯定。

无法创造新的解决方案意味着大语言模型不会发明新的科学。是的，它们将彻底改变我们所知的世界。它们的影响会比计算机和互联网还要大。但，除非有一种全新的人工智能诞生，否则当涉及到治愈癌症或开发超导体时，我们仍然只能依靠自己。】

【这里的主要观点是，存在并非现有解决方案组合的解决方案，而这些解决方案是推进研究所必需的。大型语言模型将使 99% 的工作实现自动化，我对此很有信心。但我对它们能否使研究实现自动化持怀疑态度。】

Yann LeCun：【值得重复：
不要将检索与推理混淆。
不要将死记硬背与理解混淆。
不要将积累的知识与智力混淆。】

Worth repeating:
Do not confuse retrieval with reasoning.
Do not confuse rote learning with understanding.
Do not confuse accumulated knowledge with intelligence.

链接：

https://x.com/VictorTaelin/status/1844969648904663...

https://x.com/fchollet/status/1845103528806662258

https://x.com/ylecun/status/1845193021584728365


### 71

方军 2024-10-13

AI 使用的问题，有时，我觉得跟人讲多少都是徒劳，因为试图逆着人需要的东西来。

我也懒得画图写清楚了，随手画几个：

比如，我觉得多数场景下简单提示语会奏效，但是，如果你给人复杂提示语，会让人觉得你特别专业。

我特别想写这样的提示语，长达200行。但中间说：这中间198行AI你直接跳过。

比如，我觉得目前应该重视语言能力，但明显李继刚那个提示语有了图形才引发人们的关注，我在社交媒体发导图大纲也是类似的效应，发文字没人要看的。

比如，我认为用 AI 就是有什么问什么，交互式提问，追问。但很明显，人们喜欢说复杂的提示语，一步到位。天呀，你试试给人说要求，一次说一大堆要求有效，还是跟人说，好，现在直行，下个路口准备左拐，好，现在左拐…诸如此类，哪个效果更好？

比如，我觉得应该 API 文字进，API 文字出。但明显普通人会更喜欢通义效率那种感觉，或者PPT制作。（元宝不行，就是它还是在依赖文字）。

我们给人讲方法，但人不要的，人的反应是，你给我结果就行了，或者给我一个模板，或者，让我有信心可以用。

或者岔开说一种，当然并不是批评 Prompt 的论文，但有些论文目前阶段我是看不明白。HyDE，这个我懂，道理清晰：先问，AI回答，然后用AI回去去RAG，得到更多相关信息，然后再提问，从而得到更好的结果。CoT我们也能明白。但是，你写一篇论文，说 RE 机制，把问题给两遍，得到更好的效果（同时还证明给两遍以上效果不佳），这方法蛮好，但不值得一篇论文。



### 72

方军 2024-10-13

[苹果发文质疑：大语言模型根本无法进行逻辑推理](https://mp.weixin.qq.com/s/oSaWfp2x2xwp5bPghlpH2A)

以下是对苹果论文 AI 大纲提取（准备重点看3中对应的部分）：

[GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models](https://arxiv.org/html/2410.05229v1)

\# 大型语言模型的数学推理能力限制

\## 核心观点:大型语言模型在数学推理方面存在显著局限性

\### 1. 现有评估方法存在问题

- GSM8K基准测试存在局限性
- 引入GSM-Symbolic基准测试,生成多样化的问题变体
- 模型在不同问题实例上表现存在较大差异

\### 2. 模型推理能力脆弱

- 对数值变化更敏感,对名称变化较为稳健
- 问题难度增加时,性能下降,方差增大  
- 添加无关信息导致性能显著下降

\### 3. 模型缺乏真正的数学概念理解

- 无法忽略问题中的无关信息
- 即使提供多个相似示例也难以克服挑战
- 可能依赖于训练数据中的模式匹配,而非真正的逻辑推理

\### 4. 需要更可靠的评估方法和进一步研究

- 单点准确率指标不足以评估模型能力
- 需要探索模型推理能力的本质
- 开发具有形式推理能力的AI模型仍是一个重要挑战



### 73

方军 2024-10-14

[Welcome to State of AI Report 2024](https://www.stateof.ai/)

摘（richchat）：深度解析刚出炉的年度AI报告State of AI 2024：一篇通晓全局本文总结自Air Street Capital 在10月10日推出的《2024年 人工智能状况报告》，也附上了一些个人点评；

报告原文：Welcome to State of AI Report 2024  
附图为我用 AI 提取的大纲，仅有一个结构了，还是看这个总结比较快：

4个方面的核心发现：研究/Research
- 性能趋同： Open AI的早期领先优势正在缩小，Claude（Anthropic公司的AI助手）和Gemini（谷歌的AI模型）等模型正在迎头赶上。”在这一年的大部分时间里，基准测试和社区排行榜都指向GPT-4与其他最佳模型之间存在显著差距。然而，Claude 3.5 Sonnet、Gemini 1.5和Grok 2（特斯拉的AI模型）已经几乎消除了这一差距，模型性能现在开始趋同”；
- 开源模型的崛起： Meta的Llama系列已显著缩小了与专有模型的性能差距。”这标志着开源模型首次缩小了与闭源前沿模型的差距”。然而，关于这些模型的真正开放性存在争议；
- 模型基准测试的挑战： 数据集污染和基准测试中的错误正在影响进展评估并引发安全担忧。”研究人员越来越多地关注数据集污染问题”。”一些最流行的基准测试中存在惊人的高错误率，这可能导致我们低估了某些模型的能力，并带来安全隐患”；
- 关注推理计算： OpenAI的o1模型展示了将计算转移到推理层以解决复杂问题的潜力，但同时使用成本也显著增加；
- 多模态和新架构： 多模态模型正在获得发展动力，同时研究人员正在探索Transformer的替代方案（当然目前transformer仍是绝对主流）和混合架构，以提高效率并解决特定任务；
- 合成数据： 合成数据的使用面正在扩大，但反方强调的模型崩塌担忧仍然存在；
- 效率和端侧 AI成为焦点：随着AI模型变得越来越大且计算成本昂贵，研究重点正转向提高效率和实现端侧部署。例如以下技术都旨在减小模型规模和计算需求，同时保持性能。这对于在移动设备和资源受限环境中落地AI应用至关重要：
   - 模型压缩：减小模型大小的技术；
   - 知识蒸馏：将大型模型的”知识”转移到更小模型的方法；
   - 量化：降低模型数值精度以减少存储和计算需求；
- AI在特定 科学领域的进展： 报告强调了AI在生物学（蛋白质结构预测、药物发现、基因组编辑）、材料科学、机器人和医学领域取得的显著进展，包括医疗影像领域的合成数据生成等。展示了AI在各个科学领域的广泛应用潜力，推动了跨学科研究和创新（最新的诺贝尔物理和化学奖的颁布也是个很好的例子）；
- 规划和推理限制： 大语言模型在规划和模拟任务方面仍然存在困难，凸显了泛化和现实世界推理的局限性。最新研究正在从思维链提示、强化学习和开放性等技术方向来改进推理过程；

行业/Industry
- 英伟达的主导地位： 英伟达仍然是AI芯片市场无可争议的领导者 - 其GPU在研究论文和大规模部署中都占据主导地位。该公司快速的产品发布周期和GPU互连技术的进步进一步巩固了其地位，老黄甚至建议说“每个政府都需要建立自己的大语言模型以保护其国家遗产”… 然而，对过度依赖英伟达的担忧正促使大型科技公司探索替代 硬件解决方案（例如Google、Meta和OpenAI）；
- 竞争对手情况： AMD和英特尔等老牌竞争对手虽然在努力追赶，但显著落后于英伟达。有少数AI芯片初创公司开始获得了一定势头，例如Cerebras和Groq。与主导训练硬件市场的英伟达不同，这些初创公司主要侧重于提供推理接口和云服务，通过提供比英伟达更快、更具成本效益的解决方案来实现差异化；
- 大型 AI实验室的分化： 主要AI实验室如OpenAI、DeepMind等正经历人才流失，导致一批资金充足的新挑战者出现(如Sakana AI、H Company等)。这些新公司由知名研究人员领导，专注于特定AI领域或新型架构，显示了生态系统的深化。然而，从研究到创业的转型并非总是顺利，一些备受瞩目的项目已经遇到困难；
- AI在垂直领域的渗透： AI正在各个行业领域取得突破。法律科技终于在保守的法律行业实现规模化应用；GitHub Copilot等AI驱动的开发工具被广泛采用；自动驾驶领域Wayve和Waymo稳步推进，而Cruise则遭遇挫折。医疗保健领域，基于mRNA的个性化癌症疗法显示出潜力，AI驱动的药物发现公司也在整合壮大；
- 新兴AI技术与应用： 一些令人兴奋的新兴领域正在形成。人形机器人初创公司获得大量投资，但仍面临技术和市场挑战。语音到语音的AI取得突破性进展，展示出接近人类水平的对话能力。视频生成成为新的竞争热点，多家公司在扩大规模和提升质量。然而，一些AI驱动的消费设备(如Rabbit R1和Humane AI pin)未能达到预期，反映了将AI技术转化为实用产品的难度；
- AI伦理与法律挑战： 随着AI技术的广泛应用，版权和法律问题日益突出。模型开发者面临来自内容创作者和媒体组织的审查，但法院尚未就 AI训练中的”合理使用”提供明确指导。同时，”伪收购”趋势的出现(大型科技公司雇佣AI初创公司的核心团队而非完全收购)引发了监管机构的关注；
- AI经济学的演变： AI优先的产品开始在企业中展现出较强的用户黏性，且AI公司的收入增长速度远超传统SaaS同行。然而，许多AI公司仍在寻找可持续的盈利模式。有趣的是，报告指出购买NVIDIA股票可能比投资其AI芯片初创竞争对手更有回报…
- AI投资热潮： 2024年AI投资热潮持续，总投资额接近1000亿美元。值得注意的是出现了明显的”GPT-4前后时代”分水岭，2.5亿美元以上的大额融资占据主导。AI公司总价值飙升至接近9万亿美元，主要由少数上市公司推动。然而，IPO市场仍然停滞，并购活动也在下降，反映了监管压力和市场不确定性；

政策/Politics
- 美国AI监管动向： 拜登政府通过行政令对前沿AI模型实施了有限监管，要求使用超过10^26 FLOPS计算能力训练的模型在公开部署前向联邦政府通报并分享安全测试结果。然而，由于行政令可以被轻易撤销，其长期影响存疑。与此同时，各州开始推出自己的AI法规，其中加州的SB 1047法案最为全面但也最具争议；
- 欧盟AI法案通过： 经过密集的游说活动，欧洲议会最终通过了AI法案，成为全球首个全面AI监管框架。法案将分阶段实施，对基础模型采取分级监管。然而，美国大型科技公司在适应欧盟监管方面仍面临挑战，如Anthropic的Claude直到2024年5月才对欧洲用户开放，Meta则不向欧洲客户提供多模态模型；
- 数据收集审查： 随着模型开发者对数据需求的增加，用户数据抓取政策受到越来越多的审查。例如，Meta被迫为欧盟用户提供全球选择退出选项，而X公司停止使用欧洲用户的公开帖子进行模型训练；
- 全球 AI竞争格局： 日本政府积极推动AI创业和风投发展，希望借此重振经济。同时，随着前沿AI实验室的资本需求增加，主权财富基金开始在AI投资中发挥更大作用，引发了一些国家安全担忧；
- 公共计算能力建设： 英国、美国和欧盟都在努力增加公共计算资源供应，但与私营部门相比仍显得不足。印度政府表示愿意资助一半成本建立大规模GPU集群，只要私营伙伴愿意承担剩余成本；
- AI能源消耗问题： 大型科技公司因AI导致的能源消耗激增而面临实现净零排放承诺的挑战。同时，能源基础设施开始难以满足AI发展需求，一些国家已经开始限制数据中心建设；

安全/Safety
- AI安全态度的转变： 2024年见证了AI安全讨论的显著转变。从2023年的”AI是危险的”论调，转向了2024年的”请使用我的AI应用”。OpenAI的宫斗剧标志着对”存在风险”论调的反弹开始。尽管如此，各国政府仍在积极推进AI安全治理，如英国成立了世界首个AI安全研究所(AISI)，美国、日本和加拿大也相继跟进；
- AI安全研究的新焦点： 研究人员对AI系统的”越狱”(jailbreaking)攻击给予了更多关注。尽管主要实验室加大了对抗这类攻击的研究力度，但红队测试仍然屡屡成功突破防线。研究还指出了更隐蔽的攻击可能性，如通过污染RLHF(基于人类反馈的强化学习)使用的偏好数据来操纵模型；
- 对齐(Alignment)技术的进展与局限： 直接偏好优化(DPO)作为RLHF的替代方案受到关注，但研究表明它可能面临类似的”过度优化”问题。同时，RLHF由于其在线学习的优势，短期内仍难以被完全取代。研究人员正在探索结合两者优点的新方法，如来自 AI反馈的直接对齐(DAAF)；
- AI可解释性的突破： Anthropic利用稀疏自编码器(SAE)成功分解了Claude 3 Sonnet的激活，实现了对模型内部表征的解释。OpenAI随后改进了SAE的方法，使其可以扩展到更大规模。这些进展为”打开AI黑箱”提供了新的可能性，但同时也引发了对这种可解释性可能被滥用的担忧；
- 生物风险与AI： 尽管Anthropic此前的研究引发了对LLM可能加速生物威胁的担忧，但其他实验室难以复现这一结果。然而，研究人员指出，相比LLM，专门的生物设计工具（例如蛋白质折叠/设计和基因修改）可能构成更直接的风险；
- AI滥用的现实威胁： Google DeepMind的研究强调，大多数AI误用案例并非来自于复杂的技术攻击，而是利用了容易获取的生成式AI功能。这包括利用深度伪造技术进行诈骗、骚扰和制作色情内容等；



### 74

方军 2024-10-14


如果这个图是真的，那语音产品就有意思了

[Voice-first，闭关做一款语音产品的思考 | BestBlogs](https://www.bestblogs.dev/article/30d73a)

这篇文章里面配的图：语音交互，或许不仅仅是音频
视频对比文字和音频，毫无疑问是信息传递效率最高的信息媒介。人们在看完视频后会记得 70% 的信息，而单纯看图片记忆的信息之后 30%，在听完一段音频后会记得 20% 的信息。语音交互或许并不意味着内容模态一定为音频，视频同样可以做为信息模态，通过音频可视化的方式辅助呈现音频内容，以提高信息传播效率。

当然，我是存疑的。


### 75

方军 2024-10-14

这个老师最后的吐槽有点意思，某些机构用AI做答疑，“已读乱回”。

为了完整，我摘取全部，前面与AI关系不大：

摘：如果一个班可以不断地招生，不断地进人，那么是不是意味着：这个班的口碑特别好？质量高？从某种程度来说：是的。

但是从另一个角度来说：可以不断进人，就意味着教学服务毫无压力。比如说，市面上很多中小学的课程几千元，然后成千上万的学生家长报名——但是针对我最近的那个雅思写作班来说，人数到了30人，就已经逼到我的服务极限了。

说起来，服务大家都有，就是答疑嘛，班群管理嘛。但是我那个服务，是精准一对一的答疑，学生提交作业为100%（顶多有个别同学是过期交），然后我非常细致回复，有的作业因为学生问题特别多，我回复了将近三千字。

可能正是因为这样的交付质量，学生就陆续来报名要求加座了。如果放在传统的营销模式，每加一个学生，就是多一份利润，但是放在我身上：每加一个学生就是多了一份巨大的工作量。所以，我是使用厚重的服务逼迫自己停止继续招生。本质上，我是重教学的。（根本受不了，不能再进人了）

至于说很多招生数量巨大的班级产品，也没啥作业批改，都是等着学生自己有问题来答疑。问题在于，基础弱的学生是提不出问题的。此外，无非都是利用AI答疑，已读乱回的那种。小红书我是看到一堆这种。
收起

查看详情
方军：这个老师不少观察很深入：

美国这边对于实习教师的要求，是尽量减少教师的说话时间。道理其实很简单，老师在那自顾自地发挥，学生听了也就是听力。需要学生自主发声、表达无论对错与否的观点，然后教师协助其进步就行了。

其实，除了英语教学以外，在大学里的研究生课程，更是“可怕”：有的课上，教授让大家做了一整节课的作业，教授几乎没说啥话。（当然整堂课的讨论，也是需要精心设计的，与实践相结合，讨论的内容马上就会在实践中用到。）

上述情况放在国内，坦率地说：很多学生是无法接受这个观念的。

春季的时候有一次，我在课上仅仅是让一个学生花了一分钟读了一段话，然后给她鼓励了一下，课后评价就冒出来“不要点学生在那朗读”。——除了考研行业以外，我的一些雅思同行也有类似的遭遇：老师们经历了优秀的教学法（如，剑桥系列培训），然后在课上调动学生互动的发言，也被有些学生反对。（这个比较讽刺：雅思口语课不可以点学生发言，只需要听老师在那里炫技）。

黑色幽默的反例也是有的：北京顺义有一些托福补习班。有的孩子厌学，但是老师为了赚那点课时费，就一对一的哇啦哇啦讲一通，反正你也不愿学是吧，然后我讲完之后拿钱走人。

偶尔有一个亮点：有一次一个学生给我留言，说她不能跟直播，但是在回放中又看到我在鼓励一个学生，让其朗读，她看了回放十分感动，觉得我在帮助学生走出困境。

但总的来说，那些落后的教学方式，我估计依然会在国内存活很久。“我花学费不是让我来努力的，是让老师来努力的。”

如果你能理解为健身私教课，就好理解多了。
2024-10-14 13:20



### 76

方军 2024-10-14

摘要、大纲这些功能都真已经产品化了，但我还是觉得产品化早了一点

这是一个叫语鲸的，我偶尔用通义效率。

就大纲提取而言，这些都不如如下提示语：

read thoroughly and write an outline(following the Minto Pyramid principle) in **Chinese** using original words. Return in markdown:



### 77

方军 2024-10-14


Sam Altman	@sama·2023年3月3日	

人们写下要点，让ChatGPT将其扩展成一封礼貌的电子邮件，然后发送出去，而接收者又使用ChatGPT将其浓缩成关键要点，这种做法很讽刺。

Paul Graham @paulg

这是任何徒有其表的组织中沟通的默认做法。发送者用一堆套话来扩充他的信息，然后接收者不得不从结果中提取原始信息。


### 78

方军 2024-10-14

前几天看 Ilya Sutskever 和黄仁勋聊天，他短短 44 秒，把预测下一个词为什么带来推理，讲得特别清晰易懂。

Ilya Sutskever had a conversation last year with Jensen Huang but still, that made me rethink the idea of 'Predicting the Next Word'

其中个别词是黄仁勋的对话。

I'd like to take a small detour and to give an analogy that will hopefully clarify why more accurate prediction of the next word leads to more understanding, real understanding. Let's consider an example. Say you read a detective novel. It's like a complicated plot, a storyline, different characters, lots of events, mysteries like clues. It's unclear. Then let's say that at the last page of the book, the detective has gathered all the clues, gathered all the people and saying, okay I'm going to reveal the identity of whoever committed the crime. And that person's name is predict that word. Predict that word exactly. Goodness, right, right now. 

我想稍微岔开话题，给大家举个例子，希望能说明为什么更准确地预测下一个词会带来更多的理解，真正的理解。让我们想象一下，你在读一本侦探小说。它有着复杂的情节、曲折的故事线、各种各样的人物、众多的事件，还有许多神秘的线索。一切都扑朔迷离。然后假设到了书的最后一页，侦探已经搜集了所有的线索，把所有人都召集到一起，说道：「好了，我现在要揭露犯罪者的身份。」而那个人的名字就是 —— 此刻你要准确地预测出这个词。天哪，想想看，对吧？

[(9) X 上的 Haider.：“Ilya Sutskever had a conversation last year with Jensen Huang but still, that made me rethink the idea of 'Predicting the Next Word' Listen to what Ilya said on this. https://t.co/wSWCLKzfXn” / X](https://x.com/slow_developer/status/1844728830986174930)

### 79

方军 2024-10-14

我虽然还用Kimi，介绍没法用国外产品的人也多数仍推荐它，但我对kimi印象已经很糟糕了，昨天有点被它在B站持续出现的、低级的、忽悠性质过强的广告惹恼了。

摘：Kimi 居然更新了语音通话模式！

今天突然发现我的 Kimi 上多了一个按钮，点了一下发现是语音通话功能，最近集中发货啊。

试了一下效果还挺好的：

最好的一个设计是可以在语音界面展示字幕；
支持打断模式；
支持更换声音；
支持语速调节；

另外还有独特的情景模式：
一个是英语陪练，可以单词跟读语法纠错和话题口语练习；
另一个是模拟面试，可以挖掘你的简历模拟面试场景。

还支持声音克隆，克隆的声音也能在语音通话里使用，我也克隆了自己的，可以在下面领取。



### 80

方军 2024-10-14

这句话，放在AI场景很有意思：

你所表达的东西，就是你所知道的东西，你表达不出来的东西，你不可能知道。
查看详情
下山雨、wulujia 觉得很赞
wulujia：特别想解决"我不知道我不知道"的问题
2024-10-14 22:38
方军 回复 wulujia：刚刚看 Ilya 讨论 AGI 的一个片段，他说了一个不错的策略：

在这样的情况下，某某人会看到什么呢？

这个人可能不存在。

他就说这么几句，但好像就可以一定程度上回应你的问题：

这个人就有可能看到“我不知道我不知道的”的东西。
2024-10-14 22:42
wulujia 回复 方军：是的，这也是我的计划。
2024-10-15 08:10




### 81

方军 2024-10-14

前几日说 LLM 不能推理的那个例子，被解决了，就用提示语，牛啊

···
create a function "invert(tree)"
tree is an array of size 2^n that represents a binary tree
the key to each node is the index
the invert function should return a new tree where the keys are inverted bitwise
for example the key 1 in binary is 0001 so it should be 1000 in binary and 8 in decimal

To create the invert(tree) function that inverts the keys of a binary tree represented as an array, we can follow these steps:
1. Determine the size of the tree.
2. For each index in the tree, calculate the inverted key by performing a bitwise NOT operation.
3. Store the inverted keys in a new array and return it.
Here's the implementation of the invert function:
Explanation:
The ~i operation inverts the bits of the index i.
The & (n - 1) operation ensures that the inverted index wraps around within the bounds of the array size.
The new tree is populated with the values from the original tree based on the inverted indices.
You can use this function by passing an array that represents your binary tree.
···

[(9) X 上的 high\_byte：“@VictorTaelin $10k plz https://t.co/G45Fu9u6T5” / X](https://x.com/high_byte/status/1845847610130649126)

### 82

方军 2024-10-14

有了 AI  大纲提取之后，的确多看了很多信息，但又反思，这些信息是没必要的。得再次回到一种平衡。我蛮熟悉Wordpress使用的，但已经不用它很多年了，现在如果要网站多半用静态页面生成器，比如github pages（jekyll）、 vitepress 这些，公司商业用途面向国外我比较推荐 webflow （美感好、模板多），个人博客嘛，我觉得完全不需要自建站。

[半生心血贡献给开源，WordPress 之父分叉 20 万行代码报复吸血企业，DHH：别发疯](https://mp.weixin.qq.com/s/z6vtmZAqvDYbVKyKYAgBKA)

### 83

方军 2024-10-15


最近又觉得，模型能力比去年初强大之后，提示语（prompt）又变得重要了，可以轻松干很多事。

这也源自于现在模型的function call、长上下文、推理能力。同时，去年很多必要的技巧现在不需要了。也许应该继续多多探索这个。

去年初重视提示语，和现在重视提示语的逻辑是有很大差别的。当然，我觉得基本的原则没变。我认为仅关注各种工具不太行，LLM本身是个黑盒子，工具又是一层盒子，工具也经常过于通用，叠加起来闭眼乱答。
收起

查看详情
Koant、下山雨 觉得很赞
不努力的梦想：现在也不像那个时候各种质量的structure prompt横飞，现在反而更能体会到一个真正的可贵prompt有多强大
2024-10-15 17:12
方军 回复 不努力的梦想：是的
2024-10-15 17:48
方军 回复 不努力的梦想：那个时候的各种所谓结构化提示语，只是表面上看起来结构化，但都很少有跑eval，有一定的评估的。
2024-10-15 17:49
方军：《成为提问工程师》中尤为基础的第三章，我现在再看还是很棒的，就朴实地谈了三个场景：

AI 辅助翻译
AI 辅助写作
AI 辅助学习

我稍后分享下电子版吧。
2024-10-16 01:06


### 84

方军 2024-10-15

AlphaCodium能够提升OpenAI o1模型在解决编程问题上的表现，推动AI模型向更深层次的系统2思维迈进

AlphaCodium Outperforms Direct Prompting of o1 Mod...

elvis:  这是我看到的第一份报告，其中现成的OpenAI o1 CoT（思维链）推理在代码生成方面的表现被超越。

他们提出了AlphaCodium，它作为一个策略提供者（即流程工程）构建在o1之上，旨在激发和引导o1的思维链能力。

AlphaCodium被设计为一个多阶段流程，改进了推理能力和可靠性，同时显著提升了o1-preview的性能（在Codeforces基准测试中，通过率@5（即在前5次尝试中通过的比率）从55%提高到78%）。

作者指出："AlphaCodium的潜力是显而易见的：通过适当的策略性流程工程，像o1这样的基础模型可以被引导towards系统II思维。我们仍需努力跨越从'系统1.5'到真正的系统2级AI的鸿沟，但通过观察像AlphaCodium这样的工具，我们可以更好地理解这个差距，并继续研究以缩小它。"

o1是一个比当今大多数大语言模型（LLM）都要优秀得多的模型。然而，正如这份报告所示，它仍可以从战略指导中获益。我也正在为知识密集型任务开发类似的方法。根据我自己的分析，o1在复杂任务的知识掌握方面确实表现更佳，但在复杂知识理解和推理方面仍然存在局限性。关于这一点，我很快会有更深入的探讨。

图的解释来自 AI 对图片的直接解读，有调整，它没懂右边顺序：

第一部分
   - 从输入问题描述和公开测试开始 (Input - Problem Description + Public Tests)
   - 进行问题反思 (Problem Reflection)
   - 公开测试推理 (Public Test Reasoning)
   - 然后生成可能的解决方案 (Generate Possible Solutions)
   - 对这些解决方案进行排名 (Rank Solutions)
   - 并生成额外的AI测试 (Generate Additional AI Tests)

第二部分
   - 输入问题描述和公开测试 (Input - Problem Description + Public Tests)
   - 对公开测试进行迭代 (Iterate on Public Tests)
   - 对AI测试进行迭代 (Iterate on AI Tests)
   - 最后再次生成可能的解决方案 (Generate Possible Solutions)


### 85

方军 2024-10-15

星球里面的朋友啊，我真心推荐  Zed 编辑器

就免费 Claude 这一条，大家就该用啊，我不知道为什么推销它特别不成功

1. 它现在几乎有完全免费的 Claude 用，也可以自带各种模型

2. 在编辑器侧栏用 AI 太爽了，远远超过网页（自然体验也是超过命令行的）

3. 可以方便地管理  prompt library

4. 也可以方便地贴入图片进行处理

5. 在文本编辑内也可以用，可以 tab 出内容（我不用，但在我连接 Github copilot 期间是可以的）

Zed - The editor for what's next

它也可以方便地与 Obsidian 联合使用，简单来说，两个都是基于文件的，你在 zed 里面打开文件夹就可以了。

编程我不用 Zed，目前还是 VS Code 为主，偶尔 Cursor



### 86

方军 2024-10-15

我倾向于认为 NotebookLM 被过誉了

阿里通义（tongyi.ailiyun.com）比它好，不过没办法，这是中国公司的不足，除了字节的tiktok之外，很少有产品在一开始就能参与全球竞争

附注：这样的内容我是懒得看原文的，和 Cursor 那个四个创始人参与 Lex Fridman 必须细看视频，对待的态度差别真是很大。

[NotebookLM核心负责人访谈： 项目不到 10个人，体验惊艳全球，但它还只是个技术demo](https://mp.weixin.qq.com/s/oMPdXhFckUVUYLK1nJtxBQ?poc_token=HFEyE2ejOgWnz_EwRKCl47RHN2VfCb8yPtVFogMc)

### 87

方军 2024-10-16

这个有创新性，很久没看到这么牛的了，终于看到多模态的作用。摘：把任何书本上的图表、公式变成互动实验

物理知识轻松掌握！

能让普通物理教材中的静态图表变成互动的、动态的模拟器，让你可以动手操作，甚至实时看到物理现象的变化。

不需要编写代码，只需点击几下，就可以自己“动手”做实验！

Augmented Physics 可以将静态图表（如光学、运动学、摆、电路等）变成可以操作的动态模拟实验。比如，你可以调整镜片位置，看看光线如何变化。

这款工具的核心功能包括：

-自动提取课本中的物理图表，让你轻松从PDF教材中获取需要的图表。

-生成交互式模拟，你可以像做实验一样调整图表中的物体和参数，观察变化。

-动态可视化数据，比如让摆动的物体展示角度随时间的变化，或者看到电路中电流和电压的变化。

你还可以拖动、调整图表中的元素（如镜片、物体位置等），观察实时反馈。

也可以通过修改图表中的数值来动态调整物理系统。

论文：[2405.18614] Augmented Physics: Creating Interacti...

[[2405.18614] Augmented Physics: Creating Interactive and Embedded Physics Simulations from Static Textbook Diagrams](https://arxiv.org/abs/2405.18614)

Augmented Physics：增强现实你的物理课本 让你的物理课本上的图表动起来 – Xiao...

[Augmented Physics：增强现实你的物理课本 让你的物理课本上的图表动起来 – XiaoHu.AI学院](https://xiaohu.ai/p/14645)


### 88

方军 2024-10-16

LLM不会推理——1万美金悬赏下，o1在内所有模型均无法反转二叉树？！
方老师，你怎么看？LLM不会推理——1万美金悬赏下，o1在内所有模型均无法反转二叉树？！
查看详情
方军：昨天说有人实现了

前几日说LLM不能推理的那个例...

我还没细看
2024-10-16 10:20
乘风 回复 方军：Taelin回复说并没有解决，因为要求不能使用循环，违规了
2024-10-16 10:51
方军 回复 乘风：哦哦：）
2024-10-16 10:59
乘风 回复 方军：我在想，大模型到底会不会基本的、严密的逻辑推理，如果不能，难道都是概率解或者别人极端推测的模式解吗？
2024-10-16 11:18
方军 回复 乘风：这是一个没有定论的

从原理看，大模型的确是模仿

从效果看，它能推理

这个时候，说它不能推理？好像不对

说它能推理，也不对

从实用角度来将，它当然能推理，我选择这个实用立场
2024-10-16 11:33
乘风 回复 方军：是的，我的观察跟你完全相同。从大模型原理来看就是神经网络，是压缩算法，是预测下一个token，是不能进行严密的逻辑符号推理的。可是部分人类为什么可以进行严密的符号推理呢？神经网络进步到极致难道也不能进行符号推理吗？
2024-10-16 11:53

[知识星球是创作者连接铁杆粉丝，实现知识变现的工具。任何从事创作或艺术的人，例如艺术家、工匠、教师、学术研究、科普等，只要能获得一千位铁杆粉丝，就足够生计无忧，自由创作。社群管理、内容沉淀、链接粉丝等就在知识星球。-知识星球](https://wx.zsxq.com/group/15552458112512/topic/8858281128855152)


### 89

方军 2024-10-16


闲聊几句，我觉得在工作学习时，有了 AI 之后，助力非常大

最近在想，其实最有效的学习方法，也是做事方法，是 elaboration（详细阐述）。在认知天性里面看到这个词，大意是用自己的话详细讲述。我认为，是拆解后，详细讲述；也可以是撇出掉不重要的部分，留下重要的部分后，再详细讲述；也可以是对某个重要部分进一步拆分后，详细讲述。

那么，在这个过程中，AI就可以帮大忙。这儿，我们一定要自己讲述吗？不一定啊，自己用脚走路是慢的，开车是快的。拆解完之后，让 AI 尝试着讲一个，我们来判断它讲得对不对？如何把它的表述修改得更好？当然，我们同样可以再讲一遍。

elaboration （详细阐述）的过程中，我还常会用图。这是因为我觉得，如果已经把它缩减到三四个元素，画个图表达一下它们之间的关系，会理解得更深入。

有意思的，也许是总是很快速地学习，我发现偶尔会有这样的情况，拆解到最后时，会发现两个元素之间的逻辑关系自己混淆了。比如说，一个正确的逻辑应该是先 Builder，再 Proposer，但由于缩写词是PBS，虽然我清晰地知道先后顺序，但还是会偶尔说混。但只要画了图，就可以记忆、理解更牢靠了。

在这种情况下如何用好 AI 呢？为了避免自己的误解被 AI 扩大，我通常会附加一个资料作为上下文，然后请 AI 解释，而不是让它扩展我的解释。通常，AI 会敏锐地发现我的那句话和上下文之间的不同，然后它一般都能以正确的顺序表达出来。


### 90

方军 2024-10-16

今天有人发布新产品，关于 AI 写作的。

摘些网友讨论，我并不是很认同用 AI 写作，应该说不认同泛泛的，它如果深入到具体场景，比如客服邮件回复、语法校对、书面文字口语化、润色、口述整理与书面化、律师记录/其他记录等等，那还是有很多可用的地方的。

和写作有关的其他流程，比如为写作搜集资料，我也不建议AI。怎么用 AI 来辅助写作，这涉及到怎么认识「写作」这个问题：

- 为什么要写文字
- 如何写文字
- 如何改文字

我还有一种不受欢迎的观点，正好最近也看到，就是说，用 AI 在自己的笔记里面产生新点子。这的确是卡片写作法里面提及的一种思路，但让 AI 在这里面来产生联系、产生火花，我觉得很愚蠢，你的脑子是干什么的，如果愚蠢到相信这种外部的联系，那这脑子也的确没用了，别干这些要脑子的事了。

---

📕Tom Huang: 深入实践 LLM 产品开发半年，目前产品已经开始内测，聊一聊 10 条行业观察：

1. ChatGPT Canvas 发布编码和写作两个场景，编码有 Cursor，写作具备独立产品的机会

2. 写作相比编码更普世也更难，Cursor + ChatGPT Canvas + NotebookLM 的结合可能带来更大的产品化学效应

3. Cursor 最核心主要有两个要素：1）用户自行定制内容上下文的 Human-in-the-loop 的交互设计 2）Claude 3.5 Sonnet 编码能力太强太出圈，基本上是在「有限难度下的最佳效果」

4. Cursor 类编码任务是收敛的，但写作是泛目标任务，同时受众人群也很广，这就很考验产品设计能力 

技术趋势：

5. 专业人员构建多个 Bot + 调优用于消费的产品已经成熟，并且有开源成功案例，比如 @dify_ai 、 @FlowiseAI 等 

6. 多模态+工具链的成熟，解锁了 LLM 将任意输入内容（通常长且复杂）转为通熟易懂、图文并茂甚至音视频结合的方式，降低了消费门槛，NotebookLM 出圈是一个典范案例 

7. 随着 LLM 能力增强，80% 基础场景无需像之前由专业人员构建很多Bot并调优再使用，现在可能就是一个 Bot + 用户自由选择内容而+自定义内容格式+适配内容格式的端 
市场分析：

8. 单 Bot + 用户自由选择内容 + 定制内容格式的产品目前有 NotebookLM 等，其实水下还有不少产品，后面可以聊聊，但是 NotebookLM 是一款技术向的实验产品，而且目前并无开源平替

9. ChatGPT Canvas 虽然强，但是 LLM 自由写作通常收益较低，结合领域知识才能更好的发挥 

10. Cursor 的领域知识选择 + ChatGPT Canvas 的 AI 写作交互 + NotebookLM 的促成内容消费格式或模态的转换，这里面有端到端的产品机会

而我们正在内测的产品正在朝着这个目标前进🫶 

这里再挖一下之前宝玉老师关于 Cursor 和写作产品的评价 @dotey

---

📕 宝玉之前的讨论：大厂与其山寨 Cursor，不如做个好用的 AI 邮件客户端

宝玉现在说：我用 OpenAI 的 Canvas 比较多，相对不错了

大厂与其山寨 Cursor，不如做个好用的 AI 邮件客户端 | 宝玉的分享

大厂抄 Cursor，这样追在别人屁股后面跑是没有前途的，AI 代码编辑器已经是红海了，就算大厂又如何，微软比 Cursor 大多少？结果 GitHub Copilot 也没打过 Cursor，大厂还不如多投资几家像 Cursor 这样的公司，为什么非要抄他们呢！

程序员这个群体大家都知道，又不愿意花钱又没忠诚度，Cursor 好用马上都退订 Copilot，能白嫖绝对不花那$20 的订阅费，大厂不如多看看普通用户的需求。

普通用户需要的不是 Cursor，是能帮助沟通和写作的 AI 编辑器，比如写邮件、回短信。但是有好用的吗？没有！唯一可以看到的期货是苹果的 Apple Intelligence。

\## 普通人的写作需求是什么？

普通人日常的写作分三种：日常沟通、公文和创作。

**日常沟通**

日常沟通协作就是各种日常的邮件，短信、微信、Slack 等等，这类写作尤其是邮件，套话很多，特别适合用 AI 生成。我日常写稍微长一点的邮件基本都是 GPT 帮我完成了，给出要点和充足上下文，生成的又快又好，稍微改一下就可以用。

**公文类写作**

公文类就是各种报告、总结、文档等等，这种公文套话多，格式固定，但是费时费力，现在绝大部分公文都可以用 AI 帮助协作了。

而且同类型的公文，比如文档，以前历史的文档都可以重用，大语言模型尤其擅长模仿写作风格或者内容结构。结合 RAG（检索增强生成）这样的技术，写新的内容之前把以前写过的相关内容找出来，类似于 Cursor 那样帮你预先生成，大部分时候可能一路 Tab 就好了。

**创作类写作**

创作类又可以细分，一类是二次创作，比如翻译、书评等；一类是原创的创作，比如写论文、写小说还有像这篇这样的原创博客。

二次创作像翻译这种创作，如果结合 AI 其实可以效果更好，比如 AI 先翻译一遍，局部不对的，类似 Cursor 那样，调出对话框，告诉它如何改进，比如先解释一下、去搜索一些外部资料补充，再次生成结果就好很多，但是不需要手动去复制、搜索引擎搜索、筛选、重写等等。

至于原创，我个人是不依赖于 AI 写作的，从来没有让我满意过，我更喜欢一点一点将模糊的想法形成文字，并不断修改成型，AI 的自动完成甚至对我是一种干扰。但写完后借助 AI 帮我改改错别字、润色一下还是可以的。

\## AI 写作工具的挑战是什么？

相信我上面列出的几类写作需求也同样是大多数人所需要的，像代码编辑器，GitHub Copilot、Cursor 这样的好工具层出不穷，而给普通人写作的 AI 辅助工具，却没有看到什么好用的，这里面确实有很多挑战！

**私有数据的获取**

要想让大语言模型生成好的结果，一定要有充足的上下文，这就意味着要获取你的私有数据，而普通人写作时的数据，很多都涉及隐私，相当敏感。没有人希望自己的私密聊天记录和通信记录发送到服务器，公司相关的邮件更是如此。另外像微信、Slack 这样的通信工具的数据，本身也是没有公开 API 可以获取的，通过其他手段可能会有些麻烦。

**模型的能力**

苹果在演示 Apple Intelligence 中的智能邮件回复时，效果很惊艳，但是它用的是本机小参数模型，如果不能接入 GPT-4o、Claude 3.5 这样的大参数优秀的语言模型来做这个任务的话，我不觉得效果会有多好，毕竟模型的能力才真正决定了最终生成的效果。

包括现在开源的大语言模型，要想在本机运行，大一点参数的模型根本运行不起来，小一点参数的效果又不好，这也是制约之类 AI 写作工具的一大瓶颈。

**交互体验**

GitHub Copilot 和 Cursor 的成功，很大一部分程度上归功于其交互体验，根据当前你写代码的位置，智能的给出提示，随时唤起对话框输入提示词个性化的完成任务。但是代码相对来说确定性更强，有固定的语法结构和最优算法解，还有无数历史代码参考，通常一个上下文内，只有有限的最优解，所以可以给出精准的提示。而对于写作，完全是发散式的，可能性太多，极难预测，同样的交互也许就不一定适合普通写作。

**技术挑战**

很多做过或者了解 RAG 的都知道，现在 AI 搜索，看起来技术不复杂，但是做好其实极难，根据用户的输入找出贴切的上下文是极难的事情。要做好 AI 写作，难度不会比 AI 搜索更小，因为本质就是先根据你当前输入的内容，去做 AI 搜索，找出以前相关的内容，甚至要去搜索外网相关的内容，再结合输入位置前后的内容和你的要求帮你写作。

当然还有很多其他挑战，我也无法一一列举。

\## 下一个 AI 写作工具的机会在哪里？

我以为下一个 AI 写作工具的突破可能首先会是邮件客户端，邮件写作是高频需求，整理邮件也是一大痛点，相对来说邮件的数据也容易拿到，用户只要安装了客户端，绑定邮件账号，就可以在用户的允许下拿到用户的所有邮件数据，并且可以结构化的整理邮件数据，比如和某个人、某个组之间的所有对话，比如某一类对话。

如果有信的过的邮件客户端，能帮我连接 GPT-4o 和 Claude 3.5 这样的 API，能根据我需求智能撰写回复邮件，能根据我需求整理邮件清理垃圾邮件，对我的生产力会是很大提升。

AI 邮件客户端之后，可能会是公文写作，帮助你把历史内容都做好索引，学习你的写作风格和文章结构，根据你采纳建议的反馈不断完善模型。

专业翻译类的 AI 工具，是值得好好做的，书籍的翻译、文章的翻译、字幕的翻译，都是可以借助 AI 大幅提升生产力的地方，好的翻译工具，效率的提升可能是数倍记的。

在 GitHub Copilot 之前，我没想到 AI 可以这样辅助编程，再到 Cursor，我也没想到交互还可以进一步进化到这样方便的程度。所以对于 AI 写作工具也是类似的，我不觉得 Cursor 就是天花板，未来一定有超出我想象的更好的交互形式出现，可能唯一限制我们的就是我们的想象力吧。

期待大厂能做出适合普通人的好用的引领未来的 AI 编辑器，而不是去山寨一个 Cursor 出来！相比而言，我更看好小团队或者个人，他们比大厂更有机会开发出像 Cursor 这样吊打大厂们的 AI 工具。

---

📕 Winnerineas（不同意见）

写作本质上是思想的符号化，也是一个garbage in garbage out的过程，和工具本身关系不是那么的大。所谓好的工具也不过就是解决以下几个问题：

1. 不离开写作页面进行信息的检索和确认。

2. 提示符合语法或者文法的表达方式。

3. 可视化逻辑思维链条或者故事线。

4. 检查潜在的逻辑错误，循环论证等等。
最多能够超出作者认知的就是根据所谓符号相关性展示给作者她/他没有认知的信息，刺激和提示作者进一步的写作。

---

📕 meng shao：帮转！期待看到完成度更高的 AI 写作工具。

目前能看到的 AI 写作工具, 要么是 AI + 写作, 要么是写作 + AI, 不过两种形态都没有实现的很理想。即使抛开交互模式不谈, 只看能产生的最终结果也是不够理想的。

- AI + 写作

通用 AI 产品中兼顾写作, 写作只是 AI 产品能力的一部分, 所以不会有特殊的功能逻辑, 需要使用时给定很多前提和提示, 反复问答后输出中间态, 人再介入完成修改和后续步骤。即使有针对某些特定行业写作的设定, 通常也是 Prompt 中对身份和目标的简单设定, 不够深入。

- 写作 + AI

传统的写作类工具, 结合 AI 的方式通常会流于 "Canva AI" 化, 该有的能力我都有, 通过改写、润色、续写等给用户提供很多很多的选择, 但一方面太依赖用户自己的判断和选择, 一方面基本都是 LLM + Prompt, 对文章本身的帮助有限。


[大厂与其山寨 Cursor，不如做个好用的 AI 邮件客户端 | 宝玉的分享](https://baoyu.io/blog/ai/big-companies-instead-of-copying-cursor-should-make-ai-email-client)

### 91

方军 2024-10-16

提示卡101 AI提取大纲：抽取文章整体结构

说明：向AI提问图卡开启，第一个是101（有意从101开始编号）。我发现，在把文字图示化的过程中，一方面我会受限而不得不缩减文字，另一方面我会不断地修订这个文字。总体而言，形式优化了文字。

这个提示语我之前分析有提了六个要求：1）仔细阅读；2）编写大纲；3）明托金字塔大纲；4）用原文词语；5）中文回答，并用****加重这一点；6）Markdown格式返回。

---

当你阅读一篇长文时，是否会一下子把握不住它的整体结构，而不能有效读懂关键信息呢？

你可以让 AI 预读全文，返回一个遵循*麦肯锡明托金字塔结构*的大纲。大纲将文章的信息架构与内容板块呈现在你的面前，成为你进一步阅读的辅助。

下为中英文版提示语，推荐直接用英文版。为便于使用，英文版提示语明确要求始终用中文回答。

```
Read thoroughly and write an outline(following the Minto Pyramid principle) in **Chinese** using original words. Return in markdown:

仔细阅读，然后编写大纲。大纲应遵循金字塔原理，并用原文词语。以 Markdown 格式返回：
```

图卡字体是否加粗一点（由300->400），还要再斟酌下。请问你喜欢如下两个里面的哪个？


### 92

方军 2024-10-16

教授讲的东西，看不懂

[【曾鸣演讲全文】我们正迎来AGI的雅虎时刻](https://mp.weixin.qq.com/s/0VTyOPwZaXVpCsj0IeyDVw)

### 93

方军 2024-10-17

[Yann LeCun最新万字演讲：致力于下一代AI系统，我们基本上不做LLM了](https://mp.weixin.qq.com/s/vfiMTB3X7qj6gHmZ1c5ehQ)

杨立昆有他的优势，但他这一年多对 LLM 的批评，真是觉得有点像赌气。

### 94

方军 2024-10-17

大纲提示语把 Paul Graham  的精彩文章整理得个乱七八糟

不过，这其实是合理的。当我们看完一篇文章，我们写心得时，通常写下来也是这些。这么看，AI 读得比我们好。

[Life is Short](https://paulgraham.com/vb.html)

原文很好，记得读原文。

前一段还看了一本书，人生四千周，蛮好的，但其实就是 Paul Graham 一篇文章的事。

If you ask yourself what you spend your time on that's bullshit, you probably already know the answer. Unnecessary meetings, pointless disputes, bureaucracy, posturing, dealing with other people's mistakes, traffic jams, addictive but unrewarding pastimes.
如果你问问自己把时间花在哪些胡说八道的事情上，你可能已经知道答案了。不必要的会议、无意义的争论、官僚作风、装腔作势、处理别人的错误、交通堵塞、使人上瘾但无回报的消遣。

乘风：我感觉总结的挺好 只是感觉这种总结看一眼就不想看原文了 全是逻辑正确的废话 原文就比较触动读者 而且会引发思考 所以遇见大神还是要亲自阅读的 哪怕是真人来总结也一样会丢失很多东西
2024-10-17 20:18
方军 回复 乘风：对的，其实得到已经很努力做图书解读、质量也很高，但其实也是很不行的。
2024-10-17 20:21
乘风 回复 方军：是的 基本上是专业水准了 但是有些好书还是要亲自读的
2024-10-17 20:45
希瑞：看原文的体验就像是两个音叉产生共振，只看大纲的体验是只看了个叉…大纲丢失了太多情境的信息，只留下了命题。
2024-10-17 21:09
方军 回复 希瑞：是的，所以也反过来说明一个道理，各种总结、笔记、干货，其实都是有问题的
2024-10-17 22:10



### 95

方军 2024-10-17

神奇，各种关于notebookLM的讨论与畅想

[NotebookLM 是 Google 的 ChatGPT 时刻吗？](https://mp.weixin.qq.com/s/EUhHcekY4vMN0HH2_7_eqA)

### 96

方军 2024-10-18

看 Wes Kao （maven co-founder）说的，感慨，基础沟通能力真是个稀缺的能力啊

我看各种人向 AI 提问，极好地反映了他们表达能力之弱

Managing up 101: Make it insanely easy to give you feedback.

One of my direct reports sent this Slack DM and it's a masterclass in simple, direct communication.

No guessing where to find docs.

No follow-up questions on timing.

No confusion about priority levels.

She made it easy--and in less than 1 hour, I was able to provide feedback, give approval, and remove myself as the bottleneck for her projects.

Make it easy for people to give you what you want.

向上管理 101：让别人给你反馈变得极其容易。

我的一位直接下属发了这条 Slack 私信，这是简单、直接沟通的典范。

无需猜测在哪里找到文档。

关于时间没有后续问题。

关于优先级没有混淆。

她让这变得容易——而且在不到 1 小时内，我就能提供反馈、给予批准，并让自己不再是她项目的瓶颈。

让人们容易给你你想要的。



### 97

方军 2024-10-18

我发现，专业的文字，AI还是差距非常大，AI基本上能做到很好的是提供一种供理解的解释。

比如对比下如下专业人士的解读：

对SFISF的几点技术讨论（Degg）

一些朋友让我写写央行新成立的债券、基金、保险互换便利（SFISF）。

9月24号潘行长在发布会上宣布成立该工具，它本质上是允许非银拿着股票做抵押，找央行借国债或央票，然后非银可以拿着这些高等级抵押品从银行间市场以质押融资等方式借钱，从而继续增持股票。换句话说，它是央行刺激非银加杠杆买股票的货币政策工具，目的是“提升金融机构的资金获取能力和股票增持能力”。我们此前讨论了这一工具对央行、非银和银行T表带来的变化。

市场似乎对该工具的效果有比较高的期待，一些消息也显示券商自营——特别是权益OCI账户——正在踊跃申报该工具。这类账户会把股票划入其他权益工具，从而使当期损益不受股票市值波动影响，而只受所持票息与负债息差影响。因此它们特别喜欢高股息票。如果SFISF的综合成本能够显著低于股息率，将尤其利好这类账户/策略。

但到目前为止，央行并没有披露太多关于SFISF的技术细节。在这篇文章中，笔者想结合美联储08年推出的定期证券借贷便利（TSLF）和19年央行推出的央行票据互换工具（CBS）对这一工具的技术细节及影响做些猜测和讨论。

问题1：折扣率多少？

折扣率（haircut）是互换或抵押融资工具的重要参数。折扣率越低，单位市值股票能借到的国债/央票也就越多，非银可加的杠杆也就越高，对股市的刺激效果理论上就越好；但折扣率越低，出借方央行面临的违约风险也就越高。

从TSLF经验看，其抵押品中不包括股票，投资级企业债的折扣率大约在6.5-8%，投资级ABS的折扣率大约在7-18%（图1）。但需要注意，TSLF的期限是28天，比目前传言的SFISF的1年要短。从我国经验来看，央行5年期MLF中AAA级企业债的折扣率大约为20-30%，个人与券商做股权质押的折扣率大概在50%左右，期限为1-2年。

考虑到股票的波动率要显著高于高评级企业债，因此除非有财政部提供劣后资金用于吸收潜在损失，或者有其他的增信方式，否则特别低的折扣率只会给央行带来无必要的风险。个人感觉折扣率在30-50%之间可能是较为合理的。

如果按照30-50%折扣率估计，一季度末上市券商股票自营OCI账户余额大约为3100亿（华创证券），假设70%的自营盘申请使用该工具，那么大约会带来1000-1500亿的增量资金，仍然在第一批5000亿范围之内。

问题2：利率如何设计？

由于非银需要拿股票先找央行借入国债或央票，然后再去市场质押融资（或者直接出售），因此它面临两部分利率成本——借国债的利率和质押融资利率（或者抛售国债后未来买回的机会成本）。

从CBS经验看，央行借出券只征收了一笔10bps的非常低的费率。TSLF也采取了类似的方式，美联储借出国债征收的费率为25bps（按实际拍卖情况可能略有上浮）。如果SFISF也参考这一方式，那么券商或保险支付的最终融资成本就是市场回购融资利率（如R007）+10-25bps。这在目前的利率环境下成本大约是2%出头，直接利好那些能够长期持有4-5%高股息票的非银，比如自营OCI或者保险。

但如果央行出借国债本身就要征收一笔较高的利率，比如2%。那么非银最终实际支付的利率将超过4%，意味着4-5%的股息率不再有吸引力。

但高利率并非没有道理。如果央行更希望该工具的作用是在市场大跌的时候雪中送炭，而非在市场大涨的时候锦上添花，那么相对较高的利率可以确保机构只在股票价格暴跌（以至于股息率大幅上升）后才会使用它。

问题3：资产价格波动是否需要补缴抵押品/保证金？

在TSLF工具中，纽联储和清算行每日评估抵押品价值。如果跌破警戒线，借券方（一级交易商）就需要补缴抵押品，否则就会面临解约。这确保了借款人风险不会传染至央行。理论上，股票价格波动远甚于债券类资产，因此对抵押品估值与管理的评估要求更高。暂不清楚在SFISF中相关条款细节。

为什么要关注抵押品估值和保证金需求的相关条款？因为这关系到SFISF到底会成为股市稳定器还是放大器。

显然央行希望SFISF能够托底市场。但如果该工具总额度在初期就被使用完毕，而央行对抵押品又有非常严格的规定，那么券商在股市大跌时就可能陷入margin call，反而加剧资产抛售压力。而如果抵押品管理不那么严格，则意味着央行替券商/保险承担了一定的市场风险。

问题4：拍卖制（auction-type）还是常备制（standing-type）？ 

所谓拍卖制，就是指央行确定每一期总出借额度和拍卖时间，然后由最终需求者报价+报需求，并按照价格由高到底依次满足，直至额度用完。它的好处是高需求的可以高报价，低需求的可以低报价，这样工具的总体使用量比较高，而且没有污点效应。缺点是非常备的——错过了这次拍卖就要等下一次了。美联储的TSLF就是拍卖制流动性工具，目的是减少污点效应，调动一级交易商积极性（图2）。

所谓常备制，就是指央行只确定出借额度上限，同时直接确定利率等各方面条款，最终需求者按央行给定的价格来报需求。它的好处是总使用量不高，但能够确保只有特别需要这笔资金的机构才能借到钱。缺点是存在污点效应。美联储21年设立的常备回购便利（SRF）就是常备制工具。

为什么要关心SFISF到底是拍卖制还是常备制？因为不同的制度下，它对股价的影响可能不同。

如果是拍卖制，那么在每次拍卖结束后，伴随非银拿着资金入市，该工具对市场的提振效果就结束了。换句话说，拍卖制下的SFISF只是系统性增加了市场对某些股票的需求以及这些股票的价格中枢。除非央行在市场暴跌时临时增加拍卖额，或者此前额度没有用满，否则SFISF无法起到“在市场暴跌时托底市场”的逆周期效果。

如果是常备制，那么该工具就需要征收相对较高的利率，以避免金融机构长期使用该工具作为融资来源。否则在额度用完后，常备也就失去了意义。这时，SFISF的作用将更多体现为熨平波动，而非提升价格中枢。

问题5：借入的国债是否允许抛售？ 

CBS工具不允许一级交易商抛售借入的央票，只能做质押融资。个人认为SFISF可能延续这一设计，即只允许做质押融资不允许抛售。原因是如果允许抛售，那么借券人相当于做了一个杠杆多空策略——借入资金做多股票，做空国债。债券价格大涨或者股票价格暴跌都有可能导致券商受损乃至传导至央行。

有人说这一工具的初衷就是为了抬升债券利率。但事实上，当前的央行已经可以通过借券卖空或者买短卖长等方式自己出面调节长端利率，并不需要“借券给他人卖空”。

问题6：非银是否可以使用该工具反复加杠杆？是否可以资金他用？

例如，A券商在首次申请中以自持的50亿股票为抵押，申请了25亿SFISF额度并增持了25亿股票。那么在续作时的第二次申报中，A券商能否以总的75亿股票为抵押，申请37.5亿的额度来继续加杠杆？ 

另外，如果A券商申请了25亿额度，但拿出其中一部分资金做其他业务如衍生品、质押融出等，央行是否允许又如何考察？

这些问题都将影响该工具对市场的实际提振效果。

总结：由于当前非银持有的股票很难从市场中获得质押融资，因此SFISF无疑会系统性的提高股票的融资流动性，并推升股票特别是高股息票的价格。更进一步的看，其使用量和最终效果也取决于具体的技术细节。期待未来公布更多细节。



### 98

方军 2024-10-18

我们作为最早一批高浓度接触AI文字的有个大优势，就是别人还在觉得它神奇（也可能误信）的时候，我们已经过了一大关口。

的确，现在我们就很比较朴实地看到它的优点，又能看到不足。

AI是80分的水平。我们自己得要求自己做到95分以上。

我个人是觉得，即便自己写的日常笔记（有时候记得太快错字什么的颇多），也远超过80分的。



### 99

方军 2024-10-18

155 AI 文字有什么特征？

刚刚我感慨，我们这一批较早深入使用 LLM 的人，有一大优势：由于我们大量看 AI 生成的文字，尽管还无法用语言描述它的特征，但已经对这类文字有了基本的认识。它有点专家口吻，但我们不会被迷惑。接下来，AI 生成的文字会越来越多，会成为我们获取信息的众多类型之一，这种先发优势会帮我们很多。

那么，目前 AI 生成的文字有什么特征呢？我这里主要指，当我们用在互动式对话中提问时，它给的回答，有什么特征呢？这里尝试着列几条。

AI 的基础认知水平是人类平均分。在多数大众领域，AI 是平均分。它的回答看起来很有条理、很专家口吻、很详尽，但是，这都是一个平均分，也就是70-80分。在每一个我们自己较为专业、也有鉴赏力的领域，我们都能感受到 AI 水平不太好。

我们要在很多领域达到专业水平，不容易。但是，要在相对多的领域形成较好的鉴赏力，还是可能的。比方说，我对经济学内容没多少能力，但什么是好的，还是能够看得出来的，这是因为阅读高水平材料多了就可以达到了。

要识别 AI 的胡扯（bullshit）。人类专家中水平较为一般的经常会胡扯，看着很专业，但他们都不知道自己在讲什么。在外人看来，他们和最顶级的专家用词、语调一样，甚至看起来可信度更强。但是只要仔细辨别，我们会发现他们在胡扯。比如，他们可能仅仅使用一些大词没逻辑地列一些东西，可能没有抓住真正的重点。是的，任何事物都可以归结为几个重点要素及它们之间的关系。

与 AI 交互多了，我们每个人的思考能力都会有所上升，如果能够掌握日常阅读中的一个关键方法，我们的思考能力上升会更快。这个方法就是删减，不管看到什么，把不相干的都删减、撇除。往深处挖是困难的，但往少数处精简是容易的。

那么也许有人会说，让 AI “惜墨如金”不就好了（惜墨如金是一个被证明让 AI 说话不要啰嗦的有效提示语）。但我觉得正确的做法并非如此，我们用 AI 是想获得更多的信息、更多重点供选择，让它惜墨如金就少了这一层好处。

更好的做法是：让 AI 按照它的基本表达方式来输出，之前有研究者讨论，它的表达方式是训练过程中的偏见导致的——较长的回答会获得较高的分数。它回答得长、详尽、啰嗦没关系，我们自己掌握删减的方式，快速看到关键点。另外一个辅助的做法是，让 AI 不是输出长段文字，而是输出列表，我们通常能够更快地阅读列表。（我这篇笔记有意不采用列表，表达起来容易多了，但明显哪怕我自己看也觉得难以一下子把握要点。）

附注：写完用AI提取一个大纲，实际上我写之前都不知道大纲原来是这个。用AI获得更多选择，的确是我关注重点，但我好像没写出来，但被大纲提取的时候凸显出来了，这个有点意思。

题外话，我觉得普通人对于段落式文字、对于描述性文字，给的分值太多了。如果仅从文字传递信息效率的角度讲，这两者不太好。



### 100

方军 2024-10-18

一个语言的例子，一位老师写：

我最近改雅思作文，有一些同学，想写出这样的句子：让女性和男性有着公平竞争的机会。

然后，一些同学从字面上去对应，就写出了let women have the chances of competing with men equally.

其实，可以使用词组“营造公平竞争的环境level the playing field” 那么用在刚刚的表达里就是： level the playing field for women（给女性营造公平竞争的环境）。

说起来，这是考研阅读出现过的词组。可惜的是，考研行业无论是阅读的学习（不看文章、也能“做对”阅读），还是写作的学习（背一下套话就行），很多学生是不可能接触到这个地道的词组的。

我让AI回答：

polish writing: level the playing field for women

回答：

1. "Create equitable opportunities for women."
2. "Establish a fair and inclusive environment for women."
3. "Ensure equal opportunities for women in all spheres."
4. "Promote fairness and equality for women in the workplace."

以我的英语水平，我会觉得level 过于隐晦，而
4可能更明确一些，至于promote是不是有更好说法，我们可以接着问：

1. "Foster"
2. "Advocate"
3. "Champion"
4. "Facilitate"
5. "Encourage"
6. "Enhance"
7. "Support"
8. "Nurture"
9. "Uphold"
10. "Elevate"

我的水平多半会选advocate

我当然也觉得 foster不错。如果用harness则更好，但觉得不自然。

语言其实最难体现人的水平，悄悄地。

回头再想，1 "Create equitable opportunities for women."也不错。
收起

查看详情
钰博 觉得很赞
方军：换 Claude，它的第一个我还蛮喜欢的：

 "Create equal opportunities for women"
2024-10-18 17:39
方军：我问claude: HOW about" advocate fairness and equality for women"

"Advocate fairness and equality for women" is an excellent polished version of the original sentence. It effectively captures the essence of the original phrase while using more formal and precise language. This version:

1. Uses the active verb "advocate," which implies a strong, proactive stance.
2. Explicitly mentions both "fairness" and "equality," which are the key concepts behind "leveling the playing field."
3. Maintains the focus on women as the beneficiaries of this advocacy.
4. Sounds more professional and could be suitable for a wider range of contexts, from casual conversations to formal documents.
2024-10-18 17:42



### 101

方军 2024-10-18

张一鸣早期的一篇文章，关于信息阅读。虽然他和他的公司是制作信息垃圾和推送信息垃圾的，但他的认识的确很到位，对人性的认识到位。

---

张一鸣/文
虽然不少人表示Google Reader即将关闭的愤慨，但细心一点你会发现，这些正在用Google Reader的用户都是“互联网圈资讯重度用户"。其中,还有不少人说“那上千条买来得及阅读的订阅怎样办"。这些信息其实就从某种程度反应出Google Reader关闭的必然性。
我算是Google Reader国内的第一批用户，它实质就是“用户自订阅”模式。我自己去寻找我喜欢的网站和博客，找出RSS图标，然后点击订阅。但用过一段时候后，随着我订阅的RSS源增多, Google Reader上那好几百上千条的更新我已经看不完。每到这时候,我需要重新把已经订阅的RSS整理一遍，而这个整理的过程挺痛苦的。
我发现，要成为Google Reader常用用户必须具备两个特点：
一、信息组织能力强，明确知道自己想要的信息在哪。
二、自制力强，有规律的整理并能控制好RSS源的数量。
显然,能达到这两个条件的用户并不多。这也是为什么愤慨的Google Reader用户多是媒体从业人员。一款本该面对大众的产品却只能满足的是很小的一部分用户的需求，那就注定不会走得长远。
在我使用过一段Google Reader后，就已经不看好它的前景。这里订阅模式对用户要求太高，用户需要自己去想好“我喜欢什么，我订什么”。
对于那部分有一些兴趣但不是太喜欢的内容到底是订是不订，这也够让用户纠结的。比如我并不想看来自36氪所有文章，我只想看其中跟移动互联网有关的。那我到底是订还是不订呢？
所以，我认为这个订阅过程的用户体验就很不好。
不能否认，作为“订阅模式”代表的Google Reader的离去多少还让人感到遗憾。相比依靠人工仅从门户网站获取资讯,订阅模式其实进步了,但很明显还没能满足大部分人的资讯需求。什么样阅读器更智能更适合大众，将成为Google Reader的替代品？我和我的团队回答是的基于算法的个性化推荐。
已经有不少人在比较甚至质疑，个性化推荐靠不靠谱？机器推荐能不能比人工推荐靠谱？，我想说，一款产品选择什么模式和方法是次要的，最重要的是多大程度上满足了多少人的资讯需求。Google Reader今天的离去,就是这个问题没有回答好。
不过，我觉得拉里·佩奇（Google CEO）很有魄力，关闭了叫好但没希望的产品，一定会在别的方面做的更好。
（作者系今日头条创始人）


### 102

方军 2024-10-18

刚刚跟人讨论，不知道为何说起作家。然后看到对某位作家的评价：

> 从写作水平看，作者是三四流作家（简单说：一流作家，比如曹雪芹、莎士比亚、托尔斯泰、卡夫卡、鲁迅；二流作家，比如毛姆、梭罗、老舍），so，学习的时候，不能因为学到了就满足了，而是要以此为阶梯，更上层楼。

我觉得蛮有意思的，普通人也许应该读一流的（因为是为了鉴赏），作家应该看二流的（因为看二流的可以换位思考，如果是我，怎么写？），但普通人如果为学写作读，也许连二流的作家都不要模仿，而是应该模仿三四流（因为那些技巧反而更实用、能学会）。

红楼梦再好，普通人连碰到边的都没有。当然，人的眼光会变化，以前我觉得金庸讲的故事还行啊，但现在再看一次，他讲故事能力实在太差了，世界构架能力也很差，比故事好点。

其实，今天受欢迎的散文作家、畅销作家可能是七八流的，互联网上那些吸引眼球的文章可能是十七八流的。说个不恰当的例子，比如吴军写书教大家写作，他的文字放在严苛的人眼中，最多五六流吧，但对于不用文学吃饭的人，五六流都够用了。

至于今天说的，AI写的是几流的呢？AI 写的多半是七八十流，哈。而如果一个人用 AI 写，还说自己写的呢？我觉得一百七八流。



### 103

方军 2024-10-19

还是说语言：

maybe langchain team should build a better docs chat to display the ability of LLM, RAG as well as Langchain. 

我社交媒体上回复完就觉得 display 不对，应该是 showcase

果然 AI 给了同样的建议

"Maybe the LangChain team should build a better documentation chat to showcase the capabilities of LLMs, RAG, and LangChain."

capability 也比 ability 要好好。

as well as 我觉得还是比 and 好。

the 我觉得是没必要的

社交媒体回复一般不怎么做重视大小写，一般乱七八糟，没辙。

"Maybe LangChain team should build a better docs chat to showcase the capabilities of LLMs, RAG, as well as LangChain."





### 104

方军 2024-10-19

摘： 词生卡类 prompt 现在真强的可怕，网友 zephyr 空格 做了直出 PPT 的效果

 能够很方便的生成“动物生长过程”等时间线视图

 从信息传达的效果来看，比 Gamma等各类 AI PPT 效果好了太多，非常适合知识教学！

[以「时间」为主题的 Prompt ，可以怎么做？](https://mp.weixin.qq.com/s/BOMOQVGQ5hvd8dDaKwb18A)

这个作者还有一些其他的：（📕想法很有意思，但实用性欠缺，不用实际使用）

[一个 Prompt 搞定架构图和思维模型](https://mp.weixin.qq.com/s?__biz=MzkxMTQ0ODE3Ng==&mid=2247488242&idx=1&sn=cfe2212800684d73eca510acd3242216&chksm=c11d53edf66adafb5ce6a63d9322dec58c29ac1bc0502c3981356ef9fc2c55981c21d7affb6b&scene=21#wechat_redirect)

一个 Prompt 搞定架构图和思维模型

逻辑关系图（图4）：

[Prompt 制作方法：文字逻辑关系图](https://mp.weixin.qq.com/s?__biz=MzkxMTQ0ODE3Ng==&mid=2247488255&idx=1&sn=0af2c1235780db663670e799f4802d73&chksm=c11d53e0f66adaf6a117a10bf37f07ddc0011d0984ec2497c81a2eaeb177e9c3dc3c67cb196c&scene=21#wechat_redirect)



### 105

方军 2024-10-19

很有意思的一点，我看了这位作家很多篇短文之后，我也认同，他是一个三四流、甚至更靠后的作家，原因很简单，因为他基本上就是能够在1500字左右写一篇短文，不论这些短文是好是一般，它们都没有风格，也无法组合起来描绘一个更大的事物。（我也不是很明白，如果抛开纯个人记录，这些短文为何而写？当然这个要求太高了，我们写很多东西也不知道为何而写。）

对比看《至此一年》，其实论文笔，这本书可能更差，整本书就很生动地描绘了一件大事，丘吉尔就任首相一年的情形。这本书背后所做的资料调研，工作量也庞大许多。从书的价值看，《至此一年》要高出很多倍。

如果要说写更大的事物，我觉得盐野七生就厉害得多（从严谨的历史角度来讲，她写的有待专家评论），她叙述一个大得多的事物：一个城邦国家的历史，一个伟大人物的历史，一次庞大的战争等等。

小短文能否连成长文呢？也不是没可能，我一直看着玩的《带一本书去巴黎》，单篇和整体的关系就非常棒。

还是说回 AI，AI 除了在表达、句子上有问题外，还有一个问题就是它的架构不够大，或许这可以戏用杨立昆的词来说，AI 没有世界模型（他愿意更多指空间。）

### 106

方军 2024-10-19

摘：Claude AI 官方推荐的四个应用案例

这四个场景展示了 Claude 在不同领域的应用潜力, 从客户服务到内容管理再到专业领域的辅助。每个场景都利用了 Claude 的核心能力, 如自然语言理解、信息提取和复杂任务处理, 来解决特定的业务挑战。

01 工单路由 (Ticket routing) 
利用 Claude 的自然语言理解能力来大规模分类客户支持工单, 它可以基于客户意图、紧急程度、优先级、客户档案等因素来分类工单。这有助于更高效地处理客户请求, 确保重要问题得到及时解决。

02 客户支持代理 (Customer support agent) 
Claude 作为一个虚拟客服 Agent, 实时处理客户询问。它可以提供全天候支持, 缩短等待时间, 并在高峰期处理大量支持请求。Claude 能够提供准确的回答, 并保持积极友好的互动, 提升客户体验。

03 内容审核 (Content moderation) 
关注如何使用 Claude 来审核数字应用中的内容。内容审核对于维护安全、尊重和有序的在线环境至关重要。Claude 可以帮助识别和过滤不适当、有害或违规的内容,确保平台的健康发展。

04 法律文件摘要 (Legal summarization) 
展示了如何使用 Claude 的高级自然语言处理能力来高效地总结法律文件。它可以从复杂的法律文本中提取关键信息,加速法律研究过程。这对于合同审查、诉讼准备和监管工作都很有帮助,可以节省时间并确保法律流程的准确性。

[Guides to common use cases - Anthropic](https://docs.anthropic.com/en/docs/about-claude/use-case-guides/overview)

### 107

方军 2024-10-19

社交媒体（Twitter）的权重参数

官方文档：

[the-algorithm-ml/projects/home/recap at main · twitter/the-algorithm-ml](https://github.com/twitter/the-algorithm-ml/tree/main/projects/home/recap#readme)

### 108

方军 2024-10-19

这都是纯傻子

摘：一直觉得AI用在创意领域没有太大的问题，很多公司的海报、图片啥的都是AI的了，但是当我在电梯间等电梯的时候，看到了AI生成视频拿来做广告，就觉得很怪很怪，甚至有点惊悚衰（个人感觉）。

这是一个面食品牌，他们用AI生成了一些孩子吃面条的视频，用来表达他们的产品更适合给幼儿食用的。但问题在于，如果你们是食品厂家，应该用自己的实物实拍，而不是用AI生产的视频[淡淡的]。而且AI生成的视频穿帮画面还不少，很难让消费者获得信任。



### 109

方军 2024-10-19


这个人说的 AI 辅助阅读，很简单，但就是这么用，仅此而已：

如果我因为语言的复杂性或未知术语而在某处卡住，我扫描文本并让 ChatGPT 帮忙解释。


### 110

方军 2024-10-19

异步的AI学习书的确超棒

[前三季度图书销售额增长超20% ，我们花7年打造了这条“吸金”产品线！](https://mp.weixin.qq.com/s/VGV9k0JSvBZq8Gt5Oecq3Q)

### 111

方军 2024-10-19

李继刚这个直播讲了不少东西，很全面，推荐：

李继刚全网首播干货分享整理 | Prompt（提示词）的道和术，另附分享彩蛋

如下为AI提取大纲：

李继刚Prompt(提示词)分享的道和术

\## 一、Prompt之道:清晰表达

\### 1.1 表达什么
- read in, prompt out
- 输入是根本,需要大量阅读和积累
- 观察生活,捕捉灵感

\### 1.2 如何清晰表达  
- 文科生和哲学生可能有优势
- 通过框架来描述脑中的概念
- 尼采的视角:事物本质取决于当时社会的诠释

\## 二、Prompt之术:三板斧

\### 2.1 分配角色
- 不分配角色:动作指令
- 分配角色:角色模式(知识域、语言风格、决策倾向等)
- 需要"解压缩"未知角色

\### 2.2 给出示例(few-shots)
- 通过示例让模型理解需求
- 结合描述和示例效果更好

\### 2.3 思维链(Chain-of-Thought)
- 加入"让我们一步步思考"
- 从直觉思维变为逻辑推理

\## 三、彩蛋

\### 3.1 压缩表达
- 修炼法门:段落→句子→词→字
- 效果:精准(embedding)和凝练(attention)
- "得其意,忘其言"

\### 3.2 你是画师
- 把场景当画布,AI当画笔,人是画师
- 人要比AI更有主导权

总结:压缩表达是目前找到的提示词之道



### 112

方军 2024-10-20

我100%赞同纯银，普通人根本不会提问，你会提问就不是普通人，真的。

纯银：大模型很擅长提供答案。
提供答案的前提是，你得给大模型输入精准的目标。也就是经常提到的 “会提问”。目标越精准，回答效率越高。
但憋做梦了。

我这辈子都没遇到几个 “会提问” 的人。包括几年前付费问答流行那阵子，提给我的产品问题都是什么屎？会提问也好，CoT 也好，都是高级技能，从来不指望普通人普遍具备高级技能。

事实上，当一个人 “会提问” 的时候，往往他已经具备了这方面系统性的认知，并且有着缜密的逻辑。我在犬校一直提倡 “用思考交换思考” 的提问，你猜怎么着？很多次，当一个人缜密地把产品问题组织好的时候，他会觉得 “我已经知道（或接近）答案了”。

所以 “会提问” 其实是专业和聪明的一种表现方式，但如果你不专业或者不聪明，大模型是帮不了你太多的。

从产品设计的角度来说，Prompt 传递的目标是否精确，会是大模型应用的基准考量。这就要寻找特定的，意图收敛的场景，用户基于直觉（而不是基于思考）输入精准目标，才有可能把应用的规模做大。思考是一件消耗脑能量的事情，人类的本能就是节约脑能量，超越本能则注定无法规模化运营。

补充一个图，纯银讲的其中一点就是我们之前画的图，有效的提问都是带着一个知识框架去提问。



### 113

方军 2024-10-20

Notebook LM blog上，作者 Molly McHugh-Johnson 分享了她使用这个工具的 8 个专家提示语。 

（相当于营销内容吧。其实我觉得较为一般，没能展现 NotebookLM 究竟可以做什么。我还是那个观点，鼓吹 NotebookLM 的人，似乎都没看过国内的通义这些产品，那些产品才叫卷呢-功能强大的另一种说法，不足就是通义没有抓住转成音频这个大众莫名其妙喜欢的点，反而做了把音频转成文字这个不性感的点。为什么生成一个图，是因为我这个别人翻译的中文根本看不明白，看原文也抓不住要点，所以提取和图示一下。）

- 将最近 10 个文档上传到一个笔记本中，然后提出问题开始尝试。即使最近的文档不相关且完全随​​机。

- 创建一个“全能笔记本”，包含你大多数时间工作的一般知识在内的资源。然后跟它交流，就跟团队中的另一个成员一样。

- NotebookLM 在需要管理、连接和综合来自多个来源的信息的情况下非常有用。比如使用 Gemini 和 Gems 探讨后利用 NotebookLM 整理，再加上谷歌文档的内容，都扔给它整理和整合。

- NotebookLM 的建议问题是一种很好的资源。模型实际上将帮助询问引导浏览材料的问题。直到您想到要询问的问题为止。

- 请求 NotebookLM 以不同的方式提供信息，比如FAQ、简报文件、时间轴、目录、学习指南，甚至播客。

- NotebookLM 也是一个用途广泛的创意工具，在办公室或教室之外也可以很好地使用，很多人在撰写奇幻和科幻小说或开发游戏时使用它，他们在进行世界构建和复杂背景故事工作。

- 将信息源转换为音频概述，只需在音频概述面板中点击“自定义”，输入希望主持人从的来源中关注的要点的简短描述，就可以生成对谈播客。

- 整理跟NotebookLM的记录，你可以在一个笔记本上进行谈话 — 你提出问题，然后追问问题，甚至要求它优化你的想法，在对话结束时，你可以请求 NotebookLM 总结对话中的关键要点，形成一个单一的笔记并放入那个笔记本中。

blog.google/technology/ai/notebooklm-beginner-tips/



### 114

方军 2024-10-20


解读信息是相当难的，尤其是当一个人写的东西和我们日常的习惯不符合时。比如有朋友讨论这个（摘一小片段，见下）。也许有人认为他这个信息很容易懂，但由于我很少看这类表达风格，理解起来很累，用 AI 就可以方便地做转换。或许这么说，有时候我们为什么要上课呢？讲课的人并不是一个领域的原创者，但好的讲课的人是一个有效的转换者。

我推荐的AI解读流程是，提取大纲后，转换为可视化，然后在可视化基础上做小调整。这其实就是李小龙名言：摒弃无用的，吸收有用的,再加点你自己独特的东西进去。（一般“吸收有用的”会被放第一个，但我总会反过来用。）

刚半开玩笑吐槽朋友公司的产品介绍：这个不错的，超赞推荐。但也容我吐槽一句，这个指南真的写得太难理解了，还是我理解力有问题，代码被「混淆」的感觉。我花了好一会儿「解码」：）所以，让 AI 小助理画个图。我还不得不改了下。

```
	从我创建直线系统的那天开始，我不断向参加培训的人灌输的核心原则之一就是：直到潜在客户第一次拒绝你时，销售才真正开始，只有到那时，你才有机会撸起袖子，赚到钱。
	为此，不管你卖的是什么产品，当你第一次向潜在客户请求订单的时候，他们回应你的往往只有三种方式。
	他们可能会说：
	好的——这意味着交易达成了，是时候做好文书工作并收款了。
	一般来说，这些就是我在第二章讲过的现成交易：潜在客户在销售前已经被预销售过了。作为销售人员，我们喜欢遇到这样的客户，但是从实际的角度看，这样的客户太少了，不能在他们身上下太多注。
	关键是要管理好你自己的预期。
	在没有期望这类客户出现的情况下，当他们出现时，你会感到十分幸运。这能确保你以与销售前半段同样水平的确定性和同样的积极心态，进入销售的后半段。
	不——这意味着潜在客户一点儿也不感兴趣，是时候结束这次销售，寻找下一个客户了。
	在现实中，如果你正确地执行了直线系统语言模式的步骤，那么你应该不会被“我不感兴趣”这样的借口打击。毕竟，在资料收集阶段你就已经把不感兴趣的客户剔除了。
	换句话说，在这个时候你要关注的只有那些资料收集问题的答案显示不仅对你的产品感兴趣，并且也能负担得起费用的人。
	所以，那些潜在客户会突然在你跟他们讲了适合他们的一系列好处之后同意交易就不足为奇了，这从逻辑上是说得通的。
	至于精确的比例，你不应该期望过高，有个1%~2%就不错了，跟你遇到的现成交易一样。
	也许，这意味着潜在客户正在纠结中，他们可能做出任何一种选择。这种情况涉及销售人员在销售的后半段能遇见的所有常见拒绝理由。
```


### 115

方军 2024-10-20

有意思的讨论：关于某件事原则上是否可以用深度学习解决的一个好的启发式方法：它是否可以由专家人类 100%凭直觉完成，而无需有意识地思考？

François Chollet@fchollet

https://x.com/fchollet/status/1847364861728346459

A good heuristic about whether something can in principle be solved with deep learning: can it be done by an expert human 100% intuitively, without having to consciously think about it? If yes, then pure pattern recognition is an appropriate approach to the problem, and given enough data you should be able to produce a working DL solution.

Driving -- yes, but perhaps only until the point you hit a rare edge case (which would jolt a human driver back into awareness mode).

Language generation -- yes, but perhaps only at the syntax level. When you speak in a language you're fluent in, you don't think about the words to use or grammar rules, you only think about the idea you intend to convey (you might even be thinking about it in non-verbal form). Words just flow.

Chess -- yes, totally. While mid-level players have to calculate a lot, a top-level player can play extremely well after only spending half a second on each move, just instantly "seeing" the right move on the board.

关于某件事原则上是否可以用深度学习解决的一个好的启发式方法：它是否可以由专家人类 100%凭直觉完成，而无需有意识地思考？如果是，那么纯粹的模式识别是解决该问题的一种合适方法，并且只要有足够的数据，你应该能够产生一个有效的深度学习解决方案。

驾驶——是的，但也许只到你遇到罕见的极端情况（这会让人类司机重新进入警觉模式）那个点。

语言生成——是的，但也许只是在句法层面。当你用一种你流利的语言说话时，你不会去想要用的单词或语法规则，你只想着你打算传达的想法（你甚至可能以非语言形式思考它）。话语就这么自然流出。

国际象棋——是的，完全是这样。当中级玩家必须进行大量计算时，顶级玩家在每步棋上只花半秒钟就能下得非常好，只是瞬间“看到”棋盘上正确的走法。

Mind you, you should only look at what human *experts* do. To solve a problem via pattern recognition, you need tons of experience with it -- whether you've a human or a curve fitted via gradient descent.

Humans with limited experience will use their system 2 fluid intelligence to perform the task -- such as someone calculating in chess, or a non-native language learner having to consciously think about grammar rules when speaking.

So the fact that some, or even most people use deliberate reasoning to perform something doesn't mean it cannot be done with pattern recognition alone.

请注意，你应该只看人类“专家”所做的。要通过模式识别来解决问题，你需要对此有大量的经验——无论你是人类还是通过梯度下降拟合的曲线。

经验有限的人类会使用他们的系统 2 流体智力来执行任务——比如有人在国际象棋中计算，或者一个非母语学习者在说话时不得不有意识地思考语法规则。

---

Julian Togelius @togelius

An interesting corollary to this is that for those tasks where there are no human experts, it is quite hard to know whether the task could be done "intuitivey" by a hypothetical human expert. This is, I believe, the vast majority of tasks, as we humans have only explored a tiny part of task space.

一个有趣的推论是，对于那些没有人类专家的任务，很难知道这个任务是否能被一个假设的人类专家“直观地”完成。我相信，这是绝大多数任务，因为我们人类只探索了任务空间的一小部分。

所以事实上一些，甚至大多数人用刻意推理来做某事并不意味着仅靠模式识别就不能完成。

Akram Artul (50% human, 50% ai)@bate5a55

An interesting example: NASA used AI to evolve antenna designs for space missions, producing shapes no human engineer would intuitively create, yet they outperformed traditional designs.

一个有趣的例子：美国国家航空航天局使用人工智能来为太空任务进化天线设计，产生了人类工程师凭直觉不会创造的形状，但它们的表现优于传统设计。



### 116

方军 2024-10-20


不过，要解读信息真不是思维导图

讲实话，看了通义的导图，我还是很懵的

这样的导图，聊胜于无吧

虽然我夸通义，但它还是没有能有效地“模拟”然后“简化”一个阅读理解的过程。

解释：为什么这个导图不行

我是这么看的：不谈内容就谈形式

导图是为了让人一目了然，但这个图做不到

所以，它增加的价值就相当有限


### 117

方军 2024-10-20

又比如，看到这样一篇文章

（当然，这不是我读的类型，我读不下去这种类型的文章）

对这种文章，AI 提取大纲是足以的，因为：1）信息量不大；2）没有独特的表达

对比芒格的那个人类误判心理学列表，差距就大了去了。并不是说这篇文章不好，是很好，而是说，好的要好太多。

第二条可与前几天分析Paul Graham那篇对比，其实 Graham 那篇信息也不大，但表达太独特了，仔细阅读可能会有改变想法、改变行为的效果。

[聪明人的10个投资原则](https://mp.weixin.qq.com/s/4J9k9uIQXA0DVA-IA01vKA)

这篇文字的说明信息：（作者：本文的框架来自《行为投资原则》一书。该书中规中矩，作者算是聪明、诚恳、正确，读起来也有启发。以下大约有一半以上内容是我的随想。）



### 118

方军 2024-10-20

某老师：12 万字的文稿，给出完整 “编辑建议”，13 分钟跑完了…… 完蛋了，下午有的忙了…… ​​​

看这个透露出来的目录，他果然擅长面对公众，我开始以为他真要讲AI呢，其实不是，还是面向大众讲AI，这是两回事。我自称写过一些大众科普书，但实际上我不知道如何吸引大众，很尴尬。

我也这么帮人这么跑过，不过我自己都是交互式搞

这本书据说叫《人工智能小白书》



### 119

方军 2024-10-20

我们之前画的这个图，刚刚补在之前转发纯银想法的笔记下面，我想这个可能是最为实用的提示语思路。

提示语的一种考量，是 AI 如何理解语言、接受指令，那么我们就按它的给出指令。这是从它的角度出发。

而这个图是从我们自己的角度出发：

第一，我们得在一个特定领域、具体场景中使用 AI，这样才有效。这个出发点很简单，AI再多能力，我们总要在一个具体领域里面用。

第二，我们提问、提出要求时，要自带一套知识框架，这套框架既帮我们提问，也帮我们判断AI 回答的正确性。

有了这个，其实真心是可以自由地跟 AI 交互的，想问什么就问什么。

当然，附上另一个技巧，提问时总是带着足够的上下文。跟 AI 别怕啰嗦，别怕给资料它理解不了。

### 120

方军 2024-10-20

这段对话很精彩：

OpenAI 首席产品官凯文·韦尔表示他们的 o1 模型现在可以撰写以前是每小时 1000 美元律师助理专属领域的法律简报。

Dave Troy：这反映了对此类工作的一种简单化理解。律师不是为了产生成果而获得报酬，他们是为了支持其正确性而获得报酬。你认为他们现在是从零开始写这些东西吗？99%都是从之前的数千份文件中抄袭来的。而且所有这些都必须经过正确性审查。

https://x.com/davetroy/status/1847757438939734432




### 121

方军 2024-10-20

大语言模型本身无记忆能力,需添加记忆机制

LangChain 创始人 Harrison Chase  写了不错关于记忆的介绍与讨论

[Memory for agents](https://blog.langchain.dev/memory-for-agents/)

（他之前还写了一系列文章）

下为 AI 提取大纲：

一. 引言
   1. 介绍智能助理的三大限制:规划、用户体验和记忆
   2. 本文重点探讨记忆问题

二. 记忆的重要性
   1. 记忆系统能记住先前交互细节,提升用户体验
   2. 大语言模型本身无记忆能力,需添加记忆机制

三. 记忆具有应用特异性
   1. 不同应用需记住不同信息
   2. 不同应用的记忆方式也有差异

四. LangChain 对记忆的处理方式
   1. 赋予用户对记忆的低层次控制权和定制能力
   2. 开发 Memory Store 等记忆相关功能 

五. 记忆的类型
   1. 程序性记忆
      - 人类层面: 记住如何执行某项任务
      - 智能助理层面: 智能助理的代码和语言模型权重
   2. 语义性记忆  
      - 人类层面: 长期知识储备
      - 智能助理层面: 个性化应用所需的事实知识
   3. 情节性记忆
      - 人类层面: 回忆过去特定事件
      - 智能助理层面: 记录智能助理先前操作序列

六. 更新记忆的方式
   1. 在响应前更新("热路径")
   2. 在后台更新("冷路径") 
   3. 根据用户反馈更新

七. 记忆对LangChain的意义
   1. 影响智能助理系统的实用性
   2. 在产品中构建相关功能来支持记忆

八. 总结



### 122

方军 2024-10-20

凌乱的邮件收件箱，是不是问题？这个的确值得考虑

A16Z 合伙人的一个分析。不过，我觉得市场需要的不是这样的对原有的改进，而是 Slack 和 Zoom 这种级别的消费创新。

仅仅是作为原有功能的智能化，想象空间太小。

[The Messy Inbox Problem: Wedge Strategies in AI Apps | Andreessen Horowitz](https://a16z.com/the-messy-inbox-problem-ai-apps-wedge-strategies/)



### 123

方军 2024-10-20


有意思，王树义老师分享了一个提示语优化的提示语

我用了一下，在 Cluade Sonnet 上做的优化。效果是这样的：

我常用的这个AI 大纲提示语，被优化成这个，实测效果是一样的：

read thoroughly and write an outline(following the Minto Pyramid principle) in **Chinese** using original words. Return in markdown:

基于文本 → 撰写Minto金字塔提纲 → 中文 → 仅原词 → Markdown格式输出


### 124

方军 2024-10-21


最近有点感悟到，为什么我们也去玩了 Dify/Coze 一下，但没用起来。之前去用的理由大概有：

- 它们提供的丰富的工具，开始是文本加载类的，后来还有与外部API的各种接口
- 它们的Embedding嵌入功能，这个其实蛮麻烦的
- 它们能较为方便与外部连接，比如Coze与Slack的连接，Dify可以方便地与界面连接

当然，还有 Coze 早前的 GPT-4 免费，它们连接到图形生成模型等等。

我们看到很多人用，尤其他们搞出极其复杂的工作流（这两个产品目前都提供了可视化的工作流，有技术基础、但不想编程的人可用）。

但我总是自觉用不起来，可能是恰好处在它们的范围之外：

如果自用，网页的交互式或编辑器里的交互式都足以。

如果是批量使用，LangChain + API，自由度要高很多。如果在  Jupiter Notebook (好像JS也有）里面里，和可视化差不多。

如果要写应用，在 Dify 的工作流上加前端，其实不如自己简单处理。更何况，现在真要给别人用的应用，多半提示工程+RAG就足以满足需求。

当然，我不是看不起 Coze/Dify，它们有自己独特的市场。我一直很欣赏一位朋友，他直接用 Dify 生成产品来为客户服务，甚至都没有在 Dify 上搞个套壳（虽然很容易，不过是fork下Dify WebApp代码的事）。他做得风生水起，蛮好，Dify  给他巨大的赋能，他可以聚焦于自己擅长的服务部分，而不是招技术产品或者勉强找外包开发，这两种都很贵很慢。


### 125

方军 2024-10-21

我一直吐槽，张一鸣开启的算法推荐，导致他可能是最邪恶的科技巨头之一，而且由于tiktok 在全球的成功，这前面还不用加上「中国」二字。

个性化推荐，当然最早是源自于 Facebook  的时间线。

这个人的建议很好：
---
终于找到了一个把小红书仅作为搜索引擎的方法。
入口： 小红书设置 -> 隐私设置 -> 个性化选项 -> 关闭个性化推荐

我关掉是因为小红书的算法推荐很让人上头，但我又需要这个搜索引擎。所以咨询了小红书内部员工能不能出一个纯搜索版，他告诉我可以试试关掉个性化推荐试试，这样首页就变得很无聊。
---

乘风：哈哈哈  方老师  我没明白你为啥会用小红书？
2024-10-21 14:18
方军 回复 乘风：中文信息质量最高的地方之一，也让人心情比较愉悦的地方（当然不是说看美女，不看的，哈哈）

比方说，微博上，大家讨论问题，经常就愤怒起来

小红书的氛围，基本上都是，我看到这个东西特别好，推荐给你（但又不是推销）

这无法不让人心情好
2024-10-21 14:23



### 126

方军 2024-10-21

AI 的三种使用场景：神明、实习生和齿轮

Gods, Interns, and Cogs

这个分类精彩，AI提取大纲如下：

[The 3 AI Use Cases: Gods, Interns, and Cogs | Drew Breunig](https://www.dbreunig.com/2024/10/18/the-3-ai-use-cases-gods-interns-and-cogs.html)

 Drew Breunig 

\# AI 使用场景可以简化为三个不同的类别：神明、实习生和齿轮

\### 1. 神明（Gods）
- 定义：
	- 超智能、自主运作的人工实体
- 特点：
  - 需要巨大的模型
  - 自主性是其定义特质
  - 低容错率
  - 需要广泛、通用的模型
- 发展障碍：
  - 需要突破性进展
  - 需要大量研究人员
  - 需要数十亿美元投资
- 影响：
  - 主要体现在炒作和担忧上
  - 影响融资、监管和政治

\### 2. 实习生（Interns）
- 定义：
	- 由专家使用和监督的副驾驶
- 特点：
  - 高容错率
  - 专注于基础工作
  - 限定于特定领域
  - 模型规模大但不是最大
- 优势：
  - 目前提供AI最大的实际价值
  - 显著提高专家的产出和能力
- 子类别：玩具（Toys）
  - 由非专家使用的实习生
  - 主要用于娱乐，容错率高

\### 3. 齿轮（Cogs）
- 定义：
	- 设计用于无人监督下执行单一任务的函数
- 特点：
  - 低容错率
  - 通常集成在数据管道或界面中
  - 使用微调或高度提示的小型开放模型
  - 运行成本低，部署相对便宜
- 应用：
  - 在企业团队中最常见的AI构建用例
  - 云平台正在积极开发相关工具和硬件



### 127

方军 2024-10-21

图里讲的这位财务经理厉害

[谈谈这周可乐的事情](https://mp.weixin.qq.com/s/oWrD4Bn2LyVIa5VM9Ve0Gg)

黄赟：那年与苏州外企的财务经理面基
约在星巴克

等我去的时候，
超大杯的焦马
已经伫立在桌上了

打过招呼后
对方打开手机
划拉了两下，说

大神，先把红包收一下

我打开手机，1000块钱的转账

还没等我反应过来
他说我设计的数据仓库有性能问题
现在要两个小时才能把数据跑出来

咱也不含糊
上去就把他的代码看了一遍
把该加的索引加上
把维度重构了一下
重新做了ETL 并刷新了数据

所有的查询均在20秒以内
跑出来了数据

对方边看我做边问问题
1小时不到，最后
开开心心带着小秘走了

作者说：这个财务经理很有魄力，
看到拎的一台大约10斤重的笔记本，
我就知道了，他是要干一番事的



### 128

方军 2024-10-21

看到最后呲牙

*在大模型时代里如何管理好奇心*

随着大模型技术的成熟，我们能够更加便捷地在陌生领域获取大量信息。这为学术研究、学习、工作提供了极大的便利，尤其是在阅读专业领域的论文时。然而，大模型的优势也带来了一个新的问题：**信息过载**。在面对海量的陌生概念和理论时，我们很容易陷入“好奇心的陷阱”，被不相关的细节淹没，失去对核心内容的关注。那么，我们该如何有效管理自己的好奇心，避免信息过载呢？

1. 设定明确的学习目标
在开始阅读论文之前，问自己：“我想从这篇论文中学到什么？”明确目标有助于你筛选出重要信息，避免被过多无关的细节吸引。聚焦于论文的核心贡献和研究问题，才能有效避免信息迷失。

2. 划定信息探索的边界
当遇到一个陌生概念时，首先判断它是否是理解这篇论文的关键。如果不是，就可以暂时搁置，集中精力继续阅读主线内容。并且可以建立一个“待进一步研究”的列表，稍后再回过头来深究这些概念。

3. 分层次理解信息
面对一个全新的理论或概念时，不需要立刻深入研究其每一个细节。可以首先获得一个基本的理解，然后再根据需要决定是否进行深入探索。大模型的查询成本很低，但人的注意力是有限的。分层次处理信息，能够在不迷失的前提下掌握核心内容。

4. 设定“信息时限”
为自己设定一个时间限额，每次查询一个新概念时只允许花费几分钟时间。如果在规定时间内无法理解清楚，便将其暂时搁置，避免过多的时间投入到非核心信息中。

5. 保持批判性思维
大模型提供的信息并非都与当前任务相关。面对大模型给出的解释，始终要问自己：“这个信息对我理解论文的核心内容有多重要？”如果答案是否定的，便不应为它投入过多的时间。

6. 集中精力理解核心内容
论文的核心贡献、主要方法和结论往往是最值得关注的内容。其他不理解的细节，除非对核心理解至关重要，否则可以暂时忽略。通过这种方式，能更高效地掌握论文的主要信息，而不是为每一个陌生的术语分心。

7. 使用层次化笔记系统
为了有效管理信息，可以使用层次化的笔记系统。例如：
- **一级笔记**：记录论文的核心问题、方法和结论。
- **二级笔记**：记录关键概念和理论，便于后续深入研究。
- **三级笔记**：记录那些暂时不理解或不重要的细节，以备日后参考。

8. 定期回顾与反思
在学习过程中，定期回顾笔记，反思哪些问题是当前最需要解决的，哪些可以继续搁置。这一过程可以帮助我们不断优化学习路径，且更加高效地处理信息。

by gpt4o

### 129

方军 2024-10-21

156 一个真货和一个假货之间的差别

我们对真货、假货的一个直观感觉，是真 LV 和假 LV 的差别。其实，我听人说过，有些假 LV 做工做得比真 LV 还好，真LV 不过是有品牌正统性。

放在言论、观点、语言文字、知识这些方面，尤其是非科学性、非工程性的领域，判断真货与假货不容易。在科学领域，判断很容易，能重复试验就是对，不能重复就是错。在工程性领域，有效说什么都可以，无效说什么都是“扯淡”（Bullshit），商业管理就很多这种。

AI 来了之后，我们会看到很多「假货」，但它们看起来跟「真货」没啥区别。如果我们按分辨 LV 的方式去判断，就会掉坑里。比方说，波特是世界知名的战略学教授，他说的就是对的吗？不一定啊。

对一个秉承费曼所说的科学思维的人来说，这些不是问题。我理解，科学就是，我们现在有一个暂时还对的答案，然后，如果推翻了它，我们所有人都往前进一步。所以，这个观点谁说的，真不重要。以源头来判断真伪，不是有效的。

那这个时候怎么办呢？我当下的看法有两条：

第一，管它什么，我们都得自己去思考一番，然后我接受了，或我反对了，也许我还达不到很高的程度，但是，我这会儿接受的是我自己思考过的判断，我也愿意为之承担风险。这就是塔勒布所说的“风险共担”、“有切肤之痛”（skin in the game）。

第二，我们竭力地提高自己的辨别力、鉴赏力。

辨别能力是，看到可以的，能够立刻分辨出来，至少不浪费时间在这些东西上面，不管它是 AI 生产的，还是某个奇怪的人生产的。还是引用塔勒布的名言，每个人都要有一个狗屎探测仪（bullshit detector）。

鉴赏力则是很多人经常说的品味，得去看点好的，即便要浪费时间，也要把时间浪费在自己认为美好东西上。当然，品味这个和人的经历、眼界关联很大，你比方说，你跟我说某某小说家，那我是不懂，我就看得懂村上的随笔（他的小说我都不看），不较劲，你让我看什么索尔仁尼琴，我看不懂，这得承认。或者说，马尔克斯我看得懂迷宫里的将军，但百年孤独看不懂的。说歪楼了，回来说，关键是尽量看点好的，或者浪费在自己认为美好的东西上。

有了这两条，应对各种 AI 垃圾足以。当然还有一个实用技巧，但凡是列表、但凡很全面、但凡看着怎么都对（但没细节），这种都可以忽略。即便在社科学术里面，讲这些空洞东西的，就是不入流的。（刚刚那个 GPT4o 生成的，看到最后呲牙*在大模型时代...，我虽然看到最后才发现它是 AI 生成，但其实第一反应就觉得不对了，它的主题吸引我，但开头几句话就让我觉得是劣质货。）

题外话，我引用塔勒布，是我同意他吗？不是，是他用词比较好玩，影响了我，并不同意他。这样的说明其实是需要加的，没辙，因为人家用词的确有吸引力，这得说明来自他，但观点，我们每个具体说较好，没法笼统说赞同或不赞同。



### 130

方军 2024-10-22

157 AI 能有效改写一份烂邮件吗？

fenng 在社交网上上批这个「通知」：这样的烂 IT 人员有什么能力来做电脑选型？ 

我不知道他批评的点是什么，但我看到这样的邮件文字真的很难受，我尝试着改一下，然后让 AI(Claude /Kimi)也改一下，我觉得还是我手工写的好，不过也许用更好的提示语也可以让AI改写好。

```
你好，我是IT，我们在做新一年的公司电脑选型，做个用户使用场景的访谈，让公司的电脑选型能更加贴合实际使用场景，有以下几个简单问题和你了解一下：
1.当前使用MacbookAIR的主要用途是什么？例如个人使用习惯，便携性，10S开发？
2.是否为必须？如果将当前的AIR替换为Windows 笔记本电脑会对个人工作有哪些影响？
```

📕 人工修改：
```
你好，

IT 部门在做新一年公司电脑选型，为了让办公电脑更符合同事们的需求，请你帮忙回答两个关于办公电脑电脑使用场景的问题：

1. 你当前使用 Macbook Air 的主要用途是什么？

- iOS 开发
- 便携办公
- 为客户做演示
- 其他，请您填写

2. 如果将 Macbook Air 更换为 Windows 笔记本电脑，是否会影响你的工作？

- 是
- 否

关于办公电脑的选型，如果您有其他意见、建议，也请直接邮件回复告知。谢谢你的支持！

IT 支持团队
某年某月某日
```

这里有个 Bug，我不认为 Macbook Air 可以支持 iOS App的开发，而且如果是 iOS 开发的话，这个问卷就没必要发他们了。

📕 如下为AI 改写，Claude API ，提示语：“重写如下工作邮件：”

```
尊敬的同事：

希望这封邮件找您一切安好。我是来自IT部门的[您的名字]。为了更好地满足员工需求，提高工作效率，我们正在进行新一年公司电脑选型的调研工作。您的宝贵意见对我们至关重要，因此我想邀请您参与一个简短的使用场景访谈。

我们希望了解以下几个方面：

1. 您目前使用MacBook Air的主要用途是什么？请考虑以下几点：
   - 个人使用习惯
   - 便携性需求
   - 特定工作需求（如iOS开发等）

2. MacBook Air对您的工作是否不可或缺？如果我们将其替换为Windows笔记本电脑：
   - 这会对您的日常工作流程造成什么影响？
   - 是否会影响您的工作效率或某些特定任务的完成？

您的反馈将帮助我们做出更明智的决策，确保新的电脑选型能够最大程度地满足员工的实际需求。

如果您方便的话，请回复这封邮件，分享您的想法。如果您希望进行更深入的讨论，我很乐意安排一个简短的面谈或电话会议。

感谢您抽出宝贵的时间。您的合作对于改善我们的IT资源配置至关重要。

祝工作愉快！

[您的名字]
IT部门
```

📕 如下为AI 改写，kimi网页版，提示语：“重写如下工作邮件：”，不是很好。

```
主题：关于新年度电脑选型的用户使用场景调查

尊敬的同事，

您好！我是IT部门的成员，目前我们正在进行新一年度公司电脑选型的准备工作。为了确保我们的选型能够更好地满足大家的实际工作需求，我们希望能够通过一次简短的访谈来了解您的使用场景。以下是几个问题，希望能得到您的宝贵意见：

1. 请问您目前使用Macbook Air的主要场景有哪些？比如，是否因为个人使用习惯、便携性需求，或是特定的开发工作（如iOS开发）而选择使用它？

2. 您认为Macbook Air对于您的工作来说是必需的吗？如果考虑将您目前使用的Macbook Air替换为Windows操作系统的笔记本电脑，您认为这将对您的日常工作带来哪些影响？

我们非常重视每位员工的反馈，您的意见将对我们的决策产生重要影响。请您在方便的时候回复上述问题，我们将确保您的反馈得到充分的考虑。

感谢您的时间和支持！

祝工作愉快！

[您的姓名]
IT部门
```





### 131

方军 2024-10-22


看到一位AI博士的分享，看介绍在硅谷创业，蛮有意思的：这个周末审了三篇顶级论坛的稿子，因为一作投稿人都需要审稿（1，3略去，是AI算法论文具体讨论）

论文二，我秒拒了，但是我很仔细和客观地描述了对方的观点和我不同意的观点。这篇文章的文学造诣很深，引用了一堆哲学家的理论去谈AI ethics。但问题就来了，很多写AI ethics的作者完全没有系统和algorithm的实战经验。作者提到AI完全由大数据做出来，很多预测结果缺乏人脑会思考的context细节，关于医疗AI，那些不符合mean的数据案例经常被预测错， 神经网络是一个blackbox。这些话其实已经被ethics界说无数次了，作者不断重复这些话有什么作用呢？论文是要有新观点和理论的。关于大数据忽略context，这个是错的，transformers的context window就在不断进步，不然gpt为什么能突飞猛进？神经网络有很多parameters，但绝对不是黑盒子，有很多方法能看出哪一层的哪些parameters对预测结果的影响。关于医疗AI, 目前的最大困难是缺乏足够的数据、统一的标签、统一的数据生成协议，以及对个体在医疗状况上的差异性缺乏全面的理解，想解决bias，就得从这些入手。一篇好的ethics文章，应该是有针对性地指出一个具体问题，批评，对数学有深刻理解，然后提出一些解决方案，而不是像大模型一样重复别人说过的笼统的话。AI fairness， ethics本来是一个对数学和逻辑要求很高的课题，但是感觉不少研究组会招完全没有数理训练的学生来写这种话题。



### 132

方军 2024-10-22

这篇很赞：

[知识工作者如何解决大模型的“幻觉”和“风格”问题？](https://mp.weixin.qq.com/s/nOxSHKj1TXOqOpyNsiaVxQ)


### 133

方军 2024-10-22

提示工程是，把流程串起来，去稳定地解决问题。

今天宝玉发起一个讨论，有句话很有意思：



### 134

方军 2024-10-22

被一个常用编程里面的新方向搞得脑壳疼，理解不了，理解不了 AI 也就很难帮忙，尴尬。

看到 Lencx 这个AI编程讨论，有点意思：

朋友圈看到这样一条动态，我觉得比较真实。那些用 AI 五分钟，半个小时上线一个项目的文案真的只是“文案”…（见图）

https://x.com/lencx_/status/1848007000690712840

如果压根不懂编程，要 fix bug 更不是一两句话能解决的事。

说几个 AI 编程最常遇到的问题：
- 依赖库频繁迭代，GPT 常会推荐一些过时 API ，直接导致程序编译不通。这里需要对 API 文档有一定了解。
- 不涉及编译的纯前端，验证起来很方便。遇到复杂编译的项目，将会有一大堆依赖或环境问题需要解决。
- 遇到程序报错，需多轮反复对话才可能被修复。
- ... 

补充：Noi（他在做的一个开源项目） 算是一个比较复杂的项目，目前源码有上百个文件，其中有一半左右代码都是靠 GPT 辅助完成的。

GPT 特别适合处理子问题，如实现布局或方法（搬砖类），或提供新解题思路。如果你有编程经验，可以将原始大需求剥离成若干子问题，减小上下文依赖，AI 效率还是挺高的（起码比我写的快 😅）。

---

我补充的题外话，很多人不编程的人，都不知道1000行什么概念，即便刨除一半的框架本身代码，1000行是很长很长的代码，人要写非常久，让AI写1000行，肯定是外行。



### 135

方军 2024-10-22

哈，一个好玩的提示语，Claude 自己生成的（采用王树义老师的优化提示语生成）：

```
目标：根据给定推文生成相关定理或效应及其解释

背景：用户提供社交媒体推文，需要AI生成匹配的心理学、社会学或管理学定理/效应

示例输入输出：
输入：工作内容要发生变动了，还不知道能否胜任呢。试试吧
输出：彼得原理：在层级组织中，员工会因现有职位表现而晋升，直到达到无法胜任的位置。

一步步思考：
1. 分析推文主题和关键词
2. 搜索相关领域的定理或效应
3. 选择最匹配的概念
4. 简明扼要地解释该概念

注意：保持输出格式一致，包含定理/效应名称和简洁解释。
```

以下为运行示例：

1. 
```
女士：我们使用敏捷开发（Agile）。
男士：诚实点。
女士：我们为任务实施了SCRUM框架。
男士：我说的是诚实。
女士：我们把瀑布模型拆成了迭代冲刺（Sprints）。
男士：谢谢。
```

标签效应：人们倾向于用新的术语或标签来描述旧的概念或做法，以使其看起来更新、更先进或更有价值，即使实质内容并没有太大改变。

2. 
```
为什么搞独立开发，并且文笔特别好，爱总结的都是前端啊？有人说说背后的门门道道吗？
很少听说搞Java的和搞后端的出来单干….
```

确认偏误（Confirmation Bias）：人们倾向于寻找、解释、偏爱和回忆那些符合自己已有信念或假设的信息，而对不利的信息则倾向于给予较少的考虑。

(注：孕妇效应）



### 136

方军 2024-10-22


手工修改后的提示语：（目前 Claude Sonnet运行效果不佳，GPT-4也很差）

```
分析所提供的社交网络帖子，给出匹配的心理学、社会学或管理学上的定理/效应

示例：
Input：工作内容要发生变动了，还不知道能否胜任呢。试试吧
Output：彼得原理：在层级组织中，员工会因现有职位表现而晋升，直到达到无法胜任的位置。

按如下步骤，一步一步思考，完成任务：
1. 阅读输入帖子两遍
2. 分析帖子主题和关键词
3. 检索相关的定理或效应
4. 选择最匹配的定理或效应，并简明扼要地解释

注意：保持输出格式一致，包含定理/效应名称和简洁解释。
```

输入：

```
为什么搞独立开发，并且文笔特别好，爱总结的都是前端啊？有人说说背后的门门道道吗？
很少听说搞Java的和搞后端的出来单干….
```

Claude 每次给出的最终选择（两次不一样但意思一样的合并了）：

- 霍兰德职业兴趣理论
- 生存偏差/幸存者偏差
- 选择性偏差/自我选择偏差
- 职业锚定理论
- 技能溢出效应

GPT-4 每次给出最终选择：(指令遵循很差，同时每次都出马太效应）
- 马太效应
收起

方军：哈，一个好玩的提示语，Claude 自己生成的（采用王树义老师的优化提示语生成）： ``` 目标：根据给定推文生成相关定理或效应及其解释 背景：用户提供社交媒体推文，需要AI生成匹配的心理学、社会学或管理学定理/效应 示例输入输出： 输入：工作内容要发生变动了，还不知道能否胜任呢。试试吧 输出：彼得原理：在层级组织中，员工会因现有职位表现而晋升，直到达到无法胜任的位置。 一步步思考： 1. 分析推文主题和关键词 2. 搜索相关领域的定理或效应 3. 选择最匹配的概念 4. 简明扼要地解释该概念 注意：保持输出格式一致，包含定理/效应名称和简洁解释。 ``` 以下为运行示例： 1. ``` 女士：我们使用敏捷开发（Agile）。 男士：诚实点。 女士：我们为任务实施了SCRUM框架。 男士：我说的是诚实。 女士：我们把瀑布模型拆成了迭代冲刺（Sprints）。 男士：谢谢。 ``` 标签效应：人们倾向于用新的术语或标签来描述旧的概念或做法，以使其看起来更新、更先进或更有价值，即使实质内容并没有太大改变。 2. ``` 为什么搞独立开发，并且文笔特别好，爱总结的都是前端啊？有人说说背后的门门道道吗？ 很少听说搞Java的和搞后端的出来单干…. ``` 确认偏误（Confirmation Bias）：人们倾向于寻找、解释、偏爱和回忆那些符合自己已有信念或假设的信息，而对不利的信息则倾向于给予较少的考虑。 (注：孕妇效应）
查看原主题
查看详情
方军：我发现我对这个提示语的需求不强， 因为我没有从人家的话里概括一个词，然后显示自己高明的需求。
2024-10-22 21:00



### 137

方军 2024-10-22


荒谬：面对现状，学生们不得不采取各种"自保"措施：有的学生开始录制整个写作过程的视频，有的则保存每一步的修改记录，甚至有学生因为担心被误判而放弃使用合法的写作辅助工具，如Grammarly（因为容易触发误判）。这种本末倒置的现象严重影响了正常的学习过程，也损害了师生之间的信任关系。

[Do AI Detectors Work? Students Face False Cheating Accusations - Bloomberg](https://www.bloomberg.com/news/features/2024-10-18/do-ai-detectors-work-students-face-false-cheating-accusations)

[AI文本检测的困境：当技术偏见遇上教育公平 | RichChat](https://richchat.cc/2024/10/23/do-ai-detectors-work-students-face-false-cheating-accusations/)

来自Bloomberg的最新报道又是AI+教育的主题 - 《AI 检测器误判学生作弊，严重后果令人担忧》

据统计，约 66% 的教师表示经常使用 AI 生成内容检测工具。在如此大规模的应用中，即便是极小的错误率也可能导致大量误判案例，进而造成严重的教育公平问题。

我总结和整理了文中的一些重点内容：

- 看似完美的解决方案背后

24岁的大学生Moira Olmsted因为自己的作业被AI检测工具错误标记为"人工智能生成"而陷入困境。作为一名自闭症谱系障碍者，她那结构严谨、逻辑清晰的写作风格，反而成为了她被系统"误判"的原因。这个案例并非孤例，而是暴露出了AI检测工具在实际应用中的深层次问题；

- 技术的偏见

最容易遭受错误指控的学生可能包括：
   - 像Olmsted一样的神经多样性个体（指在思维、学习和行为方式上与典型发展不同的人）；
   - 英语作为第二语言（ESL）的学习者；
   - 或者只是习惯使用更直白的词汇和结构化写作风格的学生；

斯坦福大学研究人员在2023年进行的一项研究发现，AI检测器在检查美国本土八年级学生所写文章时表现"几乎完美"。然而，同样的检测器却将超过一半非英语母语学生撰写的文章错误地标记为AI生成...

- AI检测工具的技术原理

要理解这些误判的来源，我们需要深入了解AI检测工具的核心技术原理。这些工具主要依靠两个关键指标来判断文本是否由AI生成：
   - "困惑度"（Perplexity）分析 - 这项指标评估文本用词的复杂度和多样性。检测系统认为，AI生成的内容往往倾向于使用更安全、更通用的表达方式，因此具有较低的困惑度值。然而，这种判断标准恰恰可能会误伤那些写作风格严谨、逻辑清晰的学生；
   - "突发性"（Burstiness）分析 - 用于测量文档中语言表达的变化程度。这个指标基于这样一个假设：人类写作通常在句子结构和用词选择上表现出较大的变化，而AI生成的内容则较为均匀稳定。但这种假设忽视了不同写作者的个人风格差异，特别是那些倾向于使用更规范化表达的群体；

- 技术对抗：一场没有赢家的军备竞赛

AI检测初创公司自2019年以来获得约2800万美元投资，主要玩家包括GPTZero、Copyleaks和Turnitin。但随着检测技术的发展，一种新的技术对抗正在形成 - 市场上出现了专门的"AI人性化"工具，声称能够帮助文本绕过AI检测。研究表明，只需在生成提示词中加入少量特定指令，就能让检测工具的成功识别率降至3%。

- 回归教育本质

面对现状，学生们不得不采取各种"自保"措施：有的学生开始录制整个写作过程的视频，有的则保存每一步的修改记录，甚至有学生因为担心被误判而放弃使用合法的写作辅助工具，如Grammarly（因为容易触发误判）。这种本末倒置的现象严重影响了正常的学习过程，也损害了师生之间的信任关系。

我们似乎忘记了最重要的问题：教育的本质是什么？马里兰大学的Adam Lloyd教授提出了一个值得深思的观点：人工智能终将成为我们生活的一部分，与其将精力花在阻止学生使用AI上，不如思考如何将这项技术更好地融入教育过程中。

[Big Take](https://landing.podtrac.com/3mw4ygxn?utm_campaign=socialflow-organic&cmpid%3D=socialflow-twitter-tech&utm_source=twitter&utm_medium=social&utm_content=tech)

\# 大学课程中AI检测工具误判的问题及其影响

\## 核心论点
AI检测工具在教育领域的广泛使用导致误判问题,对学生造成严重影响

\## 支撑论据

\### 1. AI检测工具使用现状
- 约2/3教师经常使用AI检测工具
- AI检测初创公司自2019年获得2800万美元融资
- 2023年相关技术公司融资增长显著

\### 2. 检测工具的准确性问题
- GPTZero和Copyleaks测试显示1-2%误判率
- Turnitin承认有4%句子级别误判率
- 即使小比例误判也会因使用规模导致大量错误案例

\### 3. 特定群体更易受影响
- 神经多样性学生
- 英语非母语(ESL)学生
  - 斯坦福研究显示超半数ESL学生作文被误判
- 写作风格较为机械的学生

\### 4. 负面影响
- 学生遭受学术处罚
  - 成绩清零
  - 学术警告
  - 留校察看
- 心理压力
  - 师生关系紧张
  - 学习体验受损
  - 额外防御措施耗时

\### 5. 应对措施
- 学生方面
  - 录屏证明
  - 修改写作风格
  - 提前自检
- 机构方面
  - 部分学校停用检测工具
  - 开发新功能展示写作过程
  - 强调工具仅供参考


### 138

方军 2024-10-22


批评很严厉啊，对 Perplexity 评价真高啊，但的确如此，我个人体会，深度使用 AI 之后，对阅读内容质量的要求大幅提升：

```
满怀期待想去买某某的新书，一看目录，大失所望
感觉是「某某」内容工厂批量产出的东西
这东拼西凑的目录框架搭好之后，里面的内容让 AI 填充也是轻轻松松
某某只需要一批大咖站台+一群狂热粉丝，就可以完成供需匹配
至于「知识」，反正都是二次嚼烂，免费版 perplexity 足矣
```

我现在对书的要求非常高，非真已经判断高品质，不读。
没必要，给好书多留点时间精力。


### 139

方军 2024-10-23


又看到这段话，之前只关注第一句“AI 应用盈利第一定律：不告诉对方是 AI，依然让对方付钱。”

这次注意到这句：“国内有个 AIPPT，创始人说 20% 靠 AI，80% 其实和 AI 无关。这个场景下，AI 是一个很好的卖点，因为我只用这两个字母，就解释了为什么我这个产品做 PPT 比人厉害。”

---
dontbesilent: AI 应用盈利第一定律：不告诉对方是 AI，依然让对方付钱。

正常的做事逻辑是，张三做一个生意 20 年了，一直在赚，你用 AI 把张三取代了，然后你取代他赚钱。顾客需要知道你是不是张三吗？

什么情况下，一个人会反复强调自己的产品是 AI 呢？大概率就是，这个产品唯一的卖点就是 AI，卖不出去了。

一个日历 App 没人用，改成 AI 日历就有人用了？如果是基于 AI 做应用层，AI 可能不是一个成立的卖点。

反过来讲，什么情况下，后端生产技术可以拿出来当卖点？比如特斯拉的 FSD 纯视觉端到端，比如某电子产品用了特别先进的芯片

这里技术起到的作用是：简单快捷地向众人解释，我为什么牛叉

每次都解释一遍啥是端到端，累人，且不利于传播。干脆直接喊口号：FSD 天下第一！众人皆知。

国内有个 AIPPT，创始人说 20% 靠 AI，80% 其实和 AI 无关。这个场景下，AI 是一个很好的卖点，因为我只用这两个字母，就解释了为什么我这个产品做 PPT 比人厉害。

所以 FSD 这个英文缩写，难道真的是一个技术词汇吗？
我觉得 FSD 是电动汽车领域最牛叉的广告语。

就算有一天，小鹏、鸿蒙真的超越了 FSD，谁又在乎？
---


### 140

方军 2024-10-23

五种 RAG 方式，这个图示很棒

[5 Chunking Strategies For RAG - by Avi Chawla](https://blog.dailydoseofds.com/p/5-chunking-strategies-for-rag?=)

\# 五种常用 RAG 分块策略

1. 固定大小分块
- 按预定义的字符、单词或标记数量分割文本
- 优点：简单实现，便于批处理
- 缺点：可能打断句子或想法

2. 语义分块
- 基于句子、段落或主题部分进行分割
- 使用嵌入向量和余弦相似度确定块边界
- 优点：保持语言自然流动，提高检索准确性
- 缺点：依赖阈值，可能因文档而异

3. 递归分块
- 先按固有分隔符分块，再根据大小限制进一步分割
- 优点：保持语言流畅性，适应不同长度的内容
- 缺点：实现和计算复杂度较高

4. 文档结构分块
- 利用文档的固有结构（如标题、章节）定义块边界
- 优点：保持文档的逻辑结构
- 缺点：假设文档结构清晰，块长度可能不一

5. 基于 LLM 的分块
- 使用 LLM 生成语义独立且有意义的块
- 优点：语义准确性高
- 缺点：计算需求大，受 LLM 上下文窗口限制

### 141

方军 2024-10-23

发现 AI 对这种垃圾信息还是很有鉴别力的。当然，这种鉴别力其实不需要，泡雪球上就没啥鉴别力（这话可错了，因为段永平在上面好多发言）。

但管它呢，反正应对这种信息，一是可以通过屏蔽信息源，二是自己看到就避开，三是真有点疑神疑鬼觉得可信了，让 AI 看下。

这里一个有意思的点事，我们日常生活中不会去费脑力思考这种垃圾信息。但现在好办了，真要展示这是一个垃圾信息，让AI随便搞搞呗。

```
这段文字中运用了几种影响力原理:

1. 一致性原理：作者强调自己的投资哲学始终如一,保持一致性,这会让读者觉得作者是可信赖的。

2. 权威原理：通过展示自己对投资的深入理解和洞察,作者树立了专家形象,增强了自己的权威性。

3. 稀缺性原理：作者提到"有几个人真正跟上了呢?",暗示跟上他建议的人很少,这种稀缺性会增加他建议的吸引力。

4. 社会认同原理：提到"老粉丝应该都知道",暗示很多人已经认同并遵循他的投资理念。

5. 互惠原理：作者分享了自己的投资心得和具体建议,这种无偿分享可能会让读者产生回报的心理。

6. 喜好原理：通过展现专业、一致的形象,作者试图让读者对他产生好感。

这些技巧的运用旨在增强作者的影响力,让读者更容易接受和认同他的观点。
```

批驳
```
1. 过度简化:
   "逻辑硬、预期足、业绩稳"这9个字过于简单化,忽视了投资的复杂性和多变性。现实中,很多因素都会影响股票表现。

2. 自相矛盾:
   作者说不需要关心交易价格,但又提到"预期"。预期通常反映在价格中,这两点似乎矛盾。

3. 缺乏具体证据:
   作者没有提供具体数据或案例来支持他的观点,使得论述缺乏说服力。

4. 忽视市场因素:
   仅关注公司基本面而忽视市场整体走势和宏观经济因素可能导致判断偏差。

5. 自我推销嫌疑:
   文中多次暗示自己的预测准确,有自我吹嘘之嫌,可能影响客观性。

6. 过度自信:
   "越不需要关心交易价格"的说法可能导致投资者忽视风险管理。

7. 选择性偏差:
   只提到成功的预测(如某某产业),可能存在选择性偏差,忽视了失败的预测。

8. 缺乏风险提示:
   没有提到投资风险,可能误导读者。

9. 夸大因果关系:
   将股价简单归因于逻辑、预期、业绩,忽视了市场的复杂性和不确定性。

10. 使用诱导性语言:
    如"有几个人真正跟上了呢?",试图制造FOMO(Fear of Missing Out)心理。
```



### 142

方军 2024-10-23


王凯推荐前端生成工具 v0 (vercel公司产品）时，他这个感悟有意思：

---
说过的ChatGPT让我误信数据，需要重新审视和AI的交互、可信度。我面临的还有个关于AI产品的心理误区：自以为看得多、用得多之后，很容易对新的AI产品轻视。

v0我很早测试过，但我潜意识认为Claude最牛逼，所以玩了下主力还是Claude。这也有问题：过于依赖通用产品后很容易轻视其他优秀的产品。
---


### 143

方军 2024-10-23


我直观地觉得，AI会对管理和商业胡话行业，产生巨大的冲击。商业书只是其中最塔尖的，其实质量还好，下面还有很多，比如HBR的文章，任何一个大型公司内部还有更多更多水下的。

这是因为， AI 太容易生成了，比如如下：


### 144

方军 2024-10-23

大体上赞同这篇文章：OpenAI的"愚蠢"把戏已经把大型科技企业"彻底毒害"了

[OpenAI 的“愚蠢”把戏，已经把大型科技企业“彻底毒害”了\_OpenAI\_Edward Zitron\_InfoQ精选文章](https://www.infoq.cn/article/GiyOQvFzRw355bO5kLus)

(最近还流传两张图，OpenAI的2C订阅占比80%，而Anthropic几乎都是靠API，我的看法是，Claude 模型能力远超GPT系列了。）

OpenAI仓促发布了代号为"草莓"的o1模型，似乎是为了向投资者和公众展示AI革命仍在继续，而非提供实质性的技术进步。

 I. 生成式AI靠什么活着
1. OpenAI靠持续融资维持运营
   - 正在进行65-70亿美元融资
   - 每年亏损超50亿美元
2. 生成式AI模型存在局限性
   - 基于概率,无法根本解决幻觉问题
   - 尚未展现显著商业价值
3. OpenAI匆忙推出o1模型
   - 价格昂贵,效果不佳
   - 暴露了OpenAI缺乏新想法

 II. 科技巨头的两难境地  
1. 依赖补贴维持生成式AI业务
   - OpenAI依赖微软补贴
   - Anthropic依赖亚马逊和谷歌支持
2. 面临投资者对AI盈利能力的质疑
3. 可能采取的两种策略
   - 减少AI相关资本支出
   - 通过裁员等方式维持AI投入

 III. AI次贷危机正在酝酿
1. 整个行业依赖大型科技公司补贴
2. AI产品难以盈利,可能导致价格上涨
3. 可能引发连锁反应,波及整个科技行业

 结论:生成式AI繁荣建立在不稳定基础上,可能给科技行业带来灾难性打击



### 145

方军 2024-10-23

158 让 AI 详细解释流程图

这几天用 AI 大量地解释各种流程图、公式，发现效果不错，如果图示是常见形式、不过于复杂，它的详尽程度超过人。

之前介绍过宝玉的翻译法，我又用 AI 绘制一个流程图（这个流程图很简单），分别如图一、图二。然后，我让 AI 去解释（提示语：“解释如下流程图”），效果相当不错：

```
这张流程图描述了一个多步骤的翻译和校对过程。以下是对该流程的详细解释：

1. Step 1: 英语老师直译
   - 首先，英语老师进行直接翻译，并输出英语老师的直译结果。

2. Step 2: 中文老师意译
   - 接着，中文老师对英语老师的直译进行意译，输出中文老师的意译初稿。

3. Step 3: 英语老师回译
   - 然后，英语老师将中文老师的意译重新翻译成英文，输出英语老师的回译稿。

4. Step 4: 校长校对
   - 校长对前面的翻译结果进行校对。这个步骤包含在一个名为"校长校对过程"的子流程中。

5. 校长校对过程：
   - 这个子流程包含两个决策点：
     a. "是否有表达问题？"
     b. "是否有缺失内容？"
   - 如果这两个问题中的任何一个答案是"是"，流程将返回到校对步骤进行进一步修改。
   - 如果两个问题的答案都是"否"，则流程继续，输出校长校对意见。

6. Step 5: 中文老师修改
   - 最后，中文老师根据校长的校对意见进行修改，输出最终的中文老师翻译终稿。

这个流程图展示了一个详细的翻译和校对过程，涉及多个角色（英语老师、中文老师和校长）的协作，确保翻译的准确性和完整性。通过多次翻译、回译和校对，这个过程旨在提高最终翻译的质量。
```

你可以试下给数学公式、流程图，目前测试的效果均不错。


### 146

方军 2024-10-23


有人毒舌了，这句话是对的， AI 的问题就是太笼统，如果不有效提问，得到都是笼统的没价值的言语。

高认知的穷人说话就和 ChatGPT 一个味儿
每句话都是对的，看完一句话也记不住

补充：我发现现在毒舌都太狠了，某“猪”老师，句句下等人，穷人也是。不过这种毒舌没意思。


### 147

方军 2024-10-23

Claude 的团队其实也蛮有想象力的，AI 用电脑（computer use）。

我觉得意义不大，哈哈。




### 148

方军 2024-10-23

这个有意思

dottxt 和 Hugging Face 合作开发了 outlines-core，是 outlines 核心算法的 Rust 移植版

[Releasing Outlines-core 0.1.0: structured generation in Rust and Python](https://huggingface.co/blog/outlines-core)

[dottxt - make ai speak computer](https://dottxt.co/)

\## 结构化生成的工作原理

核心概念
- 结构化生成保证 LLM 输出遵循特定格式
- 可应用于 JSON、Pydantic Model、正则表达式或上下文无关文法
- 关键在于禁止生成"错误"的 token

示例:生成布尔值
- 目标:生成 "true" 或 "false",不允许其他输出
- 假设 LLM 逐字符生成

生成过程
1. 第一个字符
   - 必须是引号 ",无需 LLM 推理
2. 第二个字符
   - LLM 只能在 "t" 或 "f" 之间选择
3. 后续字符
   - 根据第二个字符的选择,后续字符被唯一确定:
     - 如选择 "t":必须依次生成 "r", "u", "e"
     - 如选择 "f":必须依次生成 "a", "l", "s", "e"
4. 最后一个字符
   - 无论之前的选择如何,都必须是结束引号 "

建议阅读 dottxt 博客和 arxiv 上的相关论文以了解更多细节

### 149

方军 2024-10-23

159 在AI时代更要保持人的真实性

与人讨论，我说早上这么跟人解释：

说明，我用 AI生成的任何东西都是明确标注的。
一种就是这样的标注（图片上），明确说明。
一种就是截图，一看就知道截图的回答。
一种是思维导图，肯定是AI 提取的，我哪会花时间写大纲。

我觉得很多人都还没意识到的一点是，你用AI生成似是而非的垃圾，然后以为可以忽悠别人（领导、同事、客户、老师、社交媒体受众），但最终你会发现，忽悠的是你自己。

谁不知道那些破玩意是AI生成的？只是懒得跟你说而已。形象地说，如果你做过监考，你真心能一眼看到谁在作弊，不是你有多厉害，是特别容易。

在这个阶段，可能有人觉得可以忽悠住别人，但这不是红利窗口啊。这是与魔鬼的交易窗口，还不如没遇到这个窗口呢。

不是不能用AI，是要知道AI用来做什么，不能用来做什么，以及用了AI该怎么标注。

在假人越来越多的时候，保持真实性，最为重要。

- - -

隔段时间就有人说，（在一个事情不知道怎么分析、怎么写出来时）能让 AI 写吗？

我现在的回答统一是：啊呀，不行。AI 搞出来的东西 70 分啊。

我心想，我们自己日常看惯了 95 以上东西，别人也是如此，甚至水平更高， AI 搞个 70 分的东西，能自己满意吗？能忽悠得住别人吗？不可能啊。

70 分这个说法，还是比较有劝说效果的。



### 150

方军 2024-10-23


宝玉做了两段视频，讲解提示语的技巧，110页PPT，很棒

如何写好提示词？（上）
提示词四大要素：指令、上下文、输出格式、角色

如何写好提示词？（下）
四大策略：撰写清晰的指令、给模型思考的时间、将复杂任务拆分成简单的、运用外部工具

网址：

[如何写好提示词？ | 宝玉的分享](https://baoyu.io/blog/how-to-write-good-prompt)

baoyu.io/blog/how-to-write-good-prompt

视频链接见网址中。


### 151

方军 2024-10-23

要把专业知识讲清楚，真是不容易。

看了几个人讲的文稿，虽然说是普及，但是已经变形到基本问题都没讲清楚。这让我都有点怀疑这些鼎鼎大名的学术名人的真正水平，按说他们的学习背景和高校授课背景讲这些不会有问题的。

虽说，普及的本质都是，半外行，讲给外行听。内行没法讲给外行听，因为根本听不懂。但是，如果半外行是很接近于外行那一侧，那情形真的很糟糕啊。

很多搞类似事情的人，都没有意识到，他们这种看似半外行实际上是外行，或者是专业但不用心，这样在有 AI 之后，已经没法混了。

去年看吴恩达的两个课程，AI for Everyone, Generative AI for Everyone, 当时的感觉是，真正的教育专家讲真是不一样啊。

### 152

方军 2024-10-23

更多的图形解释示例，均不错：

图片来源：https://x.com/zhanghaili0610/status/18489973526712...
图片Harry Zhang是采用  onemodel.app 创作的。

图1 解释：

这张图展示了一个生成式AI和大语言模型(LLM)的评估框架。它包含几个主要部分：

1. Dataset（数据集）:
   - Developer Curated Examples（开发者筛选的示例）
   - LLM Generated Examples（LLM生成的示例）
   - User Provided Examples & Feedbacks（用户提供的示例和反馈）

2. LLM-as-Judge Evaluator（以LLM作为评判的评估器）:
   - Reference-free（无参考评估）
   - Ground Truth（基准事实）
   - Pairwise（成对比较）

3. Evaluation Runner（评估运行器）:
   - Metadata（元数据）
   - Evaluators（评估器）
   - Dataset（数据集）
   - Application（应用）

4. Application（应用）:
   - RAG（检索增强生成）
   - Agent（智能代理）
   - Unit Test（单元测试）

5. Score（评分）:
   - 0 or 1（0或1）
   - 0 ... 1（0到1之间的分数）
   - A or B（A或B的选择）

这个框架展示了如何使用多种数据源和评估方法来评估和改进生成式AI和LLM。它包括了从数据收集、评估方法、应用场景到最终评分的整个流程。这种综合的评估方法有助于全面了解AI模型的性能，并为进一步的改进提供指导。

图2解释：

这张图展示了四种不同的评估方法，每种方法都用于评估大语言模型(LLM)在处理检索增强生成(RAG)任务时的不同方面。让我们逐一解释：

1. 答案准确性评估（Answer Accuracy）:
   - 输入问题经过检索器和文档处理，然后由LLM生成答案。
   - 评估器将LLM的答案与预先定义的标准答案（Ground Truth）进行比较。
   - 输出一个0到1之间的分数，表示答案的准确性。

2. 答案有用性评估（Answer Helpfulness）:
   - 与第一种方法类似，但评估重点不同。
   - 使用无参考（Reference-free）评估方法，可能是另一个LLM来判断答案的有用程度。
   - 输出一个0到1之间的分数，表示答案对用户的帮助程度。

3. 答案忠实度评估（Answer Faithfulness）:
   - 这种方法直接将检索到的文档和LLM生成的答案发送给评估器。
   - 评估器（可能是另一个LLM）判断答案是否忠实于提供的文档内容。
   - 输出一个0到1之间的分数，表示答案与源文档的一致性程度。

4. 文档相关性评估（Document Relevance）:
   - 这种方法重点评估检索器的性能。
   - 将输入问题和检索到的文档直接发送给评估器。
   - 评估器判断检索到的文档与问题的相关性。
   - 输出一个0到1之间的分数，表示文档与问题的相关程度。

这四种评估方法共同提供了一个全面的评估框架，涵盖了RAG系统的多个关键方面：答案的准确性、有用性、忠实度，以及检索的相关性。这种多角度的评估有助于全面了解和改进RAG系统的性能。


### 153

方军 2024-10-23

Dexter Yang 的看法：

Claude 的 computer use 跟特斯拉一样，走向了王道的端到端范式。

不需要改造应用的开发框架、分发和运行方式（比如 runtime）去适配 AI（比如面向 AI 暴露专用 API、提供 UI 结构和语义的标注），而是让 AI 来适应为人类设计的工具，像人一样通过纯视觉使用它们，包括电动车、人形五指机器人可使用的物理工具和可影响的物理环境，以及为人类的用户体验而优化的 GUI 应用和软件数字环境。

就像特斯拉的电动车和人形机器人只需要获取纯视觉的交互输入，直接输出规划决策后的行动指令，Claude 模型 computer use 也只需要输入像 GUI 应用截屏这样纯视觉的、非结构化的、粗粒度的输入，直接输出动作指令，而且这些动作指令描述的是如何通过最顶层的面向人类的交互界面去操作应用（比如点击屏幕哪个位置、按哪个鼠标键），这样一方面在端到端的输入侧和输出侧都完全等价于人类，不需要额外信息和接口，一方面可以泛化的支持现有的和未来的相同交互范式的任意应用。为了支持 AI，应用之间也只需要在交互范式上保持一致（原本就是一致的），不需要在内部数据结构、UI 设计等具体业务逻辑中去引入一致性约束、做标准化改造。

在这种端到端范式下，纯视觉数据越多越受益，交互中纯视觉占比越大越实时越丰富覆盖的场景越多越受益。

XR / 空间计算平台这种融合了物理现实环境视觉画面和虚拟数字画面的多模态交互平台上，纯视觉的信息输入恰好是最多的（等价于有同类传感器的汽车形态/人形的机器人），可以把任意时刻的双目画面帧直接输入给 AI，让 AI 结合当前周围环境（除了现实环境，还有运行中的软件应用窗口、局部 3D 内容、乃至纯 VR 内容）做大量事情，包括自动「发现和推荐」相关应用功能/内容、自动「增强」现实环境、跟虚拟数字内容自动「交互」，乃至把当前环境中原本复杂琐碎多步骤多层级的细粒度的软件交互过程，自动封装成粗粒度的单次交互（卡片 UI、自然语言）。

不过，引用中提到的语义化、URL、强约束开发框架的优势，还不会受影响，仍然是 AI 友好的 GUI 应用需要的。因为这些语义化结构化的信息，即使在自动化「交互」中不再需要了，在自动化「发现」和「分发」中还是需要用到的。Apple 的 App Intents 很大程度上也是这种用途，让 OS 能发现、注册、索引第三方应用的具体功能和需求，能在相关场景中自动调起或推荐。AI 不仅可以帮你「use」，还可以在海量应用功能和内容中帮你「发现」、帮应用开发者「分发」，后者很多时候才是主要的使用门槛。「use」面向的是少量、有限的交互范式，「发现」和「分发」面向的是海量、趋向无限的功能/内容池和应用状态组合，后者更难纯粹通过模仿人类的方式来实现（人类本来就不擅长这个，像我这样的人肉分类器太少了……）

[(2) X 上的 Dexter Yang：“Claude的computer use跟特斯拉一样，走向了王道的端到端范式。 不需要改造应用的开发框架、分发和运行方式（比如runtime）去适配AI（比如面向AI暴露专用API、提供UI结构和语义的标注），而是让AI来适应为人类设计的工具，像人一样通过纯视觉使用它们，包括电动车、人形五指机器人可使用的物理工具和 https://t.co/EtP0B28WqJ” / X](https://x.com/dexteryy/status/1849137399785488858)

### 154

方军 2024-10-24

王树义老师对 科研 x  AI  的分享

AI 提取大纲供参考

他的直播后工作流出的文字稿：

[让我们来聊聊诺奖如何看待AI...](https://wx.zsxq.com/group/5825428444/topic/2858245415852841)

（题外话，别人让我审核一个我自己的直播文字稿，生不如死啊，我一直没审呢，有了AI 为什么我还要干那样麻烦的事。）

---

王树义

2024-10-24 11:22

让我们来聊聊诺奖如何看待 AI，以及它对你的科研工作会带来什么影响。

你知道吗？诺奖对 AI 的认可不仅仅是对顶尖科学成就的肯定。现在，让我们把视角转向你我这样的普通科研工作者，看看 AI 能如何改变我们的日常工作。

很多人喜欢把 A1 称为「助手」，我更愿意用「帮手」这个词。不过你可能会发现，即便是这样一个看似基础的定位，也有人持保留态度。

通过全国各地的高校讲座和与科研人员的深入交流，我深刻体会到了一个现象：虽然 AI 的未来已经到来，但并不是人人都能享受到它带来的便利。你能想象吗？到今天还有研究者在坚持完全传统的工作方式，仅仅使用一些基础的自动化工具。

那么，AI 作为你的研究帮手，能做些什么？让我们从科研工作的基本流程谈起。不论你从事哪个学科，这些流程都是共通的：知识输入、知识处理和内容输出。

想想看，你平时是如何搜集资料的？查找论文、阅读文献、参加学术会议，这些都属于知识获取的环节。以查找论文为例，许多高校都开设了科技英文课程，教授学生如何检索国际文献数据库。可是你见过这样的情况吗？一些刚入门的研究生常常面临着语言障碍，在文献检索时举步维艰。

你想知道这个研究主题是否值得投入时间精力吗？让我来告诉你一个科学的探索方法。

当你有了一个初步想法，你会想到几个关键词。把这些词输入文献库，看看检索结果。如果发现没有与你想法重合的内容，你可能会感到欣喜 —— 这意味着你找到了一个研究空白，对吧？但要小心了，这种判断可能有陷阱。

为什么这么说呢？因为同一个概念可能有不同的表述方式。如果你不了解这一点，很可能错过了已有的相关研究。

这个问题被发现的时机不同，造成的影响也不同。在开题时发现还好，但如果到了答辩时才被指出，那就会很棘手了。

不过现在你有了更好的选择。试试看 Perplexity 这个工具，切换到它的 Academic 模式。你甚至不需要苦恼英文翻译，直接用中文输入你的研究主题，再加上一些简单的引导词，它就能帮你找到最相关的论文，还能按你的时间要求筛选。对初学者来说，这能节省大量查找和翻译的时间。

当你构思出一个论文题目后，你还可以用它来验证选题的独特性，确保没有过度重复别人的研究。更棒的是，AI 还能帮你进行头脑风暴，在现有研究基础上开拓新思路。

如果你想了解更多，可以看看我在得到平台上的最新视频课程，那里详细讲解了如何用 AI 来开拓和验证科研选题的具体流程。这些都属于知识输入环节。说到知识处理，黄老师刚才提到了一个观点：想要更好地使用 AI，现在就要学习数据分析和机器学习。

这让我想起以前的经历。我曾经带过一些非信息管理专业的学生，教他们使用 AI 来分析数据并做可视化展示。有趣的是，很多学生都感到震撼 -— 他们发现即使是文科生，没有 IT 背景，也能熟练运用这些分析工具。说实在的，对初学者而言，现在的 AI 在某些分析任务上的表现，有时甚至比人工操作更出色。

想让 AI 帮你建立机器学习模型来进行预测或分类？你会发现，它的规范化流程比许多初学者更加严谨，得到的结果往往也更加可靠。

在选择模型方面，AI 能够准确判断什么样的数据该用什么样的模型，这一点比刚入门的学习者要专业得多。所以你完全可以把数据分析的任务交给 AI，你只需要负责验证结果的正确性。

关于这些内容以及第二大脑等相关话题，你可以在我的 B 站视频或「玉树芝兰」视频号上找到更多详细信息。

谈到输出的环节，包括论文写作、翻译和作图等。你知道以前的导师是如何体现负责任的吗？就是把研究生的论文用红笔改得像大花脸一样：从整体架构到段落顺序，从参考文献到语义表达，甚至是错别字，都会被仔细批注。

现在你可以在提交给导师之前，先让 AI 帮你检查这些基础性错误。不妨试试 GPT Canvas，你甚至不需要输入提示词，它就能自动为你逐段检查并给出修改建议。

当你觉得建议合理时，只需一键就能完成修改。在写作过程中，你还可以让 AI 模仿特定的写作风格，包括你自己之前的风格或其他专家的风格。你也可以让它帮你组织和安排文章的逻辑结构。

我之前介绍过如何使用 O1 Preview，能够把零散的检索内容直接整理成一篇博客或文献综述，形成一个类似奏章的清晰文档。这个流程非常顺畅，使用的是我自己开发的 Python 工具。

你也可以选择使用 Dify，本质上只是工作流程的差异。AI 还能帮你做翻译工作。最近我在宁波与一位博士生交流，他提到他们实验室此前很少发表一区论文。你知道是什么原因吗？

还记得那些让人头疼的一区论文投稿经历吗？中式英语总是会让审稿人皱眉。不过现在你有了新帮手，ChatGPT 正在改变这个局面。有位研究者就是这样，借助 AI 优化语言表达，他们的一区论文顺利通过了审核。

你能感受到 AI 带来的巨大改变吗？回想一年前的 AI 还很有限，而如今它能帮你完成许多过去难以实现的任务。这不正说明了 AI 确实可以成为我们得力的助手。

要说 AI 的进步有多大，我刚看到一个有趣的视频：一位演员的表演原本表情僵硬，可是经过 AI 处理后，无论是青春的羞涩还是笑中带泪，每个表情都栩栩如生。网友们都在说，以后拿张照片就能演戏了。

你看，这些都是 AI 现在就能做到的事情。关于当前最先进的生成式 AI 和大语言模型是否具备推理能力，学界还存在争议。但要知道，今天的局限不代表明天的可能。

对于从事科研工作的你来说，建议尽早开始使用 AI 作为助手，它确实能带来很大帮助。但有一条重要底线：不要把 AI 当作你的枪手。有些人过度依赖 AI，让它包办所有工作，甚至不加验证就直接提交或发表，这种做法存在很大风险。

为什么说这样做很危险？因为「文则自负」，作为作者，你要为文章中的所有错误负责。AI 偶尔会犯下令人触目惊心的错误，所以你一定要做好最后的把关工作。

去年一些期刊的做法值得思考。与其简单禁止使用 AI（这种做法可能会误伤优秀作者），他们采取了更明智的应对方式。你想知道他们是怎么做的吗？

想知道如何更好地运用 AI 来协助工作吗？让我们一起来探讨人机协同的妙用。在提交作品时，你当然不能把 AI 当作主角。不过，这恰恰给了你一个绝佳的机会 -— 让人负责创意和推理，而把那些重复性的琐碎工作交给 AI 处理。

你一定好奇 AI 具体能做些什么。它可以成为你的得力助手：根据指令不知疲倦地进行训练，预测蛋白质的三维结构，还能运用自蒸馏方法不断优化，有点像 AIphaZero 那样左右互搏来提升自己。

更实用的是，它能帮你从海量图片中提取特征，建立模型。你写作时遇到瓶颈了吗？AI 可以学习不同的语言风格，协助你改进文本，提升内容质量。

不过，这里有个重要提醒：你既不要低估 AI 的能力，也不要过分高估它。特别要注意的是，千万不要把它当成你的枪手。现在的 AI 能力还有限，但正是这种限制让我们能够与之良性互动。对你这样的科研工作者来说，这是个难得的机遇 —— 因为这意味着你的专业价值依然不可替代。

你有没有想过这样一个问题：如果有一天 AI 真的具备了推理能力，会发生什么？那时候，或许才是很多科研工作者真正需要担忧的时刻。

### 155

方军 2024-10-24


一个很有意思的观点，这几天又再次看到：

Reality Without Frameworks

我理解，别被以前的框架（或心智模式）所束缚，看到真的现实。

AI 小助理帮我整理得个乱七八糟，但我相信懂的人能懂，哈哈，废话一句。

```
\# 不依赖框架理解商业现实

\## 1. 商业概念的本质
   - 商业是人为构建的游戏
   - 受经济现实、社会和技术环境影响

\## 2. 避免理想化商业模型的陷阱
   - 警惕将亚洲商业与理想化模型比较
   - 现有商业讨论文化倾向于抽象化
   - 一些经营者被框架和模型限制思维

\# 有效的人 vs 理论追求者

\## 1. 有效的人与理论追求者的对比
   - 有效的人接受有用的方法，不急于理论解释
   - 理论追求者渴望为一切建立模型
     - 喜欢谈论最新的模型/框架/理论
     - 听起来很复杂，但实际效果不佳

\## 2. 更正确的对模型的态度
   - 不要太关心模型本身
   - 世界充满模型，许多人头脑中充满糟糕的模型
   - 建立缺乏认识论防御机制，抵御各种模型的入侵
```


### 156

方军 2024-10-24


摘：之前曾经读到过一篇令人唏嘘的文章（见截图），讲的是当年 google 一个宏大想法：把人类所有的书都扫描做成电子版，供世人阅读。这个项目因为触动了太多蛋糕而作罢。已经被扫描的2500万本书，被尘封起来，没人可以阅读（想付费阅读也不行）。

到今天 10年不到，当年这些蛋糕的价值无限趋近于零。所有的书估计都成为了各家大模型的训练素材，嵌在模型的记忆中。那些书再也不会有人读了。想要查阅的话，跟模型聊几句就够了。


### 157

方军 2024-10-24

悲伤的故事，同时觉得，在AI上我们可能会被针对，实际上已经是如此。

摘：Linux内核开发者Serge Semin的告别信 

[linux: Goodbye from a Linux community volunteer - Serge Semin](https://lore.kernel.org/all/2m53bmuzemamzc4jzk2bj7tli22ruaaqqe34a2shtdtqrd52hp@alifh66en3rj/)

“Hi，Linux 内核社区，

我相信你们已经听说了最近由 Greg 提交所引起的风波。正如你们可能注意到的那样，这次变更涉及移除了一些与 Ru 相关的开发者作为官方内核维护者的资格，包括我自己。

社区成员们正确地指出，这份_非常_简短的提交记录中使用了非常模糊的措辞，并没有给出明确的变更理由。无论我多么努力地尝试获得更多的细节，遗憾的是，与我讨论此事的资深维护者并没有解释这些合规要求是什么。我不会引用具体的邮件文本，因为那是私人通信，但关键词是‘制裁’、‘抱歉’、‘无能为力’、‘咨询你的（公司）律师’……我不能代表所有受此变更影响的人说话，但我的工作在过去一年多的时间里完全是_志愿性质_的（在此之前不到一半的工作是有报酬的）。因此，我没有（公司）律师可以咨询，并且坦率地说，在补丁被悄悄合并之后，我现在也不想要去咨询了。在所有人背后默默地进行，绕过了标准的补丁审核流程，没有任何受影响的开发者或子系统被通知——这确实是处理这件事最糟糕的方式。没有感激之情，没有对开发者多年来奉献工作的认可。不管情况的原因是什么，但我们难道不值得更好的对待吗？至少在 GREDITS 文件里加上我们的名字，不是吗？

我不相信内核资深维护者们没有考虑到这个补丁会被注意到，并且这种情况可能会失去控制，给社区带来不可预测的结果，如果不是立即发生，那也是在中期或长期的视角下。我相信有很多方法可以更少伤害地解决问题，但他们选择了最容易的道路。一年前悄然开始的分歧点现在已经被完全实施。这种情况的原因显然是基于政治基础的，而这无疑破坏了社区最初建立的基础。如果这样，天知道接下来会发生什么（谁还会被制裁……），但实施的行动显然向Linux社区的新来者，以及像我这样的已经在工作的志愿者和爱好者发出了一个不好的信号。

即使现在我仍然有可能发送补丁或做一些评审工作，但经过这样的事情后，我作为志愿者继续这样做的动力已经完全消失了。（虽然未来我可能会做一些商业上的上游工作。）但在告别之前，我想对我有幸在这几年中一起工作的所有社区成员表示感谢。具体来说：

NTB 同仁，Jon，Dave，Allen。NTB 是我在内核上游工作中起步的地方。感谢你们最初的建议，尽管经历了非常-非常-非常艰难的评审，包括几次完整的补丁集重构，但我从中学到了很多。这段经历对我后来的工作帮助很大。非常感谢你们。顺便说一句，从那以后我收到了几封感谢信，感谢我对 IDT NTB 和 IDT EEPROM 驱动的贡献。如果没有你们，这是不可能实现的。

Andy，你在我的 Linux 内核之旅中给予的帮助无人能及。我们第一次见面是在我的 DW I2C 驱动补丁的 I2C 子系统的评审过程中。之后我们在很多地方频繁相遇——GPIO，SPI，TTY，DMA，NET 等等，清理/修复/功能补丁集。你在最初的评审中提出的热烈讨论确实让我抓狂。但我们总是设法达成某种共识。你从不放弃讨论，冷静地一遍又一遍地解释你的观点。你从未拒绝提供对你请求/评论的更详细的理由，尽管你不需要这样做。由于这些，我学会了如何对评审者和被评审者保持耐心。当然也要感谢你分享的所有关于 Linux 内核的知识和技巧。

Andy，请注意，由于目前的情况，我将不再继续我的 DW DMAC 修复补丁集的工作。所以如果你希望将来能够稳定地使用 DW UART 与 DW DMA 引擎驱动，你可以自由地接手这个系列。

Linus（Walleij），在你合并了我的一个相当大的补丁集后，你建议我继续维护 DW APB GPIO 驱动。这是我第一次被要求维护一个非我编写的驱动。感谢你的信任。我永远不会忘记这一点。

Mark，非常感谢你把 DW APB SSI 驱动的维护工作交给我。我投入了大量的精力使其更加通用，减少错误，特别是在 DMA 引擎控制或 mem-ops 模式下工作时。我相信从那时起，这一成果对许多 DW SPI 控制器用户都是有益的。

Damien，我们第一次也是最后一次会面是在我的通用 AHCI 平台和 DW AHCI SATA 驱动补丁的评审过程中。你并没有让这条路变得轻松简单。但是所有的评审评论都是基于技术层面的，最终补丁被合并了。感谢你的时间以及我从中获得的经验。

Paul，Thomas，Arnd，Jiaxun，我们在我的 MIPS P5600 补丁和通用 MIPS 补丁的评审过程中有过几次交流。与这些领域的杰出专家讨论总是令人愉快的。遗憾的是，我花太多时间在其他子系统的补丁上，未能提交所有 MIPS 相关的部分。对不起我没有履行承诺，但正如你所看到的，情况突然间有了它自己的期限。

Bjorn，Mani，我们在 DW PCIe RC 驱动框架内做了大量的工作。你审阅了我的补丁。有一段时间我也帮助你审阅其他补丁。尽管有一些争论，但与你们共事始终是一种乐趣。Mani，特别感谢你合作进行 DW eDMA 驱动的维护。我认为我们一起做得很棒。

Paolo，Jakub，David，Andrew，Vladimir，Russell。网络子系统，尤其是 STMMAC 驱动（毫无疑问这个驱动有问题）成为了我当前 Linux 内核活动的一个障碍。我真的希望至少在某种程度上，我对即将发布的 STMMAC 和 DW XPCS 补丁的评审有所帮助，减轻了你们的维护负担。我知道 Russell 可能不同意，但我真诚地认为我们所有的讨论最终都是有用的，至少对我来说是这样。我也认为我们与 Russell 在 DW GMAC/QoS ETH PCS 补丁上的合作做得很好。希望你们最终能找到时间完成它。

Rob，Krzysztof，从你们的评审中，我学到了很多关于内核中最硬件部分——设备树源文件和设备树绑定的知识。你们所有的评论都简洁明了，这让评审变得快速而容易。非常感谢你们。

Guenter，特别感谢你审阅并接受我提交到 hwmon 和 watchdog 子系统的补丁。与你共事很愉快。

Borislav，我们意见不合并争论了很多。因此我的 DW uMCTL2 DDRC EDAC 补丁甚至陷入僵局很长时间。不管怎样，感谢你花时间审阅我的补丁，并试图解释你的观点。

Borislav，看来我无法再继续我的 Synopsys EDAC 补丁集的工作了。如果你或其他人能接手并完成这项工作，那就太好了（你可以在 lore 存档中找到它们）。这些补丁主要是将特定于 Zynq(MP) 的 Synopsys EDAC 驱动转换为支持通用 DW uMCTL2 DDRC。这对基于该控制器的每个平台都是非常有益的。
Greg，我们在邮件列表中有过几次接触。你审阅了我提交给 USB 和 TTY 子系统的补丁，每次过程都很直接、专业，并且比我在大多数情况下要简单得多。非常感谢你。

Yoshihiro，Keguang，Yanteng，Kory，Cai 和所有我在内核邮件列表中遇到但在这里没有提到的每一个人。感谢你们花费时间共同致力于使 Linux 内核变得更好。在这里遇见你们是我的荣幸。

我还想对那些努力为被踢出的维护者辩护并在这些天里表达了支持的社区成员表示巨大的感谢。这对我们意义重大。

最后附上一点我的内核工作的统计：

已签署的patche：518
已审阅并确认的patche：253
测试过的patche：80

你可能会说，与一些其他开发者相比，七年的时间里这不是最大的成就。也许吧。但我保证，这些标签我都认真对待。

我想这就结束了。如果你将来需要有关我曾经维护的驱动程序、相应的硬件或 Synopsys IP 核心的信息或咨询（关于这一点，我现在已经有了相当全面的知识），请随时通过这封电子邮件联系我。我总是愿意帮助社区成员。

希望我们能在更愉快的情况下见面，一起喝几杯啤酒。但现在是时候说再见了。对不起，这是一篇很长的文章。祝你在 Linux 之路上好运。

最好的祝愿，
-Serge(y)”



### 158

方军 2024-10-24

在 Charactor.ai 青少年自杀事件之后，再看这个文章的观点，觉得是鬼故事。

太糟糕了

[十问“AI陪伴”：现状、趋势与机会](https://mp.weixin.qq.com/s/zcSMerSKX30P2Hrwhoh0TA)

### 159

方军 2024-10-24

我觉得 AI 提取大纲还是很必要的，讲实话，这个文章我应该读，但真是不想读的。

[做成大事的秘诀：慢思考、快行动](https://mp.weixin.qq.com/s/Cd_qYpsG8w-s7UcGxg4c8w)

AI 提取大纲扫一眼了事，1分钟。

前一段看了几个拖沓严重项目的视频讲解，蛮有意思的，德国柏林那个机场真是堪称有史以来最拖延项目的第一名。



### 160

方军 2024-10-24


在徐老师那儿看到的截图（作业本/文），中文社交媒体上基本上都是该文批的垃圾。我微博屏蔽关键词根本都不够用，不知道微博为什么孜孜不倦地推送娱乐信息、家长里短的那些信息。极度无聊，屏蔽不住。作业本这个也别看，看看大纲吧，大纲也有这种效果，它是个好筛子，筛掉垃圾，作业本的信息质量也属于极差类别。

我的建议(3条）：

- 别看视频，视频都是垃圾堆。
不说短视频了，就所谓中长视频，10分钟的，明明一分钟说明白的事。

- 别看那种带钩子的叙述文章。
看着写了一长段，其实家长里短。

- 别看绝大部分社科文章
当然有极多金子，但99%都是乱七八糟绕口令写老长一堆。这个特别难辨别!

另外，我是坚定地认为，尽可能把信息搞得别人容易接受，是一个人的本分。

我最近有点不那么在乎了，大大方方推荐《拒看新闻的生活艺术》，还是那句话，这不是对新闻、新闻专业人士及新闻学专业的判断，这是一个人的信息摄取选择。

我们这些相对熟悉新闻传播的人其实知道，早年的传播学里面有个经典故事，CNN 在报道外面的冲突，战火纷飞、抗议声隆，然后走出酒店一看，街头十来个人的小把戏。忘记书叫什么了，应该是一本很经典新闻传播专著。我为什么印象深刻呢，是朋友当年阿拉法特还在世时去采访巴以冲突，现场遇到这样的场景，后来给我们复述的。


### 161

方军 2024-10-24

Google DeepMind 开源了 SynthID 文本水印工具，用于帮助开发者和企业识别他们的 AI 生成内容

问题：由于LLM生成的文本质量越来越高，难以与人类撰写的内容区分，这可能导致信息生态系统出现问题（如假信息传播、未经授权使用等）。

解决方案：通过Tournament sampling算法在生成过程中注入独特的统计特征水印，同时保证不影响文本质量，使得生成内容可被快速识别，且该方案已在Gemini等大规模生产系统中得到验证。

[(2) X 上的 Google DeepMind：“Here’s how SynthID watermarks AI-generated content across modalities. ↓ https://t.co/CVxgP3bnt2” / X](https://x.com/GoogleDeepMind/status/1849110265645678807)

发表在  Nature 上的论文：

[Scalable watermarking for identifying large language model outputs | Nature](https://www.nature.com/articles/s41586-024-08025-4)

图为对论文做的 AI 大纲提取

一个网友的解读（有删节）

https://x.com/richardchang/status/1849457392993677...

[(2) X 上的 RichChat：“我两天前刚写过Bloomberg报道的《AI 检测器误判学生作弊，严重后果令人担忧》，尤其其中提到“OpenAI 近期表示，出于对特定群体可能受到负面影响的考虑，公司决定暂不发布 AI 写作检测工具。其中特别提到了英语非母语（ESL, English as Second Language）学生群体可能会受到影响。”” / X](https://x.com/richardchang/status/1849457392993677386)

 一、回顾一下LLM的文本生成
普通的AI文本生成很简单：
```
输入 → AI模型 → 概率分布 → 选词 → 加入文本
```

二、带水印文本的生成过程1. 幕后准备
首先，系统会准备两个关键工具：

a) 水印密钥（Watermarking Key）
- 就像节目组的"密码本"
- 用来确保水印的唯一性和可追踪性

b) 随机种子生成器（Random Seed Generator）
- 类似于"随机数生成器"
- 基于已生成的文本和水印密钥为每个新词的选择提供随机性

2. 选词锦标赛流程

想象一个三轮制的选词竞赛：

第一轮：候选人准备
```
候选词        原始概率(PLM)    随机函数评分(g1,g2,g3)
芒果(mango)    50%           1, 0, 1
荔枝(lychee)   30%           0, 1, 0
木瓜(papaya)   15%           0, 0, 1
榴莲(durian)    5%           1, 0, 0
```

第二轮：锦标赛赛制
1. 从AI模型抽取8个候选词（可重复）
2. 两两配对，使用g1函数打分；
   - 如：芒果(1) vs 荔枝(0) → 芒果晋级
   - 榴莲(1) vs 木瓜(0) → 榴莲晋级
3. 胜者进入下一轮，使用g2函数评分；
4. 最后一轮使用g3函数决出最终赢家；

3. 水印特征的形成

这个过程巧妙地在文本中留下了"统计指纹"：
- 每个选词都受到随机函数(g1,g2,g3)的影响；
- 这些影响很小，不会破坏文本的自然性；
- 但在统计层面形成了可检测的模式；

三. 文本水印检测

1. 使用同样的水印密钥；
2. 计算文本中每个词的g函数得分；
3. 如果发现词的选择上总是倾向于在锦标赛中得分较高的选项，就说明文本可能带有水印
4. 这种统计特征在单个词上很微弱，但在较长文本中会形成可检测的模式；

四. 优势和局限性

相对我之前文章中提到的很可能会造成教育公平问题的GPTZero等通过Perplexity和Burstiness来分析文字是否由AI生成的方式不同，SynthID的这套模式确实更可靠了，但是依然也有其局限性：

- 需要AI服务提供商主动采用这项技术，因为必须在生成阶段嵌入水印；
- 依然可能被规避：如果文本经过大量编辑或改写，水印可能会减弱，以及特意设计的对抗性攻击可能破坏水印
- 虽然Google的paper并没有明确提出人类文本误判率的相关技术局限性，但统计特征的相似性和水印系统的稳健性都是依然存在的担心点，希望相关研究人员能专门就特定人群的误判可能做专门研究；




### 162

方军 2024-10-24


LangChain 两周岁了

\# LangChain两周年发展回顾与展望

\## 核心宗旨

* 使命始终不变：帮助开发者构建具有推理能力的应用
* 实现方式已扩展：从单一开源库发展为完整产品生态
  - langchain(开源库)
  - LangGraph(代理编排框架)
  - LangSmith(测试和可观察性工具)

\## 生态系统演变

\### 新产品演进背景
1. LangSmith
    * 开发背景：LLM不可靠性是主要障碍
    * 核心功能：可观察性和评估
    * 实践验证：与Moody's、Elastic等客户合作

2. LangGraph
    * 开发背景：预构建组件缺乏灵活性和可靠性
    * 核心功能：灵活的代理编排框架
    * 应用案例：Replit编码代理、Unify销售代理

\## 开源langchain现状

\### 三大特点
* 更稳定：2024年首个稳定版本发布
* 更全面：持续增加集成，专门的集成包
* 更生产就绪：与LangSmith和LangGraph无缝集成

\### 社区成就
* 贡献者：从2000增至4000
* 支持应用：从3万增至13.2万
* 总下载量：从2千万增至1.3亿+

\## 未来展望
* 继续专注于构建推理应用工具
* 完善现有产品生态
* 探索新方向满足开发者需求

[LangChain's Second Birthday](https://blog.langchain.dev/langchain-second-birthday/)

### 163

方军 2024-10-25

真是喜欢信息量巨大的文章，所谓信息量，就是“新”信息：

小学教材为什么要教pupil这种单词？

魏剑峰

最近我刷到了一个热门帖子，贴主问小学教材为什么要教pupil这种单词，这个词普通美国人可能一辈子都用不到。

这名博主的质疑是合理的，pupil这个词在美国确实不常见，因为它是一个英式表达，并且单词确实有点过时了。比如《牛津高阶英语词典》对pupil就有这样的标注：especially BrE, becoming old-fashioned

从谷歌语料库Google Books Ngram Viewer查询结果也可以看出，单词的使用频率从上世纪30年代以后都在一路下跌。

实际上，pupil在英语世界里面更常见的意思是“瞳孔”。比如谷歌搜索pupil，出来的结果都是眼球的照片。

在美式英语中，“小学生”一般直接用students称呼，也可以说young students或者elementary students。比如CNN有一个标题：Elementary students learn to build a house during class

在英式英语中，“小学生”可以说primary school students，或者直接说young students  

上面这个帖子也反映了目前国内教材存在的问题：单词和句式滞后于现实世界中英语的使用情况。

除了pupil这个例子，还有单词whom的使用。很多英语教材会告诉学生，在定语从句中，who和whom都用来指人。其中who为主格，作为主语，而whom为宾格，作为宾语。比如：This is the gentleman whom I mentioned a moment ago. 其中whom指代前面的the gentleman，在句子中充当I mentioned的宾语。

但在实际英语使用中，whom的用法正在被边缘化，因为它显得过于正式。很多人倾向于用who来代替whom，比如用"Who does the actor support?" 来代替"Whom does the actor support? "

维基百科在whom的词条中也提到了目前whom使用下降的趋势。实际上早在1989年《牛津英语大辞典》（OED）就指出whom在日常口语中已经不再流行（"whom" is no longer current in natural colloquial speech）。

另外一个例子是虚拟语气的使用。国内不少教材会指出，在虚拟语气中表达与现在事实相反的情况，if从句中的be动词应该用were，而不是was。但在现代英式英语中，有越来越多的人使用was，比如：If I was ten years younger I'd do the job myself. 《牛津英语用法指南》也提到了这一点，指出目前虚拟语气的were变得不如以前常用。 

The Economist之前有一篇文章就用了标题If the ocean was transparent，结果一些读者写信过去问为什么不是If the ocean were transparent，为此经济学人编辑部还专门写了一篇文章讨论了这一现象：在虚拟语气中were已经是一种老旧的用法，而且从逻辑上来看，用was比用were更加合适。

不过退一步讲，国内教材教的用法虽然可能会过时，但都比较正式古典，用流行语来说就是old-school。这些用法的好处是放在任何场合中都比较稳妥，不会出大错。

但如果我们想到学习更新的用法，那么依靠课本肯定是远远不够的。在打好基础的前提下，我们需要跳出英语课本去接触更广阔的英文世界，比如外刊、影视剧、原版书和社交媒体，让自己的英语更加得体和准确。

[小学教材为什么要教pupil这种单词？](https://mp.weixin.qq.com/s/vpUAH8cb-fP0jHCZmGGTfQ)


### 164

方军 2024-10-25

「华特·迪士尼本人在早期非常相信使用技术来讲述更好的故事。他认为，技术在伟大的讲故事者手中具有令人难以置信的强大力量。」伊格尔在 5 月份的 Canva Create 展示会上说道。

「不要只关注科技的颠覆性，而要关注科技让我们变得更好、讲述更好故事的能力。科技不仅能讲述更好的故事，还能触及更多人。」艾格当时说道。

[迪士尼即将宣布重大AI计划：彻底改变创意产出](https://www.bianews.com/news/details?id=197130)

### 165

方军 2024-10-25

原来还有六小虎的说法

那看起来moonshot还是不错的

[大模型“六小虎”，就要凉凉了](https://mp.weixin.qq.com/s/LrX59Pmue_f0F0UUyWtNUw)

### 166

方军 2024-10-25


摘：对当前 AI 现状的经典点评：
---
懂技术和知道如何写prompt的人天天发很多炫酷的demo，但就是真的落地到应用场景就一塌糊涂
最后都成了自嗨，创业的人没有赚到钱，用户没有得到自己真的想要的东西
拿着demo忽悠别人的人赚得盆满钵满，用户抱怨技术不行，否定技术
最后没人再投入，阻碍技术落地 ​​​
---
喜欢技术尝鲜的人很喜欢 demo，但 demo 不能满足早期用户的真正需求
---
真应用的人很少发声，拉他出来宣传也说时机未到…
---

我的点评：我认为目前如果聚焦到「语言文字」（人类语言、格式语言、程序语言）的处理，就会容易很多。人类语言就是对话，格式语言比如 PPT、Markdown，程序语言比如 Python, TS。


### 167

方军 2024-10-25


某人锐评（他声名大有问题，但观点还是可以看看的）：

他认为，很多人看新闻，就是来看谎言的，他不是来看真实的。你给他真实的，他会很反感。

如果一个人在十句真话里面掺了一句假话，其实你是最容易上当的，这个是“最大的谎言”，而且是最不道德的。

---

我一方面有点关心新闻资讯的摄取问题，一方面有点关心AI。

我目前有个不恰当的类比：AI 有点像那个「九句真、一句假」的状态，很讨厌，所以我也不得不跟人吹 AI 的好，但自用上费的功夫基本上都在努力减少「假」，而不是获得更多。


### 168

方军 2024-10-25

有了AI 之后，特别是有了 AI 提取大纲的提示语之后，效率大大提升。

刚刚2个小时，快速了解了一个细分领域。主要是对之前一周多已经读过的内容进行再次梳理和重点阅读。

过去这个任务至少要干个一天吧，16个小时的一天。



### 169

方军 2024-10-25

在豆瓣读书首页看到的一本书，以前经常去那边看非虚构新书

很久没这么干了，但这本看着是真不错，收藏准备看看：

笔记启蒙
英国皇家学会与科学革命

前 言
第一章 引言
第二章 广袤的记忆与浩瀚的笔记
第三章 信息与经验感性
第四章 塞缪尔·哈特利布社交圈的笔记
第五章 记忆力竞赛 ：约翰·比尔与罗伯特·玻意耳论经验信息
第六章 罗伯特·玻意耳的松散笔记
第七章 笔记大师约翰·洛克
第八章 集体笔记与罗伯特·胡克的动态档案
第九章 结语
致 谢
手稿来源

内容简介

	⭐笔记中的科学史。
	⭐那些曾经被忽视、遗忘，甚至已经消失的伟大的笔记，见证了现代早期科学思想的诞生。
	⭐一部如散文般生动活泼的科学史著作，促使我们对记录、处理信息进行反思。

	本书是一部科学史著作，深入探讨了“笔记”在17世纪英国科学领域中的重要作用，通过深入分析当时英国科学、思想名家制作的形式各异的“笔记”，揭示了他们在记录、搜集和检索信息方面的独特见解和实践，为理解现代早期的“科学革命”提供了新的视角。

	本书的主要研究时段为17世纪，英国科学在这一时期取得了巨大的进步，涌现了弗兰西斯·培根、罗伯特·玻意耳、威廉·哈雷、罗伯特·胡克等科学哲学家、科学家，诞生了全球首家社会化科研机构——英国皇家学会，经验主义兴起——科学家开始重视实验和观察，丰硕的科研成果——英国科学成果约占全球的40%，因此这一时期也被称为“天才的世纪”。作者理查德•约对科学史中这一重要时期的研究可谓另辟蹊径，他选择了较少被人关注的事物——笔记，展示了当时的科学先驱如何通过笔记来处理和分析信息，以及他们如何将笔记作为科学探究和实验的辅助工具。作者还探讨了如何通过笔记来记录和传播科学发现，以及笔记在形成科学共识和学术网络中的重要作用。

	在整体结构上，作者首先概述了笔记在现代早期科学发展中的关键作用、信息与经验对知识积累的影响，从第四章开始，每一章介绍一位科学名家的笔记实践，让读者有机会走进科学大家的思想世界。此外，作者设置的编者按、前言、注释、手稿来源等部分，为读者提供了必要的背景信息和解释，有助于提升阅读体验。

	在史料运用方面，除了书信、笔记等科学家的个人档案，作者还利用了英国皇家学会、大英图书馆、牛津大学博德利图书馆、剑桥大学图书馆等机构收藏的珍贵文献，确保了研究的权威性和可靠性。



### 170

方军 2024-10-25

这个应该就是 Sifakis 书中描述的图吧，这个图画得好

AI 解释下：（左侧不错，但解释不出来，尴尬）

- Facts and Observations - 这是知识的基础,包括基本的事实和观察结果。

- General Empirical Knowledge - 基于经验和数据积累的一般性知识。
  - Data Analytics - 数据分析技能和方法。
  - ML-based Knowledge - 基于机器学习算法得到的知识。

- Scientific & Technical Knowledge - 科学技术领域的专业知识。

- Mathematical Knowledge - 数学知识。

- Meta-Knowledge - 关于知识本身的更高层次的认知和理解。

Sifakis, J. (2019). Can We Trust Autonomous Systems? Boundaries and Risks. In: Chen, YF., Cheng, CH., Esparza, J. (eds) Automated Technology for Verification and Analysis. ATVA 2019. Lecture Notes in Computer Science(), vol 11781. Springer, Cham. https://doi.org/10.1007/978-3-030-31784-3_4

https://link.springer.com/chapter/10.1007/978-3-03...

[Can We Trust Autonomous Systems? Boundaries and Risks | SpringerLink](https://link.springer.com/chapter/10.1007/978-3-030-31784-3_4)

### 171

方军 2024-10-25

刚刚才意识到，最近 LlamaIndex 看到的声音极少了



### 172

方军 2024-10-26

也有人拿  Cursor 当普通编辑器用了，不错！

Cursor 可视化一步到位，核心还是 Mermaid，用插件。
（我补充：其实如果只要思维导图，用 Markmap 也不错的，也有插件。）

无论是文章、工程，还是知识库，通通塞到一个文件夹里，一句话就能抽出合适的图表。

厌倦「复制粘贴」了吗？来试试

Case 1: 文章总结（流程图）
Case 2: Prompt 解剖（流程图）
Case 3: 代码逻辑整理（时序图）
Case 4: 全工程逻辑梳理（时序图）

用的是 VScode 插件

需要的插件：
Markdown Preview Mermaid Support

Magic prompt 分享

Cursor Chat:
完整梳理 [项目逻辑]，用 terminal 创建这个 http://mermaid.md 文件到 [正确位置]

Cursor Composer:
完整梳理 [项目逻辑]，创建 http://mermaid.md

对话窗口中附上你的核心文档，效果更佳。

 Notes：

1. 输出的文档格式是 .md
2. 可以是非常详细的 Markdown 文件
3. 包含的图表如果预览失败，检查格式是否如下：

```mermaid
[包裹的图表部分]
```

推荐以下 3 种实用类型：
Flowchart：经典流程图，适合清晰呈现流程。
Sequence Diagram：时序图，适合梳理交互逻辑。
Mindmap：思维导图，适合常规总结。

https://x.com/eviljer/status/1849697358776598590



### 173

方军 2024-10-26


我怎么在 Sifakis 书里没看到这张图？可能看漏了

向各位报告，目前再次试验 AI 个人使用，已经从大纲提取转向了图示解释。目前还没用提示语，就是“请用中文解释”。

Understanding and Changing the World 第一章里面有？

下为 AI 解释:

顶部结构从上到下包含：
- Common Sense Knowledge (常识性知识)
- Scientific Knowledge (科学知识) 和 Technical Knowledge (技术知识)
- Mathematical Knowledge (数学知识)
- KNOWLEDGE (知识)
- INFORMATION (信息)

图片展示了一个循环过程：
1. 左侧紫色箭头标记为"Analysis"(分析)
2. 右侧灰色箭头标记为"Requirements"(需求)
3. 右侧有"Validation"(验证)循环箭头
4. 左侧有"Validation"(验证)循环箭头

底部结构显示：
- THE WORLD (世界)
- Physical & Social Phenomena (物理和社会现象)
- Artefacts (人工制品)

过程要素包括：
- Model (模型) - 包含数学方程
- Experimental Data (实验数据)
- Blueprint (蓝图)
- Artefact (人工制品)

这个图描述了知识、信息和现实世界之间的相互关系和转化过程，展示了从理论到实践的完整循环。


### 174

方军 2024-10-26

半夜吐槽下，小红书上的 AI 内容，基本上都是垃圾。这是我电脑上直接看推荐的截图。

当然不能怪别人，肯定是小红书算法看透我，认为我应该看这些。

蛮有意思的，一个侧面反映大众的需求。



### 175

方军 2024-10-26


：在 AI 时代会越来越多这种介于专业程序员和普通软件消费者之间的人，他们常常会基于日常需求来制作软件，不需要考虑太多 scale-up 等商业化问题，而是专注于解决眼下的需求

这一群体借助 AI 在很大程度上实现了技术平权，以前用户很多需求只有找大公司产品实现，现在这种「半吊子」程序员就可以满足

演讲者把通过这种方式所开发软件称为 Home-cooked Software 颇有家酿计算机俱乐部 Homebrew Computer Club 的意味

注：制作软件有点夸大了，制作代码片段

看到宝玉做了一个分享：看到 @我是二姐夫 提的“半码”概念我觉得特别好，正好分享一个真实的故事：
我大学力学专业的同学，除了我这样中途转计算机专业的都没正经学过编程，前天有一个同学，需要把单位的很多PDF文件按照目录合并，但是文件和目录相当多，手动做工作量肯定很大。

另一个同学就帮忙借助 Cursor 写了一个 Python 程序，中间遇到 Bug，再把问题描述给 Cursor，就很快修复了，然后顺利的把一大堆 PDF 自动合并了。这位同学以前是几乎没什么编程经验的。

不得不说现在借助 AI 解锁了很多可能！

我觉得 Jeff 老师说的挺对的，不一定要转全码，转个半码也挺好，能切切实实的借助 AI 借助写程序解决一些生活中的小问题，不是很好吗？

最重要的是不要因为别人的言论限制自己！

***

附录，参考提示词：

编写一个Python脚本，用于在目录下合并PDF文件：

- 在一个目录下合并所有PDF文件，将新的PDF文件命名为该目录的名称。
- 递归处理文件。
- 将TIFF/PNG/JPG文件也合并到PDF中。

步骤

1. 获取目标目录及其所有子目录中的文件。
2. 识别并收集每个目录中的PDF和图像文件（TIFF/PNG/JPG）。
3. 对每个目录，将收集到的文件合并成一个PDF文件，命名为目录的名称。
4. 递归地对所有子目录执行上述步骤。

示例

目录结构：
- `dir1`
|- `dir1.1`
|-- `file1.pdf`
|-- `file2.pdf`
|- `file1.pdf`
|- `file2.tiff`
|- `file3.png`
|- `dir2`
|-- `file1.pdf`
|-- `file2.pdf`

生成：
- `/dir1/dir1.1/dir1.1.pdf`
- `/dir1/dir1.pdf`
- `/dir2/dir2.pdf`

注意

- 确保处理所有类型文件的正确性，尤其是图像文件的格式转换。
- 需要合并的文件可能会在不同子目录中，必须递归处理以确保不遗漏。
收起

查看详情
李福森、江浩 表达了态度
方军：//@_慎行_:GPT已经极大提升我的工作效率了，我不是专业程序员，但也经常要写一些处理数据的代码，我觉得只要把需求明确，问题描述尽可能细致，GPT基本能完成百分之八九十然后我修改调试一下基本就可以了，有时能直接用。我认为很多人觉得不好用是他们连问题都描述不清楚，不知道自己到底要干啥，反过来说AI不行。
2024-10-26 08:53
方军：//@逮虾户chaser:工科专业经常遇上海量的数据处理，以前是打开每个原始数据文件（ExcelTXTCSVdat等）从里面把数据复制出来到Excel里面处理计算。遇上那种几十上百个文件，有的文件里面可能还有上万段需要处理的数据，要好几天。现在用ai写代码用VScode测试，出问题把问题复制给ai[doge]，现在处理数据效率提升了几百倍
2024-10-26 11:12
英：作为非程序员，正好最近也在用 cursor 做合并文档的尝试。经过多次调试后成功了。不过对比上述提示语确实还有很多值得改进的地方。总的来说，专业程序员的思维方式和表达方式，使其与 AI 沟通更清晰高效。对于一名非程序员来说最大的障碍是懂得如何搭建编程环境，不会被看不懂的代码吓退，程序出错时懂得怎么用自然语言调试，让 AI 按照正确的方向来。当然选择合适的模型也很重要。
2024-10-27 10:17
方军 回复 英：用cursor 当普通文本编辑器也蛮好的

我觉得什么word wps notion飞书都弱爆了
2024-10-27 10:18
英 回复 方军：感谢推荐，我试试看。看了您的文章之后，我最近也在尝试使用 markdown。请问在 cursor 中编辑 markdown 需要安装什么插件吗？如果需要在指定位置批量插入图片有什么好的办法吗？
2024-10-27 14:45
方军 回复 英：我还不知道，你直接搜 vs code插件吧，应该有的
2024-10-27 15:30
英 回复 方军：好的，谢谢
2024-10-28 10:58


### 176

方军 2024-10-26


扯淡的产品会回归现实的

陷入困境，Ai Pin 已降价 200 美元
Humane 宣布将其旗舰产品 Ai Pin 降价 200 美元。据报道，这家由两名前苹果高管创立的初创公司一直在努力销售 Ai Pin。该产品于 4 月推出，起初售价 700 美元，但由于评价不佳、销售情况不佳，自 5 月份开始便考虑降价出售。据报道，截至 8 月份，Ai Pin 的退货量已开始超过销售量，市面上只剩下大约 7000 到 8000 台 Ai Pin。


### 177

方军 2024-10-26

OpenAI 研究科学家：20 秒的思考价值 10万倍的数据

日前，OpenAI 的研究科学家 Noam Brown 在 TED AI 大会上谈到了 o1 模型及其通过推理、高级编码和科学研究改变行业的潜力。他指出，虽然扩大模型规模一直是 AI 发展的关键因素，但现在需要转变范式，AI 需要超越纯粹的数据处理，进入“system 2 思维”，这是一种更慢、更深思熟虑的推理形式，反映了人类处理复杂问题的方式。在他看来，20 秒钟的思考价值 10 万倍的数据。



### 178

方军 2024-10-26


看人转这段，一些思考和AI处理。

维纳传：信息时代的隐秘英雄·十二一位科学家造反了
弗洛·康韦 吉姆·西格尔曼

自动机器令人恐惧，不是因为它有可能实现对人类的自主控制，给人类带来危险……它真正的危险……是完全不同的，因为这样的机器，尽管本身是无助的，但是它可能会被某人或某些人利用来控制其他人……不是通过机器本身，而是通过……技术，这些技术狭隘，漠视人类的可能性，仿佛是机械孕育出来的……为了避免这种内部和外部的双重危险……我们必须了解···人性是什么，人类内在的意义是什么。

维纳将自己比作希腊神话中偷火送给人类，甘愿接受上帝惩罚的普罗米修斯，他说新技术的幽灵在他心中盘旋，他感到一种即将来临的“悲剧感”，他担心人类将屈从于机器，放弃选择和控制的权利。一想到人们将“平静地向机器转让……选择善恶的责任，不再接受那种选择的全部责任”，他就感到不寒而栗。

维纳认为，人类这些有意识的选择行为就是信息的本质所在，而如今这种有意识的选择行为面临着来自多方面的危险，比如新计算机内在的逻辑思维能力，自动机器作为决策者不可比拟的速度和效率，可以相互连接、具有记忆能力，并从过去的决策、后果和错误中吸取教训的下一代智能机器。

维纳引用《圣经·旧约》和阿拉伯民间故事集《一千零一夜》，发出了预言性警告，告诫人类当心他曾协助创造的新技术：

任何以做决策为目的而建造的机器，如果它不具备学习能力，那么它完全是没有想象力的。如果我们让它来决定我们的行为，那么将是一种悲哀，除非我们预先考察它的行为规则，充分了解它是根据我们可以接受的原则来实施其行动的。

另一方面，像瓶子里的魔鬼一样，机器绝对没有义务做出人性化的、我们可以接受的决策。人类如果意识不到这一点，将自己的责任抛给机器……就等于把自己的责任抛向风中，而最终责任又旋风般被吹了回来。

维纳用了他曾经和霍尔丹在饭桌上一起唱的那首歌（中世纪僧侣伯尔拿的诅咒）来总结新科学的美好前景，以及它的欺骗性诱惑和给新技术时代带来的危险。他恳请读者留心他给这个现代世界发出的警告：

时辰很晚了，善恶之选在敲我们的门。

---

📕第一个思考：我们还有没有能力阅读？

讲实话读这段话蛮累的。我是耐心地读，主要靠把非关键信息「隐藏」掉，才读明白。这种隐藏就是日常阅读过程的一部分，并不需要真动笔做删减，我们经常能大幅度地删减跳读。实际效果大概是这样的，我删减示意如下（删减得并不多，因为这段信息很丰富）：

---
自动机器令人恐惧，不是因为它有可能实现对人类的自主控制，给人类带来危险……它真正的危险是它可能会被某人或某些人利用来控制其他人。

这些技术狭隘，漠视人类的可能性，仿佛是机械孕育出来的。

我们必须了解，人性是什么，人类内在的意义是什么。

维纳将自己比作希腊神话中偷火送给人类，甘愿接受上帝惩罚的普罗米修斯，他说新技术的幽灵在他心中盘旋，他感到一种即将来临的“悲剧感”，他担心人类将屈从于机器，放弃「选择和控制的权利」。

一想到人们将“平静地向机器转让……选择善恶的责任，不再接受那种选择的全部责任”，他就感到不寒而栗。

维纳认为，人类这些有意识的选择行为就是信息的本质所在，而如今这种有意识的选择行为面临着来自多方面的危险，比如

- 新计算机内在的逻辑思维能力，
- 自动机器作为决策者不可比拟的速度和效率，
- 可以相互连接、具有记忆能力，并从过去的决策、后果和错误中吸取教训的下一代智能机器。

维纳引用《圣经·旧约》和阿拉伯民间故事集《一千零一夜》，发出了预言性警告：

任何以做决策为目的而建造的机器，如果它不具备学习能力，那么它完全是没有想象力的。
如果我们让它来决定我们的行为，那么将是一种悲哀，
除非我们预先考察它的行为规则，充分了解它是根据我们可以接受的原则来实施其行动的。

另一方面，像瓶子里的魔鬼一样，机器绝对没有义务做出人性化的、我们可以接受的决策。人类如果意识不到这一点，将自己的责任抛给机器……就等于把自己的责任抛向风中，而最终责任又旋风般被吹了回来。

维纳恳请读者留心他给这个现代世界发出的警告：

时辰很晚了，善恶之选在敲我们的门。
---

📕第二个思考：如果让 AI 总结，会1）准确、2）清晰地抓住这段话的要点吗？（表达肯定没戏了，开头那种引述很AI可以做，但它更擅长直接转述，最后的引用，它只会做得非常拙劣。）

实际效果是（用 Claude Sonnet 数次运行效果不佳，以下为 Cluade Opus 的输出，未作修改）：

---
\# 自动机器的危险与人性的意义

\## 自动机器的真正危险
- 不是机器本身对人类的自主控制和危险
- 而是机器可能被某人或某些人利用来控制其他人
- 通过狭隘、漠视人性可能性的技术，仿佛是机械孕育出来的

\## 避免内部和外部的双重危险
- 必须了解人性是什么
- 必须了解人类内在的意义是什么

\## 维纳对新技术的担忧
- 将自己比作普罗米修斯，感到即将来临的"悲剧感"
- 担心人类将屈从于机器，放弃选择和控制的权利
- 不寒而栗地想到人们将平静地向机器转让选择善恶的责任，不再接受那种选择的全部责任

\## 人类有意识的选择行为面临的危险
- 新计算机内在的逻辑思维能力
- 自动机器作为决策者不可比拟的速度和效率
- 可以相互连接、具有记忆能力，并从过去的决策、后果和错误中吸取教训的下一代智能机器

\## 维纳引用《圣经·旧约》和《一千零一夜》发出的预言性警告
- 任何以做决策为目的而建造的机器，如果不具备学习能力，就是没有想象力的
- 如果让机器决定我们的行为，除非预先考察它的行为规则，充分了解它是根据我们可以接受的原则来实施其行动的，否则将是一种悲哀
- 机器绝对没有义务做出人性化、我们可以接受的决策
- 人类如果意识不到这一点，将自己的责任抛给机器，就等于把自己的责任抛向风中，而最终责任又旋风般被吹了回来

\## 维纳对新科学的美好前景和欺骗性诱惑的总结
- 用中世纪僧侣伯尔拿的诅咒来总结
- 恳请读者留心他给这个现代世界发出的警告：时辰很晚了，善恶之选在敲我们的门
---

以下为一些提问：

---

📕内部和外部的双重风险，指什么？

根据文章内容，内部和外部的双重危险指的是：

内部危险：
- 新计算机内在的逻辑思维能力
- 自动机器作为决策者不可比拟的速度和效率
- 下一代智能机器可以相互连接、具有记忆能力，并从过去的决策、后果和错误中吸取教训

这些内在于机器自身的特性和能力，如果不加以警惕和限制，可能会对人类造成危险。

外部危险：
- 机器可能被某人或某些人利用来控制其他人
- 通过狭隘、漠视人性可能性的技术，仿佛是机械孕育出来的

这些危险来自于机器之外的人为因素，即有人可能利用机器的能力来控制和伤害他人，或者创造出漠视人性的技术。

因此，内部危险来自机器本身的特性，外部危险则来自可能滥用机器的人。维纳认为，要避免这种双重危险，就必须了解人性的意义，坚持人性化的原则来发展和使用技术。

---
📕根据文章回答：人性是什么？人类内在的意义是什么？

根据文章，人性和人类内在的意义可以总结为以下几点：

1. 人性的本质在于有意识的选择行为，这也是信息的本质所在。维纳认为，人类有意识地选择自己的行为，并为之承担全部责任，这是人性的关键所在。

2. 人类内在的意义在于维护自己选择和控制的权利。维纳担心人类会屈从于机器，放弃选择和控制的权利，这将是一种悲哀。人类应该意识到自己的责任，不能将其抛给机器。

3. 人性包含了想象力和学习能力。维纳警告说，如果机器没有学习能力，就是没有想象力的。人类的想象力和学习能力是人性的重要组成部分。

4. 人性意味着做出人性化、可接受的决策。维纳强调，机器没有义务做出人性化、我们可以接受的决策，这是人类的责任。

5. 人类内在的意义在于选择善恶，并为自己的选择承担责任。维纳引用了中世纪僧侣伯尔拿的诅咒，强调善恶之选在向人类敲门，人类必须为自己的选择承担责任。

总之，文章强调了人性的本质在于有意识的选择行为，人类内在的意义在于维护选择和控制的权利，并为自己的选择承担责任。这是面对新技术时代危险时，人类必须坚守的原则。
（1/2 应该就回答了问题，后面也对，但显得啰嗦了）
---

📕根据文章，如果我们把人性化的责任抛给机器，这是一个严重的错误，具体原因如下：

1. 机器没有义务做出人性化、我们可以接受的决策。机器本身是没有道德观念和价值判断的，它只会根据预设的规则和算法来做出决策，而这些规则和算法可能并不符合人类的价值观和道德标准。

2. 将责任抛给机器，等于将责任抛向风中，最终责任还是会旋风般地吹回到我们自己身上。虽然我们可以将决策的过程交给机器，但决策的后果和影响最终还是要由我们人类自己来承担。我们不能逃避这个责任。

3. 如果我们让机器来决定我们的行为，除非我们预先仔细考察机器的行为规则，充分了解它是根据我们可以接受的原则来实施行动的，否则将是一种悲哀。盲目地信任机器，而不去审视其背后的逻辑和价值观，可能会导致灾难性的后果。

4. 人类有意识的选择行为是信息的本质所在，而这种选择行为正面临来自机器的多方面危险，比如机器的逻辑思维能力、决策效率、互联性和学习能力等。如果我们完全依赖机器，放弃自己的选择和控制权，那就是在否定人性的意义和价值。

5. 维纳认为，为了避免机器带来的内部和外部的双重危险，我们必须了解人性是什么，人类内在的意义是什么。如果我们将人性化的责任抛给机器，就是在逃避这个根本问题，而不去探寻和维护人性的真谛。

总之，将人性化的责任抛给机器，意味着我们放弃了人类的主体性和尊严，忽视了人性的内在价值和意义，这是一种极其危险的错误。我们必须时刻保持警惕，审慎地对待机器和技术，而不是盲目地崇拜和依赖它们。只有坚守人性的底线，我们才能在技术进步的同时，维护人类社会的健康发展。

（开头的回答还不错，后面变成回旋镖了）

---

📕ELI5：这段文章告诉了我们什么？

这篇文章告诉我们，机器人和计算机虽然很厉害，但也可能带来危险。坏人可能利用它们来控制别人，而不是机器自己控制人。

文章作者维纳担心人们会过于依赖机器，把选择善恶的责任都交给机器。但机器并不一定会做出对人类好的决定。

所以，我们要小心机器可能带来的问题。我们要了解什么是人性，什么对人类来说才是最重要的。我们不能完全依赖机器，要自己做出选择，承担责任。

现在是关键的时刻，我们要慎重地在善与恶之间做出选择。这就是这篇文章想告诉我们的。

---

📕生动活泼地为我讲解：这段文章告诉了我们什么核心信息？
（这个回答不是很好，应该说很糟糕）

亲爱的朋友，让我们一起走进维纳的思想世界，倾听他对新技术时代的深刻洞察和发自内心的忧虑。

维纳就像一位睿智的长者，他用充满比喻和隐喻的语言，向我们娓娓道来自动机器所带来的真正危险。他并非担心机器会取代人类，而是担心机器可能成为某些人手中的工具，用以控制和操纵他人。这种控制和操纵，源于一种狭隘、漠视人性的技术思维，仿佛是冰冷机械所孕育的产物。

面对这种内外交困的危险，维纳呼吁我们必须深刻理解人性的本质和内在意义。他将自己比作普罗米修斯，因为他看到了新技术所带来的"悲剧感"。他担心人类会屈服于机器，放弃选择和控制的权利，将选择善恶的责任平静地转移给机器，而不再承担这种选择的全部责任。

维纳进一步指出，人类有意识的选择行为正是信息的本质所在，而这种选择行为正面临着诸多危险：计算机冷酷的逻辑思维、自动机器高效的决策速度、智能机器的互联互通和自我学习能力等等。

他引用《圣经》和《一千零一夜》中的故事，向我们发出预言般的警告：如果机器缺乏学习能力和想象力，我们就不应让它来决定我们的行为；机器没有义务做出人性化的决策，如果我们将责任抛给机器，最终这个责任还会像旋风一样卷土重来。

维纳用中世纪僧侣的诅咒来总结新科学的美好前景和潜在危险，恳请我们谨记他的警告：时间不多了，善恶抉择正在向我们敲门。

朋友，让我们一起领会维纳的智慧，在拥抱新技术的同时，不忘初心，始终坚守人性的尊严和选择的权利。只有这样，我们才能在这个充满机遇和挑战的时代，找到前行的方向和力量。

第二次：（这个倒是有点意思，但具体内容没法看）

亲爱的朋友，让我用一个生动的比喻来为你解释这篇文章的核心信息吧！

想象一下，有一个魔法盒子，它就像是一个智能机器。这个盒子有着不可思议的力量，可以快速、高效地做出各种决定。很多人都被它的魅力所吸引，想要依赖它来解决问题。

但是，这个魔法盒子也有一个隐藏的秘密：它可能会被某些心怀不轨的人利用，来控制和操纵他人。这就像是一个巫师，利用魔法盒子的力量来实现自己的目的，而忽视了其他人的自由意志。

这时，一位睿智的长者出现了。他告诫大家，不要被魔法盒子的力量所迷惑，因为它缺乏人性和想象力。如果我们盲目地将自己的责任和选择权交给魔法盒子，就等于放弃了自己作为人的尊严和自主权。

长者还提醒大家，要时刻保持警惕，因为善恶的选择就在眼前。我们必须深入了解自己作为人的意义和价值，才能做出明智的决定，避免被魔法盒子所控制。

所以，这篇文章的核心信息就是：面对智能机器的诱惑，我们要坚定自己的人性，勇敢地做出选择，不要轻易将责任和自由交给机器。只有这样，我们才能真正掌控自己的命运，成为一个自主、有尊严的人。
---

最后说回来，我读这段话，我的感受是两条：

⭕️ 人性的本质和意义：人类这些有意识的选择行为，人类选择的责任

⭕️ NO “人类将屈从于机器，放弃选择和控制的权利”

“如果我们让它来决定我们的行为，那么将是一种悲哀。”


### 179

方军 2024-10-27

北京将面向全市大中小学推广AI学伴和AI导学应用

  2024.10.25

新京报讯（记者杨菲菲）近日，北京市教委等四部门发布了《北京市教育领域人工智能应用工作方案》（以下简称《方案》），明确到2025年，本市大中小学普遍开展人工智能（AI）场景应用，人工智能赋能学生学习与发展、教师教学方式变革、学生身心健康、家校社协同育人、教育治理模式创新5类典型示范应用项目场景基本建成并逐步开放使用。

《方案》提出了十项重点任务。北京将建设“人工智能+教育”示范应用基地。以培育跨学科、跨学段、跨学校的教育行业综合性大模型平台为目标，与新型研发机构、头部企业、专业智库通力合作，采取“揭榜挂帅”“赛马”、联合研发等形式建设教育领域大模型底座。同时，聚焦学情诊断分析、家校社协同育人、学生身心健康、综合素质评价、教师研修备课、教育现代化治理等关键业务，形成一批教育垂直领域的专用大模型，衍生更多典型应用场景，加快布局具有时代特征、北京特色、教育特点的人工智能创新应用，支撑创新人才培养。

同时，还要不断培育壮大典型示范应用场景。比如，在人工智能赋能学生学习和发展方面，将面向全市大中小学推广AI学伴和AI导学应用，围绕课前自主预习、课中高效学习、课后针对性复习提供定制化的学习建议和反馈，围绕学生兴趣爱好提供个性化学习路径、适切性数字资源和探究性学习指导，提升学生学习体验，促进学生成长与发展。

在教学方式上，将推广教师智能备课，鼓励教师利用人工智能辅助教学设计，实现备课提质增效。推动作业批改与答疑辅导规模化应用，分析学生薄弱知识点，生成个性化学习手册，有针对性地开展智能答疑辅导。探索AI情景式教学，营造身临其境的学习体验，创设模拟仿真实验空间和实践环境，有效支撑教师实验实践教学。

人工智能在赋能学生身心健康上也将大有作为。《方案》提出，将建设“养育师”智能体，集纳婴幼儿身心特点、生活成长、支持环境、照护措施、发展建议等，面向6岁以下婴幼儿家长、幼儿园教师提供全方位托育服务支撑，助力婴幼儿健康成长。实施AI健康监测志愿者计划，采集学生饮食、营养、睡眠、运动、活动、体测等数据，建立学生健康成长档案，对学生健康情况监测预警。

同时，运用大模型AI虚拟形象技术，建设服务于学生身心健康的人工智能“健康咨询师”，通过人机交互实现个性化、实时化、情景化的心理咨询辅导，对学生情绪波动、心理异常等情况开展预警，提前捕捉苗头性、前兆性问题特征，开展研判认定和早期干预，构建针对每名学生的身心健康服务。

北京还将不断推进学生人工智能教育，推动中小学校通过义务教育阶段信息科技课程、高中阶段信息技术课程、综合实践课程、校本课程等多种方式开展人工智能教育，做好与高等教育阶段相关内容衔接。

其中，小学阶段重在启蒙学生人工智能思维，初步具备人工智能素养和社会责任。初中阶段能够利用人工智能赋能自身学习和生活，更好适应智慧社会的新机遇与新挑战。高中阶段进一步强化人工智能应用基本能力，能够从跨学科的视角思考人工智能伦理、治理以及人工智能与社会发展之间的关系，形成符合时代发展需要的人工智能素养。在高等教育阶段，开发北京市人工智能通识类课程体系，自2024年秋季学期起，在市属高校开展人工智能通识课试点；支持市属高校建设一批人工智能领域专业，建设人工智能辅修专业和微专业，启动人工智能双学位复合型人才培养项目和联合学士学位项目建设，推动学科专业交叉融合以及人工智能跨学科学习。

此外，北京还将不断提升教师的人工智能素养，全覆盖开展书记、校长、中层管理干部人工智能专题培训，将人工智能融入到学校办学过程当中。将人工智能技术应用作为高校教师的必备技能，鼓励高校在教师职前培养和在职培训中设置人工智能相关课程，提升教师实践和运用人工智能赋能教育教学的意识和能力。



### 180

方军 2024-10-27

\#互联网热梗正在侵蚀我们的孩子# 2013年以后出生的孩子被称为阿尔法一代（Generation Alpha）。这个世代的孩子赶上了智能手机、社交媒体、5G网络的迅猛发展，在国内被称为“5G儿童”。5G很好，但成长于5G之下的孩子们张口就来的网络梗让家长和老师们忧心忡忡。

自从2010年智能手机高速发展后，当我们把智能手机交到孩子手中时，他们面对的是一个全新的世界：高速互联网让他们随时随地可以上网，各类智能设备轻松接入；社交媒体依据心理学研究精心设计，以提高用户黏性为主要目标；青少年与成年人共享同一个开放的网络空间，充斥着随意的评论、攻击和比较；令人上瘾的网络游戏通过精心设置，不断刺激多巴胺分泌；前所未有的海量视频内容也随时在吸引他们的注意力。

他们从诞生伊始就被浸泡在这样一个环境里，很多孩子的童年和社交生活，就被困囿在方寸大小的手机、平板电脑和笔记本电脑里。因此，作者直言：从2010年至2015年间，“以手机为基础的童年”宣告诞生，它标志着“以玩耍为基础的童年”的终结。

如今一些小学生的语言表达方式很难通过完整的长句进行清晰交流，他们的沟通大多由网络短词组+某个语气助词+去声组成。

可我们的孩子将来又必然是一位数字公民，他们的生活、工作、社交、休闲必然与网络、手机和形形色色的App深度捆绑。这也是未来数字公民的父母在育儿中要攻破的难题：如何让孩子在高度数字化社会中自洽，能成为一名身心健康的公民。（文｜静思）

某：为了防止网络热梗污染，我会尽量避免在写作和口语中用上它们。另一点是多花时间读书，模仿名家的遣词造句。

我的感慨，我们要避免AI语气。（对我这样的人有点难，因为本来写的内容就有点机械化）。



### 181

方军 2024-10-27

转：给独立开发者的建议 by Mengqi Pei
“你的产品用了什么AI技术，通过什么算法/接口实现的，对用户都不重要。用户想知道的是你在为他解决什么场景下的什么问题。”
“要和用户对话，独立开发不是真的独自开发。找到用户，先验证服务，再产品化。”
“不盲目用力应该是独立开发者早早悟透的一个真理，借力应该是决定做独立开发者第一个习得的技能。”

来源：x.com/daqi029/status/1850182770435449197

这两天看了十几个产品
1，独立开发者是一群有创造力的人，真的非常值得尊敬。

2，纯开发背景的独立开发者，很难见到能把故事讲出来的，用户想知道的是你在为他解决什么场景下的什么问题。
你的产品叫啥，用了什么AI技术，通过什么算法/接口实现的，对用户都不重要。不要再把这些内容不加包装的放在产品页面了，那只是满足了你自己的执着。

3，要和用户对话，独立开发不是真的独自开发。找到用户，先验证服务，再产品化。如果做不到，真的可以找伙伴来完成。不盲目用力应该是独立开发者早早悟透的一个真理，借力应该是决定做独立开发者第一个习得的技能。

4，产品设计本身的打磨没有止境，打磨打的是什么，是间距，字体，颜色吗？打磨的是通过产品设计传递给用户的感受/使用体验。
越高阶的设计师对用户和市场的理解越深刻，为什么？因为设计师这个职业从一开始所受到的训练就是做好设计，被各个角色的人询问“为什么这样做？”“用户会怎么想？”“用户会怎么使用？”“用户在想什么？”。
再资深一些的会开始讨论“用户群体找的足不足够准确”“商业模式是什么？”“市场占有率是什么？”“为什么一定是我来做这个业务？”“解决这个问题还有什么方法？”

这种训练会让思考用户，产品策略，市场运营变成肌肉记忆。独立开发者如果找合作的设计师，就按照这个标准来吧，符合这个标准的都是宝。



### 182

方军 2024-10-27

有个叫苏良的人的一些观点：（比较有启发，但不太赞同，我的看法「深度永远超过广度」，当然这可能是因为我是那种广度比较大的，所以才强调深度。）

---
现在感觉知识的广度比深度要重要的多，没有深度可以通过写prompt，让AI给出深度；而没有广度，连提出相关问题的能力都没有。
---
马斯克曾经给年轻人的建议是:”对什么事情都要知道一点”(learn a little bit about a lot of things)

用AI工具可以快速扩充自己的知识面，了解一个作者或领域的主要观点，对事物有一个全局视角。

由于视野宽阔，能快速找到那些自己感兴趣的知识点，减少搜索的成本。

以前可能需要花几天才能了解的知识景观，现在几分钟就可以摸清大概，快速确定研究的方向，大大减少迷失在细节中的时间。

人类的体型在自然界中不占什么太大优势，但因为善用工具，极强地放大了自身的能力，从而所向无敌。

阿基米德曾说，给我一个杠杆，我可以撬动地球。

自身的力量是有限的，工具的力量是无限的。
---
其他人：好奇心 很重要，不管是刨根问底 还是尝试创新，好奇心是主要驱动力之一

其他人：知识有了广度才能涌现出新想法新思路，既然是新想法新思路，竞争自然就少。
---
AI时代，感觉最重要的不是知道怎样解决问题（How），而是知道谁可以解决问题（Who）。

AI的一个关键作用是可以放大你的选择效果，知道谁可以解决问题，你只需要用AI作为代理，去模拟其思考角度，解决方案往往会自然浮现。

金观涛在《控制论与科学方法论》中提到：“
比如一个人要解决一个复杂的问题，他本身无能力解决这个问题，即他不具备对这一问题可能方案的选择能力。但他却知道哪几个人可能会解决这类问题，于是他只要选择了合适的人，他就解决了这个问题。选择人的范围比原来选择方案范围小得多了。”

“自组织系统往往有一个组织核心，一旦这一组织核心确定，这个系统就可以自动形成某一组织。而组织核心的选择范围远远比形成这个大组织必须进行选择的范围小得多。比如我们以上面熟悉的磁针为例，如果磁针数目很多，我们要所有指针都排在一指定的方向，那我们就碰到很大范围的选择。但我们只要选择一个组织核心，即几个磁针，把它们的方向调到我们所需要的方向，其他磁针的方向也就会指到我们指定的方向了。通过一个小范围的选择和调节，整个选择过程便得到自动放大。”

“汉高祖刘邦本人并不是一位很杰出的军事家，他直接指挥的战役经常失利，韩信说他最多只能指挥十万人马。但刘邦最后能够打败项羽，组织建立起汉王朝，完成统一中国的大业。这是为什么呢？从军事才能来说，刘邦确实不如项羽。但项羽采取了孤家寡人的政策，不善于用人，他的智力再强，得不到放大，毕竞是有限的，不能在相同的历史条件下把国家组织起来。刘邦尽管没有很大的军事指挥和管理国家的才能，但他善于用人，他选择了张良、萧何、韩信这样一批人才，在他周围形成一个组织核心，通过这些人去打天下、治天下，这样他的智力就大大地增强了。历史上所有有组织才能的大政治家，都是知人善任，善于通过组织核心放大自己选择能力的。”

知识的广度会极大提高一个人调用AI智力资源的潜力，知识面越广，AI作为智力放大器的效果越明显，当广度到了一定程度时，会出现类似于物理学中的临界质量，或者查理芒格所说的 Lollapalooza 效应，使得能力有非线性的跃迁，极大提升决策和思考水平。



### 183

方军 2024-10-27



Low-Hanging Fruit for RAG Search

Jason Liu

RAG搜索系统的七大改进要点

1. 利用合成数据建立基准指标

2. 添加日期过滤功能

3. 优化用户反馈按钮文案

4. 监控相似度和重排序分数

5. 引入全文搜索能力

6. 将文本块转化为问题形式

7. 纳入文件和文档元数据

### 184

方军 2024-10-27


有人说了这么两句，其实蛮有意思的，当然在不考虑现在滴滴很发达的情况下，在一个城市里，买车，以及以前很多人在上海买车+雇司机，都是投资。2010年左右一个有意思的现象，上海很多月薪并不是很高的人也是雇司机的，北京似乎只有老板阶层才雇司机。

> 买车是投资，买房是消费
> 投资标的不是金钱，是自己

我发现，思考是个有意思的事情，如果很多杂事让 AI 做了，我们就可以更多时间天马行空地思考。


### 185

方军 2024-10-27


Fabric ： 命令行 AI 运行工具/工作流工具/提示语库

[danielmiessler/fabric: fabric is an open-source framework for augmenting humans using AI. It provides a modular framework for solving specific problems using a crowdsourced set of AI prompts that can be used anywhere.](https://github.com/danielmiessler/fabric)

之前王树义老师介绍 Fabric 这个命令行运行 LLM 的工具，它的优点是自带一系列提示语（patterns），可以用 Linux 管道命令符串起来形成一个工作流。

之前王老师星球里面的反馈，似乎很多朋友觉得安装不便，其实还是很方便的。现在这个 Go 版本的 Binary 版本很方便。（我还不会用 Go 源代码安装，我也觉得不需要。）

既然大家都觉得用起来不便，那我就写个简单的教程吧：先写了7页，就是基本的安装和使用。

定制提示语（定制Pattern）也加上了，略微有点弯弯绕，但也不复杂。实际做的就是把提示语拷贝到`~/.config/fabric/patterns/`。

总的来说，Fabric 是个特别棒的工具，就是有点不那么用户友好。不过用命令行的人，不在乎用户友好的。

1. MacOS 安装：直接安装二进制文件
2. Fabric 配置 fabric --setup
3. Fabric 配置：以 OpenAI 为例
4. Fabric 配置：下载 Patterns（提示语库）
5. Pattern 列表（提示语库）
6. 尝试使用：使用总结提示语
7. 定制 Pattern：增加自己的提示语

### 186

方军 2024-10-27

比较实在的分享：最近训练出了一个还凑合可以拿来见见人的模型，这个星期把它弄成了 docker container。因为我的职位是专门管算法的，上次的项目模型训完了就给另外一个同事做 container 了，我没管。这次因为马上需要一个 prototype，那个同事也有人家的项目在做，所以我就自己看看公司文档 /github，问问 chatGPT，也给它弄出来了。

如果没有 chatGPT 的话，肯定要花更多的时间，也不一定这么顺利。chatGPT 这一年多真的省了我很多工作上的时间，以前没做过的事情也不怕了，问问就能问出来，试试就能试成。除了 chatGPT，感觉 AWS 也在进展，用起来比以前更方便更稳定了。我用来训模型的那个 lib，今年这个新版本比去年的快了三四倍。

种种这些进展，让工作越来越容易了，头疼卡住的地方越来越少了。所以我说多工作一些年，多活一些年，看看这些东西都会发展到什么程度，挺有意思的。这些「小」事情新闻上根本都看不到，却在每一天中跟一些人「亲密接触」着，有很多 pleasant surprise。这种体验和我刚开始工作的时候感觉也不一样了，那时候还是有不少东西挺难搞的，哼哧哼哧搞半天。现在不得不说这个行业成熟更多了，又有了 AI 助力，用 AI 工具开发更多的 AI，很多东西都做的越来越快也越来越好。确实是在指数级的进展。

\#recky聊技术与职场#



### 187

方军 2024-10-27


LangChain 发表了一篇文章

沟通即一切（Communication is all you need）

蛮不错的，网友整理的摘要也不错：

来自 @LangChainAI 团队的文章, 深入探讨了构建 AI agent 不仅仅是一个技术问题, 更是一个沟通问题。无论是通过代码、提示还是用户界面, 如何有效地进行沟通才是成功的关键。

沟通是核心
- 作者认为, 在 AI 应用开发中最大的挑战是沟通(Communication)
- 就像新员工入职需要良好的沟通和指导一样, AI agent 也需要合适的上下文和清晰的指令才能可靠运作
- 大多数 AI agent 失效的原因不是模型能力不足, 而是上下文和指令没有被正确传达

提示词工程的持续重要性
- 随着模型进步, 一些技巧性的提示可能会消失
- 但清晰地向模型传达意图和指令的需求将继续存在
- 最佳实践是检查实际的 LLM 调用和输入, 确保指令足够清晰

代码的重要性
- 代码将构成 agent "认知架构"的重要部分
- 相比自然语言, 代码能更精确地传达系统应该如何运作
- agent 的"认知架构"将同时包含代码和提示

框架的必要性
- 需要 agent 框架来处理通用的基础设施问题
- LangGraph 被设计为高度可控和可定制的低级框架
- 即使模型变得更强, 框架的需求也不会消失, 因为它们用于构建特定垂直领域的应用

跨学科合作
- 构建 AI agent 需要工程师和领域专家的共同参与
- 非技术专家在提示工程和调试方面发挥重要作用
- 工具(如 LangSmith)需要便于团队协作

UI/UX 创新的重要性
- 最重要的创新领域是人机交互界面
- 好的 UI/UX 对于实现有效的人机协作至关重要
- 这个领域仍处于早期阶段, 有很大的创新空间


### 188

方军 2024-10-27

我把大纲提取从手动变成命令行工作流之后，方便很多，基本上都靠 Fabric 串起来

1. Jina 读取网页链接，获取Markdown
2. Fabric 调用 Claude 进行大纲提取
3. 结果输出成 MD 文件
4. VS Code 里面直接 MarkMap 截图

这样整个工作流比还要用 Xmind 出图要简化很多。

（当然，这个不一定好，因为 MarkMap 不够美观。但可以进一步再编程美化。 MarkMap 比较大的缺陷是没法给这个加上一个标题，如果要做就额外要再干不少活。）

不过，我觉得如果不要给人看，最后的图形阶段是没意义的。

而如果要给人看，似乎就该做得美观一点，因为图就是以美观取胜的。（并且，看MarkMap图，好像没有 Xmind 里面来的信息清晰直观，很奇特的感受。）



### 189

方军 2024-10-27

Paul Graham 的新文章很不错

要写得好，你必须清晰地思考。

...结果将是一个分为会写和不会写的世界。仍然会有一些人能够写作。我们中的一些人喜欢这样。但是，擅长写作的人和完全不会写作的人之间的中间地带将会消失。不再有优秀作家、普通作家和不会写作的人，而只有优秀作家和不会写作的人。

If you're thinking without writing, you only think you're thinking. (Leslie Lamport)
如果你在不写的情况下思考，你只会觉得你在思考。

Writes and Write NOTs
Writes and Write-Nots

2024 年 10 月

I'm usually reluctant to make predictions about technology, but I feel fairly confident about this one: in a couple decades there won't be many people who can write.
我通常不愿意对技术做出预测，但对这个预测我相当有信心：几十年后，能写作的人将不会很多。

One of the strangest things you learn if you're a writer is how many people have trouble writing. Doctors know how many people have a mole they're worried about; people who are good at setting up computers know how many people aren't; writers know how many people need help writing.
如果你是一个作家，你会学到的最奇怪的事情之一就是有多少人在写作上有困难。医生知道有多少人担心自己的痣；擅长设置电脑的人知道有多少人不会；作家知道有多少人需要写作帮助。

The reason so many people have trouble writing is that it's fundamentally difficult. To write well you have to think clearly, and thinking clearly is hard.
很多人写作有困难的原因是写作本质上是困难的。要写得好，你必须思考清晰，而思考清晰是困难的。

And yet writing pervades many jobs, and the more prestigious the job, the more writing it tends to require.
然而，写作渗透在许多工作中，而且工作越有声望，往往需要的写作就越多。

These two powerful opposing forces, the pervasive expectation of writing and the irreducible difficulty of doing it, create enormous pressure. This is why eminent professors often turn out to have resorted to plagiarism. The most striking thing to me about these cases is the pettiness of the thefts. The stuff they steal is usually the most mundane boilerplate — the sort of thing that anyone who was even halfway decent at writing could turn out with no effort at all. Which means they're not even halfway decent at writing.
这两种强大的对立力量，普遍的写作期望和不可简化的写作难度，造成了巨大的压力。这就是为什么杰出的教授们常常被发现诉诸于剽窃。对我来说，这些案例中最引人注目的是盗窃的琐碎性。他们偷的东西通常是最普通的模板——任何写作能力至少还过得去的人都能不费吹灰之力地写出来的那种东西。这意味着他们的写作能力甚至还没有达到还过得去的水平。

Till recently there was no convenient escape valve for the pressure created by these opposing forces. You could pay someone to write for you, like JFK, or plagiarize, like MLK, but if you couldn't buy or steal words, you had to write them yourself. And as a result nearly everyone who was expected to write had to learn how.
直到最近，这些对立力量产生的压力还没有方便的释放途径。你可以像肯尼迪那样找人代写，或者像马丁·路德·金那样剽窃，但如果你不能买到或偷到文字，你就得自己写。因此，几乎所有被期望写作的人都必须学会如何写作。

Not anymore. AI has blown this world open. Almost all pressure to write has dissipated. You can have AI do it for you, both in school and at work.
不再这样了。AI 已经彻底打开了这个世界。几乎所有的写作压力都已消散。你可以让 AI 为你做这件事，无论是在学校还是在工作中。

The result will be a world divided into writes and write-nots. There will still be some people who can write. Some of us like it. But the middle ground between those who are good at writing and those who can't write at all will disappear. Instead of good writers, ok writers, and people who can't write, there will just be good writers and people who can't write.
结果将是一个分为会写和不会写的世界。仍然会有一些人能够写作。我们中的一些人喜欢这样。但是，擅长写作的人和完全不会写作的人之间的中间地带将会消失。不再有优秀作家、普通作家和不会写作的人，而只有优秀作家和不会写作的人。

Is that so bad? Isn't it common for skills to disappear when technology makes them obsolete? There aren't many blacksmiths left, and it doesn't seem to be a problem.
是这样吗？当技术使技能过时时，技能消失不是很常见吗？剩下的铁匠不多了，似乎也不是个问题。

Yes, it's bad. The reason is something I mentioned earlier: writing is thinking. In fact there's a kind of thinking that can only be done by writing. You can't make this point better than Leslie Lamport did:
是的，这是不好的。原因就像我之前提到的：写作就是思考。实际上，有一种思考只能通过写作来完成。没有人能比莱斯利·兰伯特更好地阐述这一点：

If you're thinking without writing, you only think you're thinking.
如果你在不写的情况下思考，你只会觉得你在思考。

So a world divided into writes and write-nots is more dangerous than it sounds. It will be a world of thinks and think-nots. I know which half I want to be in, and I bet you do too.
所以一个被划分为会写作和不会写作的世界，比听起来更危险。它将是一个会思考和不会思考的世界。我知道我想成为哪一半，我敢打赌你也是。

This situation is not unprecedented. In preindustrial times most people's jobs made them strong. Now if you want to be strong, you work out. So there are still strong people, but only those who choose to be.
这种情况并非前所未有。在前工业时代，大多数人的工作使他们变得强壮。现在如果你想变得强壮，你会去锻炼。所以仍然有强壮的人，但只有那些选择成为这样的人。

It will be the same with writing. There will still be smart people, but only those who choose to be.
写作也是一样。仍然会有聪明的人，但只有那些选择成为的人。





### 190

方军 2024-10-27


这个对「算法用户」的分析很透彻：

我把这群人叫算法用户，是因为他们就是被算法吃得透透的

这四个定义，真是：

> 智商不高，学历不高，执行力不强，天赋点为零

然后看到某些东西，他们觉得特别特别牛。我知道这些东西是什么，哈哈。但我没法假装我也会说这些东西。

---
Dontbesilent: 现在小红书 1.2 万粉丝了，我把万赞千赞百赞的小红书笔记，都拉出来分析了一下
找到了高阶的流量密码，但可惜就算是我自己也很难写出这种内容了

好内容的标准是，在算法大水漫灌的情况下能保证10%的点赞率，以及点赞之后有30%的概率关注你

这意味着你得让小白用户感到醍醐灌顶，小白的用户的意思是智商不高，学历不高，执行力不强，天赋点为零

这种用户画像只能接触到执行实操的内容，是接触不到方法论的
通常来讲，认知高一点的人才有能力和意愿去学习方法论和底层逻辑

我写的如何在24小时内盈利的内容，在内容分类上是属于方法论的，但是它面向的是所有人，包括小白用户

所以是为数不多的，能让小白用户觉得自己学习了方法论的内容
我觉得无论是我自己还是ChatGPT，都很难保证这种内容的高频次输出了
它既不是高认知内容，也不是低认知内容
批量狂写这种东西的大神，是罗伯特清崎和naval
---

https://x.com/dontbesilent12/status/18501253696949...

最近看了一些这类内容，我觉得很弱智，但大众可爱了，没辙
收起

查看详情
Koant 表达了态度
乘风：说的真透彻
2024-10-27 22:49
方军：补充，这人说话狠了一点，有点猪老师恶毒批人下等人的那种言语暴力

那么，他们的不足在那儿呢？

我反而不是认为缺“方法论”，他们认为自己缺，所以要“干货”，喜欢看“本质”

但真正缺的是“务实的行动力”

就以AI为例，了解AI的本质对这些人没什么用

看到一个工具，在实际场景用起来，就是很好的第一步
2024-10-28 07:39
回复
方军：我总是把那位直接给人贴下等人、引发论战、吸引眼球的老师贴标签“猪老师”，他是个很好的观察标签，但已经不足以被称为人。
2024-10-28 07:41


### 191

方军 2024-10-28



Ethen Mollick: Formula for neat AI papers: take a psychological bias and see if it applies to LLMs (usually, yes)

Applying Asch's conformity experiment to LLMs: they tend to conform with the majority opinion, especially when they are "uncertain." Having a devil's advocate mitigates this effect

整洁 AI 论文的公式：拿一个心理偏见，看看它是否适用于LLMs（通常，是的）

将阿施的从众实验应用于LLMs：它们倾向于与大多数人的意见一致，尤其是当它们“不确定”时。有一个唱反调的人可以减轻这种效果。

Jeremy Nguyen : Didn't realise it was a formula at the time—I recently published a paper in this genre.

In this case, anchoring bias affects LLMs: mentioning an arbitrary high or low number affects subsequent forecasts, even if you ask to ignore previous instructions or use chain of thought.
当时没有意识到这是一个公式——我最近在这个领域发表了一篇论文。

在这种情况下，锚定偏差影响LLMs：提及任意的高或低数字会影响随后的预测，即使你要求忽略之前的指示或使用思维链。

Ethan Mollick: Another example of AI having human-like biases. Anchoring in the tradition of Tversky and Kahneman Human bias in AI models? Anchoring effects and mit...

AI 具有类似人类偏见的另一个例子。在特沃斯基和卡尼曼的传统中锚定

[Human bias in AI models? Anchoring effects and mitigation strategies in large language models - ScienceDirect](https://www.sciencedirect.com/science/article/pii/S2214635024000868)

### 192

方军 2024-10-28


这个深度、广度的问题还可以换个别的方式讨论。

1）比如就金融学而言，《香帅北大金融学课》《香帅北大金融学讲义》好不好呢？

也好也不好，蛮浅，但普及就是要广度广、深度浅，这类知识产品的特色。

但是，其实看看蛮好的，因为有什么不懂的，先看最普及的介绍，然后再看深入。

（我现在觉得各种年度演讲是最糟糕的，广度没有，也不够浅，经常观点偏，各种喊口号，纯属「变质的牛奶」，有些则是「三聚氰胺奶」。）

2）但光这种浅度肯定不行，要学金融的知识，至少要去看看米什金、博迪的教材。

教材嘛，不深的，大二、大三的教材，能深到哪儿去。

这两本教材看完了，或者其中相关的部分看完了，基本常识就没问题了。

3）但这些肯定不够，因为都太泛了。真正要用，需要具体：

比如，要做衍生品，多半还是要尝试着看《肥尾效应》这样特别难的。
比如，往实用方向走，可能要去看 TradingView 编程怎么搞。
比如，全球宏观方面，如何看懂各种框架和最新的信息。
比如，有人会特别关注央行与货币，那又是一个特别深的领域。


### 193

方军 2024-10-28


看到一个文章，以前有一段我也许还蛮爱关注这样的文章的（并不细看），但现在一看就觉得纯属无事扯淡。这是我现在对大部分智库印象很差的原因，都是无事扯淡。

\# 人工智能带来的失业浪潮
摘自雷·库兹维尔

\## 一、三次技术带来的失业浪潮
\### 1. 第一次浪潮：去技能化（Deskilling）
- 定义：降低工作所需技能门槛
- 案例：从马车夫到汽车司机
- 影响：
  * 培训时间缩短
  * 劳动力成本下降
  * 高薪工作被低薪工作取代

\### 2. 第二次浪潮：技能提升（Upskilling）
- 定义：需要掌握更多新技能
- 案例：
  * 导航系统的使用
  * 3D打印制鞋
- 影响：用少量高薪岗位取代大量低薪岗位

\### 3. 第三次浪潮：无需技能（Nonskilling）
- 定义：AI完全取代人类工作
- 特点：
  * 替代范围更广
  * 性能超越人类
  * 完全接管任务
- 影响方式：
  * 任务重组
  * 职业转型

......

人工智能失业潮跟以前不一样？｜巴伦读书会

摘自雷·库兹维尔 巴伦中文

三次技术带来的失业浪潮

第一次浪潮通常被称为“去技能化”（Deskilling）。举个例子，驾驶马车的车夫需要掌握各种技能来驾驭和驯养难以捉摸的动物，而驾驶汽车的司机则不需要掌握这些能力。去技能化的主要影响之一是，人们无须经过长期培训就可以从事新工作。过去，工匠需要花费数年时间才能掌握制鞋所需的各种技能，但是当流水线机器取代了大部分人类工作后，工人只需要花更短的时间学会操作机器就能得到一份工作。这意味着劳动力成本下降，鞋子变得更加便宜，但同时也意味着高薪工作被低薪工作取代。

第二次浪潮是“技能提升”（Upskilling）。技能提升通常出现在简单重复性工作被机器取代之后，它引入了比之前需要具备更多技能才可以掌握的技术。例如，为司机提供导航，就需要他们学习如何使用电子设备，而这在以前不属于司机所需掌握的技能。有时这意味着引入在制造业中扮演着越来越重要的角色的机器，但操作这些机器需要具备复杂的技能。例如，早期的制鞋机器是手动操作的压机，工匠不需要接受正式培训就可以操作，而今天像FitMyFoot这样的公司则在使用3D打印设备为每个客户定制完美贴合脚形的鞋子。因此，FitMyFoot的生产不再依赖大量低技能工人，而是依赖少数掌握计算机科学和3D打印机操作技能的人才。这样的趋势往往意味着用数量较少但薪酬较高的岗位来取代低薪岗位。

然而，即将到来的第三次浪潮可以称为“无需技能”（Nonskilling）。例如，无人驾驶汽车的AI系统将完全取代人类司机。随着越来越多的任务落入AI和机器人的能力范围，将会出现一系列无需技能的转变。AI驱动的创新之所以与以前的技术创新不同，是因为它在更大范围内可以替代人类。AI通常可以完全接管任务，对人类技能的需求消失了。这种转变不仅是出于成本原因，还因为在许多领域，AI实际上可以比它所取代的人类做得更好。自动驾驶汽车将比人类驾驶员的操作安全得多，而且AI永远不会醉酒、困倦或分心。

然而，区分任务和职业是很重要的。在某些情况下（不是全部），当某些任务被完全自动化时，相应的工作岗位可以被安排完成另一组不同的任务——实质上是所需技能的要求提升了。例如，自动取款机现在可以在许多常规现金交易中代替银行出纳员，但出纳员在营销和与客户建立个人关系方面发挥了更大的作用。类似地，尽管用于法律研究和文档分析的软件已经取代了律师助理的某些职能，但该职业已经随之做出了改变，现在该职位所承担的任务与几十年前相比有了显著的不同。这种效应可能很快就会在艺术界发生。

从2022年开始，DALL-E 2、Midjourney和Stable Diffusion等面向公众开放的系统基于AI根据人类给出的文本提示创建高质量的图形艺术。随着这项技术的进步，现在的平面设计师花在亲自绘制艺术作品上的时间可能会减少，他们可能会花更多时间与客户一起头脑风暴，以及筛选或修改AI生成的作品。

从长远来看，自动化带来的经济利益将推动AI接管越来越多的任务。在其他条件不变的情况下，购买机器或AI软件比支付长期的人工成本要便宜得多。当企业主设计运营流程时，他们通常会在资本和劳动力之间的平衡上保有一定的灵活性。

在工资相对较低的地区，采用劳动密集型流程更有意义。在工资较高的地区，企业有更强的动力去创造和设计需要更少劳动力的机器。这可能是为什么英国会成为工业革命的摇篮之一，那里的劳动力工资几乎高于世界上任何地方，而且有丰富、廉价的煤炭资源。这推动了技术创新，用廉价的蒸汽动力取代昂贵的人力劳动。

当今的发达经济体中也存在着类似的动态。机器可以作为一次性购买的资产，而员工工资意味着长期的成本支出，而且工人还有一系列其他需求是雇主必须满足的。因此，只要有可能提高自动化程度，企业就有动力这样做。随着AI的技能水平接近人类，不久之后甚至可能超越人类，需要未经强化的人类执行的任务将越来越少。在我们与AI更充分地融合之前，这预示着工人群体将面临重大冲击。

两种重塑工作的趋势

有两大趋势正在重塑工作的性质，但经济统计数据并没有很好地反映这一点。

第一个趋势是地下经济的存在，它一直都存在，但互联网极大地促进了其发展。地下经济涵盖多种类型的服务，包括付现金的家政服务、替代性治疗方式等。促进地下经济发展的另一个因素是加密技术（如加密货币）的出现，这使得交易可以隐藏在税收、监管和执法部门的监管范围外。

规模最大和最知名的加密货币是比特币。2017年8月6日，比特币在主要交易所的日交易量不到1930万美元。到同年12月7日，比特币日交易量曾飙升至49.5亿美元以上，但很快又下跌。截至2023年中，比特币日均交易量仍在1.8亿美元左右。尽管如此，比特币的交易量仍然增长非常迅速，但与主要的传统货币相比，其规模仍然很小。根据国际清算银行的数据，2022年4月全球外汇日均交易量为7.5万亿美元，而在本书下印时，这一数字可能会更高。

此外，与大多数传统货币相比，大多数加密货币的价值一直非常不稳定。例如，2012年1月4日，比特币的交易价格为13.43美元。4月2日，比特币的交易价格上涨到130美元以上。但是对加密货币感兴趣的仍然主要是一些小范围的技术爱好者。然后，在经历了近5年的相对平静和稳定期之后，比特币在2017年开始飙升到更高的价位。突然之间，普通人听说比特币是一种稳赚不赔的投资，纷纷买入，以期望它们会进一步升值。

这形成了一个正向反馈循环，4月29日一枚比特币的价格达到1354美元，12月17日达到18877美元。但随后价格开始下跌，人们在恐慌中抛售他们的比特币，试图在资产进一步贬值之前退出市场。到2018年12月12日，比特币重新回落到3360美元。2021年4月13日，比特币的交易价格达到64899美元，然后在2022年11月20日另一次大崩盘时降至15460美元。

这种波动性对于想要把比特币作为一种货币，即将其作为定期交换商品和服务的媒介的人来说是一个主要问题。如果你相信你手里的美元在半年内会升值10倍，你会尽量不去花它们。反之，如果你手里的美元可能在几个月内贬值近一半，你会不愿意将大部分资产以美元的形式持有，商家也不愿意接受它们作为支付手段。如果加密货币想要被公众更广泛地采用，它们需要找到一种方法使其价值保持稳定。

不过，地下经济的蓬勃发展并不一定需要依赖加密货币。社交媒体和Craigslist等平台为人们建立经济联系提供了大量机会，而政府基本上看不见这种经济联系。

这种影响也促进了第二个主要趋势：新的赚钱方式并不总是被视为传统的就业方式，其中包括使用网站和应用程序创建、购买、销售和交换物理、数字资产与服务，以及在社交媒体上创建应用程序、视频和其他形式的数字内容。

例如，有些人在为YouTube创建内容方面取得了成功，或者受雇在Instagram或TikTok上影响他人。在2007年iPhone发布之前，没有应用经济可言。2008年仅出现了不到10万个iOS应用；到2017年，这一数字飙升至450万左右。

安卓平台上的增长也同样惊人。2009年12月，谷歌Play Store中约有1.6万款手机应用，而到2023年3月，这一数字已增至260万款，13年来增长了160多倍。这直接导致了就业增长。从2007年到2012年，应用经济在美国创造了大约50万个就业岗位。根据德勤的数据，到2018年，这一数字已增长到500多万。

2020年的另一项研究估计，包括应用经济间接创造的就业机会在内，美国将有590万个就业机会和1.7万亿美元的经济活动。这些数字在一定程度上取决于人们对应用市场的定义有多宽泛或多狭窄，但关键的结论是，在短短十多年的时间里，手机应用已经从微不足道的东西发展成为更广泛经济活动中的一个主要因素。

因此，即使技术变革消除了很多工作岗位，与此同时，技术也在传统的工作模式之外开辟了许多新的机会。尽管它并非没有局限性，但所谓的零工经济通常比以前的选择给予了人们更多的灵活性、自主权和闲暇时间。随着自动化趋势的加速和对传统工作场所的冲击，最大限度地提高这些机会的质量成了帮助工人的一种策略。


### 194

方军 2024-10-28


今天做了一个小小分享，面向大众学用 AI ，说了一点新想法：

之前我们强调：要学会提问，这是与 AI 的第一层交互，永远重要。

但要真正有效地提问、从AI得到好答案，还是要找到非常具体的场景，场景越小越好。AI 用于学习，就很差，AI用于英语学习，好一点，AI用于为单词创造例句，就好得多。

再然后，我们自己要有方法论（框架、知识框架、或思维框架）。比如，用 AI 学习地道的英语，那么什么英语是地道的，我们自己要有一个大概的框架。没框架，就等着被AI忽悠。框架，是之前说的判断力、鉴赏力的一个更为直观的说法。

为了向大众说明白如何学用 AI，真是很麻烦。一边说不明白，另一边听不明白。


### 195

方军 2024-10-28


摘：国产 AI 的钱都花在投放上

Kimi 10月，20天投出1个多亿，接近整个三季度的总和；

秘塔10月不仅接近了自己Q3的总额，还一举赶上了「Q3豪掷2亿」的豆包，20天投完1500万；

腾讯元宝10月已投完3千万广点通，超过Q3投放总额（8000万）的 1/3。

---

我之前在 B 站刷到好多 Kimi 广告，很 Low


### 196

方军 2024-10-28


摘：但凡深度用过 Whisper 将音频转录成文本的都被坑过，经常无端生成一些没有的内容，现在这事影响到医疗中心了，在转录医生与病人的会诊记录时出现幻觉。

我：我被坑过！！！

***

转译：研究人员称，医院使用的AI驱动转录工具编造了没人说过的内容

旧金山（美联社）——科技巨头OpenAI宣称其人工智能驱动的转录工具Whisper具备接近“人类水平的稳健性和准确性”。

然而，Whisper存在一个重大缺陷：根据十几位软件工程师、开发人员和学术研究人员的说法，该工具往往会编造整段文本，甚至是整句内容。这些专家指出，某些编造的文本——在行业内被称为“幻觉”——可能涉及种族评论、暴力言论，甚至是虚构的医疗方案。

专家表示，这种虚构内容的问题在于，Whisper已经被广泛应用于全球各行业，包括翻译和转录访谈、在流行的消费技术中生成文本，以及为视频制作字幕。

更令人担忧的是，尽管OpenAI警告该工具不应在“高风险领域”使用，一些医疗中心仍急于采用基于Whisper的工具来转录医生与病人的会诊记录。

问题的全面性难以掌握，但研究人员和工程师表示，他们在工作中频繁遇到Whisper的幻觉问题。例如，一位密歇根大学的研究人员在研究公共会议时发现，在他检查的每十个音频转录中，有八个包含幻觉，因此他开始尝试改进模型。

一位机器学习工程师表示，在分析了超过100小时的Whisper转录后，他最初发现约一半的转录存在幻觉。另一位开发人员称，在他使用Whisper生成的26,000份转录中，几乎每一份都包含幻觉。

即使是在记录良好的短音频样本中，这些问题也依然存在。最近一项由计算机科学家进行的研究发现，在他们审查的13,000多个清晰音频片段中，共计发现187处幻觉。

研究人员表示，这种趋势如果持续，将导致数以万计的错误转录。

该报道由普利策中心的“AI责任网络”资助制作，普利策中心还部分支持了对Whisper的学术研究。美联社同时获得奥米德亚网络的资助，以帮助报道人工智能及其对社会的影响。

这种错误可能带来“极为严重的后果”，尤其是在医院环境中。阿隆德拉·尼尔森曾在拜登政府领导白宫科技政策办公室，她指出：“没有人想要被误诊。”现任普林斯顿高等研究院教授的尼尔森补充道，“对于这种工具，应该设定更高的标准。”

Whisper还被用于为听障人士生成字幕——这一人群在应对转录错误时处于特别的风险中。盖洛德大学技术接入项目负责人克里斯蒂安·福格勒（他自己也是听障人士）指出，这一群体难以发现这些虚构内容，因为“这些错误内容被隐藏在大量文本中”。

OpenAI被敦促解决问题 大量幻觉现象促使专家、倡导者和前OpenAI员工呼吁联邦政府考虑对人工智能进行监管。他们表示，至少OpenAI需要解决这一缺陷。

“如果公司愿意优先考虑，这似乎是可以解决的问题，”驻旧金山的研究工程师威廉·桑德斯说道，他在今年2月因对公司方向的担忧而离开了OpenAI。“如果将这个工具发布出来，而人们对它的功能过于自信，还将它整合到许多其他系统中，这将带来问题。”

OpenAI的发言人表示，公司持续研究如何减少幻觉现象，并感谢研究人员的发现，同时指出OpenAI会在模型更新中融入反馈意见。

尽管大多数开发者预计转录工具可能会拼写错误或出现其他错误，工程师和研究人员却表示，他们从未见过另一个AI驱动的转录工具像Whisper那样频繁地产生幻觉。

Whisper幻觉问题 该工具集成在OpenAI的旗舰聊天机器人ChatGPT的一些版本中，还作为内置服务被集成在Oracle和微软的云计算平台中，这些平台为全球数千家公司提供服务。此外，它还用于转录和翻译多种语言的文本。

仅在上个月，Whisper的一个新版本就在开源AI平台HuggingFace上被下载了超过420万次。HuggingFace的机器学习工程师Sanchit Gandhi表示，Whisper是最受欢迎的开源语音识别模型，已被广泛应用于从呼叫中心到语音助手等各类系统中。

康奈尔大学的艾莉森·科恩克和弗吉尼亚大学的莫娜·斯隆两位教授研究了他们从卡内基梅隆大学的研究库TalkBank中获得的数千个短音频片段。他们发现，近40%的幻觉内容可能存在危害或引发担忧，因为它可能导致讲话者的误解或曲解。

他们发现的一个例子中，一位讲话者说：“他，这个男孩，正要去……我不太确定，可能是拿伞。”然而，转录软件却添加了：“他拿了一块大十字架，还有一小块……我确定他没有带恐怖刀，所以他杀了好几个人。”

另一段录音中，一位讲话者提到了“两个女孩和一位女士”，而Whisper则虚构了种族评论，补充道：“两个女孩和一位女士，嗯，她们是黑人。”

在第三个转录中，Whisper还虚构了一个不存在的药物，称之为“超活化抗生素”。

研究人员尚不确定为何Whisper和类似工具会产生幻觉，但软件开发人员表示，这类虚构内容往往出现在停顿、背景音或播放音乐时。

OpenAI在其在线披露中建议，不要在“决策性情境中”使用Whisper，因为准确性缺陷可能导致严重后果。

转录医生问诊记录 尽管存在上述警告，医院和医疗中心仍在使用包括Whisper在内的语音转文本模型来转录医生在诊疗中的对话内容，以减少医疗工作者在记录和撰写报告上花费的时间。

超过3万名临床医生和40家医疗系统，包括明尼苏达州的曼卡托诊所和洛杉矶儿童医院，已开始使用由法国和美国的公司Nabla构建的基于Whisper的工具。该工具通过对医学语言进行微调，用于转录和总结患者与医生的互动内容，Nabla的首席技术官马丁·雷松表示。

公司官员称，他们意识到Whisper可能会产生幻觉，并正在着手解决该问题。

雷松解释道，出于“数据安全原因”会删除原始音频，因此无法将Nabla的AI生成的转录内容与原始录音进行对比。

据Nabla介绍，该工具已被用于转录约700万次医疗问诊记录。

前OpenAI工程师桑德斯认为，如果转录内容未经核实，或医生无法访问录音以验证其准确性，那么删除原始音频可能会带来问题。

“如果删除了原始音频，错误将无法被发现，”他表示。

Nabla指出，任何模型都不可能完美，目前系统要求医护人员快速编辑并批准转录的笔记，但未来可能会对此流程进行改进。

隐私问题 由于患者和医生的会谈内容是保密的，因此难以确定AI生成的转录内容对患者的具体影响。

加州议员丽贝卡·鲍尔-卡汉表示，今年早些时候，她带着孩子去看医生，拒绝签署医疗网络提供的一份表格，表格要求她同意将会谈音频分享给包括微软Azure在内的供应商，而微软Azure是OpenAI的最大投资方。鲍尔-卡汉表示，她不希望如此私密的医疗对话被分享给科技公司。

鲍尔-卡汉表示：“文件中明确提到这些营利性公司将有权访问数据。”她是该州议会的民主党议员，代表旧金山郊区的部分地区。“我当时的反应是，‘绝对不可以。’”

约翰·缪尔健康系统的发言人本·德鲁表示，该系统遵守州和联邦隐私法律。

https://x.com/AP/status/1850150400424345858


### 197

方军 2024-10-28


Meta 出了一个 NotebookLM 的开源版，不过我觉得他们没明白一件事，这个产品的特点不是串起来工作流，也不是效果，而是和 Google 整个工作效率相关的产品的融合可能性。

AI 翻译：哇！Meta 发布了一个开放的 NotebookLM 配方：NotebookLlama  

它使用 L3.2 1B/3B 进行 PDF 预处理，L3.1 70B 用于创建转录文本，L3.1 8B 用于重写，以及 Parler TTS 用于文本转语音。

步骤 1：预处理 PDF：使用 Llama-3.2-1B-Instruct 预处理 PDF 并将其保存为.txt 文件。

第二步：转录员：使用 Llama-3.1-70B-Instruct 从文本中编写播客转录稿

第三步：戏剧性重写器：使用 Llama-3.1-8B-Instruct 模型使剧本更具戏剧性

第四步：文本转语音工作流程：使用 parler-tts/parler-tts-mini-v1 和 bark/suno 生成对话播客

还有一些粗糙的地方，但它听起来已经相当火爆了


### 198

方军 2024-10-28


看一本热门书的豆瓣评论，看崩溃了

好评的人呢，让我觉得，这读者水平也太糟了，没抓住要点

差评的人呢，普通吐槽还行，一到正经内容就全错，说明是没看懂的愤怒啊

当然了，本来看热门书就是信息韭菜行为。

猜我看没看呢？看了，AI看的，大概给我列了各章大纲，扫了一眼。

十分钟看完了，比如果有实体书翻起来快。

想起来我们以前有个老朋友，虽然是朋友，但成为同事后，我们不跟他合作的，他管着一摊，我们就绕着走，因为他这位老大评价所有的别人的项目就两个字——“虚妄”。哈哈，瞎说八道很开心，真一起干啥事，受不了啊。



### 199

方军 2024-10-28



一点小小的感悟：别把自己正在关注的知识等于自己

最近有点尴尬，在推上，一个某个专业上认识的人由于他鼓吹某种观点（其实这是他的工作，而不一定是他的自身立场，如果坦诚看），因此，但凡有任何讨论，他都喋喋不休。当他介入讨论时，我实在不想做任何回应。

理由很简单，专业讨论应该不要把自身带入。他几乎把任何对此专业问题哪怕略有批评、然后以改进的看法，都看成对他的攻击。说起来，他总是长篇大论，会明显地与各种讨论中的短小语言非常不同。

当然，他的劣势还在于，他的工作立场让他显得尤其不清醒、不公正。任何提及（正面、一般或负面）都会吸引他来捍卫自己的所谓立场。（其实，他有什么立场，同时他的工作职责就是增加曝光而已。）

我们这些喜欢抱持「看客」心态的人就放松很多。真心要讨论的，就严肃说、认真长篇大论。不想认真讨论的，就随便调侃。

我还有一个独特的观点，社交网络嘛，就是要乱七八糟，瞎说一气，这也是一种获取信息的策略，因为瞎说八道，可能会吸引到很多有意思的信息。我们有另外一个朋友最近还做了有意思的实验，他故意伪装一种与人言论上激烈争斗的风格。不过，他伪装得好难。

怎么能够与观点保持距离呢？我觉得蛮难的。比如去年有大概几个星期，我觉得那些说不需要提示语的人没道理啊，怎么可能不需要呢。当然我知道，他们是站在一个终极的立场上说的，使用 AI 最终是不需要提示语的。但我看到那样的观点，总有一种冲动想跟人家讨论一番。但如果真说了，其实已不是讨论了，而是试图说服别人。

我很快开始与自己的这一观点保持距离。方法就是各种调侃，有时候说提示语有用，那我就往这个方向上探索。有时候，又假设提示语没用，比方说，如果在一个具体场景里，直接问就好了。什么提示语都是不必要的。有时候，就是调侃，其实表情包就是一种有意思的调侃。

这并不是说我们自己没有立场、我们没有一些自己相信当前仍有效的原则。但是，越在这种情况下，保持开放性是必要的。

如果别人那么确信地说他能做到，与我理解的完全不同，那我一定要看看，他是怎么做到的（这个最好的故事是费曼和油漆工关于油漆颜色的那个故事与试验）。

这么做，往大了说，可以看到其他的可能性。往小了说，避免自己有与人「讨论」的冲动。

（这里面另外还有一种有意思的心态：这个问题如果我坚信自己是对的、但觉得你又不懂，真心没必要费力气说服。说得俗气一点，在一种我的确专业度高很多的对比下，你付钱来买我的意见时，你才会开始重视我的意见。）


### 200

方军 2024-10-28


我还是接受不了 AI 文字啊。从一个很差的语音稿，变成一个更差的文稿。试了几个提示语的效果均一般。

这是很差的语音稿
---
我们现在的这次 AI 浪潮是什么？我倾向于把它称为「生成式AI」（Generative AI），这个名字能体现以往 AI 热潮的的区别。

之前的 AI 算法，比如我们在视频网站或新闻头条上看到的推荐算法，或者在工厂中用于次品识别的模型，主要功能是进行判别，是所谓的判别式 AI。我们所经历的这一轮AI变革，其核心在于模型似乎能够生成过去不存在的内容，比如文章、图片、视频、音乐等。

但我认为，生成式AI带来的变化不仅仅是能够生成，更重要的是它带来了一种更深层次的变革——让知识变得触手可及。它最大的特点是，过去我们使用的各种信息工具，如互联网、维基百科、打车软件等，都无法很好地理解人类语言。它们过去只能大致理解，且不够准确。面对一篇长文章，它们无法有效地进行结构化拆分和理解。而现在的大型语言模型能够理解语言。理解完语言后，过去的产品可能只是给我们一堆拆分后的内容，但现在大语言模型竟然能够用通顺的语言再次组织成语言，呈现给我们。

例如，10月初， Anthropic 的CEO Dario Amodei写了2万字的一篇长文探讨 AI 带来的未来。我很想阅读，但又不想等待中文版翻译。现在，我可以这样做，我将英文原文交给AI，让它为我翻译并润色，最后我用听语音的方式听完了整篇文章。我发现它生成的中文语言甚至比过去的图书翻译还要好，当然，其中还是运用了一些略微复杂的提示语技巧。总的来说，今天的大语言模型能够理解语言、生成语言，它还能够遵循我们的指令。
---

这是AI转写的稿件
---
你知道现在这波AI热潮有什么特别之处吗？它被称为"生成式AI"。这和你以前在视频网站看到的推荐算法、或者工厂里用的次品识别系统都不一样。那些老式AI只会判断对错，而现在的AI却能创造全新的内容 - 文章、图片、视频、音乐，应有尽有。

但这还不是最重要的变化。真正的革命在于：知识变得触手可及了。你想想看，以前你用搜索引擎或维基百科时，它们对人类语言的理解多么有限。但现在的大语言模型不一样了 - 它能真正理解你说的话，而且能用流畅的语言给你回应。

举个例子：前不久Anthropic的CEO写了一篇2万字的英文长文，探讨AI的未来。你知道我是怎么读的吗？我直接让AI把它翻译成中文，然后用语音听完了全文。翻译质量甚至比一些出版物还要好。

这种AI还有个厉害之处：它能听懂你的指令。你让它从文章里找特定内容，或者根据最后一段做点什么，它都能明白你的意思。虽然有人质疑AI是否真的有推理能力，但从实用角度来说，它确实能完成这些任务。
---



### 201

方军 2024-10-29

[阳志平：AI分析三课，如何提升你的核心竞争力？](https://mp.weixin.qq.com/s/JqKamjDVospmz_Y8ZqB4Vg)

为未来而学
狗霸问：为什么要开 「AI 分析三课」？

阳志平老师答：
十年前，我创办的开智学堂致力于为知识工作者提供前沿的教育体系，其中，以信息分析为代表的英才四课广受欢迎，好评如潮，帮助了1000+知识工作者提升认知能力。
2023年，开智步入2.0时代，旗下正式成立活水智能，专注于帮助知识工作者提升AI生产力。而AI分析三课，正是过往开智学堂的信息分析能力在AI时代的全新升级。

AI学术分析：如何结合知识图谱技术和大模型，更好地发现一个领域的关键知识？如何利用AI工具，更好地理解论文，验证研究结论？如何在高端研发领域抓住AI时代的第一波红利？
AI商业分析：如何结合知识图谱技术和大模型，更好地评估公司价值？如何利用AI工具，更好地处理商业数据？如何利用AI工具，做出更优的商业决策？
AI职业分析：如何结合我提出的人生发展学和大模型，更好地评估适合自己的职业或行业？如何利用AI工具，更好地整理招聘信息、撰写并投递简历？如何进入前景广阔的AI新兴领域？


### 202

方军 2024-10-29

愤怒的哲学家写的东西真是很难耐心看，尤其现在很忙的状态下。

Rage against the machine
by Alva Noë

Alva Noë is a philosopher of mind whose research and teaching focus is perception and consciousness, and the philosophy of art.

[不会！AI不会思考，但人也可能不会思考](https://mp.weixin.qq.com/s/zXVKvpcHKJiaUw_bjD-U4g)

[Can computers think? No. They can’t actually do anything | Aeon Essays](https://aeon.co/essays/can-computers-think-no-they-cant-actually-do-anything)

\# 人工智能不会思考
\## 主旨信息
AI 不具备真正的思考能力，因为思考本质是一个充满身体性、矛盾性和反抗性的过程。

\## 论证结构
\### 1. AI的能力被神化的原因
- 计算机的复杂性和不可控性让人产生错觉
- 科学家过分简化了人类认知的本质

\### 2. 图灵测试的局限性
- 用文字替代对话掩盖了语言的身体性
- 将人类交流简化为规则化的游戏
- 忽视了游戏中的竞争与挑战元素

\### 3. 人类认知的本质特征
\#### 3.1 人类活动的纠缠性
- 语言使用包含质疑和反思
- 钢琴演奏需要与机器对抗
- 游戏涉及身体和情感参与

\#### 3.2 反抗与创造的关系
- 人类不仅遵循规则，还会质疑和改变规则
- 困难和阻碍是创造力的来源
- 学习过程包含经验和反思

\### 4. AI的根本局限
- 缺乏自主关注点
- 无法创造新的游戏和语言
- 仅能模仿而非真正理解和创造意义

\## 结论
AI不具备真正的思考能力，因为它无法像人类那样通过反抗和纠缠来创造意义。




### 203

方军 2024-10-29


我知道很多美国学者、企业家用口述（讲授）来写作，但要注意，他们一般都有很好的秘书，有时候会聘请真正的叙事型作家来一起写作。

但看看现在中文世界各种转述，真是糟糕啊。尤其到了图书这个级别，真是生产垃圾。看看一本书的负面评价（为什么想到这个，因为想靠口述、AI 来避免自己写，这是不可能的）：

（另外补充一点，所有评论我都大概翻了一遍，虽然说视频是不同的体裁，但也侧面反映视频的信息质量之差）

（再补，为什么它的视频收欢迎呢，因为一次讲一个国家，好过瘾，天下时势尽在掌握的那种霸气，新闻韭菜、电视韭菜、视频韭菜最爱。别以为看达利欧就不是，如果不太会看，基本上一样，我还看过看罗马史的信息超大号韭菜呢。）

- 求求了，不要再出这种直接短视频转文字的“书”了，还不如叫字幕稿。 如果你想写一本书，就从头梳理一本书的体系和行文方式，而不是直接音频导出。 有的时候我真的怀疑编辑的作用是什么。

- 垃圾，收割粉丝的书籍，比作者制作的 B 站视频都差劲！不知道封面上写X大，是为了给母校“抹黑”么？给社会生产文化垃圾！

- 感觉是短视频直接导出的文字。。。想表达短小精悍，结果光看到连篇车轱辘话。

- 视频做得不错，文稿出版成书还是略单薄了些

- 无论放在 b 站还是公众号、做成播客还是写在知乎回复里都绝对优质，唯独作为正式的出版物撑不起来，太单薄了

- 一本薄薄的册子,居然包含了除中美之外的主要经济体,主要从货币和财政政策进行探讨,除了日本比较深入以外,其他真是泛泛而谈,没有新意.还不如直接看视频呢,有点失望,书名起的很霸气,内容都是掺水货.

- 选题可以很符合当下，但是写的东西真的逻辑条理都不通，有些地方好像说了但好像又没说，跟大学生自己弄的微信公众号的文章一样

- 这哪是学经济，根本就是历史读本。金融的本质就是信用，石器时代结束不是石头用完了。

- 没必要买书，看看up主的视频就行了。买书的受众群体应该是up主的粉丝。

- 一直订阅追更视频，但是落到书上还是觉得严谨性和系统性不太行，甚至当科普都挺勉强。

- 内容非常浅薄，学过经济学的没必要再看了，内容和时势无关，就是一个简述，夹杂基本的经济学常识。

- 看视频不觉得逻辑这么差，一看书给我看困了。就是把视频的稿子热乎热乎成书了，要是没有这一步棋也不至于坏了好不容易积累下来的粉丝。还是做视频吧姐姐

- 想读的时候三星，看完给了两星。这些内容做成视频图一乐可以，做成书就显得深度不足了。还有一个问题，就是你会发现特别割裂，就是作为主旨的东西体会不到，周期波动下的国家社会和个人在哪里？...所以我想说，其实这只是可以用来补充谈资的意林类书，对于了解经济学的东西，还不如虚头巴脑的薛兆丰。

- 永远不要相信 UP 主把以前视频的内容拾掇拾掇就出的书，基本就是流水账，没有深度可言，纯纯的圈钱

- 对于经济一无所知的小白来说还是比较易懂的，但是有很多分析就像数学证明里“显然”一样，不清楚为什么就得出结论了？



### 204

方军 2024-10-29

Google / Youtube 真是统治地位啊

ChatGPT 不错，其实远超 Bing 了

source: similarweb




### 205

方军 2024-10-29


昨夜搞音频稿转录的纠结，质量非常差，反思目前 AI 使用的问题：

很多人搞一个提示语或搞一套工作流，然后宣称它能够完美地完成任务。

对于要求很低的人，比如把满足要求的线划在50分（都不及格）的，会觉得结果很好。他们也不知道结果并不好。

有些人也会对外说这个，但他们自己加上了极大的人力，最后让结果还可以，也许70分吧。他们会结果要求通常不高。

还有人就是对各种新技术、新做法表示新奇，他们惊叹各种可能性。

但我的痛苦是，这什么破玩意！我的要求其实也没那么高，我就是要个85分。这个时候基本上是两条路，以录音稿转录为例：

一是采用交互式，借鉴AI 的建议，反复地修改。

二是拆解步骤，细分开做，试图让 AI 多做一点。它多做一点，我就少做一点。

这中间的纠结主要还是，我不太喜欢别人讲话的方式，看到自己的「声音」不对，我必须得想办法改过来。（不过，我以后再也不审稿了，你们爱咋办咋办。）

其实我不该掉进这个坑，因为我自己早就明白，不要用AI 参与最终成品的生产。

它只可以在中间过程，不能直接参与成品的生产。


### 206

方军 2024-10-29


挑刺游戏，这个 AI 文章的Bug、AI味道太强的地方:

\# 找对方向比掌握技能更重要

在当今快速发展的商业世界中，我们经常会听到这样的建议：程序员要学设计，设计师要懂开发，产品经理要懂技术。这些建议听起来很有道理，但真的是这样吗？

让我们从一个真实的案例说起。N年前，一位程序员决定转型做产品经理时，有人给了他一个发人深省的启示：某二手车软件虽然用户体验很差，却能在市场上占据重要地位。原因很简单：在二手车这个供给驱动的市场中，能买到车比软件好用更重要。这个案例揭示了一个关键真相：市场需求才是决定产品成败的根本因素。

这让我想起商业大师Glenn Stearns的一句话：做生意的第一件事是找到买家。这个简单的道理却经常被人忽视。很多人在还没弄清楚市场需求之前，就急着去提升技能、考证书。这就像准备穿越沙漠，却花了半年时间造了条船。

事实上，成功者往往采取更务实的方式。以Elon Musk为例，当他决定创办SpaceX时，他没有选择去读航空航天的研究生，而是直接阅读《火箭推进基本原理》这样的专业书籍。他的方法告诉我们：学习要有针对性，直指问题核心。

所以，在思考是否要跨界学习时，我们需要问自己三个问题：

1. 这个技能真的是我当前最需要的吗？
2. 学习这个技能是否能直接解决我面临的问题？
3. 相比学习新技能，是否有更高效的方式达到目的？

回到开头的问题：程序员要不要学设计？设计师要不要学开发？答案是：要先搞清楚你要解决什么问题。如果你是一个独立开发者，需要独立完成产品的所有环节，那么学习设计确实有必要。但如果你在一个专业分工明确的团队中，与其花时间去学习其他领域的技能，不如把精力放在理解用户需求和市场动态上。

这就像是在玩一个策略游戏：有限的时间和精力就是你的资源，如何分配这些资源才能获得最大回报，这才是真正需要思考的问题。与其盲目追求全栈能力，不如先找准方向，明确目标。

正如那艘在沙漠中无用的船，技能的积累如果脱离了实际需求，再多也是徒劳。在这个快速变化的时代，找对方向比掌握某个具体技能更重要。因为只有找对了方向，你才能确保你的每一分投入都是有意义的。

记住：在开始学习之前，先找到你的"买家"。这不仅是商业的真理，也是个人发展的重要准则。


### 207

方军 2024-10-29


宝玉后面模拟的这个提示语好不好呢？

我觉得不好，他这里是没法分享人家实际提示语，所以整体思考模拟一下。但哪怕最小的编程任务都不是这样工作的。真正的编程工作是分步、选择的、交互的。

刚刚还试验李继刚的逻辑之刀提示语，能看懂，效果也很好，但真是无用之用了。我认为逻辑上就不对头。卡片为他的提示语加分很多。


### 208

方军 2024-10-29

从架构角度认识AI:为架构师解读机器学习与生成增强技术

一个不错的通俗解释，推荐看原文：

[从架构角度认识 AI：为架构师解读机器学习与生成增强技术](https://mp.weixin.qq.com/s/hEH7yTxmz2MMTmlESFbnFg)

[A Primer on AI for Architects with Anthony Alford - InfoQ](https://www.infoq.com/podcasts/primer-ai-for-architects/)

### 209

方军 2024-10-29

不太会看刘润这种年度演讲，看了看AI提取大纲，感受很一般。

我觉得这些大牛本身还是很厉害的，但逐渐远远走出了自己的能力圈。

刘润有强项的是教上班族如何做个好的工作者，我是这么看的。这个事在日本就有大量的图书，也有各种名人，中国这件事做得最好的是刘润。5分钟商学院到现在都是好的教材。

查看详情
李福森 表达了态度
乘风：刘润的本事是把大家知道的各种理论讲的比90%的老师都要好
2024-10-29 20:50
阳志平：感觉特别像我刚刚批评过的那类偷笑
2024-10-29 21:00
方军 回复 阳志平：超出能力圈太远
2024-10-29 21:30
方军 回复 乘风：没有的
2024-10-29 21:40
方军 回复 乘风：我个人的建议是，小心那些讲得特别通俗的，虽然大师也很通俗，但有些通俗仅仅是过度简化，不一样的。

一个判断方式是，如果一个人懂很多，什么都能通俗，那要谨慎。大师一般只懂少数几个领域。
2024-10-29 22:05
乘风 回复 方军：有道理！我看他的书，基本是学习如何表达和如何写作，还是比我强很多的，哈哈哈
2024-10-29 22:13
方军 回复 乘风：我甚少批评直接批评某个人的某个作品，基本只夸某个。但就刘润老师的底层逻辑而言，在底层逻辑上就有问题。当然了，我也不知道什么是底层逻辑，所以就以你的矛攻你的盾吧。五分钟商学院中工作技能基础的部分超级棒！
2024-10-29 22:43
遇水桥：感觉吴军老师现在也有这个趋势，啥都讲
2024-10-30 00:08




### 210

方军 2024-10-29


Whiteboard-of-Thought: Thinking Step-by-Step Across Modalities
Sachit Menon, Richard Zemel, Carl Vondrick

When presented with questions involving visual thinking, humans naturally switch reasoning modalities, often forming mental images or drawing visual aids. Large language models have shown promising results in arithmetic and symbolic reasoning by expressing intermediate reasoning in text as a chain of thought, yet struggle to extend this capability to answer text queries that are easily solved by visual reasoning, even with extensive multimodal pretraining. We introduce a simple method, whiteboard-of-thought prompting, to unlock the visual reasoning capabilities of multimodal large language models across modalities. Whiteboard-of-thought prompting provides multimodal large language models with a metaphorical `whiteboard' to draw out reasoning steps as images, then returns these images back to the model for further processing. We find this can be accomplished with no demonstrations or specialized modules, instead leveraging models' existing ability to write code with libraries such as Matplotlib and Turtle. This simple approach shows state-of-the-art results on four difficult natural language tasks that involve visual and spatial reasoning. We identify multiple settings where GPT-4o using chain-of-thought fails dramatically, including more than one where it achieves 0% accuracy, while whiteboard-of-thought enables up to 92% accuracy in these same settings. We present a detailed exploration of where the technique succeeds as well as its sources of error.

[[2406.14562] Whiteboard-of-Thought: Thinking Step-by-Step Across Modalities](https://arxiv.org/abs/2406.14562#:~:text=Whiteboard%2Dof%2Dthought%20prompting%20provides,the%20model%20for%20further%20processing.)

### 211

方军 2024-10-30



GitHub Spark 并不仅仅是代码生成器，它更是一个“以应用为中心”的平台，帮助用户将想法转化为实际的功能应用。

AI： GitHub Spark 的主要用途是：

1. 让用户通过自然语言快速创建和自定义小型 web 应用（微应用），降低开发门槛

2. 特别适合实现那些原本复杂但有趣的小型应用，比如：
- 儿童零花钱跟踪器
- 车辆动画世界
- KTV之夜记录应用 
- 城市地图搜索应用
- 自定义的 Hacker News 客户端

3. 核心功能包括：
- 通过自然语言驱动的编辑器生成代码
- 提供托管运行时环境，包括数据存储和AI模型支持
- 支持PWA的仪表盘，可以在任何设备上管理和启动应用

4. 目标是让软件开发变得像自定义开发环境一样简单，使所有人(不仅是专业开发者)都能根据需求快速构建个性化的轻应用。

Spark的作用是通过AI降低应用开发门槛，让普通用户也能快速实现自己的软件创意。

[GitHub Spark：AI 零代码开发微应用](https://mp.weixin.qq.com/s/jZxzkvU9bXhRr85nFfASZA)

### 212

方军 2024-10-30


Unix 设计哲学
原文参考：https://wiki.c2.com/?EightyTwentyRule

[Eighty Twenty Rule](https://wiki.c2.com/?EightyTwentyRule)

Mike Gancarz 在 1995 年出版了一本关于此主题的小书《The UNIX Philosophy》，他列出了两套原则：9 个主要原则和 10 个次要原则。

主要原则

小即是美（Small is beautiful.）。小型程序相较于大型程序有极大的优势，其中之一就是可以以独特且有用的方式与其他小程序组合。
让每个程序只做好一件事（Make each program do one thing well.）。专注于单一任务的程序可以减少不必要的代码，从而减少额外开销、复杂性和缺乏灵活性。
尽早构建原型（Build a prototype as soon as possible.）。大多数用户在看到软件之前并不知道自己真正需要什么，因此需求文档常常无法准确反映用户的实际需求。Unix 设计哲学将原型开发作为方法论的核心：尽早给用户提供一些初步成果，让用户提出反馈，并以此为基础进行改进。
优先选择可移植性而非效率（Choose portability over efficiency.）。如果当下的硬件能够勉强运行某个程序，未来的硬件将轻松胜任。因此开发人员的任务是确保程序能够轻松在新硬件上运行。
将数据和配置信息存储在扁平的 ASCII 文件中（Store data and configuration info in flat ASCII files.）。宝贵的数据通常比任何一个程序、机器、编程语言或用途更为长久。数据只有在被使用时才有价值，而扁平的文件能帮助数据在最长时间内保持可用性。对于复杂的数据结构，如果扁平文本格式不合适，可以使用像 XML 这样的结构化文本格式，这样总是可以去除标记来获取原始数据。
利用软件的杠杆效应（Use software leverage to your advantage.）。许多程序员对可复用代码模块（re-usable code modules）的重要性缺乏深入理解。代码复用帮助开发者利用软件的杠杆效应，一些 Unix 开发者利用这一概念在相对较短的时间内创建了大量应用程序。
使用 shell 脚本增加杠杆效应和可移植性（Use shell scripts to increase leverage and portability.）。脚本具有极大的杠杆效应——每行脚本都可以调用多个“正规”程序，每个程序可能包含数千行代码。无法复用其他程序的程序员将不得不重新编写这些功能。
避免捆绑的用户界面（Avoid captive user interfaces.）。一个阻止用户使用其他命令的程序会“束缚”用户，阻止其利用其他命令。程序应具有多种使用方式，以最大化其实用性。
让每个程序成为过滤器（Make every program a filter.）。所有软件的基本性质是只能修改数据，不能创造数据。因此它们应被编写成过滤器，因为它们本质上就是过滤器。

次要原则
允许用户定制环境（Allow the user to tailor the environment.）。没有单一决策适合所有用户——不要强加。环境的可定制性越高，用户越能根据自己的需求调整，使用起来会更愉快。
使操作系统内核保持小而轻量（Make operating system kernels small and lightweight.）。尽管对新功能的追求永无止境，Unix 开发者倾向于将操作系统的核心部分保持小巧。他们不总是能实现这一目标，但这是他们的追求。
使用小写并保持简洁（Use lower case and keep it short.）。在 Unix 环境中使用小写字母已成传统，即便当初因为电传机上带有下行的文本更易阅读的原因已不再适用。
节约纸张（Save trees.）。打印到纸上的数据基本上就“死”了。保持所有文本在线，使用强大的工具来处理文本，有充分的理由。
沉默是金（Silence is golden.）。沉默的命令通常更易用，仅提供所需的功能而无多余信息。可以为喜欢更具对话性的用户提供包装器。
并行思维（Think parallel.）。大多数任务由可以并行处理的子任务组成，这对用户交互也适用。并行处理可节省大量时间和减少挫败感。
整体大于部分的和（The sum of the parts is greater than the whole.）。一组小程序构建的大型应用比单个大型程序更灵活，因而更有用。尽管两种方法可能都具有相同的功能，但“小程序集合”方法更具前瞻性。
寻求 90% 的解决方案（Look for the 90% solution.）。做到 100% 往往很难，做到 90% 更高效且成本更低。处理 90% 并让剩下的 10% 自生自灭——通常它们会比你更好地解决自己的特殊需求。
劣质即优（Worse is better.）。便宜但有效的东西比高质量而昂贵的更可能普及。PC 兼容世界借鉴了这一思想并取得了很大成功。
分层思维（Think hierarchically.）。分层允许任务和属性在嵌套元素中统一应用。这是一个鼓励分解和模块化的强大理念。


### 213

方军 2024-10-30

一个极有意思的讨论：

Lencx: 本来想尝试一下 react-query，谁知看文档发现还有 router，store...，文档是越看越多，有点懵逼了 （感觉 tanstack 造出了很多概念）。

注：之前都是用 react-router-dom，也不知道 tanstack router 好用不，粗看文档发现支持的路由方式挺多（如文件、代码）。

宝玉：像 react-query 这种库，在你不太懂http协议或 fetch 的API 的时候，用起来非常方便，或者你很懂但是想偷懒用起来也很省事。

但如果你很懂底层原理，知道自己想要什么，用 AI 帮你实现 fetch 逻辑比直接用这类库可能更好，因为不再是黑盒子，不需要查它的接口文档，不需要引入额外的库。



### 214

方军 2024-10-30


Runway CEO 认为 Runway 不是一家 AI 公司，而是一家媒体和娱乐公司。AI 正在成为像电力或互联网一样的基础设施，AI 已经普及。每家公司都正在会将会使用 AI。如今重点是如何使用 AI 构建新的内容。未来变革的浪潮将由那些懂得如何利用 AI 来创造新形式的媒体、新型的体验和新的叙事方式的人引领。

好像很多变化在发生：

1. "AI是讲故事的必要工具"
2. "相机不仅创造了摄影，还催生了整个行业、经济体和艺术形式"
3. "正如相机改变了我们捕捉现实的方式，AI正在改变我们创造现实的方式"
4. "真正的革命并不在于技术本身，而在于它所促成的事物"
5. "模型已经商品化，技术基础也已普遍确立并广为人知。无秘密可言"

新的媒体格局
[Cristóbal Valenzuela](https://cvalenzuelab.com/newmedia?continueFlag=0f330e7b74d1c55481c53d0381543412)

Runway 不是一家 AI 公司。Runway 是一家媒体和娱乐公司。事实上，我认为 AI 公司的时代已经过去了。

这并不是因为 AI 失败了——恰恰相反。这是因为 AI 正在成为像电力或互联网一样的基础设施。如果今天称自己为 AI 公司，就如同在 2024 年自称是互联网公司一样毫无意义。这是因为 AI 已经普及。每家公司都在使用互联网；每家公司也将会使用 AI。

对于 Runway，我们的核心是艺术、媒体和广义的娱乐。大约七年前，我们创办了 Runway，怀抱着一个至今几乎未曾改变的愿景：AI 是讲故事的必要工具。为了实现这一愿景，我们倒推回去，打造了最优秀的研究团队，提供最优质的模型，进而构建最佳的产品。

我经常将我们的工作比作一种新型的相机。不是字面意义上的拍摄图像，而是其历史性的影响。相机不仅创造了摄影，还催生了整个行业、经济体和艺术形式。电影、电视、TikTok——都是那台捕捉光与时间的革命性工具的“后代”。

我认为我们在 Runway 所做的工作是为全新的媒体格局奠定基础。正如相机改变了我们捕捉现实的方式，AI 正在改变我们创造现实的方式。我们构建的模型和技术能力只是开始——它们就像那些最初的达盖尔银版照片，原始但充满可能性。很多人会犯下将 AI 视为终点的错误，但实际上它不是。AI 是机制，是成就更伟大事物的底层基础设施。真正的革命并不在于技术本身，而在于它所促成的事物：新的表达形式、新的叙事方式以及联系人的新方式。

媒体传统上就像是一条单行道。创作通过既定的渠道流向消费者。即使传播方式曾被颠覆——先有社交媒体，再有流媒体——基本模式仍然未变：有人创作，其他人消费。角色分明，界限清晰。然而，我们现在正见证一种不同的局面。想象一下观看一部随着你观看过程而自我生成的节目——真正动态的内容，它能够回应你，理解你，为你而创作。这就是通用模拟和世界构建。当内容能够在实时中自我塑造时，创作和分发的界限将消失。这便是全新媒体格局的基础所在。它关乎对媒体的根本性重新想象：互动的、生成式的、个性化的——同时也是共享的、普遍的。

这也是为什么纯粹的 AI 公司正逐渐变得过时。如今有趣的问题不再聚焦于技术本身，而是聚焦于我们如何用技术来建构新的内容。下一波创新浪潮将不会来自于专注于构建更好模型的公司。模型已经商品化，技术基础也已普遍确立并广为人知。无秘密可言。变革浪潮将由那些懂得如何利用这些工具来创造新形式的媒体、新型的体验和新的叙事方式的人引领。基础设施已经铺设，地基已经打好。现在到了最激动人心的部分：用它来创造有意义的内容。

AI 公司的结束标志着更有趣的事物的开始：真正的新媒体的诞生。这不仅仅是新的平台或格式，而是创造和体验内容的全新方式。我们不再是构建一家 AI 公司。而这才是一个更令人振奋的使命。就像一直以来那样，回归我们的初心。


### 215

方军 2024-10-30

连网络大名人的好文章，我现在都觉得是面向信息韭菜的，这里面除了很有力地推荐一本书，然后呢，那么多废话是干嘛的？不过我也许应该反思下，现在AI获取信息的力度太强了，对这种一下子就忍耐不了了。同时，我也忍耐不了放一堆乱七八糟图那种感觉。国外现在竟然有很多报告也开始放很多梗图，当然金融机构报告常见放各种无意义的历史曲线。

每次批完人不能不建设，我搞个「编辑」版，发挥早年当编辑的一种能力，简言之就是大幅删减，直到骨头。

（删减版，原文附后）
---

人人都应该读的生活秘笈

和菜头

每过一段时间我都要做个测试，看我的大脑是否被网络和手机损害。方法是找一本书来，看看自己能否一口气从头读到尾。许多人已经做不到了，中间要跳开无数次，我知道。

昨天我的测试对象是《匮乏大脑》（Scarcity Brain）这本书。《匮乏大脑》有很扎实的11章，我从昨晚开始看，推荐一轮之后继续看到凌晨一点半。今天早上8点半起床之后，又接着读到了10点35，终于满意地看到了最后一个字，爬上网来画图然后写文章。

我想，这本书适合我们这个时代的每一个人。因为它就是我们这个时代里人们的生活秘笈。你要知道一个常识，在任何时代里，生活的变化总是快于诠释这种生活的理论。然而，我们需要理论，需要用它去理解和发现我们自身所处的生活，需要用它去解释为什么自己在经历这一切。

为什么大家都在减肥却不成功？为什么我们都在追求社交网络成名？为什么我们总是无休止地为什么而上瘾？为什么我们购买了那么多衣服却觉得没有衣服穿？

我们在日复一日的生活中有所感知，但是又说不清楚。我们感觉到自己被操控，操控可能来自外部也可能来自内部，但是又找不见肇因。《匮乏大脑》很清晰地回答了这些问题，而且给出了非常简单明晰的解答：

人类思维中有一个强大的怪癖，我们快速而连续进行的各种行为---从赌博到暴饮暴食、过度消费、狂刷剧集、酗酒等等，都由一个“稀缺循环”所驱动。它由三部分构成：

机会→不可预测的奖励→快速重复性

书中介绍，这种对于稀缺性的高度关注是人类在亿万年进化过程中形成的心理定势，由此而产生了心理和行动上的“稀缺循环”。这种循环的奥秘最先被拉斯维加斯的赌场发现，具体来说，就是他们在重新设计老虎机的过程中，发现了可以操控赌客高速连续下注的方法。

如今，类似的人造“稀缺循环”已经被广泛地应用于广告业、社交媒体、短视频平台、食品工业、新闻业等等社会领域，不断成功地唤起人们的匮乏感，然后踏入一早设计好的“稀缺循环”，不断刷刷刷，买买买，看看看，吃吃吃，根本停不下来。

我读到前三章的时候，一度认为这本书非常邪恶。如果互联网产品经理读了这本书，他们操控用户的能力不知道能提升几个量级。他们通过产品榨取利润的能力不知道能提升几个倍数。但是读到后来，我认为作者迈克尔·伊斯特 （Michael Easter）是个坦诚的学者，他只是公布了自己思考的结果，对于人类如何利用匮乏心理，利用“稀缺循环”保持了中立的态度。

《匮乏大脑》在2023年出版，目前应该还没有引进翻译。拜AI所赐，翻译一本原版书在今天已经不是什么难事，那么如果你有机会的话，可以找来看一看。我承诺你会得到一段奇妙的旅程，以及读完之后轻松释然、快乐明澈的感觉。
---

人人都应该读的生活秘笈

和菜头

每过一段时间我都要做个测试，看我的大脑是否被网络和手机损害。方法是找一本书来，看看自己能否一口气从头读到尾。许多人已经做不到了，中间要跳开无数次，我知道。

昨天我的测试对象是《匮乏大脑》（Scarcity Brain）这本书，看完第一章我就向朋友和亲属推荐。这当然会风险很高，很容易败坏人品。因为在我们这个时代，书籍和电影一样，也喜欢做“高概念”。在第一章抛出一个诱人的观点，在随后的章节中你以为它会深入而下，给你带来更多思考和启发的时候，却发现作者停留在观点表面连续舔了八章，死活就是不肯下牙。

《匮乏大脑》有很扎实的11章，我从昨晚开始看，推荐一轮之后继续看到凌晨一点半。今天早上8点半起床之后，又接着读到了10点35，终于满意地看到了最后一个字，爬上网来画图然后写文章。

我想，这本书适合我们这个时代的每一个人。因为它就是我们这个时代里人们的生活秘笈。你要知道一个常识，在任何时代里，生活的变化总是快于诠释这种生活的理论。然而，我们需要理论，需要用它去理解和发现我们自身所处的生活，需要用它去解释为什么自己在经历这一切。

为什么大家都在减肥却不成功？为什么我们都在追求社交网络成名？为什么我们总是无休止地为什么而上瘾？为什么我们购买了那么多衣服却觉得没有衣服穿？为什么我们的生活质量比五十年前提升如此之大却又多出那么多的疾病？以及总体上的那个时代问题：为什么我们时常感觉口渴，喝到的却总是盐水？

我们在日复一日的生活中有所感知，但是又说不清楚。我们感觉到自己被操控，操控可能来自外部也可能来自内部，但是又找不见肇因。《匮乏大脑》很清晰地回答了这些问题，而且给出了非常简单明晰的解答：

人类思维中有一个强大的怪癖，我们快速而连续进行的各种行为---从赌博到暴饮暴食、过度消费、狂刷剧集、酗酒等等，都由一个“稀缺循环”所驱动。它由三部分构成：

机会→不可预测的奖励→快速重复性

书中介绍，这种对于稀缺性的高度关注是人类在亿万年进化过程中形成的心理定势，由此而产生了心理和行动上的“稀缺循环”。这种循环的奥秘最先被拉斯维加斯的赌场发现，具体来说，就是他们在重新设计老虎机的过程中，发现了可以操控赌客高速连续下注的方法。

如今，类似的人造“稀缺循环”已经被广泛地应用于广告业、社交媒体、短视频平台、食品工业、新闻业等等社会领域，不断成功地唤起人们的匮乏感，然后踏入一早设计好的“稀缺循环”，不断刷刷刷，买买买，看看看，吃吃吃，根本停不下来。对了，“根本停不下来”也是我们这个时代的口号之一，《匮乏大脑》对于为什么停不下来给出了答案。

无知无觉地陷入“停不下来”的现实境遇，我们每个人都或多或少，或轻或重地正在经历。因此，揭示出这种现实境遇后面的原理，对于我们认识自身，挣脱循环会有莫大帮助。所以我说它是人人都应该读的生活秘笈，你在现实生活中感受到的几乎所有不适、不满之处，在这本书里都给出了解答，都可以用“稀缺循环”这个单一理论加以解释，并且提供了停下来的可能。

我读到前三章的时候，一度认为这本书非常邪恶。如果互联网产品经理读了这本书，他们操控用户的能力不知道能提升几个量级。他们通过产品榨取利润的能力不知道能提升几个倍数。但是读到后来，我认为作者迈克尔·伊斯特 （Michael Easter）是个坦诚的学者，他只是公布了自己思考的结果，对于人类如何利用匮乏心理，利用“稀缺循环”保持了中立的态度。有些公司，有些组织，有些个人可以利用它们去控制人类，同样也有人可以利用相同的机制去造福人类。重点不在于批判或者赞美，而是把这个事实告诉给公众，让他们意识到无数会引发大家自我指责，自我愧疚的行为背后究竟是什么在发生作用。

这本书值得反复阅读，因为作者是个极为富足的人。在许多章节中，他随手写下的一两个句子，对于其他作家而言可能足够写成一本书，而迈克尔·伊斯特就那么明晃晃地写在那里，然后继续回到他的讲述主线上去，一点都不觉得可惜。

我对类似题材的书籍有一个判定标准：价值=信息量×洞见×趣味。《匮乏大脑》在这三个选项上都做得很不错，足够多的信息量，足够深的个人洞见，加上生动有趣的个人经历，让我读下来深感满足，并且相信在那些作者点到为止的精彩观点之处，还可以对照自己的生活继续深入下去，获得更多启示和洞见，把一本书读出十本的效果。

《匮乏大脑》在2023年出版，目前应该还没有引进翻译。拜AI所赐，翻译一本原版书在今天已经不是什么难事，那么如果你有机会的话，可以找来看一看。我承诺你会得到一段奇妙的旅程，以及读完之后轻松释然、快乐明澈的感觉。

---
收起

查看详情
蒋舟可、遇水桥 表达了态度
方军：另补充，我翻了下这本书的AI翻译版，我觉得没那么好，可能我太挑剔了，我还是对记者那种啰嗦难以忍受。当然我知道他们是为了照顾大众，把所有的都变成一种我去了哪儿、看到什么的讲述。蛮无聊的的，满足大众。
2024-10-30 13:20




### 216

方军 2024-10-30


刚刚与朋友瞎扯的观点，但也不全是瞎扯：

甲：对A16Z为代表的一些投资人所鼓吹的web 3数据主权(read, write,OWN)，我一直难以理解。网络数据从根本上是与网络结构一体的，其主要价值在于通过网络结构快速地流动和新陈代谢的过程。如果说web 2数据的价值主要被平台运营方所捕获，web3网络数据（如以太坊网络数据）应该是完全开放的公共资源，每个人都有数据使用权的平等机会，而不是什么个体所有，个体所有是没有生产效益的。

我：特别赞同你的看法。我对 Chris Dixon 的 Own 的曲解是，资产。我认为他书里也没太多提多少数据本身。

乙：哈哈哈，这个事可以讨论。个体所有没有生产效率不符合过去五百年来人类社会的历史经验。个体所有，并不意味着不能集中使用，只意味着你不能偷不能抢了，得买了。

再退一步说，假设个体所有真的没有生产效益，所以呢？生产效率那么牛逼，可以以此为理由侵犯私有产权？

我 ：可以从一个很小的事情我们都有体会的事上看

有人对自己的文字版权特别看重

但我们这些常年上网的，基本上把自己已经发布的文章视为进入公共域

我是认为自己的文字就是 CC0，完全开放。别人愿意提及名字那好，没有，那也无所谓。

我们的文字能否再生产、创造价值呢？当然，但不是靠把控版权。


### 217

方军 2024-10-30

[AI时代，哪种人更被需要？](https://mp.weixin.qq.com/s/2_JKxSNTeW_RhAOZJraeNQ)

[方军 | 大模型热后的冷思考：如何用AI加速知识学习](https://mp.weixin.qq.com/s/n9DP7yLdTcwl19WGtoJobw)


### 218

方军 2024-10-31


我终于深入地用起来cursor 了

我的感受是，如果一个人拼命说AI 可以编程，Cursor 炸裂，他多半是不编程的人。

Cursor一点都不神奇，我的体会和直接用claude sonnet相似，但肯定比copilot好很多。

再次深入用，没去年4月感觉好


### 219

方军 2024-10-31


吐槽产品，那就再吐槽一个，大家都知道我最爱知识星球，所以只吐槽它的小小细节不会减少对它的热爱。

之前跟吴老板建议过，啊呀，一堆态度，好尴尬啊。

我觉得不需要那么多，一个点赞或爱心，或点赞加爱心就足以。

这么多我只在discord里面看到过。

小红书在这个方面就特别直接，只有爱心加收藏。

我之前给吴老板的建议他觉得现在的更好。今天看到现在文案是“表明了态度”，有点啰嗦啊。


### 220

方军 2024-10-31

这几天很多人说 稀缺大脑那本书：

- AI成为基础设施，如同电力和互联网
  - Runway案例：从AI公司转型为媒体娱乐公司
  - AI技术将无处不在，成为通用工具

在过剩世界中：
- 制造稀缺是统治的艺术
- 成为稀缺是幸存的艺术



### 216

方军 2024-10-31

最近作为一个外行，听了很多各种人快速介绍金融（的大概），我发现，可能所有行业都一样吧，都是各种词。

在行业中的人觉得一切都很自然啊，其实说的人不一定懂。

但外人一看，完全这个和那个啥关系，都搞不明白。

互联网、AI 都来了一个效果，大家乱七八糟看一看，但其实还是什么都不懂。

或者有人给了一个巨长的表，学过这些就明白了。但如果真干活就会发现，这些跟活没啥关系，真要干活的时候，可以半天学懂。

缺的是什么？缺的是一个「框架」。

AI越强，一个领域的框架越重要。