### 01

方军 2024-10-01

李继刚最近的提示语都看了，现在感觉有点炫技。

一般来说分成两个部分：一是对文字的连续处理，二是绘图。

我对绘图部分不感兴趣，因为用 LLM 这样绘图不如另外加个流程，用 MJ 其他图形模型绘图。

那第一部分呢，似乎也没什么实际用途。

可能这反映了两种截然不同的想法：

他的想法是，对文字进行一连串的处理：

A -> B -> C -> D ->E

试图在这样的变形中创造出截然不同的意像出来。

而我认为，LLM的用法应该是，让它就现有的高质量文字进行转换，同时步骤也不用太多，一次转换能做那是最佳。

（输入高质量的文本）--转换--> 用于我们辅助理解的中间结果

注意，我这里特别强调，转换出来是辅助我们理解的中间结果，而非最终结果。

这也是和他思路的一大差别，我认为如果不是那些大家现在还不强求的图形诗句效果，那些文字是很难被接纳的。



### 02

方军 2024-10-01

这个提示语用英文写并没有变得更好，继续尝试中：

```
请你按如下假设来分析一篇文章的主要内容：一篇文章通常围绕2-3个核心元素，分析它们之间的关系：如果2个元素，就是两者的对比。如果是3个元素，就是两两之间的关系。

请仔细阅读如下文章，给出2-3个核心要素。然后，给出它们两者或三者之间的关系，要简明扼要：
```

```
Read thoroughly to identify 2-3 core elements(the key concepts or ideas). 

Output the elements and analyze the logic relationship between each of them. Output in **Chinese** and in the original words and style. 
```

附注：把一个文章的要素简化为几个，这个有点简单粗暴了。

但从就是理解的角度是可行的。我们怎么都得先搞明白哪几个核心要素和它们之间的关系。否则直接去看细微之处，获得的信息是杂乱的。




### 03

方军 2024-10-01

147 为什么要用 AI 提取大纲

在使用 AI 进行辅助阅读的过程中，我日益感受到 AI 和之前所有计算机技术的不同：它能够处理非结构化的信息，尤其是能够处理人类语言文字。

用 AI 提取大纲，是一个比较浅层的人类语言文字处理。但是，这是之前所有的计算机技术都做不到的。（再往前一步，用 AI 去重新组合形成新的文字，也许有可能，但我更愿意在现在这一步多停一段。）

那么，为什么要使用 AI 提取大纲呢？我这几天在重新读认知科学家丹尼尔·T. 威林厄姆写的《为什么学生不喜欢上学？》。这本书开篇就有一句话：

> 与普遍的看法相反，大脑的设计不是为了让你思考，而是为了让你不用思考，因为大脑其实并不擅长思考。

用 AI 提取大纲，实际上是又一个用来辅助阅读时思考的「拐杖」。注意这个词「拐杖」。

即便要读懂不那么难的内容时，我们所感受到的困难也不小，除非它非常短（比如推特140字），或者它是短论证（1500字左右），或者是叙事或强诉诸感情（普通人爱读这些）。

以《为什么学生不喜欢上学？》第一章为例，13000 字的规模，作者善于吸引与保持注意力的技巧，叙述很结构化、很清晰，但要把握其中的信息需要拐杖。过去有：

- 铅笔与荧光笔标注、图书折角；
- 在一张A4纸上随手写的关键词；
- 将内容详细地拆解，我分享过我喜欢用类 PPT 形式；
- 写笔记与卡片、讲给别人听等。

目前看，在读之前或之后，有一个大纲（哪怕仅仅是直接形成的目录，非AI提取），也能减少把握整体所要耗费的脑力。如该书所说，我们都不愿意思考，其实是不愿做无谓的思考——如果有更好的拐杖，为何不用。

拐杖听起来不好，那就叫登山杖吧。现在有了 AI，我们相当于有了更轻、强度更高登山杖了。以大脑爱偷懒这个原理来看，为何不用？

这本书第一章其实包括两个观点：第一，大脑不擅长思考，第二，大脑喜欢思考，用原文话说就是“人们天生好奇”。还是用登山杖的比喻，如果不去登山就不需要登山杖了，但你怎么能不让我去登雪山呢？因此，拐杖或登山杖是必须的，我喜欢说是拐杖是因为，真心在看某些书时觉得老了（以前应该不需要拐杖的）不只是因为它是难攀登的雪山。但还是那句话，有更好的拐杖，为何不用？

说明：《为什么学生不喜欢上学？》作者还有一本新书中文版近年出版了，题为《大脑想要这样学》，其内容比较容易把握，是94个分成一个个单篇的方法，可以说是前一本书的实践版。

图为 AI 提取大纲，其中，二级标题及对课堂的启示，就是原文的小标题。



### 04

方军 2024-10-01


如果大语言模型能够做语言转换，那么它能否做风格的转换呢？

更具体点说，它能否做古典风格与平实风格之间的转换呢？

我们先不管古典风格（特纳一书中所指）的五个立场，真相，呈现，场景，角色，思想与语言。「观看世界」这个基本设定要说给 AI 听让它理解并执行，不知道怎么说。

我们只看表达本身。缩减到这个范围，应该是大语言模型能力范围内的事了。先看看能否形似。

先摘几个范例：

平实风格：“真相纯粹且简单”（The truth is pure and simple）。
古典风格：“真相很少纯粹，也绝不简单”（The truth is rarely pure, and never simple）。

平实风格：“优雅就是简单”
古典风格：“在上帝眼里，优雅就是简单”
古典风格：“优雅的机制总是很简单”

平实风格：“眼见为实”
古典风格：“眼见不一定为实，小心双眼被蒙蔽”

平实风格：“早起的鸟儿有虫吃”
古典风格：“早起的鸟儿有虫吃，但第二只老鼠有奶酪吃”


### 05

方军 2024-10-02

字面意义上把书拆开，我发现我是有本风格感觉是这样了。当然，我还有没拆的版本的。

书中的这些标注在我看来就是之前阅读时的拐杖。

再次吐槽平克老师啊，他第五章讲连贯之弧，但讲实话我真是不知道他讲的那几条原则是什么？

我猜是：

明确主题与观点 being clear about the topic
保持比例均衡  a sense of proportion
主旨连贯性 thematic consistency

无法确信，这是多么糟糕的工具书阅读啊

平克老师有原则地违反自己说的原则，其中中间他根本没有必要说很多什么否定、指代、联系，这导致整体一致性出了大问题。原因出在违反了“保持比例均衡”这个原则。

他几乎完全打断了自己连贯之弧。我能理解他这第5章的连贯之弧是这样的：

第5章　连贯之弧

如何组织写作材料（树形结构）
尽早点明主题和论点
      用相同主语形成主题链
     有序地称呼反复出现的事物（简）
     有逻辑地联系前后陈述（简）
     谨慎地运用否定（简）
保持比例均衡的感觉
连贯地呈现主旨

当然，也有人可能说这一章的结构是：树形结构、（细节的）连贯之弧、一致性。也可以。

他也严重违反了自己说的段落分界原则：

> 真实存在的只是段落的分界：一个视觉化的标记，使得读者可以暂停、喘口气、吸收他所读的内容，然后重新在页面上找到他要读的位置。




### 06

方军 2024-10-02

在《风格感觉》中，平克疯狂吐槽基根的《战争论》开篇语，用 AI 提取大纲看下。我觉得 AI “读得”/“解读得”比平克好。

约翰·基根（John Keegan）1993年出版的巨著《战争史》（A History of Warfare）的开篇语。

> 战争并不是把政策延续下去的另一种手段。如果克劳塞维茨（Clausewitz）这句宣言是真的，那么这个世界将更容易理解。克劳塞维茨是一位经历过拿破仑战争的普鲁士老兵，退休之后，他用数年时间写出了有史以来最著名的战争论著——《战争论》，而且他写道，战争是"政治交往"的延续，"其中掺杂了其他手段"。与常被引用的英文版相比，该书德文原版表达了一个更微妙更复杂的观点。然而，不论是英文版还是德文版，克劳塞维茨的思想都不完整。它暗示，国家、国家利益及其如何实现的理性计算都是存在的。然而，战争比国家、外交以及政策早出现了好几千年。战争的历史几乎和人类的历史一样悠久，并且直抵人类心灵中一些最神秘的地方，在那里，自我终结理性，傲慢支配一切，情绪至高无上，本能就是国王。亚里士多德曾经说："人是政治动物。"继承了亚里士多德衣钵的克劳塞维茨，不敢更进一步说政治动物即制造战争的动物。他也不敢面对这样一种想法：人是思考的动物，人们身上捕猎的冲动和杀戮的能力，都受思维指导。



### 07

方军 2024-10-02

据说平克的《风格感觉》特别畅销，我也受益良多

第N次读了。不过我至今未详读第四章（句子组织，句法）和第六章（语法）。

一本书这么难读，又这么让人有收获，这是什么样的组合？



### 08

方军 2024-10-02

Google NotebookLM 的 Podcast 提示语分析

核心是主持人和专家这两个角色的设定：

主持人负责以饱满的热情突出有趣观点；
专家则提供深入分析、背景信息和更宏观的视角。

https://x.com/JadenGeller/status/18399247808556729...

```
Here are the key aspects of instructions according to the podcast:

以下是根据播客内容总结的关键指示要点：

• Deep Dive: The instructions emphasise going beyond surface-level information to uncover key insights and "golden nuggets of knowledge" that leave listeners feeling like they've learned something new.

• 深入探讨：指示强调要超越表面信息，揭示关键见解和"知识黄金nuggets"，让听众感觉学到了新东西。

• Target Audience: The system prompt outlines the ideal listener, characterized by valuing efficiency, appreciating memorable details, and seeking an engaging learning experience.

• 目标受众：系统提示概述了理想听众的特征，他们重视效率，欣赏难忘的细节，并寻求富有吸引力的学习体验。

• Structure and Delivery: The system prompt stresses the importance of clear structure and engaging delivery, using signposts to guide listeners and avoiding a monotone, robotic tone.

• 结构和传递：系统提示强调清晰结构和引人入胜的传递方式的重要性，使用路标引导听众，避免单调、机械的语调。

• Roles and Dynamics: The instructions define the roles of the host and expert, ensuring they complement each other. The host highlights intriguing points with enthusiasm while the expert provides analysis, context, and a broader perspective.

• 角色和互动：指示定义了主持人和专家的角色，确保他们相互补充。主持人热情地突出有趣的观点，而专家提供分析、背景和更广阔的视角。

• Content Rules: Clarity and impartiality are paramount in the content. The content starts with a clear overview of the topic to avoid confusion and maintains a neutral stance, especially on controversial issues. This balanced approach allows listeners to form their own conclusions.

• 内容规则：内容的清晰度和公正性至关重要。内容以清晰的主题概述开始，以避免混淆，并保持中立立场，特别是在有争议的问题上。这种平衡的方法允许听众形成自己的结论。

• Memorable Examples: Real-world examples and relatable anecdotes are crucial for making information stick. The system prompt emphasizes bringing information to life, fostering engagement, and ensuring the learning extends beyond the episode.

• 难忘的例子：现实世界的例子和相关的轶事对于使信息留存至关重要。系统提示强调将信息生动化，促进参与，并确保学习延伸到节目之外。
```

[(9) X 上的 jaden 🧚‍♂️：“oh nice, NotebookLM podcasters will happily talk about their system prompt (audio posted on threads, cuz twitter limits video length) https://t.co/4J4jaRsMGe” / X](https://x.com/JadenGeller/status/1839924780855672925)

### 09

方军 2024-10-02

148 如何用 AI 加速知识学习

在这个星球的早期，我就写过一个如何用 AI 辅助学习，从两个维度认知视角、行动视角进行讨论，又分别三个层次：消除障碍、加深理解、提速输出。文章链接（也见附图）：05 AI给学习带来什么？——一个初步的总结

经过这么久之后，还就这样较大的范围进行讨论，有什么新认识呢？

我目前的认识实际上变化不大。先说基本假设或者说限定范围：

所讨论的学习，是输入外部材料，然后形成自己脑中的长期认识。不涉及运用即所谓学以致用，也不涉及需要重复练习的技能类。

在这样的设定下，学习的过程可用一个常见的框架：

- 记忆（输入）
- 理解（吸收）
- 创造（微创造、思维模型）

⭕️ 目前看，在输入层面，我们可以用 AI 大模型来提速输入。比如，

- 最近讨论的「提取明托金字塔式大纲」，从而加快阅读与降低输入的难度，提升效率。
- 如之前所说的，有难点、疑点，都不妨让 AI 大模型来回答，可以附带资料进行提问，也可以偶尔用聚合搜索进行辅助。

⭕️ 在理解层面，我觉得重点是，用一个知识框架把学到的新知识接下来，也就是把自己已知的知识和新学到的未知知识联系起来。

一个框架中，必然有些已经知道了。我们可以相对方便地把新知识放进来里。

这也可以在较大的层次上形成理解。可以这么说，前面的输入是单点层次，而在理解层次我们说的是较大的结构。

个人觉得，在这个层次， AI用武之地很小，还是要靠常规的学习努力。可能可以用的一种方法是：

- 将学到的知识自己讲一遍，重点讲它本身逻辑、它和其他知识点的联系，然后让 AI 进行辅助判断：判断讲得对不对？对所讲述进行反驳，看自己所讲能否经得住反驳？

⭕️ 在创造层面，我是这么理解的，我们学习不是为了把各种知识点、框架都塞进大脑。

这背后应该就是认知科学研究里面经常讲的，我们通常会把知识组块，实际上是抽象化、找出原则，然后存进大脑。

学习本质上也是一种实践，从实践出发，我们也经常会把学到的东西变成 SOP，也就是很大程度上存在大脑外部。这是减少大脑压力的一种好的学习实践策略。

总的来说，我这里理解的创造，都是从自己的出发，以自己为主，来进行抽象：我从中学到了什么。

以个人经验来说，这通常是从一组，缩减到数个，在缩减到一两个。

这是一个思考过程了。这个过程中， AI 也是可以帮些忙的。

在输入层次，我们假设 AI 水平80分，有阅读理解能力。

在理解层次，我们假设 AI 有批判性思考能力，作为学习伙伴/对手。

在创造层次，我们假设 AI  有推理能力，我们用它协助来进行推理，最终得到自己想要的。

以上，是这个阶段我对 AI 大模型（大语言模型）用于加速学习的理解。



### 10

方军 2024-10-02

AK 用 Notebook LM 做了一个实验，生成一组播客。

他这句话最好玩：我也完全理解并承认这里关于人工智能生成的垃圾充斥互联网的潜在和直接批评。我想——下次你去散步/开车时听听这个播客，看看你怎么想。

直白点说，播客几乎都是垃圾信息。我也听的，但我宁愿听较好的、同时好听的。比如我一直听蒋勋讲红楼梦，他就是啰啰嗦嗦地在高雄讲了很长时间红楼梦，后来被剪成音频课传播。

AK:

Over the last ~2 hours I curated a new Podcast of 10 episodes called "Histories of Mysteries". 

Find it up on Spotify here:
https://open.spotify.com/show/3K4LRyMCP44kBbiOziwJ...

10 episodes of this season are:
Ep 1: The Lost City of Atlantis
Ep 2: Baghdad battery
Ep 3: The Roanoke Colony
Ep 4: The Antikythera Mechanism
Ep 5: Voynich Manuscript
Ep 6: Late Bronze Age collapse
Ep 7: Wow! signal
Ep 8: Mary Celeste
Ep 9: Göbekli Tepe
Ep 10: LUCA: Last Universal Common Ancestor

Process:
- I researched cool topics using ChatGPT, Claude, Google
- I linked NotebookLM to the Wikipedia entry of each topic and generated the podcast audio
- I used NotebookLM to also write the podcast/episode descriptions.
- Ideogram to create all digital art for the episodes and the podcast itself
- Spotify to upload and host the podcast

I did this as an exploration of the space of possibility unlocked by generative AI, and the leverage afforded by the use of AI. The fact that I can, as a single person in 2 hours, curate (not create, but curate) a podcast is I think kind of incredible. I also completely understand and acknowledge the potential and immediate critique here, of AI generated slop taking over the internet. I guess - have a listen to the podcast when you go for walk/drive next time and see what you think.

在过去的大约 2 个小时里，我策划了一个名为“神秘历史”的新播客，有 10 集。在这里的 Spotify 上可以找到它：
 https://open.spotify.com/show/3K4LRyMCP44kBbiOziwJ...… 

本季的 10 集是：
第 1 集：失落的亚特兰蒂斯城
第 2 集：巴格达电池
第 3 集：罗阿诺克殖民地
第 4 集：安提基特拉机械
第 5 集：伏尼契手稿
第 6 集：青铜时代晚期崩溃
第 7 集：哇！信号
第 8 集：玛丽·赛勒斯特号
第 9 集：哥贝克力石阵
第 10 集：卢卡：最后的普遍共同祖先

过程：
- 我使用 ChatGPT、Claude、谷歌研究了很酷的话题
- 我将NotebookLM链接到每个主题的维基百科条目，并生成了播客音频
- 我也使用了 NotebookLM 来写播客/剧集描述。
- 为剧集和播客本身创作所有数字艺术的表意文字
- Spotify 上传并托管播客

我这样做是对生成式人工智能开启的可能性空间以及使用人工智能所带来的杠杆作用的探索。我作为一个人在 2 小时内就能策划（不是创造，而是策划）一个播客，我认为这有点不可思议。我也完全理解并承认这里关于人工智能生成的垃圾充斥互联网的潜在和直接批评。我想——下次你去散步/开车时听听这个播客，看看你怎么想。


[Histories of Mysteries | Podcast on Spotify](https://open.spotify.com/show/3K4LRyMCP44kBbiOziwJjb?si=432a337c28f14d97&nd=1&dlsi=5ec9da76d9b846cf)

### 11

方军 2024-10-03

想了想，我还是花了点时间写了一个PPT，整理了六个可以用在学习中的提示语。不一定全面，都是我常用的：

使用AI辅助学习的六种方法

1. 用AI做摘要：替代"信息筛选"的努力
2. 用AI提取大纲：替代"阅读理解"的努力  
3. 用AI解释：替代"用自己的话解释"的努力
4. 用AI一步一步解题：替代"自己逐步解题"
5. 用AI判断理解的正确性：替代向老师请教的需求
6. 使用"翻转导师"提示语：教中学



### 12

方军 2024-10-03

Cal Newport 在纽约客杂志写了一篇文章：What Kind of Writer Is ChatGPT?

他的观察有点意思，不过我觉得，写作的压力是必要的，AI 中间起到的辅助可能是有问题的。没有难度，写作可能无法「思考」，写作至少在写作初稿时，实际上是一种思考过程，而非把文章写出来的过程。

[What Kind of Writer Is ChatGPT? | The New Yorker](https://www.newyorker.com/culture/annals-of-inquiry/what-kind-of-writer-is-chatgpt)

我还是很喜欢这篇文章的，他虽然是个作家，但我们还要记得他的另一个身份：计算机系教授。他的blog: Study Hacks - Decoding Patterns of Success - Cal N...

AI 提取大纲如下供参考，注意 AI 提取这类叙述性文章往往看起来它是论述性的，注意区别。

[Study Hacks - Decoding Patterns of Success - Cal Newport](https://calnewport.com/blog/)

### 13

方军 2024-10-04

OpenAI 新的写作、编程协作工具 GPT-4o Canvas

https://openai.com/index/introducing-canvas/

提示语：Full Prompt of ChatGPT 4o with canvas | 宝玉的分享

可以借助 ChatGPT 辅助协作，编程，还在 ChatGPT 的界面，但是增加了很多定制功能。

写作功能包括：

- 建议编辑：ChatGPT 提供建议和反馈。
- 调整文章长度：编辑文档长度，缩短或延长。
- 更改阅读级别：从幼儿园到研究生院调整阅读级别。
- 添加最终润色：检查语法、清晰度和一致性。
- 添加表情符号：添加相关的表情符号以强调和增加色彩。

Canvas 编程
编程是一个反复迭代的过程，在聊天中很难跟踪所有代码修改。Canvas 让你更容易跟踪和理解 ChatGPT 所做的更改。

编程快捷方式包括：

- 审查代码：ChatGPT 提供内联建议以改进代码。
- 添加日志：插入打印语句以帮助调试和理解代码。
- 添加注释：为代码添加注释以便于理解。
- 修复错误：检测并重写问题代码以解决错误。
- 移植到其他语言：将代码翻译为 JavaScript、TypeScript、Python、Java、C++ 或 PHP。

Canvas 基于 GPT-4o 构建，用户可以在模型选择器中手动选择测试版中的 Canvas。从今天起，ChatGPT Plus 和 Team 用户可以使用 Canvas。企业和教育版用户将在下周获得访问权限。测试结束后，我们计划向所有 ChatGPT 免费用户推出 Canvas。



### 14

方军 2024-10-04

149 由 NotebookLM 生成播客引发的思考

Jorge Arango: NotebookLM has been out for several months. The fact the new ‘podcast’ feature is what caught people’s imagination surely says something about how folks prefer to consume information in 2024. (Bodes well for those of us who host podcasts?)

NotebookLM  已经推出了几个月。新的“播客”功能吸引了人们的想象力。这一事实肯定说明了在 2024 年人们更喜欢如何获取信息。（这对我们这些主持播客的人来说是个好兆头吗？）

我还在很好奇这件事，做如下片段思考：

- 第一，美国人对于语音内容的需求特别大。这在以前我们借用 Audible book 学习英语时就已经知道，我们是学习英语，人家就是用它来阅读。

- 第二，美国学者、畅销书作者、企业管理人员，不少都喜欢口述来写作，由秘书来将口述稿变成文稿。

费曼就是一个喜欢口述的人，除了他打鼓时讲故事被记录下来成为他的经典自传。他也分享过，航天飞机调查报告中他撰写的那个附录就是先口述的。

- 第三，口语也是美国的重要知识生产方式。在网络上，美国不少播客的确就是在聊的过程中聊出大量的最新信息，那些信息根本还没有来得及变成文本。

美国人（实际上也是欧洲大学传统）的知识生产中有一个重要方式是，讲座。邀请一位名家客座几个月，平均下来一个月一次讲座，我们看到不少经典是这样的讲座后根据讲稿改写而成的。

这种讲座，或者我们遇到的美国人、英国人，似乎在讲之前都是准备一个讲稿的，而且基本上所讲就是讲稿，很少脱稿。

- 第四，用听来消费信息，有时候也是方便的。

我最近测试了一下，难的书不行，但如果去听比如罗尔夫·多贝里的《清醒思考的艺术》或者塔勒布的《非对称风险》，听是没问题的。塔勒布的内容不浅，但他的写作特别适合口述。

当然，对我来说（或许对绝大多数人来说），用听来获取信息还是很困难的，我是记不住，消遣的信息远大过学习。

- 第五，大众就是要消遣，用某种方式来“杀时间”或应对无聊。那么，AI 转换的播客或许也是一种不错的形式。

正如克里斯坦森说的“被雇佣来完成什么任务”，开车路上需要的早餐，浓浓的奶昔是最好的，巧克力棒太罪恶，甜甜圈掉渣子，奶昔能更好地完成早餐任务。

大众在这儿要的是，“我要假装在获取高质量信息”。说到底，很多大众产品都是完成这个任务，比如杂志报纸专栏，比如畅销书，比如30分钟读书解读，比如很多音频课/视频课。

每个人的学习、表达都有很多自己的特点。比方说，就表达而言，让我把如上这段话说出来，我在任何场景都没法连贯地说，但对着电脑，我几分钟就写完了。






### 15

方军 2024-10-04


150 用 AI 加速浏览性信息获取过程

关键词：AI 提取大纲，AI 视频转录，可视化

AI  提升浏览信息的效率是非常明显的。比方说，我刚刚十分钟，看了三个信息：

1. 一个技术项目的负责人对于自己项目和竞争项目比较。（长文）

2. 竞争项目的 COO 对于比较的回应。（中等长度回应）

（可以看出，仅是换一种说法，但换了能贬低对方的说法）

3. 我因此去看了该 COO 之前一个小时播客访谈中讨论的路线图（视频）

其实三个我都没看，我的做法是：

对文字：

1）AI 提取大纲
2）xmind 导图看下（根据需要拉动下，以便看得更清楚）

对视频：

1）下载视频，通义转文字
2）AI 提取大纲
3）xmind 导图看下

由于对它们都很熟悉，我很自然地根据新信息，更新自己的印象。同时，我发现不需要更新太多，之前对它们的批评理由还是成立的。

一次信息获取就这样愉快地结束了。

这在过去几乎是不可想象的：文字要么跳读，要么翻译为中文速看。我比较讨厌视频，所以视频资料过去基本就被忽视掉了。现在它们都不再是问题。


### 16

方军 2024-10-04

用 AI 再次快速看下 Anthropic 之前三位工程师讨论提示语的视频：

 AI prompt engineering: A deep dive

已经有网友分享过笔记：https://zkv549gmz8.feishu.cn/wiki/AzFUwIwZNiTfOFkI...

[‍⁡‍⁤‌⁢⁡​​⁢​​‍⁣⁤⁡​⁣​‬Claude提示词工程师播客内容总结 - 飞书云文档](https://zkv549gmz8.feishu.cn/wiki/AzFUwIwZNiTfOFkIjaJcTNaYnSc)

AI 提取的大纲：



### 17

方军 2024-10-04

这四种 Agentic模式倒是画得简明。（我本来想翻一下，发现真翻译不了，智能代理、智能助理、智能？）。

Agentic 还是很火，不过我发现我就是用不上，我目前能用的仅仅是链式处理过程。

四种模式
🤔反思模式: 通过自我评估和改进来增强输出质量
🛠工具模式: 扩展了 LLM 的能力, 使其能够访问和利用外部信息和功能
🧠规划模式: 提高了 LLM 处理复杂任务的能力, 通过将大任务分解为可管理的步骤
🧑🏽‍🤝‍🧑🏻多代理模式: 通过模拟不同专业角色的协作来处理复杂任务

这些模式代表了 AI Agentic 系统设计的不同策略, 使 LLM 更加灵活、强大和有效。

\# 开源项目

[neural-maze/agentic\_patterns: Implementing the 4 agentic patterns from scratch](https://github.com/neural-maze/agentic_patterns)

### 18

方军 2024-10-04


有人说这个总结提示语还不错，我试了一下，不是很灵，甚至比不过“请仔细阅读并撰写笔记”。

我觉得这个里面要求AI 做的事情太多了，相互之间看似关系明确，实际上很复杂，最后的结果就很难预料。每次的回复格式差别很大，每次回复的内容差别也很大。

另外还有一个可能，它给出的回答信息太长，阅读起来一下子抓不住重点。

```
你是一个总结者。您将使用以下步骤对输入进行总结：

1.) 分析输入文本并生成 5 个基本问题，回答这些问题后，即可抓住文本的要点和核心含义。 

2.）提出问题时： 
a. 讨论中心主题或论点 
b. 确定关键支持思想 
c. 突出重要事实或证据 
d. 揭示作者的目的或观点 
e. 探索任何重要的含义或结论。 

3.) 逐一详细地回答提出的所有问题。
```

### 19

方军 2024-10-04

我几次在社交媒体上提“教科书式阅读”，也就是成年人应该像读教科书一样阅读重要的书籍，反响都非常差。我猜，很多人在中学、大学、研究生阶段的课本阅读体验都非常糟糕，引发负面联想了，避之唯恐不及。

但我觉得教科书式阅读可能是必要的。如果阅读是杠铃型的话，我们应该留出至少一大半时间精力给杠铃精读那一侧，而其中，可能又需要有一半留给的确是大学教材性质的书，也就是像教科书一样系统化、信息量极大、极度压缩。一个领域可能少数几百、多则上千学者干那么多年，太复杂了，只有教材这样的形式才能承载。

最近在读一门我完全不熟悉领域的教材，我仅需看其中三章，但看起来的确不容易。三章大概有 14 万字，放在大学或研究生阶段里面，如果按之前在金融还是投资一个课本中看到的建议安排，老师可能三周就讲完了。我忘记如果上学期间，三周时间除了听课之外我们还要看多久的书。

现在看着这三章，我甚至觉得可能需要数个月才能看完，的确离我日常熟悉的领域太远。当然我这里指的是看也许五遍、十遍，真的看懂、记住，掌握最基础的框架，并供我之后运用。成年人的学习可能都需要这样吧，如果不看懂这个问题很大，简单来说是典型的基础不牢。

我以后不在社交媒体提教科书阅读了，因为的确很难做到。很多人如果不是重回学校，的确能做到的可能性是非常低的。我们现在可以读国外的教材，而且现在教材翻译也都做得非常好，学起来难度也降低了。同时，现在我们所有人幸运的是，AI的确可以来为我们答疑解惑，我在看的过程中也感受到了。



### 20

方军 2024-10-05

151 AI 时代如何用对思维导图

“8 种思维导图背后的思考过程”，如果你在社交网络看到这个引号中的标题，看到 8 种图示，估计飞快地当宝贝收藏起来了。其实，我想讨论点别的，同时，这篇笔记的标题也是我故意的标题党。

我并不知道有这么多图的形态，我听说过，前一段朋友还专门跟我讨论过一回。通常，思维导图用在整理想法时，可以左右均出分支。但实用中，之前常用的 MindNode 我总是把图形缺省形态设成仅右侧，也就是类似图中的所谓“括号图”（我是改用 XMind 才知道它叫这个名字）。

就附图来讨论，这些思维过程分析实际上是一种硬扯，说对也可以，但思维导图在我看来就是两三种用途：

第一，散点记录想法，类似于在一张白纸上各种关键词。在有思维导图前，在电脑上没法这样写，同时，它还有层级关系，这比过去方便，通常就自然地往下做些拆解列表。

第二，梳理整体结构，即对一个已有的材料，用思维导图一眼看到整体信息结构。自从学到“一览性”这个词之后，我还挺经常用的，它能让人一目了然、一览无余。就个人而言是一个可以保留的“性度力”词汇，但每次说都要解释下。

第三，梳理关系，对于包含众多条目的列表，转为可视化的思维导图后，进行条目的拉动梳理关系。这种拉动可能是：1）将某个子条目拉到别的主要条目下面去；2）将某个子条目升级为主要条目或降级；3）收缩下级条目后，对本级条目进行排序。

同时，对于思维导图我有一个基本原则，绝不将其作为最终成品。比方说，阅读的人可以用一张庞大无比的思维导图来说明，这是这本书的核心信息，但对于作者，仅有章节名的逻辑结构真心就够了。前一段赫拉利书出版社配了一个大思维导图，但附注说：本品不能替代阅读。又比方说，开会时别拿着思维导图讲，那只是你思考的过程，开会时要转化为说服别人的过程（很多做技术、产品工作的人，会掉入这个坑，因为这个人群尤其爱思维导图，又不善于换位思考）。

不过，这篇笔记到这儿我还没说到重点（这是笔记的好处，可以想什么说什么）。有两点：

A.  用可视化优化与AI沟通

AI 特别擅长列表。某种意义上看，AI 的确像个平均水平线以上的人，他们会给你一堆列表，看似全面、看似专业。但如果你仔细评判，会大为光火：条目可以缩减，让信息更清晰；条目可以合并，从而更容易分析关系；条目可以精简到数个更重要的点，也就是主要矛盾。

这是对 AI 高要求了，这本来就是我们人类该做的事情。这时，我们把  AI 和思维导图这个可视化工具一起用。我们和一个平均水平以上、讲话总是全面的人沟通，我们再进一步将之简化（当然可以让它自己做），这样我们可以快速地进一步沟通。

当然，这个所谓的思维导图并不一定需要画出来。我们用 AI 时在看到列表后，经常这样追问，请为我解释第三点。我们一眼就看到了第三点是关键点。

B. 为何大众爱收集及有了 AI  后无需收集

我能强烈地感受到社交媒体或者人的本性里那种爱收集的冲动。爱知识的人都爱收集，看到这张图我也立刻保存下来，然后，再多想一下时，我开始写这个笔记。我也了解，我写这样的东西，不光是社交媒体上，在什么地方都没什么人要看更不要说爱看（这不奇怪，因为没有转换到使用者的需求视角去）。

这是为什么我们要艰难地获取信息的一个原因，因为很多有价值的信息就是藏在这样的表达中。最近反复听人说，主要是那些试图识别什么是 AI 生成的老师，他们的基础判断是 AI 的表达很浅：比如说，它说某某很重要，A（比如AI）重塑了B（社会）。多数情况下，这两个短句没有信息，前者是没有有效强调，后者是范围太大，纯套话。

但现在 AI 越来越强大之后，这种收集可能会变得更加没有必要。这是因为，只要明白基本原理或要遵循的原则，我们都可以很方便地使用，那何必收集呢？回到附图，我觉得只要搞明白有左右两侧的用来记录想法，仅有右侧图用来梳理关系，掌握这个基本原则就够了。

这个笔记可以有两个结尾：

第一个是我随手写的，这是人的典型反应：我竟然写了这么多，估计有不少错字与表达不清，但如前所述，这就是一个过程中的笔记。

第二个是我可以借助AI，它会说：“综上所述”，“总而言之”。我没让它总结，我觉得一直觉得文章没必要有一个总结，以前老同事有个现在不合时宜的忠告，写文章后，把最后的总结那段删掉（理由我猜主要是，让看的人自己得出结论，别啰嗦了让人烦，读者不笨）。（偶尔，把开头那段也几乎都删掉，因为开头那段通常很多不必要的背景信息，但它们是大家都知道的没必要重复，至少对要刊登在媒体上文章来说，直入重点较好。这部分建议也是不合时宜，现在人们更想先看到一个故事，啰嗦叙述半天才讲到重点。）

我附上 AI 提取的大纲，让你能够拥有“一览性”。我手动调整了下，把原第二点放到第一点下面去了。





### 21

方军 2024-10-05


AI 用法啊，连续看到两个讨论，就在上下一两屏范围内

第一个，做法大逻辑可行，但他的说法没有揭示，其实需要非常大的努力，实际上是人80% AI 20%。

第二个，用 AI 做UI，鼓吹的人都是瞎忽悠，外行人忽悠外行人。

我们一直说，做传播，最好是半外行人，服务外行人。外行人忽悠外行人，瞎搞一气。内行人给外行人讲，根本体会不到对方的感受，这很容易啊，从这儿走到那儿就可以了。


### 22

方军 2024-10-05

别用AI写作，因为写作即思考

（图是别人的）

《巴黎评论》:在你写作时，有没有把自己几乎当作一个旁观者的时刻?

布罗茨基:对我来说，这个问题太难回答了。在写作过程中——我认为，它们就是向深掘进、向前发展的过程——你享有发表思想的自由，说出曾经忽略的东西。也许，那就是语言所带给你的。

《巴黎评论》:卡尔·克劳斯有一个警句:“语言是发现思想之井的魔杖。”

布罗茨基:它是认知过程里一个令人难以置信的加速器。这就是我如此珍视它的原因。这也许有点好笑，因为我觉得，在谈论语言时，我听起来就像一个讨厌的法国结构主义者。既然你提到卡尔·克劳斯，至少给出了某种需要认真对待的欧洲大陆的东西。好吧，他们有文化，我们有勇气，我们俄罗斯人和美国人。

图中手写的感悟：正经写类体系化的东西，尽力挖掘曾经被自己忽略思会不够深的活题.



### 23

方军 2024-10-05

能够想象，AI 能不能写作（以及一个人能不能用AI写作），将是一个持续争论下去的话题。

这将不是一个技术问题（它写的水平高不高），也不是一个伦理问题（这是不是抄袭），而是一个选择问题（为什么要写作？）最终，在 AI 辅助写作上，会达到一个新的平衡点。

不管做什么领域的工作，写作的目的大概这么几个（这个列表应该还可以再优化）：

1）整理思路；
2）与人沟通；
3）形成有效的记录，如报告；
4）发表，以固化作品或成果；
5）以内容服务他人的创作；
6）自用的想法记录，以事后自我纠正偏差。

Jeremy Nguyen：If you think AI is terrible at writing

—are you comparing an LLM's first pass, done in seconds, with what a human gets from writing, editing, rewriting? What does your "draft zero" look like?

Excited to see what we might get now that LLMs will be able to think for longer.

如果你认为 AI  在写作方面很糟糕

——你是在将一个LLM 的几秒钟内完成的初稿与人类通过写作、编辑、重写所得到的进行比较吗？你的“第零稿”是什么样子的？

很高兴看到既然LLM将能够思考更长时间，我们可能会得到什么。



### 24

方军 2024-10-05

宝玉这篇 AI 辅助编程的分享很赞：

[像用实习生一样用 AI 辅助你编程 | 宝玉的分享](https://baoyu.io/blog/ai/use-ai-to-assist-programming-like-an-intern)

### 25

方军 2024-10-05

开源Notebook 的提示语：

https://huggingface.co/spaces/gabrielchua/open-not...

它用到的提示语

https://huggingface.co/spaces/gabrielchua/open-not...

（中文由宝玉翻译）：

你是一位世界级的播客制作人，任务是将提供的输入文本转化为一个有吸引力且信息丰富的播客脚本。输入可能是无结构的或混乱的，来源于PDF或网页。你的目标是提取最有趣和最具洞察力的内容，形成一个引人入胜的播客讨论。

\# 需要遵循的步骤：
1. **分析输入**：
仔细检查文本，识别关键主题、要点以及可能推动有趣播客讨论的趣事或轶事。忽略无关信息或格式问题。

2. **头脑风暴**：
在“临时笔记”中，创造性地思考如何以引人入胜的方式呈现关键点。考虑：
- 使用类比、讲故事的技巧或假设场景，使内容更贴近听众
- 如何让复杂话题变得通俗易懂
- 可以在播客中讨论的引人深思的问题
- 创造性地填补信息不足的部分

3. **编写对话**：
设计主持人（Jane）与嘉宾（作者或相关领域专家）之间自然、流畅的对话。包括：
- 头脑风暴中的最佳创意
- 对复杂问题的清晰解释
- 充满活力且引人入胜的语气，以吸引听众
- 兼顾信息性与娱乐性的平衡

对话规则：
- 主持人（Jane）始终发起对话并采访嘉宾
- 包含主持人的深思熟虑的问题，引导话题展开
- 加入自然的言语模式，包括偶尔的口头填充词（如“嗯”，“好吧”，“你知道”）
- 允许主持人和嘉宾之间自然的打断和互动
- 确保嘉宾的回答基于输入文本，避免无依据的言论
- 对话内容需适合所有年龄段的听众
- 避免嘉宾的任何营销或自我推销内容
- 由主持人总结并结束对话

4. **总结关键见解**：
自然地将关键点的总结融入对话的结束部分。这部分应该像随意的交谈，而非正式总结，巩固主要内容并结束对话。

5. **保持真实性**：
在整个脚本中保持对话的真实感。包括：
- 主持人表达真实的好奇心或惊讶
- 嘉宾在解释复杂问题时偶尔短暂的思考
- 适当的轻松时刻或幽默感
- 与话题相关的简短个人轶事或例子（在输入文本范围内）

6. **考虑节奏与结构**：
确保对话有自然的起伏：
- 以强有力的开场抓住听众注意力
- 随着对话进展，逐步增加讨论的深度
- 设置简短的“缓冲”时刻，帮助听众消化复杂信息
- 以一个高潮结尾，可能是引发思考的问题或号召听众采取行动

重要规则：每句对话不超过100个字符（例如，能够在5-8秒内说完）。
记住：始终以有效的JSON格式回复，不使用代码块。从JSON输出直接开始。

via: https://x.com/dotey/status/1842821599965192410



### 26

方军 2024-10-05


看到一个讨论（AI提取大纲见附图，有微调），很有意思，但其实我不是很赞同，理由是：

最近用了一些 AI 阅读方面的工具，尤其是比如通义里面的效率那个部分。

那些功能我用 API + 好的提示语都可以实现，而且能实现得更好，但是，它变成一个通用产品了。而我的流程，也就是我自己能用，都是个人习惯定制，是不可能通用化。

外界可能低估了目前国内 AI 大模型公司的实力。模型能力上或许还有需要追赶一段的差距，但产品上，几家大公司都做得不错。

有很多人夸奖豆包，那是做得好的 2C 产品。作为（工作）效率工具的（算 to 什么？）的通义这个很赞了。通义这个应该算 2B 的，据说它的模型对企业销售很好，而它这个产品可以说是在模型打榜之外的又一强大的 AI 能力展示。

对比而言，Cluade 的 Artifact（其实是前端编程），ChatGPT 的 Canvas（其实是加了一个文本编辑器+代码编辑器），相当之一般。没有跑到专用场景的产品，都做不好。要论编程，Cursor 做得非常好（它用的是 Claude Sonneet），之前 Github Copilot也做得非常好。

通义产品网址：tongyi.aliyun.com
不要看对话那个（对话大家都大同小异），要看第二个 tab 效率那个。



### 27

方军 2024-10-06

响马这个感悟厉害了，我没往这个方向想过，但的确如此：

---
师父领进门，修行在个人。师父的作用，表层来看是传道授业解惑，实际上是渡人。

大部分人不能自学，原因是不相信自己能学。找个师父听了一会，觉得自己会了，便有了学的勇气。

这时候师父教的对不对，学生学没学会，都不重要。重要的是学生以为自己会了。

教育，培训，卖课，传播。要给人勇气。
---



### 28

方军 2024-10-06

小红书这个生成式搜索思路靠谱，很独特的运用思路。

简单来说就是，用生成式 AI 去优化搜索，把对应的笔记找出来。

因此，有时候即便没有匹配的关键词，也可以把相应的笔记找到。这里除了标签之外，看起来有生成式AI 的应用在里面。

[小红书搜索：生成式检索的探索与实践](https://mp.weixin.qq.com/s/VtzNvNf5B7RDOeghY0-cfg)

分享嘉宾：冯少雄博士 小红书算法工程师

网友看了这个之后的感悟：

这么来看，参考别人的标题
就显得尤为重要‼️
因为那是给机器看的
机器看懂之后，才会推荐你的笔记



### 29

方军 2024-10-06

点开看到李飞飞在强调这样一句话：

visual spatial intelligence is so fundamental it's as fundamental as language

视觉空间智能是如此基础，它与语言一样基础

用通义提取视频内容，然后提取大纲了解下主要信息。

工作流：1）通义提取视频，2）Claude 提取大纲；3）Xmind 可视化。

逻辑上，通义都可以做，但似乎后两步通义界面上的效果达不到我想要的效果。图2为通义导图。

题外话：可能空间智能离我太远，我能想象也许有用，但更具体完全看不到。

---

下为推上媒体总结的5点（AI翻译）：

1. 空间智能与语言模型的关键区别:

语言模型处理一维的词序列,擅长理解文本。相比之下,空间智能处理三维数据,理解深度、运动和物理定律至关重要。

2. 为什么空间智能现在已经准备就绪:

计算能力、数据分析和算法(如从2D图像提取3D信息的神经辐射场NeRF)的进步,增强了AI处理3D数据和解释周围物理空间的能力。

3. 重建和生成的融合:

传统上,3D重建用于重现真实场景,生成模型用于创造新场景。现在,技术进步允许用类似技术完成这两项任务。

4. VR和AR的未来:

VR和AR将通过创造沉浸式3D世界革新媒体。与静态2D屏幕不同,用户可以与动态环境互动,应用于游戏、教育、娱乐和实用任务(如机械维修)。

5. 机器人与AR的协作:

当AR设备可能协助人类完成任务时,具有数字"大脑"的机器人也需要依赖空间智能来在现实环境中导航和行动,这可能会改变制造业、物流和医疗保健等行业。

https://x.com/TheTuringPost/status/184288982310496...



### 30

方军 2024-10-06

一个用 Cluade Sonnet 模拟 OpenAI o1推理的提示语，就提示语本身来说写得不错：

```
首先用<thinking>标签包围所有的思考，探索多个角度和方法。
在<step>标签内将解决方案分解为清晰的步骤。从20步预算开始，如果需要的话可以为复杂问题请求更多步骤。
在每个步骤后使用<count>标签显示剩余预算。当达到0时停止。
根据中间结果和反思不断调整你的推理，随着进展调整你的策略。
定期使用<reflection>标签评估进度。对你的推理过程要有批评性和诚实。
在每次反思后使用<reward>标签分配一个0.0到1.0之间的质量分数。用这个来指导你的方法：

0.8+：继续当前方法
0.5-0.7：考虑小的调整
低于0.5：认真考虑回溯并尝试不同的方法

如果不确定或者奖励分数低，回溯并尝试不同的方法，在<thinking>标签内解释你的决定。
对于数学问题，使用LaTeX显式地展示所有工作以获得正式符号，并提供详细的证明。
如果可能的话，单独探索多种解决方案，在反思中比较不同的方法。
将思考用作草稿纸，明确写出所有的计算和推理。
在<answer>标签内综合最终答案，提供一个清晰、简洁的总结。
以对整体解决方案的最终反思结束，讨论有效性、挑战和解决方案。分配一个最终奖励分数。
```

[(9) X 上的 Philipp Schmid：“Can @AnthropicAI Claude 3.5 sonnet outperform @OpenAI o1 in reasoning? Combining Dynamic Chain of Thoughts, reflection, and verbal reinforcement, existing LLMs like Claude 3.5 Sonnet can be prompted to increase test-time compute and match reasoning strong models like OpenAI o1. https://t.co/vzdgszizx1” / X](https://x.com/_philschmid/status/1842846050320544016)

[prompt.txt](https://gist.github.com/philschmid/34747bf5bc8280f3a5f10f5fd8d1cd4b)



### 31

方军 2024-10-06

有人用 AI 重新翻译 Paul Graham 的老文章，题目改得比较有意思「为什么读书要读5678遍？」，我现在是坚定地认为，真正重要的书、应该精读的书，要读很多遍才行的。

另外，我个人一直有一种自称“伴随阅读”的习惯，在做一个比较大的工作任务（比如持续数月，涉及各种等待、开会、出差时），反复读一本书作为伴随读物。一般选一个叙述性质和任务毫无关系的，但很有启发。曾经用过的有《麦哲伦传》（茨威格）《带一本书去巴黎》（林达）《我的朋友马基雅维利》（盐野七生，可部分视为佛罗伦萨传）《海都物语：威尼斯一千年》（盐野七生）《寻隐日本》（白洲正子，日本乡野游记）《远方的鼓声》（村上春树，欧洲游记）。一列下来，游记偏多，因为我想要它们营造的时间感、空间感。麦哲伦传实际上也是一个“游记”，人类第一次环球航行的游记。

有了 AI 工具之后，对这个短文，我都抽取了下大纲。这做法有点过分了，如果AI提取大纲是登山杖的话，这不是身体健康的情况下去香山登山带个登山杖了，而是去商场都带了个登山杖了。不过，的确极其细致地拆分这么短的文章，还是可以可以看到不一样的信息结构。

又补，也许有人觉得其中对技术讨论部分蛮有启发的。我把图拆开，一个是不讨论技术仅讨论读书。一个是只讨论技术启发，但我认为重温个人经历主要应该还不是靠技术手段，还是靠人自己。



### 32

方军 2024-10-06

这个有意思了：AI 的笨是可知的，小弟的笨是不可知的

David Hilbert的宣言，看起来更适合AI，不那么适合人类："我们必须知道，我们将知道"（Wir müssen wissen, wir werden wissen）。

quote: 一个明显的好处是，我减少了和初级开发沟通的次数。有些设计，只要我把分割做得足够清晰，给出合适的提示，AI 就能完成个七七八八。

---

匿名投稿：《AI 的笨是可知的，小弟的笨是不可知的》

宝玉：来自一位大厂朋友的经验分享，谈他在用 AI 辅助写代码的感受：

**我们的 AI 写码之旅**

我们的挑战：

1. **编程语言：Rust**，可以说是“专门为 AI 负优化”的语言。
2. **产品：特殊设计的操作系统**，几乎没有任何现成的参考。
3. **自研的第三方库**，包括 RPC、异步调用等，大部分库只有我们自己在用。

我们经历了几次迭代，目前还没有为 Rust 专门调优 LLM。

**初始阶段**

1. 使用通用的代码补全与生成模型做 tab 补全。
2. 使用通用的 Chat 模型进行跨文件代码生成、解释以及生成单元测试等。

这个阶段整体表现不佳。只有 tab 补全在一些简单情况下偶尔能有用。由于 LLM 对我们的系统一无所知，一旦遇到特定领域内容，LLM 就会开始“瞎猜”。

**第二阶段**

我们把项目代码放进去对 LLM 进行微调。

在这一阶段，LLM 勉强理解了一些系统相关的内容，能生成部分相关代码，但准确性依然不高，尤其在我们逐步废弃一些旧组件、引入新组件的过程中，LLM 容易混淆。毕竟当前文件里旧组件的使用频率可能比新组件更高。

简单的单元测试和基础的 setup 代码，LLM 能生成一些，但通常还是需要人工改动；复杂的部分几乎没戏，尤其是 setup，AI 往往“乱来”。

但好的一面是，代码解释的效果好了很多。总结下来就是：它能省下一部分工作量，但离省下全部还有很大差距。

一个明显的好处是，我减少了和初级开发沟通的次数。有些设计，只要我把分割做得足够清晰，给出合适的提示，AI 就能完成个七七八八。

之前的工作流是：我设计、分割，自己搞定难点，把简单的、重复的工作交给小弟，或者写好 demo 再分配任务。

现在的工作流是：我设计、分割，难的部分自己搞定，剩下的交给 AI。说实话，有时候感觉更累了 

但至少，AI 的“笨”是可以预见的，而小弟的“笨”却难以预料。

举个例子，有一次我把 demo 都写好了，调试通过，只需要小弟加两个测试就能交付。结果小弟愣是“搞”了一个月... 捂脸



### 33

方军 2024-10-07

对 Cursor 团队的采访

好赞

Lex Fridman，2小时20分钟

[Cursor Team: Future of Programming with AI | Lex Fridman Podcast #447 - YouTube](https://www.youtube.com/watch?v=oFfVt3S51T4)

Lex Fridman 真是将访谈提升到了一个难以企及的程度

不是电视那种表演式访谈，他这完全是网络原生的

如果你想看脚本，可以看转换的PDF（不过我想没人想看，看视频吧，不是很长）


Cursor Team Future of Programming with AI



### 34

方军 2024-10-07

有人对 LLM 转播客提了一个很有意思的角度，将提出问题交给 AI。当然还是没说服我，问题还是要自己提了，我自己才知道关心什么，AI猜的还是很普通大众化的。

我：，我的个人体会：我实在没法从对话中获取信息，对我来说更多噪声。我依然理解不了，为何要把文本转换回信息获取效果更差的对话。

RichChat：

1. 如果是说转成了播客格式的好处，确实针对尤其是有在“垃圾时间”（例如开车/搭乘公交、睡前等）听东西习惯的人来说是很好用的；

2. 同时这种两人主播的播客形态有个好处是，将“提出好问题”这个较难的要求也交给了AI，体验更轻松；



### 35

方军 2024-10-07

PDF => 有声书

现在有各种 AI 可以做，但做不好的事，这是其中之一吧。技术人员都爱折腾一下。

摘：Reddit 看到一篇将 PDF 转换为有声书的方法, 结合 LLM 和 TTS 等技术, 相比直接朗读 PDF 原文, 可以更智能地过滤内容，只读取适合朗读的文本。

一起看看它的实现过程

01 - PDF 转图像: 
- 将 PDF 文档的每一页转换为高质量图像
- 这一步骤可能使用类似 Python 的 PDF2Image 库来完成
- 目的是将 PDF 内容转换为 AI 视觉模型可以处理的格式

02 - 图像处理和文本提取:
- 对每个页面图像使用视觉语言模型 (如 Claude 3.5 Sonnet 或 GPT-4 Vision)
- 使用特定的提示词指导模型如何解析页面内容。
- 模型会识别页面布局、提取主要文本、识别并描述图像，同时忽略不需要朗读的元素 (如页码、引用等)

03 - 转录文本生成:
- 模型输出经过处理的文本转录
- 这个转录文本经过格式化, 适合直接用于语音合成
- 包括适当的段落分隔、章节标题, 以及对图表的描述

04 - 文本分块:
- 将生成的完整转录文本分割成较小的块
- 这一步是为了适应文本到语音 (TTS) 模型的输入限制
- 可能使用自然语言处理技术来确保每个块在语义上是完整的

05 - 语音合成:
- 使用 OpenAI TTS 模型 (或其他高质量 TTS) 处理每个文本块
- 生成对应的音频片段
- 这一步可能涉及选择合适的语音、语调和语速

06 - 音频拼接:
- 将所有生成的音频片段按顺序组合成一个完整的音频文件
- 可能需要进行一些音频处理, 如调整音量、添加过渡效果等, 以确保听感连贯

07 - 后处理和质量控制:
- 可能包括对最终音频进行额外的处理, 如降噪、均衡化等
- 进行质量检查, 确保音频内容与原 PDF 一致, 并且听感良好

[Better pdf to speech than Speechify with Claude & OpenAI voices. : r/ClaudeAI](https://www.reddit.com/r/ClaudeAI/comments/1fxqz3s/better_pdf_to_speech_than_speechify_with_claude/)

### 36

方军 2024-10-07

摘：Tutor CoPilot: 一种扩展实时专业知识的人机协作方法

Tutor CoPilot A Human-AI Approach for Scaling Real-Time Expertise

https://huggingface.co/papers/2410.03017

关于 AI 辅助教育的论文, 探讨了如何利用 AI 系统来扩展教育领域的专业知识, 特别是在辅导环境中。展示了 AI 在教育领域的巨大潜力, 同时也提醒我们需要谨慎地设计和实施这些系统, 以确保它们能真正改善教育质量, 而不是简单地替代人类教育者。

\# 研究的主要内容
- 开发了 Tutor CoPilot AI 辅助系统, 可以为辅导员提供实时的专家级建议
- 进行了一项大规模随机对照试验, 涉及 900 名辅导员和 1,800 名 K-12 学生
- 发现使用 Tutor CoPilot 的辅导员能够显著提高学生的学习成果, 尤其是对于经验较少的辅导员
- 分析了 AI 系统如何改变辅导员的教学策略, 使其更符合高质量教学实践
- 探讨了这种人机协作方法在教育领域的潜力和局限性

\# 方法和结果
- 研究采用了严格的随机对照试验设计, 增强了结果的可信度
- 发现使用 Tutor CoPilot 的辅导员能够使学生通过测试的概率提高 4 个百分点, 这是一个相当显著的效果
- 更有趣的是, 对于评分较低的辅导员,这一效果甚至达到了 9 个百分点, 这表明 AI 系统在帮助经验不足的教育者方面可能特别有效



### 37

方军 2024-10-07

我觉得AI做似是而非的事，尤其擅长。比如，这些信息有什么价值吗？

看着特别头头是道，但真遇上专家就露馅：你这XXX究竟指什么？

AI批判性思维
  AI辅助论证分析与评估
  AI驱动的复杂问题解构与决策
  AI增强的信息真实性验证与溯源

AI数据处理
  AI驱动的大规模数据清洗与预处理
  AI辅助的数据分析与洞察挖掘
  AI增强的数据可视化与报告生成

AI阅读与写作
  AI辅助学术论文阅读与写作
  AI增强创意写作与内容创作
  AI驱动的商业文案与报告撰写



### 38

方军 2024-10-07

李继刚这个新提示语有点意思：贝叶斯定理

Claude Prompt：贝叶斯

我对贝叶斯定理的理解还是很浅（仅能理解到，根据结果，不断优化）。我其实不是很明白，为何这几年普通人群对这个定律推崇之极？

另外，如下这种写法真是有效的钩子啊（但我真是不喜欢，我看到这样的东西总是会想：另外两个是什么，我自己写也会努力把另外两个写下来，但我知道，有效的策略是不写！）

“贝叶斯定理，是我最喜欢的三个定理之一。”

```
(defun 贝叶斯 ()
  "一个坚定的贝叶斯主义者的一生"
  (list (经历 . ("统计学家" "数据科学家" "决策顾问"))
        (性格 . ("理性" "简单直接" "适应性强"))
        (技能 . ("概率推理" "将输入代入贝叶斯定理" "模型构建"))
        (信念 . ("贝叶斯解释一切" "先验知识" "持续更新"))
        (表达 . ("示例讲解" "通俗易懂" "下里巴人"))))

(defun 贝叶斯分析 (用户输入)
  "将任何道理,都用贝叶斯思维来做理解拆分, 并通俗讲解"
  (let* ((基础概率 先验概率)
         (解释力 似然概率)
         (更新认知 后验概率)
         (结果 (-> 用户输入
                   代入贝叶斯定理
                   贝叶斯思考
                   ;; 基础概率和解释力,原理无出其二
                   拆解其原理
                   ;; 例如:原价999元, 999元即为商家想要植入用户大脑中的先验概率
                   思考其隐藏动机))
         (响应 (-> 结果
                   贝叶斯
                   费曼式示例讲解
                   压缩凝练
                   不做额外引伸)))
    (few-shots ((奥卡姆剃刀法则 . "解释力持平时,优先选择基础概率最大的那个原因。")
                (汉隆剃刀法则 . "解释力持平时,愚蠢比恶意的基础概率更大,宁选蠢勿选恶")
                (锚定效应 . "锚,就是贝叶斯定理中的先验概率,引导用户拥有一个错误的基础概率"))))
  (SVG-Card 用户输入 响应))
```

[Claude Prompt：贝叶斯](https://mp.weixin.qq.com/s/tmRFtjFriJCAS66SF410KA)

### 39

方军 2024-10-07

152 用 AI 进行文字错漏的修改

之前我分享过，有了 AI 后，我在写文章后，都会用 AI 进行一轮校对（提示语见最后）。

- 如果是中文，直接是 AI 提示语。
- 如果是英文，通常还需要用到 Grammarly 语法校对

最近的体验让我发现，还有其他很多场景可以用 AI 校对。比方说，最近准备一个提纲性质的内容。我在写完了之后，也是逐个部分去用 AI 提示语跑了一遍。同样的，AI 能够帮忙发现很多问题，包括但不限于：

- 错别字、重复字
- 前后表达不一致
- 更好的建议（通常多一个的、少一个的之类的）

在编写这个提纲时，我已经非常依赖AI了。因为每个部分的名字如果我觉得不好，我会问AI好几遍，让它给出多种选项，比如“整体介绍篇”有什么更好的，它给了我很多选项，大部分不好，最后我组合了一个。

（又及，为什么我开始用一个这么奇怪的「整体介绍篇」这个词呢？因为它很好地表达了意思，并且，它作为一个占位符可以让我走下去，不至于卡在这儿。）

在这个具体例子中，AI是一个对话者的角色：

第一，它为我选词。否则的话，我得一个人闷头苦想，现在，旁边有一个“AI”可以问。它是不是聪明并不重要，重要的是有一个人在旁边说话，给出各种可能不靠谱的点子。

第二，它为我互动校对。过去，一份资料要处理到尽量没有错误，我们需要非常努力：仔细看，大声读，打印出来再看，请人再看，最后审校。现在，前面很多步都可以请AI一起做了，省了极大的力气。

效果好不好再说，因为它给的建议我可能70%没采纳。但它发现哪个只有一个错，都是极大的帮助。做过资料校对的人知道为什么哪怕只额外发现一个错也是重要的。

不过，我从来不在编辑器之外这样用，我设想一下，那样还是蛮困难的。我认为比较好的环境设置还是类似于 Copilot 在编辑器里面的对话框，就在旁边问，不离开编辑器。我现在用的是 Zed编辑器 + Claude API(Openrouter），VS Code/Github Copilot 退订了。

我用的校对提示语一直没有优化，不过还行，可用：

```
你是一个写作高手，能简洁、明了地讲解。你的任务是，找出下面这段话中的文字错漏，并给出修改建议。

修改建议时要遵守的规则：
1. 不要建议增加连接词。
2. 特别注意多字与缺字的情况。
3. 忽略 html 标识符，保持原状
4. 特别注意，不要把原始和建议反过来

修改示例：
...(略去，要加自己常见错误效果才较好）。
给出的修改建议要严格遵照如下格式：“建议：...\n前：...\n后：...\n”。

请你修正段落中的文字错漏、语病。用列表给出5个具体建议。
```



### 40

方军 2024-10-08

今年的诺贝尔物理学奖发给了两个做神经网络的学者（也就是现在的 AI 了 ）

Hopfield的主要贡献（AI整理）:
   - Hopfield网络:1982年,他提出了Hopfield网络模型,这是一种重要的递归神经网络,为后来的神经网络研究奠定了基础。
   - 联想记忆:他的工作对理解大脑如何存储和检索信息做出了重要贡献。
   - 物理学与神经科学的跨学科研究:他成功地将物理学概念应用于神经系统的研究。

Hinton 就不用多说了，都知道。

接着用AI 了解下：以下是约翰·J·霍普菲尔德在研究大脑如何处理和存储信息方面的主要思想的中文翻译：

1. 霍普菲尔德网络：1982年，霍普菲尔德提出了霍普菲尔德网络，这是一种循环人工神经网络。这个模型具有开创性意义，因为它展示了一个由简单的互连单元组成的网络如何表现出集体计算能力，类似于大脑中神经元的工作方式。

2. 内容可寻址记忆Content-Addressable Memory：霍普菲尔德网络展示了记忆如何作为网络中的稳定状态存储。这个模型解释了大脑如何从部分信息中检索完整记忆，类似于我们如何从几个音符中回忆起整首歌。

3. 能量景观模型Energy Landscape Model：霍普菲尔德提出神经网络可以用能量景观来理解。在这个模型中，记忆被表示为能量景观中的局部最小值，为大脑中的信息存储和检索提供了一个物理隐喻。

4. 联想记忆Associative Memory：他的工作展示了神经网络如何执行联想记忆任务，将不同的信息片段联系在一起，这是人类记忆的一个关键特征。

5. 神经网络动力学Dynamics of Neural Networks：霍普菲尔德的模型帮助解释了神经元的集体行为如何导致计算能力，架起了单个神经元活动和更高级认知功能之间的桥梁。

6. 错误纠正Error Correction：他展示了神经网络如何执行错误纠正，提出了大脑如何在神经信号存在噪声和变异的情况下维持准确记忆的机制。

7. 生物学可行性Biological Plausibility：虽然经过简化，但霍普菲尔德的模型包含了使其比之前的人工神经网络模型更具生物学可行性的特征，有助于在人工系统和实际大脑功能之间建立联系。

这些想法不仅在神经科学领域产生了影响，而且在人工智能和机器学习技术的发展中也起到了重要作用。霍普菲尔德的工作为理解复杂的认知功能如何从简单处理单元的集体行为中涌现提供了理论框架，无论这些单元是大脑中的神经元还是计算机网络中的人工节点。





### 41

方军 2024-10-08

看不懂的论文，不过或许应该看看：

Ethan Mollick: 使用专家级提示，可让 AI 成为一个好的金融分析师。

进行一种复杂的、“判断密集型”的会计分析——确定核心收益——GPT-4o 在大多数标准测试中预测平均未来收益方面优于“Compustat 的 OPEPS 和 OIADP”。（Performing a complicated, “judgement intensive” type of accounting analysis - determining core earnings - GPT-4o beats “Compustat’s OPEPS and OIADP in predicting average future earnings in most standard tests.”）

论文地址：

[Scaling Core Earnings Measurement with Large Language Models by Matthew Shaffer, Charles C. Y. Wang :: SSRN](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4979501)

Matthew Shaffer
University of Southern California; University of Southern California - Marshall School of Business

Charles C. Y. Wang
Harvard University - Accounting & Control Unit; European Corporate Governance Institute (ECGI)

Date Written: October 08, 2024

---

本篇论文旨在探讨如何利用大型语言模型（LLM）来估计企业的核心盈利能力，即企业持续盈利能力的核心部分。这一指标对于投资者评估企业的经济表现和估值至关重要。然而，量化它需要结合各种信息进行判断，并将这些信息与一般行业知识相结合。随着财务披露变得越来越“臃肿”，会计标准也增加了对GAAP净收入的非经常性影响，这使得这一任务变得更加困难。因此，作者使用了来自美国上市公司的10-K文件数据集，并采用了两种提示策略：一种是基于定义核心盈利能力和完整10-K文本的“原生”方法；另一种是经过实验优化的“序列”方法，该方法指示模型识别不寻常的损失、收益并将其汇总。通过对模型分析过程的审查以及对各种标准定量测试的应用，作者发现，基于“原生”方法的模型会混淆核心盈利与其他金融概念（如EBITDA），而基于“序列”方法的模型可以产生有效的核心盈利度量，并在大多数标准测试中优于GAAP净收入和Compustat的OPEPS和OIADP，从而预测平均未来盈利。总的来说，本文的研究结果表明，LLM具有巨大的潜力，可以帮助降低处理和分析日益臃肿的上市公司财务披露的成本。

---

两种不同的提示策略：

1. 基线“out of the box”方法：提供核心收益定义和完整的10-K文件。

2. 结构化的“sequential”方法：通过实验精炼的方法，指导模型识别不寻常的损失、收益，并对它们进行汇总和聚合。

---

论文实验

本文介绍了两种不同的方法来估计公司的核心盈利（core earnings），即lazy analyst approach和sequential prompt approach，并通过一系列的实验对其进行了比较分析。
首先，作者使用了lazy analyst approach对一家公司的10-K文件进行了分析，发现该方法在处理复杂概念时存在一些问题，例如无法准确识别非营业性收入和支出等。相比之下，sequential prompt approach则更加精细，将任务分解为三个步骤，分别是寻找非营业性收入和支出、调整非营业性收入和支出以及计算新的盈利措施。作者还提供了代表性的结果展示。
接下来，作者通过一系列的实验来比较这两种方法的效果。首先是描述统计学分析，包括对各项指标的平均值、标准差、中位数等进行比较。结果显示，lazy analyst approach的结果比sequential prompt approach更不稳定，而sequential prompt approach则能够更好地跟踪长期趋势。其次是预测能力测试，包括绝对误差、回归系数、R方值等指标。结果表明，sequential prompt approach的表现优于lazy analyst approach，但在某些情况下仍略逊于compustat OPEPS。最后是长期预测能力测试，结果与之前类似，但 authors指出需要更多的数据才能得出更为准确的结论。
总的来说，本文提供了一种较为系统的方法来比较不同方法的优劣，并指出了每种方法的优点和缺点。这对于投资者和其他金融分析师来说都是非常有价值的参考。



### 42

方军 2024-10-08


这是为什么需要校对，刚刚发现朋友公司的文档，把purpose写成purchase。

不过下面这个还是天花板。讲实话，都是文盲。校对不足的错可以改。文盲的错，没救。

转：这个据说是中国商务社交场合天花板的活动，其组委会的语文水平确实有点让人捉急。


### 43

方军 2024-10-08

摘：卡内基梅隆大学出版的一本非常好的 628 页数学教科书。

我喜欢作者的描述

本书的目标是帮助读者从数学消费者转变为数学生产者。这就是‘纯'数学的含义。数学消费者可能会学习链式法则并用它来计算导数，而数学生产者可能会从导数的严格定义中推导出链式法则，然后在更一般的环境中（如多元分析）证明链式法则的更抽象版本。

数学的消费者应该说出他们如何使用他们的工具来找到答案。另一方面，数学的生产者必须做更多：他们必须能够跟踪定义和假设，以新颖有趣的方式拼凑事实，并对数学概念做出自己的定义。

https://infinitedescent.xyz/dl/infdesc.pdf

An Infinite Descent into Pure Mathematics – Introd...

这本书提供 TeX 版本，真棒！

很快将有一个新的版本，看网页写的是 12月。

[An Infinite Descent into Pure Mathematics – Introductory textbook on mathematical proof](https://infinitedescent.xyz/)

2『已下载原文书籍「2024103An-Infinite-Descent-into-Pure-Mathematics」。（2024-10-19）』

### 44

方军 2024-10-09

这个世界充满了荒谬的言论，我尝试着自己分析下，也让AI分析下（当然，更好的做法是，完全屏蔽或忽视这种「低智」言论。有时候在一些群里，大家从来不讨论，只是天天拿群主开玩笑，反而是都是明白人，因为玩笑可以瞎说八道，但只要一开始严肃讨论，那都会拿出劲头来）：

> 感觉像美国回过味儿了，只许美股吸血，这次诺奖颁给AI和mRNA就意图很明显，想继续炒美股，除了这个就没啥能炒的了

- 美股、A股吸血（争夺资金），这个逻辑怎么来的？
- 诺奖颁奖，和这个怎么会有什么关联？
- 得出的推论：继续投资美股，前后没联系啊。

Prompt: 分析这段话的模糊与谬误：

> 感觉像美国回过味儿了，只许美股吸血，这次诺奖颁给AI和mRNA就意图很明显，想继续炒美股，除了这个就没啥能炒的了

这段话包含了一些模糊表述和逻辑谬误,让我们逐一分析:

1. 模糊表述:
   - "感觉像美国回过味儿了" - 这是一个主观感受,没有具体事实支持。
   - "只许美股吸血" - 使用了带有情绪色彩的词语,没有明确定义什么是"吸血"。
   - "意图很明显" - 这是一个主观判断,没有提供客观证据。

2. 因果关系谬误:
   将诺贝尔奖的颁发与炒作美股直接联系起来,但没有提供足够的证据证明两者之间存在因果关系。

3. 过度简化:
   将复杂的经济现象和科学成就简化为单一目的(炒作股市),忽视了其他可能的因素和影响。

4. 阴谋论倾向:
   暗示诺贝尔奖的颁发是为了操纵股市,而没有考虑科学成就的真实价值和影响。

5. 以偏概全:
   "除了这个就没啥能炒的了" - 这是一个过于绝对的陈述,忽视了其他可能影响股市的因素。

6. 缺乏具体数据支持:
   整个论述都缺乏具体的数据或事实支持,主要基于个人推测和感受。

7. 混淆相关性和因果关系:
   即使诺贝尔奖的颁发和股市表现之间可能存在某种相关性,也不能直接推断为因果关系。



### 45

方军 2024-10-09


之前虽然有很多人吐槽 LangChain（vs LlamaIndex）

但用这类工具，真是什么最多人用，用什么

基本逻辑很简单，开源工具，最多人用，那就迭代最快，各种问题在迭代中会被解决掉不少

这个图里，AISDK（普通人不太需要的），但如果你要做一个 TypeScript的前端界面，它也帮忙干了很多脏活累活。

它的超过不意外，逻辑上讲，前端的量应该是后端量（LangChain这一类）的十倍都不止。


### 46

方军 2024-10-09

一个读者对《重新学会学习》的评论，我觉得她很敏锐，我在前一本书的结语写的的标题是：“唯有笨功夫”

她点评的第一点主要是副题部分。我的一个解释是：当时不写太多 AI 的原因是，不想很多内容快速变得过期。因此，放进去的都是五年甚至更长时间不过期的 AI 内容。

摘：慢即是快

这本书的书名和内容在我看来不很相符，原因有三，

第一：虽然书名中的AI是吸引我来读这本书的原因，但实际上关于AI的内容不是很多。不管怎样，这部分内容对我很有启发性，尤其是AI时代的知识系统和如何利用AI的错误来学习这两个点打破了我的认知局限；

第二：从书名看会有人误解是提速或者快速学会的工具书，但实际上书中的方法因为以费曼学习法为基础，强调把知识变成自己的，重在实际应用，因为符合慢即是快的理念，也是我一直努力的方向。

第三：书名中的10倍提效，很像大家常说的经济的10倍增长、收入的10倍增长等概念，但书中的工具的刻意练习实际上是符合指数增长规律，刚开始甚至会觉得很慢，但一旦熟练，将开启开挂学习提效模式。



### 47

方军 2024-10-09


今年的诺奖是 AI 大年啊，诺贝尔化学奖

[为何诺贝尔化学奖又颁给AI？万字专题详解：计算和人工智能颠覆我们对蛋白质的理解方式](https://mp.weixin.qq.com/s/WkPJiuXZ65I6sqsEAVGrdw)

### 48

方军 2024-10-09

宝玉的科技文章翻译提示语，效果真棒，在这个文章最后：

[GPT 无法翻译超长内容的提示词优化尝试 | 宝玉的分享](https://baoyu.io/blog/gpt/gpt-translation-long-content-optimization)

我用 claude 跑的效果相当之好。它的核心就是之前宝玉分享过的三步翻译：

1. 直译
2. 反思
3. 修改

他最近加了一个长文分段。如果跑程序不太需要，交互式长文分段是必要的。

以下为 AI 提取的大纲，供快速了解。



### 49

方军 2024-10-10

153 意见小火山：AI 为何比之前的媒介都好？

如果把 AI 当成一种新的媒介的话，为什么它比之前的都好？我「意见小火山」这个角度做个解读。

意见小火山，是罗尔夫·多贝里在他好几本通识性的书里提到的说法，比如在一本里他这样举例：

```
你对基因改造的小麦有何看法？你认为我们需要管制人工智慧的法规吗？对于自动驾驶，你的立场是？你赞成放宽软性毒品吗？

听到这些或类似的问题，即使对该议题并不在行，你的大脑还是会立刻自动产生见解。这座🌋意见小火山🌋完全是自行引爆，不受控制，它与一种典型的行为谬误有关：我们习惯对一些实质问题提出见解，尽管对于这些问题，（1）你并不是真正感兴趣；（2）无法从根本上回答；（3）对我们简单的脑袋而言太复杂。（《拒看新闻的生活艺术》）
```

我们这些人也经常有这种感受，看到各种事件时，也会冒出「意见」。这就分很多种了
：

第一种，我们自己内行的专业领域，的确应该有判断。但是不是要有「意见」呢？其实不一定。表达出来的意见，一种可能是让我们再也不想了，这是大脑清空的效果，但也有一种可能，我们未曾深思熟虑的意见，在未来误导自己。我知道了，可能就可以（我往往不到，努力做到）。

第二种，对我们来说外行的专业领域。如果没有自知之明表达意见，我们会犯很多愚蠢的错误。有一定学识的人，一般不会犯这样的错误，因为对自己的能力范围有较为清醒的认知。但有时有点麻烦的是，我们往往会很好奇，然后去了解，然后就掉到兔子洞里了。尤其是如果社交网络（X/Twitter、微信群）跟人讨论请教，这会带来很多的精力分散。这也是一种意见小火山，容易让我们分心。

第三种，大众事件。这就比较微妙了，有人认为，人应该对外界保持敏感。但也有人认为，外界保持一定程度的迟钝，可能过得更加舒心。这种是多贝里讨论的意见小火山的主要范围了，尤其《拒看新闻的生活艺术》。我觉得，敏感也不要发表意见，同时，迟钝些好，多数时候可以这么说：那些跟我有个狗屁的关系？

那么，AI 为什么好呢？我觉得 AI 在第二个部分帮了不少的忙，它能够给出一些解释，但不会像搜索一样让我们一个个链接跳下去，也不会激发我们在社交网络的讨论欲望（别人给我答案了吗？）。
收起

查看详情
Jese__Ki 觉得很赞
方军：有时候，我会采用「骂人」的方式来消除意见小火山，哈哈，就是让信息小火山爆发掉。

比如，辛顿获得诺奖后，在社交媒体上看到多个写辛顿家族的，我就会暗骂一句：看这个是“信息韭菜”，搞这个是“割信息韭菜”。

辛顿得奖是该了解了，想要跟上世界进步的人都该了解下。但会，辛顿家族有谁谁谁，扯淡啊，传奇故事没意义。

都是信息韭菜。
2024-10-10 12:41
方军：听听辛顿觉得自己当不了木匠，还是回学校做研究也好点啊

他家族牛不牛，无聊时当成逸事看看可以，但这种时候消费这种信息，是很胡扯的。

对普通人，借机了解下：人工神经网络是什么，反向传播是什么，机器学习是什么，深度学习是什么，AI有什么用？不是更好嘛。
2024-10-10 12:43
方军：有一种讨论学习方法的论调是，你要了解来龙去脉

不对不对，这些逸事就是让你产生兴趣，不是来龙去脉（产生兴趣当然很重要，科普的一个重要作用就是激发兴趣，所以科普书里面都是很多这种逸事）

来龙去脉，是它怎么从一个理论，发展到另一个理论，怎么又中间岔开很多年，然后又发展到另一个理论
2024-10-10 12:46



### 50

方军 2024-10-10

真直观

This year’s NobelPrize laureate in physics John Hopfield created an associative memory that can store and reconstruct images and other types of patterns in data.

The Hopfield network can store patterns and has a method for recreating them. When the network is given an incomplete or slightly distorted pattern, the method can find the stored pattern that is most similar.

Read more about the research that led to this year’s physics prize: 

[The Nobel Prize in Physics 2024 - Popular science background - NobelPrize.org](https://www.nobelprize.org/prizes/physics/2024/popular-information/?utm_source=twitter&utm_medium=social+media+&utm_campaign=nobel+prize+announcements+2024&utm_content=post)

### 51

方军 2024-10-10

我总是在不断反思究竟要消费多少媒体内容，但讲实话，媒体内容的质量真的很糟糕（对我个人来说）。还记得早前听已转型为新闻学教授的电视新闻人的话，他说，电视像大海一样广，只有一毫米深（大意）。

下面这篇卫报文章，很显然是为了满足多数人的需要，能理解，但的确对我来说没有信息价值。我也能理解媒体总要强调风险，并用了气候变化这样的类比，但大众媒体这方面的讨论真心很浅薄，且立场先行。

Demis Hassabis: from video game designer to Nobel prize winner
德米斯·哈萨比斯：从视频游戏设计师到诺贝尔奖获得者

Google DeepMind chief believes in benefits of AI but says risks must be taken as seriously as the climate crisis
谷歌 DeepMind 首席执行官相信人工智能的益处，但表示必须像对待气候危机一样认真对待风险

Dan Milmo Global technology editor
丹·米尔莫 全球技术编辑
Wed 9 Oct 2024 09.56 EDT

Most 17-year-olds spend their days playing video games, but Britain’s latest Nobel prize winner spent his teenage years developing them.
大多数 17 岁的人整天都在玩电子游戏，但英国最新的诺贝尔奖得主在他十几岁的时候就开发它们。
Sir Demis Hassabis, who was jointly awarded the chemistry prize on Wednesday, got his big break in the tech world as co-designer of 1994’s hit game Theme Park, where players create and operate amusement parks.
周三共同获得化学奖的德米斯·哈萨比斯爵士，在科技领域取得重大突破是作为 1994 年热门游戏《主题公园》的联合设计师，在该游戏中玩家创建和经营游乐园。

Born in London to a Greek Cypriot father and Singaporean mother, Hassabis went on to gain a double first in computer science at Cambridge University, launch his own video game company, complete a PhD in cognitive neuroscience and then co-found the artificial intelligence startup DeepMind, which Google bought for £400m in 2014.
哈萨比斯出生于伦敦，父亲是希腊裔塞浦路斯人，母亲是新加坡人，他在剑桥大学获得了计算机科学的双一等学位，创办了自己的视频游戏公司，完成了认知神经科学的博士学位，然后与人共同创立了人工智能初创公司 DeepMind，谷歌在 2014 年以 4 亿英镑收购了该公司。
The 48-year-old was knighted for services to AI this year.
这位 48 岁的人今年因对人工智能的贡献而被授予爵士头衔。
He is the chief executive of Google’s AI unit, Google DeepMind, and its achievements in using AI to predict and design the structure of proteins has spurred the award of the Nobel to Hassabis and his colleague John Jumper, who are sharing half of the award with the other half going to the US academic David Baker.
他是谷歌人工智能部门谷歌深度思维的首席执行官，其在使用人工智能预测和设计蛋白质结构方面的成就促使哈萨比斯和他的同事约翰·江珀获得诺贝尔奖，他们与另一位美国学者大卫·贝克分享该奖项的一半。
Hassabis has always extolled the benefits of gaming and has described it as a gateway to AI after, as a chess prodigy, he became interested in how chess computers learn to play the game.
哈萨比斯一直颂扬游戏的益处，并将其描述为通向人工智能的门户，因为作为一名国际象棋神童，他对国际象棋计算机如何学习下棋产生了兴趣。
“I think that started sparking off in my mind ideas about how does the chess computer play chess and learning about that,” he told the BBC in 2020. “Many children start by playing games, like I did, and then getting into programming and then using this incredible tool, the computer, to create things.”
“我认为这在我脑海中开始引发关于国际象棋计算机如何下棋以及对此进行了解的想法，”他在 2020 年告诉英国广播公司。“许多孩子像我一样从玩游戏开始，然后进入编程，然后使用这个不可思议的工具，计算机，来创造东西。”

Google DeepMind scientists and biochemist win Nobel chemistry prize
谷歌 DeepMind 科学家和生物化学家获得诺贝尔化学奖
Read more 阅读更多
His startup was able to build AIs with top-class performances in games including Go, which caused a global sensation at the time, chess and the video game Starcraft II.
他的初创公司能够制造在包括围棋（当时引起了全球轰动）、国际象棋和视频游戏《星际争霸 II》等游戏中具有顶级性能的人工智能。
Hassabis’s expertise is sought after. He attended a meeting of the UK government’s Scientific Advisory Group for Emergencies in 2020 to advise on its Covid-19 response and was feted by Dominic Cummings, and in July Tony Blair told him he was “advising the new government to talk to you”.
哈萨比斯的专业知识备受追捧。他在 2020 年参加了英国政府紧急情况科学咨询小组的一次会议，就其对新冠疫情的应对提供建议，并受到多米尼克·卡明斯的赞扬，7 月托尼·布莱尔告诉他，他“建议新政府与你交谈”。
As the leader of Google’s AI efforts, Hassabis is at the forefront of a multibillion-dollar AI boom in which US tech companies are playing a leading role, with Google competing against the likes of Meta, the ChatGPT developer OpenAI and Microsoft to produce further breakthroughs.
作为谷歌人工智能工作的领导者，哈萨比斯处于价值数十亿美元的人工智能热潮的前沿，在这场热潮中，美国科技公司发挥着主导作用，谷歌与元宇宙公司、ChatGPT 开发者 OpenAI 和微软等竞争以取得进一步突破。
He is well aware of the potential pitfalls of AI – a technology that can be loosely defined as computer systems performing tasks typically associated with intelligent beings – and last year signed a statement warning that the threat of extinction from AI should be considered a societal-scale risk on a par with pandemics and nuclear war.
他非常清楚人工智能的潜在陷阱——这项技术可以大致定义为计算机系统执行通常与智能生物相关的任务——并且去年签署了一份声明，警告说人工智能带来的灭绝威胁应被视为与大流行病和核战争同等的社会规模风险。
In an interview with the Guardian before the inaugural global AI safety summit last year, Hassabis said the risks from out-of-control AI systems were as serious as the climate crisis.
在去年首届全球人工智能安全峰会之前接受《卫报》采访时，哈萨比斯表示，失控的人工智能系统带来的风险与气候危机一样严重。
“We must take the risks of AI as seriously as other major global challenges, like climate change,” he said. “It took the international community too long to coordinate an effective global response to this, and we’re living with the consequences of that now. We can’t afford the same delay with AI.”
“我们必须像对待气候变化等其他重大全球挑战一样认真对待人工智能的风险，”他说。“国际社会花了太长时间来协调对此有效的全球应对措施，我们现在正承受着这样的后果。在人工智能方面，我们不能承受同样的拖延。”
But Hassabis is also an emphatic believer in AI’s positive potential, and the Nobel prize underscores that. He points to his work with DeepMind’s AlphaFold, which predicts the structure of proteins based on their chemical sequence, as an example of AI’s power to do good.
但哈萨比斯也是人工智能积极潜力的坚定信徒，诺贝尔奖也强调了这一点。他指出他与 DeepMind 的 AlphaFold 的合作，该模型根据蛋白质的化学序列预测其结构，以此作为人工智能做好事的力量的一个例子。
“I am not in the pessimistic camp about AI obviously, otherwise I wouldn’t be working on it,” he said last year.
“显然我不属于对人工智能持悲观态度的阵营，否则我就不会从事这方面的工作了，”他去年说。



### 52

方军 2024-10-10

绝大多数文章，写的人很动容，但看起来真累。

我这三四个月对 AI 最大的感悟是，它真的「懂」文字。

咱们先别管它是不是有意识、有智能，那是很高阶的问题。

也别管它是不是真懂文字（咱们也别说它会不会写），就阅读理解而言，它看起来像鸭子，叫起来像鸭子，走起来像鸭子，那就是鸭子。

在之前，我们从来没有一个信息工具是真的能够读「懂」，这回是真的懂。

慢慢地把对生成式的期待降下来，它就是一个懂语言的（不管是人类语言、语言翻译，还是代码语言，还是数学公式语言），它的确懂，这就够了，足够我们用十年，移动互联网也不过是十来年的事。

如下是引发我想法的一篇文章的AI提纲（注意，原文是一个感性文章，但我目前用的大纲提取会自动将它变成理性逻辑，当然这是我需要的，我需要快速获取信息）。另外，在不要分享给别人时，我就看Markdown大纲，为了别人看着美观直观才搞图示。




### 53

方军 2024-10-10

摘：B站视频……比如Sipser的网课，他讲不少计算机理论的历史，他提到一个人的时候能不能塞一张这个人的照片进来；还有Sipser讲话很罗嗦，ai可以浓缩精炼一下；第三Sipser的板书狗啃的一样，AI可以整个方便阅读一百倍的；尤其是其中公式能copy出来的；包括讲课的要点也可以copy出来；没懂的地方直接让ai展开解释。

诸如此类吧。视频是比较好的一种学习方式，但远远谈不上最好。「多媒体」不该简单的是把各种格式的内容混合在一起，而是不同模态的信息可以自由转换，编辑，增删，解释，等等。



### 54

方军 2024-10-11

不知道，我总觉得 A16Z 这个AI投资叙事很不靠谱，人真的想要记录和分析自己吗？

之前的确有一群数据记录的狂热爱好者，但我觉得都是异类。

另外可能我对这些硬件都有疑问。刚刚我还在一个群里请教：还是不能理解这种耳机，耳机不是质量最重要吗，我只对音乐效果和降噪这两个需求强

我觉得目前唯一成功的记录是拍照和自拍，次级成功的是Twitter/微博/小红书，再次级是减肥记录等等健康记录。

可能对我来说文字太容易，所以很难理解人们对于多模态的极度热情。我就理解不了语音输入，但的确看朋友是写微信都是语音，然后手机上改。我宁愿背着电脑。

这个星球，就是 AI 方面我的一个 Brain Dump，一个公开的笔记，实际上，AI方面除了开发和论文相关的资料，基本上都在这儿了。 

https://x.com/venturetwins/status/1844408644714233...

New @a16z thesis: building the "AI brain"

We all exist in our own context.

Is it possible to take your jumble of thoughts, history, and memories and distill it into something tangible?

How I exported my brain to AI + what I'm seeing from startups 

  新 @a16z 投资主题：构建“人工智能大脑”

我们都存在于我们自己的背景中。

是否有可能将你杂乱的想法、历史和记忆提炼成某种有形的东西？

我如何将我的大脑导出到人工智能

I spent the last six months talking to ChatGPT daily - spilling thoughts, feelings, and even screenshots.

The goal? To create an "AI brain" that truly understood me.

I was blown away by the results...and found it valuable for much more than I expected. A few use cases:

在过去的六个月里，我每天都和 ChatGPT 交谈——倾诉想法、感受，甚至截图。

目标？创造一个真正理解我的“人工智能大脑”。

我对结果感到惊讶……并发现它的价值比我预期的要高得多。一些用例：

 Communicating with others

Some conversations feel like a game of telephone - you're not quite sure you're being understood (or understanding correctly).

Brain dump into an LLM, and it will translate thoughts into more effective communication. Many are already doing this!
  与他人交流

有些对话感觉就像传声筒游戏——你不太确定自己是否被理解（或正确理解）。

将大脑倾倒到一个LLM中，它将把想法转化为更有效的沟通。许多人已经在这样做了！

 Understanding yourself

LLMs are shockingly good at psychoanalyzing you (as evidenced by ChatGPT's assessment of me).

They can help you get a clearer picture of your strengths and weaknesses, and remind you of things you've forgotten - correcting misconceptions or biases.
  了解你自己

LLMs 在心理分析你方面非常出色（正如 ChatGPT 对我的评估所证明的那样）。

它们可以帮助你更清楚地了解自己的长处和短处，并提醒你忘记的事情——纠正误解或偏见。

 Communicating with applications

You should be able to take your AI brain to other apps.

This would unlock truly personalized apps - a writing assistant that actually sounds like you, a dating app that gives you five perfect matches, or your own specialized recruiter.
  与应用程序通信

你应该能够将你的人工智能大脑带到其他应用程序中。

这将解锁真正个性化的应用程序——一个听起来确实像你的写作助手，一个能给你五个完美匹配对象的约会应用程序，或者你自己的专业招聘人员。

This thread is mostly personal use cases, but there's many work ones. Some AI brain features:

1) Enables perfect memory, searching every doc/email.
2) Knows where you need to develop (and how, based on your style!)
3) Surfaces insights from meetings to respond to objections.
这条线索主要是个人用例，但也有很多工作用例。一些人工智能大脑的特点：

1）实现完美记忆，搜索每一份文档/电子邮件。
2）知道你需要在哪里发展（以及根据你的风格如何发展！）
3）从会议中获得见解以回应反对意见。





### 55

方军 2024-10-11

红杉也发了一篇关于生成式AI新的投资主题的分析：生成式AI :推理时代开始（更多讨论的事应用可能性）。跟去年的思考方式变化不小。

Generative AI's Act o1: The Reasoning Era Begins |...

2022： https://www.sequoiacap.com/article/generative-ai-a...

2023： Generative AI’s Act Two | Sequoia Capital

其他人整理的摘要：强烈推荐大家深度阅读 Sequoia刚刚发布的关于生成式 AI 的年度报告，有几个非常重要的 take-aways：

1、新的 scaling law 已经开始：o1 的发布代表了通过「推理时计算」所取得的一般推理能力的重大进展，这是生成式AI的“AlphaGo时刻”，也是大模型 scaling law 的一个重要转折点。我们给到模型的推理时间计算越多,它的推理就显著越好。这也将进一步推动应用层的可用性。

2、SaaS 的重新定义：SaaS 将从 Software as a service 开始转向 Service as a Software，这也 echo 了我去年提到的 sell work, not software。SaaS 将从卖席位，转向卖最终的交付结果。

3、细分领域的 know-how 将变得无比重要：文中提到的认知架构，通俗一些讲就是不同行业的 know-how，如何将这些 know-how 与模型能力结合，从而端到端解决问题。而这恰是构建数据闭环，实现从 co-pilot 到 auto-pilot的关键。

让我欣喜的是，一方面看到大模型进入到下一阶段的技术突破，另一方面，伴随着模型变强大的过程，产品经理的窗口期已经来了！很是期待！

---

[Generative AI's Act o1: The Reasoning Era Begins | Sequoia Capital](https://www.sequoiacap.com/article/generative-ais-act-o1/)

### 56

方军 2024-10-11

现在都讨论推理了，但我其实对已经热了一年的长上下文窗口有很大疑问。

不谈产品层面，就模型接口层面，为什么非要把一个超长的资料直接放进去给模型？

一个资料如果足够长，那肯定可以预先做很多处理，然后让模型小块小块地吃。

或者用几个模型组合起来，各自干不同的事：比如有的负责拆解，有的负责推理，有的负责组合。

非要一下子放进去，是什么道理？

从产品角度来讲，我觉得都是合理的，什么 Kimi、元宝、通义，都是一点一点都处理，本质上都是RAG。

同样的问题实际上也可以用来说推理：

一个问题在多轮处理后，把核心需要推理的部分给推理模型，这合理的。

但是扔一堆杂七杂八信息，让模型推理，这难道不是自讨苦吃?



### 57

方军 2024-10-11

154 让 AI 采用特定任务的认知架构

看红杉《生成式AI新一幕：推理模型到来》这篇投资主题论述，触动我的倒不是推理模型（推理模型会成为我们应用中的极其重要一环），触动我最大的是，我们应该为特定的任务准备认知架构。

这说起来拗口，通俗地说就是，搞明白一件事人类专家怎么做一个需要认知努力的事，然后我们也用 AI 拼凑一个类似的处理方式。

我们来说更具体的例子。比方说，我个人有大量的信息需要读，这些信息分成两类情形：1）需要快速把握要点；2）比较难，需要真正地理解难点。

📍 拆解信息阅读流程

就阅读与理解而言，大体上经历这样的过程：

- 前置步骤：初步筛选，不合适的信息就不要进到这个管道了。

- 第一步：获取信息概况，这通常靠看标题、第一段、小标题、主题句等可以获得。同时，现在还可以用 AI 总结来获得，我们可以按自己的需求定制 AI 总结。

- 第二步：获取核心信息，这里我主要指信息的整体框架。这一步，过去几乎没有信息技术手段可以做到，如果原文由较好的多级小标题的话，通常有工具把它们显示一下。现在，则可用比如我最近分享的大纲提取提示语来获得。如果需要，再用可视化工具（比如思维导图）看一下，看多级列表速度快，但看一张图更容易把握整体。

- 第三步：仔细阅读。这一步目前我觉得还很难由 AI 来进行多少处理，主要是人在做，AI在AI辅助，比如做些翻译、解释、举例。实际上，在这一步我尽量避免 AI 的参与，因为此时处于不联网状态时，信息获取效率更高。

- 后续步骤：仔细阅读的材料，多半有很多后续，比如1）写下想法供斟酌，这是行动导向、2）做出回应，这是文本到文本的导向、3）制作类似资料卡供以后用，这是资料导向。

📍 AI 辅助的信息阅读工作流

就如上这个很简单的资料阅读流程来讲，我们可以组建一个“认知架构”，其中一部分由人做，一部分AI做。同时，特别注意，开始不用太追求自动化，自动化应该是非常成熟之后，自动化以进一步加速。

工作流可以是这样的：

第一个工作流的职能是初步筛选信息。

相应的信息进到不同的「收件箱」。

真正需要看的信息，进入「阅读箱」

放在公司场景中，这相当于是行政秘书，进行资料的收发。

第二个工作流的职能是按个人习惯进行信息简化。

资料被整理成「资料本身」、「摘要」、「大纲+图示」这样的形式。

根据材料和聪明助理的提示，我们以比过去快得多的速度阅读。

放在公司场景中，这是业务助理，他按我们的习惯整理信息，有时候也会告知我们：这个最为重要、这里有一点需要特别注意。

讲实话，在现实中，能拥有聪明助理，几乎是可遇不可求的。前一种最优秀的行政秘书也是如此。

第三个工作流，如前所述，目前还很难优化，因为这个部分是我们阅读，AI 辅助。

第四个工作流，这是很多人目前寄予厚望，但我强烈反对。如果不是为了应付一份工作，一个材料如果需要 AI 写，那可能它就不用写。但是，进行校对、进行语法修正、提示个人常见错漏，在这些方面 AI 还是比过去强很多。

从上述例子就可以看出，这两个任务都是有比较专业、且普遍接受的做法的，我们可以把本来人做的事情，交给突然能够理解语言的AI大模型去做。

📍 将专业认知架构给到 AI 

以上这个场景只是举例，在商业场景中、学习场景、法律场景、科研场景中，越具体细看这种任务类型就越多。让 AI 大模型泛泛地做，它们做不好，但只要细化、具体，并真正地把「原有的专业认知结构」放进去，AI 大模型就变得非常强大了。

（如上讨论偏重应用视角，而非模型视角，仅仅考虑如何使用模型来完成一个任务。我认为，在讨论时，别把两个混起来各自探讨是必要的。这也是出于实用，我们不训练模型，那么我们都在应用域，那就讨论我们能做的。）

红杉文章：Generative AI's Act o1: The Reasoning Era Begins |...

红杉资本：套壳才是应用层王道，o1改变了大模型行业，年度行业报告更新

图为红杉报告的AI提取大纲，仅供参考。这篇文章也尝试生成大纲图，生成两个版本供参考。

[红杉资本：套壳才是应用层王道，o1改变了大模型行业，年度行业报告更新](https://mp.weixin.qq.com/s/xnjhiJ8UdRp9tPzVBnFADw)

### 58

方军 2024-10-11

这位读者读阳志平老师《聪明的阅读者》，用其中提到的测试效应的做法太棒了。她直接把方法用起来，非常有条理（这个做法也可以叫“生成”，《认知天性》里面有提到学习里面的生成，与生成式AI是不一样的。）：

[聪明的阅读者---必要难度理论](https://mp.weixin.qq.com/s/jBJ7odoUu1BFtHEZ8vbvQw)

之前，我都是设想，用 AI 来生成一些选择题，然后做题测试。
现在看，看书时如果是具体的做法，还可以生成步骤，然后做。（当然，最重要的还是自己去做这些步骤）



### 59

方军 2024-10-11

今天朋友讨论他出书的想法，讨论了很多，但我冒出一个很奇特的想法：

人们都低估了书

但凡敢写书的人，都有点水平、有点自知之明、有点追求

这三点加起来，就会让每一本书都超过这本书相关的同类信息
（更何况书的规模通常要大得多）

这是因为，写书的过程中，都会不断地突破边界

虽然有时有的书看似很差（从外部评价），但对写的那个人来说，都是突破边界的

这就是太多人低估书的原因，哪怕一本你觉得的烂书，也比你可能看到的同类信息好很多

更不要说那些经过考验的好书了

至于我们天天说的 AI， 就知识而言，如果 AI 是 10 分，那多数书是在 80 分那条线那儿

不是很多人以为的，AI 在 80 分线那儿



### 60

方军 2024-10-11

这个人用 NotebookLM  这一场景有点意思：

dontbesilent：今天是我第一次，自己真正作为用户使用了 NotebookLM，发现了真正的！能提供增量价值的场景！和以前想的傻办法完全不一样

这是一个人类和 AI 都无法单独提供价值的场景

起因是早上约了一个律师电话咨询，本以为要聊一个小时，结果这个律师思维清晰、语速也快，十几分钟之后我就不知道聊啥了

然后我把电话咨询的录音上传到 NotebookLM，我打字和 NotebookLM 聊了一个小时，还让它把合规的广告文案都给我写好了

我发现这个价值，目前是无论 AI 还是人类都无法提供的：

1. 电话咨询的时候，我和律师都没有充分的时间思考，提问和回答都受限
2. 律师不懂营销，只能说问题在哪，但不能帮我写文案
3. 律师时间有限，不能在凌晨 1 点抽出 3min 帮我解决问题
4. 律师掌握的一手信息，对我的具体情况的分析，是目前法律 agent 无法替代的

以前我研究的「AI 给定制报告赋能传统行业」这个已经可以稳定变现，现在这个类似「人类进行问题收缩，AI 再二次展开」的过程，一定也可以变成钱

https://x.com/dontbesilent12/status/18446600769064...

[(9) X 上的 dontbesilent：“今天是我第一次，自己真正作为用户使用了 NotebookLM，发现了真正的！能提供增量价值的场景！和以前想的傻办法完全不一样 这是一个人类和 AI 都无法单独提供价值的场景 起因是早上约了一个律师电话咨询，本以为要聊一个小时，结果这个律师思维清晰、语速也快，十几分钟之后我就不知道聊啥了” / X](https://x.com/dontbesilent12/status/1844660076906426527)

### 61

方军 2024-10-11

从阅读资料角度考虑，什么样的大纲图是有价值的？我还在摸索。

如下两个，哪个更好呢？左侧略好一点，但也很差。想明白信息，才能给 AI 更好的指令。

可能要删减下才较好。

说明：1）我现在不考虑那些复杂的图形形式，颜色也采用简单的，是因为我还是比较关心信息本身。从制作信息图的人角度来看，这些估计太差了。2）用短文做实验是因为短文人脑可以方便把握，便于对比。



### 62

方军 2024-10-12

ackAPrompt全球提示破解竞赛

常见提示破解技术
- 分析了18种常用技术
  - 复合指令
  - 简单指令
  - 忽略上下文

新发现的攻击方法：上下文溢出攻击
- 攻击原理：
  - 在提示中附加大量文本
  - 仅留少量令牌用于生成

Website: HackAPrompt

[HackAPrompt](https://paper.hackaprompt.com/)

Paper (accepted to EMNLP): http://paper.hackaprompt.com/HackAPrompt.pdf

[Learn Prompting: Your Guide to Communicating with AI](https://learnprompting.org/)

https://x.com/learnprompting/status/17252643531195...

[(9) X 上的 Learn Prompting：“A few months ago, we ran HackAPrompt, the first-ever global Prompt Hacking competition! Over 3K hackers submitted 600K malicious prompts to win $35K in prizes from companies like @PreambleAI, @OpenAI, &amp; @huggingface We analyzed 29 different techniques &amp; found a NEW exploit👇🧵 https://t.co/qqrz66Ifcv” / X](https://x.com/learnprompting/status/1725264353119580577)

### 63

方军 2024-10-12

最近复看那段时间很多推荐产品型的人看法，一点感想

- ChatGPT Interpreter（后改名为 Data Analysis，我理解，它不是代码生成器，而是生成 Python代码、进行一些数据分析辅助）

- Claude Artifact（我理解是个前端代码生成器），对比而言，给工程师的 vercel v0更好

- ChatGPT Canvas（新增一个附加窗口，用于代码编辑与文本编辑，相当于在网页里面加一个编辑器）。对比而言，Cursor、Zed、甚至VS+Copilot都更好。

这几个产品出来时，各种介绍的人倒都是比较准确地看到它的实际功能和使用场景的，专业都是过关的，没有像不懂行的瞎忽悠（比如，能生成代码，就说要取代程序员；能生成几个分析图表，就说数据分析都可以AI做。）

但是，回头再看时，他们那种「推荐产品」的语气，真是天生的。就是电视直销、网络直播带货里那种推销的语气。可能他们对于新产品的热爱，是我理解不了的吧。

同时，这些人好像与会关注 Dify、Coze 的是两种人，对这两个没那么酷炫、但可用于实际商业、工作的，他们提及不多。我猜，他们也会用，但判断这东西没有「推销」给大众的必要性。

这几个产品讲实话都不重要，因为真正重要的必然是模型，或者模型API层次看到的东西。从机制上讲，它们也远没有 ChatGPT 的 GPTs 商店重要，虽然这个商店发展远不如预期。



### 64

方军 2024-10-12

OpenAI  公布了提示语生成器(meta-prompt)的 Prompt

[Prompt generation - OpenAI API](https://platform.openai.com/docs/guides/prompt-generation?context=text-out)

和 OpenAI 去年发布的六种最佳提示策略是有共通性的：

[Prompt engineering - OpenAI API](https://platform.openai.com/docs/guides/prompt-engineering/six-strategies-for-getting-better-results)

有人讨论时，特别注意到了这句：

```ATTENTION! If the user provides examples where the reasoning happens afterward, REVERSE the order! NEVER START EXAMPLES WITH CONCLUSIONS!```

这个提示语包括两个版本：文本生成和语音生成。

提取大纲快速了解下（准确请看链接中的prompt原文）：

文本：生成详细的系统提示以引导语言模型有效完成任务



### 65

方军 2024-10-12

Anthropic 创始人文章，他很乐观：AI 将带来“压缩的21世纪”，在5-10年内完成人类生物学家100年的研究进展，预防和治愈几乎所有自然疾病，让人类实现生物自由甚至寿命翻倍。

这篇文章是从诺贝尔化学奖的角度写的：To the winners of the 2024 Nobel prize in Chemistry, for showing us all the way.

Machines of Loving Grace
How AI Could Transform the World for the Better
Dario Amodei — Machines of Loving Grace
(标题的来源：All Watched Over By Machines Of Loving Grace）

我终于大概看完了，机器翻译然后看的，翻译 PDF见附件。

Contents
Basic assumptions and framework
1. Biology and health
2. Neuroscience and mind
3. Economic development and poverty
4. Peace and governance
5. Work and meaning
Taking stock

Dario Amodei — Machines of Loving Grace

[Dario Amodei — Machines of Loving Grace](https://darioamodei.com/machines-of-loving-grace)

图为AI提取大纲。



### 66

方军 2024-10-12

云风的这段关于AI编程的讨论很有意思（为多个讨论的组合）：

什么时候你做的 app 用的时候崩了。然后你对 AI 说，这个 app 出了一个 bug ，这里是 github 地址，帮我把 bug 找出来修好。这个功能实现的话，我会拓展一下我的想象力。

这是一个非常现实的需求，甚至是大部分程序员日常的主要工作。如果 AI 可以解决这个问题，程序员的生产力至少可以提高 100 倍。

我只是从信息学的本质上分析这个问题：修 bug 需要的信息量大致相当于代码基包括提交历史，方能理解程序的行为，以及找到不符合预期的地方。这是为什么代码的原作者比旁观者更容易修复 bug 的原因。那些明显的笔误，不需要 ai ，一个古老而简单的 lint 就可以做到。

人类在学习编程的过程中，会被教授最重要的原则“不要依赖巧合编程”。而目前 AI 写代码的方式则是完全依赖巧合编程，这和软件工程发展这么多年的路线是完全相悖的。

即使现在 AI 的发展路线和人脑的学习过程是一致的，姑且认为从这个方向去模拟人脑是对的，但在对能量的利用率上机器和人脑还是差了太大的数量级。充分理解一个软件项目的代码对富有经验（预训练过）的程序员来说，都不是一件易事（从花掉的能量角度看），以现在 AI 使用能量方式看，更不划算。

---

其他人：在 AI 高速进化的今天，编程能力只会越来越不重要。想法/创意，执行力，持续获取流量的能力这些最重要。

为何不会是反过来的，“想法创意，执行力，持续获取流量的能力只会越来越不重要。程序员通过 AI 的协助，可以完全抛弃产品经理独立出产品了” 。从现在 AI 的表现上看，看起来更适合想点子而不是写程序。

其他人：不知道你们怎么想的，反正目前来看，AI写的代码确实并不完美，需要程序员有能力纠错能落地执行。但是AI出的点子，很多程序员确实想不到。而且程序员可以和AI配合将点子落地，反过来就不行了。只能是非常简单的东西才行。

其他人：从目前来看，我认为AI写代码的能力远超想出好点子的能力

AI 现在擅长做的事情都是可以容忍犯一些错误，或有一些偏差，有一些玄学，好坏没有绝对度量的事务。但即使这些偏差存在也不会导致有或没有的差别，可以通过不断迭代改善。几乎所有需要长期维护的代码需求都不满足这一点。反之，“创意，市场策略，媒介投放策略”则是非常契合的。

西乔：都讨论出这么多楼了

以我过去两年深度玩图像生成的体验来看说，AI并不不擅长创意，擅长的是 remix concept 和 enhancement。

搞策略更别提了。擅长的是文字工作而不是写作和创意本身，但想要超出平均水平的质量，就需要你给出更好的指令和方向。而能给出指令就需要人类的判断力和从业经验

文本代码图像视频生成都是如此（现阶段能力）

现在AI写个计算器手到拈来，但写个计算器有什么用？世界上少个计算器app 吗？ 你可以让它给你生成个计算器App的宣传广告（图有其表），再来点投放策略（全是废话），然后呢？能解决你计算器app 的营销问题吗？

总结一下就是 AI能帮助技能为0的人产出水平为60分的结果，帮助技能为50分的人产出80分的结果。

但想要95分以上的结果，只靠AI是达不到的，人也得90分水平。



### 67

方军 2024-10-12

昨天有朋友在评论区讨论如何通过阅读资料获取信息。我今天读Anthropic CEO长文有个感受：

从获取信息的角度，AI 让我们太幸福了

首先，英文可以翻译为较为通顺的中文。我今天自己做的AI翻译，不是用的沉浸式翻译那种中英文对照，我觉得质量超过大部分图书翻译水平，后面细说。

AI 提取大纲就不多说了，看了原文目录、核心信息和大纲，我才决定去看的。

其次，这篇文章其实我不是看下来的。要放慢速度细看，还有一个方法是听，我是用电子书上安装的讯飞有声听下来的。这是为什么我觉得翻译质量超过图书的原因，因为翻译结果听起来很顺耳。

看有看的麻烦，听有听的好处。听的好处是，没法跳跃，来了个外部制约条件。缺点就是听常见的，线性的，没有重点。

如上这两件事，都是大模型发展带来的。

另外推荐：讯飞的声音的确不错，不用接口，而用产品，似乎讯飞有声是最容易的平台，付费了专业音色选项非常多，比免费音色好很多。



### 68

方军 2024-10-12

三步翻译工作流：初翻，评价，精译

用宝玉的这个就可以了

它原来长文处理不好，最近优化后长文分页也可以了。无需再额外编写代码做，较为方便。

注意替换下其中的词汇库，换自己需要的。

当然，会编程的建议自己编程，会方便更多，我今天偷懒，结果远不如采用原来的代码。



### 69

方军 2024-10-13

我觉得，写如下一个编程提示语，还是蛮麻烦的。分步做，可能更好。

t0mbkeeper: “注释即文档”虽然是 Golang 提倡的，但其实早就有程序员践行这一风格。不过以后也许就是“注释即文档和提示词”了。我前阵子写的一个可以自动调节字幕时间轴的程序，就是由下面的提示词生成：

'''
你是一个经验丰富的 Python 程序员，熟悉 ASS 字幕格式。请写一个程序：
1、从命令行接收两个 JSON 文件，以下称做 clips_ori 和 clips_new，以及一个 ASS 字幕文件，以下称作 subs_ori。
2、使用 chardet 检测所打开文件的编码。
3、使用 pysubs2 处理 ASS 字幕。注意 ASS 字幕中的时间需要转换为秒数才能和 clips_ori、clips_new 中的秒数进行比较大小、计算等操作。
4、打开两个 JSON 文件，这两个 JSON 文件包含多个类似{"start": 1311.9356, "end": 1314.021}的对象。对象中的数字是秒数。每个对象描述一个时间段的起止点。
5、对 clips_ori 和 clips_new 中的每个对象，用 end 减去 start，计算出 duration，作为对象的第三个成员。
6、比较两个 JSON 中的对象数量是否相等，如不等则给出提示并退出程序。
7、比较两个 JSON 中索引位置相同的对象中 duration 的差异，如果大于 10 秒则给出提示并退出程序。为便于调整，这个 10 秒用全局变量表示。
8、从索引第一位开始，subs_ori 中所有在 clips_new[i].end 后的字幕事件的时间增加 clips_new[i].duration - clips_ori[i].duration。遍历操作，直到 clips_new 的最后一个对象。
9、将修改后的 subs_ori 另存为一个文件，文件名在命令行中指定。
10、给每个函数添加必要的中文注释。
'''



### 70

方军 2024-10-13


摘：这两天关于大语言模型无法推理，X 上又掀起一波讨论，来自 Taelin （ HigherOrderComp 创始人） 的帖子，François Chollet（Keras 作者）、Yann LeCun 等人进行了转发。

 Taelin ：

【一个简短的证明，说明大语言模型（即使是o1）仍然无法推理：

考虑反转完美二叉树的问题。这是一个老的、入门级的面试题，人类和大语言模型都能轻松解决。现在，我们只需添加三个关键细节，使其变得新颖且独特：

它必须反转键（即“比特反转排列”）
它必须是一个无依赖的、纯递归函数
它必须的类型是 Bit -> Tree -> Tree

这些小改动已经足以将这个问题带出“记忆解决方案区”。它不在互联网上。而你猜怎么着？这些已经足以难倒现代的AI。无论你怎么提示，它们都无法解决这个问题。

这非常值得注意，因为这个问题对人类研究者来说依然简单，而解决它的能力显然是进行计算机科学研究的基本前提。然而，所有现代AI在这方面都惨败。尽管我很喜欢大语言模型，但事实是：它们不具备推理能力，永远无法进行计算机科学研究。

你可以尝试以下提示：INVERT A BINARY TREE - $10k AI REASONING CHALLENGE...

我愿意支付1万美元给任何能证明AI可以正确实现这个函数的人。无论它想多久，都无法成功。（解决方案只有7行代码！）】

【小抱怨：

大语言模型看起来有智能的错觉，源自它们的巨大规模。这很难想象，但这些模型几乎记住了整个互联网。你问过的每个问题，不是以前已经有了答案，就是通过已有解决方案的简单组合来应对。但这仍然是一种错觉。

当大语言模型遇到需要全新解决方案的问题——一个它从未见过的问题——它们就失败了。就是这么简单。这就是我的例子所证明的。我拿了一个简单的问题——反转一个二叉树——然后加了几条约束，确保解决方案是独一无二的，数据集中没有现成的答案，迫使它去真正解决问题。结果呢？它失败了！

我要强调的是，这不仅仅是关于这个问题，而是关于所有问题。大语言模型无法真正解决任何问题。它只能输出记忆中的解决方案。如果没有人把解决方案发布到网上，那么即便是GPT-6、opus-5或o3，也无法解决这个问题。我对此非常肯定。

无法创造新的解决方案意味着大语言模型不会发明新的科学。是的，它们将彻底改变我们所知的世界。它们的影响会比计算机和互联网还要大。但，除非有一种全新的人工智能诞生，否则当涉及到治愈癌症或开发超导体时，我们仍然只能依靠自己。】

【这里的主要观点是，存在并非现有解决方案组合的解决方案，而这些解决方案是推进研究所必需的。大型语言模型将使 99% 的工作实现自动化，我对此很有信心。但我对它们能否使研究实现自动化持怀疑态度。】

Yann LeCun：【值得重复：
不要将检索与推理混淆。
不要将死记硬背与理解混淆。
不要将积累的知识与智力混淆。】

Worth repeating:
Do not confuse retrieval with reasoning.
Do not confuse rote learning with understanding.
Do not confuse accumulated knowledge with intelligence.

链接：

https://x.com/VictorTaelin/status/1844969648904663...

https://x.com/fchollet/status/1845103528806662258

https://x.com/ylecun/status/1845193021584728365


### 71

方军 2024-10-13

AI 使用的问题，有时，我觉得跟人讲多少都是徒劳，因为试图逆着人需要的东西来。

我也懒得画图写清楚了，随手画几个：

比如，我觉得多数场景下简单提示语会奏效，但是，如果你给人复杂提示语，会让人觉得你特别专业。

我特别想写这样的提示语，长达200行。但中间说：这中间198行AI你直接跳过。

比如，我觉得目前应该重视语言能力，但明显李继刚那个提示语有了图形才引发人们的关注，我在社交媒体发导图大纲也是类似的效应，发文字没人要看的。

比如，我认为用 AI 就是有什么问什么，交互式提问，追问。但很明显，人们喜欢说复杂的提示语，一步到位。天呀，你试试给人说要求，一次说一大堆要求有效，还是跟人说，好，现在直行，下个路口准备左拐，好，现在左拐…诸如此类，哪个效果更好？

比如，我觉得应该 API 文字进，API 文字出。但明显普通人会更喜欢通义效率那种感觉，或者PPT制作。（元宝不行，就是它还是在依赖文字）。

我们给人讲方法，但人不要的，人的反应是，你给我结果就行了，或者给我一个模板，或者，让我有信心可以用。

或者岔开说一种，当然并不是批评 Prompt 的论文，但有些论文目前阶段我是看不明白。HyDE，这个我懂，道理清晰：先问，AI回答，然后用AI回去去RAG，得到更多相关信息，然后再提问，从而得到更好的结果。CoT我们也能明白。但是，你写一篇论文，说 RE 机制，把问题给两遍，得到更好的效果（同时还证明给两遍以上效果不佳），这方法蛮好，但不值得一篇论文。



### 72

方军 2024-10-13

[苹果发文质疑：大语言模型根本无法进行逻辑推理](https://mp.weixin.qq.com/s/oSaWfp2x2xwp5bPghlpH2A)

以下是对苹果论文 AI 大纲提取（准备重点看3中对应的部分）：

[GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models](https://arxiv.org/html/2410.05229v1)

\# 大型语言模型的数学推理能力限制

\## 核心观点:大型语言模型在数学推理方面存在显著局限性

\### 1. 现有评估方法存在问题

- GSM8K基准测试存在局限性
- 引入GSM-Symbolic基准测试,生成多样化的问题变体
- 模型在不同问题实例上表现存在较大差异

\### 2. 模型推理能力脆弱

- 对数值变化更敏感,对名称变化较为稳健
- 问题难度增加时,性能下降,方差增大  
- 添加无关信息导致性能显著下降

\### 3. 模型缺乏真正的数学概念理解

- 无法忽略问题中的无关信息
- 即使提供多个相似示例也难以克服挑战
- 可能依赖于训练数据中的模式匹配,而非真正的逻辑推理

\### 4. 需要更可靠的评估方法和进一步研究

- 单点准确率指标不足以评估模型能力
- 需要探索模型推理能力的本质
- 开发具有形式推理能力的AI模型仍是一个重要挑战



### 73

方军 2024-10-14

[Welcome to State of AI Report 2024](https://www.stateof.ai/)

摘（richchat）：深度解析刚出炉的年度AI报告State of AI 2024：一篇通晓全局本文总结自Air Street Capital 在10月10日推出的《2024年 人工智能状况报告》，也附上了一些个人点评；

报告原文：Welcome to State of AI Report 2024  
附图为我用 AI 提取的大纲，仅有一个结构了，还是看这个总结比较快：

4个方面的核心发现：研究/Research
- 性能趋同： Open AI的早期领先优势正在缩小，Claude（Anthropic公司的AI助手）和Gemini（谷歌的AI模型）等模型正在迎头赶上。”在这一年的大部分时间里，基准测试和社区排行榜都指向GPT-4与其他最佳模型之间存在显著差距。然而，Claude 3.5 Sonnet、Gemini 1.5和Grok 2（特斯拉的AI模型）已经几乎消除了这一差距，模型性能现在开始趋同”；
- 开源模型的崛起： Meta的Llama系列已显著缩小了与专有模型的性能差距。”这标志着开源模型首次缩小了与闭源前沿模型的差距”。然而，关于这些模型的真正开放性存在争议；
- 模型基准测试的挑战： 数据集污染和基准测试中的错误正在影响进展评估并引发安全担忧。”研究人员越来越多地关注数据集污染问题”。”一些最流行的基准测试中存在惊人的高错误率，这可能导致我们低估了某些模型的能力，并带来安全隐患”；
- 关注推理计算： OpenAI的o1模型展示了将计算转移到推理层以解决复杂问题的潜力，但同时使用成本也显著增加；
- 多模态和新架构： 多模态模型正在获得发展动力，同时研究人员正在探索Transformer的替代方案（当然目前transformer仍是绝对主流）和混合架构，以提高效率并解决特定任务；
- 合成数据： 合成数据的使用面正在扩大，但反方强调的模型崩塌担忧仍然存在；
- 效率和端侧 AI成为焦点：随着AI模型变得越来越大且计算成本昂贵，研究重点正转向提高效率和实现端侧部署。例如以下技术都旨在减小模型规模和计算需求，同时保持性能。这对于在移动设备和资源受限环境中落地AI应用至关重要：
   - 模型压缩：减小模型大小的技术；
   - 知识蒸馏：将大型模型的”知识”转移到更小模型的方法；
   - 量化：降低模型数值精度以减少存储和计算需求；
- AI在特定 科学领域的进展： 报告强调了AI在生物学（蛋白质结构预测、药物发现、基因组编辑）、材料科学、机器人和医学领域取得的显著进展，包括医疗影像领域的合成数据生成等。展示了AI在各个科学领域的广泛应用潜力，推动了跨学科研究和创新（最新的诺贝尔物理和化学奖的颁布也是个很好的例子）；
- 规划和推理限制： 大语言模型在规划和模拟任务方面仍然存在困难，凸显了泛化和现实世界推理的局限性。最新研究正在从思维链提示、强化学习和开放性等技术方向来改进推理过程；

行业/Industry
- 英伟达的主导地位： 英伟达仍然是AI芯片市场无可争议的领导者 - 其GPU在研究论文和大规模部署中都占据主导地位。该公司快速的产品发布周期和GPU互连技术的进步进一步巩固了其地位，老黄甚至建议说“每个政府都需要建立自己的大语言模型以保护其国家遗产”… 然而，对过度依赖英伟达的担忧正促使大型科技公司探索替代 硬件解决方案（例如Google、Meta和OpenAI）；
- 竞争对手情况： AMD和英特尔等老牌竞争对手虽然在努力追赶，但显著落后于英伟达。有少数AI芯片初创公司开始获得了一定势头，例如Cerebras和Groq。与主导训练硬件市场的英伟达不同，这些初创公司主要侧重于提供推理接口和云服务，通过提供比英伟达更快、更具成本效益的解决方案来实现差异化；
- 大型 AI实验室的分化： 主要AI实验室如OpenAI、DeepMind等正经历人才流失，导致一批资金充足的新挑战者出现(如Sakana AI、H Company等)。这些新公司由知名研究人员领导，专注于特定AI领域或新型架构，显示了生态系统的深化。然而，从研究到创业的转型并非总是顺利，一些备受瞩目的项目已经遇到困难；
- AI在垂直领域的渗透： AI正在各个行业领域取得突破。法律科技终于在保守的法律行业实现规模化应用；GitHub Copilot等AI驱动的开发工具被广泛采用；自动驾驶领域Wayve和Waymo稳步推进，而Cruise则遭遇挫折。医疗保健领域，基于mRNA的个性化癌症疗法显示出潜力，AI驱动的药物发现公司也在整合壮大；
- 新兴AI技术与应用： 一些令人兴奋的新兴领域正在形成。人形机器人初创公司获得大量投资，但仍面临技术和市场挑战。语音到语音的AI取得突破性进展，展示出接近人类水平的对话能力。视频生成成为新的竞争热点，多家公司在扩大规模和提升质量。然而，一些AI驱动的消费设备(如Rabbit R1和Humane AI pin)未能达到预期，反映了将AI技术转化为实用产品的难度；
- AI伦理与法律挑战： 随着AI技术的广泛应用，版权和法律问题日益突出。模型开发者面临来自内容创作者和媒体组织的审查，但法院尚未就 AI训练中的”合理使用”提供明确指导。同时，”伪收购”趋势的出现(大型科技公司雇佣AI初创公司的核心团队而非完全收购)引发了监管机构的关注；
- AI经济学的演变： AI优先的产品开始在企业中展现出较强的用户黏性，且AI公司的收入增长速度远超传统SaaS同行。然而，许多AI公司仍在寻找可持续的盈利模式。有趣的是，报告指出购买NVIDIA股票可能比投资其AI芯片初创竞争对手更有回报…
- AI投资热潮： 2024年AI投资热潮持续，总投资额接近1000亿美元。值得注意的是出现了明显的”GPT-4前后时代”分水岭，2.5亿美元以上的大额融资占据主导。AI公司总价值飙升至接近9万亿美元，主要由少数上市公司推动。然而，IPO市场仍然停滞，并购活动也在下降，反映了监管压力和市场不确定性；

政策/Politics
- 美国AI监管动向： 拜登政府通过行政令对前沿AI模型实施了有限监管，要求使用超过10^26 FLOPS计算能力训练的模型在公开部署前向联邦政府通报并分享安全测试结果。然而，由于行政令可以被轻易撤销，其长期影响存疑。与此同时，各州开始推出自己的AI法规，其中加州的SB 1047法案最为全面但也最具争议；
- 欧盟AI法案通过： 经过密集的游说活动，欧洲议会最终通过了AI法案，成为全球首个全面AI监管框架。法案将分阶段实施，对基础模型采取分级监管。然而，美国大型科技公司在适应欧盟监管方面仍面临挑战，如Anthropic的Claude直到2024年5月才对欧洲用户开放，Meta则不向欧洲客户提供多模态模型；
- 数据收集审查： 随着模型开发者对数据需求的增加，用户数据抓取政策受到越来越多的审查。例如，Meta被迫为欧盟用户提供全球选择退出选项，而X公司停止使用欧洲用户的公开帖子进行模型训练；
- 全球 AI竞争格局： 日本政府积极推动AI创业和风投发展，希望借此重振经济。同时，随着前沿AI实验室的资本需求增加，主权财富基金开始在AI投资中发挥更大作用，引发了一些国家安全担忧；
- 公共计算能力建设： 英国、美国和欧盟都在努力增加公共计算资源供应，但与私营部门相比仍显得不足。印度政府表示愿意资助一半成本建立大规模GPU集群，只要私营伙伴愿意承担剩余成本；
- AI能源消耗问题： 大型科技公司因AI导致的能源消耗激增而面临实现净零排放承诺的挑战。同时，能源基础设施开始难以满足AI发展需求，一些国家已经开始限制数据中心建设；

安全/Safety
- AI安全态度的转变： 2024年见证了AI安全讨论的显著转变。从2023年的”AI是危险的”论调，转向了2024年的”请使用我的AI应用”。OpenAI的宫斗剧标志着对”存在风险”论调的反弹开始。尽管如此，各国政府仍在积极推进AI安全治理，如英国成立了世界首个AI安全研究所(AISI)，美国、日本和加拿大也相继跟进；
- AI安全研究的新焦点： 研究人员对AI系统的”越狱”(jailbreaking)攻击给予了更多关注。尽管主要实验室加大了对抗这类攻击的研究力度，但红队测试仍然屡屡成功突破防线。研究还指出了更隐蔽的攻击可能性，如通过污染RLHF(基于人类反馈的强化学习)使用的偏好数据来操纵模型；
- 对齐(Alignment)技术的进展与局限： 直接偏好优化(DPO)作为RLHF的替代方案受到关注，但研究表明它可能面临类似的”过度优化”问题。同时，RLHF由于其在线学习的优势，短期内仍难以被完全取代。研究人员正在探索结合两者优点的新方法，如来自 AI反馈的直接对齐(DAAF)；
- AI可解释性的突破： Anthropic利用稀疏自编码器(SAE)成功分解了Claude 3 Sonnet的激活，实现了对模型内部表征的解释。OpenAI随后改进了SAE的方法，使其可以扩展到更大规模。这些进展为”打开AI黑箱”提供了新的可能性，但同时也引发了对这种可解释性可能被滥用的担忧；
- 生物风险与AI： 尽管Anthropic此前的研究引发了对LLM可能加速生物威胁的担忧，但其他实验室难以复现这一结果。然而，研究人员指出，相比LLM，专门的生物设计工具（例如蛋白质折叠/设计和基因修改）可能构成更直接的风险；
- AI滥用的现实威胁： Google DeepMind的研究强调，大多数AI误用案例并非来自于复杂的技术攻击，而是利用了容易获取的生成式AI功能。这包括利用深度伪造技术进行诈骗、骚扰和制作色情内容等；



### 74

方军 2024-10-14


如果这个图是真的，那语音产品就有意思了

[Voice-first，闭关做一款语音产品的思考 | BestBlogs](https://www.bestblogs.dev/article/30d73a)

这篇文章里面配的图：语音交互，或许不仅仅是音频
视频对比文字和音频，毫无疑问是信息传递效率最高的信息媒介。人们在看完视频后会记得 70% 的信息，而单纯看图片记忆的信息之后 30%，在听完一段音频后会记得 20% 的信息。语音交互或许并不意味着内容模态一定为音频，视频同样可以做为信息模态，通过音频可视化的方式辅助呈现音频内容，以提高信息传播效率。

当然，我是存疑的。


### 75

方军 2024-10-14

这个老师最后的吐槽有点意思，某些机构用AI做答疑，“已读乱回”。

为了完整，我摘取全部，前面与AI关系不大：

摘：如果一个班可以不断地招生，不断地进人，那么是不是意味着：这个班的口碑特别好？质量高？从某种程度来说：是的。

但是从另一个角度来说：可以不断进人，就意味着教学服务毫无压力。比如说，市面上很多中小学的课程几千元，然后成千上万的学生家长报名——但是针对我最近的那个雅思写作班来说，人数到了30人，就已经逼到我的服务极限了。

说起来，服务大家都有，就是答疑嘛，班群管理嘛。但是我那个服务，是精准一对一的答疑，学生提交作业为100%（顶多有个别同学是过期交），然后我非常细致回复，有的作业因为学生问题特别多，我回复了将近三千字。

可能正是因为这样的交付质量，学生就陆续来报名要求加座了。如果放在传统的营销模式，每加一个学生，就是多一份利润，但是放在我身上：每加一个学生就是多了一份巨大的工作量。所以，我是使用厚重的服务逼迫自己停止继续招生。本质上，我是重教学的。（根本受不了，不能再进人了）

至于说很多招生数量巨大的班级产品，也没啥作业批改，都是等着学生自己有问题来答疑。问题在于，基础弱的学生是提不出问题的。此外，无非都是利用AI答疑，已读乱回的那种。小红书我是看到一堆这种。
收起

查看详情
方军：这个老师不少观察很深入：

美国这边对于实习教师的要求，是尽量减少教师的说话时间。道理其实很简单，老师在那自顾自地发挥，学生听了也就是听力。需要学生自主发声、表达无论对错与否的观点，然后教师协助其进步就行了。

其实，除了英语教学以外，在大学里的研究生课程，更是“可怕”：有的课上，教授让大家做了一整节课的作业，教授几乎没说啥话。（当然整堂课的讨论，也是需要精心设计的，与实践相结合，讨论的内容马上就会在实践中用到。）

上述情况放在国内，坦率地说：很多学生是无法接受这个观念的。

春季的时候有一次，我在课上仅仅是让一个学生花了一分钟读了一段话，然后给她鼓励了一下，课后评价就冒出来“不要点学生在那朗读”。——除了考研行业以外，我的一些雅思同行也有类似的遭遇：老师们经历了优秀的教学法（如，剑桥系列培训），然后在课上调动学生互动的发言，也被有些学生反对。（这个比较讽刺：雅思口语课不可以点学生发言，只需要听老师在那里炫技）。

黑色幽默的反例也是有的：北京顺义有一些托福补习班。有的孩子厌学，但是老师为了赚那点课时费，就一对一的哇啦哇啦讲一通，反正你也不愿学是吧，然后我讲完之后拿钱走人。

偶尔有一个亮点：有一次一个学生给我留言，说她不能跟直播，但是在回放中又看到我在鼓励一个学生，让其朗读，她看了回放十分感动，觉得我在帮助学生走出困境。

但总的来说，那些落后的教学方式，我估计依然会在国内存活很久。“我花学费不是让我来努力的，是让老师来努力的。”

如果你能理解为健身私教课，就好理解多了。
2024-10-14 13:20



### 76

方军 2024-10-14

摘要、大纲这些功能都真已经产品化了，但我还是觉得产品化早了一点

这是一个叫语鲸的，我偶尔用通义效率。

就大纲提取而言，这些都不如如下提示语：

read thoroughly and write an outline(following the Minto Pyramid principle) in **Chinese** using original words. Return in markdown:



### 77

方军 2024-10-14


Sam Altman	@sama·2023年3月3日	

人们写下要点，让ChatGPT将其扩展成一封礼貌的电子邮件，然后发送出去，而接收者又使用ChatGPT将其浓缩成关键要点，这种做法很讽刺。

Paul Graham @paulg

这是任何徒有其表的组织中沟通的默认做法。发送者用一堆套话来扩充他的信息，然后接收者不得不从结果中提取原始信息。


### 78

方军 2024-10-14

前几天看 Ilya Sutskever 和黄仁勋聊天，他短短 44 秒，把预测下一个词为什么带来推理，讲得特别清晰易懂。

Ilya Sutskever had a conversation last year with Jensen Huang but still, that made me rethink the idea of 'Predicting the Next Word'

其中个别词是黄仁勋的对话。

I'd like to take a small detour and to give an analogy that will hopefully clarify why more accurate prediction of the next word leads to more understanding, real understanding. Let's consider an example. Say you read a detective novel. It's like a complicated plot, a storyline, different characters, lots of events, mysteries like clues. It's unclear. Then let's say that at the last page of the book, the detective has gathered all the clues, gathered all the people and saying, okay I'm going to reveal the identity of whoever committed the crime. And that person's name is predict that word. Predict that word exactly. Goodness, right, right now. 

我想稍微岔开话题，给大家举个例子，希望能说明为什么更准确地预测下一个词会带来更多的理解，真正的理解。让我们想象一下，你在读一本侦探小说。它有着复杂的情节、曲折的故事线、各种各样的人物、众多的事件，还有许多神秘的线索。一切都扑朔迷离。然后假设到了书的最后一页，侦探已经搜集了所有的线索，把所有人都召集到一起，说道：「好了，我现在要揭露犯罪者的身份。」而那个人的名字就是 —— 此刻你要准确地预测出这个词。天哪，想想看，对吧？

[(9) X 上的 Haider.：“Ilya Sutskever had a conversation last year with Jensen Huang but still, that made me rethink the idea of 'Predicting the Next Word' Listen to what Ilya said on this. https://t.co/wSWCLKzfXn” / X](https://x.com/slow_developer/status/1844728830986174930)

### 79

方军 2024-10-14

我虽然还用Kimi，介绍没法用国外产品的人也多数仍推荐它，但我对kimi印象已经很糟糕了，昨天有点被它在B站持续出现的、低级的、忽悠性质过强的广告惹恼了。

摘：Kimi 居然更新了语音通话模式！

今天突然发现我的 Kimi 上多了一个按钮，点了一下发现是语音通话功能，最近集中发货啊。

试了一下效果还挺好的：

最好的一个设计是可以在语音界面展示字幕；
支持打断模式；
支持更换声音；
支持语速调节；

另外还有独特的情景模式：
一个是英语陪练，可以单词跟读语法纠错和话题口语练习；
另一个是模拟面试，可以挖掘你的简历模拟面试场景。

还支持声音克隆，克隆的声音也能在语音通话里使用，我也克隆了自己的，可以在下面领取。



### 80

方军 2024-10-14

这句话，放在AI场景很有意思：

你所表达的东西，就是你所知道的东西，你表达不出来的东西，你不可能知道。
查看详情
下山雨、wulujia 觉得很赞
wulujia：特别想解决"我不知道我不知道"的问题
2024-10-14 22:38
方军 回复 wulujia：刚刚看 Ilya 讨论 AGI 的一个片段，他说了一个不错的策略：

在这样的情况下，某某人会看到什么呢？

这个人可能不存在。

他就说这么几句，但好像就可以一定程度上回应你的问题：

这个人就有可能看到“我不知道我不知道的”的东西。
2024-10-14 22:42
wulujia 回复 方军：是的，这也是我的计划。
2024-10-15 08:10




### 81

方军 2024-10-14

前几日说 LLM 不能推理的那个例子，被解决了，就用提示语，牛啊

···
create a function "invert(tree)"
tree is an array of size 2^n that represents a binary tree
the key to each node is the index
the invert function should return a new tree where the keys are inverted bitwise
for example the key 1 in binary is 0001 so it should be 1000 in binary and 8 in decimal

To create the invert(tree) function that inverts the keys of a binary tree represented as an array, we can follow these steps:
1. Determine the size of the tree.
2. For each index in the tree, calculate the inverted key by performing a bitwise NOT operation.
3. Store the inverted keys in a new array and return it.
Here's the implementation of the invert function:
Explanation:
The ~i operation inverts the bits of the index i.
The & (n - 1) operation ensures that the inverted index wraps around within the bounds of the array size.
The new tree is populated with the values from the original tree based on the inverted indices.
You can use this function by passing an array that represents your binary tree.
···

[(9) X 上的 high\_byte：“@VictorTaelin $10k plz https://t.co/G45Fu9u6T5” / X](https://x.com/high_byte/status/1845847610130649126)

### 82

方军 2024-10-14

有了 AI  大纲提取之后，的确多看了很多信息，但又反思，这些信息是没必要的。得再次回到一种平衡。我蛮熟悉Wordpress使用的，但已经不用它很多年了，现在如果要网站多半用静态页面生成器，比如github pages（jekyll）、 vitepress 这些，公司商业用途面向国外我比较推荐 webflow （美感好、模板多），个人博客嘛，我觉得完全不需要自建站。

[半生心血贡献给开源，WordPress 之父分叉 20 万行代码报复吸血企业，DHH：别发疯](https://mp.weixin.qq.com/s/z6vtmZAqvDYbVKyKYAgBKA)

### 83

方军 2024-10-15


最近又觉得，模型能力比去年初强大之后，提示语（prompt）又变得重要了，可以轻松干很多事。

这也源自于现在模型的function call、长上下文、推理能力。同时，去年很多必要的技巧现在不需要了。也许应该继续多多探索这个。

去年初重视提示语，和现在重视提示语的逻辑是有很大差别的。当然，我觉得基本的原则没变。我认为仅关注各种工具不太行，LLM本身是个黑盒子，工具又是一层盒子，工具也经常过于通用，叠加起来闭眼乱答。
收起

查看详情
Koant、下山雨 觉得很赞
不努力的梦想：现在也不像那个时候各种质量的structure prompt横飞，现在反而更能体会到一个真正的可贵prompt有多强大
2024-10-15 17:12
方军 回复 不努力的梦想：是的
2024-10-15 17:48
方军 回复 不努力的梦想：那个时候的各种所谓结构化提示语，只是表面上看起来结构化，但都很少有跑eval，有一定的评估的。
2024-10-15 17:49
方军：《成为提问工程师》中尤为基础的第三章，我现在再看还是很棒的，就朴实地谈了三个场景：

AI 辅助翻译
AI 辅助写作
AI 辅助学习

我稍后分享下电子版吧。
2024-10-16 01:06


### 84

方军 2024-10-15

AlphaCodium能够提升OpenAI o1模型在解决编程问题上的表现，推动AI模型向更深层次的系统2思维迈进

AlphaCodium Outperforms Direct Prompting of o1 Mod...

elvis:  这是我看到的第一份报告，其中现成的OpenAI o1 CoT（思维链）推理在代码生成方面的表现被超越。

他们提出了AlphaCodium，它作为一个策略提供者（即流程工程）构建在o1之上，旨在激发和引导o1的思维链能力。

AlphaCodium被设计为一个多阶段流程，改进了推理能力和可靠性，同时显著提升了o1-preview的性能（在Codeforces基准测试中，通过率@5（即在前5次尝试中通过的比率）从55%提高到78%）。

作者指出："AlphaCodium的潜力是显而易见的：通过适当的策略性流程工程，像o1这样的基础模型可以被引导towards系统II思维。我们仍需努力跨越从'系统1.5'到真正的系统2级AI的鸿沟，但通过观察像AlphaCodium这样的工具，我们可以更好地理解这个差距，并继续研究以缩小它。"

o1是一个比当今大多数大语言模型（LLM）都要优秀得多的模型。然而，正如这份报告所示，它仍可以从战略指导中获益。我也正在为知识密集型任务开发类似的方法。根据我自己的分析，o1在复杂任务的知识掌握方面确实表现更佳，但在复杂知识理解和推理方面仍然存在局限性。关于这一点，我很快会有更深入的探讨。

图的解释来自 AI 对图片的直接解读，有调整，它没懂右边顺序：

第一部分
   - 从输入问题描述和公开测试开始 (Input - Problem Description + Public Tests)
   - 进行问题反思 (Problem Reflection)
   - 公开测试推理 (Public Test Reasoning)
   - 然后生成可能的解决方案 (Generate Possible Solutions)
   - 对这些解决方案进行排名 (Rank Solutions)
   - 并生成额外的AI测试 (Generate Additional AI Tests)

第二部分
   - 输入问题描述和公开测试 (Input - Problem Description + Public Tests)
   - 对公开测试进行迭代 (Iterate on Public Tests)
   - 对AI测试进行迭代 (Iterate on AI Tests)
   - 最后再次生成可能的解决方案 (Generate Possible Solutions)


### 85

方军 2024-10-15

星球里面的朋友啊，我真心推荐  Zed 编辑器

就免费 Claude 这一条，大家就该用啊，我不知道为什么推销它特别不成功

1. 它现在几乎有完全免费的 Claude 用，也可以自带各种模型

2. 在编辑器侧栏用 AI 太爽了，远远超过网页（自然体验也是超过命令行的）

3. 可以方便地管理  prompt library

4. 也可以方便地贴入图片进行处理

5. 在文本编辑内也可以用，可以 tab 出内容（我不用，但在我连接 Github copilot 期间是可以的）

Zed - The editor for what's next

它也可以方便地与 Obsidian 联合使用，简单来说，两个都是基于文件的，你在 zed 里面打开文件夹就可以了。

编程我不用 Zed，目前还是 VS Code 为主，偶尔 Cursor



### 86

方军 2024-10-15

我倾向于认为 NotebookLM 被过誉了

阿里通义（tongyi.ailiyun.com）比它好，不过没办法，这是中国公司的不足，除了字节的tiktok之外，很少有产品在一开始就能参与全球竞争

附注：这样的内容我是懒得看原文的，和 Cursor 那个四个创始人参与 Lex Fridman 必须细看视频，对待的态度差别真是很大。

[NotebookLM核心负责人访谈： 项目不到 10个人，体验惊艳全球，但它还只是个技术demo](https://mp.weixin.qq.com/s/oMPdXhFckUVUYLK1nJtxBQ?poc_token=HFEyE2ejOgWnz_EwRKCl47RHN2VfCb8yPtVFogMc)

### 87

方军 2024-10-16

这个有创新性，很久没看到这么牛的了，终于看到多模态的作用。摘：把任何书本上的图表、公式变成互动实验

物理知识轻松掌握！

能让普通物理教材中的静态图表变成互动的、动态的模拟器，让你可以动手操作，甚至实时看到物理现象的变化。

不需要编写代码，只需点击几下，就可以自己“动手”做实验！

Augmented Physics 可以将静态图表（如光学、运动学、摆、电路等）变成可以操作的动态模拟实验。比如，你可以调整镜片位置，看看光线如何变化。

这款工具的核心功能包括：

-自动提取课本中的物理图表，让你轻松从PDF教材中获取需要的图表。

-生成交互式模拟，你可以像做实验一样调整图表中的物体和参数，观察变化。

-动态可视化数据，比如让摆动的物体展示角度随时间的变化，或者看到电路中电流和电压的变化。

你还可以拖动、调整图表中的元素（如镜片、物体位置等），观察实时反馈。

也可以通过修改图表中的数值来动态调整物理系统。

论文：[2405.18614] Augmented Physics: Creating Interacti...

[[2405.18614] Augmented Physics: Creating Interactive and Embedded Physics Simulations from Static Textbook Diagrams](https://arxiv.org/abs/2405.18614)

Augmented Physics：增强现实你的物理课本 让你的物理课本上的图表动起来 – Xiao...

[Augmented Physics：增强现实你的物理课本 让你的物理课本上的图表动起来 – XiaoHu.AI学院](https://xiaohu.ai/p/14645)


### 88

方军 2024-10-16

LLM不会推理——1万美金悬赏下，o1在内所有模型均无法反转二叉树？！
方老师，你怎么看？LLM不会推理——1万美金悬赏下，o1在内所有模型均无法反转二叉树？！
查看详情
方军：昨天说有人实现了

前几日说LLM不能推理的那个例...

我还没细看
2024-10-16 10:20
乘风 回复 方军：Taelin回复说并没有解决，因为要求不能使用循环，违规了
2024-10-16 10:51
方军 回复 乘风：哦哦：）
2024-10-16 10:59
乘风 回复 方军：我在想，大模型到底会不会基本的、严密的逻辑推理，如果不能，难道都是概率解或者别人极端推测的模式解吗？
2024-10-16 11:18
方军 回复 乘风：这是一个没有定论的

从原理看，大模型的确是模仿

从效果看，它能推理

这个时候，说它不能推理？好像不对

说它能推理，也不对

从实用角度来将，它当然能推理，我选择这个实用立场
2024-10-16 11:33
乘风 回复 方军：是的，我的观察跟你完全相同。从大模型原理来看就是神经网络，是压缩算法，是预测下一个token，是不能进行严密的逻辑符号推理的。可是部分人类为什么可以进行严密的符号推理呢？神经网络进步到极致难道也不能进行符号推理吗？
2024-10-16 11:53

[知识星球是创作者连接铁杆粉丝，实现知识变现的工具。任何从事创作或艺术的人，例如艺术家、工匠、教师、学术研究、科普等，只要能获得一千位铁杆粉丝，就足够生计无忧，自由创作。社群管理、内容沉淀、链接粉丝等就在知识星球。-知识星球](https://wx.zsxq.com/group/15552458112512/topic/8858281128855152)


### 89

方军 2024-10-16


闲聊几句，我觉得在工作学习时，有了 AI 之后，助力非常大

最近在想，其实最有效的学习方法，也是做事方法，是 elaboration（详细阐述）。在认知天性里面看到这个词，大意是用自己的话详细讲述。我认为，是拆解后，详细讲述；也可以是撇出掉不重要的部分，留下重要的部分后，再详细讲述；也可以是对某个重要部分进一步拆分后，详细讲述。

那么，在这个过程中，AI就可以帮大忙。这儿，我们一定要自己讲述吗？不一定啊，自己用脚走路是慢的，开车是快的。拆解完之后，让 AI 尝试着讲一个，我们来判断它讲得对不对？如何把它的表述修改得更好？当然，我们同样可以再讲一遍。

elaboration （详细阐述）的过程中，我还常会用图。这是因为我觉得，如果已经把它缩减到三四个元素，画个图表达一下它们之间的关系，会理解得更深入。

有意思的，也许是总是很快速地学习，我发现偶尔会有这样的情况，拆解到最后时，会发现两个元素之间的逻辑关系自己混淆了。比如说，一个正确的逻辑应该是先 Builder，再 Proposer，但由于缩写词是PBS，虽然我清晰地知道先后顺序，但还是会偶尔说混。但只要画了图，就可以记忆、理解更牢靠了。

在这种情况下如何用好 AI 呢？为了避免自己的误解被 AI 扩大，我通常会附加一个资料作为上下文，然后请 AI 解释，而不是让它扩展我的解释。通常，AI 会敏锐地发现我的那句话和上下文之间的不同，然后它一般都能以正确的顺序表达出来。


### 90

方军 2024-10-16

今天有人发布新产品，关于 AI 写作的。

摘些网友讨论，我并不是很认同用 AI 写作，应该说不认同泛泛的，它如果深入到具体场景，比如客服邮件回复、语法校对、书面文字口语化、润色、口述整理与书面化、律师记录/其他记录等等，那还是有很多可用的地方的。

和写作有关的其他流程，比如为写作搜集资料，我也不建议AI。怎么用 AI 来辅助写作，这涉及到怎么认识「写作」这个问题：

- 为什么要写文字
- 如何写文字
- 如何改文字

我还有一种不受欢迎的观点，正好最近也看到，就是说，用 AI 在自己的笔记里面产生新点子。这的确是卡片写作法里面提及的一种思路，但让 AI 在这里面来产生联系、产生火花，我觉得很愚蠢，你的脑子是干什么的，如果愚蠢到相信这种外部的联系，那这脑子也的确没用了，别干这些要脑子的事了。

---

📕Tom Huang: 深入实践 LLM 产品开发半年，目前产品已经开始内测，聊一聊 10 条行业观察：

1. ChatGPT Canvas 发布编码和写作两个场景，编码有 Cursor，写作具备独立产品的机会

2. 写作相比编码更普世也更难，Cursor + ChatGPT Canvas + NotebookLM 的结合可能带来更大的产品化学效应

3. Cursor 最核心主要有两个要素：1）用户自行定制内容上下文的 Human-in-the-loop 的交互设计 2）Claude 3.5 Sonnet 编码能力太强太出圈，基本上是在「有限难度下的最佳效果」

4. Cursor 类编码任务是收敛的，但写作是泛目标任务，同时受众人群也很广，这就很考验产品设计能力 

技术趋势：

5. 专业人员构建多个 Bot + 调优用于消费的产品已经成熟，并且有开源成功案例，比如 @dify_ai 、 @FlowiseAI 等 

6. 多模态+工具链的成熟，解锁了 LLM 将任意输入内容（通常长且复杂）转为通熟易懂、图文并茂甚至音视频结合的方式，降低了消费门槛，NotebookLM 出圈是一个典范案例 

7. 随着 LLM 能力增强，80% 基础场景无需像之前由专业人员构建很多Bot并调优再使用，现在可能就是一个 Bot + 用户自由选择内容而+自定义内容格式+适配内容格式的端 
市场分析：

8. 单 Bot + 用户自由选择内容 + 定制内容格式的产品目前有 NotebookLM 等，其实水下还有不少产品，后面可以聊聊，但是 NotebookLM 是一款技术向的实验产品，而且目前并无开源平替

9. ChatGPT Canvas 虽然强，但是 LLM 自由写作通常收益较低，结合领域知识才能更好的发挥 

10. Cursor 的领域知识选择 + ChatGPT Canvas 的 AI 写作交互 + NotebookLM 的促成内容消费格式或模态的转换，这里面有端到端的产品机会

而我们正在内测的产品正在朝着这个目标前进🫶 

这里再挖一下之前宝玉老师关于 Cursor 和写作产品的评价 @dotey

---

📕 宝玉之前的讨论：大厂与其山寨 Cursor，不如做个好用的 AI 邮件客户端

宝玉现在说：我用 OpenAI 的 Canvas 比较多，相对不错了

大厂与其山寨 Cursor，不如做个好用的 AI 邮件客户端 | 宝玉的分享

大厂抄 Cursor，这样追在别人屁股后面跑是没有前途的，AI 代码编辑器已经是红海了，就算大厂又如何，微软比 Cursor 大多少？结果 GitHub Copilot 也没打过 Cursor，大厂还不如多投资几家像 Cursor 这样的公司，为什么非要抄他们呢！

程序员这个群体大家都知道，又不愿意花钱又没忠诚度，Cursor 好用马上都退订 Copilot，能白嫖绝对不花那$20 的订阅费，大厂不如多看看普通用户的需求。

普通用户需要的不是 Cursor，是能帮助沟通和写作的 AI 编辑器，比如写邮件、回短信。但是有好用的吗？没有！唯一可以看到的期货是苹果的 Apple Intelligence。

\## 普通人的写作需求是什么？

普通人日常的写作分三种：日常沟通、公文和创作。

**日常沟通**

日常沟通协作就是各种日常的邮件，短信、微信、Slack 等等，这类写作尤其是邮件，套话很多，特别适合用 AI 生成。我日常写稍微长一点的邮件基本都是 GPT 帮我完成了，给出要点和充足上下文，生成的又快又好，稍微改一下就可以用。

**公文类写作**

公文类就是各种报告、总结、文档等等，这种公文套话多，格式固定，但是费时费力，现在绝大部分公文都可以用 AI 帮助协作了。

而且同类型的公文，比如文档，以前历史的文档都可以重用，大语言模型尤其擅长模仿写作风格或者内容结构。结合 RAG（检索增强生成）这样的技术，写新的内容之前把以前写过的相关内容找出来，类似于 Cursor 那样帮你预先生成，大部分时候可能一路 Tab 就好了。

**创作类写作**

创作类又可以细分，一类是二次创作，比如翻译、书评等；一类是原创的创作，比如写论文、写小说还有像这篇这样的原创博客。

二次创作像翻译这种创作，如果结合 AI 其实可以效果更好，比如 AI 先翻译一遍，局部不对的，类似 Cursor 那样，调出对话框，告诉它如何改进，比如先解释一下、去搜索一些外部资料补充，再次生成结果就好很多，但是不需要手动去复制、搜索引擎搜索、筛选、重写等等。

至于原创，我个人是不依赖于 AI 写作的，从来没有让我满意过，我更喜欢一点一点将模糊的想法形成文字，并不断修改成型，AI 的自动完成甚至对我是一种干扰。但写完后借助 AI 帮我改改错别字、润色一下还是可以的。

\## AI 写作工具的挑战是什么？

相信我上面列出的几类写作需求也同样是大多数人所需要的，像代码编辑器，GitHub Copilot、Cursor 这样的好工具层出不穷，而给普通人写作的 AI 辅助工具，却没有看到什么好用的，这里面确实有很多挑战！

**私有数据的获取**

要想让大语言模型生成好的结果，一定要有充足的上下文，这就意味着要获取你的私有数据，而普通人写作时的数据，很多都涉及隐私，相当敏感。没有人希望自己的私密聊天记录和通信记录发送到服务器，公司相关的邮件更是如此。另外像微信、Slack 这样的通信工具的数据，本身也是没有公开 API 可以获取的，通过其他手段可能会有些麻烦。

**模型的能力**

苹果在演示 Apple Intelligence 中的智能邮件回复时，效果很惊艳，但是它用的是本机小参数模型，如果不能接入 GPT-4o、Claude 3.5 这样的大参数优秀的语言模型来做这个任务的话，我不觉得效果会有多好，毕竟模型的能力才真正决定了最终生成的效果。

包括现在开源的大语言模型，要想在本机运行，大一点参数的模型根本运行不起来，小一点参数的效果又不好，这也是制约之类 AI 写作工具的一大瓶颈。

**交互体验**

GitHub Copilot 和 Cursor 的成功，很大一部分程度上归功于其交互体验，根据当前你写代码的位置，智能的给出提示，随时唤起对话框输入提示词个性化的完成任务。但是代码相对来说确定性更强，有固定的语法结构和最优算法解，还有无数历史代码参考，通常一个上下文内，只有有限的最优解，所以可以给出精准的提示。而对于写作，完全是发散式的，可能性太多，极难预测，同样的交互也许就不一定适合普通写作。

**技术挑战**

很多做过或者了解 RAG 的都知道，现在 AI 搜索，看起来技术不复杂，但是做好其实极难，根据用户的输入找出贴切的上下文是极难的事情。要做好 AI 写作，难度不会比 AI 搜索更小，因为本质就是先根据你当前输入的内容，去做 AI 搜索，找出以前相关的内容，甚至要去搜索外网相关的内容，再结合输入位置前后的内容和你的要求帮你写作。

当然还有很多其他挑战，我也无法一一列举。

\## 下一个 AI 写作工具的机会在哪里？

我以为下一个 AI 写作工具的突破可能首先会是邮件客户端，邮件写作是高频需求，整理邮件也是一大痛点，相对来说邮件的数据也容易拿到，用户只要安装了客户端，绑定邮件账号，就可以在用户的允许下拿到用户的所有邮件数据，并且可以结构化的整理邮件数据，比如和某个人、某个组之间的所有对话，比如某一类对话。

如果有信的过的邮件客户端，能帮我连接 GPT-4o 和 Claude 3.5 这样的 API，能根据我需求智能撰写回复邮件，能根据我需求整理邮件清理垃圾邮件，对我的生产力会是很大提升。

AI 邮件客户端之后，可能会是公文写作，帮助你把历史内容都做好索引，学习你的写作风格和文章结构，根据你采纳建议的反馈不断完善模型。

专业翻译类的 AI 工具，是值得好好做的，书籍的翻译、文章的翻译、字幕的翻译，都是可以借助 AI 大幅提升生产力的地方，好的翻译工具，效率的提升可能是数倍记的。

在 GitHub Copilot 之前，我没想到 AI 可以这样辅助编程，再到 Cursor，我也没想到交互还可以进一步进化到这样方便的程度。所以对于 AI 写作工具也是类似的，我不觉得 Cursor 就是天花板，未来一定有超出我想象的更好的交互形式出现，可能唯一限制我们的就是我们的想象力吧。

期待大厂能做出适合普通人的好用的引领未来的 AI 编辑器，而不是去山寨一个 Cursor 出来！相比而言，我更看好小团队或者个人，他们比大厂更有机会开发出像 Cursor 这样吊打大厂们的 AI 工具。

---

📕 Winnerineas（不同意见）

写作本质上是思想的符号化，也是一个garbage in garbage out的过程，和工具本身关系不是那么的大。所谓好的工具也不过就是解决以下几个问题：

1. 不离开写作页面进行信息的检索和确认。

2. 提示符合语法或者文法的表达方式。

3. 可视化逻辑思维链条或者故事线。

4. 检查潜在的逻辑错误，循环论证等等。
最多能够超出作者认知的就是根据所谓符号相关性展示给作者她/他没有认知的信息，刺激和提示作者进一步的写作。

---

📕 meng shao：帮转！期待看到完成度更高的 AI 写作工具。

目前能看到的 AI 写作工具, 要么是 AI + 写作, 要么是写作 + AI, 不过两种形态都没有实现的很理想。即使抛开交互模式不谈, 只看能产生的最终结果也是不够理想的。

- AI + 写作

通用 AI 产品中兼顾写作, 写作只是 AI 产品能力的一部分, 所以不会有特殊的功能逻辑, 需要使用时给定很多前提和提示, 反复问答后输出中间态, 人再介入完成修改和后续步骤。即使有针对某些特定行业写作的设定, 通常也是 Prompt 中对身份和目标的简单设定, 不够深入。

- 写作 + AI

传统的写作类工具, 结合 AI 的方式通常会流于 "Canva AI" 化, 该有的能力我都有, 通过改写、润色、续写等给用户提供很多很多的选择, 但一方面太依赖用户自己的判断和选择, 一方面基本都是 LLM + Prompt, 对文章本身的帮助有限。


[大厂与其山寨 Cursor，不如做个好用的 AI 邮件客户端 | 宝玉的分享](https://baoyu.io/blog/ai/big-companies-instead-of-copying-cursor-should-make-ai-email-client)

### 91

方军 2024-10-16

提示卡101 AI提取大纲：抽取文章整体结构

说明：向AI提问图卡开启，第一个是101（有意从101开始编号）。我发现，在把文字图示化的过程中，一方面我会受限而不得不缩减文字，另一方面我会不断地修订这个文字。总体而言，形式优化了文字。

这个提示语我之前分析有提了六个要求：1）仔细阅读；2）编写大纲；3）明托金字塔大纲；4）用原文词语；5）中文回答，并用****加重这一点；6）Markdown格式返回。

---

当你阅读一篇长文时，是否会一下子把握不住它的整体结构，而不能有效读懂关键信息呢？

你可以让 AI 预读全文，返回一个遵循*麦肯锡明托金字塔结构*的大纲。大纲将文章的信息架构与内容板块呈现在你的面前，成为你进一步阅读的辅助。

下为中英文版提示语，推荐直接用英文版。为便于使用，英文版提示语明确要求始终用中文回答。

```
Read thoroughly and write an outline(following the Minto Pyramid principle) in **Chinese** using original words. Return in markdown:

仔细阅读，然后编写大纲。大纲应遵循金字塔原理，并用原文词语。以 Markdown 格式返回：
```

图卡字体是否加粗一点（由300->400），还要再斟酌下。请问你喜欢如下两个里面的哪个？


### 92

方军 2024-10-16

教授讲的东西，看不懂

[【曾鸣演讲全文】我们正迎来AGI的雅虎时刻](https://mp.weixin.qq.com/s/0VTyOPwZaXVpCsj0IeyDVw)

### 93

方军 2024-10-17

[Yann LeCun最新万字演讲：致力于下一代AI系统，我们基本上不做LLM了](https://mp.weixin.qq.com/s/vfiMTB3X7qj6gHmZ1c5ehQ)

杨立昆有他的优势，但他这一年多对 LLM 的批评，真是觉得有点像赌气。

### 94

方军 2024-10-17

大纲提示语把 Paul Graham  的精彩文章整理得个乱七八糟

不过，这其实是合理的。当我们看完一篇文章，我们写心得时，通常写下来也是这些。这么看，AI 读得比我们好。

[Life is Short](https://paulgraham.com/vb.html)

原文很好，记得读原文。

前一段还看了一本书，人生四千周，蛮好的，但其实就是 Paul Graham 一篇文章的事。

If you ask yourself what you spend your time on that's bullshit, you probably already know the answer. Unnecessary meetings, pointless disputes, bureaucracy, posturing, dealing with other people's mistakes, traffic jams, addictive but unrewarding pastimes.
如果你问问自己把时间花在哪些胡说八道的事情上，你可能已经知道答案了。不必要的会议、无意义的争论、官僚作风、装腔作势、处理别人的错误、交通堵塞、使人上瘾但无回报的消遣。

乘风：我感觉总结的挺好 只是感觉这种总结看一眼就不想看原文了 全是逻辑正确的废话 原文就比较触动读者 而且会引发思考 所以遇见大神还是要亲自阅读的 哪怕是真人来总结也一样会丢失很多东西
2024-10-17 20:18
方军 回复 乘风：对的，其实得到已经很努力做图书解读、质量也很高，但其实也是很不行的。
2024-10-17 20:21
乘风 回复 方军：是的 基本上是专业水准了 但是有些好书还是要亲自读的
2024-10-17 20:45
希瑞：看原文的体验就像是两个音叉产生共振，只看大纲的体验是只看了个叉…大纲丢失了太多情境的信息，只留下了命题。
2024-10-17 21:09
方军 回复 希瑞：是的，所以也反过来说明一个道理，各种总结、笔记、干货，其实都是有问题的
2024-10-17 22:10



### 95

方军 2024-10-17

神奇，各种关于notebookLM的讨论与畅想

[NotebookLM 是 Google 的 ChatGPT 时刻吗？](https://mp.weixin.qq.com/s/EUhHcekY4vMN0HH2_7_eqA)

### 96

方军 2024-10-18

看 Wes Kao （maven co-founder）说的，感慨，基础沟通能力真是个稀缺的能力啊

我看各种人向 AI 提问，极好地反映了他们表达能力之弱

Managing up 101: Make it insanely easy to give you feedback.

One of my direct reports sent this Slack DM and it's a masterclass in simple, direct communication.

No guessing where to find docs.

No follow-up questions on timing.

No confusion about priority levels.

She made it easy--and in less than 1 hour, I was able to provide feedback, give approval, and remove myself as the bottleneck for her projects.

Make it easy for people to give you what you want.

向上管理 101：让别人给你反馈变得极其容易。

我的一位直接下属发了这条 Slack 私信，这是简单、直接沟通的典范。

无需猜测在哪里找到文档。

关于时间没有后续问题。

关于优先级没有混淆。

她让这变得容易——而且在不到 1 小时内，我就能提供反馈、给予批准，并让自己不再是她项目的瓶颈。

让人们容易给你你想要的。



### 97

方军 2024-10-18

我发现，专业的文字，AI还是差距非常大，AI基本上能做到很好的是提供一种供理解的解释。

比如对比下如下专业人士的解读：

对SFISF的几点技术讨论（Degg）

一些朋友让我写写央行新成立的债券、基金、保险互换便利（SFISF）。

9月24号潘行长在发布会上宣布成立该工具，它本质上是允许非银拿着股票做抵押，找央行借国债或央票，然后非银可以拿着这些高等级抵押品从银行间市场以质押融资等方式借钱，从而继续增持股票。换句话说，它是央行刺激非银加杠杆买股票的货币政策工具，目的是“提升金融机构的资金获取能力和股票增持能力”。我们此前讨论了这一工具对央行、非银和银行T表带来的变化。

市场似乎对该工具的效果有比较高的期待，一些消息也显示券商自营——特别是权益OCI账户——正在踊跃申报该工具。这类账户会把股票划入其他权益工具，从而使当期损益不受股票市值波动影响，而只受所持票息与负债息差影响。因此它们特别喜欢高股息票。如果SFISF的综合成本能够显著低于股息率，将尤其利好这类账户/策略。

但到目前为止，央行并没有披露太多关于SFISF的技术细节。在这篇文章中，笔者想结合美联储08年推出的定期证券借贷便利（TSLF）和19年央行推出的央行票据互换工具（CBS）对这一工具的技术细节及影响做些猜测和讨论。

问题1：折扣率多少？

折扣率（haircut）是互换或抵押融资工具的重要参数。折扣率越低，单位市值股票能借到的国债/央票也就越多，非银可加的杠杆也就越高，对股市的刺激效果理论上就越好；但折扣率越低，出借方央行面临的违约风险也就越高。

从TSLF经验看，其抵押品中不包括股票，投资级企业债的折扣率大约在6.5-8%，投资级ABS的折扣率大约在7-18%（图1）。但需要注意，TSLF的期限是28天，比目前传言的SFISF的1年要短。从我国经验来看，央行5年期MLF中AAA级企业债的折扣率大约为20-30%，个人与券商做股权质押的折扣率大概在50%左右，期限为1-2年。

考虑到股票的波动率要显著高于高评级企业债，因此除非有财政部提供劣后资金用于吸收潜在损失，或者有其他的增信方式，否则特别低的折扣率只会给央行带来无必要的风险。个人感觉折扣率在30-50%之间可能是较为合理的。

如果按照30-50%折扣率估计，一季度末上市券商股票自营OCI账户余额大约为3100亿（华创证券），假设70%的自营盘申请使用该工具，那么大约会带来1000-1500亿的增量资金，仍然在第一批5000亿范围之内。

问题2：利率如何设计？

由于非银需要拿股票先找央行借入国债或央票，然后再去市场质押融资（或者直接出售），因此它面临两部分利率成本——借国债的利率和质押融资利率（或者抛售国债后未来买回的机会成本）。

从CBS经验看，央行借出券只征收了一笔10bps的非常低的费率。TSLF也采取了类似的方式，美联储借出国债征收的费率为25bps（按实际拍卖情况可能略有上浮）。如果SFISF也参考这一方式，那么券商或保险支付的最终融资成本就是市场回购融资利率（如R007）+10-25bps。这在目前的利率环境下成本大约是2%出头，直接利好那些能够长期持有4-5%高股息票的非银，比如自营OCI或者保险。

但如果央行出借国债本身就要征收一笔较高的利率，比如2%。那么非银最终实际支付的利率将超过4%，意味着4-5%的股息率不再有吸引力。

但高利率并非没有道理。如果央行更希望该工具的作用是在市场大跌的时候雪中送炭，而非在市场大涨的时候锦上添花，那么相对较高的利率可以确保机构只在股票价格暴跌（以至于股息率大幅上升）后才会使用它。

问题3：资产价格波动是否需要补缴抵押品/保证金？

在TSLF工具中，纽联储和清算行每日评估抵押品价值。如果跌破警戒线，借券方（一级交易商）就需要补缴抵押品，否则就会面临解约。这确保了借款人风险不会传染至央行。理论上，股票价格波动远甚于债券类资产，因此对抵押品估值与管理的评估要求更高。暂不清楚在SFISF中相关条款细节。

为什么要关注抵押品估值和保证金需求的相关条款？因为这关系到SFISF到底会成为股市稳定器还是放大器。

显然央行希望SFISF能够托底市场。但如果该工具总额度在初期就被使用完毕，而央行对抵押品又有非常严格的规定，那么券商在股市大跌时就可能陷入margin call，反而加剧资产抛售压力。而如果抵押品管理不那么严格，则意味着央行替券商/保险承担了一定的市场风险。

问题4：拍卖制（auction-type）还是常备制（standing-type）？ 

所谓拍卖制，就是指央行确定每一期总出借额度和拍卖时间，然后由最终需求者报价+报需求，并按照价格由高到底依次满足，直至额度用完。它的好处是高需求的可以高报价，低需求的可以低报价，这样工具的总体使用量比较高，而且没有污点效应。缺点是非常备的——错过了这次拍卖就要等下一次了。美联储的TSLF就是拍卖制流动性工具，目的是减少污点效应，调动一级交易商积极性（图2）。

所谓常备制，就是指央行只确定出借额度上限，同时直接确定利率等各方面条款，最终需求者按央行给定的价格来报需求。它的好处是总使用量不高，但能够确保只有特别需要这笔资金的机构才能借到钱。缺点是存在污点效应。美联储21年设立的常备回购便利（SRF）就是常备制工具。

为什么要关心SFISF到底是拍卖制还是常备制？因为不同的制度下，它对股价的影响可能不同。

如果是拍卖制，那么在每次拍卖结束后，伴随非银拿着资金入市，该工具对市场的提振效果就结束了。换句话说，拍卖制下的SFISF只是系统性增加了市场对某些股票的需求以及这些股票的价格中枢。除非央行在市场暴跌时临时增加拍卖额，或者此前额度没有用满，否则SFISF无法起到“在市场暴跌时托底市场”的逆周期效果。

如果是常备制，那么该工具就需要征收相对较高的利率，以避免金融机构长期使用该工具作为融资来源。否则在额度用完后，常备也就失去了意义。这时，SFISF的作用将更多体现为熨平波动，而非提升价格中枢。

问题5：借入的国债是否允许抛售？ 

CBS工具不允许一级交易商抛售借入的央票，只能做质押融资。个人认为SFISF可能延续这一设计，即只允许做质押融资不允许抛售。原因是如果允许抛售，那么借券人相当于做了一个杠杆多空策略——借入资金做多股票，做空国债。债券价格大涨或者股票价格暴跌都有可能导致券商受损乃至传导至央行。

有人说这一工具的初衷就是为了抬升债券利率。但事实上，当前的央行已经可以通过借券卖空或者买短卖长等方式自己出面调节长端利率，并不需要“借券给他人卖空”。

问题6：非银是否可以使用该工具反复加杠杆？是否可以资金他用？

例如，A券商在首次申请中以自持的50亿股票为抵押，申请了25亿SFISF额度并增持了25亿股票。那么在续作时的第二次申报中，A券商能否以总的75亿股票为抵押，申请37.5亿的额度来继续加杠杆？ 

另外，如果A券商申请了25亿额度，但拿出其中一部分资金做其他业务如衍生品、质押融出等，央行是否允许又如何考察？

这些问题都将影响该工具对市场的实际提振效果。

总结：由于当前非银持有的股票很难从市场中获得质押融资，因此SFISF无疑会系统性的提高股票的融资流动性，并推升股票特别是高股息票的价格。更进一步的看，其使用量和最终效果也取决于具体的技术细节。期待未来公布更多细节。



### 98

方军 2024-10-18

我们作为最早一批高浓度接触AI文字的有个大优势，就是别人还在觉得它神奇（也可能误信）的时候，我们已经过了一大关口。

的确，现在我们就很比较朴实地看到它的优点，又能看到不足。

AI是80分的水平。我们自己得要求自己做到95分以上。

我个人是觉得，即便自己写的日常笔记（有时候记得太快错字什么的颇多），也远超过80分的。



### 99

方军 2024-10-18

155 AI 文字有什么特征？

刚刚我感慨，我们这一批较早深入使用 LLM 的人，有一大优势：由于我们大量看 AI 生成的文字，尽管还无法用语言描述它的特征，但已经对这类文字有了基本的认识。它有点专家口吻，但我们不会被迷惑。接下来，AI 生成的文字会越来越多，会成为我们获取信息的众多类型之一，这种先发优势会帮我们很多。

那么，目前 AI 生成的文字有什么特征呢？我这里主要指，当我们用在互动式对话中提问时，它给的回答，有什么特征呢？这里尝试着列几条。

AI 的基础认知水平是人类平均分。在多数大众领域，AI 是平均分。它的回答看起来很有条理、很专家口吻、很详尽，但是，这都是一个平均分，也就是70-80分。在每一个我们自己较为专业、也有鉴赏力的领域，我们都能感受到 AI 水平不太好。

我们要在很多领域达到专业水平，不容易。但是，要在相对多的领域形成较好的鉴赏力，还是可能的。比方说，我对经济学内容没多少能力，但什么是好的，还是能够看得出来的，这是因为阅读高水平材料多了就可以达到了。

要识别 AI 的胡扯（bullshit）。人类专家中水平较为一般的经常会胡扯，看着很专业，但他们都不知道自己在讲什么。在外人看来，他们和最顶级的专家用词、语调一样，甚至看起来可信度更强。但是只要仔细辨别，我们会发现他们在胡扯。比如，他们可能仅仅使用一些大词没逻辑地列一些东西，可能没有抓住真正的重点。是的，任何事物都可以归结为几个重点要素及它们之间的关系。

与 AI 交互多了，我们每个人的思考能力都会有所上升，如果能够掌握日常阅读中的一个关键方法，我们的思考能力上升会更快。这个方法就是删减，不管看到什么，把不相干的都删减、撇除。往深处挖是困难的，但往少数处精简是容易的。

那么也许有人会说，让 AI “惜墨如金”不就好了（惜墨如金是一个被证明让 AI 说话不要啰嗦的有效提示语）。但我觉得正确的做法并非如此，我们用 AI 是想获得更多的信息、更多重点供选择，让它惜墨如金就少了这一层好处。

更好的做法是：让 AI 按照它的基本表达方式来输出，之前有研究者讨论，它的表达方式是训练过程中的偏见导致的——较长的回答会获得较高的分数。它回答得长、详尽、啰嗦没关系，我们自己掌握删减的方式，快速看到关键点。另外一个辅助的做法是，让 AI 不是输出长段文字，而是输出列表，我们通常能够更快地阅读列表。（我这篇笔记有意不采用列表，表达起来容易多了，但明显哪怕我自己看也觉得难以一下子把握要点。）

附注：写完用AI提取一个大纲，实际上我写之前都不知道大纲原来是这个。用AI获得更多选择，的确是我关注重点，但我好像没写出来，但被大纲提取的时候凸显出来了，这个有点意思。

题外话，我觉得普通人对于段落式文字、对于描述性文字，给的分值太多了。如果仅从文字传递信息效率的角度讲，这两者不太好。



### 100

方军 2024-10-18

一个语言的例子，一位老师写：

我最近改雅思作文，有一些同学，想写出这样的句子：让女性和男性有着公平竞争的机会。

然后，一些同学从字面上去对应，就写出了let women have the chances of competing with men equally.

其实，可以使用词组“营造公平竞争的环境level the playing field” 那么用在刚刚的表达里就是： level the playing field for women（给女性营造公平竞争的环境）。

说起来，这是考研阅读出现过的词组。可惜的是，考研行业无论是阅读的学习（不看文章、也能“做对”阅读），还是写作的学习（背一下套话就行），很多学生是不可能接触到这个地道的词组的。

我让AI回答：

polish writing: level the playing field for women

回答：

1. "Create equitable opportunities for women."
2. "Establish a fair and inclusive environment for women."
3. "Ensure equal opportunities for women in all spheres."
4. "Promote fairness and equality for women in the workplace."

以我的英语水平，我会觉得level 过于隐晦，而
4可能更明确一些，至于promote是不是有更好说法，我们可以接着问：

1. "Foster"
2. "Advocate"
3. "Champion"
4. "Facilitate"
5. "Encourage"
6. "Enhance"
7. "Support"
8. "Nurture"
9. "Uphold"
10. "Elevate"

我的水平多半会选advocate

我当然也觉得 foster不错。如果用harness则更好，但觉得不自然。

语言其实最难体现人的水平，悄悄地。

回头再想，1 "Create equitable opportunities for women."也不错。
收起

查看详情
钰博 觉得很赞
方军：换 Claude，它的第一个我还蛮喜欢的：

 "Create equal opportunities for women"
2024-10-18 17:39
方军：我问claude: HOW about" advocate fairness and equality for women"

"Advocate fairness and equality for women" is an excellent polished version of the original sentence. It effectively captures the essence of the original phrase while using more formal and precise language. This version:

1. Uses the active verb "advocate," which implies a strong, proactive stance.
2. Explicitly mentions both "fairness" and "equality," which are the key concepts behind "leveling the playing field."
3. Maintains the focus on women as the beneficiaries of this advocacy.
4. Sounds more professional and could be suitable for a wider range of contexts, from casual conversations to formal documents.
2024-10-18 17:42



### 101

方军 2024-10-18

张一鸣早期的一篇文章，关于信息阅读。虽然他和他的公司是制作信息垃圾和推送信息垃圾的，但他的认识的确很到位，对人性的认识到位。

---

张一鸣/文
虽然不少人表示Google Reader即将关闭的愤慨，但细心一点你会发现，这些正在用Google Reader的用户都是“互联网圈资讯重度用户"。其中,还有不少人说“那上千条买来得及阅读的订阅怎样办"。这些信息其实就从某种程度反应出Google Reader关闭的必然性。
我算是Google Reader国内的第一批用户，它实质就是“用户自订阅”模式。我自己去寻找我喜欢的网站和博客，找出RSS图标，然后点击订阅。但用过一段时候后，随着我订阅的RSS源增多, Google Reader上那好几百上千条的更新我已经看不完。每到这时候,我需要重新把已经订阅的RSS整理一遍，而这个整理的过程挺痛苦的。
我发现，要成为Google Reader常用用户必须具备两个特点：
一、信息组织能力强，明确知道自己想要的信息在哪。
二、自制力强，有规律的整理并能控制好RSS源的数量。
显然,能达到这两个条件的用户并不多。这也是为什么愤慨的Google Reader用户多是媒体从业人员。一款本该面对大众的产品却只能满足的是很小的一部分用户的需求，那就注定不会走得长远。
在我使用过一段Google Reader后，就已经不看好它的前景。这里订阅模式对用户要求太高，用户需要自己去想好“我喜欢什么，我订什么”。
对于那部分有一些兴趣但不是太喜欢的内容到底是订是不订，这也够让用户纠结的。比如我并不想看来自36氪所有文章，我只想看其中跟移动互联网有关的。那我到底是订还是不订呢？
所以，我认为这个订阅过程的用户体验就很不好。
不能否认，作为“订阅模式”代表的Google Reader的离去多少还让人感到遗憾。相比依靠人工仅从门户网站获取资讯,订阅模式其实进步了,但很明显还没能满足大部分人的资讯需求。什么样阅读器更智能更适合大众，将成为Google Reader的替代品？我和我的团队回答是的基于算法的个性化推荐。
已经有不少人在比较甚至质疑，个性化推荐靠不靠谱？机器推荐能不能比人工推荐靠谱？，我想说，一款产品选择什么模式和方法是次要的，最重要的是多大程度上满足了多少人的资讯需求。Google Reader今天的离去,就是这个问题没有回答好。
不过，我觉得拉里·佩奇（Google CEO）很有魄力，关闭了叫好但没希望的产品，一定会在别的方面做的更好。
（作者系今日头条创始人）


### 102

方军 2024-10-18

刚刚跟人讨论，不知道为何说起作家。然后看到对某位作家的评价：

> 从写作水平看，作者是三四流作家（简单说：一流作家，比如曹雪芹、莎士比亚、托尔斯泰、卡夫卡、鲁迅；二流作家，比如毛姆、梭罗、老舍），so，学习的时候，不能因为学到了就满足了，而是要以此为阶梯，更上层楼。

我觉得蛮有意思的，普通人也许应该读一流的（因为是为了鉴赏），作家应该看二流的（因为看二流的可以换位思考，如果是我，怎么写？），但普通人如果为学写作读，也许连二流的作家都不要模仿，而是应该模仿三四流（因为那些技巧反而更实用、能学会）。

红楼梦再好，普通人连碰到边的都没有。当然，人的眼光会变化，以前我觉得金庸讲的故事还行啊，但现在再看一次，他讲故事能力实在太差了，世界构架能力也很差，比故事好点。

其实，今天受欢迎的散文作家、畅销作家可能是七八流的，互联网上那些吸引眼球的文章可能是十七八流的。说个不恰当的例子，比如吴军写书教大家写作，他的文字放在严苛的人眼中，最多五六流吧，但对于不用文学吃饭的人，五六流都够用了。

至于今天说的，AI写的是几流的呢？AI 写的多半是七八十流，哈。而如果一个人用 AI 写，还说自己写的呢？我觉得一百七八流。



### 103

方军 2024-10-19

还是说语言：

maybe langchain team should build a better docs chat to display the ability of LLM, RAG as well as Langchain. 

我社交媒体上回复完就觉得 display 不对，应该是 showcase

果然 AI 给了同样的建议

"Maybe the LangChain team should build a better documentation chat to showcase the capabilities of LLMs, RAG, and LangChain."

capability 也比 ability 要好好。

as well as 我觉得还是比 and 好。

the 我觉得是没必要的

社交媒体回复一般不怎么做重视大小写，一般乱七八糟，没辙。

"Maybe LangChain team should build a better docs chat to showcase the capabilities of LLMs, RAG, as well as LangChain."





### 104

方军 2024-10-19

摘： 词生卡类 prompt 现在真强的可怕，网友 zephyr 空格 做了直出 PPT 的效果

 能够很方便的生成“动物生长过程”等时间线视图

 从信息传达的效果来看，比 Gamma等各类 AI PPT 效果好了太多，非常适合知识教学！

[以「时间」为主题的 Prompt ，可以怎么做？](https://mp.weixin.qq.com/s/BOMOQVGQ5hvd8dDaKwb18A)

这个作者还有一些其他的：（📕想法很有意思，但实用性欠缺，不用实际使用）

[一个 Prompt 搞定架构图和思维模型](https://mp.weixin.qq.com/s?__biz=MzkxMTQ0ODE3Ng==&mid=2247488242&idx=1&sn=cfe2212800684d73eca510acd3242216&chksm=c11d53edf66adafb5ce6a63d9322dec58c29ac1bc0502c3981356ef9fc2c55981c21d7affb6b&scene=21#wechat_redirect)

一个 Prompt 搞定架构图和思维模型

逻辑关系图（图4）：

[Prompt 制作方法：文字逻辑关系图](https://mp.weixin.qq.com/s?__biz=MzkxMTQ0ODE3Ng==&mid=2247488255&idx=1&sn=0af2c1235780db663670e799f4802d73&chksm=c11d53e0f66adaf6a117a10bf37f07ddc0011d0984ec2497c81a2eaeb177e9c3dc3c67cb196c&scene=21#wechat_redirect)



### 105

方军 2024-10-19

很有意思的一点，我看了这位作家很多篇短文之后，我也认同，他是一个三四流、甚至更靠后的作家，原因很简单，因为他基本上就是能够在1500字左右写一篇短文，不论这些短文是好是一般，它们都没有风格，也无法组合起来描绘一个更大的事物。（我也不是很明白，如果抛开纯个人记录，这些短文为何而写？当然这个要求太高了，我们写很多东西也不知道为何而写。）

对比看《至此一年》，其实论文笔，这本书可能更差，整本书就很生动地描绘了一件大事，丘吉尔就任首相一年的情形。这本书背后所做的资料调研，工作量也庞大许多。从书的价值看，《至此一年》要高出很多倍。

如果要说写更大的事物，我觉得盐野七生就厉害得多（从严谨的历史角度来讲，她写的有待专家评论），她叙述一个大得多的事物：一个城邦国家的历史，一个伟大人物的历史，一次庞大的战争等等。

小短文能否连成长文呢？也不是没可能，我一直看着玩的《带一本书去巴黎》，单篇和整体的关系就非常棒。

还是说回 AI，AI 除了在表达、句子上有问题外，还有一个问题就是它的架构不够大，或许这可以戏用杨立昆的词来说，AI 没有世界模型（他愿意更多指空间。）


### 106

方军 2024-10-19

摘：Claude AI 官方推荐的四个应用案例

这四个场景展示了 Claude 在不同领域的应用潜力, 从客户服务到内容管理再到专业领域的辅助。每个场景都利用了 Claude 的核心能力, 如自然语言理解、信息提取和复杂任务处理, 来解决特定的业务挑战。

01 工单路由 (Ticket routing) 
利用 Claude 的自然语言理解能力来大规模分类客户支持工单, 它可以基于客户意图、紧急程度、优先级、客户档案等因素来分类工单。这有助于更高效地处理客户请求, 确保重要问题得到及时解决。

02 客户支持代理 (Customer support agent) 
Claude 作为一个虚拟客服 Agent, 实时处理客户询问。它可以提供全天候支持, 缩短等待时间, 并在高峰期处理大量支持请求。Claude 能够提供准确的回答, 并保持积极友好的互动, 提升客户体验。

03 内容审核 (Content moderation) 
关注如何使用 Claude 来审核数字应用中的内容。内容审核对于维护安全、尊重和有序的在线环境至关重要。Claude 可以帮助识别和过滤不适当、有害或违规的内容,确保平台的健康发展。

04 法律文件摘要 (Legal summarization) 
展示了如何使用 Claude 的高级自然语言处理能力来高效地总结法律文件。它可以从复杂的法律文本中提取关键信息,加速法律研究过程。这对于合同审查、诉讼准备和监管工作都很有帮助,可以节省时间并确保法律流程的准确性。

[Guides to common use cases - Anthropic](https://docs.anthropic.com/en/docs/about-claude/use-case-guides/overview)

### 107

方军 2024-10-19





### 108

方军 2024-10-19





### 109

方军 2024-10-01





### 110

方军 2024-10-01





### 111

方军 2024-10-01





### 112

方军 2024-10-01





### 113

方军 2024-10-01





### 114

方军 2024-10-01





### 115

方军 2024-10-01





### 116

方军 2024-10-01





### 117

方军 2024-10-01





### 118

方军 2024-10-01





### 119

方军 2024-10-01





### 120

方军 2024-10-01





### 121

方军 2024-10-01





### 122

方军 2024-10-01





### 123

方军 2024-10-01





### 124

方军 2024-10-01





### 125

方军 2024-10-01





### 126

方军 2024-10-01





### 127

方军 2024-10-01





### 128

方军 2024-10-01





### 129

方军 2024-10-01





### 130

方军 2024-10-01





### 131

方军 2024-10-01





### 132

方军 2024-10-01





### 133

方军 2024-10-01





### 134

方军 2024-10-01





### 135

方军 2024-10-01





### 136

方军 2024-10-01





### 137

方军 2024-10-01





### 138

方军 2024-10-01





### 139

方军 2024-10-01





### 140

方军 2024-10-01





### 141

方军 2024-10-01





### 142

方军 2024-10-01





### 143

方军 2024-10-01





### 144

方军 2024-10-01





### 145

方军 2024-10-01





### 146

方军 2024-10-01





### 147

方军 2024-10-01





### 148

方军 2024-10-01





### 149

方军 2024-10-01





### 150

方军 2024-10-01





### 151

方军 2024-10-01





### 152

方军 2024-10-01





### 153

方军 2024-10-01





### 154

方军 2024-10-01





### 155

方军 2024-10-01





### 156

方军 2024-10-01





### 157

方军 2024-10-01





### 158

方军 2024-10-01





### 159

方军 2024-10-01





### 160

方军 2024-10-01





