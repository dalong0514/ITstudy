## 20241225Andrew-Ng-and-Fei-Fei-Li-Discuss-Human-Centered-Artificial-Intelligence

SPEAKER_00: Hi, I'm delighted to have with us here today my old friend Professor Fei-Fei Li. Fei-Fei is a professor of computer science at Stanford University and also co-director of HAI, the Human Centered AI Institute, and previously she also was responsible for AI at Google Cloud as a chief scientist for the division. It's great to have you here Fei Fei. Thank you Andrew.

SPEAKER_01: Very happy to be here. So I guess actually how long have you known each

SPEAKER_00: other? I've lost track. Definitely more than a decade. I mean I've known your

SPEAKER_01: work right before we even met and I came to Stanford 2009 but we started talking

SPEAKER_00: 2007 so 15 years and I just still have very clear memories of how stressful it was when collectively you know bunch of us me Chris Manning bunch of us we're

SPEAKER_01: trying to figure out how to recruit you to come to Stanford. It wasn't hard. I just needed to sort out my students and life, but it's hard to resist Stanford.

SPEAKER_00: Isn't it really great having you as a friend and colleague here?

SPEAKER_01: Yeah, me too. It's been a long time and we're very lucky to be the generation seeing AI's great progress.

SPEAKER_00: Okay, so there was something about your background that I always found inspiring, which is, you know, today people are entering AI from all walks of life, and sometimes people still wonder, oh, I majored in something or other. Is AI a right path for me? So I thought one of the most interesting parts of your background was that you actually started out not studying computer science or AI but you started out studying physics and then had this path to becoming one of the most globally recognizable AI scientists. So how did you make that switch from physics to AI?

SPEAKER_01: Right, well that's a great question Andrew, especially both of us are passionate about young people's future and they come into the world of AI. The truth is, if I could enter AI back then, more than 20 years ago, today anybody can enter AI because AI has become such a prevalent and globally impactful technology. But myself, maybe I was an accident. So I have always been a physics kid or STEM kids. I'm sure you were too. But physics was my passion all the way through middle school, high school, college. I went to Princeton and majored in physics. And one thing physics has taught me till today is really the passion for asking big questions, the passion for seeking North Stars. And I was really having fun as a physics student at Princeton. And one thing I did was reading up stories and just writings of great physicists of the 20th century and just hear about what they think about the world, especially people like Albert Einstein, Roger Penrose, Irving Schrodinger. And it was really funny to notice that many of the writings towards the later half of the career of these great physicists were not about just the atomic world or the the physical world but ponderings about equally audacious questions like life like, like human conditions. You know, Schrodinger wrote this book, What is Life? And Roger Penrose wrote this book, Emperor's New Mind, right? And that really got me very curious about the topic of intelligence. So one thing led to another. During college time, I did intern at a couple of neuroscience labs, and especially vision-related. And I was like, wow, this is just as audacious a question to ask as the beginning of the universe or what is matter made of. And that got me to switch from undergraduate degree in physics to graduate degree in AI, even though, I don't know about you, during our time, AI was a dirty word. It was AI winter, so it was more machine learning and computer vision and computational neuroscience.

SPEAKER_00: Yeah, I know. Honestly, I think when I was an undergrad, I was too busy writing code. I just managed to blithely ignore the AI winter and just kept on coding.

SPEAKER_01: Yeah, well, I was too busy solving PDE equations.

SPEAKER_00: Hey, and so actually, do you have an audacious question now?

SPEAKER_01: Yes, my audacious question is still intelligence. I think since Alan Turing, humanity has not fully understand what is the fundamental computing principles behind intelligence. Today we use the words AI, we use the word AGI, but at the end of the day, I still dream of a set of simple equations or simple principles that can define the process of intelligence, whether it's animal intelligence or machine intelligence. And this is similar to physics. For example, many people have joined the analogy of flying, right? Are we replicating birds flying, or are we building an airplane? And a lot of people ask the question of the relationship between AI and brain. And to me, whether we're building a bird, or replicating a bird, or building an airplane, at the end of the day air dynamics and physics that govern the the the process of flying and I do believe one day we'll discover that I sometimes think about this you know one learning

SPEAKER_00: algorithm hypothesis could a lot of intelligence maybe not all but a lot of it be explained by one or or very simple machine learning principles. It feels like we're still so far from cracking that nut, but in the weekends when I have spare time, when I think about learning algorithms and where they could go, this is one of the things I still am excited about, just thinking about.

SPEAKER_01: I totally agree. I still feel like we are pre-Newtonian if we're doing physics analogy. Before Newton, there has been great physics, great physicists, a lot of phenomenology, a lot of studies of how the astral bodies move and all that, but it was Newton who started to write the very simple laws. And I think we are still going through that very exciting coming-of-age of AI as a basic science and We're pre-Newton

SPEAKER_00: In my opinion, it's really nice to hear you talk about how despite machine learning and AI having come so far It still feels like there are a lot more unanswered questions a lot more work to be done By maybe some of the people joining the field today than work that's already been done.

SPEAKER_01: Absolutely. I mean, let's calculate. It's only, what, 60 years about? It's a very nascent field. Modern physics and chemistry and biology are all hundreds of years, right? so I think it is very it is very exciting to be entering the field of science of intelligence and studying AI today.

SPEAKER_00: I remember chatting with the late professor John McCarthy who had coined the term artificial intelligence and boy the field has changed since when you know he conceived of it at the workshop and came up the term AI but maybe another ten years from now you know maybe someone watching this will come with a new set of ideas and then we'll be saying boy AI sure is different than what you know you and I thought it would be that that's an exciting future to build towards yeah I'm

SPEAKER_01: sure Newton would have not dreamed of uh einstein so you know our our evolution of science uh sometimes takes strides sometimes takes a while and i think we're absolutely in a in an exciting phase of ai right now

SPEAKER_00: you know it's interesting hearing you paint this grand vision for AI. Going back a little bit, there was one of the pieces of your background that I found inspiring, which is when you're just getting started, I've heard you speak about how you're a physics student, but not only that, you're also running a laundromat to pay for school. And so just tell us more about that.

SPEAKER_01: So I came to this country, to New Jersey actually when I was 15. One thing great about being in New Jersey is it was close to Princeton, so I often just take a weekend trip with my parents and to admire the place where Einstein spent most of his career in the latter half of his life but you know with typical immigrant life and it was tough and by the time I entered Princeton my parents didn't speak English and one thing led to another. It turns out running a dry cleaner might be the best option for my family, especially for me to lead that business because it's a weakened business. If it's a weekday business, it would be hard for me to be a student. And it's actually, believe it or not, running a dry cleaning shop is very machine heavy which is good for a STEM student like me. So we decided to open a dry cleaner shop in a small town in New Jersey called Pursipity, New Jersey. It turned out we were physically not too far from Bell Labs and where lots of early convolutional neural network research was happening, but I had no idea.

SPEAKER_00: I was actually a summer intern at AT&T Bell Labs way back.

SPEAKER_01: With Rob Shapiro?

SPEAKER_00: With Michael Kearns was my mentor,

SPEAKER_01: and Rob Shapiro, inventor of Bruce Singh, great algorithms. See, you're coding AI. I was trying to clean clothes.

SPEAKER_00: No, no, no. Not very far. Only much later in my life did I start interning.

SPEAKER_01: Yeah, and then it was seven years. I did that for the entire undergrad and most of my grad school, and I hired my parents. Yeah.

SPEAKER_00: Yeah, no, that's really inspiring. I think, you know, I know you've been brilliant and doing exciting work all your life, and I think the story of, you know, running a laundromat to globally prominent computer scientists, I hope that inspires some people watching this, that no matter where you are,

SPEAKER_01: there's plenty of room for everyone. Exactly, yeah.

SPEAKER_00: Don't even notice, my high school job was an office admin. that no matter where you are, there's plenty of room for everyone. Don't even know this, my high school job was an office admin. So to this day, I remember doing a lot of photocopying. And the exciting part was using the shredder. That was the glamorous part. But I was doing so much photocopying in high school, I thought, boy, if only I could build a robot to do this photocopying, maybe I could do something else.

SPEAKER_01: Did you succeed?

SPEAKER_00: I'm still working on it. We'll see.

SPEAKER_01: And then, you know, when people think about you and the work you've done, one of the huge successes

SPEAKER_00: everyone thinks about is ImageNet, right, where Hub established early benchmark for computer vision. It was really completely instrumental to the modern rise of deep learning and computer vision. One thing I bet not many people know about is how you actually got started on ImageNet. So tell us the origin story of ImageNet.

SPEAKER_01: Yeah, well, Andrew, that's a good question, because a lot of people see ImageNet as just labeling a ton of images, but where we began was really going after North Star brings back my physics background. So when I entered grad school, when did you enter grad school? Which year?

SPEAKER_00: 97.

SPEAKER_01: Okay, I was three years later than you, 2000. And that was a very exciting period because I was in the computer vision and computational neuroscience lab of Pietro Perona and Christoph Koch at Caltech. And leading up to that, there has been, first of all, two things was very exciting. One is that the world of AI at that point wasn't called AI. Computer vision or natural language processing has found its lingua de franco, its machine learning. Statistical modeling as a new tool has emerged, right? I mean, it's been around.

SPEAKER_00: And I remember when the idea of applying machine learning to computer vision, that was like a controversial thing.

SPEAKER_01: Right. And I was the first generation of graduate students who were embracing all the base net, all the inference algorithms, and all that. And that was one exciting happening. Second exciting happening that most people don't know and don't appreciate is that a couple of decades, probably more than two or three decades, of incredible cognitive science and cognitive neuroscience work in the field of vision, in the world of vision, human vision, that has really established a couple of really critical North Star problems, just understanding human visual processing and human intelligence. And one of them is the recognition of understanding of natural objects and natural things. Because a lot of the psychology and cognitive science work is pointing to us that is an innately optimized, whatever that word is, functionality and ability of human intelligence. It's more robust, faster, and more nuanced than we had thought. We even find neural correlates, brain areas, devoted to faces or places or body parts. So these two things led to my PhD study of using machine learning methods to work on real-world object recognition. But it became very painful very quickly that we are banging against one of the most, continue to be the most important challenge in AI and machine learning is the lack of generalizability. You can design a beautiful model all you want if you're overfitting that model.

SPEAKER_00: I remember when it used to be possible to publish a computer vision paper, showing your words on one image. Exactly.

SPEAKER_01: Yeah, it's just the overfitting. The models are not very expressive, and we lack the data. And we also, as a field, was betting on making the variables very rich by hand-engineered features.

SPEAKER_00: Remember, every variable carrying a ton of semantic meaning,

SPEAKER_01: but with hand-engineered features. So and then towards the end of my PhD, my advisor Pietro and I start to look at each other and say, well, boy, we need more data. If we believe in this North Star problem of object recognition, and we look back at the tools we have, you know, mathematically speaking, we're overfitting every model we're encountering. We need to take a fresh look at this. mathematically speaking we're overfitting every model we're encountering we need to take a fresh look at this so one thing led to another he he and I decided we'll just do a at that point we think it was a large-scale data project called

SPEAKER_00: Caltech 101 I remember the data set I wrote papers using you know your Caltech

SPEAKER_01: 101 you did you and your early graduate student. It helped benefit a lot of researchers, Caltech 101 data set.

SPEAKER_00: That was me and my mom labeling images.

SPEAKER_01: Oh, and a couple of undergrads. But that was the early days of internet. So suddenly, the availability of data was a new thing. I remember Pietro still have this super expensive digital camera. I think it was Canon or something like $6,000 walking around Caltech taking pictures. But we are the internet generation. I go to Google image search, I start to see these thousands and tens of thousands of images and I tell Pietro let's just download. Of course it's not that easy to download so one thing led to another. We built this Caltech 101 data set of 101 object categories and about I would say 30 to 50, 30,000 pictures. I think it's really interesting that you know even though everyone's

SPEAKER_00: heard of ImageNet today, even you kind of took a couple iterations where you did Caltech 101 and that was a success. Lots of people used it but it's the even the early learnings from building Caltech 101 that gave you the basis to build what

SPEAKER_01: turned out to be even an even bigger. Right, except that by the time we started, I became an assistant professor. We started to look at the problem, and realized it's way bigger than we think. Just mathematically speaking, Caltech 101 was not sufficient to power the algorithms. We decided to do ImageNet, and that was the time people started to think we're doing too much. It's just too crazy.

SPEAKER_00: The idea of downloading the entire Internet of Images and mapping out all the English nouns was a little bit,

SPEAKER_01: I start to get a lot of pushback.

SPEAKER_00: I remember at one of the CVPR conference when I presented the early idea of ImageNet, a couple of researchers publicly questioned and said, if you cannot recognize one category of object, let's say the chair you're sitting in, how do you imagine,

SPEAKER_01: or what's the use of a data set of 22,000 classes and 15 million images?

SPEAKER_00: Yeah, but in the end, that giant data set unlocked a lot of value for countless number of researchers around the world.

SPEAKER_01: Well, I think it was the combination of betting on the right North Star problem and the data that drives it. So it was a fun process.

SPEAKER_00: Yeah, and to me, when I think about that story, it seems like one of those examples where, you know, sometimes people feel like they should only work on projects that are the huge thing at the first outset, but I feel like for people working machine learning if your first project is a bit smaller it's totally fine have a good win use the learnings to build up to even bigger things and then sometimes you get a you know image net size win all of it yeah

SPEAKER_01: well but in the meantime I think it's also important to be driven by an audacious goal though you know you can size your problem or size your project as local milestones and so on along this journey but I also look at some of our current students they're so peer pressured by this current climate of publishing nonstop. It becomes more incremental papers to just get into a publication for the sake of it. And I personally always push my students to ask the question, what is the North Star that's driving you?

SPEAKER_00: Yeah, that's true. You're right. For myself, when I do research over the years I've always pretty much done

SPEAKER_01: what I'm excited about where I want to you know try to push the field forward doesn't it don't listen to people I have to listen people let them shape your opinion but in the end I think the best research is let the world shape their opinion but in the end drag things forward using their own opinion. Totally agree. It's your own inner fire, right?

SPEAKER_00: So as your research program developed, you've wound up taking your, let's say, foundations in computer vision and neuroscience and applying to all sorts of topics including very visibly healthcare, look at neuroscience applications. Would love to hear a bit more about that.

SPEAKER_01: Yeah, happy to. I think the evolution of my research in computer vision also kind of follows the evolution of visual intelligence in animals and there are two topics that truly excites me. One is what is a truly impactful application area that would help human lives and that's my healthcare work the other one is what is vision at the end of the day about and that brings me to the the trying to close the loop between perception and robotic learning so on the healthcare side, you know, one thing, Andrew, there was a number that shocked me about 10 years ago when I met my long-term collaborator, Dr. Arne Milstein at Stanford Medical School. And that number is about a quarter of a million Americans die of medical errors every year. I had never imagined a number being that high due to medical errors there are many many reasons but we can rest assured most of the reasons are not intentional these are her errors of unintended you know mistakes and and so on for That's a mind-boggling number.

SPEAKER_00: It is.

SPEAKER_01: It's about 40,000 deaths a year from automotive accidents,

SPEAKER_00: which is completely tragic and this is even vastly greater.

SPEAKER_01: I was going to say that. I'm glad you brought it up. Just one example, one number within that mind-boggling number is the number of hospital acquired infection resulted fatality is more than 95,000 that is more than that's 2.5 times than the death of car accidents and and in this particular case hospital car infection is a result of many things but by enlarged lack of good hand hygiene

SPEAKER_00: practice so if you look at WHO there has been a lot of protocols about clinicians hand hygiene practice but in real healthcare delivery the when things get busy and when the process is tedious and when there is a lack of feedback system you still make a lot of mistakes another medical tragic medical fact is that more than 70 billion dollars every year are spent in in full resulted injuries and fatalities and most of this happened to elderlies at home but also in the hospital rooms and these are huge issues and when arnie and i got together back in 2012 it was the height of

SPEAKER_01: self-driving car um let's say not hype but what's the word right word excitement in Silicon Valley. And then we look at the technology

SPEAKER_00: of smart sensing cameras, LIDARs, radars, whatever,

SPEAKER_01: smart sensors, machine learning algorithm, and holistic understanding of a complex environment with high stakes for human lives. I was looking at all that for a self-driving car and realized in healthcare delivery we have the same situation. Much of the process, the human behavior process of healthcare is in the dark and if we could have smart sensors, be it in patient rooms or senior homes, to help our clinicians and patients to stay safer that would be amazing so Arne and I embarked on this what we call ambient intelligence research agenda but one thing I learned which probably will lead to our other topics is as soon as you're applying AI to real human conditions, there's a lot of human issues in addition to machine learning issues, for example, privacy.

SPEAKER_00: And I remember reading some of your papers with Arnie

SPEAKER_01: and found it really interesting how you could build and deploy

SPEAKER_00: systems that were relatively privacy-preserving. Yeah, well, thank you.

SPEAKER_01: Well, the first iteration of that technology is we use cameras that do not capture RGB information. You've used a lot of that in self-driving cars, the depth cameras for example. And there you preserve a lot of privacy information just by not seeing the faces and the identity of the people. But what's really interesting over the past decade is the changes of technology is actually giving us a bigger tool set for privacy preserved computing in this condition. For example, on-device inference, you know, as the chips getting more and more powerful, if you don't have to transmit any data through the network and to the central server, you help people better. Federated learning, we know it's still early stage, but that's another potential tool for privacy, preserve computing, and then differential privacy and also encryption technologies. So we're starting to see that human demand, privacy and other issues, is driving actually a new wave of machine learning technology in ambient intelligence in healthcare.

SPEAKER_00: Yeah, that's really, yeah. I've been encouraged to see the real practical applications of differential privacy that are actually real.

SPEAKER_01: Federated learning, as you said, probably the PR is a little bit ahead of the reality, but I think we'll get there.

SPEAKER_00: But it's interesting how consumers in the last several years have fortunately gotten much more knowledgeable about privacy and are increasingly demanding.

SPEAKER_01: So important. I think the public is also making us to be better scientists.

SPEAKER_00: Yeah. And I think ultimately, you know, people understand AI holds everyone, including us, but holds everyone accountable for really doing the right thing.

SPEAKER_01: Yeah.

SPEAKER_00: And, you know, and on that note, one of the really interesting pieces of work you've been doing has been

SPEAKER_01: leading several efforts to help educate legislators or help governments, especially U.S. government,

SPEAKER_00: work toward better laws and better regulation, especially as it relates to AI. That sounds like very important and I suspect some days of the week I would guess somewhat frustrating work, but we'd love to hear more about that.

SPEAKER_01: Yeah, so I think first of all, I have to credit many, many people. So about four years ago, and I was actually finishing my sabbatical from Google time, I was very privileged to work with so many businesses, enterprise developers, just a large number and variety of vertical industries realizing AI's human impact. That was when many faculty leaders at Stanford and also just our president provost, former president and former provost all get together and realize there is a role, historical role, that Stanford needs to play in advances of AI. We were part of the birthplace of AI. You know, a lot of work our previous generation have done, and a lot of work you've done and some of the work I've done led to AI, today's AI. What is our historical opportunity and responsibility? With that, we believe that the next generation of AI education and research and policy needs to be human centered and having established the human center AI Institute what we call HAI one of the work that really took me outside of my comfort zone or aiding expertise is really a deeper engagement with policy thinkers and makers because you know we're here in Silicon Valley and there is a culture in Silicon Valley is we just keep making things and the law will catch up by itself but AI is impacting human lives and some sometimes negatively so rapidly that it is not good for any of us if we the experts are not at the table with the policy thinkers and makers to really try to make this technology better for the people. I mean we're talking about fairness, we're talking about privacy, we also are talking about the brain drain of AI to industry and the concentration of data and compute in a small number of technology companies, all these are really part of the changes of our time. Some are really exciting changes. Some have profound impact that we cannot necessarily predict yet. So one of the policy work that Stanford HAI has very proudly engaged in is we were one of the leading universities that lobbied a bill called the National AI Research Cloud Task Force bill. It changed the name from Research Cloud to Research Resource. So now the bill's acronym is NAIR, National AI Research Resource. And this bill is calling for a task force to put together a roadmap for America's public sector, especially higher education and research sector, to increase their access to resource for AI compute and AI data. It really is aimed to rejuvenate America's ecosystem in AI innovation and research. And I'm on the 12-person task force under Biden administration for this bill and we hope that's a piece of policy that is not a regulatory policy it's more an incentive policy to build and rejuvenate ecosystems I'm glad that you're doing this to help shape

SPEAKER_00: US policy and this type of making sure enough resources are allocated to you know ensure healthy development of AI. It feels like this is something that every country needs at this point. Yeah. So, you know, just from the things that you are doing by yourself, not to speak of the things that the global AI community is doing, there's just so much going on in AI right now. So many opportunities, so much excitement.

SPEAKER_01: Yeah.

SPEAKER_00: I found that for someone getting started in machine learning for the first time, sometimes there's so much going

SPEAKER_01: on they can almost feel a little bit overwhelming. What advice do you have for someone getting

SPEAKER_00: started in machine learning?

SPEAKER_01: Great question Andrew. I'm sure you have great advice. You're one of the world-known advocate

SPEAKER_00: for AI machine learning education. So I do get this question a lot as well. And one thing you're totally right is AI really today

SPEAKER_01: feels different from our time. During our time.

SPEAKER_00: Today, just for the record, now is still our time.

SPEAKER_01: Just you. That's true. When we were starting in AI.

SPEAKER_00: I love that. Exactly. We're still part of this. When we got started, the entrance to AI and machine learning was relatively narrow.

SPEAKER_01: You almost have to start from computer science angle. As a physics major, I still had to wedge myself into the computer science track or electrical engineering track to get to AI. But today I actually think that there is many aspect of AI that that creates entry points for people from all walks of life. On the technical side, I think it's obvious that there's just an incredible plethora of resources out there on the internet, from Coursera to YouTube to TikTok to GitHub. There's just so much that students worldwide can learn about AI and machine learning compared to the time we began learning machine learning and also any campuses we're not talking about just college campuses we're talking about high school campuses even sometimes earlier we're starting to see more more available classes and resources. So I think there is, I do encourage those of the young people with the technical interest and resource and opportunity to embrace these resources because it's a lot of fun. But having said that, for those of you who are not coming from a technical angle, who still are passionate about AI, whether it's the downstream application or the creativity it engenders or the policy and social angle or important social problems, whether it's digital economics or the governance or history, ethics, political sciences, I do invite you to join us because there is a lot of work to be done. There is a lot of unknown questions. For example, my colleague at HAI are questioning, are trying to find answers on how do you define our economy in the digital age? What does it mean when robots software are participating in the workflow more and more? How do you measure our economy? That's not an AI coding question. That is an AI impact question. We're looking at the incredible advances of generative AI. And there will be more. What does that mean for creativity? And to the creators, from music to art to writing, I think there is a lot of concerns concerns and I think it's rightfully so but in the meantime it takes people together to figure this out and also to use this new tool. So I think in short I just think it's a it's a very exciting time and anybody with any walks of life as long as you're passionate about this there's a role to play.

SPEAKER_00: Yeah, and that's really exciting. When you talk about economics, think about, you know, my conversations with Professor Eric Bryn Austin, right, studying impact of AI on the economy. But from what you're saying, and I agree, it seems like no matter what your current interests are,

SPEAKER_01: AI is such a general-purpose technology that the combination of your current interests are, AI is such a general purpose technology that the combination of your current interest and AI is often promising.

SPEAKER_00: And I find that even for learners that may not yet have a specific interest, if you find your way into AI, start learning things, often the interest will evolve and then you can start to craft your own path.

SPEAKER_01: And given where AI is today, there's still so much room and so much need for a lot more people to craft their own paths to do this exciting work that I think the world still needs a lot more of.

SPEAKER_00: I totally agree.

SPEAKER_01: Yeah.

SPEAKER_00: So one piece of work that you did that I thought was very cool was starting a program, initially

SPEAKER_01: called Sailors and then later AI for All which was really reaching out to you know high school and even younger

SPEAKER_00: students to try to give them more opportunities in AI including people of all walks of life. I'd love to hear more about that.

SPEAKER_01: Yeah well this is in the spirit of this conversation is that was back in 2015. There was starting to be a lot of excitement of AI, but there was also starting to be this talk about killer robot coming next door, Terminator is coming. At that time, Andrew, I was the director of Stanford AI Lab, and I was thinking, you know, we know how far we are from Terminators coming, and that seemed to be a really, a little bit of far-fetched concern, but I was living my work life with a real concern I felt no one was talking about, which was the lack of representation in AI.

SPEAKER_00: At that time, I guess after Daphne has left, I was the only woman faculty

SPEAKER_01: at Stanford AI lab and we're having very small, around 15 percent of women graduate students,

SPEAKER_00: and we really don't see anybody from the underrepresented minority groups in Stanford AI

SPEAKER_01: underrepresented minority groups in Stanford AI program. And this is a national or even worldwide issue. So it wasn't just Stanford.

SPEAKER_00: Frankly, it still needs a lot of work today.

SPEAKER_01: Exactly. So how do we do this? Well, I got together with my former student, Olga Rusarkovsky, and also a long-term educator of STEM topics, Dr. Rick Sommer, from Stanford pre-collegiate study program, and thought about inviting high schoolers, at that time, women, high school young women, to participate in a summer program to inspire them to learn AI. And that was how it started in 2015. In 2017, we got a lot of encouragement and support from people like Jensen and Lori Huang and Melinda Gates. And we formed the national nonprofit AI for All, which is really committed to training or helping tomorrow's leaders, shaping tomorrow's leaders for AI from students of all walks of life, especially the traditionally underserved and underrepresented communities. And you know till today we've had many many summer camps and summer programs across the country. More than 15 universities are involved. And we have online curriculum to encourage students, as well as college pathway programs to continue to support these students' career by matching them with internships and mentors. So it's a continued effort of encouraging students of all walks of life.

SPEAKER_00: And I remember back then, I think your group was printing these really cool T-shirts that asked the question, AI will change the world, who will change AI? And I thought the answer of making sure everyone can come in and participate, that was a great

SPEAKER_01: answer. Still an important question today.

SPEAKER_00: So that's a great thought and I think that takes us to the end of the interview. Any final thoughts for the people watching this?

SPEAKER_01: This is a very nascent field. As you said, Andrew, we are still in the middle of this. I still feel there's just so many questions that I wake up excited to work on with my students in the lab. I think there's a lot more opportunities for the young people out there who want to learn and contribute and shape tomorrow's AI.

SPEAKER_00: Well said, Fei-Fei. That's very inspiring.

SPEAKER_01: Really great to chat with you and thank you for this video.

SPEAKER_00: Thank you. It's fun to have these conversations.

SPEAKER_01: Always.