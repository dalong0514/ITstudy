## 20250107黄仁勋CES2025演讲

This is how intelligence is made. A new kind of factory, generator of tokens. The building blocks of AI. Tokens have opened a new frontier, the first step into an extraordinary world where endless possibilities are born.

智能就是这样被创造出来的。一种新型的 Token 生成工厂。构成 AI 的基石。Token 开辟了一个新的领域，这是迈向一个非凡世界的第一步，在这里，无限的可能性正在诞生。

Tokens transform words into knowledge and breathe life into images. They turn ideas into videos and help us safely navigate any environment. Tokens teach robots to move like the masters, inspire new ways to celebrate our victories, and give us peace of mind when we need it most. Hi, Maroka. Hi, Emma. It's good to see you again. Hi, Emma. We're going to take a blood sample today, okay? Don't worry I'm going to be here the whole time.

Token 将文字转化为知识，让图像栩栩如生。它们将想法变成视频，并帮助我们在各种环境中安全穿行。Token 教会机器人像高手一样行动，启发我们用新的方式庆祝胜利，并在我们最需要的时候带来安心。你好，Maroka。你好，Emma。很高兴又见到你们了。你好，Emma。我们今天要做个抽血检查，好吗？别担心，我会一直在这里陪着你。

They bring meaning to numbers to help us better understand the world around us, predict the dangers that surround us, and find cures for the threats within us. Tokens can bring our visions to life and restore what we've lost. Zachary, I got my voice back, buddy. They help us move forward, one small step at a time and one giant leap together. And here is where it all begins. Welcome to the stage, NVIDIA founder and CEO, Jensen Wong.

它们让数字变得有意义，帮助我们更好地理解周围的世界，预测我们身边的危险，并找到治愈我们疾病的方法。Token（令牌）可以将我们的愿景变为现实，并恢复我们失去的东西。扎卡里，我又能说话了，伙计。它们帮助我们前进，一步一个脚印，携手迈向未来。这里，一切才刚刚开始。欢迎来到舞台，NVIDIA（英伟达）创始人兼首席执行官，黄仁勋。

Welcome to CES! Are you excited to be in Las Vegas? Do you like my jacket? I thought I'd go the other way from Gary Shapiro. I'm in Las Vegas after all. If this doesn't work out, if all of you object, well just get used to it. I think I really think you have to let this sink in. In another hour or so you're gonna feel good about it.

欢迎来到 CES！来到拉斯维加斯，你是不是很兴奋？你觉得我的夹克怎么样？我寻思着得和 Gary Shapiro 穿得不一样。毕竟我可是在拉斯维加斯。要是大家不喜欢，要是你们都反对，那... 你们就慢慢习惯吧。我觉得这事儿你们得好好琢磨琢磨。再过个把小时，你们就觉得挺不错了。

Well, welcome to NVIDIA. In fact, you're inside NVIDIA's digital twin. And we're gonna take you to NVIDIA. Ladies and gentlemen, welcome to NVIDIA. You're inside our digital twin. Everything here is generated by AI.

欢迎来到英伟达（NVIDIA）。实际上，你现在位于英伟达的数字孪生（digital twin）中。女士们先生们，欢迎来到英伟达，这里的一切都由 AI 生成。

It has been an extraordinary journey, extraordinary year, and it started in 1993. Ready, go! With NV1, we wanted to build computers that can do things that normal computers couldn't. And NV1 made it possible to have a game console in your PC. Our programming architecture was called UDA. Missing the letter C until a little while later, but UDA, Unified Device Architecture. And the first developer for UDA, and the first application that ever worked on UDA, was Sega's Virtual Fighter.

这是一段非凡的旅程，也是非凡的一年，一切都始于 1993 年。预备，开始！我们希望通过 NV1 打造出能够完成普通计算机无法完成之事的计算机。NV1 让在个人电脑（PC）上玩游戏机游戏成为了可能。我们的编程架构叫做 UDA，即统一设备架构（Unified Device Architecture），最初缺少字母 C，过了一段时间才加上。为 UDA 编写代码的第一位开发者，以及第一个在 UDA 上运行的应用程序，是世嘉的《VR 战士》（Virtual Fighter）。

Six years later, we invented in 1999 the programmable GPU. And it started 20 years, 20 plus years of incredible advance in this incredible processor called the GPU. It made modern computer graphics possible. And now, 30 years later, Sega's Virtual Fighter is completely cinematic. This is the new Virtual Fighter project that's coming. I just can't wait. Absolutely incredible.

在（发明固定功能 GPU）六年之后，我们在 1999 年发明了可编程 GPU 。由此开始了在接下来的 20 多年里，名为 GPU 的这种强大处理器令人瞩目的发展。它使得现代计算机图形技术成为可能。而现在，30 年之后，世嘉的《Virtual Fighter》已经完全达到了电影级的效果。这是即将到来的新的《Virtual Fighter》项目。我简直迫不及待了。这真是太不可思议了。

Six years after that, six years after 1999, we invented CUDA so that we could explain or express the programmability of our GPUs to a rich set of algorithms. I could benefit from it. CUDA initially was difficult to explain. And it took years, in fact. It took approximately six years. Somehow, six years later, six years later or so, 2012, Alex Krashevsky, Ilya Suskiver, and Jeff Hinton discovered CUDA, used it to process AlexNet, and the rest of it is history.

在 1999 年之后的六年，也就是六年之后，我们发明了 CUDA，以便能够向各种算法更清晰地展现我们 GPU 的可编程性，这让我受益匪浅。CUDA 最初很难理解，实际上花费了大约六年时间才被接受。大约在六年后的 2012 年左右，Alex Krashevsky、Ilya Suskever 和 Jeff Hinton 发现了 CUDA，并用它处理了 AlexNet，接下来的事情就众所周知了。

AI has been advancing at an incredible pace since. It started with perception AI. We now can understand images and words and sounds. To generative AI, we can generate images and text and sounds. Degenerative AI, we can generate images and texts and sounds. And now, agentic AI, AIs that can perceive, reason, plan, and act. And then the next phase, some of which we'll talk about tonight, physical AI, 2012.

自那之后，人工智能（AI）的发展日新月异。它最初以具备感知能力的人工智能（perception AI）为起点，使我们能够理解图像、文字和声音。随后，发展到生成式 AI（Generative AI）阶段，我们现在可以生成图像、文本和声音。接下来是具备退化能力的人工智能（Degenerative AI），能够生成图像、文本和声音。现在，我们迎来了具备智能体能力的人工智能（agentic AI），即 AI 智能体，它们可以感知、推理、计划和行动。而下一个阶段，我们将会在今晚讨论其中的一部分，是物理 AI（physical AI），时间是 2012 年。

Now, magically, 2018, something happened that was pretty incredible. Google's transformer was released as BERT and the world of AI really took off. Transformers, as you know, completely changed the landscape for artificial intelligence. In fact, completely changed the landscape for artificial intelligence. In fact, it completely changed the landscape for computing altogether.

现在，神奇的是，2018 年发生了一件非常了不起的事情。谷歌的 Transformer 模型以 BERT 的形式发布，人工智能（AI）的世界由此开始蓬勃发展。正如大家所知，Transformer 模型彻底改变了人工智能领域的格局。事实上，它甚至完全改变了整个计算领域的格局。

We recognized properly that AI was not just a new application with a new business opportunity, but AI, more importantly, machine learning enabled by transformers, was going to fundamentally change how computing works. And today, computing is revolutionized in every single layer, from hand coding, instructions that run on CPUs to create software tools that humans use. We now have machine learning that creates and optimizes neural networks that processes on GPUs and creates artificial intelligence. Every single layer of the technology stack has been completely changed. An incredible transformation in just 12 years.

我们很早就意识到，人工智能不仅仅是一个新应用，它带来了新的商机。更重要的是，基于 Transformer 的机器学习将从根本上改变计算的工作方式。如今，计算的每一层都发生了革命性的变化，从最初的手工编码和在 CPU 上运行的指令，到创建人类使用的软件工具，都发生了翻天覆地的变化。现在，机器学习可以创建和优化在 GPU 上运行的神经网络，从而创造出人工智能。技术的每一层都已彻底改变。短短 12 年，就发生了如此巨大的变革。

Well, we can now understand information of just about any modality. Surely you've seen text and images and sounds and things like that. But not only can we understand those, we can understand amino acids. We can understand physics. We understand them. We can translate them and generate them. The applications are just completely endless. In fact, almost any AI application that you see out there, what modality is the input that it learned from, what modality of information did it translate to, and what modality of information is it generating if you ask these three fundamental questions? Just about every single application could be inferred. And so when you see application after applications that are AI driven, AI native, at the core of it this fundamental concept is there. Machine learning has changed how every application is going to be built, how computing will be done, and the possibilities beyond.

好的，我们现在可以理解几乎任何形式的信息。你肯定见过文本、图像和声音等等。但我们不仅能理解这些，还能理解氨基酸和物理学。我们理解它们，可以翻译它们，也可以生成它们。这些应用的前景非常广阔。事实上，你看到的几乎任何 AI 应用，都可以通过这三个基本问题来理解：它从什么形式的输入信息中学习？它将信息翻译成什么形式？以及它生成什么形式的信息？几乎所有应用都可以通过这种方式理解。因此，当你看到一个又一个以 AI 驱动、以 AI 为核心的应用出现时，你会发现这个基本概念贯穿其中。机器学习已经改变了每个应用的构建方式、计算的方式，以及未来的各种可能性。

Well, GPUs, G-Force, in a lot of ways, all of this with AI is the house that G-Force built. G-Force enabled AI to reach the masses. And now, AI is coming home to G-Force. There are so many things that you can't do without AI. Let me show you some of it now. Thank you.

好的，GPU，G-Force，在很多方面，可以说 AI 的发展都离不开 G-Force 奠定的基础。G-Force 使 AI 能够普及大众。现在，AI 的发展反过来也推动 G-Force 的进步。很多事情都需要 AI 的支持。接下来给大家展示一些例子。谢谢。

The End. That was real-time computer graphics. No computer graphics researcher, no computer scientist, would have told you that it is possible for us to ray trace every single pixel at this point. Ray tracing is a simulation of light. The amount of geometry that you saw was absolutely insane. It would have been impossible without artificial intelligence.

这就是实时的计算机图形技术。任何计算机图形研究人员或计算机科学家，在过去都难以想象我们现在能够做到对每一个像素进行光线追踪。光线追踪是对光线传播的模拟。刚才大家看到的几何体数量之庞大，是难以置信的。如果没有人工智能，这一切根本不可能实现。

There are two fundamental things that we did. We used, of course, programmable shading and ray-traced acceleration to produce incredibly beautiful pixels. But then we have artificial intelligence be conditioned, be controlled by that pixel to generate a whole bunch of other pixels. Not only is it able to generate other pixels spatially because it's aware of what the colors should be, it has been trained on a supercomputer back in NVIDIA and so the neural network that's running on the GPU can infer and predict the pixels that we did not render.

我们主要完成了两项核心工作。首先，我们利用可编程着色与光线追踪加速技术，生成了极其精美的像素点。其次，我们利用这些像素点来引导和控制人工智能，使其生成更多其他的像素点。人工智能不仅可以在空间上生成新的像素点（因为它理解色彩应该如何分布），而且还在 NVIDIA 的超级计算机上接受了训练。因此，在 GPU 上运行的神经网络能够推断和预测那些我们没有渲染的像素。

Not only can we do that, it's called DLSS, the latest generation of DLSS also generates beyond frames. It can predict the future, generating three additional frames for every frame that we calculate. What you saw, if we just said four frames of what you saw, because we're going to render one frame and generate three, if I said four frames at full HD, 4K, that's 33 million pixels or so, out of that 33 million pixels, we computed only two. It is an absolute miracle that we can computationally, computationally using programmable shaders and our ray tracing engine to compute 2 million pixels and have AI predict all of the other 33. And as a result, we're able to render at incredibly high performance because AI does a lot less computation.

我们不仅可以做到这一点，它叫做 DLSS（Deep Learning Super Sampling），最新一代的 DLSS 技术甚至可以生成额外的帧。它可以预测未来，对每一帧生成三个额外的帧。比如，我们看到的是四帧画面，实际上我们只渲染了一帧，另外三帧是由 AI 生成的。如果这四帧画面的分辨率是全高清或 4K，那就是大约 3300 万像素。在这 3300 万像素中，我们只计算了 200 万像素。这是一个绝对的奇迹，我们仅使用可编程着色器和光线追踪引擎计算 200 万像素，就让 AI 预测其余的 3100 万像素。因此，由于 AI 大大减少了计算量，我们可以用极高的性能进行渲染。

It takes, of course, an enormous amount of training to produce that, but once you train it, the generation is extremely efficient. So this is one of the incredible capabilities of artificial intelligence, and that's why there's so many amazing things that are happening. We used G-Force to enable artificial intelligence, and now artificial intelligence is revolutionizing G-Force.

当然，这需要大量的训练才能实现，但一旦完成训练，生成效率就极高。这是人工智能令人惊叹的能力之一，也是为什么会出现这么多奇迹般进展的原因。我们曾利用 G-Force 来推动人工智能的发展，而现在，人工智能正在彻底革新 G-Force。

Everyone, today we're announcing our next generation, the RTX Blackwell family. Let's take a look. The End. I'm sorry. Here it is. Our brand new GeForce RTX 50 series Blackwell architecture, the GPU is just a beast. 92 billion transistors, 4,000 tops, four petaflops of AI, three times higher than the last generation ADA, and we need all of it to generate those pixels that I showed you.

大家好，今天我们宣布下一代产品，RTX Blackwell 系列。让我们一起看看。稍等一下，不好意思，马上开始。这就是我们全新的 GeForce RTX 50 系列 Blackwell 架构，这块 GPU 性能非常强大。它拥有 920 亿个晶体管，算力高达 4,000 TOPS（万亿次操作每秒），AI 性能达到 4 Petaflops（千万亿次浮点运算每秒），是上一代 ADA 的三倍。我们需要如此强大的性能，才能生成刚才展示的那些像素。

380 ray tracing teraflops so that we could for the pixels that we have to compute, compute the most beautiful image you possibly can. And of course 125 shader teraflops, there is actually a concurrent shader teraflops as well as an integer unit of equal performance, so two dual shaders, one is for floating point, one is for integer. G7 memory from Micron, 1.8 terabytes per second, twice the performance of our last generation, and we now have the ability to intermix AI workloads with computer graphics workloads. And one of the amazing things about this generation is the programmable shader is also able to now process neural networks. So the shader is able to carry these neural networks and as a result we invented neural texture compression and neural material shading. As a result of that you get these amazingly beautiful images that are only possible because we use AIs to learn the texture, learn the compression algorithm, and as a result, get extraordinary results.

拥有 380 teraflops 的光线追踪性能，我们可以为每一个需要计算的像素，渲染出尽可能精美的图像。同时，还有 125 teraflops 的着色器性能，实际上，着色器单元还拥有等同性能的并发整数运算单元。因此，总共有两个着色器单元，一个处理浮点运算，另一个处理整数运算。采用美光 G7 显存，带宽高达每秒 1.8 太字节，是上一代产品的两倍。我们现在还能够将 AI 工作负载与计算机图形工作负载混合处理。这一代产品最令人瞩目的创新之一是，可编程着色器现在也能够处理神经网络。着色器能够运行这些神经网络，因此我们开发出了神经纹理压缩和神经材质着色技术。得益于此，我们能够获得极其精美的图像，而这完全是因为我们利用 AI 来学习纹理和压缩算法，最终取得了卓越的成果。

Okay, so this is the brand new RTX Blackwell 59 Blackwell, 59. Now, even the mechanical design is a miracle. Look at this, it's got two fans. This whole graphics card is just one giant fan. You know, so the question is, where's the graphics card? Is it literally this big? The voltage regular to design is state-of-the-art, incredible design. The engineering the art, incredible design. The engineering team did a great job. So here it is. Thank you.

好的，这是全新的 RTX Blackwell 59。现在，就连它的机械设计也堪称奇迹。看看这个，它配备了两个风扇，整个显卡看起来就像一个巨大的散热风扇。那么问题来了，显卡的核心在哪里？它真的有这么大吗？其电压调节器采用了最先进的设计，令人惊叹。工程团队将工程技术与艺术完美结合，设计非常出色。工程团队做得非常棒。这就是它了。谢谢。

Okay, so those are the speeds and feeds. So how does it compare? Well, this is RTX 4090. I know, I know many of you have one. I know it. Look, it's $1,599. It is your $10,000 PC entertainment command center. Isn't that right? Don't tell me that's not true. Don't be ashamed. It's liquid cooled. Fancy lights all over it. You lock it when you leave. It's the modern home theater. It makes perfect sense. And now for $1599, you get to upgrade that and turbo charge the living daylights out of it.

好的，这些就是它的性能参数。那么它性能如何呢？好的，这是 RTX 4090。我知道，我知道你们很多人都有一个。我了解的。看，它售价 1599 美元。它是你价值 10000 美元的电脑娱乐中心。没错吧？别说不是。不用不好意思。它是液冷的，全身都有炫酷的灯光。你离开的时候还会把它锁起来。它就是现代的家庭影院。这很合理。现在，只需 1599 美元，你就能升级它，让它的性能彻底爆发。

Well, now with the Blackwell family, RTX 5070, 4090 performance at 549. Impossible without artificial intelligence. Impossible without the four tops, four teraes of AI tensor cores, impossible without the G7 memories. Okay, so 5070, 4090 performance, $549, and here's the whole family. Starting from 5070 all the way up to 5090, 5090, twice the performance of a 4090.

好的，现在有了 Blackwell 系列，RTX 5070 显卡，以 549 美元的价格达到了 4090 显卡的性能。这如果没有人工智能（Artificial Intelligence）是不可能实现的。如果没有顶级的、拥有 4 tera 的 AI 张量核心，以及 G7 显存也是不可能实现的。好的，所以 5070 显卡达到 4090 显卡的性能，售价 549 美元，这就是整个 Blackwell 系列的显卡。从 5070 一直到 5090，其中 5090 的性能是 4090 的两倍。

Starting, of course, we're producing a very large scale availability starting January. Well it is incredible but we managed to put these in gigantic performance GPUs into a laptop. This is a 5070 laptop for 1299. This 5070 laptop. For $12.99, this 5070 laptop has a 4090 performance. I think there's one here somewhere. Let me show you this. This is a, look at this thing. Here, let me, here. There's only so many pockets. Ladies and gentlemen, Janine Paul.

当然，首先，我们从一月份开始就会大规模供货。这真的令人难以置信，我们竟然成功地将如此强大的 GPU 集成到了笔记本电脑中。这是一款 5070 型号的笔记本电脑，售价 1299 美元。这款 5070 笔记本电脑的性能却能媲美 4090 显卡。我想这里应该有一台样机。让我给你们展示一下。看，就是这个。稍等一下，我找找。口袋就这么几个。女士们先生们，下面有请 Janine Paul。

So can you imagine? You've got this incredible graphics card here, Blackwell. We're going to shrink it and put it in there. Does that make any sense? Well, you can't do that without artificial intelligence. And the reason for that is because we're generating most of the pixels using our tensor cores. So we ray trace only the pixels we need and we generate using artificial intelligence all the other pixels we have. As a result, the amount of energy efficiency is just off the charts. The future of computer graphics is neural rendering, the fusion of artificial intelligence and computer graphics.

那么，你能想象一下吗？你拥有一张性能卓越的 Blackwell 显卡。我们计划将其小型化并集成到设备中。这听起来是不是很不可思议？要实现这一目标，人工智能必不可少。这是因为我们主要利用张量核心来生成像素。具体来说，我们只对需要的像素进行光线追踪，而其余的像素则通过人工智能生成。如此一来，能效便实现了惊人的提升。计算机图形学的未来在于神经渲染，它是人工智能与计算机图形学的完美结合。

And what's really amazing is, oh, here we go. Thank you. This is a surprisingly kinetic keynote. And what's really amazing is the family of GPUs we're going to put in here. And so the 5090, the 5090 will fit into a laptop, a thin laptop. That last laptop was 14, 14.9 millimeters. You got a 5080, 5070 Ti, and 5070. Okay, so ladies and gentlemen, the RTX Blackwell family.

好的，我们开始吧。谢谢。这次的主题演讲节奏很快，令人意外。真正令人惊奇的是我们即将推出的 GPU 系列。其中，5090 将适用于轻薄笔记本电脑。上一代产品的厚度仅有 14.9 毫米。还有 5080、5070 Ti 和 5070 型号。女士们先生们，RTX Blackwell 系列。

Well, GeForce brought AI to the world, democratized AI. Now AI has come back and revolutionized GeForce. Let's talk about artificial intelligence. Let's go to somewhere else at NVIDIA. This is literally our office. This is literally NVIDIA's headquarters.

GeForce 将人工智能（Artificial Intelligence）带给大众，使其得以普及。如今，人工智能反过来又彻底革新了 GeForce。接下来，我们来聊聊人工智能。让我们前往英伟达（NVIDIA）的其他部门看看。这里正是我们的办公场所，也是英伟达的总部所在地。

Okay, so let's talk about AI. The industry is chasing and racing to scale artificial intelligence. And the scaling law is a powerful model. It's an empirical law that has been observed and demonstrated by researchers and industry over several generations. And's the the scale the scaling laws says that the more data you have, the training data that you have, the larger model that you have and the more compute that you apply to it therefore the more effective or the more capable your model will become. And so the scaling law continues. What's really amazing is that now we're moving towards, of course, and the Internet is producing about twice the amount of data every single year as it did last year. I think in the next couple of years we'll produce, humanity will produce more data than all of humanity has ever produced since the beginning. And so we're still producing a gigantic amount of data, and it's becoming more multimodal. Video and images and sound, all of that data could be used to train the fundamental knowledge, the foundational knowledge of an AI.

好的，我们来聊聊人工智能（AI）。业界正在竞相扩大人工智能的规模。而规模扩展定律（Scaling Law）是一个强大的模型。这是一个经验法则，研究人员和业界已经观察并验证了这一法则几代。规模扩展定律指出，训练数据越多，模型越大，投入的计算资源越多，模型的性能和能力就越强。规模扩展效应仍在持续。令人惊讶的是，我们正朝着这个方向快速发展。互联网每年产生的数据量大约是上一年的两倍。我认为在未来几年，人类产生的数据量将超过自人类文明开始以来所有数据的总和。我们仍在产生海量数据，而且这些数据正变得更加多模态，包括视频、图像和声音。所有这些数据都可以用来训练 AI 的基础知识。

But there are, in fact, two other scaling laws that has now emerged. And it's somewhat intuitive. The second scaling law is post-training scaling law. Post-training scaling law uses technologies, techniques like reinforcement learning, human feedback. Basically, the AI produces and generates answers based on a human query. The human then of course gives a feedback. It's much more complicated than that, but that reinforcement learning system with a fair number of very high quality prompts causes the AI to refine its skills. It could fine tune its skills for particular domains. It could be better at solving math problems, better at reasoning, so on and so forth. And so it's essentially like having a mentor or having a coach give you feedback after you're done going to school. And so you get tests, you get feedback, you improve yourself.

但事实上，现在出现了另外两个扩展规律（scaling law）。这在某种程度上是直观的。第二个扩展规律是训练后扩展规律（post-training scaling law）。训练后扩展规律使用诸如强化学习（reinforcement learning)、人类反馈之类的技术。基本上，AI 根据人类的查询生成答案。然后，人类会给出反馈。实际情况比这复杂得多，但是使用大量高质量提示的强化学习系统会导致 AI 改进其技能。它能够针对特定领域微调技能。它可以更好地解决数学问题，更好地进行推理，诸如此类。因此，它本质上就像有一个导师或教练在你完成学业后给你反馈。通过考试获得反馈，从而提高自己。

We also have reinforcement learning AI feedback, and we have synthetic data generation. These techniques are rather akin to, if you will, self-practice. You know the answer to a particular problem, and you continue to try it until you get it right. And so an AI could be presented with a very complicated and a difficult problem that is verifiable functionally and has an answer that we understand. Maybe proving a theorem, maybe solving a geometry problem. And so these problems would cause the AI to produce answers and using reinforcement learning, you would learn how to improve itself. That's called post training. Post training requires enormous amount of computation, but the end result produces incredible models.

我们还有强化学习 AI 反馈和合成数据生成技术。这些技术很像自我练习。你知道某个特定问题的答案，然后不断尝试，直到得到正确答案。因此，我们可以给 AI 呈现一个非常复杂且难以解决的问题，这个问题的功能是可验证的，并且我们知道正确答案。例如，证明一个定理或解决一个几何问题。这些问题会促使 AI 生成答案，然后通过强化学习，AI 将学习如何自我改进。这被称为后训练。后训练需要大量的计算资源，但最终会产生非常强大的模型。

We now have a third scaling law, and this third scaling law has to do with what's called test time scaling. Test time scaling is basically when you're being used. When you're using the AI, the AI has the ability to now apply a different resource allocation instead of improving its parameters. Now it's focused on deciding how much computation to use to produce the answers it wants to produce. Reasoning is a way of thinking about this long thinking is a way to think about this. Instead of a direct inference or one-shot answer, you might reason about it. You might break down the problem into multiple steps. You might generate multiple ideas and evaluate, you know, your AI system would evaluate which one of the ideas that you generated was the best one. Maybe it solves the problem step by step, so on and so forth. And so now test time scaling has proven to be incredibly effective.

我们现在有了第三个缩放定律，它与所谓的测试时间缩放有关。测试时间缩放主要指 AI 被实际使用时的情况。当用户使用 AI 时，AI 可以调整资源分配，而不再是单纯地优化自身参数。此时，AI 的重点是如何利用计算资源来生成所需的答案。推理是理解这种「长时间思考」的一种方式。它不像直接推断或一次性回答那样，而是需要进行推理。可以将问题分解为多个步骤，或者生成多个想法并进行评估。AI 系统会评估哪个想法是最佳的。例如，AI 可能会逐步解决问题。测试时间缩放已被证明非常有效。

You're watching this sequence of technology and this all of these scaling laws emerge as we see incredible achievements from ChatGPT to 01 to 03, and now Gemini Pro. All of these systems are going through this journey step by step by step of pre-training to post-training to test time scaling. Well, the amount of computation that we need, of course, is incredible. And we would like, in fact, we would like, in fact, that society has the ability to scale the amount of computation to produce more and more novel and better intelligence. Intelligence, of course, is the most valuable asset that we have, and it can be applied to solve a lot of very challenging problems. And so, scaling law. It's driving enormous demand for NVIDIA computing. It's driving enormous demand for this incredible chip we call Blackwell. Let's take a look at Blackwell.

你正在见证科技的飞速发展，以及伴随其涌现的各种扩展定律。从 ChatGPT 到 01、03，再到现在的 Gemini Pro，我们看到了一个又一个令人惊叹的成就。这些系统都在经历着一个逐步演进的过程，从预训练到后训练，再到测试时的扩展。当然，这其中所需的计算量是巨大的。实际上，我们都希望社会有能力不断提升计算能力，从而产生更多、更新、更优秀的智能。毕竟，智能是我们拥有的最宝贵的财富，它能被应用于解决许多极具挑战性的难题。正是因为这些扩展定律，才驱动了对 NVIDIA 计算的巨大需求，也驱动了对我们称之为 Blackwell 这种强大芯片的巨大需求。接下来，让我们一起了解一下 Blackwell。

Well, Blackwell is in full production. It is incredible what it looks like. So first of all, every single Cloud service provider now has systems up and running. We have systems here from about 15 computer makers. It's being made about 200 different SKUs, 200 different configurations. They're liquid cooled, air cooled, x86, NVIDIA gray CPU versions, NVLink 36 by 2, NVLink 72 by 1, whole bunch of different types of systems so that we can accommodate just about every single data center in the world.

好的，Blackwell 正在全面量产。它的外观令人惊叹。首先，现在每个云服务提供商的系统都已经上线运行。我们这里有大约 15 家计算机制造商的系统。它正在生产大约 200 种不同的 SKU 和 200 种不同的配置。这些系统包括液冷、风冷、x86 架构、英伟达灰色 CPU 版本、NVLink 36x2 以及 NVLink 72x1 等多种不同类型，以便能够满足世界上几乎所有数据中心的需求。

Well, these systems are being currently manufactured in some 45 factories. It tells you how pervasive artificial intelligence is and how much the industry is jumping onto artificial intelligence in this new computing model. Well, the reason why we're driving it so hard is because we need a lot more computation. And it's very clear that.. Janine? You know, it's hard to tell, you don't ever wanna reach your hands into a dark place. Hang on a second, is this a good idea? All right. Wait for it. Wait for it. I thought I was worthy. Apparently Yonir didn't think I was worthy. All right. This is my show and tell. This is a show and tell. This is a show and tell.

目前，这些系统在约 45 家工厂进行生产。这足以说明人工智能的普及程度，以及在这个新的计算模式下，整个行业对人工智能的投入是多么巨大。我们如此大力推动人工智能发展的原因，是因为我们需要更强大的算力。而且很明显… Janine？ 你知道，这很难说，你永远不想贸然涉险。等一下，这样做真的好吗？ 好吧，稍等。稍等。我本以为我能胜任。显然 Yonir 并不认为我能胜任。好吧。这就是我的展示环节。这就是一个展示环节。这就是一个展示环节。

So this MVLink system, this right here, this MVLink system, this is GB200 MVLink 72. It is one and a half tons, 600,000 parts, approximately equal to 20 cars. 12, 120 kilowatts. it has a spine behind it that connects all of these GPU together, two miles of copper cable, 5, 5000 cables. This is being manufactured in 45 factories around the world. We build them, we liquid cool them, we test them, we disassemble them, ship them in parts to the data centers because it's one and a half tons. We reassemble it outside the data centers and install them. The manufacturing is insane.

所以这个 MVLink 系统，你看，这个 MVLink 系统，是 GB200 MVLink 72。它的重量有一吨半，由 60 万个零件组成，其复杂程度大约相当于 20 辆汽车。它的功率为 12,120 千瓦。它背面有一个主干，用于连接所有这些 GPU，使用了两英里的铜缆和 5000 根电缆。它正在全球 45 家工厂进行制造。我们制造、液冷、测试、拆卸这些系统，然后以部件形式运送到数据中心，因为它太重了，有一吨半。我们在数据中心外重新组装并安装它们。其制造过程堪称复杂至极。

But the goal of all of this is because the scaling laws are driving computing so hard that this level of computation, Blackwell over our last generation, improves the performance per watt by a factor of four. Performance per watt by a factor of four, performance per dollar by a factor of three. That basically says that in one generation, we reduce the cost of training these models by a factor of three. Or if you wanna increase the size of your model by a factor of three, it's about the same cost. But the important thing is this. These are generating tokens that are being used by all of us when we use ChatGPT or when we use Gemini and use our phones in the future, just all of these applications are going to be consuming these AI tokens. These AI tokens are being generated by these systems. Every single data center is limited by power. So if the perp per watt of Blackwell is four times our last generation, then the revenue that could be generated, the amount of business that could be generated in the data center is increased by a factor of four. And so these AI factory systems really are factories today.

但这一切的目标，都是因为规模效应正在推动计算能力飞速发展。这种计算水平的提升，使得 Blackwell 相比上一代产品，每瓦特的性能提高了四倍，每美元的性能提高了三倍。这意味着，在短短一代产品的迭代中，训练这些模型的成本就降低了三倍。或者说，如果想将模型规模扩大三倍，成本基本保持不变。但最重要的是：当我们使用 ChatGPT 或 Gemini，以及未来在手机上使用各种应用时，我们所使用的 Token，正是由这些系统生成的。这些 AI Token 正被各种应用消耗着。每个数据中心都面临电力供应的限制。因此，如果 Blackwell 的每瓦特性能是上一代产品的四倍，那么数据中心所能产生的收入和业务量也将随之增加四倍。所以，这些 AI 工厂系统如今就像真正的工厂一样运转。

Now the goal of all of this is to so that we can create one giant chip. The amount of computation we need is really quite incredible and this is basically one giant chip. If we would have had to build a chip, one, here we go, sorry guys, you see that? That's cool. Look at that, disco lights in here. If we had to build this as one chip, obviously this would be the size of the wafer, but this doesn't include the impact of yield. It would have to be probably three or four times the size. But what we basically have here is 72 black wall GPUs or 144 dies. This one chip here is 1.4 exaflops. The world's largest supercomputer, fastest supercomputer only recently, this entire room supercomputer only recently achieved an exaflop plus. This is 1.4 exaflops of AI floating point performance. It has 14 terabytes of memory but here's the amazing thing the memory bandwidth is 1.2 petabytes per second.

现在，所有这一切的目标是为了创建一个巨大的芯片。我们需要的计算量非常惊人，这实际上就是一个巨大的芯片。如果我们必须构建这样一个芯片，大家看，这里有点像迪斯科灯光，这挺酷的。如果将它制成单个芯片，它将达到晶圆尺寸，并且这还没有考虑良率问题。但我们这里实际上有 72 个黑墙 GPU 或 144 个芯片。这个芯片的算力为 1.4 exaflops。之前，世界最快超级计算机的算力才刚刚达到每秒百亿亿次浮点运算以上，而这个房间里的整个超级计算机的算力也只是刚刚达到这个级别。而这一个芯片就拥有 1.4 exaflops 的人工智能浮点计算性能。它拥有 14 TB 的内存，更令人惊叹的是，其内存带宽高达每秒 1.2 PB。

That's basically the entire internet traffic that's happening right now. The entire world's internet traffic is being processed across these chips. And we have 130 trillion transistors in total, 2,592 CPU cores, a whole bunch of networking. And so these, I wish I could do this I don't think I will. So these are the Blackwells. These are our ConnectX networking chips. These are the NVLink, and we're trying to pretend about the NVLink spine, but that's not possible. And these are all of the HBM memories, 14 terabytes of HBM memory. This is what we're trying to do, and this is the miracle of the black wall system.

这几乎是当前整个互联网的流量总和。全球的互联网数据都在这些芯片上进行处理。总计，我们拥有 130 万亿个晶体管、2,592 个 CPU 核心，以及强大的网络连接能力。这些，我真希望我能演示一下，但我觉得我做不到。这些就是 Blackwell 芯片。这些是我们的 ConnectX 网络芯片。这些是 NVLink，我们试图忽略 NVLink 的主干连接，但这不太可能。这些是所有的 HBM 内存，总共 14 TB 的 HBM 内存。这就是我们正在努力实现的，也是 Blackwell 系统的强大之处。

The black wall dies right here. It is the largest single chip the world's ever made. But yet, the miracle is really, in addition to that, this is the grace black wall system. Well the goal of all of this, of course, is so that we can.. Thank you, thanks. Boy, is there a chair I could sit down for a second? Thank you, thanks. Boy, is there a chair I could sit down for a second? Can I have a Michelob Ultra? How is it possible that we're in the Michelob Ultra stadium? It's like coming to NVIDIA and we don't have a GPU for you. It's like coming to NVIDIA and we don't have a GPU for you.

黑墙到此为止。它是目前世界上最大的单芯片。但更令人惊叹的是，它还构成了一套精密的黑墙系统。当然，我们做这一切的目标是为了... 谢谢，谢谢。哎呀，有没有椅子可以让我坐一会儿？谢谢，谢谢。哎呀，有没有椅子可以让我坐一会儿？能给我来一杯米凯罗啤酒吗？我们竟然身处米凯罗体育场，这真是太不可思议了。这就像来到 NVIDIA 公司，却发现我们没有 GPU 提供给你。这就像来到 NVIDIA 公司，却发现我们没有 GPU 提供给你。

So we need an enormous amount of computation because we want to train larger and larger models. And these inferences used to be one inference, but in the future, the AI is going to be talking to itself. It's going to be thinking. It's going to be internally reflecting, processing. So today, when the tokens are being generated at you, so long as it's coming out at 20 or 30 tokens per second, it's basically as fast as anybody can read. However, in the future, and right now with GPT-01, with the new Gemini Pro and the new G, the 01, 03 models, they're talking to themselves, reflecting, they're thinking. And so as you can imagine, the rate at which the tokens could be ingested is incredibly high.

因此，我们需要大量的计算资源，因为我们需要训练越来越大的模型。过去，模型的推理过程只进行一次，但未来，AI 将能够自言自语，进行思考和内部处理。现在，当模型以每秒 20 或 30 个 Token 的速度生成内容时，其速度基本上与人们的阅读速度相当。然而，在未来，包括现在的 GPT-01、Gemini Pro 以及 G 系列的 01 和 03 模型，它们都在进行自我对话和思考。可以预见，Token 的处理速度将会变得非常快。

And so we need the token rates, the token generation rates to go way up. And we also have to drive the cost way down simultaneously so that the quality of service can be extraordinary, the cost to customers can continue to be low, and AI will continue to scale. And so that's the fundamental purpose, the reason why we created MVLink. Well, one of the most important things that's happening in the world of enterprise is agentic AI. Agentic AI basically is a perfect example of test time scaling. AI is a system of models, some of it is understanding, interacting with the customer, interacting with the user, some of it is maybe retrieving information, retrieving information from storage, a semantic AI system like a reg, maybe it's going on to the internet, maybe it's studying a PDF file, and so it might be using tools, it might be using a calculator, and it might be using a generative AI to generate charts and such. And it's taking the problem you gave it, breaking it down step-by-step, and it's iterating through all these different models.

因此，我们需要大幅提升 Token 的处理速度和生成速度。与此同时，我们还必须大幅降低成本，这样才能保证卓越的服务质量，客户的成本才能持续降低，AI 也才能不断扩展。这正是我们创建 MVLink 的根本原因。企业界目前最重要发展趋势之一就是 AI 智能体（Agentic AI）。AI 智能体是测试时扩展的绝佳范例。AI 是一个由多个模型构成的系统，其中一些模型负责理解并与客户或用户交互，另一些模型可能负责从存储中检索信息，例如语义 AI 系统，或者访问互联网，或是研究 PDF 文件。因此，它可能会使用各种工具，例如计算器，或者利用生成式 AI（Generative AI）生成图表等等。它会接收你提出的问题，然后逐步分解，并遍历所有这些不同的模型来解决问题。

Well, in order to respond to a customer in the future, in order for AI to respond, it used to be ask a question, answer starts spewing out. In the future, you ask a question, a whole bunch of models are going to be working in the background. And so test time scaling, the amount of computation used for inferencing is going to go through the roof. It's going to go through the roof because we want better and better answers. Well, to help the industry build agentic AI, our go-to-market is not direct to enterprise customers. Our go-to-market is we work with software developers in the IT ecosystem to integrate our technology to make possible new capabilities, just like we did with CUDA libraries, we now want to do that with AI libraries. And just as the computing model of the past has APIs that are doing computer graphics or doing linear algebra or doing fluid dynamics, in the future on top of those acceleration libraries, CUDA acceleration libraries, we'll have AI libraries.

好的，为了将来 AI 能够更好地回应客户，过去的方式是提出一个问题，答案会立即给出。而未来，当你提出一个问题时，会有许多模型在后台协同工作。因此，在推理阶段，计算量将会大幅增加。计算量之所以会大幅增加，是因为我们想要得到越来越好的答案。为了帮助业界构建 AI 智能体（AI Agent），我们的市场推广方式不是直接面向企业客户。我们的市场推广方式是与 IT 生态系统中的软件开发者合作，集成我们的技术来实现新的功能。就像我们之前使用 CUDA 库一样，现在我们希望通过 AI 库来实现这一点。正如过去的计算模型拥有执行计算机图形、线性代数或流体动力学的 API 一样，未来，在这些加速库，也就是 CUDA 加速库的基础上，我们将会有 AI 库。

We've created three things for helping the ecosystem build agentic AI. NVIDIA NIMS, which are essentially AI microservices all packaged up. It takes all of this really complicated Cuda software, Cuda DNN, Cutlass, or TensorRTLM, or Triton, all of these different really complicated software, and the model itself, we package it up, we optimize it, we put it into a container, and you can take it wherever you like. And so we have models for vision, for understanding languages, for speech, for animation, for digital biology, and we have some new exciting models coming for physical AI. And these AI models run in every single cloud, because NVIDIA's GPUs are now available in every single cloud, it's available in every single OEM, so you could literally take these models, integrate it into your software packages, create AI agents that run on Cadence, or they might be ServiceNow agents, or they might be SAP agents, and they could deploy it to their customers and run it wherever the customers want to run the software.

我们创造了三件事来帮助生态系统构建 AI 智能体。NVIDIA NIMS，它们本质上是打包好的 AI 微服务。它整合了所有复杂的 Cuda 软件，例如 Cuda DNN、Cutlass、TensorRTLM、Triton 等，以及模型本身。我们将其打包、优化并放入容器中，您可以将其部署到任何地方。因此，我们有用于视觉、语言理解、语音、动画和数字生物学的模型，并且还有一些令人兴奋的物理 AI 新模型即将推出。这些 AI 模型可以在所有云平台中运行，因为 NVIDIA 的 GPU 现已在所有云平台和所有 OEM（原始设备制造商）中可用。因此，您可以直接使用这些模型，将其集成到您的软件包中，创建在 Cadence、ServiceNow 或 SAP 等平台上运行的 AI 智能体，并将其部署给客户，让客户在他们希望运行软件的任何地方运行。

The next layer is what we call NVIDIA NEMO. NEMO is essentially a digital employee onboarding and training evaluation system. In the future these AI agents are essentially digital workforce that are working alongside your employees, working a lot doing things for you on your behalf. And so the way that you would bring these specialized agents into your, these special agents into your company is to onboard them just like you onboard an employee. And so we have different libraries that helps these AI agents be trained for the type of language in your company, maybe the vocabulary is unique to your company, the business process is different, the way you work is different. So you would give them examples of what the work product should look like and they would try to generate and you would give them examples of what the work product should look like. And they would try to generate it and you would give a feedback. And then you would evaluate them, so on and so forth. And so that, and you would guard rail them. You say these are the things that you're not allowed to do. These are the things you're not allowed to say. And we even give them access to certain information.

下一层我们称为 NVIDIA NEMO。NEMO 实际上是一个数字员工入职和培训评估系统。未来，这些 AI 智能体将成为与你的员工并肩工作的数字劳动力，代表你完成大量任务。因此，引入这些专业智能体的方式，就如同为新员工办理入职一样。我们提供不同的工具库，帮助这些 AI 智能体学习你公司特有的语言，包括可能独特的词汇、不同的业务流程以及特定的工作方式。你会提供工作成果的示例，AI 智能体会尝试生成类似的结果，并根据你的反馈进行调整。接下来，你会对它们进行评估，并设置行为规范，明确它们不能做和不能说的事情。我们还会赋予它们访问特定信息的权限。

Okay, so that entire pipeline, digital employee pipeline, is called Nemo. In a lot of ways, the IT department of every company is going to be the HR department of AI agents in the future. Today, they manage and maintain a bunch of software from the IT industry. In the future, they'll maintain, nurture, onboard, and improve a whole bunch of digital agents and provision them to the companies to use. And so your IT department is going to become kind of like AI agent HR. And on top of that, we provide a whole bunch of blueprints that our ecosystem could take advantage of. All of this is completely open source, and so you could take it and modify the blueprints. We have blueprints for all kinds of different types of agents.

整个数字员工流程被称为 Nemo。从很多方面来看，未来每家公司的 IT 部门都将成为 AI 智能体（AI Agent）的人力资源部门。如今，他们管理和维护着来自 IT 行业的大量软件。未来，他们将维护、培养、引导和改进大量的数字智能体，并将其配置给公司使用。因此，IT 部门将变得更像是 AI 智能体的人力资源部。此外，我们还提供许多蓝图，供我们的生态系统使用。所有这些都是完全开源的，因此您可以获取并修改这些蓝图。我们为各种不同类型的智能体提供了蓝图。

Well today we're also announcing that we're doing something that's really cool and I think really clever. We're announcing a whole family of models that are based off of LAMA, the NVIDIA LAMA NemoTron language foundation models. LAMA 3.1 is a complete phenomenon. The download of LAMA 3.1 from Meta, 650,000 times, something like that, it has been derived and turned into other models, about 60,000 other different models. It is singularly the reason why just about every single enterprise and every single industry has been activated to start working on AI.

好的，今天我们还要宣布一项非常酷且我认为非常巧妙的举措。我们正在发布一系列基于 LAMA 的模型，即 NVIDIA LAMA NemoTron 语言基础模型。LAMA 3.1 的现象级表现令人瞩目。LAMA 3.1 从 Meta 的下载次数约为 65 万次，并被衍生出约 6 万个其他模型。这极大地推动了几乎每个企业和行业开始研究人工智能（AI）。

Well, the thing that we did was we realized that the Lama models really could be better fine-tuned for enterprise use. So we fine-tune them using our expertise and our capabilities and we turn them into the Lama Nemo Tron suite of open models. There are small ones that interact in very very fast response time, extremely small. They're what we call super Lama Nemo Tron supers. They're basically your mainstream versions of your models or your ultra model the ultra model could be used to be a teacher model for a whole bunch of other models it could be a reward model evaluator a judge for other models to create answers and decide whether it's a good answer or not give basically give feedback to other models. It could be distilled in a lot of different ways. Basically a teacher model, a knowledge distillation model. Very large, very capable. And so all of this is now available online.

我们意识到，Lama 模型实际上可以针对企业应用进行更优的微调。因此，我们利用自身的专业知识和能力对这些模型进行微调，将其转化为 Lama Nemo Tron 开源模型套件。其中一些模型体积很小，响应速度极快，我们称之为「超微型 Lama Nemo Tron 模型」。它们可以看作是模型的主流版本。此外，还有一种「超大型模型」，它可以作为其他模型的教师模型，例如作为奖励模型的评估器，或者作为评判其他模型生成答案质量的裁判，为其他模型提供反馈。这个超大型模型还可以通过多种方式进行知识提炼， 它本身就是一个功能非常强大的教师模型或知识提炼模型。所有这些模型现在都可以在网上获取。

Well these models are incredible. It's a number one in leaderboards for chat, leaderboard for instruction, leaderboard for retrieval. So the different types of functionalities necessary that are used in AI agents around the world, these are going to be incredible models for you. We're also working with the ecosystem. These, all of our NVIDIA AI technologies are integrated into the IT industry. We have great partners and really great work being done at ServiceNow, at SAP, at Siemens for industrial AI. Cadence is doing great work, Synopsys is doing great work. I'm really proud of the work that we do with Perplexity. As you know, they revolutionized search. Yeah, really fantastic stuff. Codium every every software engineer in the world this is going to be the next giant AI application next giant AI service period is software coding. 30 million software engineers around the world everybody is going to have a software assistant helping them code if if if not obviously you're just, you're going to be way less productive and create lesser good code. And so this is 30 million.

这些模型真是太棒了。它们在聊天、指令和检索的各项排行榜上都位居榜首。因此，对于全球 AI 智能体（AI Agent）所需的各种功能，这些模型将是你的得力助手。我们也在积极拓展生态合作。NVIDIA 的所有 AI 技术都已深度融入 IT 行业。我们与 ServiceNow、SAP 和西门子等公司建立了强大的合作伙伴关系，在工业 AI 领域取得了卓越进展。Cadence 和 Synopsys 也表现出色。我为我们与 Perplexity 的合作感到非常自豪，正如大家所知，他们彻底革新了搜索体验。真是非常了不起的成就。Codium 的出现，将为全球每一位软件工程师带来变革，软件编码将是下一个巨大的 AI 应用和 AI 服务浪潮。全球有 3000 万软件工程师，未来每个人都将拥有一个 AI 软件助手来辅助编码。如果没有 AI 助手，你的工作效率会大幅降低，代码质量也会大打折扣。这关乎 3000 万软件工程师的未来。

There's a billion knowledge workers in the world. It is very, very clear AI agents is probably the next robotics industry and likely to be a multi-trillion dollar opportunity. Well, let me show you some of the and likely to be a multi-trillion dollar opportunity. Well, let me show you some of the blueprints that we created and some of the work that we've done with our partners with these AI agents. AI agents are the new digital workforce, working for and with us. AI agents are a system of models that reason about a mission, break it down into tasks, and retrieve data or use tools to generate a quality response. NVIDIA's agentic AI building blocks, NIM pre-trained models, and NEMO framework let organizations easily develop AI agents and deploy them anywhere. We will onboard and train our agentic workforces on our company's methods, like we do for employees. AI agents are domain-specific task experts. Let me show you four examples.

全球有数十亿知识工作者。很明显，AI 智能体很可能成为继机器人产业之后的下一个新兴产业，并有望带来数万亿美元的市场机遇。接下来，我将展示我们所构建的一些框架，以及我们与合作伙伴在 AI 智能体方面的一些工作成果。AI 智能体是新型的数字劳动力，它们为我们工作，也与我们协同工作。AI 智能体是一套模型系统，能够分析任务目标，将其分解为具体步骤，并检索数据或利用工具生成高质量的反馈。NVIDIA 的 AI 智能体构建模块、NIM 预训练模型以及 NEMO 框架，让各机构能够便捷地开发 AI 智能体，并将其部署在任何场景中。我们将像对待新入职的员工一样，对 AI 智能体进行培训，使其掌握我们公司的工作流程。AI 智能体是特定领域的任务专家。接下来，我将展示四个例子。

For the billions of knowledge workers and students, AI research assistant agents ingest complex documents like lectures, journals, financial results, and generate interactive podcasts for easy learning. By combining a UNet regression model with a diffusion model, CoreDiff can downscale global weather forecasts down from 25 kilometers to 2 kilometers. Developers, like at NVIDVIDIA manage software security AI agents that continuously scan software for vulnerabilities, alerting developers to what action is needed. Virtual Lab AI agents help researchers design and screen billions of compounds to find promising drug candidates faster than ever and screen billions of compounds to find promising drug candidates faster than ever.

对于数十亿的知识工作者和学生而言，人工智能研究助理可以处理复杂的文档，例如讲座、期刊和财务报告，并生成交互式播客，方便学习。通过结合 UNet 回归模型和扩散模型，CoreDiff 可以将全球天气预报的分辨率从 25 公里提高到 2 公里。像 NVIDIA 这样的公司，其开发人员使用软件安全人工智能智能体持续扫描软件漏洞，并提醒开发人员需要采取的行动。虚拟实验室人工智能智能体帮助研究人员设计和筛选数十亿种化合物，以便更快地找到有前景的候选药物。

NVIDIA Analytics AI agents built on an NVIDIA Metropolis blueprint, including NVIDIA Cosmos Nematron Vision Language Models, Lama Nematron LLMs, and Nemo Retriever. Metropolis agents analyze content from the billions of cameras generating 100,000 petabytes of video per day. They enable interactive search, summarization, and automated reporting. And help monitor traffic flows, flagging congestion or danger. In industrial facilities, they monitor processes and generate recommendations or improvement. Metropolis agents centralize data from hundreds of cameras and can reroute workers or robots when incidents occur. The age of agentic AI is here for every organization is here for every organization.

基于 NVIDIA Metropolis 蓝图的 NVIDIA 分析智能体，包括 NVIDIA Cosmos Nematron 视觉语言模型（Vision Language Models），Lama Nematron 大语言模型（LLMs），和 Nemo Retriever。Metropolis 智能体分析来自数十亿摄像头的内容，这些摄像头每天产生 10 万 PB 的视频。它们支持交互式搜索、摘要和自动报告，并帮助监控交通流量，标记拥堵或危险情况。在工业设施中，它们监控流程并生成建议或优化建议。Metropolis 智能体集中来自数百个摄像头的数据，可以在事件发生时重新引导工人或机器人。每个组织的 AI 智能体时代已经到来。

Okay. That was the first pitch at a baseball game. That was not generated. I just felt that none of you were impressed. Okay, so AI was created in the cloud and for the cloud. AI is created in the cloud for the cloud. And for enjoying AI on phones, of course, it's perfect. Very, very soon, we're gonna have a continuous AI that's gonna be with you. And when you use those meta glasses, you could, of course, point at something, look at something, and ask it whatever information you want. And so AI is perfect in the cloud. What's creating the cloud is perfect in the cloud. However, we would love to be able to take that AI everywhere. I've mentioned already that you could take NVIDIA AI to any cloud, but you could also put it inside your company. But the thing that we want to do more than anything is put it on our PC as well.

好的，那是棒球比赛的第一次投球，不是 AI 生成的。我只是觉得大家都没什么反应。好吧，所以说，AI 是在云端被创造出来，并服务于云端的。为了在手机上使用 AI，这种方式当然很理想。很快，我们将会拥有一个持续运行的 AI 智能体，它将常伴你左右。当你使用 Meta 公司的眼镜时，你可以指向或看着某个物体，并向它询问你想要的任何信息。因此，AI 在云端是完美的，为云端而生的技术在云端也是完美的。然而，我们希望能够将 AI 带到任何地方。我之前提到过，你可以将 NVIDIA 的 AI 应用部署到任何云端，也可以部署在公司内部。但我们更希望把它放到个人电脑上。

And so, as you know, Windows 95 revolutionized the computer industry. It made possible this new suite of multimedia services and it changed the way that applications was created forever. Windows 95, this model of computing, of course, is not perfect for AI. And so, the thing that we would like to do is we would like to have in the future your AI basically become your AI assistant. And instead of instead of just the 3D APIs and the sound APIs and the video APIs, you would have generative APIs, generative APIs for 3D and generative APIs for language and generative AI for sound and so on and so forth. And we need a system that makes that possible while leveraging the massive investment that's in the cloud. There's no way that the world can create yet another way of programming AI models. It's just not going to happen. And so if we could figure out a way to make Windows PC a world-class AI PC, it would be completely awesome.

所以，正如你所知，Windows 95 彻底改变了计算机行业。它使得一套新的多媒体服务成为可能，并永远改变了应用程序的创建方式。Windows 95 这种计算模型，当然，对于 AI 来说并不完美。因此，我们希望在未来，你的 AI 基本上成为你的 AI 助手。并且，不再仅仅是 3D API、声音 API 和视频 API，你还将拥有生成式 API，包括用于 3D、语言的生成式 API，以及用于声音的生成式 AI 等等。我们需要一个系统，它既能利用云端的巨额投资，又能实现上述目标。世界不太可能再创造出另一种编程 AI 模型的方式。因此，如果我们能找到一种方法使 Windows PC 成为世界级的 AI PC，那将会非常棒。

And it turns out the answer is Windows. It's Windows WSL2. Windows WSL2. Windows WSL2 basically is two operating systems within one. It works perfectly. It's developed for developers and it's developed so that you can have access to bare metal. WSL2 has been optimized for cloud-native applications. It is optimized for, and very importantly, it's been optimized for CUDA. And so WSL2 supports CUDA perfectly out of the box. As a result, everything that I showed you with NVIDIA NIMS, NVIDIA NEMO, the blueprints that we develop that are going to be up in AI.NVIDIA.com, so long as the computer fits it, so long as you can fit that model, and we're going to have many models that fit, whether it's vision models or language models or speech models or these animation human digital human models, all kinds of different types of models are going to be perfect for your PC. And you download it and it should just run. And so our focus is to turn Windows WSL 2, Windows PC, into a target first-class platform that we will support and maintain for as long as we shall live. And so this is an incredible thing for engineers and developers everywhere.

答案是 Windows，确切地说是 Windows WSL2。Windows WSL2 本质上是在一个系统中运行两个操作系统。它运行流畅，专为开发者设计，并允许他们直接访问硬件底层（bare metal）。WSL2 针对云原生应用进行了优化，更重要的是，它对 CUDA 进行了深度优化。因此，WSL2 可以开箱即用，完美支持 CUDA。这样一来，我之前演示的 NVIDIA NIMS 和 NVIDIA NEMO，以及我们开发的蓝图都将在 AI.NVIDIA.com 上提供。只要你的电脑配置足够，能够运行相应的模型（我们会有很多适配的模型，包括视觉模型、语言模型、语音模型以及动画数字人模型等），这些不同类型的模型都将非常适合在你的 PC 上运行。你只需下载，即可直接运行。因此，我们的目标是将 Windows WSL 2 和 Windows PC 打造成一流平台，我们会长期支持和维护。这对全球的工程师和开发者来说，无疑是一项巨大的福音。

Let me show you something that we can do with that. This is one of the examples of a blueprint we just made for you something that we can do with that. This is one of the examples of a blueprint we just made for you. Generative AI synthesizes amazing images from simple text prompts. Yet image composition can be challenging to control using only words. With NVIDIA NIMH microservices, creators can use simple 3D objects to guide AI image generation. Let's see how a concept artist can use this technology to develop the look of a scene. They start by laying out 3D assets, created by hand or generated with AI. Then use an image generation NIMH, such as Flux, to create a visual that adheres to the 3D scene. Add or move objects to refine the composition. Change camera angles to frame the perfect shot. Or reimagine the whole scene with a new prompt. Assisted by Generative AI and NVIDIA NIM, an artist can quickly realize their vision. NVIDIA AI for your PCs.

我来向您展示一些有趣的应用。这是我们为您准备的一个蓝图示例，展示了它的用途。生成式 AI（Generative AI）可以根据简单的文本提示生成惊艳的图像。但是，仅仅使用文字来控制图像的构图可能比较困难。借助 NVIDIA NIMH 微服务，创作者可以使用简单的 3D 对象来引导 AI 图像的生成。我们来看看概念艺术家如何利用这项技术来设计场景。他们首先会布置 3D 素材，这些素材可以是手工创建的，也可以是通过 AI 生成的。然后，他们使用像 Flux 这样的图像生成 NIMH，创建与 3D 场景相符的视觉效果。通过添加或移动对象来调整构图，改变相机角度来获得完美的镜头，或者通过新的提示来重新构想整个场景。在生成式 AI 和 NVIDIA NIM 的帮助下，艺术家可以快速地将他们的想法变为现实。NVIDIA AI，为您的 PC 而生。

Hundreds of millions of PCs in the world with Windows, and so we could get them ready for AI. OEMs, all the PC OEMs we work with, just basically all of the world's leading PC OEMs, are going to get their PCs ready for this stack. And so AI PCs are coming to a home near you. Linux is good. Okay, let's talk about physical AI. Speaking of Linux, let's talk about physical AI. Speaking of Linux, let's talk about physical AI. So, physical AI.

世界上有数亿台安装 Windows 的个人电脑，所以我们可以让它们为 AI 做好准备。OEM（Original Equipment Manufacturer），我们合作的所有个人电脑 OEM，基本上所有世界领先的个人电脑 OEM，都将让他们的个人电脑为这个技术堆栈做好准备。因此，AI 个人电脑即将进入千家万户。Linux 也很棒。好的，让我们谈谈物理 AI（Physical AI）。提到 Linux，我们来聊聊物理 AI。所以，物理 AI。

Imagine, imagine, whereas your large language model, you give it your context, your prompt on the left, and it generates tokens one at a time to produce the output. That's basically how it works. The amazing thing is this model in the middle is quite large, has billions of parameters. The context length is incredibly large because you might decide to load in a PDF. In my case, I might load in several PDFs before I ask it a question. Those PDFs are turned into tokens. The basic attention characteristic of a transformer has every single token find its relationship and relevance against every other token. So you could have hundreds of thousands of tokens and the computational load increases quadratically and it does this, all of the parameters, all of the input sequence, process it through every single layer of the transformer and it produces one token. That's the reason why we need a black wall. And then the next token is produced when the current token is done. It puts the current token into the input sequence and takes that whole thing and generates the next token. It does it one at a time. This is the transformer model. It's the reason why it is so incredibly effective, computationally demanding.

设想一下，一个大语言模型（LLM），你将上下文和提示输入到左侧，它会逐个生成 Token ，从而产生输出。这便是它基本的工作原理。令人惊叹的是，模型本身非常庞大，拥有数十亿个参数。它的上下文长度也极其巨大，因为你可能会加载一个 PDF 文件。例如，我可能会在提问之前加载多个 PDF 文件。这些 PDF 文件会被转换为 Token。Transformer 的核心注意力机制是让每个 Token 都计算它与其他所有 Token 的关联性。因此，即使有成千上万个 Token，计算量也会以平方级的速度增长。模型会处理所有参数和输入序列，使其通过 Transformer 的每一层，最终生成一个 Token。这就是为什么我们需要一个「黑盒」。当生成当前 Token 后，模型会将这个 Token 添加到输入序列中，然后利用更新后的序列生成下一个 Token，这个过程是逐个 Token 进行的。这就是 Transformer 模型的工作方式。它之所以如此有效，也是因为它对计算资源的需求非常高。

What if instead of PDFs, it's your surrounding? And what if instead of the prompt, a question, it's a request? Go over there and pick up that box and bring it back. And instead of what is produced in tokens as text, it produces action tokens. Well, that I just described is a very sensible thing for the future of robotics. And the technology is right around the corner. But what we need to do is we need to create effectively the world model as opposed to GPT, which is a language model. And this world model has to understand the language of the world. It has to understand physical dynamics things like gravity and friction and inertia. It has to understand geometric and spatial relationships. It has to understand cause and effect. If you drop something and fall to the ground, if you, you know, poke at it, it tips over. It has to understand object permanence. If you roll a ball over the kitchen counter, when it goes off the other side, the ball didn't leave into another quantum universe that's still there. And so all of these types of understanding, those intuitive understanding that we know, that most models today have a very hard time with.

如果我们将关注点从 PDF 文件转移到周围真实的环境，会怎么样呢？如果将「提示」这个概念替换为「请求」，例如「到那边去，把那个盒子捡起来，然后把它带回来」这样的指令，又会怎么样呢？如果模型不是产生文本形式的 Token（Token），而是产生动作 Token（Token）来执行操作，又会怎么样呢？嗯，我刚才描述的正是未来机器人技术发展的一个非常合理的方向。而且，相关技术已经触手可及。但我们现在需要做的，是构建一个有效的「世界模型」，而不是像 GPT 那样的「语言模型」（Language Model）。这个世界模型必须理解真实世界的运行规律，例如物理动力学 —— 重力、摩擦和惯性；它还需要理解几何和空间关系，以及因果关系。例如，如果你把东西掉在地上，它会因为重力而掉落；如果你戳一下它，它可能会翻倒。此外，这个模型还必须理解「物体恒存性」的概念。比如，当你把一个球滚过厨房台面，球从另一侧掉下去时，它并没有消失到另一个量子宇宙，它仍然存在。所有这些类型的理解，那些我们人类所拥有的直观理解能力，是目前大多数模型都难以掌握的。

And so we would like to create a world, we need a world foundation model. Today, we're announcing a very big thing. We're announcing NVIDIA Cosmos, a world foundation model that is designed, that was created to understand the physical world. And the only way for you to really understand this is to see it. Let's play it. The next frontier of AI is physical AI. Model performance is directly related to data availability, but physical world data is costly to capture, curate, and label. NVIDIA Cosmos is a world foundation model development platform to advance physical AI. It includes auto-regressive world foundation models, diffusion-based world foundation models, advanced tokenizers, and an NVIDIA CUDA, an AI accelerated data pipeline. Cosmos models ingest text, image, or video prompts and generate virtual world states as videos. Cosmos generations prioritize the unique requirements of AV and robotics use cases, like real-world environments, lighting and object permanence.

因此，为了创建一个虚拟世界，我们需要一个世界基础模型。今天，我们宣布一件非常重要的成果。我们发布 NVIDIA Cosmos，这是一个为了理解物理世界而打造的世界基础模型。要真正理解它的强大之处，最好的方式就是亲眼见证。请看演示。物理 AI 是人工智能的下一个前沿。模型的性能很大程度上取决于数据的可用性，而物理世界数据的获取、整理和标注成本都非常高。NVIDIA Cosmos 是一个用于开发物理 AI 的世界基础模型平台。它包括自回归世界基础模型（auto-regressive world foundation model）、基于扩散的世界基础模型（diffusion-based world foundation model）、高级 Tokenizer（Tokenizer）以及 NVIDIA CUDA，一个由 AI 加速的数据处理流程。Cosmos 模型可以接收文本、图像或视频的输入，并生成虚拟世界状态的视频。Cosmos 的生成结果会优先考虑自动驾驶和机器人等应用场景的特殊需求，例如真实世界的环境、光照以及物体不会凭空消失的特性。

Developers use NVIDIA Omniverse to build physics-based, geospatially accurate scenarios, then output Omniverse renders into Cosmos, which generates photoreal, physically-based synthetic data. Whether diverse objects or environments, conditions like weather or time of day or edge case scenarios. Developers use Cosmos to generate worlds for reinforcement learning. AI feedback to improve policy models or to test and validate model performance even across multi-sensor views. Cosmos can generate tokens in real time bringing the power of foresight and multiverse simulation to AI models, generating every possible future to help the model select the right path.

开发人员使用 NVIDIA Omniverse 构建基于物理、且具有精确地理空间信息的场景，然后将 Omniverse 的渲染结果输出到 Cosmos。Cosmos 可以生成照片般真实且基于物理的合成数据，包括各种不同的物体、环境以及天气、时间或极端情况等条件。开发人员利用 Cosmos 为强化学习创建虚拟世界。通过 AI 反馈，可以改进策略模型，或者在多传感器视角下测试和验证模型的性能。Cosmos 能够实时生成 Token（Token），为 AI 模型带来预测能力和多重宇宙模拟，生成所有可能的未来，帮助模型选择最优路径。

Working with the world's developer ecosystem, NVIDIA is helping advance the next wave of physical AI. NVIDIA Cosmos, the world's first world foundation model, is trained on 20 million hours of video. The 20 million hours of video focuses on physical dynamic things, so dynamic nature, nature themes, humans walking, hands moving, manipulating things, you know, things that are fast camera movements. It's really about teaching the AI, not about generating creative content, but teaching the AI to understand the physical world.

通过与全球开发者生态系统合作，NVIDIA 正在推动下一波现实世界 AI 的发展。NVIDIA Cosmos，世界上首个全球通用基础模型，使用 2000 万小时的视频进行训练。这 2000 万小时的视频专注于现实世界中动态的物体，例如动态的自然场景、人类行走、手部移动、操作物体，以及快速的摄像机运动等。它的重点在于训练 AI，使其理解物理世界，而不是生成创造性内容。

And with this physical AI, there are many downstream things that we could do as a result. We could do synthetic data generation to train models. We could distill it and turn it into effectively the seed, the beginnings of a robotics model. You could have it generate multiple physically based, physically plausible scenarios of the future, basically do a Doctor Strange. You could, because this model understands the physical world, of course, you saw a whole bunch of images generated, this model understands the physical world, it also could do, of course, captioning. And so it could take videos caption it incredibly well and that captioning and the video could be used to train large language models, multi-modality large language models.

有了这种物理 AI（Physical AI），我们就可以开展许多后续应用。例如，我们可以生成合成数据来训练模型。我们可以提炼它，使其成为机器人模型的初始种子。它可以生成多个基于物理且在物理上合理的未来场景，就像「奇异博士」那样预见未来。由于该模型理解物理世界，正如大家所见，它生成了大量的图像，所以它当然也可以进行字幕添加。因此，它可以为视频添加高质量的字幕，而这些字幕和视频可以用于训练大语言模型（LLM）和多模态大语言模型。

And so you could use this technology, to use this foundation model to train robotics robots as well as large language models. This is the NVIDIA Cosmos. The platform has an auto regressive model for real-time applications, has diffusion model for a very high quality image generation, it's incredible tokenizer, basically learning the vocabulary of real world and a data pipeline so that if you would like to take all of this and then train it on your own data, this data pipeline, because there's so much data involved, we've accelerated everything end-to-end for you. And so this is the world's first data processing pipeline that's CUDA accelerated as well as AI accelerated. All of this is part of the Cosmos platform and today we're announcing that Cosmos is open licensed. It's open available on GitHub.

因此，你可以利用这项技术，使用这个基础模型来训练机器人和大语言模型（Large Language Model）。这就是 NVIDIA Cosmos。该平台拥有一个用于实时应用的自回归模型，以及一个用于生成高质量图像的扩散模型。它还具备强大的 Tokenizer（Tokenizer），能够学习真实世界的「词汇」，并提供数据管道。如果你想采用这些技术，并在自己的数据上进行训练，由于涉及大量数据，我们已经为你进行了端到端的加速。因此，这是世界上首个 CUDA 加速和 AI 加速的数据处理管道。所有这些都是 Cosmos 平台的一部分。今天，我们宣布 Cosmos 采用开放许可，并在 GitHub 上开源。

We hope that this moment, and there's a small, medium, large for very fast models, you know, mainstream models and also teacher models, basically not knowledge transfer models. Cosmos World Foundation model being open, we really hope will do for the world of robotics and industrial AI what Lama 3 has done for enterprise AI. The magic happens when you connect Cosmos to Omniverse, and the reason fundamentally is this. Omniverse is a physics grounded, not physically grounded, but physics grounded. It's algorithmic physics, principled physics simulation grounded system. It's a simulator.

我们期望，针对不同类型的模型 —— 包括超快速模型、主流模型以及教师模型（这些模型主要不用于知识转移）—— 都能有小、中、大等多种规模的选择。我们衷心希望，开放的宇宙世界基础模型（Cosmos World Foundation model） 能够在机器人和工业 AI 领域，取得像 Lama 3 在企业 AI 领域那样的成就。当 Cosmos 与 Omniverse 相连接时，奇迹就会发生，其根本原因在于：Omniverse 是一个以物理为基础的系统，它并非基于真实的物理环境，而是基于算法物理，是一个遵循物理原理的模拟系统。它本质上是一个模拟器。

When you connect that to Cosmos, it provides the grounding, the ground truth, that can control and to condition the Cosmos generation. As a result, what comes out of Cosmos is grounded on truth. This is exactly the same idea as connecting a large language model to a RAG, to a retrieval augmented generation system. You want to ground the AI generation on ground truth. And so the combination of the two gives you a physically simulated, a physically grounded multiverse generator.

当我们将它连接到 Cosmos 时，它便提供了基础，或者说事实依据，从而能够控制和调节 Cosmos 的生成过程。因此，Cosmos 输出的内容是基于真实信息的。这与将大语言模型连接到 RAG（检索增强生成系统）的思路一致。我们都希望 AI 生成的内容有事实依据。所以，将两者结合，就得到了一个基于物理模拟和物理基础的多重宇宙生成器。






And the application, the use cases are really quite exciting. And of course, for robotics, for industrial applications it is very very clear this cosmos plus omniverse plus cosmos represents the third computer that's necessary for building robotic systems. Every robotics company will ultimately have to build three computers. The robotic system could be a factory. The robotic system could be a car. It could be a robot. You need three fundamental computers.

而且，这些应用和用例确实非常令人兴奋。当然，对于机器人技术和工业应用来说，很明显，cosmos、Omniverse 和 cosmos 的结合代表了构建机器人系统所必需的第三台计算机。每家机器人公司最终都将需要构建三台计算机。机器人系统可以是一个工厂、一辆汽车或者一个机器人。你需要三台基本计算机来实现这些功能。

One computer, of course, to train the AI. We call it the DGX computer to train the AI. Another, of course, when you're done, to deploy the AI. We call that AGX. That's inside the car, in the robot, or in an AMR, or in a stadium, or whatever it is. These computers are at the edge, and they're autonomous. But to connect the two, you need a digital twin. And this is all the simulations that you were seeing. The digital twin is where the AI that has been trained goes to practice, to be refined, to do with synthetic data generation, reinforcement learning AI feedback, such and such. And so it's the digital twin of the AI. These three computers are gonna be working interactively. NVIDIA's strategy for the industrial world, and we've been talking about this for some time, is this three computer system. You know, instead of a three body problem, we have a three computer solution. And so, it's the NVIDIA of robotics.

一台计算机，用于训练 AI（Artificial Intelligence），我们称之为 DGX 计算机。另一台，则用于 AI 训练完成后的部署，我们称之为 AGX。AGX 被部署在汽车、机器人、自动移动机器人（AMR)、体育场等各种边缘设备中，它们是自主运行的。为了连接这两者，我们需要一个数字孪生系统。你所看到的模拟都发生在这里。数字孪生是经过训练的 AI 进行实践、改进、合成数据生成以及强化学习反馈的场所。简而言之，它是 AI 的数字孪生环境。这三台计算机将协同工作。NVIDIA 在工业领域的策略，我们已经讨论过一段时间了，就是构建这个三计算机系统。这不是三体问题，而是三计算机解决方案。因此，这代表了 NVIDIA 在机器人领域的布局。

So let me give you three examples. All right, so the first example is how we apply all of this to industrial digitalization. There are millions of factories, hundreds of thousands of warehouses. That's basically is the backbone of a $50 trillion manufacturing industry. All of that has to become software defined. All of it has to have automation in the future and all of it will be infused with robotics. We're partnering with Keyon, the world's leading warehouse automation solutions provider and Accenture, the world's largest professional services provider and they have a big focus in digital manufacturing and we're working together to create something that's really special. I'll show you that in a second.

好的，让我给你三个例子。第一个例子是我们如何将这些技术应用于工业数字化。有数百万家工厂和数十万个仓库，它们构成了价值 50 万亿美元的制造业的支柱。这些设施都需要实现软件定义（software defined），未来的发展方向是自动化和机器人技术的深度融合。我们正在与全球领先的仓库自动化解决方案供应商 Keyon 和全球最大的专业服务公司埃森哲合作，埃森哲在数字制造领域投入了大量资源。我们正在共同打造一个非常特别的解决方案，稍后我会展示给你们。

But our go-to-market is essentially the same as all of the other software platforms and all the technology platforms that we have. Through the developers and ecosystem partners, we have just a growing number of ecosystem partners connecting to Omniverse. And the reason for that is very clear. Everybody wants to digitalize the future of industries. There's so much waste, so much opportunity for automation in that $50 trillion of the world's GDP.

但我们的市场推广策略，与我们现有的其他所有软件和技术平台基本一致。通过开发者和生态伙伴，越来越多的生态伙伴正在接入 Omniverse。原因显而易见，大家都希望将各行业的未来数字化。全球 GDP 高达 50 万亿美元，其中存在着巨大的浪费，以及大量的自动化机会。

So let's take a look at this one example that we're doing with Keyon and Accenture. Keyon, the supply chain solution company, Accenture, a global leader in professional services, and NVIDIA are bringing physical AI to the $1 trillion warehouse and distribution center market. Managing high-performance warehouse logistics involves navigating a complex web of decisions influenced by constantly shifting variables. These include daily and seasonal demand changes, space constraints, workforce availability, and the integration of diverse robotic and automated systems. And predicting operational KPIs of a physical warehouse is nearly impossible today.

现在，让我们来看一个我们与 Keyon 和埃森哲合作的案例。供应链解决方案公司 Keyon，全球专业服务领导者埃森哲，以及 NVIDIA 正在将实体 AI 应用于价值达万亿美元的仓库和配送中心市场。管理高性能的仓库物流需要应对一个复杂且受多变因素影响的决策网络。这些因素包括每日和季节性的需求变化、空间限制、劳动力可用性，以及各种机器人和自动化系统的集成。此外，如今要预测实体仓库的运营关键绩效指标（KPI）几乎是不可能的。

To tackle these challenges, Keon is adopting Mega, an NVIDIA Omniverse blueprint for building industrial digital twins to test and optimize robotic fleets. First, Keon's warehouse management solution assigns tasks to the industrial AI brains in the digital twin, such as moving a load from a buffer location to a shuttle storage solution. The robot's brains are in a simulation of a physical warehouse, digitalized into Omniverse using open USD connectors to aggregate CAD, video and image to 3D, LIDAR to point cloud, and AI-generated data. The fleet of robots execute tasks by perceiving and reasoning about their Omniverse digital twin environment, planning their next motion and acting.

为了解决这些难题，Keon 公司正在采用 Mega，这是 NVIDIA Omniverse 的一个蓝图，它能帮助构建工业数字孪生，从而测试和优化机器人 fleet 。首先，Keon 的仓库管理方案会给数字孪生中的工业 AI 系统分配任务，例如，将货物从缓冲位置转移到穿梭存储系统。这些机器人的「大脑」存在于一个物理仓库的模拟环境中，该环境通过开放的 USD 连接器被数字化到 Omniverse 中。这个过程将 CAD 文件、视频和图像等数据整合为 3D 模型，将 LIDAR 数据转化为点云，并纳入 AI 生成的数据。机器人 fleet 通过感知和理解它们在 Omniverse 中的数字孪生环境来执行任务，规划下一步行动并付诸实践。

The robot brains can see the resulting state through sensor simulations and decide their next action. The loop continues while Mega precisely tracks the state of everything in the digital twin. Now, Kion can simulate infinite scenarios at scale while measuring operational KPIs, such as throughput, efficiency, and utilization, all before deploying changes to the physical warehouse. Together with NVIDIA, Keon and Accenture are reinventing industrial autonomy. In the future, that's incredible.

机器人通过模拟传感器来观察当前状态，并由此决定下一步行动。当 Mega 精确地追踪数字孪生中的所有状态时，这个循环会持续进行。现在，Kion 能够大规模地模拟各种无限场景，并在将任何更改部署到实际仓库之前，就衡量诸如吞吐量、效率和利用率等运营关键绩效指标（Key Performance Indicators，KPI）。Keon 和埃森哲正与 NVIDIA 携手，共同重塑工业自动化。展望未来，这无疑将带来巨大的变革。

Everything is in simulation. In the future, every factory will have a digital twin. And that digital twin operates exactly like the real factory. And in fact, you could use Omniverse with Cosmos to generate a whole bunch of future scenarios and you pick, then an AI decides which one of the scenarios are the most optimal for whatever KPIs and that becomes the programming constraints, the program, if you will, the AIs that will be deployed into the real factories.

一切都将在模拟中进行。在未来，每个工厂都将拥有一个数字孪生体（digital twin）。这个数字孪生体的运行方式将与真实工厂完全一致。事实上，你可以使用 Omniverse 和 Cosmos 来生成大量未来情景，然后从中选择，接着由一个 AI 来决定哪个情景对于给定的 KPI 来说是最优的。这个最优情景将成为编程约束，或者说程序，然后这些 AI 将会被部署到真实的工厂中。

The next example, autonomous vehicles. The AV revolution has arrived. After so many years, with Waymo's success and Tesla's success, it is very, very clear autonomous vehicles has finally arrived. Well, our offering to this industry is the three computers. The training with just about every major car company around the world. Waymo and Zooks and Tesla of course in their data center. BYD the largest EV company in the world. JLR has got a really cool car coming. Mercedes because a fleet of cars coming with Nvidia with starting with this starting this year going to production.

下一个例子，自动驾驶汽车。自动驾驶汽车的变革已经来临。经过多年的发展，凭借 Waymo 和 Tesla 的成功，自动驾驶汽车的时代已经到来，这一点毋庸置疑。我们为这个行业提供的产品是三款计算平台。我们与全球几乎所有主要的汽车公司都有合作，进行相关训练，例如 Waymo、Zoox 和 Tesla 在他们的数据中心，还有全球最大的电动汽车公司比亚迪。捷豹路虎（JLR）也即将推出一款非常棒的车型。梅赛德斯将有一批搭载英伟达技术的汽车，从今年开始投入量产。

And I'm super, super pleased to announce that today, Toyota and NVIDIA are gonna partner together to create their next generation AVs. Just so many, so many cool companies. Lucid and Rivian and Xiaomi and of course Volvo just so many different companies. Wabi is building self-driving trucks. Aurora we announced this week also that Aurora is going to use Nvidia to build self-driving trucks. Autonomous a hundred million cars built each year, a billion cars vehicles on a road all over the world. A trillion miles that are driven around the world each year, that's all going to be either highly autonomous or fully autonomous coming up. And so this is going to be a very large industry.

我今天非常高兴地宣布，丰田和 NVIDIA 将合作开发他们的下一代自动驾驶汽车（AV）。有很多非常酷的公司，例如 Lucid、Rivian、小米，当然还有沃尔沃等。Wabi 正在开发自动驾驶卡车。Aurora，我们本周也宣布了 Aurora 将使用 Nvidia 来开发自动驾驶卡车。每年生产一亿辆汽车，这些汽车将会是自动驾驶的，全球道路上有十亿辆汽车在行驶。每年全球的行驶里程达到一万亿英里，所有这些车辆都将逐步实现高度自动驾驶或完全自动驾驶。因此，这将是一个规模庞大的产业。

I predict that this will likely be the first multi-trillion dollar robotics industry. This business for us, notice in just a few of these cars that are starting to ramp into the world, our business is already $4 billion and this year probably on a run rate about $5 billion. So really significant business already. This is going to be very large.

我预测，这很可能将是首个产值达数万亿美元的机器人产业。对于我们而言，请注意，仅仅是在少数几款开始推向市场的汽车中，我们的业务额已经达到了 40 亿美元，并且今年很可能以约 50 亿美元的年化速度增长。所以，这已经是一项非常重要的业务了。这个产业的规模将会非常庞大。

Well today we're announcing that our next generation processor for the car, our next generation computer for the car is called Thor. I have one right here, hang on a second. Okay this is Thor. This is a robotics computer. This takes sensors and just a madness amount of sensor information process it. You know, umpteen cameras high resolution radars, lidars, they're all coming into this chip and this chip has to process all that sensor turn them into tokens put them into a transformer and predict the next path. And this AV computer is now in full production. Thor is 20 times the processing capability of our last generation Oren, which is really the standard of autonomous vehicles today.

好的，今天我们宣布，我们为汽车打造的下一代处理器，也就是下一代车载计算机，名为 Thor。我这里有一个，请稍候。好，这就是 Thor。它是一款机器人计算机，能够接收来自各种传感器的大量信息并进行处理。例如，它能处理来自众多摄像头、高分辨率雷达和激光雷达的数据。这些数据都会汇集到这枚芯片中，芯片会处理这些传感器数据，将它们转化为 Token，然后输入到 Transformer 中，从而预测车辆的下一步行驶路径。这款自动驾驶计算机现已进入量产阶段。Thor 的处理能力是我们上一代产品 Oren 的 20 倍，而 Oren 实际上是目前自动驾驶汽车的性能标杆。

And so this is just really quite incredible. Thor is in full production. This robotics processor, by the way, also goes into a full robot. And so it could be an AMR, it could be a human or robot, it could be the brain, it could be the manipulator. This processor basically is a universal robotics computer. The second part of our Drive system that I'm incredibly proud of is the dedication to safety.

这真是令人难以置信的成就。Thor 芯片正在全面量产。这款机器人处理器，不仅应用于机器人，更可作为机器人的核心部件。它可以是自主移动机器人（AMR），可以是人形机器人，可以是机器人的大脑，也可以控制机械臂。这款处理器本质上是一款通用的机器人计算平台。我们 Drive 系统的第二大亮点，也是我引以为豪的一点，是对安全性的极致追求。

Drive OS, I'm pleased to announce, is now the first software defined programmable AI computer that has been certified up to ASIL-D, which is the highest standard of functional safety for automobiles. The only and the highest. And so I'm really, really proud of this ASIL-D, ISO 26262. It is the work of some 15,000 engineering years. This is just extraordinary work. And as a result of that, CUDA is now a functional, safe computer. And so if you're building a robot NVIDIA CUDA yeah okay.

我很高兴地宣布，Drive OS 如今是首个通过 ASIL-D 认证的软件定义可编程 AI 计算机，ASIL-D 是汽车功能安全的最高标准，也是唯一的最高标准。我为获得 ASIL-D（ISO 26262）认证感到非常自豪，这凝聚了 15,000 个工程年的努力，是一项非凡（extraordinary）的成就。因此，CUDA 现在成为了一个功能安全的计算机。所以，如果你正在用 NVIDIA CUDA 构建机器人，那它将是不错的选择。

So now I wanted to I told you I was going to show you what would we use omniverse and cosmos to do in the context of self-driving cars. And you know today instead of showing you a whole bunch of videos of cars driving on the road, I'll show you some of that too. But I want to show you how we use the car to reconstruct digital twins automatically using AI and use that capability to train future AI models. Okay, let's play it.

现在，我将向大家展示在自动驾驶汽车领域，我们如何利用 Omniverse 和 Cosmos 。今天，我不会播放大量汽车在道路上行驶的视频，虽然也会展示一部分，但我更想重点介绍如何利用 AI 技术，让汽车自动重建数字孪生模型，并使用这些模型来训练未来的 AI 模型。好的，让我们开始吧。

The autonomous vehicle revolution is here. Building autonomous vehicles like all robots requires three computers: NVIDIA DGX to train AI models, Omniverse to test drive and generate synthetic data and drive AGX, a supercomputer in the car. Building safe autonomous vehicles means addressing edge scenarios, but real-world data is limited, so synthetic data is essential for training. The Autonomous Vehicle Data Factory, powered by NVIDIA Omniverse, AI Models, and Cosmos, generates synthetic driving scenarios that enhance training data by orders of magnitude.

自动驾驶汽车的变革已经到来。像所有机器人一样，开发自动驾驶汽车需要三台计算机：NVIDIA DGX 用于训练 AI 模型，Omniverse 用于模拟驾驶和生成合成数据，以及车载超级计算机 AGX。为了确保自动驾驶汽车的安全，必须解决各种极端情况，但现实世界中的数据有限，因此合成数据对于训练至关重要。借助 NVIDIA Omniverse、AI 模型和 Cosmos 的强大支持，自动驾驶汽车数据工厂能够生成大量的合成驾驶场景，从而显著提升训练数据的规模。

First, Omnimap fuses map and geospatial data to construct drivable 3D environments. Driving scenario variations can be generated from replay drive logs or AI traffic generators. Next, a neural reconstruction engine uses autonomous vehicle sensor logs to create high-fidelity 4D simulation environments. It replays previous drives in 3d and generates scenario variations to amplify training data. Finally edify 3ds automatically searches through existing asset libraries or generates new assets to create sim ready scenes.

首先，Omnimap 将地图和地理空间数据融合，构建出可驾驶的 3D 环境。驾驶场景的变化可以从回放的驾驶日志或 AI 交通生成器中产生。接下来，神经重建引擎利用自动驾驶汽车的传感器日志，创建高精度的 4D 仿真环境。它以 3D 形式回放之前的驾驶过程，并生成不同的场景，以此来扩充训练数据。最后，edify 3ds 会自动搜索现有的资源库或生成新的资源，来创建可直接用于仿真的场景。

The Omniverse scenarios are used to condition Cosmos to generate massive amounts of photorealistic data, reducing the sim-to-real gap. And with text prompts, generate near-infinite variations of the driving scenario. With Cosmos NemoTron Video Search, the massively scaled synthetic data set combined with recorded drives can be curated to train models. NVIDIA's AI Data Factory scales hundreds of drives into billions of effective miles, setting the standard for safe and advanced autonomous driving. Isn't that incredible?

Omniverse 场景被用来训练 Cosmos 生成海量的照片级真实数据，从而缩小模拟与现实的差距。通过文本提示，可以生成几乎无限的驾驶场景变种。借助 Cosmos NemoTron 视频搜索，大规模的合成数据集与真实驾驶记录相结合，可以用来训练模型。NVIDIA 的 AI 数据工厂将数百次驾驶转化为数十亿有效里程，为安全和先进的自动驾驶设定了标准。这真是令人赞叹，不是吗？

We take thousands of drives and turn them into billions of miles. We are going to have mountains of training data for autonomous vehicles. Of course, we still need actual cars on the road. Of course, we will continuously collect data for as long as we shall live. However, synthetic data generation using this multiverse, physically based, physically grounded capability so that we generate data for training AIs that are physically grounded and accurate and plausible so that we could have an enormous amount of data to train with.

我们收集数千次的驾驶数据，并将其转化为数十亿英里的里程。我们将积累海量的自动驾驶训练数据。当然，实际道路测试仍然不可或缺。而且，只要我们持续进行研究，数据收集就不会停止。然而，通过使用这种基于物理建模的合成数据生成技术，我们可以生成具有物理真实性、准确性和可信度的 AI 训练数据，从而获得庞大的训练数据集。

The AV industry is here. This is an incredibly exciting time, super, super, super excited about the next several years. I think you're gonna see, just as computer graphics was revolutionized at such incredible pace, you're going to see the pace of AV development increasing tremendously over the next several years. I think the next part is robotics. So human robots, my friends.

自动驾驶（AV）时代已经来临。这是一个令人无比激动的时刻，我对未来几年的发展感到非常兴奋。我认为，正如计算机图形技术曾以惊人的速度发生革命性变革一样，未来几年自动驾驶（AV）技术的进步速度也将大幅提升。我认为接下来的重点是机器人技术，尤其是人形机器人。

The chat GPT moment for general robotics is just around the corner. And in fact, all of the enabling technologies that I've been talking about is going to make it possible for us in the next several years to see very rapid breakthroughs, surprising breakthroughs in general robotics. Now the reason why general robotics is so important is whereas robots with tracks and wheels require special environments to accommodate them, there are three robots, three robots in the world that we can make that require no green fields. Brown field adaptation is perfect.

通用机器人领域的「ChatGPT 时刻」已经近在眼前。事实上，我一直提到的那些关键技术，将在未来几年内促成通用机器人领域快速且令人惊喜的突破。通用机器人之所以如此重要，是因为履带式和轮式机器人需要特定的环境才能运作，而有三种我们可以制造的机器人，它们不需要专门的场地。它们可以完美地适应现有环境。

If we could possibly build these amazing robots, we could deploy them in exactly the world that we've built for ourselves. These three robots are one, agentic robots and agentic AI, because they're information workers, so long as they could accommodate the computers that we have in our offices, it's gonna be great. Number two, self-driving cars, and the reason for that is we spent 100 plus years building roads and cities. And then number three, human or robots. If we have the technology to solve these three, this will be the largest technology industry the world's ever seen. And so we think that robotics era is just around the corner.

如果我们可以制造出这些令人惊叹的机器人，我们就能将它们部署到我们为自己构建的世界中。这三个机器人领域分别是：第一，AI 智能体（AI Agent）机器人和 AI 智能体，因为它们本质上是信息处理工作者。只要它们能够兼容我们办公室里的现有计算机系统，就能发挥巨大作用。第二，自动驾驶汽车。这是因为我们已经花费了一百多年的时间来建设道路和城市基础设施。第三，人形机器人。如果我们在技术上能够解决这三个领域的挑战，这将催生出世界有史以来最大的科技产业。因此，我们相信机器人时代已经近在眼前。

The critical capability is how to train these robots. In the case of human or robots, the imitation information is rather hard to collect. And the reason for that is in the case of car, you just drive it. We're driving cars all the time. In the case of these human or robots, the imitation information, the human demonstration is rather laborious to do. And so we need to come up with a clever way to take hundreds of demonstrations, thousands of human demonstrations, and somehow use artificial intelligence and omniverse to synthetically generate millions of synthetically generated motions.

如何训练这些机器人是关键所在。无论是人类还是机器人，模仿信息的收集都相当困难。例如，对于汽车，我们只需驾驶即可，而且我们一直在驾驶。但对于人类或机器人而言，要收集模仿信息，特别是人类的演示，则需要付出大量的努力。因此，我们需要找到一种巧妙的方法，利用人工智能和 Omniverse，将数百甚至数千个人类演示，合成为数百万个模拟动作。

And from those motions, the AI can learn how to perform a task. Let me show you how that's done. Developers around the world are building the next wave of physical, AI-embodied robots, humanoids. Developing general-purpose robot models requires massive amounts of real-world data, which is costly to capture and curate. NVIDIA Isaac Groot helps tackle these challenges, providing humanoid robot developers with four things: Robot foundation models, data pipelines, simulation frameworks, and a Thor robotics computer.

通过观察这些动作，AI 便能学习如何执行任务。接下来，让我向您展示这是如何实现的。世界各地的开发人员正在构建下一代物理的、搭载 AI 的机器人，也就是人形机器人。开发通用机器人模型需要大量的真实世界数据，而采集和整理这些数据成本很高。NVIDIA Isaac Groot 旨在帮助解决这些挑战，它为人形机器人开发人员提供以下四个方面的支持：机器人基础模型（Robot foundation models)、数据管道、仿真框架以及一个 Thor 机器人计算机。

The NVIDIA Isaac Groot blueprint for synthetic motion generation is a simulation workflow for imitation learning, enabling developers to generate exponentially large datasets from a small number of human demonstrations. First, Groot Teleop enables skilled human workers to portal into a digital twin of their robot using the Apple Vision Pro. This means operators can capture data even without a physical robot and they can operate the robot in a risk-free environment, eliminating the chance of physical damage or wear and tear. To teach a robot a single task, operators capture motion trajectories through a handful of teleoperated demonstrations.

英伟达（NVIDIA）Isaac Groot 提供的合成运动生成方案，是一种用于模仿学习的模拟工作流程，它使得开发人员能够仅通过少量的人工演示，生成指数级增长的大型数据集。首先，Groot Teleop 功能允许熟练的操作人员使用 Apple Vision Pro 进入他们机器人的数字孪生环境。这意味着，即使没有真实的机器人，操作员也可以采集数据，并且可以在零风险的环境下操作机器人，从而避免物理损坏或部件损耗。为了教机器人执行一项任务，操作员只需通过几次远程操控演示来捕获运动轨迹。

Then use Groot Mimic to multiply these trajectories into a much larger data set. Next, they use Groot Gen, built on Omniverse and Cosmos for domain randomization and 3D-to-real upscaling, generating an exponentially larger data set. The Omniverse and Cosmos Multiverse Simulation Engine provides a massively scaled dataset to train the robot policy. Once the policy is trained, developers can perform software-in-the-loop testing and validation in ISACSIM before deploying to the real robot. The age of general robotics is arriving, powered by NVIDIA Isaac Groot.

然后，他们利用 Groot Mimic 将这些轨迹扩展成一个更大的数据集。接下来，他们使用基于 Omniverse 和 Cosmos 构建的 Groot Gen，进行领域随机化和 3D 到真实世界的转换，从而生成一个指数级增长的数据集。Omniverse 和 Cosmos Multiverse 仿真引擎提供了大规模的数据集，用于训练机器人策略。一旦策略训练完成，开发人员就可以在部署到真实机器人之前，在 ISACSIM 中进行模拟环境中的软件测试和验证。在 NVIDIA Isaac Groot 的驱动下，通用机器人时代即将到来。

We're gonna have mountains of data to train robots with NVIDIA Isaac Groot. This is our platform to provide technology elements to the robotics industry to accelerate the development of general robotics. And well, I have one more thing that I want to show you. None of this would be possible if not for this incredible project that we started about a decade ago. Inside the company was called Project Digits, Deep Learning GPU Intelligence Training System, Digits.

有了 NVIDIA Isaac Groot，我们将拥有海量的数据来训练机器人。这是一个为机器人行业提供技术组件的平台，旨在加速通用机器人的发展。另外，我还想向大家展示一个东西。如果没有我们大约十年前启动的这项卓越的计划，这一切都无法实现。在公司内部，这个项目被称为「Project Digits」，即深度学习 GPU 智能训练系统（Deep Learning GPU Intelligence Training System），简称 Digits。

Well, before we launched it, I shrunk it to DGX, and to harmonize it with RTX, AGX, OVX, and all of the other Xs that we have in the company. And it really revolutionized, DGX1 really revolutionized, where's DGX1? DGX1 revolutionized artificial intelligence. The reason why we built it was because we wanted to make it possible for researchers and startups to have an out of the box AI supercomputer. Imagine the way supercomputers were built in the past. You really have to build your own facility and you have to go build your own infrastructure and really engineer it into existence. And so we created a super computer for AI development for researchers and startups that comes literally one out of the box.

在发布之前，我把它改成了 DGX，使其与公司其他产品线 RTX、AGX、OVX 等「X」系列产品保持一致。DGX1 的确带来了革命性的变化，DGX1 真正地变革了人工智能领域。我们之所以打造 DGX1，是希望研究人员和初创公司能够拥有一台开箱即用的 AI 超级计算机。试想一下，过去的超级计算机构建是多么复杂：你必须自建机房，自行搭建基础设施，从头开始进行工程设计。而我们为 AI 开发打造的这台超级计算机，研究人员和初创公司拿到手就可以直接使用。

I delivered the first one to a startup company in 2016 called OpenAI. And Elon was there and Ilya Suskover was there and many of the engineers were there. And we celebrated the arrival of DGX1 and obviously it revolutionized artificial intelligence and computing. But now artificial intelligence is everywhere. It's not just in researchers and startup labs. You know, we want artificial intelligence, as I mentioned in the beginning of our talk, this is now the new way of doing computing. This is the new way of doing software. Every software engineer, every engineer, every creative artist, everybody who uses computers today as a tool will need an AI super computer. And so I just wish that DGX1 was smaller. And, you know, so, you know, imagine, ladies and gentlemen, this is NVIDIA's latest AI supercomputer. And it's fondly called Project Digits right now.

2016 年，我将第一台交付给了一家名为 OpenAI 的初创公司。当时，埃隆（Elon）、伊利亚·苏斯科弗（Ilya Suskover）以及许多工程师都在现场。我们一同庆祝了 DGX1 的到来，它无疑给人工智能和计算领域带来了革命性的变革。如今，人工智能已经无处不在，不再局限于研究机构和初创实验室。正如我在演讲开始时所说，我们希望人工智能成为一种全新的计算方式和软件开发模式。每一位软件工程师、每一位工程师、每一位创意工作者，以及所有将计算机作为工具的人，都将需要一台 AI 超级计算机（AI supercomputer）。我多么希望 DGX1 的体积能更小一些。现在，请大家想象一下，这款 NVIDIA 最新的 AI 超级计算机，目前被大家亲切地称为「Digits 项目」。

And if you have a good name for it, reach out to us. Here's the amazing thing. This is an AI supercomputer. It runs the entire NVIDIA AI stack. All of NVIDIA software runs on this. DGX cloud runs on this. This sits well somewhere and it's wireless or, you know, connected to your computer. It's even a workstation if you like it to be. And you could access it. You could reach it like a cloud supercomputer.

如果您有好的命名方案，请联系我们。这是一台令人惊叹的 AI 超级计算机。它运行着整个 NVIDIA AI 软件栈，所有 NVIDIA 的软件都在此之上运行，DGX 云也运行于此。它可以放置在任何方便的位置，并通过无线或有线方式连接到您的计算机。它甚至可以作为工作站使用，如果您有此需要。您可以像访问云端超级计算机一样访问和使用它。

And NVIDIA's AI works on it. And it's based on a super secret chip that we've been working on called GB110, the smallest grace blackwell that we make. And I have, well, you know what, let's show, let's show everybody inside. Isn't this just so cute? And this is the chip that's inside. It is in production.

英伟达的 AI 技术正在此设备上运行。该设备基于我们一直在开发的代号为 GB110 的高度机密芯片，它是我们生产的最小的 Grace Blackwell 系列芯片。我这里有一个，不如这样，让我们向大家展示一下它的内部构造。是不是非常精致？这就是它内部所使用的芯片。目前，该芯片已经投入生产。

This top secret chip we did in collaboration. The gray CPU is built for NVIDIA in collaboration with MediaTek. They're the world's leading SOC company, and they worked with us to build this CPU, the CPU SOC, and connected with chip to chip NVLink to the Blackwell GPU. And this little, this little thing here is in full production. And this little thing here is in full production. We're expecting this computer to be available around May timeframe. And so it's coming at you.

这是我们合作开发的顶级机密芯片。这款灰色的 CPU 是 NVIDIA 与联发科合作打造的。联发科是世界领先的片上系统（System on Chip，SOC）公司，他们与我们合作开发了这款 CPU，即 CPU SOC，并通过芯片间 NVLink 将其连接到 Blackwell GPU。这个小小的芯片目前已全面投产。我们预计这款计算机将于五月份左右上市。它即将与大家见面。

It's just incredible what we could do. And it's just, I think it's, you really, I was trying to figure out do I need more hands or more pockets? All right, so imagine this is what it looks like. You know, who doesn't want one of those? And if you use PC, Mac, you know, anything. Because, you know, it's a cloud platform. It's a cloud computing platform that sits on your desk. You could also use it as a Linux workstation if you like. If you would like to have double digits, this is what it looks like. And you connect it together with ConnectX and it has nickel, GPU direct, all of that out of the box. It's like a super computer.

我们能做到这些真是太不可思议了。我一直在想，我到底需要更多双手还是更多口袋来装下这些东西？好吧，想象一下它大概长这个样子。谁不想要一个这样的设备呢？ 无论你用的是 PC、Mac，或者其他任何设备，都可以使用它，因为它是一个云平台，一个放在你桌面的云计算平台。你甚至可以把它当作 Linux 工作站来使用。如果你想要更多算力，比如达到两位数，它们可以像这样连接起来。通过 ConnectX 连接，并且它支持 GPU Direct 等技术，所有这些都是开箱即用的。它就像一台超级计算机一样强大。

Our entire super computing stack is available. And so, NVIDIA Project Digits. Okay. Well, let me tell you what I told you. I told you that we are in production with three new Blackwells. Not only is the Grace Blackwell super computers and NVLink 72 in production all over the world, we now have three new Blackwell systems in production. One amazing AI, world foundation model, the world's first physical AI foundation model is open, available to activate the world's industries of robotics and such, and three robotics, three robots working on agentic AI, human or robots, and self-driving cars.

我们所有的超级计算资源都已就绪。此外，还有英伟达的 Project Digits 项目。好的，让我来回顾一下之前我所讲的内容。我提到过，我们有三套新的 Blackwell 系统已经投入生产。不仅 Grace Blackwell 超级计算机和 NVLink 72 正在全球范围内量产，我们现在还有另外三套新的 Blackwell 系统也已投入生产。一个令人瞩目的 AI 模型，作为全球首个物理 AI 基础模型已开放使用，旨在激活全球机器人等相关行业。此外，还有三个机器人正在进行 AI 智能体的研发，这些 AI 智能体既可以由人类控制，也可以由机器人自身控制，其应用方向还包括自动驾驶汽车。

It's been an incredible year. I want to thank all of you for your partnership. I thank all of you for coming. I made you a short video to reflect on last year and look forward to next year. Play, please. Thank you. I'm sorry. Thank you. I'm sorry. Thank you. Have a great CES, everybody. Happy New Year. Thank you. Thank you.

这一年真是太棒了。我想感谢各位的合作，也感谢大家的到来。我做了一个小短片，回顾过去一年，也展望一下来年。请播放一下。谢谢。抱歉，抱歉。谢谢。祝大家在 CES 玩得开心，新年快乐！谢谢。