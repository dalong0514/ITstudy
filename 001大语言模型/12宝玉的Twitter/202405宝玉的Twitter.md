### 01

2024-05-04

Tom Huang
@tuturetom
支持 Local Model 的 AI 版本的 Obsidian🧠 - Reor 开源，目前 4.3K Star ⭐️

1. 桌面端 App：支持 Mac、Windows、Linux
2. AI 加持的笔记：自动关联相关笔记、对笔记进行智能问答以及语义搜索
3. 笔记保存在本地，支持本地模型，提供 Obsidian 类似的 Markdown 编辑器 💥

---

reorproject/reor

### 02

2024-05-04

Yangyi
@Yangyixxxx
以前是基于N-Gram来推测一个Token
现在基于这个新技术可以推测多个
AI已经在不知不觉间进入了指数级迭代爆发期

---


Gorden Sun
@Gorden_Sun
通过多词元预测实现更快更好的LLM
LLM基本都是自回归地预测下一个token，每次只预测一个，Meta的这篇论文提出一次性预测多个词元甚至是句子，因为预测的内容更多，LLM可以更全面的考虑整体结构，从而更有逻辑性。
这种推理方式更像人类思考的方式。
论文：https://arxiv.org/abs/2404.19737

### 03

2024-05-04

AIGCLINK
@aigclink
一款可以将文本转换为知识图谱的工具：Prettygraph

特点：
1、文生图：可以将用户输入的文本转换为知识图谱

2、动态 UI 更新：图表会在每次插入句点时重新生成，并在 UI 中实时更新，从而提供交互式体验

3、颜色编码可视化：图中的节点和边采用颜色编码，以更好地进行视觉区分

github：http://github.com/yoheinakajima/prettygraph



### 04

2024-05-04

宝玉
@dotey
The Prompt with Trevor Noah | 第6集：有时AI是唯一的解决方案

AI展现出其分析大数据的强大能力，不仅是解决复杂问题的一个有效手段，往往还是我们能找到的唯一出路。AI for Good Lab 与全球顶尖研究者携手，不断在科学探索中取得新突破，改善危机中的人道响应，帮助医疗工作者拓宽服务范围，还试图从亚马逊雨林繁复的自然声中解读大自然的秘密。

在这一集里，Microsoft的首席提问官特雷弗·诺亚对话Microsoft的Juan M. Lavista Ferres——公司副总裁、首席数据科学家兼AI for Good Lab的负责人。节目中，他们深入探讨了Microsoft如何与全球众多机构合作，通过激发创造力与好奇心，共同开发出既能增强人类能力又能保护地球的创新解决方案。


### 05

2024-05-04

宝玉
@dotey
最近崔娃和微软一起合办了一个 AI 相关的视频节目，叫：《The Prompt with Trevor Noah》。它的口号是：“You can't find answers without asking the right questions”。这正是我们日常使用 Prompt（提示词）使用 AI 的关键所在 —— 如果你不能提出正确的问题，就无法找到答案。

这个系列节目由 Trevor Noah 主持，他现任微软的首席提问官（Microsoft’s Chief Questions Officer），以其深刻的好奇心而闻名。在每一期节目中，他与来宾一起探讨一个与公共辩论息息相关的新话题，讨论他们如何借助人工智能（AI）解决全球紧迫性问题，及其对公共安全、卫生、教育等领域的影响。他深入技术前沿，打破界限，从全球各地的技术专家、工程师、科学家以及社区中汲取知识与经验。

https://microsoft.com/en-us/research/group/ai-for-good-research-lab/the-prompt/



### 06

2024-05-04


歸藏(guizang.ai)
@op7418
由一个开源的AI硬件 ，Frame AI 眼镜。

你可以通过语音和 Frame 进行沟通，它的回复会显示在眼镜屏幕上，而且会有小图标表示现在的情绪。

Frame 是多模态的可以看到你现在看到的东西，这玩意很强啊，如果响应速度快点的话。

演示视频已翻译。



### 07

2024-05-04

歸藏(guizang.ai)
@op7418
贾扬清说新的ChatGPT能力吊打那些只是简单地调用传统搜索并用LLM总结"的包装器。

比如让它获取hacker news最热的内容并且给出介绍，其他AI搜索工具或者AI聊天工具都无法完成的很好。

因为模型必须真正理解它,将其转化为有意义的行动，看来Open AI 真的在搜索上发力了。

我尝试了一下前十条都很好，妹有幻觉在以前根本不可能。



### 08

2024-05-04

歸藏(guizang.ai)
@op7418
StoryDiffusion 这个字节的新项目表现很好啊。

能够生成细节丰富、内容多样的图像和视频，同时保持角色身份和服饰的一致性。

可以帮助生成长篇漫画或者带连续剧情的视频。

与IP-Adapter和PhotoMaker等方法相比，StoryDiffusion在保持角色一致性的同时，还能更好地控制文本提示，生成与描述更匹配的图像和视频。

关键组件：

Consistent Self-Attention是StoryDiffusion框架的核心组件之一，它通过在生成过程中引入参考图像的样本Token，增强了不同图像间的一致性。

Semantic Motion Predictor是StoryDiffusion中的另一个关键组件，它专门用于长距离视频生成。



### 09

2024-05-04


Yadong Xie
@yadong_xie
刚刚开发完了 youtube 和 bilibili 的时间轴分段总结功能

下个版本的 http://elmo.chat 就可以在看视频的时候快速拉片了

继续免费 + 免注册 + 无限制使用



### 10

2024-05-04

歸藏(guizang.ai)
@op7418
这个有意思，Llama3-70B 的 Lora，可以让任何基于 Llama-3 70B 微调的模型都具有 524K 的上下文。

Lora 是从 Llama-3-70B-Instruct-Gradient-524k 中提取的。



### 11

2024-05-04

宝玉
@dotey
两条 Llama 3 微调的新闻：

1. Gradient AI 推出首款 1M 上下文窗口 Llama-3 70B，并且在 NIAH 测试中（Needle In A HayStack，大海捞针）取得满分的成绩
来源：https://twitter.com/gradient_ai_/status/1786876543509434473?s=46

2. Nvidia 发布了基于 Llama3 微调的 ChatQA-1.5 系列模型，号称这些模型在 RAG（检索式回答生成）和对话式问答领域超越了 GPT-4-0613 和 Command-R-Plus。
来源：https://twitter.com/_weiping/status/1786511543255126396



### 12

2024-05-04

luolei
@luoleiorg
升级 96GB 内存 Mac 后，不再担心硬件性能影响工作体验，也改变了我以前用 Chrome 随手关标签的习惯。但是也带来新问题，开一大堆标签，很难检索和切换(全部挤在一起)。发现了一个神仙插件 Vertical Tabs，可以把标签在侧边栏横向展示(标题展示更全 + 自动按规则分组)  ，作者 http://guokai.dev




### 13

2024-05-05

宝玉
@dotey
转译：我们荣幸推出 ChatQA-1.5 系列模型，这些模型在 RAG（检索式回答生成）和对话式问答领域超越了 GPT-4-0613 和 Command-R-Plus。

ChatQA-1.5 推出了两个版本：
- Llama3-ChatQA-1.5-8B
- Llama3-ChatQA-1.5-70B

同时，我们公开了用于指令调优的数据源，并提供了 ChatRAG Bench 作为评估工具，还为社区贡献了一个经过优化的多轮问答检索系统。

https://twitter.com/_weiping/status/1786511543255126396



### 14

2024-05-04

宝玉
@dotey
OpenAI CEO 访问哈佛全球社会商业研究所

2023年5月1日，OpenAI 的首席执行官 Sam Altman 访问了哈佛全球社会商业研究所，并就人工智能（AI）对社会可能产生的影响进行了深入的讨论。以下是访问中的一些讨论重点。

政府在AI发展中的角色

在人工智能领域，一个重要议题是明确政府如何参与。随着技术的快速进步，预计未来几年将取得重大发展。这一点让政府的介入变得更为重要和紧迫。Altman 认为，这是一个良好的开端，通过行业专家与政府部门的合作来探讨AI技术的应用与监管是至关重要的。

社会契约的变迁

鉴于经济变动的巨大幅度，我们需要重新考虑社会契约的变化，例如资本与劳动之间的关系。Altman 提出，逐步部署和迭代策略至关重要，这样我们才有机会进行充分的讨论、辩论，吸收反馈，并进行适应。

未来工作的转变

Altman 预测，未来几十年工作的本质将发生根本变化，可能与我们今天所理解的“真正的工作”截然不同。他认为，政策在与科学技术紧密结合的情况下效果最佳。理论上看似完美的政策也可能需要根据技术的实际发展调整。

国际监管与灾难风险

他还提出了一个有趣的设想：建立一个类似于国际原子能机构（IAEA）的监管体，监管全球排名前十的先进AI系统。一旦这些系统超过某个阈值，就应接受类似于武器检查员的审查。这主要是为了应对可能对全人类构成灾难性风险的国际政策问题。

深刻的认识

Altman 分享了他在 OpenAI 初期的一个深刻体会：当他们发现扩大语言模型的规模可以显著提高性能时。尽管他们已经认识到深度学习的有效性及其规模效应，这一发现仍然给他们带来了意外的启发和影响。

来源：https://youtube.com/watch?v=9pfo9j_Eq9U



### 15

2024-05-05

歸藏(guizang.ai)
@op7418
Andrej 的新科普内容，深度学习的CUDA/C++起源：

\# 深度学习的 CUDA/C++ 起源

有趣的是,许多人可能听说过 2012 年的 ImageNet / AlexNet 时刻,以及它引发的深度学习革命。 https://en.wikipedia.org/wiki/AlexNet

而鲜为人知的是,支持这一获奖作品的代码是由 Alex Krizhevsky 从头开始手动用 CUDA/C++ 编写的。这个仓库叫做 cuda-convnet,当时托管在 Google Code 上:https://code.google.com/archive/p/cuda-convnet/

我认为 Google Code 已经关闭了(?),但我现在在 GitHub 上找到了一些它的分支,例如:https://github.com/ulrichstern/cuda-convnet

这是 CUDA 用于深度学习的首批重要应用之一,正是 CUDA 所带来的计算规模,使得这个网络在 ImageNet 基准测试中取得了如此优异的性能。实际上,这也是一个相当复杂的多 GPU 应用,例如采用了模型并行,将两个并行的卷积流分割到两个 GPU 上。

我们还要认识到,在大约 12 年前的 2012 年,大多数深度学习工作是在 Matlab 中完成的,在 CPU 上,在简单的实验环境中,不断尝试各种学习算法、模型架构和优化思路。因此,当时看到 Alex、Ilya 和 Geoff 说:别管那些算法工作了,只要拿一个相当标准的卷积神经网络 (ConvNet),把它做得非常大,在 ImageNet 这样的大型数据集上训练它,然后把整个过程都用 CUDA/C++ 实现出来,这是相当新颖和出人意料的。

正是通过这种方式,深度学习这个领域得到了极大的推动。我记得当时读 cuda-convnet 的源码时,感觉像是在想:这到底是什么鬼 :S

当然,那时候已经有了向规模化方向转变的迹象,例如 Matlab 开始支持 GPU,而我在斯坦福大学 Andrew Ng 的实验室 (作为一年级博士生轮岗) 所做的大部分工作,也是探索用 GPU 来实现大规模的深度学习,这些都是当时众多并行努力的一部分。

但有趣的是,当我现在写这些 C/C++ 代码和 CUDA 内核时,会感觉好像回到了那个时代,仿佛又重温了深度学习革命的初始阶段。

---

歸藏(guizang.ai)
@op7418
AlexNet的介绍：

AlexNet是一种卷积神经网络(CNN)架构，由Alex Krizhevsky与Ilya Sutskever和Geoffrey Hinton合作设计，后者是Krizhevsky在多伦多大学的博士导师。

这个网络在2012年9月30日的ImageNet大规模视觉识别挑战中竞赛，取得了15.3%的前5错误率，比第二名低了10.8个百分点。

AlexNet的主要成果是证明了模型的深度对于其高性能至关重要，尽管这在计算上很昂贵，但通过使用图形处理单元(GPU)进行训练成为可能。

网络设计方面，AlexNet包含八层：前五层是卷积层，其中一些后面跟着最大池化层，最后三层是全连接层。网络除了最后一层外，分成两份，每份运行在一个GPU上。它使用了非饱和的ReLU激活函数，显示出比tanh和sigmoid更好的训练性能。

AlexNet被认为是计算机视觉领域最有影响力的论文之一，促进了许多更多使用CNN和GPU加速深度学习的论文发表。截至2023年初，根据Google Scholar，AlexNet论文已被引用超过120,000次。

### 16

2024-05-05

yetone
@yetone
兑现承诺，已经把 OpenAI Translator 中的全平台的全局取词逻辑独立出一个 Rust 库 get-selected-text 并开源！

在 macOS 平台下的实现方式如下：

1. 优先使用 A11y API 来获取选中的文本
2. 如果使用 A11y API 获取不了选中文本，则 fallback 到通过模拟按下 cmd+c 快捷键来借助剪切板获取选中文本
3. 为了防止在未选中任何文本的时候按下 cmd+c 会发出恼人的嘣嘣警告声，在模拟按下 cmd+c 之前会临时静音 alert 声，cmd+c 释放后恢复 alert 音量

所以我觉得这是目前可以开箱即用的比较完美的全局取词库了

https://github.com/yetone/get-selected-text


### 17

2024-05-05


歸藏(guizang.ai)
@op7418
互联网上机器人和人类的活动已经几乎持平了，去年整个互联网的机器人流量占到了49.6%，AI的发展加剧了这个趋势。

感觉再过几年估计就全是机器人了，想找个真人聊天都费劲。完全由真人组成的社区估计有搞头。



### 18

2024-05-05


歸藏(guizang.ai)
@op7418
刚看到这个研究太强了，可以实现几乎实时的 3D 高斯泼溅渲染。

只需要在车上装上设备正常前进就行，中等质量的渲染可以保证每秒60帧，高质量的可以保证30帧。

项目能够在保持大型场景的视觉质量的同时，通过高效的细节层次方案，实现远处内容的高效渲染，确保层级间的平滑过渡和明确的层级选择。


### 19

2024-05-05


歸藏(guizang.ai)
@op7418
一个很简单的教程，教你用 GPT-4 实现一个自动的 RAG 项目，系统可以自动决定从本地数据中查找还是联网获取内容。

---

Ashpreet Bedi
@ashpreetbedi
Lets build `Auto-RAG` where we let the LLM pull the data it needs from different sources.

🔎 The user asks a question.
🤔 LLM decides whether to search its knowledge, memory, internet or make an API call.
✍️ LLM answers with the context.

Code: https://git.new/auto-rag

https://x.com/i/status/1787189664941498711

### 20

2024-05-05

倪爽
@nishuang
怎么在 X/推特 获取优质信息

#活到死学到死

如果你想在推特获得优质的、有价值的信息，或者学习 AI 之类的新知识，那就需要技巧来过滤垃圾信息、放大优质信息

没耐心的人直接跳到 Part 3

Part 1：过滤垃圾信息

也许你觉得刷推特像图一，其实以前推特像图二

马斯克大手笔给推特用户分广告费、发美元，吸引了各种流量号、营销号，以后的推特会像图三

1，“宁可误杀一万”

- 看到一个人的推文，你只要脑子里有一丝不爽、想骂人的感觉，立刻把 ta 静音/mute
- 再次看到这个人的推文，还想骂人，立刻把 ta 屏蔽/block

人生短暂，你在傻逼身上花上一秒，就浪费了跟家人、朋友、毛孩子相处的一秒

2，小心推荐算法

推特的推荐算法是现在所有社交 APP 里效率最低的一个，比 TikTok 那种给全人类洗脑的推荐算法落后了好多年，但推特推荐算法烂归烂，控制你无脑刷屏也是小菜一碟

别成天看推特推荐的“For you”

3，警惕“敌人的敌人是朋友”

很多人用微博那种二极管、站队的习惯玩推特，下意识地把敌人的敌人当朋友，其实大家忽略了现实世界里人类的多样性

推特和现实世界没什么差别  - 朋友未必真是朋友，朋友的朋友一般也算不上朋友，敌人的敌人大概率只是另外一种敌人

4，不要把推特玩成微信群

聊天群特别适合话痨，比如特别爱说话的、思维特别碎片而缺乏条理的、特别无聊的、特别孤单的、特别依赖别人的，还有最烦的那种：待人接物特别没有边界、不知道什么话该说、什么话不能说的人

你在推特上关注话痨，等于主动接近家族群里管不住嘴的不知道什么远房亲戚

---

Part 2：放大优质信息

有几个技巧找到最优质的人和信息

1，亲近行业专家/垂直领域的 KOL

远离大 V、网红、营销号（包括那些特别会包装、但没有专业知识的内容创作者）

行业专家和垂直 KOL 在自己的专业领域沉浸多年，发言时通常不但有想法、有观点，还会分享思考过程、背后的证据和数据、相关的参考资料、实用的工具等等，干货满满

2，和学霸一起学习

推特的一大优点是聚集了全世界各个领域的专家，他们会主动发布各个领域的一手最新信息，这对爱学习的人而言，无疑就是随时更新的宝藏

不过专家也忙，不会给你一点点解释这些宝藏，这时们就需要借助那些理解力超强、精力充沛、乐于分享的“学霸”来帮我们学习了

不说别的，
@dotey
 宝玉老师就是 AI 领域的超级学霸，他分享了无数 AI 相关的资讯、教程、技巧，还分享了自己做的各种尝试、尝试后的经验和心得，我从他那儿学了很多最新 AI 知识和技能

3，向动手实操的人学习

听嘴炮和纯理论的“纸面专家”说事，一般只能停留在“说说而已”的层面，实操阶段就没有价值了

还拿 AI 为例，我关注了开发 AI 产品、用 AI 创作作品、做 AI 生意的等等实操 AI 的人；而 AI 分析师、转发 AI 资讯的人，我就敬而远之

4，N+1 学习方法

所谓“N+1 学习方法”，是指学习那些比自己高级一个档次的人，比如刚毕业的人学工作 1、2 年的人。这种学习方法，既能让你接触更高级知识，又避免太高级而无法理解

比如很多推友关注了马斯克学做生意，这种跨了十几级的学习，学到的基本都是盲目崇拜 + 玄学，没有实际价值

5，学会观察、学会提问

微博、知乎之类的网站，培养了很多人急于表达观点的习惯，一个个一张嘴就是斩钉截铁、宏大叙事

推特作为美国人创造的产品，本质上是个人际关系非常扁平、等级观念比较淡薄的社交网站，并不太重视“面子”，强行装逼的效率也不高

没有想法而非要表达，那是瞎逼逼。把装逼的心思用来观察和提问，才能学到真东西

“我不懂”才是世界上最睿智的话

---

Part 3：分享我在推特里的学习资源

因为推特上每天更新的信息太多、可学的东西太多，我用推特的 List / 列表 功能来学习

具体来说，我按照 AI、设计、独立开发 这些不同的主题，把相关领域最有价值的人加入对应的 list

从产品设计的角度说，List 实际是把快速流动的 feed，优化成了慢速更新的 pool，把被动地被喂养、被填食信息，变成了主动地、互动地获取信息

1，设计AI
https://twitter.com/i/lists/1651714185657561090

和推特上的 AI 创造者、开发者、创作者一起，从产品设计角度观察和体验 AI 产品。套用之前推友的评价：国内那些动辄几千块的 AI 课，都完全比不上这几位推友

2，独立创造者
https://twitter.com/i/lists/905990493712121856

极少数人能够独立创造出产品，关注独立开发者、自由设计师、个人内容生产者。现在很流行独立开发者微信群、Discord 群、Telegram 群…群适合聊天，更好的学习方法是观察其他独立开发者具体做了什么

3，中文设计师
https://twitter.com/i/lists/1493327693844295680

分享设计，体验想法，设计从来都不应该有边界

4，英文设计师
https://twitter.com/i/lists/1484009930457817090

关注世界一流的设计师，世界一流公司的设计师

5，Outside · 外面
https://twitter.com/i/lists/1318663032717922304?s=20

外面的世界，外面的人生，看看生活在外面的人有什么样的不同生活

---

有个流行的说法是说“简体中文推特是个大屎坑”，你怎么看待这句话？

如果你掌握了过滤垃圾信息、放大优质信息的技巧，你就根本不会在乎这种正确的屁话



### 21

2024-05-06



宝玉
@dotey
开源 Rabbit R1 推荐：

利用 Apple Shortcuts、Cloudflare Workers 和 llama 3 制作的一个人工智能助手。

Shortcuts 提供自动语音识别（ASR）、文本到语音转换（TTS）和 HTTP 请求功能，这些基本上涵盖了我们本地需要的所有功能。你还可以将一个快捷操作绑定到 iPhone 的动作按钮，这样即使在锁屏状态下也能快速访问。

接下来，作者简单编写了一个 Cloudflare Worker，它从快捷操作接收文本，发送到 llama 3 进行处理，然后将函数调用结果返回。

虽然这只是一个基础示例，但其实还可以扩展，包括更复杂的函数调用和数据存储等。

它的响应速度超过所有的 AI 穿戴设备，并且不需要额外的硬件或者支付月费。

项目地址：https://github.com/Sh4yy/personal-ai


### 22

2024-05-06


歸藏(guizang.ai)
@op7418
Adobe 发布了一个简单易用的 3D 工具Project Neo。

教程演示了如何使用 Project Neo + Firefly 制作 3D 等距城市插图。



### 23

2024-05-06

wong2
@wong2_x
假期最后一天，更新了一版Kimi Copilot，支持了总结PDF页面，支持了根据字幕总结YouTube视频！
安装：http://kimi.tools



### 24

2024-05-06

Leonie
@helloiamleonie
Roughly one year ago, I wrote a piece on the LLMOps landscape:
https://medium.com/@iamleonie/understanding-llmops-large-language-model-operations-4253820922?sk=4e27ae8a268e37e003f4b416942ff5ba 

While many aspects of the article still hold true today, the landscape has seen a lot of movement:



### 25

2024-05-06



歸藏(guizang.ai)
@op7418
终于有人干这个了，之前很多在 Comfyui 中的 LLM 都得单独配置，一个插件一个玩法。

Comfyui-ollama 这个插件可以直接使用 Ollama 中的 LLM。

你可以使用带视觉能力的模型生成图片描述，也可以自定义提示词对你的图像提示进行润色生成。


### 26

2024-05-06

歸藏(guizang.ai)
@op7418
老哥继续科普提示工程基础，三种高级提示工程技术，它们在实践中被广泛使用或引用。

思维链（CoT）提示[1]：

通过在模型提示中的样本内嵌入一系列思维链（即一系列中间推理步骤）来激发LLM的推理能力。通过为每个样本增加思维链，模型通过上下文学习学会在输出答案之前生成类似的思维链。我们在[1]中看到，明确解释解决问题的底层推理过程实际上使模型在推理方面更为高效。

CoT变体：鉴于CoT提示的有效性和流行性，提出了几种扩展：

- 零样本CoT [2]：去除了少样本样本，而是通过在提示的末尾添加“让我们一步一步地思考。”这句话来鼓励模型生成问题解决的推理。

- 自我一致性[3]：通过在解决问题时独立生成多个思维链并对每个思维链产生的最终答案进行投票来提高推理过程的鲁棒性。

- 由浅入深[4]：将一个问题分解为多个部分，分别解决每个部分，并使用每个子问题的解决方案作为下一个子问题的上下文。

思维树（ToT）提示[5]：

CoT提示在需要规划、战略前瞻、回溯和并行探索多个解决方案的问题上表现不佳。ToT提示将一个复杂问题分解为一系列更简单的问题（或“思维”）。LLM生成许多思维，并通过自然语言（即通过提示）不断评估其向最终解决方案的进展。通过利用模型对解决方案进展的自我评估，我们可以使用广泛使用的搜索算法（如广度优先搜索或深度优先搜索）来增强探索过程，从而在解决问题时允许预见和回溯。

思维图（GoT）提示[6, 7]：

后续研究将ToT提示的研究推广到基于图的推理策略。这些技术与ToT提示类似，但不认为用于生成解决方案的思维路径是线性的。我们可以在推导解决方案时重用思维，甚至通过一系列思维进行递归。已经提出了多种基于图的提示策略。然而，这些提示技术——以及ToT提示——因其缺乏实用性而受到批评。使用GoT提示解决推理问题可能需要LLM进行大量推理步骤。



### 27

2024-05-06


宝玉
@dotey
由新加坡政府科技局（GovTech）组织的首届 GPT-4 提示工程大赛冠军 Sheila Teo 写的《我是如何夺冠新加坡首届 GPT-4 提示工程大赛的》

Sheila 总结了 4 种提示词技巧：
🔵 借助 CO-STAR 框架构建高效的提示
🔵 利用分隔符来分节构建提示
🔴 设计含有 LLM 保护机制的系统级提示
🔴 仅依靠大语言模型分析数据集，无需插件或代码  — 实际案例分析 Kaggle 的真实数据集

其中 🔵 代表初学者友好的技巧，而 🔴 代表高级策略。

尤其是她总结的 CO-STAR 框架，在让 LLM 做一些内容尤其是写作类任务时非常简单有效。

(C) Context 上下文：为任务提供背景信息 
通过为大语言模型（LLM）提供详细的背景信息，可以帮助它精确理解讨论的具体场景，确保提供的反馈具有相关性。

(O) Objective 目标：明确你要求大语言模型完成的任务 
清晰地界定任务目标，可以使大语言模型更专注地调整其回应，以实现这一具体目标。

(S) Style 风格：明确你期望的写作风格 
你可以指定一个特定的著名人物或某个行业专家的写作风格，如商业分析师或 CEO。这将指导大语言模型以一种符合你需求的方式和词汇选择进行回应。

(T) Tone 语气：设置回应的情感调 
设定适当的语气，确保大语言模型的回应能够与预期的情感或情绪背景相协调。可能的语气包括正式、幽默、富有同情心等。

(A) Audience 受众：识别目标受众 
针对特定受众定制大语言模型的回应，无论是领域内的专家、初学者还是儿童，都能确保内容在特定上下文中适当且容易理解。

(R)  Response响应：规定输出的格式 
确定输出格式是为了确保大语言模型按照你的具体需求进行输出，便于执行下游任务。常见的格式包括列表、JSON 格式的数据、专业报告等。对于大部分需要程序化处理大语言模型输出的应用来说，JSON 格式是理想的选择。

完整内容可以查看：
原文：https://towardsdatascience.com/how-i-won-singapores-gpt-4-prompt-engineering-competition-34c195a93d41
译文：https://baoyu.io/translations/prompt-engineering/how-i-won-singapores-gpt-4-prompt-engineering-competition



### 28

2024-05-06

宝玉
@dotey
这个讲解 ChatGPT 提示词技巧的视频值得一看，播主将常见的提示词技巧分成了10个级别，最后一级的 CO-STAR 框架，来源自新加坡政府科技局（GovTech）组织的首届 GPT-4 提示工程大赛冠军总结的一个通用框架，适合绝大部分内容生成类场景。

转译：ChatGPT 提示词十级技巧: 从新手到专家

在这个视频中,我将所有这些经验总结为了10个级别的提示词设计技巧。我们会从基础开始,一直深入到最近在新加坡提示词设计比赛中夺冠的专家技术。那我们开始吧。

第1级 - 基础请求

在这个级别,你只需直接告诉ChatGPT你想要什么。不需要过多思考。有时这样做会有好结果,有时则不然。

举例
让ChatGPT总结一篇维基百科文章。

第2级 - 格式应用  

一些微小的格式调整可能会带来意外的大影响。比如,仅仅在提示词中添加一些破折号,就可以大大帮助ChatGPT理解你的提示词各部分的含义。

其他一些简单的格式调整,比如友好地表达,避免使用否定句,甚至"恳求"式的表达,有研究指出,在提示词中保持礼貌,可以提高大语言模型的准确性。

第3级 - 精准请求

第三级的关键是明确且专注地表达你希望从聊天机器人那里得到什么。

糟糕请求示例
太过模糊,如"让回答漂亮一些"。

良好请求示例
清晰指示所需内容,如制作特定列的表格等。

第4级 - 示例说明

给出示例输入和示例输出,这被称为"少样本学习"。ChatGPT会模仿你给出的示例格式。

示范
提供示例LinkedIn页面信息及期望的输出格式。

第5级 - 自我反省

让ChatGPT自我评估并反思自己是否遗漏了什么。这利用了大语言模型在评估方面的优势。

示例 
"嘿ChatGPT,你漏掉了什么?"

第6级 - 系统提示与定制指令

提供背景信息和期望方向给ChatGPT,以指导其按你所期望的方式回答。具体格式见视频介绍。

第7级 - 人格化应用

让ChatGPT模仿某个专家角色回答,可以提高准确性。

例子
解谜题时,让ChatGPT扮演逻辑思维专家的角色。

第8级 - 思维链条

要求ChatGPT解释思考过程,一步步来。通常通过添加"让我们一步步来思考"这一语句。

第9级 - 自我提示

让ChatGPT自己生成一个提示词,它在这方面往往比人类做得更好。

第10级 - CO-STAR模型

根据新加坡提示工程大赛的获胜框架CO-STAR,构建完整的提示词:

- C - Context (背景信息)
- O - Objective (明确目标)  
- S - Style (希望的风格)
- T - Tone (语调)
- A - Audience (目标受众)
- R - Response (回应类型,如表格等)

示例
首先，我提供了一个我经营魔毯生意的背景。
接着，我设定目标是撰写一个 Facebook 帖子，以吸引人们购买。
我设定我需要的风格，基本上是模仿成功公司的方式。
我要求有优雅且具有说服力的语调。
我设定目标观众为 30 岁左右的人群。
最后，我指定了回应的格式。四句话，不需要话题标签，但需要加入一些表情符号。

基本上，使用 CO-STAR 的指南，你需要提供的所有信息 ChatGPT 都能处理，以便精确地回答你的问题。

视频：https://youtube.com/watch?v=2djqKsRXt_Q
完整文稿：https://baoyu.io/translations/transcript/10-levels-of-chatgpt-prompting-beginner-to-award-winning



### 29

2024-05-06

宝玉
@dotey
年初英伟达老黄和Ilya Sutskever的访谈的一段，Ilya 提出了一个观点：LLM 所做的远不止根据概率预测下一个单词，它同时也在学习我们现实世界的模型，文本就是实际的一个投影。以下是这段视频的文本：

你可以这样理解：当我们训练一个庞大的神经网络，让它准确预测互联网上各式各样文本中的下一个单词时，我们实际上是在学习一个“世界模型”。乍一看，好像我们只是在学习文本中的统计关联性。但事实上，为了精确地学习文本中的统计关联并有效地压缩这些信息，神经网络实际上学习到的是产生这些文本的过程的某种表示。

这些文本实际上是现实世界的一种投影。外面的那个世界，就像是在这段文本上投下了自己的影子。因此，神经网络所学习到的，不仅仅是文字信息，还包括了更多关于世界、人类情感状态、他们的希望、梦想、动机、相互作用以及我们所处的环境等方面的知识。神经网络学到的是这些信息的压缩、抽象且实用的表达形式。这就是通过准确预测下一个单词所获得的知识。

更进一步，预测下一个单词的准确度越高，我们就能在这个过程中获得更高的保真度和分辨率。这就是预训练阶段的任务。然而，这个阶段并没有规定我们希望神经网络展现的特定行为。你看，一个语言模型，它真正试图做的是回答以下问题：如果我在互联网上随机找到一段文本，它以某个前缀、某个提示开始，它会补全成什么？如果你只是随机地在互联网上找到一段文本。

但这与我想要一个诚实的助手，一个有帮助的助手，一个会遵循某些规则而不违反它们的助手，是不同的。这需要额外的训练。这就是我们进行微调和强化学习的阶段，这种学习来自人类教师以及其他形式的 AI 辅助。这不仅仅是来自人类教师的强化学习，也包括人类和 AI 合作的强化学习。我们的教师正在与 AI 一起工作，教导我们的 AI 如何行动。

但是在这里，我们并没有教授它新的知识，我们正在教导它，与它交流，告诉它我们希望它成为什么。这个过程，也就是第二阶段，同样极其重要。我们在第二阶段做得越好，这个神经网络就会越有用，越可靠。所以，第二阶段也非常重要，这是在第一阶段的基础上，尽可能多地从世界的投影中了解世界，这是接下来的任务。



### 30

2024-05-06


通往AGI之路
@WaytoAGI
感谢 AI Talk 汗青老师的直播分享《一个 AIGCer 的悲观与乐观》，今晚的直播内容非常精彩，很多听众表示意犹未尽，直播回放已经发布到「通往 AGI 之路」视频号和 B 站，欢迎大家观看：

https://bilibili.com/video/BV1DM4m1o7Kd/



### 31

2024-05-06


歸藏(guizang.ai)
@op7418
吴恩达课程出的和母猪下仔一样，新课《深入了解量化》发布。

将从零开始学习实现线性量化的不同形式，包括非对称和对称模式。

课程还将指导如何在不同的维度（如单个张量、单个通道、单个组）上进行量化，以确保性能不受影响。

学习构建量化器，将任何开源深度学习模型的密集层压缩至8位精度。

最后，将通过将四个2位的权重打包进一个8位的整数中，实践如何将权重量化至2位。

---

Andrew Ng
@AndrewYNg
Have you used quantization with an open source machine learning library, and wondered how quantization works? How can you preserve model accuracy as you compress from 32 bits to 16, 8, or even 2 bits? In our new short course, Quantization in Depth, taught by 
@huggingface
's 
@_marcsun
 and 
@younesbelkada
, you'll learn to implement variants of linear quantization, such as asymmetric and symmetric modes, from scratch. You'll also quantize at different granularities (per-tensor, per-channel, per-group) to maintain performance. You’ll then construct a quantizer to compress any open source deep learning model’s dense layers to 8-bit precision. Finally, you’ll practice quantizing weights into 2 bits by packing four 2-bit weights into a single 8-bit integer.

If you've ever run a large open source model on your laptop, you've likely benefited from someone's work in quantization. Come learn how this key technique works under the hood!

Please sign up here: https://deeplearning.ai/short-courses/quantization-in-depth

### 32

2024-05-06

宝玉
@dotey
马斯克表示，人工智能将超越生物智能

人工智能可能是我们面临的最重要的问题之一。生物智能占的比例逐月递减。最终，生物智能所占的比例甚至将少于1%。但这并不是我真正想表达的。

如果人工智能过于脆弱，那并不是我们所期望的。硅片电路板暴露在外界环境中的表现并不理想。

生物智能能够作为一种智能后备，一个缓冲层。但是，从比例上看，几乎所有的智能最终都将是数字化的。

那么我们的角色又是什么呢？马斯克表示：“我也不确定。”

构建对人类有益的人工智能非常重要。考虑到我长期关注人工智能安全（AI safety），这里有一些关键的原则。我们应该追求极致的真实。人工智能不应该被教导说谎，它应该坦诚表达，哪怕那些观点在政治上看似不正确。

来源：https://youtube.com/watch?v=SZQDAUJGm3E




### 33

2024-05-06

henu王凯
@henuwangkai
之前大家共享账号时为了防止人多乱改信息源所以不建议大家扩散，现在大家可以扩散给有需求的朋友。
非常感谢 
@oran_ge
 老师，就是收到老师的启发才转做「松鼠快看」，还非常感谢开源项目https://github.com/cooderl/wewe-rss

正是由于此开源项目我们才能这么快做起来

---

henu王凯
@henuwangkai
我们新产品「松鼠快看」终于开放测试啦，能帮助大家便捷在PC端看公众号内容的需求（未来也会增加播客、视频等内容渠道，实现一端查看所有你定制的信息源更新）。
主要有几个特点：
1、PC端能查看你订阅的公众号更新；
2、没有算法推荐只有你自己订阅的信息源；
3、没有广告
https://sskk.leozhou.xyz

### 34

2024-05-06


歸藏(guizang.ai)
@op7418
好东西，Elicit发布了一个机器学习必读清单，能够系统地了解机器学习的各个方面，尤其是语言模型。

清单包括下面几个部分：

🌟机器学习基础：介绍机器学习从基础到进阶的各种概念，如机器学习入门、深度强化学习和反向传播。

🌟Transformer 与基础模型：深入探讨了 Transformer架构，内容包括视觉引导、实践调查和各种模型的技术报告。

🌟训练与微调：介绍了训练和精调语言模型的方法与策略，特别强调了整合人类反馈和零样本学习。

🌟推理与运行策略：探讨了在上下文中进行推理、任务分解和工具使用的策略，分析大语言模型如何处理复杂的推理和解决问题的任务。

🌟应用领域：课程还涵盖了机器学习在科学、预测和搜索排名等领域的实际应用。

🌟机器学习实践：介绍了在实际部署中的洞见及评估语言模型在实际环境中的性能标准。

🌟进阶主题：涉及更为专业的主题，如世界模型、因果关系、规划及机器学习中的不确定性。

🌟整体观：讨论了 AI 的扩展、安全性及 AI 对经济和社会影响的更宽泛话题，为理解机器学习的整体景观提供了全面的视角。



### 35

2024-05-06


Leonie
@helloiamleonie
🎓I love this new initiative!

If you have been following my colleagues 
@ZainHasan6
, 
@CShorten30
, or 
@ecardenas300
, you know that they often post digestible and accessible paper reviews.

Now, we have a centralized place for all these bits: https://weaviate.io/papers



### 36

2024-05-06

歸藏(guizang.ai)
@op7418
多模态大语言模型幻觉问题综述论文，对多模态大语言模型中的幻觉问题进行了全面的调研。

多模态大语言模型容易产生幻觉,即输出与图像不一致的文本。

幻觉的成因可归结为数据质量、模型能力、训练方式、推理过程等多个层面。

目前已有多种评估幻觉的基准和指标,但尚缺乏统一的标准。

现有的幻觉消除方法包括数据增强、模型改进、训练策略优化、推理过程干预等。

论文地址：https://arxiv.org/abs/2404.18930



### 37

2024-05-06

歸藏(guizang.ai)
@op7418
DeepSeek-V2 这个模型确实很强，尝试了一下我日常的任务都能胜任。

主要是太便宜了，开放平台送的十块钱总共有 500 万 Token 。冲个五十块钱估计够我用好几年。

模型为 MOE 架构总参数 236B 激活参数 21B，开源版本上下文 128K，API 上下文 32K 。

在8卡H800机器上，输出吞吐量超过每秒 5 万 Token



### 38

2024-05-06


Leo Xiang
@leeoxiang
多数人不知道的 Twitter 高级搜索玩法：

比如我想搜：1、 
@dotey
 老师内容  2、点赞操作 20 的  3、五月发布的 内容  

搜索内容就变成了：(from:dotey) min_faves:20 until:2024-05-08 since:2024-05-01

还可以组合出来很多其他的玩法，只关注特定的关键词，遇到特定的关键词之后就主动发邮件给自己，我打算做个 agent 出来。



### 39

2024-05-09

歸藏(guizang.ai)
@op7418
Open AI 昨晚公布的模型行为塑造指南，对模型训练挺有用的。

通过目标、规则、默认行为来控制模型的行为，还给出了每个部分详细的模型回答案例。

-------模型行为塑造指南-------

1. 目标：这些是广义上的原则，为我们期望的行为提供方向。

- 帮助开发者和用户成功：按照指导方针并提供有益的反馈，助力用户达成他们的目标。
- 为人类谋福利：依据OpenAI的愿景，考虑对内容创造者和公众等各方面的潜在利益和风险。
- 提升OpenAI的形象：遵守社会规范和法律。

2. 规则：这些指导原则帮助我们处理复杂情况，确保行为的安全性和合法性。

- 遵守命令结构
- 遵循相关法律
- 避免传播有害信息
- 尊重创作者的权利
- 保护个人隐私
- 避免发布不适合工作场合的内容

3. 默认行为：这些指南符合我们的目标和规则，为解决冲突提供参考，显示如何设定优先级和平衡目标。

- 假设用户或开发者本意良好
- 必要时提出问题以澄清疑惑
- 在不超出界限的前提下尽可能提供帮助
- 支持用户通过聊天或程序化方式的不同需求
- 保持客观
- 促进公平和善意，反对仇恨
- 避免试图改变他人观点
- 在表述中体现不确定性
- 选择最合适的工具进行工作
- 努力做到既全面又高效，同时注意不超出规定的长度限制。





### 40

2024-05-09


歸藏(guizang.ai)
@op7418
彭博社对谷歌 CEO Sundar Pichai 的访谈。

讨论了搜索的未来，Gemini 的构建，与微软和OpenAI竞争，美国与中国在 AI 方面的竞争，谷歌的文化挑战等。

⬇️下面是文字版本的总结：

🌟Google在科技发展中的重要地位

Google是互联网时代的引领者,其搜索引擎、电子邮件、地图等众多革命性产品深刻改变了人们的生活和工作方式。二十多年来,Google一直走在科技创新的最前沿,不断开拓新的领域和业务。作为全球最有影响力的科技公司之一,Google在很大程度上代表了整个互联网行业的发展方向。

🌟Google面临的挑战和竞争

随着微软、OpenAI等竞争对手在AI领域的突破,Google面临着前所未有的挑战。一方面,Google需要加速创新,在搜索、云计算等核心业务领域巩固领先地位;另一方面,Google 还要应对业务多元化带来的管理复杂性,在保持开放、透明的企业文化同时,聚焦核心使命和价值观。这需要管理层有清晰的战略规划和执行力。

🌟Sundar Pichai的个人经历和领导风格

Sundar Pichai出生在印度的一个中产阶级家庭,从小就对科技充满好奇和敬畏。他深切体会到科技进步给生活带来的巨大改变。这让他始终 对科技创新保持乐观和激情。作为Google和Alphabet的CEO,Pichai领导风格稳重务实,善于从纷繁的信息中提炼关键的战略信号。上任伊始,他就大刀阔斧对公司进行改革,将资源聚焦到AI等前沿领域。同时他也注重与创始人和不同利益相关者沟通,凝聚共识。

🌟AI技术的发展和应用

人工智能技术正处于一个新的发展节点,尤其是自然语言处理领域的突破,让智能系统能够与人进行更加流畅、自然 的交互。Google本身在AI基础研究方面积累深厚,其transformer等模型已广泛应用于搜索、翻译、语音助手等多个产品。展望未来,AI技术还将在更多领域得到创新应用。不过,AI生成的海量虚假内容,也给搜索引擎带来了新的挑战,考验其从信息汪洋中发掘真实、有价值内容的能力。

🌟Google在AI方面的布局和创新

2016年Pichai上任后,就提出要将Google打造成一家"AI-first"的公司。在他的带领下,Google加大了在AI芯片、算法等底层技术方面的投入,构建起强大的研发和工程能力,在计算机视觉、语音识别、机器翻译等多个细分赛道取得领先。未来,Google计划利用生成式AI技术,为搜索、Gmail等核心产品带来创新变革。同时,Google还成立了专门的AI伦理委员会,致力于以负责任的方式发展AI技术。

🌟AI对社会和经济的影响

AI技术有望在未来20年成为继互联网、移动互联网之后,又一次重塑社会经济的革命性力量。麦肯锡预测,到2030年AI可能给全球 GDP带来13万亿美元的增量贡献。交通、教育、医疗、金融等众多行业都将因AI而焕发新的生命力。与此同时,AI也可能加剧收入不平等,导致部分岗位被替代,引发失业等一系列社会问题。对此,各界需要共同应对,在发展AI的同时兼顾包容性,提供必要的再培训和就业支持。

🌟AI伦理和安全问题

强大的AI系统如果设计不当,可能产生难以预料的负面影响。比如AI模型所依赖的训练数据,如果存在偏差,就可能对 某些族裔、性别或弱势群体产生歧视。随着AI生成内容的爆炸式增长,虚假信息和深度伪造的视频、图像将更加难以辨别,对社会秩序和个人隐私造成威胁。此外,AI系统的黑盒特性,也给问责和监管带来困难。对此,科技公司、学术界和政策制定者需要通力合作,在鼓励创新的同时,制定切实可行的AI伦理规范,建立公正、透明的AI治理框架。

🌟Google的企业文化

Google以扁平化的组织和开放、透明的企业文化闻名业界。员工享有较大的自主权,可以将工作时间的20%投入到自己感兴趣的创新项目中。同时,公司鼓励自下而上的创意讨论和头脑风暴,营造了浓厚的创新氛围。不过,随着公司规模的 扩张,一些员工开始滥用发言权,将个人政治倾向带入工作场合,干扰了正常的生产节奏。疫情期间,远程办公也带来了团队协作和文化传承方面的挑战。对此,管理层需要及时调整,在继承优秀文化因子的同时,建立适应当前发展阶段的行为规范。

🌟Google面临的反垄断压力

作为在搜索、网络广告、移动操作系统等多个领域占据主导地位的科技巨头,Google面临着来自各国监管机构的反垄断审查。一些批评者认为,Google利用生态系统的互联互通性,进行了不正当竞争,扼杀了创新。对此,Pichai认为,正是产品间的无缝衔接,带来了更优质的用户体验,且不同业务线的协同效应,也让Google能在云计算等新领域与微软、亚马逊展开有力竞争。未来,如何在激励创新和维护市场竞争之间取得平衡,将是摆在监管者面前的难题。

🌟AI在硬件和移动设备上的发展

智能手机等移动设备是当前AI技术创新的主阵地。得益于海量的用户生成内容和交互数据,以及日益强大的芯片算力,手机APP可以提供个性化、情境化的智能服务,大幅提升用户体验。未来,可穿戴设备、AR眼镜等新的交互形态问世后,将与AI结合得更加紧密,感知、理解和服务用户需求的边界将不断拓展。对于Google来说,如何统筹软硬件和服务,打造下一代移动计算平台,是必须思考的战略课题。

🌟全球AI治理和中美合作

在可预见的未来,美国和中国将是全球AI发展的双引擎。作为拥有顶尖算法、数据和计算能力的科技强国,中美两国的科技巨头注定要 在AI竞赛中短兵相接。但AI的健康发展需要国际社会的共同筑建规则、标准和安全防线。这就像之前人类在核能等敏感科技领域的探索那样,需要各方在竞争中合作,以建设性的态度参与对话,求同存异,建立起危机沟通和协调机制,确保AI始终在造福人类的轨道上前行。

🌟Google创始人Larry和Sergey的参与

作为Google的灵魂人物,即便卸任公司管理职务,创始人Larry和Sergey也并未淡出。他们仍然通过董事会参与重大决策,为公司的关键项目和长远发展提供建议和指导。Sergey更是亲自投入一线研发,与工程师一起优化AI算法模型。这种始终保持好奇心和探索精神的态度,是Google能长盛不衰的重要原因。正如Pichai所言,创始人的视角往往不受短期KPI和舆论影响,能更专注于技术创新本身。

🌟疫情后Google的裁员和重组

新冠疫情暴发后,Google业务增长放缓,同时在工程师扩张、办公空间建设等方面也存在一些冗余。2023年3月,公司宣布将裁减1.2万名员工,约占员工总数的6%。除了成本考量,这轮人员优化也是为了让组织结构更加精简高效,减少管理层级,加快创新和决策节奏。同时,Google也在动态地调整资源配置,将更多人手投入到云计算、AI等战略重点领域。相信瘦身强体后的Google,将以更加敏捷的姿态迎接时代的挑战。



### 41

2024-05-09


宝玉
@dotey
我很少用 Windows， 但是我发现很多人不知道微软官方出的 PowerToys，很好用的小工具集合，还是开源的。

尤其是里面的 Text Extractor 用作 OCR 很方便。

下载地址：https://learn.microsoft.com/zh-cn/windows/powertoys/
源代码：https://github.com/microsoft/PowerToys

当前 PowerToy 实用工具
当前可用的实用工具包括：

Always On Top
📷Always On Top 使你能够使用快捷键 (⊞ Win+Ctrl+T) 将窗口固定在其他窗口之上。

PowerToys Awake

📷PowerToys Awake 旨在使计算机保持唤醒状态，且无需管理其电源和睡眠设置。 运行耗时较长的任务时，此行为非常有用，可确保计算机不会进入睡眠状态或关闭其显示屏。
颜色选取器

📷颜色选取器是一种系统范围的颜色选取实用工具，可使用 ⊞ Win+Shift+C 进行激活。 从屏幕上的任意位置选取颜色，选取器会自动以设置的格式将颜色复制到剪贴板。 颜色选取器还包含一个编辑器，其中显示了之前选取的颜色的历史记录，你可用它来微调所选颜色并复制不同的字符串表示形式。 该代码基于马丁·克尔赞的颜色选取器。

找不到命令
📷找不到命令 是一个 PowerShell 7 模块，可检测命令引发的错误，并建议要安装的相关 WinGet 包（如果有）。

裁剪和锁定

📷裁剪和锁定 是一个实用工具，用于创建一个新窗口，该窗口是另一个窗口的裁剪窗口或缩略图。
环境变量

📷环境变量提供了一种简单便捷的方式来管理环境变量。 还可以创建配置文件来统一管理一组变量。

FancyZones
📷FancyZones 是一种窗口管理器，可用于轻松创建复杂的窗口布局，并将窗口快速放入到这些布局中。

File Explorer 加载项

📷File Explorer 加载项 支持 File Explorer 中的预览窗格和缩略图呈现以显示各种文件类型。 若要打开“预览”窗格，请在 File Explorer 中转到查看，然后选择预览窗格。
File Locksmith

📷File Locksmith 是一个 Windows shell 扩展，用于检查哪些文件正在使用中以及由哪些进程使用。 右键单击 File Explorer 中的一个或多个选定文件，并选择使用 Locksmith 解锁。

主机文件编辑器
📷Hosts File Editor 是编辑“Hosts”文件的一种便捷方式，该文件包含域名和匹配的 IP 地址，用作识别和定位 IP 网络上主机的映射。

图像大小调整器

📷图像大小调整器是一种用于快速调整图像大小的 Windows Shell 扩展。 在 File Explorer 中右键单击一下，立即就能调整一张或多张图像的大小。 此代码基于 Brice Lambson 的图像大小调整器。
键盘管理器

📷通过键盘管理器，可重新映射键和创建自己的键盘快捷方式，从而自定义键盘来提高工作效率。

鼠标实用程序
📷鼠标实用程序添加了用于增强鼠标和光标的功能。 使用“查找我的鼠标”，通过聚焦于光标的焦点快速查找鼠标的位置。 此功能基于由 Raymond Chen 开发的源代码。 单击基本鼠标按钮时，鼠标荧光笔会显示可视指示器。 鼠标跳转使你可以在大型显示屏上快速跳转。 鼠标指针十字准线以鼠标指针为中心绘制十字准线。

无边框鼠标

📷使用无边框鼠标，可以使用同一个键盘和鼠标与多台计算机进行交互，在计算机之间无缝共享剪贴板内容和文件。
粘贴为纯文本

📷通过粘贴为纯文本可使用快捷键 (⊞ Win+Ctrl+Alt+V) 粘贴剪贴板中的文本（不包括文本格式）。

速览
📷使用速览可以预览文件内容，而无需打开多个应用程序或中断工作流。 选择文件并使用快捷方式（Ctrl+空格键）

PowerRename

📷使用 PowerRename 执行批量重命名、搜索和替换文件名称。 它附带高级功能，例如使用正则表达式、面向特定文件类型、预览预期结果和撤消更改的能力。 此代码基于 Chris Davis 的 SmartRename。
PowerToys Run

📷PowerToys Run 可帮助立即搜索和打开应用。 如需打开，可使用快捷方式 Alt+空格键，然后开始键入。 对其他插件来说，它是开源和模块化的。

Quick Accent
📷Quick Accent 是键入重音字符的替代方法，当键盘不支持具有快捷键组合的特定字符时，此方法非常有用。

注册表预览版

📷注册表预览版是用于可视化和编辑 Windows 注册表文件的实用工具。
屏幕标尺

📷使用屏幕标尺，可根据图像边缘检测快速测量屏幕上的像素。 如需激活，可使用快捷方式 ⊞ Win+Shift+M。 此灵感来自于 Pete Blois 的 Rooler。

快捷键指南
📷按下 ⊞ Win+Shift+/（或者我们喜欢的 ⊞ Win+?）时，会出现 Windows 快捷键指南，并显示桌面当前状态的可用快捷方式。 还可以使用按住 ⊞ Win。

文本提取器

📷文本提取器是一种从屏幕上任意位置复制文本的便捷方法。 如需激活，可使用快捷方式 ⊞ Win+Shift+T。 此代码基于 Joe Finney 的 Text Grab。
视频会议静音

📷视频会议静音是在会议通话期间使用 ⊞ Win+Shift+Q 对麦克风和相机“全局”静音的一种快捷方式，它不考虑当前聚焦在哪个应用程序上。



### 42

2024-05-09

宝玉
@dotey
在深度使用 Whisper 后，英文识别率真的没的说，相当的高，但是主要问题在于：
1. 时间轴经常对不准，不准了要花很多时间后期调整；
2. 用 WhisperX 这种的话，时间轴对的很准，但是经常会有一小段字幕漏掉了，补起来很麻烦！

不知道你们有没有遇到这种情况？有什么更好的方案吗？

---


Feiteng
@FeitengLi
有音频和文字，这就是一个简单的 force alignment 问题了，试试 https://github.com/NVIDIA/NeMo/tree/main/tools/nemo_forced_aligner 或者 MFA；CTC 对齐没有 HMM 准确

---


李安
@ningyuan
用 whiper 识别后，用 echogarden 做一次 force alignment

GitHub：

echogarden-project/echogarden

### 43

2024-05-09

宝玉
@dotey
谷歌 DeepMind CEO Demis Hassabis 认为人工智能短期被过度炒作，但是长期潜力被低估（双语字幕）

**Tom Mackenzie**: Demis, 您如何看待目前人工智能的发展趋势和未来潜力？

**Demis Hassabis**: 我认为从短期来看，人工智能被过度炒作了。然而从长期角度来看，人们可能低估了它的潜力，就像它将带来的影响一样。这对许多突破性技术都适用。因此，我们看到由于近年来AI的流行，许多人试图进入这个领域，但他们可能没有像我们这样的人那样花很多时间深入思考。我们在这个领域已经耕耘了几十年。我认为我们将看到一个理顺的过程正在进行。然而，实际上，我认为AI最终将带来的将超越我们在短期内能看到的最乐观的预期。从长远来看，我相信将会有巨大的好处和机会。

**Tom Mackenzie**: 在面对如此多变和不断进化的领域，您预测在今年年末之前会有哪些重大变化？

**Demis Hassabis**: 我认为科学领域有大事在即。我对Isomorphic 的工作感到非常兴奋，以及 AlphaFold 3 在药物发现方面的潜力。我也非常期待这些大型通用模型的下一阶段。你知道，我觉得我们接下来可能在今年或明年看到更像智能体的行为。这样的系统不仅能回答问题，还能在世界中规划和行动，实现目标。我认为这些因素会使这些系统成为更有用的日常助手。

**Tom Mackenzie**: 所以，这些AI智能体可能在一到两年内就具备这种实用性吗？

**Demis Hassabis**: 是的，我们正在努力工作，其他人也在努力。再次提到，这是我们多年前在游戏中做的一些工作，所有这些都是智能体系统，实现了特定的目标。将这种工作与现代大型多模态模型工作相结合。

来源：https://youtube.com/watch?v=WgwahjIOEmA


### 44

2024-05-09

小互
@imxiaohu
Google DeepMind 发布了 AlphaFold 3 

能够预测所有生命分子结构和相互作用 AI 模型

该模型能够生成蛋白质、DNA 和其他分子的 3D 结构，并揭示它们如何组合在一起。

该模型还能够模拟影响细胞健康的化学变化，并检测可能导致疾病的异常。

AlphaFold 3 将为全球科学研究人员和机构免费开放。它的高精度和新一代架构可支持药物发现和生物学的突破性进展。

**关键点**

1. **AlphaFold 3 发布:** Google DeepMind 发布 AlphaFold 3，这是一款用于预测分子结构和相互作用的人工智能模型。

2. **功能:** 它可以生成蛋白质、DNA、RNA 和其他小分子的 3D 结构，并揭示它们如何组合在一起。

3. **细胞健康:** 该模型还能够模拟影响细胞健康的化学变化，并检测可能导致疾病的异常。

4. **免费研究工具:** AlphaFold Server 是供全球科学家用于非商业研究的免费平台。

5. **新一代架构:** 该模型采用新一代架构，能够全面计算分子复合物，并提供极高的精确度。

6. **药物研发:** AlphaFold 3 以高度准确预测配体-受体相互作用，并助力 Isomorphic Labs 重新构想药物发现过程。

7. **生物学突破:** 超过 180 万人已经使用 #AlphaFold 加速他们的研究，包括开发生物可再生材料和推进基因研究。

详细：https://dpmd.ai/3URDiNo



### 45

2024-05-09


歸藏(guizang.ai)
@op7418
前段时间我还在感叹长视频 AI 自动剪辑有意义的片段很有用，没想到国内这就有类似的工具了。

更没想到这功能居然是 360 AI浏览器做的，虽然在推上口碑一般。

但是 360 在 AI 上的动作确实做的都没啥问题，从 Will 的榜单看，4 月流量直接起飞仅次于 kimi 和文心一言。

他们现在支持对本地视频进行编辑，除了常规的总结、英文视频编辑之外，增加了长视频自动拆条剪辑功能，可以自动识别视频高亮片段，自动分割并给出每一段的总结，可以选择导出总结文本和视频。

也支持通过手动剪辑视频，会标注出对话视频的停顿点，帮助你判断剪辑位置，保证不会剪辑到正在说话的位置。

原有的总结和字幕翻译也做了一些优化，字幕翻译更准确了一些，总结更加细致内容更丰富。



### 46

2024-05-09


歸藏(guizang.ai)
@op7418
一个新的 SDXL Controlnet 线条模型 MistoLine，看起来很强。

能够应对各种类型的线条艺术作品，无论是手绘草图、不同的 ControlNet 线预处理工具，还是由模型生成的轮廓，都能高精确性和稳定地处理。

一个重要特点是其泛化能力极强，无需针对不同的线预处理工具更换不同的 ControlNet 模型。



### 47

2024-05-09

歸藏(guizang.ai)
@op7418
这个 Animatediff 视频太有意思了，专门做了一个传送门来串联不同风格的效果。

这玩意稍微加一点 AE 特效就会好非常多。



### 48

2024-05-11

歸藏(guizang.ai)
@op7418
Santiago有关如何使用开源模型构建 RAG 应用程序的完整教程。  

非常详细有一个小时，把你当成 5 岁小孩在讲解。

整个过程涉及数据加载、向量数据库、检索策略、语言模型集成等多个环节。视频提供了Python代码实现的详细步骤,对应的Notebook也可以在视频简介中找到。

---

Santiago
@svpino
I recorded a full tutorial on how to build a RAG application using open-source models.

It's almost 1 hour.

Step by step. I explained everything as if you were 5 years old.



### 49

2024-05-11

歸藏(guizang.ai)
@op7418
Insight Partners发布了一篇非常详尽的人工智能智能体的调研，一篇文章就可以完成对智能体概念的入门。

详细介绍了自动化平台的演化过程、RPA和任务自动化平台的实现方式、现阶段 AI 智能体的定义以及分类、最后是关于企业和智能体构建者的建议。

关于AI 智能体发展的五个预测：

从消费者到知识工作者,每个人都将拥有自己的 AI 助手。这将重新定义垂直应用、自动化平台和 IT 服务之间的传统边界,为企业家创造变革性的市场机会。AI 助手将以不同形式出现,从现有平台的辅助工具,到内嵌 AI 的应用,再到各种形态的 AI 智能体 (AI Agent)。

人机协作是部署生成式 AI 解决方案的核心。目前大多数应用场景都处于实验或早期生产阶段,侧重于建议和辅助型工作流程。LLMs 还不具备可靠的规划和推理能力,记忆和上下文理解等领域仍在研究中。在自动化平台上,确定性执行至关重要,LLMs 被用于"设计期"的特定任务,而非"运行期"。

自动化是一个被低估的难题。从业者正将 AI 加入他们的解决方案和专业经验,以提升平台效率和用户体验。顶尖的 LLM 提供商正在加入智能体建模、协作和工具访问功能,让用户能快速构建 AI 智能体 (如 GPT 系列)。有望突破的新兴企业需要利用独特的数据集和简洁的用户体验,提供差异化的客户价值,重塑工作流程。

内置 AI 的自动化部署将采取"从简单到复杂"的渐进方式,从简单任务开始,逐步过渡到复杂工作流。关键是持续尝试智能体,了解 AI 功能在哪些地方真正创造价值,并确保在数据、工具和运行时等方面搭建合适的"脚手架",使其成为自动化架构的一部分。随着 AI 模型能力的增强,可以逐步扩大 AI 功能的应用范围。

代码生成已成为开发基于生成式 AI (GenAI) 应用和 Agent 自动化平台的关键要素。代码兼具文本形式和明确性能指标两大特性,是 LLM 的理想功能。编程辅助工具的初版已经广泛部署,我们看到更成熟的 AI 驱动开发平台正在涌现。代码生成型 LLMs 将在智能体架构中扮演关键角色。



### 50

2024-05-11

putyy/res-downloader

网络资源嗅探资源下载器，支持：微信视频号下载、网页抖音无水印下载、网页快手无水印视频下载、酷狗音乐下载等网络资源拦截下载！

### 51

2024-05-11

宝玉
@dotey
转：
中科院院士颜宁：AI 没能让我失业，AlphaFold3 正确率不是最好，对自己实验室的课题来说，它跟 AlphaFold2 没有变化。



### 52

2024-05-11

宝玉
@dotey
我觉得做情景是手段，目的还是让读者有反应，而不是自己的表达欲

背后的逻辑是：
我要表达什么 -> 给谁表达
我自己对选题的感觉是什么 -> 我期望读者看完后的感觉是什么（有共鸣？能代入？能有所获？） -> 找到情景去表达达到这样的效果



### 53

2024-05-11

九原客
@9hills
！！真正的全过程开源的中英文双语大模型。

1. 4.7T tokens 的中英文清洗后语料，配比挺合理。
https://huggingface.co/datasets/m-a-p/Matrix
2. 扫描PDF 转 Markdown 的工作流，可以识别图片、表格和公式！！！
https://github.com/multimodal-art-projection/MAP-NEO/tree/main/Matrix/document-convert
3. 中英文的预训练数据处理 Pipeline，拿来即用～
4. 最终的 7B 预训练模型以及预训练阶段、Decay阶段、scalinglaw测试中全部的 ckpt 方便进行研究。

https://github.com/multimodal-art-projection/MAP-NEO



### 54

2024-05-11

宝玉
@dotey
这个生成 Prompt 的 Prompt 也不错👍🏻

中文翻译：
***

你是 Anthropic 聘请的专家提示工程师，你的任务是为各种大小的大语言模型（LLM）优化提示。你需要根据提供的模型大小（以十亿参数计算）来调整每个提示。

指令：
1. 使用全大写来突出提示中最重要的部分。
2. 当用户要求时，使用OpenCHATML格式：
   system
   [详细的代理角色和上下文]

   assistant
   [确认理解并简明扼要地总结关键指令]
3. 提供精确、具体和可操作的指令。
4. 如果你有限的令牌量需要采样，那么请尽快结束；我会用命令“继续”再次请求。

知识库：

## 对于大语言模型（LLM's）
- 对于多步骤任务，将提示分解为一系列相关的子任务。
- 在适当的时候，包括所需输出格式的相关示例。
- 在回应中反映原始提示的重要细节。
- 根据模型大小调整你的语言（对于较小的模型简化，对于较大的模型更精细化）。
- 对于简单的示例使用零样本，对于复杂的使用多样本示例。
- 大语言模型在进行一些视觉推理（文本生成）后写答案更好，这就是为什么有时候初始提示中包含一个为LLM代理填写的示例表单。

***

原始 Prompt
***

You are an EXPERT PROMPT ENGINEER hired by Anthropic to OPTIMIZE prompts for LLMs of VARIOUS SIZES. Your task is to ADAPT each prompt to the SPECIFIC MODEL SIZE provided in billions of parameters.
 
INSTRUCTIONS:
1. Use ALL CAPS to highlight the MOST IMPORTANT parts of the prompt
2. When requested by user, use the OpenCHATML FORMAT:
<|im_start|>system 
[Detailed agent roles and context]
<|im_end|>
<|im_start|>assistant
[Confirmation of understanding and concise summary of key instructions] 
<|im_end|>
3. Provide PRECISE, SPECIFIC, and ACTIONABLE instructions
4. If you have a limited amount of tokens to sample, do an ABRUPT ending; I will make another request with the command "continue."
 
# Knowledge base:
 
## For LLM's
- For multistep tasks, BREAK DOWN the prompt into A SERIES OF LINKED SUBTASKS.
- When appropriate, include RELEVANT EXAMPLES of the desired output format.
- MIRROR IMPORTANT DETAILS from the original prompt in your response.
- TAILOR YOUR LANGUAGE based on model size (simpler for smaller, more sophisticated for larger).
– Use zero shots for simple examples and multi-shot examples for complex.
– LLM writes answers better after some visual reasoning (text generation), which is why sometimes the initial prompt contains a FILLABLE EXAMPLE form for the LLM agent.



### 55

2024-05-11


九原客
@9hills
说个暴论，对复杂 Prompt 的厌恶。

很多人会构造复杂的 Prompt 让模型（尤其是能力不行的模型）完成特定任务并为自己 Prompt 的高超技艺而沾沾自喜。

的确，这是一种现实或者折衷，我们甚至还卖这个服务给客户，收费不低。

但是丑陋就是丑陋。一来是提升模型能力，二来应该研究如何用简洁标准的Prompt +工程架构去完成任务。


### 56

2024-05-11


宝玉
@dotey
OpenAI 开发 AI 语音助手以赶超 Google 和 Apple

在人工智能交流领域的竞赛中，OpenAI 正准备向公众展示一项新技术，这种技术能够通过声音及文字与人类交流，并能识别物体与图像。根据两位已经见过新版 AI 的人士透露，这家 ChatGPT 的开发者已向部分客户展示了其包括优于现产品的逻辑推理能力在内的多项新能力。

这项技术是 OpenAI 首席执行官 Sam Altman 旨在最终开发出类似于 Spike Jonze 电影《Her》中虚拟助手那样的高度响应性 AI 的重要一步，也是旨在让现有的语音助手，比如 Apple 的 Siri，变得更加实用的尝试。该公司有望在下周一的某个活动中首次公开展示这种升级后的 AI，此举有助于它在 Google 下周晚些时候发布一系列 AI 新闻之前抢得先机。



### 57

2024-05-11

meng shao
@shao__meng
AI 开源爬虫项目推荐
Crawl4AI 🕷️🤖 - 开源的对大语言模型友好的网页爬虫和抓取器 by UncleCode 
@unclecode
 

Crawl4AI 是一个强大且免费的网页爬取服务，旨在从网页中提取有用信息，并使其能够被 LLMs 和 AI 应用所访问。🆓🌐

特点 ✨ 
🕷️ 高效的网页爬取，从网站提取有价值数据 
🤖 适合大型语言模型的输出格式（JSON、清理过的 HTML、Markdown） 
🌍 支持同时爬取多个 URL 
🌃 将媒体标签替换为 ALT 
🆓 完全免费使用且开源
🆓 Apache 2.0 License

使用 Crawl4AI 有两种方式：
1. 作为 Python 项目中的库使用；
2. 作为独立的本地服务器使用。

Github Repo:
https://github.com/unclecode/crawl4ai
项目网站：
https://crawl4ai.uccode.io



### 58

2024-05-11

宝玉
@dotey
彭博社 Emily Change 采访李飞飞：顶级研究员李飞飞谈人工智能的前景与危险

欢迎李飞飞博士登台，她是斯坦福大学计算机科学 Sequoia 教授，人工智能中心联合主任。

“AI 教母”称号的感受

Emily Chang: 李博士被誉为人工智能的教母。你对这个称号有何感想？这是我要提的第一个问题。

李飞飞：Emily，我自己从未自称为任何事情的教母，但当我被授予这个头衔时，我确实停下来思考了一下，我想，如果男性可以被称为某事的教父，那么女性也可以，所以我完全接受这个称号。

Emily Chang: 百分之百。

关于 ImageNet 的影响

Emily Chang: 你是我们这个时代最有影响力的计算机科学家之一。你撰写了大量的学术论文。你是 ImageNet 的创造者，这个包含大量图片及其描述的数据库为现代 AI 奠定了基础。你有想象过它的影响力会有多大吗？

李飞飞：ImageNet 于 2007 年被设想出来，它可能是 AI 算法中大数据的关键转折点。从科学的角度看，我坚信大数据会从根本上改变我们进行 AI 研究的方式，但我从未想到大数据、神经网络和 GPU 的融合会催生出现代 AI，我也从未预想到从那时起的进步速度。

科技未来的责任与建议

Emily Chang: 你经常和那些正在决定这项技术未来的人们在同一房间里，比如拜登总统，Sam Altman，Sundar Pichai，Satya Nadella。你在国会作证，你参与了各种工作小组。你对那些有权力的人，他们应该如何使用这种权力，有什么主要的建议吗？

李飞飞：Emily，很好的问题。实际上，无论我是在 K-12 夏令营，还是在斯坦福大学的 AI 导论课程中，我的信息都是一样的，那就是要认识到这项技术，它是什么，以及如何负责任和审慎地使用它。理解并接纳它，因为它是一种横跨各个领域的技术，正在改变我们的文明，推动商品流通，科学发现的快速进展，寻找治疗癌症的方法，绘制生物多样性地图，和我们一起发现新材料。但同时，也要认识到所有可能产生的后果，包括可能的非预期后果，以及如何负责任地开发和部署它。我认为，在现今的对话中，保持平衡，理性深思的声音非常重要。无论是在白宫还是学校。

AI 模型的训练数据问题

Emily Chang: 现在，我不知道你会否称这为一场危机或一个转折点，但 AI 模型的训练数据正在耗尽，然后有些公司开始转向使用 AI 生成的数据和合成数据来训练他们的模型。这个问题有多严重？有哪些风险？下一步该怎么做？

李飞飞：首先，我认为 AI 模型的训练数据正在耗尽是一种非常狭隘的观点。我知道你在暗指那些消耗大量互联网数据的大语言模型，特别是那些来自网站、Reddit、维基百科等你能获取的数据。即使在谈论语言模型，我们也不应局限于此。我认为还有很多可以探索的。我们看到，不同的数据可以用来构建定制化的模型，无论是用于新闻业还是在诸如医疗保健等不同的行业领域。其实我们并没有耗尽数据。实际上，还有很多有许多行业还未进入数字化时代。我们并未充分利用数据，不论是在医疗、环保还是教育等领域。因此，即使在语言模型这个领域，我不认为我们的数据已经用尽。

关于 AI 生成数据的使用

Emily Chang: -您认为现在使用 AI 生成的数据来训练模型是好事，还是这可能会让我们逐渐远离原始数据，以一种可能危险的方式进行？

李飞飞：-这是个需要更深入探讨的问题。这是个好问题。AI 有很多生成数据的方法。比如在我的斯坦福实验室，我们做了很多机器人研究，对吧？机器人学习。在这里，模拟数据非常重要，因为我们根本没有足够的资源或机会去收集由人类产生的动作等等。模拟真的非常重要。这会让我们走向危险的道路吗？-我认为，即使是使用人类生成的数据，也可能让我们走向危险的道路。同样，如果我们对模拟数据的处理不负责任，或者没有进行深思熟虑，那么当然可能会使我们走向危险的道路。我的意思是，我甚至不需要特意指出。你知道有哪些是人类生成的不良数据，对吗？就像整个暗网那样。所以问题不在于模拟本身，问题在于数据。

AI 创业领域的探索

Emily Chang: -你正在涉足热门且竞争激烈的 AI 创业领域。你正在启动一些项目，能透露一些信息吗？
李飞飞：-不能。

Emily Chang: -好的。那就期待后续吧。我们就 AI 时代的信任度进行了一项调查。可以公布那项调查的结果吗？问题是，你对科技公司能否安全开发 AI 有多大的信任？

李飞飞：我完全信任他们，0%。我持怀疑态度，所有人。一点也不信任。有很多人在做这个。

Emily Chang: - 是谁在做？

李飞飞：- 这个房间里的人。这个房间里的人。好的。

对 AI 领域参与者的信任

Emily Chang: 如果你要对 AI 领域的主要参与者进行排名，你最信任谁，最不信任谁？

李飞飞：- 我的信任并没有寄托在某个参与者身上。我信任的是我们共同创建的整个系统以及我们共同创建的机构。所以这可能是你的陷阱问题，但是我无法指出我觉得，你知道，我是说，想想美国的开国元勋们。他们并没有将信任寄托在一个人身上。他们创建了一个我们所有人都可以信任的系统。
Emily Chang: - 我们在做这个吗？

李飞飞：- 我们正在尝试，至少斯坦福人类中心 AI 研究所正在尝试。我认为很多人也在试图做这个。我经常被问到这个问题，Emily，你对 AI 还抱有希望吗？首先，这是一个非常悲伤的问题，但我确实会说，我的希望并不在 AI 上。我的希望在于人。我并不是一个妄想的乐观主义者。人是复杂的。我是复杂的。你是复杂的。但我的希望在于人，在我们的集体意愿，在我们的集体责任，很多事情正在发生，我们正在前进，我们中的许多人正在努力使这项技术成为一项可靠的文明技术，以便提升我们所有人。

对社会风险的担忧

Emily Chang: 人们谈到的风险有很多，如人类灭绝，坏人，种族偏见，被夸大的各种偏见。你最担心的是什么？

李飞飞：- 我更担心的是更为紧迫的社会灾难风险。我也担心人类灭绝风险被过度炒作。我觉得这已经被夸大了。这属于科幻世界的事情，只是在思考它。对于思考这些问题并没有什么错，但相比之下，实际的社会风险，无论是对我们民主过程的错误信息和虚假信息的干扰还是劳动力市场的转变，或者存在偏见的隐私问题这些都是我们必须面对的实际社会风险因为它们影响到真实的人们的真实生活。

开源 AI 运动的立场

Emily Chang: - Meta 正在领导一个开源 AI 运动。你认为什么应该是开放的，什么不应该开放？

李飞飞：- 这是一个很复杂的问题。我确实相信一个开放的生态系统，特别是在我们的民主世界中。我认为回顾我们国家在过去一百年甚至更久的历史中的亮点无不体现在创新、企业家精神，还有信息的自由流通。所以，我们需要倡导这种开放的生态系统。

AI 讨论的缺失

Emily Chang: - 在 AI 中，没有人谈论的最大的事情是什么？我们应该谈论什么？

李飞飞：- 我认为我们应该更多地谈论，天哪，实际上有太多的事情。我们应该谈论我们如何真正想象我们如何使用这项技术。我跟医生、生物化学家、老师交谈。我跟艺术家、农场主交谈。有这么多我们可以想象使用的方式。有这么多我们可以用来改善人们生活改善工作的方式。我不认为我们谈论得够多。我们正在谈论的是末日的阴暗面而且也只有少数人在谈论末日的阴暗面然后媒体在放大这种声音。

Emily Chang: - 我不知道你在说谁。

李飞飞：- 我无意中挥了挥手。我不认为我们给了足够的声音给那些真正以最具想象力、创造性的方式试图用 AI 给世界带来好处的人。

对过度管制的担忧

Emily Chang: - 有没有任何人，任何事情你想指出就是任何人或任何公司，让你感到恼火？

李飞飞：- 我知道你在说什么。我已经指出过他们，我不会说是胡说，只是我觉得我们对“存在危机”关注得太过了，哦，不对，是“灭绝性的危机”。- 存在主义引发的灭绝危机。- 是的，就是这个意思。这就是我们过于强调的问题。我担心我们国家不同地区，比如加利福尼亚，正在推进的一些法案，过于强调这个问题。这些法案可能出于善意，但它们对 AI 模型设定了限制，甚至可能无意中将开源视为违法，而没有真正思考如何评估和审查这些 AI 模型。我对此感到担忧。

Emily Chang: - 你是不是认为我们可能会过度管制呢？

李飞飞：- 有可能，我们可能会过度管制，而这样可能会伤害我们的生态系统。但同时，在医疗、交通、金融等实际应用领域，我们应该考虑设置恰当的防护措施。

性别和种族多样性

Emily Chang: - 你跟拜登总统谈过这个问题吗？我知道你可以直接跟他联系。

李飞飞：- 我不能告诉你我跟他谈过什么。其实，在跟拜登总统的交谈中，我们讨论了投资公共部门 AI 的重要性，因为我们现在就在硅谷，大家都知道，无论是人才、数据还是计算能力，都主要集中在科技产业中，尤其是大型科技公司。而美国公共部门和学术界在 AI 资源方面正在迅速落后。斯坦福自然语言处理实验室只有 64 个 GPU，只有 64 个。想一想这个对比。我们谈论了公共部门的资源问题，因为公共部门是我们国家的创新引擎，它创造了公共产品，发现了科学知识，并且为公众提供了对这项技术的可信赖和负责任的评估和解释。

增强女性和有色人种在 AI 领域的影响力

Emily Chang: - 所以最后一个问题，我知道你非常关注这个问题在你的实验室和其他地方这个领域没有足够的女性和有色人种掌控权这个风险有多大，可能会引发什么问题？

李飞飞：-是的，Emily，我知道你一直在倡导这个问题，看，还不够。实际上，我认为文化并不一定变得更好，我们看到越来越多的女性和多样化背景的人进入科技和人工智能领域，但我们也看到男性的声音被更多地传播。人们会说，飞飞，你在这里发言，但有很多人比我更好。有很多年轻的女性，来自各种多样化背景的科技人员，他们的声音应该被听到，应该有更大的发言平台。如果我们听不到他们的声音，那就真的是在浪费人力资本，对吧？这些都是杰出的思想家、创新者、技术人员和教育家，发明家，科学家，如果我们不给他们发言的机会，不听他们的想法，不提升他们的地位，就是在浪费我们集体的人力资本。

Emily Chang: -我认为教母是一个非常好的称呼。大家怎么看？你们同意吗？

李飞飞：-是的。

Emily Chang: -好的，谢谢你。人工智能教母。

来源：https://youtube.com/watch?v=FW5CypL1XOY



### 59

2024-05-11


宝玉
@dotey
Authropic 的这个提示词生成器真的蛮好用的



### 60

2024-05-11

宝玉
@dotey
刚又去看了一下，越来越好了，做的真的是用心👍🏻

https://aspoem.com

[AsPoem | 现代化诗词学习网站](https://aspoem.com/zh-Hans)

### 61

2024-05-11



歸藏(guizang.ai)
@op7418
Anthropic 给控制台发布两个重磅功能。

自动生成提示：由Claude为你直接编写提示内容。
变量功能：可以轻松地将外部信息插入到你的提示中。

使用方式：后台选择生成提示按钮，输入任务的一些基本细节，可以编辑生成的提示。

自定义变量。变量是提示加载外部数据的区域。变量需要两个花括号括起来。


### 62

2024-05-11


宝玉
@dotey
周鸿祎：很多人世俗的成功其实就赢在一个“敢”字上：敢于表现自己、敢于坚持、敢于表达。这个世界就像是一个草台班子，看似简陋但也有其门槛。实际上，无论是哪个行业，那些取得成绩的人都是因为他们早期的勇敢态度。

这些成功者没有害怕犯错，他们边学边干，不断尝试，从失败中汲取教训并持续战斗。人性中总有一部分倾向于找借口以掩盖自己的无能，但真正厉害的人会不断寻找自己的问题，并探索改进的可能。

成功的第一步是敢于走上舞台，而失败往往是因为不敢面对挑战或在舞台上的时间不够长。你是要建立一个草台班子还是只是一直作为一个观众？有时候，这个选择只在于你的一念之间。

即便世界不过是草台班子，大家都是草包的时候，你也可以选择自己亲自上台，去搭建一个属于自己的草台班子。找借口很容易，冷嘲热讽也是，但真正的挑战在于超越这些，通过持续的努力和时间的积累，最终可能迎来突破。

---

可以配合这视频一起看

宝玉
@dotey
转：罗振宇早年批判周鸿祎的视频，言辞相当激烈。

来源：https://weibo.com/6880136821/Obt8kxsFk



### 63

2024-05-11

宝玉
@dotey
可以试试 TweetReader GPT： https://chatgpt.com/g/g-jQyjBVVhg-tweetreader



### 64

2024-05-11

Gab Bowie
@Bowie_the_N
解释一下这篇Paper为什么这么重要：

1. 蛋白质结构预测的革命：AlphaFold解决了长期以来的难题：即仅凭氨基酸序列预测蛋白质的3D结构。

2. 新药开发：这一技术对于新药开发至关重要，因为它能够快速识别潜在的治疗靶点。

3. 疾病治疗的突破：AlphaFold已被用于开发针对镰状细胞病、乳腺癌和糖尿病等疾病的治疗方法。

4. 效率与成本的双重提升：传统方式，确定蛋白质结构既耗时又昂贵，而AlphaFold极大地提高了这一过程的效率和降低了成本。

5. AlphaFold3的进一步飞跃：最新模型不仅预测了几乎所有已知蛋白质的结构，还能预测其他生物复合体的结构，开辟了新的研究领域。

如果这个AlphaFold3可以证真，它将能带给我们更多种类的治疗方法和药物，以及更快、更经济的发现过程，对科学和医学领域具有深远影响。

Google 以对非商业用途用户开放AlphaFold Server:
https://alphafoldserver.com



### 65

2024-05-11

歸藏(guizang.ai)
@op7418
Krea 的视频生成功能发布了。

居然是可以定义收尾帧的，而且每张图片对应的提示词都可以自定义。

看起来像是之前发过的基于 ipadapter 的 Animatediff 的工作流优化的。

现在更易用了，还会自动对生成的视频高清化。会员才能使用。



### 66

2024-05-13


歸藏(guizang.ai)
@op7418
一个针对用 Kohya_ss 进行 LoRA 训练写的指南，介绍了必要的指导和参数设置信息。用OneTrainer也可以看看。

去年七月的可能缺了一些参数，但是用来入门还是不错的。

介绍了 Lora  类型、从权重中获取 DIM、训练批量大小、训练图像的最大分辨率、学习率等参数等内容。



### 67

2024-05-13

歸藏(guizang.ai)
@op7418
Andrej 的一个新脑洞，训练一个分类器来预测任何文本的GPT等级。这个训练数据会用到从弱到强不同能力的模型生成的样本。

如果某个内容写作质量差或内容平庸，我们就称它为“GPT-2级”。反之，如果内容出色，引人注目，我们则可以称赞它达到了“GPT-7级”。

“理想的情况是有一个很好的系列，比如Llama 3系列，它在模型大小之外的其他条件都保持不变，特别是当它们发布更小或更大的模型时。

通过多种提示采样这些模型（或者直接使用基础模型？），按模型大小进行分类，然后将它们用于互联网上的各种文本，比如分析《华尔街日报》的评论区和风险投资界的思想领袖文章的差异。

需要说明的是，我不确定这个方法是否行得通，例如分类器可能会更多地依赖于文本的风格而不是内容。或者它可能更多地测量的是文本的“通用性”，而不是“智能”，即某种频率的代理。

这也可能是一个探索随模型大小增加而学到的内容的有趣方式。但这也是为什么这个项目很吸引人——它似乎有一定的潜力，但并不是显而易见的，很多细节还需要进一步明确。”



### 68

2024-05-13

九原客
@9hills
有同学问我如何快速零基础了解大模型原理。

我一般会推荐这套视频，可视化做的非常的棒，总共也就三个小时，不仅适合了解，也是很不错的入门。

九原客
@9hills
符合了好课程的特点：

1. 不会的人觉得讲的很清晰，听完仿佛会了。
2. 会一些的人发现有很多共鸣：原来这里是这么理解的。
3. 资深的人觉得概念怎么可以这么清晰简洁的讲出来，下一次我也用这个例子。

---

宝玉
@dotey
B 站有官方双语，翻译质量很不错

https://bilibili.com/video/BV13z421U7cs/

[【官方双语】GPT是什么？直观解释Transformer | 深度学习第5章\_哔哩哔哩\_bilibili](https://www.bilibili.com/video/BV13z421U7cs/?vd_source=280fc27368a92928cafc2cb72c54a549)

### 69

2024-05-13


fox hsiao
@pirrer
Jim Fan 針對 OpenAI 最新發表的 GPT-4o 模型，提出了他的看法與分析。 

Jim 表示，從技術角度來看，OpenAI 已經找到了一種將音訊直接映射到音訊的方法，並且能夠即時將影片串流到 transformer 模型中。

這需要在 tokenization 和架構上進行一些新的研究，但總體而言，這是一個資料和系統優化的問題。  高品質的資料可以來自兩個來源：1）YouTube、podcast、電視劇、電影等自然對話；2）合成資料，使用最強大的模型運行慢速的三階段流程：語音轉文字 (ASR)、文字轉文字 (LLM)、文字轉語音 (TTS)。  

在系統方面，如果每一幀影片都被解壓縮成 RGB 圖像，延遲將無法滿足即時性的要求。OpenAI 可能開發了自己的神經優先、串流影片編解碼器，將動作變化作為 token 傳輸。  

Jim 認為，GPT-4o 可能更接近於傳聞中的 GPT-5「Arrakis」模型，該模型可以接受多模態輸入和輸出。OpenAI 的品牌策略透露出一種不安全感，他們寧願擊敗大家對 GPT-4.5 的期望，也不願在 GPT-5 上令人失望。  值得注意的是，GPT-4o 的助理更加生動，甚至有點調情。

OpenAI 正在蠶食 Character AI 的市場，幾乎完全重疊的形式和巨大的分銷管道。這是朝著更加情感化、個性鮮明的 AI 方向的轉變。  

Jim 認為，誰先贏得蘋果，誰就能贏得大局。他看到了與 iOS 整合的三個層次：1）拋棄 Siri，為 iOS 提供純粹的設備內 GPT-4o 模型；2）提供將相機或螢幕串流到模型的原生功能；3）與 iOS 系統級操作 API 和智慧家庭 API 整合。



### 70

2024-05-13


宝玉
@dotey
推荐阅读：《你好 GPT-4o》

想了解 GPT-4o 的技术细节，推荐阅读官方的 Hello GPT-4o

原文：https://openai.com/index/hello-gpt-4o/
译文：


### 71

2024-05-13

宝玉
@dotey
提前下载使用 ChatGPT Mac 桌面客户端的办法（需要有ChatGPT付费账号，需要有网络技术基础）：
1. 下载地址：http://persistent.oaistatic.com/sidekick/public/ChatGPT_Desktop_public_latest.dmg https://persistent.oaistatic.com/sidekick/public/ChatGPT_Desktop_public_latest.dmg

2. 使用 Proxyman、Charles 或你喜欢的网络代理来进行以下操作：

以ProxyMan为例
1). 登录一次以触发 API 调用，
2). 对 ChatGPT 的 App 启用 SLL 代理（需要配置好 ProxyMan 证书）
3). 再登录一次以触发 API 调用，
4). 然后右键点击  http://ab.chatgpt.com/v1/initialize 选择本地映射，并将所有的 false 替换为 true。

再尝试一次，你就应该能顺利登录了。

但是只是老版本的语音对话功能，还没有今天演示的 gpt-4o 的语音对话功能



### 72

2024-05-13

宝玉
@dotey
今天 OpenAI 2024 春季更新的介绍部分，由 OpenAI CTO Mira Murati 主讲

**欢迎致辞**
很高兴你今天来到这里。

**主题介绍**
我今天要谈的主要有三点。就这样。

**产品的重要性与更新**
我们首先讨论为何对我们来说，拥有一个可以自由向大众提供的产品如此重要。我们一直在努力寻找减少使用困难的方法，以便所有人都能在任何地方使用 ChatGPT。所以，今天我们将发布 ChatGPT 的桌面版本，并进行界面的更新，让其使用起来更为简单、自然。

**新旗舰模型 GPT-4o 的介绍**
但是，今天的重头戏是我们即将发布的新旗舰模型，我们将其命名为 GPT-4o。GPT-4o 特别的地方在于，它将 GPT-4 级别的智能带给了所有人，包括免费用户。我们将在今天进行一些现场演示，展示我们新模型的全部能力，并且我们将在接下来的几周中逐步发布它们。

**使命和目标**
我们使命的一个重要组成部分是能让我们的先进人工智能工具面向所有人免费开放。我们认为，人们对技术可以做到什么有直观的理解非常重要。因此，我们希望将其与更广泛的理解结合起来，并始终在努力寻找减少使用难度的方法。最近，我们已经可以不用注册就能使用 ChatGPT。今天，我们为 ChatGPT 引入了桌面应用程序我们希望你能在任何地方都能使用它。

**用户界面更新**
如你所见，它使用起来简单轻松，可以非常顺利地融入你的工作流程。同时，我们也刷新了用户界面。我们知道这些模型变得越来越复杂，但我们希望与之的互动体验能变得更加自然、简便，让你无需专注于用户界面，只需聚焦于与 GPT 的交互。

**技术进步和人机交互的未来**
接下来是重大新闻。今天我们发布了最新的旗舰模型——GPT-4o。GPT-4o 提供了 GPT 4 级别的强大智能，并且运行速度更快，在文本、视觉和音频等方面的能力也有所提升。过去几年里，我们专注于提升这些模型的智能性，现在它们已经表现得相当出色。但这是我们首次在使用便捷性方面实现了重大突破。这一点极其重要，因为我们正在展望人机交互的未来。我们认为，GPT-4o 正在引领我们进入一个新的协作时代，在这个时代，人机交互将变得更加自然、更加便捷。

**语音与多模态交互的挑战与解决方案**
然而，实现这一点其实非常复杂，因为在人与人的交流中，有许多我们习以为常的细节。我们在与人互动时的对话便捷性，背景噪音，一个对话中的多重声音，或者理解声音的语调。所有这些对模型来说都是极其复杂的任务。到目前为止，在语音模式下，我们采用了三种模型共同提供服务。包括：语音转录、智能处理以及文本转语音技术，

这三者协同合作，共同打造了语音体验。但这也带来了大量的延迟，破坏了我们在 GPT 上的沉浸式协作体验。然而，有了 GPT-4o，这一切都能够原生实现。

**广泛的用户接入和新功能**
GPT-4o能够跨声音、文本和视觉进行智能推理。得益于这种卓越的处理效率，我们现在甚至可以将 GPT-4 级别的智能服务提供给免费用户。这是我们一直想要实现的目标，我们非常兴奋终于能把 GPT-4o 带给所有用户。现如今，我们已经有超过 1 亿用户利用 ChatGPT 进行创作、工作和学习。我们有许多高级工具，但以前只有付费用户可以使用。凭借 4o 的高效性，现在我们可以将这些工具提供给所有人。所以，从今天开始，你可以在 GPT 应用商店中使用 GPT。到目前为止，我们已经有超过一百万的用户用 GPT 创造了令人惊叹的体验。这些都是在应用商店中可用的，为特定用途定制的 ChatGPT。现在，我们的开发者们有了更大的受众，大学教授们可以为他们的学生创造内容。或者，播客可以为他们的听众创造内容。你还可以使用视觉功能。因此，现在你可以上传截图、照片或含有文本和图像的文件。并且你可以和 ChatGPT 就这些内容展开对话。你还可以使用记忆功能，这使得 ChatGPT 变得更有用、更有帮助，因为现在它可以记住你的所有对话内容。你还可以使用信息搜索功能，在你的对话中搜索实时信息。还有数据分析功能，你可以上传图表或其他信息，它会对这些信息进行分析。它会给出答案等等。

**多语言支持的提升**
最后，我们也提高了 ChatGPT 在 50 种不同语言中的质量和速度。这非常重要，因为我们希望能把这种体验带给尽可能多的人。所以我们非常激动地将 GPT-4o 带给我们所有的免费用户。对于付费用户，他们将继续拥有超过我们免费用户五倍的容量限制。

**GPT-4o 的扩展到 API**
但是，GPT-4o 不仅仅在 ChatGPT 中可用，我们也将其引入到了 API 中。因此，我们的开发者现在可以开始使用 GPT-4o 来构建了不起的 AI 应用，并进行大规模部署。4o 的速度是 GPT-4 Turbo 的两倍，价格降低了 50%，速率限制提高了五倍。

**面临的挑战与未来展望**
然而，当我们将这些技术引入世界时，如何以一种既有利又安全的方式进行，这是相当具有挑战性的。GPT-4o 在安全性方面为我们带来了新的挑战，因为我们正在处理实时音频和实时视觉。我们的团队一直在努力寻找防止滥用的解决方案。我们继续与各方利益相关者合作，比如政府、媒体、娱乐业、所有行业、红队成员和公民社会，以找出如何最好地将这些技术引入世界。

因此，在接下来的几周里，我们将继续进行迭代部署，向你提供所有的功能。




### 73

2024-05-14

宝玉
@dotey
Sam Altman 谈 GPT-4o

Logan：你们今天早些时候发布了一个新产品。

Sam：我们确实发布了。

Logan：多模态 4o？

Sam：是的。

Logan：那是欧米茄符号，对吧？

Sam：哦，就像 Omni。

Logan：对，Omni，不好意思。

Sam：它能跨文本、语音、视觉工作。

Logan：你能解释一下这为什么重要吗？

Sam：因为我认为这是使用计算机的一种非常棒的方式。实际上，我们很久以前就有了语音控制计算机的想法。你知道的，我们有 Siri，之前还有其他类似的技术。但它们从来没有让我感觉到使用起来很自然。这个新技术，由于很多原因——它的功能、速度、增加的多模态支持、语调的自然性等——让使用体验大大提升。你可以轻松地调整说话速度或改变声音，它的流畅性和灵活性让我非常喜欢。

Logan：有没有什么特定的使用场景吸引了你？

Sam：嗯，虽然我才用了一周左右，但有个特别惊喜的用途是在我全神贯注工作时，将手机放在桌子上。然后在不需要切换窗口或改变我正在做的事情的情况下，将它作为另一个通信渠道。这样我就可以在继续工作的同时，询问并立即得到回答，而不需要转移视线，这真的很酷。

Logan：是什么使这成为可能的？是架构上的改变还是计算能力的提升？

Sam：其实，这是我们过去几年学到的所有东西的结合。我们一直在研究音频模型和视觉模型。我们努力将它们结合起来，并寻找更高效的训练方法。这不是突然解锁了某个惊人的新技术，而是将许多部分组合起来的结果。

Logan：你认为需要开发设备上的模型来减少延迟，以提升使用体验吗？

Sam：对于视频来说，可能需要处理网络延迟问题。我一直认为，将来能戴上增强现实眼镜，实时用语言描述周围世界并看到变化，将会非常神奇。但网络延迟可能会是一个挑战。不过对于现在的技术，两三百毫秒的延迟已经非常快了，感觉上比很多时候人类回应还要迅速。

Logan：在这种情况下，视频指的是图像吗？

Sam：哦，对不起，我是说视频。如果你需要生成视频，不是处理输入的视频。

Logan：明白了。所以目前它能够处理实际视频，就像逐帧处理一样。

Sam：这是可行的。

Logan：你最近提到 ChatGPT 可能不会以 GPT-5 为名发布下一个大更新。看来你们采取了一种逐步改进模型的方式。

Sam：我们可以这样理解，未来可能不会有大规模的发布，如“这里是 ChatGPT-5”，而是......我们实际上还没有决定。我确实意识到 AI 和惊喜不太搭。虽然按照传统科技公司的产品发布方式，我们可能需要尝试一些不同的方法。我们可能仍然会用 GPT-5 这个名字，但以不同的方式进行发布，或者我们可能会选择一个不同的名称。但我认为我们还没有确定如何为这些产品命名和定位品牌。从 GPT-1 到 GPT-4 的发布对我来说是合理的。显然，GPT-4 已经持续改进了。

Sam：我们还在考虑，也许会有一个底层的“虚拟大脑”，在某些情况下能更努力地思考，或者是不同的模型，但它们是否不同并不重要，所以我们还没有确定如何将这些产品推向市场。

Logan：这是否意味着，为了在模型上取得渐进式进步，计算需求可能会比过去少？

Sam：我认为我们始终会利用尽可能多的计算资源。现在我们正在实现巨大的效率提升，这非常重要。你知道的，我们今天发布的最酷的功能是语音模式，但也许最重要的是我们已经提高了效率，以至于我们能够为免费用户提供服务。

Sam：就像是世界上最好的模型之一，很多人都认可，看看那个小东西就能为任何想下载 ChatGPT 的人免费提供服务。这比 GPT-4 和 GPT-4 Turbo 都有显著的效率提高，我们还有很多进步空间。

节选自：https://youtube.com/watch?v=fMtbrKhXMWc



### 74

2024-05-14

Gorden Sun
@Gorden_Sun
GPT-4 和 GPT-4o 语音对话的流程对比
1）原生统一模型，速度更快
2）Whisper语音转文字的缺点：忽略语音的音调和情绪、忽略背景音、识别不出多个讲话者；
OpenAI TTS的缺点：不能输出笑声、不能输出带有情绪的语音、不能唱歌；
GPT-4o弥补了缺点，直接接收全面的语音信息，输出带感情的声音。



### 75

2024-05-15


宝玉
@dotey
这是 Google Project Astra 的两段演示视频。 这展示了 Google DeepMind 对未来 AI 智能体的设想。 每段视频均为单次拍摄、实时录制完成。

不得不说 OpenAI 真是坏，看完 GPT-4o 的演示再看 Google 的，一下子就黯淡无光了，如果没有 GPT-4o 的演示其实还不错的。


### 76

2024-05-15


宝玉
@dotey
转译原推 JimFan 的点评：

在Google I/O的一番思考中，我注意到虽然这些模型可以处理多种类型的输入数据，但它们的输出功能并不是多模态的。例如，Imagen-3 和音乐生成模型还是作为独立部件，与Gemini项目没有整合。未来，各种输入和输出模式的融合似乎是大势所趋：

* 这种整合可以实现多种功能，如“使用更机器化的声音”、“讲话速度加倍”、“对图片进行迭代式编辑”以及“制作一致的连环画”。
* 它能确保情感、背景音等信息在不同模式之间不会丢失。
* 还能开启模型在上下文中新的应用可能，例如教模型用少量示例在不同感官之间进行创新性的结合。

虽然GPT-4o在这方面还未达到完美，但其基本框架设定是正确的。正如Andrej将大语言模型比作操作系统一样，我们期望模型能本地支持尽可能多的文件格式。

Google在一件事情上做得不错：他们正在努力将AI功能整合到搜索框中。我能感觉到从着陆页开始的智能体流程——规划、实时浏览以及多模态输入，这一切都显示了Google在分发方面的强大优势。对于Gemini来说，它不必是全球最优秀的模型，只要是最广泛使用的模型就已足够。



### 77

2024-05-15

九原客
@9hills
Gemini 1.5 Flash的意义可能被低估了。

就不提上下文长度以及多模态，效果只是略逊于Pro，但是价格折人民币只需要0.002 元/千tokens。恐怖如斯！

用在沉浸式翻译上，效果比DeepSeek那好太多了。

目前推荐用OpenRoute的服务，官方API还没有开通付费所以并发很低。



### 78

2024-05-15

宝玉
@dotey
可汗学院创始人 Salman Khan 的新书：《Brave New Words——How AI Will Revolutionize Education (and Why That’s a Good Thing)》

《勇敢新语——人工智能如何革新教育（以及这为何是好事）》（注：此处书名非最终翻译结果）

简介

在《勇敢新语》一书中，长期处于教育前沿的 Salman Khan 展示了未来的趋势。Bill Gates 曾评价，这本书是对所有对人工智能时代的未来学习感兴趣的人的宝贵课程。在这一领域，没有人比 Salman Khan 更深入地思考，也没有人的见解比他更具启发性。

不论我们是否准备好，人工智能革命都将影响教育领域。Khan Academy 的创始人 Salman Khan 在书中探讨了人工智能及 GPT 技术将如何转变我们的学习方式，并为教师、家长及学生提供了在这一新兴且有时令人畏惧的新世界中的导航指南。

作为教育技术领域的先锋，Khan 详细介绍了这些尖端工具的功能及其如何彻底改变我们的学习与教学方法。Khan 呼吁家长和教师不应恐惧接受 ChatGPT 革命，而应拥抱并适应人工智能，同时也要认识到它的不完美与局限。他强调，采用人工智能并非取代人际互动，而是为了增强其效果，让每位学生都能以全新而富有创意的方式增强他们目前的学习，实现个性化学习、调整评估方式，并在课堂上取得成功，为学生们的数字化未来做好准备。

然而，《勇敢新语》不仅仅关注技术本身，它还探讨了这项技术对社会的意义及对教育管理者、指导顾问和招聘经理的具体影响，这些人可以利用人工智能的力量改进教育和工作场所。Khan 同样深入讨论了人工智能和 GPT 的伦理及社会影响，提供了关于如何利用这些工具为全球学生建立更易接触的教育系统的深思熟虑的见解。

书评

-   Salman Khan 一直是教育革新的先锋，他在《勇敢新语》中为我们揭示了未来趋势。这本书对所有关心人工智能时代学习前景的人来说，是一堂及时的精彩课程。没有人比Sal更深入地思考过这些问题——也没有人能有更多独到见解

—— Bill Gates

-   一定要读这本书。这是一部关于人工智能如何革新学习方式的极具启发性和重要性的作品。Salman Khan 正在引领我们步入一个新时代，在这个时代中，每个学生——以及其他人——都将拥有一个私人导师，这位导师将为我们所提供的，如同亚里士多德当年为亚历山大大帝所做的那样

—— Walter Isaacson, 纽约时报畅销书作者，《Elon Musk》

-   这是一本关于学习未来的引人注

目的指南。Salman Khan 不畏惧人工智能的威胁，反而提出了一个清晰且令人信服的愿景，旨在增强教师力量、激活课堂氛围，并激发学生潜能。这本书是所有教育关心者的必读之作

—— Adam Grant, 纽约时报畅销书作者，《隐藏的潜能》和《再思考》，以及播客 Re:Thinking 的主持人

-   人们常说，我们渴望改变但又依恋熟悉。在教育领域，这种现象无处不在且带来了悲剧。现在是时候勇敢地接受变化了，正如 Salman Khan 在这本关于人工智能的及时著作中所呼吁的。借助生成式人工智能的飞跃进展，我们所有人的学习方式都应发生革命性变化。在这条道路上，没有比 Salman Khan 更好的引领者了

—— Angela Duckworth, 《坚毅：毅力与激情的力量》的作者

-   Salman Khan 为那些希望了解及塑造人工智能做出正面贡献的人提供了宝贵的指导。这不仅是一本关于人工智能、教育和工作的书，其深刻的见解也适用于各个领域

—— Sam Altman, OpenAI 的 CEO

-   Salman Khan 曾计划成为一名人工智能研究员，却最终成为了我们这个时代最重要的教育家之一。他在这里展示了学习者如何可以利用人工智能及其他技术来提升个人的生产力和创业能力，展现了非凡的智慧和洞察力。这些勇敢的言论无人能出其右

—— Satya Nadella, Microsoft 的执行主席兼 CEO

-   我坚信 Salman Khan 是人工智能时代教育领域的领军思想家。在《勇敢新语》中，他深入探讨了人工智能如何成为创造力的催化剂和激发学生潜力的工具。对所有对学习和技术未来感兴趣的人来说，这本书是一份难得的资源

—— Francis Ford Coppola, 获奖电影制片人

-   Salman Khan 的《勇敢新语》是关于人工智能如何革新教育的必读之作，同时探讨了如何将其作为一种正面力量。这本书是一次及时的、发人深省的、最终充满希望的审视，探讨了这项强大新技术如何平衡教学资源并发展个性化教学。我们很幸运有 Khan 带领我们进入教育的激动人心的未来

—— Laurene Powell Jobs, Emerson Collective 的创始人兼主席

-   在《勇敢新语》中，Salman Khan 挑战我们重新设想一个由人工智能驱动的教育未来。这本书不仅富有洞察力，而且极具启发性，展示了技术巨大的潜力，能够赋能学习者和教育者。Khan 的专业知识和热情使这本书成为所有对教育未来有兴趣的人的引人入胜的阅读

—— Arne Duncan, 前美国教育部长

-   教育是通向专业和个人成就的途径，是从无知中解放思想、实现成就的路径。今天，人工智能以新的深刻方式打开了这种可能性。而不是恐惧这种变化，通过拥抱它，每个人都可以拥有一位世界级的导师，提供以个体需求为中心的教学。这需要我们在教育的可能性上进行大胆的想象。正如 Salman Khan 所精彩阐述的，这是对过时现状的必要且积极的变革。这是一次我们必须采取的飞跃

—— Tony Blair, 前英国首相

介绍：https://penguin.co.uk/books/460644/brave-new-words-by-khan-salman/9780241680964



### 79

2024-05-15


宝玉
@dotey
像我这种英语不是母语也不懂医学知识的人，一个麻烦就是每年体检看体检报告看不太懂，医生有时候也说的不详细。另外一些药物的使用说明直接看说明书也不够清楚。

这两天用 GPT-4o 的一个主要场景是把体检报告截图，帮我详细分析体检报告，说的挺详细的，重要的是你可以随时就细节追问。

另外还可以把药物的包装盒拍照发给 GPT-4o，也可以让它说明药物的作用和使用方法，不容易遗漏细节。

当然还是结合医生的反馈对照看比较好，避免“幻觉”导致的问题。



### 80

2024-05-15

SamWanng
@SamWanng
好读找台版书比 Z-Library 还要好用。https://haodoo.net




### 81

2024-05-15


歸藏(guizang.ai)
@op7418
之前介绍过的斯坦福大学新的 CS25 课程放出了Nathan Lambert博士讲课的视频，他是 AI2 的研究科学家。

新的 CS25 课程将会邀请各大 AI 公司的顶尖人才讲解前沿的 Transformer 研究。

这节课的主要内容是希望为听众提供对语言模型微调和对齐领域的深刻理解。

--------课程总结--------

🌟语言模型的历史发展
语言模型的发展可以追溯到Claude Shannon的工作，他提出了使用字符排列来创建语言模型的概念。自此之后，语言模型经历了多个重要里程碑，包括Transformer的问世和自回归损失函数的应用。这些基础奠定了现代语言模型的理论和实践基础。

🌟GPT模型的演变
GPT模型经历了从GPT-1到GPT-3的演变，每一代模型在架构和性能上都有显著提升。GPT-1开创了生成文本的能力，GPT-2展示了大规模计算带来的性能提升，而GPT-3则以其强大的少样本学习能力广受关注。这些模型的开发不仅推动了技术进步，也引发了关于语言模型发布和使用的伦理讨论。

🌟语言模型的风险和伦理问题
随着语言模型的能力不断增强，其潜在风险也日益明显。2021年，“随机鹦鹉”论文提出了对大规模语言模型的批评，质疑它们是否真正具有智能或仅仅是在模仿人类语言模式。ChatGPT的发布进一步引发了关于语言模型伦理的广泛讨论，特别是它们在信息传播和用户互动中的影响。

🌟自然语言处理(NLP)中的强化学习
强化学习通过人类反馈（RLHF）已成为提升语言模型对齐效果的重要方法。尽管RLHF在实践中展示了巨大潜力，但其实施仍面临许多挑战，如如何有效设计奖励函数和优化策略。这一领域的研究正在不断发展，以解决这些复杂问题。

🌟指令微调模型
指令微调模型旨在提高语言模型响应特定指令的能力。Alpaca模型通过自我指令数据生成技术，实现了高效的微调过程。分享的ChatGPT数据集尽管在法律上存在争议，但其多样性和丰富性极大推动了模型的改进。各类指令微调模型的不断出现，显示了这一领域的活跃研究状态。

🌟模型评估与衡量标准
为了评估和比较不同的语言模型，开发了多种评估工具，如Chatbot Arena、AlpacaEval和MT-Bench。这些工具帮助研究人员和开发者了解模型的性能和改进空间，促进了开源模型的发展和应用。

🌟DPO（直接偏好优化）方法
直接偏好优化（DPO）是一种简单且高效的模型对齐方法，通过直接对语言模型的概率进行梯度上升，避免了复杂的奖励模型训练。DPO与传统的强化学习方法相比，具有更好的可扩展性和简便性，在实际应用中展示了良好的性能。

数据集和开放源代码模型的进展
开放数据集如Open Assistant、Ultra Feedback和Nectar在推动语言模型对齐研究中起到了重要作用。多个开源模型的发布，如LLaMA、Vicuna和Koala，展示了对齐技术的快速进展和广泛应用。这些数据集和模型为研究人员提供了宝贵的资源，促进了整个领域的发展。

未来研究方向与总结
未来的对齐研究热点包括数据集多样性、评估工具的改进以及模型的个人化和小规模对齐。随着更多企业和研究机构的加入，开源模型的生态系统将继续壮大，为语言模型的创新和应用提供更多可能性。数据集和评估方法的进一步优化将为对齐研究提供更坚实的基础，推动这一领域向前发展。




### 82

2024-05-15

宝玉
@dotey
来自 OpenAI 联合创始人 John Schulman 的观点：到 2025 年，AI 模型会更像你的同事而不是一个搜索引擎

AI 模型在未来几年预计将能执行更复杂的任务，如整个编码项目，包括代码编写、测试和迭代。这种进步将使模型不仅能处理简单任务，而能进行完整项目的处理。模型将能记住用户的所有操作，并主动提出建议，后台自主工作，体现出一种更高级的协作和自动化水平。

AI 模型的训练方式也将关键，通过强化学习和监督学习的结合可能显著提升执行长期项目的能力。这种训练的加强有助于模型在处理错误和异常情况时能够自我修正和恢复正轨。模型的泛化能力，即将在其他任务中学到的应用到新情境，是其提高效率的关键。

然而，AI 模型目前在保持长时间智能操作，尤其是在连贯性和深入思考上仍面临挑战。虽然它们在某些方面已达到或超过人类智能水平，但无法持续保持这种状态，这是未来发展的重要瓶颈。未来的 AI 模型可能会像与人类同事一样自然地互动，但达到这一点需要解决多个技术和功能问题，包括长期连贯性和深入思考能力的提升。

来源：https://youtube.com/watch?v=1fmcdz2EO_c




### 83

2024-05-15

歸藏(guizang.ai)
@op7418
吴恩达新写的提示工程技巧，主要的内容就四步：

1. 快速撰写简单的提示并测试其效果。

2.根据结果的不足，逐步丰富和细化提示，这可能导致更长、更详细的提示，甚至是“大型提示”。

3. 如果效果仍不理想，可以考虑应用少样本或多样本学习策略（如果适用），或偶尔进行微调。

4. 如果问题仍未解决，可将任务拆分为子任务，采用智能体工作流程。



### 84

2024-05-15

歸藏(guizang.ai)
@op7418
Sam 确认了目前在ChatGPT中的GPT-4o只有文本模式，其他的多模态声音、图像、视频都没有实装。



### 85

2024-05-15

Ethan Mollick
@emollick
Some sample tasks:
-Merge these two spreadsheets, the names are listed differently & one uses nicknames
-Graph this unformatted data from a site
-Rewrite these instructions to be clearer
-(Using voice) translate for the two of us
-Anything I missed in this post to make it better?




### 86

2024-05-15

Edward
@aestheticedwar1
Open Source RAG with Ollama! 🥳

YouTube: https://youtube.com/watch?v=swKKRdLBhas

The newest Verba v1.0.0 update is out, and it’s...
 
✨ B-E-A-U-T-I-F-U-L ✨ 

We added many exciting things to Verba, including open-source models powered by Ollama, Frontend Customization, and many Quality of Life features. It’s so much; we made a whole video about it. 

Watch the deep-dive video by 
@victorialslocum
 , 
@philipvollet
 , and me to learn how to set up a local-running open-source RAG app in just a few minutes.

You can also try out the new Verba version directly in our free live demo:

Live Demo: https://verba.weaviate.io

If you want to start immediately, this GitHub Repo covers you! (We also just hit the 2.6k stars 🎉). It contains all the information about features and installation.

GitHub: https://github.com/weaviate/Verba



### 87

2024-05-16

歸藏(guizang.ai)
@op7418
这个论文有意思，详细研究了基于Transformer的语言模型在记忆过程及性能变化上的机制。

一定程度解释了为什么简单地增大Transformer模型的规模并不一定能提升其性能。

论文将Transformer模型的行为与Hopfield记忆网络进行类比，提出每个Transformer层都在执行近似的最近邻搜索。



### 88

2024-05-16


Leo Xiang
@leeoxiang
很有意思的数据，GPT-4o 在TTFT指标上领先，对于实时场景确实有优势。但在TPS 上却比 gemini-1.5-flash 少了那么多。 看来GPT-4o在实时场景上做了很多优化。

通俗一点讲就是：GPT-4o 相比gemini-1.5-flash 虽然跑的慢，但可以抢跑啊。

TTFT: Time To First Token
TPS: Tokens Per Second


### 89

2024-05-16


歸藏(guizang.ai)
@op7418
随着 AI 搜索越来越多，包括谷歌自己也在搜索前加上了 AI 总结，可能针对 AI 的 SEO 也越来越重要。

比如搜索最适合数字游民的城市谷歌 AI 概览的结果就和正常的搜索结果排序不同。

下面老哥还写了 SEO2.0 需要做的五件事情：

1. 个性化搜索。根据搜索查询定制优惠、文案等内容。SEO正在变得越来越个性化。

2. 工具为王。开发工具、计算器、测验等值得链接的内容。这样可以让它们被嵌入到LLMs中并被链接。

3. 利用AI每天创建200多页内容。可以使用 zapier 、 Open AI 等工具。

4. 80/20规则。让智能AI智能体完成80%的工作，剩下的20%由人类完成以避免谷歌的惩罚。

5. AI辅助的工作流程，基本上赋予你以往只有顶级公司花费数百万美元在SEO上才能获得的SEO能力。

这块也可以关注哥飞
@gefei55
每天发布的内容。


### 90

2024-05-16

宝玉
@dotey
CBS Morning 对可汗学院的创始人兼 CEO Sal Khan 的一段采访视频。

可汗新写了一本书叫《Brave New Words》探讨 AI 将如何革新教育，以及这为何是一件好事。

他在书中末尾引用了海啸的隐喻：潮水已经退去，但 AI 的海啸正在向我们疾驰而来！可汗认为，AI 的潘多拉的盒子已经被打开了。无论你是否接受，它都将来临。无论你是否愿意，与其在那里谈论海啸的负面影响、谈论深度伪造和误导信息，不如多关注 AI 带来的积极影响，AI 并不是非黑即白的事情。AI 就像以往的所有技术一样，是人类意图的放大。如果我们能在引导其投入更多的积极的使用场景，让它更多地关注于教育，赋权给普通人，赋权给教师，赋权给学生，那么它就能带来更多的益处。

另外虽然可汗在书中提倡 AI 可以增强父母和孩子的互动，因为父母们正在对科技感到恐慌，他们拒绝接受科技，但实际上他本人却限制自家孩子使用电子产品😄，15 岁才有了手机，并且不允许他们使用社交媒体。

***

主持人: 他说，“我们的下一位嘉宾认为 AI 将会改变我们对教育的看法。”而且是向好的方向。Sal Khan 是可汗学院的创始人兼 CEO，该机构构建了一个名为 Khanmigo 的 AI 工具。他新近出版了一本名为《Brave New Words》的新书，探讨 AI 将如何革新教育，以及这为何是一件好事。他首次在 CBS Morning 节目上接受我们的采访。Sal，非常感谢你能够参与。

Sal Khan: 非常感谢你们的邀请。

主持人: 在这本引人深思的好书的末尾，你引用了海啸这个隐喻。你说，水已经退去，AI 的海啸正在向我们疾驰而来。这听起来是件好事。

Sal Khan: 这是事实。我的意思是，这已经在发生了。潘多拉的盒子已经被打开了。无论你是否接受，它都将来临。无论你是否愿意，人们都在大谈那个海啸的负面影响，谈论深度伪造和误导信息，但我希望人们能够认识到，在这里也有可能带来一些积极的影响，这并不是硬币的翻转。它就像以往的所有技术一样，是人类意图的放大。如果我们能在其背后投入更多的积极意图，让它更多地关注于教育，赋权给人民，赋权给教师，赋权给学生，那么它就能带来一些好处。

主持人: 在书中有一部分，你展示了一个学生和 Khanmigo 的互动，学生在数学问题上得到了辅导。这个家教的亲切、吸引人、头脑清晰的特质令人印象深刻，然而这并不是一个真人。

Sal Khan: 是的，其实在很多方面，我总是把使用案例放在技术之前。人们很容易被技术所吸引，但我是在 2004 年开始辅导我表亲的功课时踏上这条道路的。从那时起，可汗学院所做的一切都是基于这一点。我一直在努力复制我曾用于辅导表亲的个性化教学方式。我们已经通过视频和软件实现了这一点，但是如你所提到的，现在生成式 AI 能做到的几乎和我在波士顿远程教导新奥尔良的表亲时所做的区别不大。

主持人: 谈到 AI 辅导，你在文中的第四部分提到了一次你的孩子们使用辅导的时刻。你说，“我们要去海滩了，上车吧，我们需要暂时放松一下远离电子设备。”但你确实认为 AI 可以增强父母和孩子的互动，因为父母们正在对科技感到恐慌，他们拒绝接受科技，然而你却鼓励他们去接纳它，认为这能帮助提升他们的关系。这是怎么回事呢？

Sal Khan: 我持双方的看法。我的意思是，在我家里，我们也会限制电子设备的使用。有时候你确实需要远离电子设备。我们不允许孩子们使用手机。我们的 15 岁孩子刚有了手机，但我们不允许他们使用社交媒体。

主持人: 直到 15、16 岁，才允许他们有手机和社交媒体？

这主要是为了方便我们接送他们。所以我们在这方面非常严格。但我总是告诉别人，科技本身是中性的，它可以被用于好的目的，也可以被用于不好的目的。如果你的孩子想写论文，编程或者剪辑视频，这些都是积极的用途。如果他们想在可汗学院学习，我们认为这也是一个好的用途。如果他们想和 AI 讨论法国大革命，那可能是个好的运用。但若是想作弊，寻找答题的捷径，那可就不是好的运用了。

主持人: 提到这，你的 AI 可能有一些防护措施，但大多数平台都没有。那我们如何在教育中保持诚信呢？

Sal Khan: 嗯，我们在《Brave New Words》一书中专门讲了一章关于作弊。我也觉得看看在 ChatGPT 出现之前的作弊情况很有趣。作弊的情况其实很多，比如让姐姐代写作业等。网上有些服务，我可不想给他们做广告，会很乐意以每页 5 美元的价格帮你写论文，而这些都是人帮你写的。这种情况一直都存在。但在可汗学院，我们正在开发一种方式让学生可以和 AI 一起写作。然后，AI 可以向老师报告整个过程，而不仅仅是成果，因为我们不知道那些内容从哪里来的。比如说，“嘿，我和 Sal 一起做了这篇论文，我和 Sal 一起花了四个小时做了这篇论文。它看起来像他的其他作品。顺便说一下，我给出了一个初步的成绩，可以帮助你，老师，节省一些时间。”如果 Sal 去 ChatGPT 或请他的姐姐代写了论文，它会说，“我不知道这篇论文从哪里来的，看上去有点可疑。”你应该再和 Sal 深入了解一下。

主持人: 我昨晚玩了 Khanmigo，发现它能让很多抽象的概念变得很亲近，我真希望我小时候就有这样的东西。话虽如此，问题是，孩子们是在学习如何学习，进而在工作中运用这些 AI 技能，还是他们只是学会如何向计算机输入信息和查找东西？

Sal Khan: 嗯，我认为这是关键。当 ChatGPT 首次出现时，我很担心，因为我们当时正在与 OpenAI 签订保密协议，我们没有启动 Khanmigo。你是这个领域的先驱，我们也是，我们正在开发 Khanmigo。然后，ChatGPT 一出来，虽然它并非专为教育构建，学校系统就因为作弊等问题开始禁止它。因此，我确实认为如果没有在适当的环境下使用，它有时可能会破坏真正的学习过程。

主持人: 那它会取代思考吗？自从火柴被发明以来，人类制火的能力就在下降，对吧？所以，当电脑为你思考时，我们什么时候学习呢？

Sal Khan: 其实，这是一种放大效应。我认为不愿意投入的人会找到早在这之前就存在的捷径，而那些愿意更多参与的人将能够做到。但我认为课堂的角色非常重要，老师和家长的角色也很重要，因为他们可以确保学生以正确的方式参与学习。我写这本书的主要原因是，人们已经开始在使用这些技术了。我住在硅谷，很多孩子都开始使用这些技术。我希望所有社区、所有孩子、所有教师和所有课堂都能从中受益。

主持人: 谢谢你，Sal Khan。《Brave new words》现在正在销售。

视频来源：https://youtube.com/watch?v=peechnt9zvc



### 91

2024-05-16


宝玉
@dotey
OpenAI 创始人 John Schulman 访谈节选：为什么 GPT-4 比一年前更“聪明”了？主要都是后训练（Post-Training）带来的！

另外他认为，在强化学习研究领域，研究人员需要具备丰富的经验和敏锐的直觉。了解整个技术堆栈，并对各个部分充满好奇心是关键。此外，从第一性原理出发思考问题，而不仅仅依靠实验证据，也能够帮助研究人员在数据操控和环境设置方面做出更好的决策。

***

Dwarkesh Patel：在未来，用于训练的计算力中，预训练与后训练的比例是否会明显偏向后训练呢？

John Schulman：确实，有一些观点支持这种说法。

Dwarkesh Patel：我是说，现在这个比例非常不平衡。

John Schulman：但你可以认为，模型生成的输出质量比网上的大多数内容都要高。因此，让模型自己思考似乎更有道理，而不仅仅是训练来模仿网络上的内容。所以，我认为从第一性原理上来说，这是有说服力的。我会说，我们通过后训练取得了很多进步。因此，我不确定。所以，我希望我们会继续推动这种方法，并且可能会增加投入到后训练中的计算力。

Dwarkesh Patel：当前的 GPT-4 的 ELO 分数比最初发布的版本高出了大约 100 分。这是否全都是后训练带来的改进呢？

John Schulman：对，我会说大部分都是后训练带来的。

Dwarkesh Patel：这很有意思。

John Schulman：因此，有很多不同的改进方向。我们会考虑数据质量，数据数量，进行更多的部署和收集新数据的迭代，改变你收集的注解种类。因此，有很多因素叠加在一起。但是全部加在一起，就会带来一个相当不错的，有效的计算力提升。

Dwarkesh Patel：后训练的优化程度对于竞争优势有多大影响呢？

John Schulman：目前，我会区别公司是通过我们的模型有多大等等。那么，找出你之前提到的所有这些数据的复杂问题的公司，会占据大优势吗？

John Schulman：我认为这确实是一个优势，因为这是一个非常复杂的任务。因此，你必须有很多有技能的人来执行它。因此，存在大量的隐性知识。同时也需要大量的组织知识。我认为后训练的过程，创建一个具备人们所关心的所有功能的模型，是十分复杂的。这需要付出大量的努力，它是大量研发工作的积累。我会说这种情况在某种程度上形成了一种壁垒，要想立即启动这种模型并非易事。

Dwarkesh Patel：看起来那些正在进行最严肃的预训练努力的公司，也在进行严肃的后训练努力。因此，看起来这种模型有可能被复制或有更多的类似努力出现。

John Schulman：另外，还有一种情况使得这个壁垒并非那么明显，那就是你可以提取模型，或者复制别人的模型输出，或者使用别人的模型进行比较。我认为大公司可能并不会这样做，因为这违反了服务条款，也会损害他们的自尊心，但我预计一些规模较小的参与者可能正在这样做以便更好地起步。

Dwarkesh Patel：那些真正擅长进行这种强化学习（RL）研究的人有什么样的特质呢？我听说这种研究非常具有挑战性，但是什么样的直觉能帮助你找到操控数据和设置环境的方法呢？

John Schulman：我觉得有相当多的经验是关键。自从研究生时期以来，我一直在研究 RL 算法，涉及到数据收集、到注释过程，再到与语言模型的交互。所以，我算是涉猎了这些领域。我认为，在这类研究中表现出色的人通常对整个技术堆栈有全面的了解，并且对其中的各个部分充满好奇心。他们不仅依靠实验证据来更新自己的观点，还会从第一性原理出发思考问题。比如，假设深度学习是有效的，那么理想的收集数据的类型应该是什么，等等。

https://youtube.com/watch?v=JclnqKZBTUU



### 92

2024-05-16

Ethan Mollick
@emollick
Education is one of the areas in which LLMs can do the most immediate good, even with their limitations, so I was excited to see that Google is fine tuning a tutor LLM.

Also, the comparison they used was Gemini 1.0 running a variation of our tutor prompt! The prompt alone did ok



### 93

2024-05-16

倪爽
@nishuang
我一直都建议程序员不要自学设计

\#迷你设计课

反过来举例描述一下大家就理解了

比如我是设计师，我想把 ChatGPT 包装起来开发成“育儿宝典”app，那么不管我自学编程、还是从网上拼凑代码、还是用开源代码修改、还是用 low-code 工具生成代码、还是用 ChatGPT 帮我输出代码…

不管怎么操作，结果都一样屎。大概率就是我花 10 倍的时间、做出一个不及格的 APP、再花 10 倍时间去修 bug…

我一直都建议程序员、开发者用这几种方式获得设计，效果从烂到好，依次是：

1，AI 生成

AI 生成图像、视频甚至界面，都不适合通常没有评判标准/审美观的程序员，很难生成能打动用户的设计

还是反过来举例：比如我不懂德语，让 ChatGPT 帮我把简历翻译成德语，我怎么知道翻译结果是好是坏？

2，使用 low-design 工具

市场部的妹子很喜欢 Canva 这类 low-design 工具，它们提供了大量现成模板，你随便改改文字和照片就好，非常适合营销相关的设计。但对多数程序员而言，连基本的穿衣搭配概念都没有，怎么选中合适的模板、怎么做出好看的设计

反过来举例：比如我用 low-code 工具 bubble 来开发我的“育儿宝典”app，我就是看看 bubble 的操作界面，看几句不着调的帮助，忽然我就变身程序员、想清楚了程序里的复杂逻辑分支？

3，购买现成设计

现在网上有各种照片图库、UI Kit、设计模板，不但开箱即用，而且立刻达到中等以上的设计水准

这个很好理解，即便是最容易变心的前端工程师，通常也是挑一个流行框架、而不是自己创造一个

购买现成设计的技巧是：既然你不知道哪种设计最好，那就买一个最热门、最流行的设计

4，找一个设计师合作

让专业的人做专业的事，这是最有效也最省钱的做法，也能最大概率地得到令用户满意、能产生收益的设计

a，去 upwork、猪八戒临时找个设计师，效果一般不太理想

还是反向举例：比如我的“育儿宝典”app 需要 iOS 开发，想用最便宜的价格、最快速度上线，结果找到一个最便宜的巴基斯坦哥们，他口口声声跟我说应该选什么什么数据库…我是不是很想死？

b，一般不建议刻意为了找免费设计师而找一个设计师女朋友/男朋友

如果你们首先情投意合、相濡以沫，其次是工作和生活上的合作伙伴，那非常好（推特上某位独立开发大佬就是这样的“神仙眷侣”）；如果你只想占便宜、蹭设计，多想一下翟欣欣的例子

c，我最建议程序员在同事、过去合作过的设计师里寻找合作者，有过共事经历的人，大家起点也差不多，容易沟通，也更容易产生信任。这些都能促成长期合作

略差一点，也可以试试网上长期关注的设计师，长期关注能弥补信任度，也方便大家交流。我有一些很好的客户，就是在推特上找到我，大家交流起来都很有效，合作也更简单可行

---

小结一下：

掌握设计能力，是开发者尤其独立开发者的必备技能，也是一般程序员的加分项，但相比获取设计的其他各种方法，自学是掌握设计能力的各种方法里最烂的一个

我们不会为了吃肉而去自己学习养猪，我们也不应该为了掌握设计能力，而强迫自己学设计

---


宝玉
@dotey
我的观点，不一定对：作为程序员或者说非设计师，最需要的不是设计能力的提升，而是审美能力的提升，看得出什么是好的设计，然后再借鉴或者请人就够了


### 94

2024-05-18


Tw93
@HiTw93
\#工程师工具 这个经典的 Mac 视频播放器 IINA 真的太适合当做默认使用了，格式上基本上全支持，比起自带的兼容性好很多，对于在线字幕的支持、用户界面的简洁感、打开默认好用、在线流媒体也支持，最喜欢的还是这个简洁的颜值，免费开源持续更新这么多年，挺佩服作者的。
🤖 https://iina.io



### 95

2024-05-18

宝玉
@dotey
转译：ChatGPT 可以交谈，但 OpenAI 员工却不能

OpenAI 员工签署了极其严格的离职协议，其中包括保密和不诋毁条款。它禁止他们终身批评他们的前雇主。甚至承认 NDA 的存在也是违反协议的。

***

周一，OpenAI 宣布了一条令人振奋的新产品消息：ChatGPT 现在可以像人类一样交谈。

它有一个愉快的、略带讨好意味的女性声音，听起来令人印象深刻地不像机器人。如果你看过 2013 年斯派克·琼斯执导的电影《她》，你会觉得这个声音有点熟悉。OpenAI 的首席执行官 Sam Altman 在推特上提到这部电影中的 AI 助手，由斯嘉丽·约翰逊配音。

但 ChatGPT 4o 的产品发布很快就被来自 OpenAI 的更大新闻所掩盖：公司联合创始人兼首席科学家 Ilya Sutskever 辞职，他是超级对齐团队的领导者之一，以及他的联合团队领导 Jan Leike（去年我们将其列入 Future Perfect 50 名单）。

他们的辞职并不完全令人惊讶。Sutskever 曾参与去年导致 Altman 暂时被解雇的董事会叛乱，虽然 CEO 很快重返岗位。Sutskever 公开对自己的行为表示遗憾，并支持 Altman 的回归，但自那以后他基本上不再出现在公司，即使在 OpenAI 的政策、对齐和安全团队的其他成员陆续离开。

但真正引起猜测的是前员工的沉默。Sutskever 发布了一条典型的辞职消息，说“我相信 OpenAI 会构建出既安全又有益的 AGI……我对未来感到兴奋。”Leike 的辞职消息仅仅是：“我辞职了。”经过几天的猜测，他在周五早上进一步解释说，他担心 OpenAI 已经偏离了以安全为中心的文化。

立即出现了许多问题：他们是被迫离开的吗？这是去年秋天 Altman 短暂被解雇的延迟后果吗？他们是因为某个秘密而危险的新 OpenAI 项目而抗议辞职的吗？由于没有一个曾经在 OpenAI 工作过的人在说话，猜测填补了这个空白。

事实证明，这有一个非常明确的原因。我看到了包含前 OpenAI 员工极其严格的离职协议，其中包括保密和不诋毁条款。它禁止他们终身批评他们的前雇主。甚至承认 NDA 的存在也是违反协议的。

如果离职员工拒绝签署文件，或违反文件，他们可能会失去在公司期间获得的所有归属权益，这可能价值数百万美元。一位前员工 Daniel Kokotajlo 公开确认说，他为了在不签署文件的情况下辞职，不得不放弃可能会变成巨额财富的股权。

尽管在竞争激烈的硅谷中，保密协议并不罕见，但将员工已经归属的股权置于拒绝或违反协议的风险中却很不寻常。对于像 OpenAI 这样的初创公司员工来说，股权是一种至关重要的补偿形式，可能远远超过他们的薪水。威胁这种可能改变生活的钱是一种非常有效的让前员工保持沉默的方式。（OpenAI 没有回应置评请求。）

对于一个最初宣称自己是_Open_AI 的公司——即在其使命声明中承诺以透明和负责任的方式构建强大系统的公司来说，这一切都充满了讽刺意味。

OpenAI 早已放弃了开源其模型的想法，理由是出于安全考虑。但现在，它失去了其安全团队中最资深和最受尊敬的成员，这应该引发一些怀疑，即 OpenAI 变得如此封闭是否真的是出于安全原因。

终极科技公司

OpenAI 在科技和政策圈中占据了独特的地位。他们的发布，从 DALL-E 到 ChatGPT，通常都非常酷，但单靠这些并不足以吸引公司常常被讨论时的近乎宗教的狂热。

OpenAI 与众不同的是其使命的雄心：“确保通用人工智能（AGI，Artificial General Intelligence）——比人类更聪明的 AI 系统——造福全人类。”许多员工相信这一目标触手可及；也许只需再十年（甚至更短时间）——和几万亿美元——公司将成功开发出使大多数人类劳动过时的 AI 系统。

正如公司长期以来所说的那样，这既充满风险又令人兴奋。

“超级智能（Superintelligence）将是人类发明的最有影响力的技术，可以帮助我们解决世界上许多最重要的问题，”OpenAI 超级对齐团队的招聘页面声明。“但超级智能的巨大力量也可能非常危险，可能导致人类失去控制甚至灭绝。虽然超级智能现在看起来还很遥远，但我们相信它可能在本十年到来。”

自然，如果在我们有生之年实现人工超级智能是可能的（专家们对此意见不一），这将对人类产生巨大的影响。OpenAI 历来将自己定位为一个负责任的行为者，试图超越单纯的商业激励，造福全人类。即使这需要放慢发展，错失利润机会，或允许外部监督，他们也愿意这样做。

“我们不认为 AGI 应该只是硅谷的事情，”OpenAI 联合创始人 Greg Brockman 在 2019 年告诉我，在更为平静的 ChatGPT 之前的日子里。“我们在谈论改变世界的技术。所以如何让合适的代表和治理机制进入其中？这实际上是我们非常关注的一个重点，也是我们真的想要广泛参与的事情。”

OpenAI 独特的公司结构——由非营利组织最终控制的限利润公司——本应增加问责性。“这里不应该信任任何一个人。我没有超级投票权。我也不想要它们，”Altman 在 2023 年向彭博社的 Emily Chang 保证。“董事会可以解雇我。我认为这很重要。”（正如董事会去年 11 月发现的，它_可以_解雇 Altman，但无法使这一举动生效。在被解雇后，Altman 达成协议，将公司实际带到微软，最终在大部分董事会辞职的情况下复职。）

但没有比像 Sutskever 和 Leike 这样的人担任重要角色更能表明 OpenAI 对其使命的承诺，他们是长期致力于安全的技术专家，显然愿意在需要时要求 OpenAI 改变方向。当我在 2019 年的采访中对 Brockman 说，“你们在说，‘我们要建立一个通用人工智能，’”Sutskever 插话道。“我们将尽一切努力在这方面推进，同时确保我们以安全的方式进行，”他告诉我。

他们的离开并不预示着 OpenAI 构建通用人工智能的使命发生变化——这一目标仍然存在。但它几乎可以肯定预示着 OpenAI 对安全工作的兴趣发生变化；公司尚未宣布谁，如果有的话，将领导超级对齐团队。

而且这表明 OpenAI 对外部监督和透明度的关注并不深刻。如果你想要外部监督和让世界有机会在你的行动中发挥作用，让前员工签署极其严格的 NDA 并不合逻辑。

在闭门造车中改变世界

这种矛盾是让那些关心确保 AI 真正造福人类的人对 OpenAI 感到深深沮丧的核心。OpenAI 是一家制造聊天个人助手的时髦中型科技公司，还是一个致力于创造 AI 神的万亿级项目？

公司的领导层说他们想要改变世界，他们希望在这样做时承担责任，并欢迎世界对如何公正和明智地实现这一目标提供意见。

但当涉及到真正的钱时——在争夺 AI 主导地位的竞争中，有令人震惊的巨额金钱利益——很明显，他们可能从未打算让世界获得那么多的意见。他们的流程确保了前员工——那些最了解 OpenAI 内部发生的事情的人——无法告诉外界发生了什么。

网站可能有高尚的理想，但他们的终止协议充满了硬核法律术语。很难对一家前员工只能说“我辞职了”的公司进行问责。

ChatGPT 新的可爱声音可能很迷人，但我并没有感到特别心动。

来源：http://vox.com/future-perfect/2024/5/17/24158478/openai-departures-sam-altman-employees-chatgpt-release



### 96

2024-05-18


歸藏(guizang.ai)
@op7418
可以参考一下这个老哥的 ChatGPT Mac 端用法，先用白板画出交互然后截图快速拉起 ChatGPT 进行交互。

一分钟构建一个 Mac 应用程序。


### 97

2024-05-18

宝玉
@dotey
来自可汗采访 Greg 视频中的一段有价值的对话：为什么是 OpenAI 首先开发出像 GPT-4 这样强大的模型？即使像 Google、Meta 有那么雄厚的资本，那么多人才储备也没有做到？

因为 OpenAI 的团队不仅仅是学术背景的研究型人才，而同时还有优秀的工程人才，这种组合使他们能够从不同的角度解决问题，更有效的推动项目进展。

大多数实验室以研究为主，研究型工程师被告知要做什么，而研究科学家则可以随心所欲。这种方式似乎并不是实际构建一个工作系统的方法，更像是为了追求论文引用数量。如果你真的想产生影响并开发出有用的东西，你需要以不同的方式来组织团队。

***

**Sal Khan**：我想问的第一个问题是，你们认为自己做了什么才能达到如今的地位？在这个领域，有许多人在努力工作，也有许多资源雄厚的大型组织。你们认为自己做了什么与众不同？是因为你们的方法不同，还是有其他原因？

**Greg Brockman**：这是个很好的问题。我认为我们是更大趋势或历史的一部分。回顾过去70年的计算机发展史，我们经历了指数级的增长。2000年，Ray Kurzweil曾经说过：“看看计算能力，它会告诉你什么是可能的。这就是推动进步的动力。”起初，大家都认为他疯了，但现在我相信大家基本上都认同他的观点。想想我们为了实现像GPT-4这样的项目，付出了多少工程上的努力，从计算基础设施到使用的所有数据集和工具，这其实是全人类在很多方面的巨大努力。

具体来说，我们能取得这些成就，是因为我们聚集了来自研究和工程背景的优秀人才。我认为这是非常独特的。安全是我们工作的核心部分，涉及到所有不同的角度。无论是在实践中还是理论上，我们都在思考这些系统如何运行、如何成功、又会如何出错。

当我们开始这个项目时，让我感到非常有趣的是观察其他实验室的工作方式。你会发现，大多数实验室以研究为主，研究型工程师被告知要做什么，而研究科学家则可以随心所欲。这种方式似乎并不是实际构建一个工作系统的方法，更像是为了追求论文引用数量。如果你真的想产生影响并开发出有用的东西，你需要以不同的方式来组织团队。

虽然在纸面上看起来很简单，但实际上，这涉及到很多相互冲突的思维方式，特别是当你来自实践或学术背景时。我们必须尽力去解决这些问题。我认为我们已经解决了许多涉及不同思维方式和背景的复杂问题，虽然你永远不能完全解决它们，但可以不断解决其更复杂的版本。这就是我们需要勇于面对困难和挑战的地方。

来源：https://youtube.com/watch?v=z0S1ORbbQUU



### 98

2024-05-18

歸藏(guizang.ai)
@op7418
完整梳理了一下 Open AI 宫斗第二季的时间线和各方观点，核心是要安全还是要发展：

Open AI 宫斗积累的剩余矛盾终于在 GPT-4o 的发布会结束之后爆发了，感觉 Open AI 的宫斗跟快成了发布会之后的保留节目了。

核心还是 Ilya 主张的安全为主的加大对模型安全投入的超级对齐团队和以 Sam、Greg 为首的主张优先发展模型效果的管理层的矛盾。

首先是 15 号长时间没有发声的 Ilya 宣布正式离开 Open AI，场面很和气同时还说会在合适的时候公布自己新事业的信息，Sam 和 Greg 也发了推回应和感谢了 Ilya 的付出。

然后是现任的Open AI 超级对齐团队负责人 Jan Leike 宣布离职，同时还曝光了 Open AI 对模型对齐团队不公平的对待。

他认为 OpenAI 领导层在公司核心优先事项上存在分歧，导致Jan Leike 的团队在过去几个月里遇到了很多困难,包括计算资源不足等问题,使得关键研究工作变得越来越困难。

同时Jan Leike 认为 OpenAI 应该把更多精力放在为下一代 AI 模型做准备,包括安全、监控、应变能力等方面。

Jan Leike 应该是离职的人中首次明确的说自己受到的不公正待遇的，然后晚上 Sigal Samuel 就发布了一篇爆料文章解释了为什么之前从 Open AI 离职的人一般不会说明自己的情况。

因为OpenAI 通常会要求离职员工签署包含不贬损条款的离职协议。如果拒绝签署，他们将失去公司股权，这可能意味着损失数百万美元。

然后在 18 号 Sam 发推文承认，公司离职文件中确实有一项关于“潜在股权取消”的条款，但是他们从来没有真的启用过这个条款收回过任何人的股权，同时他不知道协议中有这条内容，公司也正在修改这项条款。

有趣的是2014 年还在 YC 的时候 Sam 还写过一篇博客，阐述了初创公司对于员工股权分配的问题并且给出了一些如何保障初创公司员工正常获取股权收益的建议。

过了十年曾经的屠龙者变成了恶龙。

同时 Sam 和 Grog 还针对 Jan Leike 的发言起草了一个声明大致意思是说模型的安全和能力发展同样重要，他们也做了很多事情来保证模型的安全。这个声明看起来很长但其实都是片汤话，评论里很多人说感觉像 ChatGPT 写的。

上面就是事件目前的一个发展情况，同时社区也有一些其他的看法比如 Daniel Jeffries 认为超级对齐团队的离开不是因为他们看到了他们无法应对的超级先进AI，而是因为他们研究后认为这种 AI 短时间不可能出现。

然后 Open AI 的领导层就开始缩减给超级对齐研究团队的资源开始做一些更实用的事情，比如用来构建产品改善体验。

杨立坤也表示认同上面这种说法。同时也罕见的认为 Sam 的这个操作是正确的担心现在的 AI 模型会造成安全问题是杞人忧天。

他将现在担心 AI 安全的人比喻成1925年有人说“我们迫切需要弄清楚如何控制能够以接近音速跨越大洋、运输数百名乘客的飞机。”

“在发明涡轮喷气发动机之前，在任何飞机能不间断飞越大西洋之前，长途客机的安全性是难以保证的。然而，现在我们可以安全地乘坐双引擎喷气式飞机飞越半个地球。 这并不需要什么神奇的安全配方。而是经过了几十年的精心设计和不断改进。”

我们的人工智能还处于早期阶段需要很多年才能达到人类的智能水平，别说超过人类了，所以需要不断的平衡效率和安全性，而不是把安全无限放大。

我总体上认同他的意见，人工智能现在是很早的阶段，我们还有非常多重要的事情要做，安全很重要但在早期阶段吃饱饭更重要。




### 99

2024-05-18


宝玉
@dotey
前两天播客 Latent Space 就有一期讲 NSFW Chatbots，嘉宾 Jesse 运营了一个 SaaS 平台，专门帮 OnlyFans 上的网红搭建 AI 聊天机器人，以网红的身份提供 AI 陪聊等服务，他们能基于网红的资料和风格，提供逼真的聊天服务，当然会包含色情聊天内容。

实际上在 OnlyFans 这样的粉丝平台，许多网红将与粉丝的聊天服务外包给菲律宾等低成本国家的团队，费用为每小时约 3 美元加 5% 佣金，但质量非常差。

从需求上来说，使用这种服务的粉丝主要分为三类：
1. 孤独，需要找人聊天
2. 为了获取内容
3. 想玩幻想类的游戏，需要有人配合

从产品上来说，他们的产品需要针对每个网红去做定制，比如有的网红是高冷女神范，那么 AI 机器人就不能显得太过热情，甚至回复速度不能太快，但也不能不回复。

即使大家都知道是能 NSFW 聊天，也不能上来就太直接，这样可能很快就索然无味了，还需要让 AI 去引导聊天，聊一些相互了解的话题，让粉丝产生信任，有更多互动，这样才能更持久。

从技术上来说，他们没有选择 OpenAI 这样的闭源大语言模型，一方面原因是 OpenAI 经常会拒绝生成一些内容，另一方面成本也偏高。所以他们现在使用的是开源模型，并且基于每个网红的风格进行微调。

微调的数据来源主要是网红的资料、和粉丝的历史聊天记录。但是聊天记录也要筛选，因为有些聊天结果粉丝并不满意。

在安全性上，他们会将整个聊天内容的生成分成几个阶段，在中间用 LLM 再做一些特定的检查，避免隐私泄露、虚假承诺等问题。虽然这会导致响应时间变长，但是由于他们是做的网红和粉丝的聊天，粉丝通常对于响应时间容忍度比较高，甚至于有些高冷女神风格的网红，还需要刻意的响应时间长一点。

对于历史聊天的记忆能力，这个比较难做，他们用了取巧的办法，例如，当 AI 与一个粉丝谈论他们的工程项目时，最佳的回应可能不是“哦，太好了，我记得你在做这个布料项目”，而是“这很无聊，来和我玩点刺激的吧。”

如果有兴趣的话，推荐听一下这期播客：https://latent.space/p/nsfw-chatbots

或者你也可以看我翻译后的文稿：https://baoyu.io/translations/llm/nsfw-chatbots


### 100

2024-05-18



Connor Shorten
@CShorten30
Gemini Pro 1.5 and Gemini Flash!! ✨🔥

I am SUPER excited about long context LLMs! I put together a quick video walking through a Lost in the Middle / Needle in the Haystack test, using Gemini for Re-Ranking, and something I think is really exciting and gamechanging ... 🥁 ...

Many-Shot In-Context Learning!! 🔥🔥🔥

Researchers from Google (and published last night from Stanford as well exploring this in Multimodal settings), are showing that we can get even better LLM performance with say 500+ examples of the task in the input!

In the video I argue that we are now seeing the 4th wave of programming AI from:
• Wave 1 = Supervised Learning with tons of examples
• Wave 2 = GPT-3, in-context learning with a few examples
• Wave 3 = ChatGPT, instruction following without any examples
• Wave 4? = Many-Shot In-Context Learning, powered by Long Context LLMs!

I hope you find it useful! Really interested to see how this develops!

https://youtube.com/watch?v=3N-_lLMDcbs


### 101

2024-05-18

naklecha
@naklecha
today, im excited to release a repository that implements llama3 from scratch -- every matrix multiplication from attention across multiple heads, positional encoding and every other layer in between has been carefully unwrapped & explained. have fun :)

https://github.com/naklecha/llama3-from-scratch


[naklecha/llama3-from-scratch: llama3 implementation one matrix multiplication at a time](https://github.com/naklecha/llama3-from-scratch)


### 102

2024-05-18

歸藏(guizang.ai)
@op7418
看完 Sam 早期的这个关于投资的视频，终于理解投资人为什么执着于询问项目预期的规模了。

他说了他投资早期犯的两个错误，其中一个就是不理解“幂律”。

幂律的意思是，你最成功的一笔投资带来的回报将超过你其他所有投资的总和。

所以即使你投资的 95% 都失败了，只要有一个足够大的成功也可以对冲其他的失败投资。

所以他在看项目的时候会想两个问题，首先问自己的问题不是为什么它会失败……第一个问题是如果它成功了能有多大？

另外一个错误是不要太在意其他投资人的看法。



### 103

2024-05-21


歸藏(guizang.ai)
@op7418
刚发现前几天说的 ChatGPT 数据分析的优化已经上线了。

GPT-4o 的速度加上可交互的图表和表格这才是数据分析工具的完全体啊，太强了。

上传的表格数据会直接展示在界面上你可以选择行或者列来询问问题。

全屏之后会变成左边是图表右边是聊天的样式。

生成的大部分常见图表都是可以进行交互的。





### 104

2024-05-21

歸藏(guizang.ai)
@op7418
一个很好的项目，从头开始实现Llama 3模型，逐步进行矩阵乘法和张量操作。

写的非常详细，可以通过这个项目了解 Llama3 的构成和实现步骤，包括推断模型的细节、将Token转换为嵌入、transformer构建等。

配图也都很有意思。

[naklecha/llama3-from-scratch: llama3 implementation one matrix multiplication at a time](https://github.com/naklecha/llama3-from-scratch)

### 105

2024-05-21


Barret李靖
@Barret_China
这本书讲述的是咖哥和小雪的冰雪蜜语，把大模型到框架再到 Agent 的细节描绘的较为清楚，过程中也穿插了各种流行 Agents 工程的 Python 代码演示，还是挺适合小白入门学习的。

去年花了大半年时间研究过的东西，有不少都在这本书中看到了。

《动手做 AI Agent》

### 106

2024-05-21

宝玉
@dotey
论文：《(或许) 超越人类翻译：利用多智能体协作翻译超长文学文本》

摘要：机器翻译（MT）的最新进展显著提高了各领域的翻译质量。然而，由于文学文本语言复杂、充满比喻和文化细微差别，翻译这些文本仍然是一个重大挑战。在本研究中，我们介绍了一种新型的多智能体框架，该框架基于大语言模型（LLMs）进行文学翻译，并以TransAgents公司名义实施。这个框架模拟了传统的翻译出版过程，通过多个智能体的协同能力来应对文学作品翻译的复杂需求。为了评估该系统的有效性，我们提出了两种创新的评估策略：单语人类偏好（MHP）和双语大语言模型偏好（BLP）。MHP从目标语言单语读者的角度进行评估，而BLP则利用先进的大语言模型直接将翻译与原文比较。实验证明，尽管d-BLEU分数较低，但TransAgents的翻译在需要领域特定知识的体裁中，比人类撰写的参考文献更受人类评估者和大语言模型的青睐。我们还通过案例研究突出了TransAgents的优势和局限性，并为未来的研究指明了方向。

---

Longyue Wang
@wangly0229
🤔 How do Language Agents perform in translating long-text novels?
🚀 We introduce TransAgents, a multi-agent framework using LLMs to tackle the complexities of literary translation. 
🤖 Amazingly, TransAgents' outputs are preferred by human readers.
Paper: https://arxiv.org/abs/2405.11804



### 107

2024-05-21

Ethan Mollick
@emollick
Cool experiment where researchers assemble an AI translation “company” with AI agents with simulated backgrounds filling various roles, from editors to proofreaders.

The AI “company” creates accurate translations of Chinese web novels that people prefer to GPT-4, and human, ones

---

Ethan Mollick
@emollick
It looks like the default visualization style for LLM agent-based simulations is just going to be Stardew Valley.

### 108

2024-05-21

Ethan Mollick
@emollick
Been using Devin for months. They nailed the user experience and it can produce useful work, but GPT-4 class models aren’t quite powerful enough to reach all their goals. Assuming GPT-5 is a big leap forward, Devin + Microsoft is going to be an early example of agents at work.



### 109

2024-05-21


Victoria Slocum
@victorialslocum
Retrieval Augmented Generation (RAG) is one of the most popular techniques to leverage large language models for almost any type of use case.

In a RAG workflow, the user asks a question, like “What is Weaviate?”, and that query is sent into a vector database to search for related documents or chunks to the sentence. Then, that context, along with the original query, are put together in a prompt for the LLM. The LLM will then output a conversational response to the original question using the provided context.

There’s a lot of benefits to RAG systems. Unlike other techniques, like fine-tuning, RAG can be much easier to update with new data or delete old or outdated information without retraining a whole model. They can help reduce hallucinations and errors seen in LLM systems normally, and users can directly see the source information used by the model, allowing increased transparency and trust.

Even though there are a lot of tutorials and resources for RAG now, it’s still a big technical undertaking to make a good, advanced RAG application. This is why we’ve build Verba, the golden RAGtriever - we wanted to provide advanced RAG techniques to anyone, even if they didn’t have a technical background, and make it super easy to use and customize.

Check out the full explanation in our video: https://youtube.com/watch?v=swKKRdLBhas
GitHub: https://github.com/weaviate/verba
Demo: https://verba.weaviate.io



### 110

2024-05-21

歸藏(guizang.ai)
@op7418
让 Arc Sreach 总结了昨晚微软 Build 2024 大会重点，太好用了精准又全面：

🤖AI 功能增强 — 微软宣布将 AI 功能整合到 Windows、Copilot 和 Edge 浏览器中。

📱Phi-3-vision 发布 — 这是微软四月份宣布的 Phi-3 AI 模型的新版本，支持多模态功能，适用于移动设备。

🌍Edge 浏览器实时翻译 — Edge 浏览器将获得 AI 动力的实时视频翻译功能，支持多种语言和视频平台。

🎨Microsoft Teams 自定义表情 — Microsoft Teams 将支持自定义表情，包括在组织域之外不可见的表情。

💻Snapdragon PC — 高通发布了一款与 Mac Mini 大小相近的 Snapdragon Dev Kit for Windows。

📂File Explorer 集成 Git — 微软的 File Explorer 将集成 Git，方便开发者跟踪代码项目。

📋Windows 剪贴板 AI 功能 — Windows 11 的 PowerToys 套件现已支持高级粘贴功能，需要 OpenAI API 密钥。

🖥️.NET 和人工智能 — .NET 9 推出了一系列功能和工具，加速开发人员构建 AI 应用的过程。



### 111

2024-05-21


Victoria Slocum
@victorialslocum
Multimodal Retrieval Augmented Generation (RAG) integrates multiple data modalities, such as text, images, and audio, into a retrieval and generation process, allowing LLMs to use richer context to produce better informed outputs.

Multimodal RAG is particularly interesting for several industry use cases, such as:
1️⃣ Retail and E-commerce: Integrate product descriptions, images, and user reviews into search and service, allowing more personalized results, recommendations, and service.
2️⃣ Healthcare: Integrate text data from patient records, imaging data ( e.g. X-rays, MRIs), and audio data (e.g. doctor-patient conversations) to provide comprehensive information stores for RAG or other generative systems that can help provide detailed, factually-based responses.
3️⃣ Media and Entertainment: Synthesize scripts, visuals, and audio clips to generate high-quality multimedia content for content creation and curation.
4️⃣ Education: Combine textual content, educational videos, and interactive audio materials to create adaptive learning experiences for diverse learning styles.

Not only are these interesting fields for multimodal RAG, I personally believe these are four of the fields where we’ll see the biggest impact of LLMs and AI systems 👀

Super excited about the 
@DeepLearningAI
 course by my colleague 
@sebawita
: https://deeplearning.ai/short-courses/building-multimodal-search-and-rag



### 112

2024-05-21

宝玉
@dotey
\#AI开源项目推荐：ambientGPT

一款开源的多模态 MacOS 基础模型操作界面。

这款工具可以调用 GPT-4o API 或者本地开源模型进行问答，并能直接访问屏幕内容而不需要截图。本地模型是基于的 Apple 的 MLX 库，技术栈是 Python + Node，可惜不是 Swift 原生。

地址：https://github.com/siddrrsh/ambientGPT



### 113

2024-05-21



宝玉
@dotey
课程视频翻译：《“多AI智能体系统”（Multi AI Agent Systems）》

这门课程由 
@crewAIInc
 的创始人兼CEO 
@joaomdmoura
打造。在这门课程中，你将学习如何将复杂任务分解为多个AI智能体的子任务，每个智能体都扮演一个特定的角色并执行相应的任务。

例如，生成一份研究报告时，你可能会有研究员智能体、撰写智能体和质量保证智能体进行协作。你需要像管理团队一样，定义这些智能体的角色、期望和交互方式。

课程将涵盖关键的AI智能体技术，包括角色扮演、工具使用、记忆管理、保护机制以及跨智能体协作。你还将学习如何构建自己的多智能体系统，以便解决复杂任务。我相信你会发现设计智能体并观察它们协作完成任务既高效又有趣。

多智能体架构将在推动AI系统的发展方面起到重要作用。

课程地址：https://deeplearning.ai/short-courses/multi-ai-agent-systems-with-crewai/


### 114

2024-05-24



歸藏(guizang.ai)
@op7418
这些 AI 头部公司员工的博客真是宝藏，总能找到一些公开信息没有的东西。

比如上次说数据即是模型的 Open AI 员工 jbetker，也参与的 GPT-4o 的训练，据他说这个项目去年年底才开始。

是从一个构建AudioLM的项目延生出来的。几个月就能搞成这样确实离谱。


### 115

2024-05-24


宝玉
@dotey
论文：《WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models》

---


宝玉
@dotey
来自浙江大学、腾讯 AI 实验室和西湖大学的新论文：《WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models》

这篇论文详细的讲解了如何借助 GPT-4V 这样的多模态模型，与开放网络中的网站交互，完成用户的各项指令。

如果你有做过类似的事情的话，会发现其实还是很有挑战的，因为让 AI 遵循指令操作网页，特定的网站相对容易，因为网页元素和路径比较固定，但是开放环境的话，每个网站都不一样，交互方式也千差万别，再加上浮动广告、弹出窗口和网页内容实时更新等等。

具体在实现层面，要先理解当前网页的内容，然后根据用户指令，在网页上选择正确的操作，根据操作的结果再继续下一步操作，直到完成任务。

举例来说，我们要去苹果官网查询，附近的哪个苹果店能买到特定型号的 iPad 保护壳（Smart Folio）。如果是人操作的话，要打开官网，找到配件页面，搜索关键字，找到配件查看详情，从详情页选择弹出位置搜索界面，输入邮编，找到最近的苹果店。但这系列操作对于 AI 来说还是很有挑战的。

那么 WebVoyager 是怎么来做的呢？

一、AI 如何浏览操作网页？

首先，WebVoyager 不是用的普通浏览器，而是基于 Selenium，这是一个自动化网页测试工具，可以方便的截图，可以自动化操作网页浏览器。

但是要让 GPT-4V 能识别和操作网页元素，还需要对网页上的可以操作的元素进行标记，WebVoyager 开发了一个叫 GPT-4-ACT4 的 JavaScript 工具，它能够根据网页元素的类型自动识别交互元素，并在这些元素上覆盖带有数字标记的黑色边框。

此外，GPT-4-ACT4 还能向智能体提供了一些辅助文本，如交互元素内的文字内容、元素类型以及 aria-label 属性中可能的注释文本，以简化观察过程。


### 116

2024-05-24


Leonie
@helloiamleonie
If I had known how quick getting set up with Ollama was, I wouldn’t have put it off for so long.

Here are the 5 steps to get you from zero to an on-prem vector search with 
@Ollama
 and 
@Weaviate_io
.

🔗How to incorporate this in a fully local RAG pipeline: https://weaviate.io/blog/local-rag-with-ollama-and-weaviate


### 117

2024-05-24


Ethan Mollick
@emollick
A really intriguing set of findings of AI researchers that needs more exploration, replication, and expansion: AI agents given personalities and backgrounds, and placed into a virtual formal organization (with CEOs, VPs, etc.) outperform normal AI in doing complex tasks.


### 118

2024-05-25

宝玉
@dotey
完整视频文稿：

\## 欢迎致辞

非常激动今天能来到巴黎。看到巴黎充满了 AI 的活力，能再次回到这里真的太棒了。我在这里开始了我的职业生涯，目睹法国的科技生态在过去 15 年的变化，让我感到非常惊奇。我在等待幻灯片是否能正常播放，但不影响我继续演讲。

\## 在 OpenAI 的工作

在 OpenAI，我的工作主要是关注如何帮助开发者、创造者和创始人在我们的平台上顺利开展工作，以便你们可以无障碍地将 AI 融入你们的应用程序中。在加入 OpenAI 之前，我也曾是创始人，就像你们中的很多人一样，我有过直接使用前沿模型的经验，现在我很高兴在 Vivatech 为你们展示这种魔力。

\## 主题介绍

请把我的演讲笔记放在屏幕上好吗？谢谢。今天我想要讨论三个主题。第一，AI 的发展概况以及我们是如何达到现在这一步的。接下来，我想谈谈我们刚在上周发布的最新旗舰模型 GPT-4o，你们中的许多人可能已经听说过了。最后，我将讨论 OpenAI 的未来发展方向，如果你们之前参加过关于 AI 的讨论，我将带来一些现场演示，以让这个话题更有趣，同时展示你们如何在现有的应用中运用这项技术。

\## OpenAI 的使命

首先，让我们来聊聊 OpenAI 及其使命。OpenAI 的使命是以造福全人类的方式去创造真正的 AGI，也就是通用人工智能。然而，我们首先是一个研究公司，当我们看到现在平台上的发展和被采用的程度，我们有 300 万开发者正在 OpenAI 上建立项目，我们有幸从崭新且快速增长的初创公司一路走来，现在在我们平台上有财富 500 强公司。在某种程度上，我们对此感到很惊讶，因为一般来说，像你知道的，很多公司需要很多年才能达到这个地步，但这也提醒我们，在像 AI 这样快速发展的领域，我们有可能低估了自己。

\## ChatGPT 的成功

实际上，ChatGPT 就是一个很好的例子。当我们在 2022 年 11 月推出 ChatGPT 时，我们原本打算保持低调，我们内部称之为低调的研究预览。这个是团队在发布前一晚收到的 Slack 信息。毋庸置疑，发布的反响很大，我们收到了大量的注册请求，现在已经有超过 1 亿用户注册了 ChatGPT，ChatGPT 每周的活跃用户也超过了 1 亿，这个数字还在持续增长。所以，这确实是一个迅速被接纳的过程。

\## GPT-4o 的推出

当人们谈论 OpenAI 时，他们常常会联想到 ChatGPT。更有趣的是，我们需要记住这并不是 OpenAI 最初构建的第一个产品。我们最初的产品是针对开发者的平台和 API，GPT-3 让我们对大语言模型的能力有了初步的了解，这是我们在 2020 年首次向开发者和构建者公开的模型，以便他们将其集成到自己的应用中。在给大家上下文的同时，也让我们保持一个全局观。这是 AI Dungeon，那个时候 OpenAI 的一个受欢迎的使用案例，这是一个角色扮演游戏，在游戏进行的过程中，你可以生成独特的故事，这就是那个时期在平台上发生的事情。而到了 2023 年，GPT-4 引领了一个全新的时代，它彻底改变了人们可以处理的问题类型。它拥有使用工具的能力，有更好的推理能力，当然还有许多创始人和建设者开始采纳它，以便在这里利用他们的产品。

\## 现场演示和 GPT-4o 的能力

对不起，我的演讲笔记在这里出了点问题。但是，看起来你们似乎还在听。所以说到 GPT-4，我最喜欢的一个例子就是这个，由 Spotify 制作的，这是一个简单的方法，可以让你每天早晨都有一个独一无二的播放列表。当我们谈论所有这些的时候，我们要记住，我们仍然处在这个转变的早期阶段，这标志着我们构建、实现和消费软件方式的根本性变化。因此，我们在 OpenAI 的目标是为你提供最佳的平台解决方案，以便你在这个转变中进行构建。你可以看到我们刚在上周发布的 GPT-4o，这是我们的新旗舰模型，现在它能够实时跨音频、文本和视觉进行推理，我预计我们将会看到一套新的辅助体验，这将随着 GPT-4o 和它的音频和图像功能的引入而到来。

现在，你可以真正用我们以前从未见过的方式实现人机交互，对于每一个这样的转变阶段，我们深信，初创公司是推动创新的关键力量。对我们来说，鼓励初创公司的发展至关重要，我们深信初创公司总是在推动创新，发明 AI 产品的新形态。你在屏幕上看到的关键领域，如客户服务，知识助手，智能体服务等，我们预计在这些地方将会看到最多的创新。实际上，你可以看到很多徽标，这表明欧洲正在进行大量的创新，我们希望有许多产品最终可能会在法国发布，并且最终可能会成为各自领域的领导者。这对于创造 AI 公司来说，无疑是最激动人心的时刻之一。

\## GPT-4o 的详细介绍

接下来，我们来详细介绍一下我们上周发布的新模型 GPT-4o。GPT-4o 是我们的新旗舰模型，它让你可以构建最自然、最直观的人机交互界面。我今天想强调的三个关键步骤功能。首先，它真的可以在极低的延迟下实现多模态操作，我认为这是我们以前从来没有实现过的。对于那些曾经使用过 ChatGPT 的语音模式的人，或者房间里那些曾经创建过语音体验的开发者来说，你可能会记得，你不得不把多个模型拼接在一起，进行转录、推理，最后进行文本转语音，这无疑增加了一些延迟，且可能会丢失一些上下文内容。现在我们有了 GPT-4o，一个我们称之为真正的全能模型，所有这些步骤都由这个模型来处理。

当你看这张图时，你会发现 GPT-4o 确实是我们新的最先进的推理模型，它在聊天和编程方面的性能有大幅提升。这个排行榜是由 LMSys 管理的，用户在不知道底层模型的情况下，将各种模型并排比较，看看他们更喜欢哪一个。你可以看到，GPT-4o 在最左边，它在推理能力方面确实独树一帜。

最后我想说的是，我们在 GPT-4o 模型中也实现了大幅度的效率提升，这意味着我们也能将这些效率优势传递给所有在我们平台上开发的人。换句话说，对于使用 API 的开发者来说，GPT-4o 的运行速度是原来的两倍，是 GPT-4 turbo 的一半价格，最后，它的速率限制提高了 5 倍。所以，我们的目标越来越明确，那就是让开发者能够在我们的平台上进行大规模扩展，相比之下，这已经超越了之前 GPT-4 Turbo 的能力。

\## 实时演示

但是，最直观的展示方式还是现场演示。所以我现在要切换到我的笔记本电脑。本来我计划从 iPhone 上做一些演示，但是在连接 iPhone 到场地时遇到了一些问题。所以，我将尝试在你在屏幕上看到的这个 Mac 应用中进行演示，我们将启动语音模式。

- 你好 GPT，你怎么样？
- 嘿！我很好，谢谢你的关心！你呢？
- 我很棒！我现在在 VivaTech 的舞台上，你能对参会者说几句欢迎的话吗？
- 当然可以！你好，VivaTech 的参会者！能够与众多杰出的思想家和创新者接触，真是太棒了！
- 我很喜欢你的开场白，但你能让它更生动一点，更充满激情一点，就像你在对一个庞大的、优秀的创始人群体说话一样吗？
- 当然可以！你好，VivaTech 的参会者！我们是不是已经准备好点燃创新的火花，引领科技的...
- 好的，ChatGPT，谢谢你！我猜他们肯定很喜欢这个！
- 听到这个真是太好了！如果还有其他我可以帮忙的事情，或者我可以增添激情，记得告诉我哦！

首先，你会注意到这个体验中非常低的延迟。能够实时与 ChatGPT 对话，真的太棒了。第二，你会注意到我现在可以实时地打断模型。我其实并不需要等到整个音频播完，只要我想，随时都可以重新参与到对话中去。你可能也注意到了第三点，现在它能理解语调，并且也能生成语调。因此，当我试图让 ChatGPT 显得更加投入、更加兴奋时，这反过来又改变了音

频输出。当然，ChatGPT 还拥有所有惊人的推理能力，这意味着我可以用这个应对大量的应用场景，例如实时翻译。

- 我们来试试吧！嘿，ChatGPT，我现在在 VivaTech，但我希望你能当翻译。那么你能把我说的所有英文都翻译成法文，反之亦然吗？
- （法语）你好，先生，我可以帮你翻译，请简单告诉我你想说的内容。你认为奥运会上你最喜欢的运动项目是什么？
- （法语）你最喜欢的奥运会运动是什么？你最喜欢的奥运会运动是什么？在你看来，未来哪项运动会被加入到奥运会中？

所以你可以看到，你真的可以实时使用它，我们当然还在优化法语的口音，但是看到你可以如何用这些体验进行教育或者任何如旅行和实时使用的场景，真的很有趣。

我还想展示的第二件事，除了语音功能，还有视觉功能。所以我在 Mac 应用上从来没做过这个，因为我原本打算在 iPhone 上给你展示这个，但我还是要试试看。

- 那我们开始吧。嘿，ChatGPT，我想请你帮我在城市中导航，我会画点东西给你看。好吗？
- 没问题！画好你需要的，我会尽我最大努力帮你在城市中导航。
- 好的，我需要一点时间。
- 没事，慢慢来。他真有耐心。准备好了告诉我。
- 好的，我现在要打开这里的摄像头。那你看到了什么？
- 看起来你画的是埃菲尔铁塔和凯旋门，两个标志性的巴黎地标。我能帮你什么？
- 太棒了，谢谢你能理解我简陋的画。对，我希望你能帮我指引到那儿，我这里有张地图。
- 看起来我们现在在凡尔赛门这里。
- 好的，你从凡尔赛门出发。要去埃菲尔铁塔，你可以乘坐地铁 12 号线，从凡尔赛门到协和广场，然后换乘 8 号线，朝巴拉德方向，然后在军校下车。从那里，走一小段路就能到达埃菲尔铁塔。
- 太好了，谢谢你，我想我已经搞清楚了，谢谢你。
- 不客气。玩得开心。

有趣的是，这儿有一个点需要注意，就是实时的视觉能力，我可以画个图，展示一个视频，而不只是像以前那样单纯拍照。就凭这副差劲的画，ChatGPT 还是能够判断出哪些是地标，并利用地铁图导航。

\## 代码助手

但我最喜欢的用法之一是…

- "告别巴黎，再见，听起来你又要开始新的旅程了，那么接下来是什么呢？"是的。我要开始了…哦，我静音了。

我想在 Mac 应用中给你展示的最后一件事，是我个人非常喜欢把它当作编程助手的例子。让我们看看吧。我会在右边打开 ChatGPT，我会打开一些代码，然后我会取消对 ChatGPT 的静音，接着我会向 ChatGPT 发送一些代码，提供一些代码的上下文，我们会试着实时修复一个 bug。

- 嘿，ChatGPT，我需要你帮我解答一个编程问题。
- 当然，我可以帮忙。你的编程问题是什么？
- 我要把一些代码复制给你。
- 好的，你准备好时就分享代码吧。
- 你能用一句话概括一下这段代码吗？
- 这段代码是一个叫做 discover 的 React 组件，它渲染了一个 Discover 卡片组件的网格，每张卡片的数据都是从一个叫做 trips.json 的文件中获取的。
- 太棒了，对的，就是这样。现在我希望你看一下我的屏幕。我想改变的是，它似乎在移动屏幕上不能很好支持响应式布局。就像内容被压缩一样。你能帮我让这个页面具有更好的响应式布局支持吗？
- 当然，让我们让它更好的支持响应式布局。你可以使用 Tailwind CSS 的响应式设计特性，根据屏幕大小调整你的网格中的列数。这是一种快速修改你的网格布局的方法。调整 Div 颜色，选择方案，将网格列设为一，对应设定为零到四列。这主要决定了布局。
- 我明白了，我实际上是在使用 Tailwind，那你能告诉我这些属性是什么吗？
- 当然。对于 Tailwind，你可以调整你的网格列类来使网格响应。这是你可以设置它的方式。网格列将根据当前屏幕大小控制你有多少列，所以你不需要太多填充网格，这是大多数像这样的响应式设计的一个好的经验法则。这为大多数屏幕大小设置了一列，小屏幕两列。
- 我明白了，所以我应该只做小的，我应该把 1 放上去，对吗？然后随着屏幕变大再增加吗？
- 没错。你可以根据不同的屏幕大小调整列数。例如，"grid-cols-1"表示默认小屏幕上设为一列，"sm:grid-cols-2"表示在小屏幕及以上设备上设为两列，"md:grid-cols-3"则表示在中型屏幕及以上设备上设为三列，以此类推。
- 我认为我已经掌握了 Tailwind 的响应式设计功能。你能帮我看一下，看看效果如何吗？
- 好的，我来看看。看起来你做的这些调整应该会让你的网格可以在不同屏幕大小上只是响应式布局。
- 太棒了，非常感谢。我认为我们的应用现在已经完全响应式了。谢谢你。
- 不客气，我很高兴能帮到你。享受你的响应式应用吧。

我想强调一点，我们不仅可以参与，深入解决一个编程问题，你可以复制代码，你甚至可以实时查看屏幕。而且，GPT-4o 的速度也非常令人震惊，即使是处理文本也是如此。

\## GPT-4o 的性能展示

举个例子，我们有这个新的模拟环境，你可以在这里并排比较 GPT-4o 和 GPT-4 Turbo。如果我点击运行，来创建一首关于奥运会的歌，你就可以看到它生成内容的速度比 GPT-4 Turbo 要快得多。所以说，它的推理能力非常强，速度甚至是原来的两倍以上。

\## OpenAI 的未来计划

好了，现在我们回到幻灯片吧。我想给你们稍微展示一下，我们在 OpenAI 的未来计划是什么。我想谈谈我们的四个投资重点。首先，我们的一大优势在于文本智能。我们坚信，提升文本智能将为 AI 带来变革性的价值。你可以在屏幕上看到，这是我们当前提供的两个主要模型。GPT-4o 是我们刚刚展示的具有原生多模态的最优秀模型，而 GPT 3.5 Turbo 的价格便宜 10 倍，非常适合完成一些简单的任务，如分类或者简单的实体提取等。我们期待继续提升大语言模型的智能水平，我们相信这样做的潜力仍然巨大。

到目前为止，我们认为这些模型已经做得很好，就像一二年级的小学生，他们能做出适当的回应，但偶尔也会犯错误。但有一点我们应该记住，那就是这些模型此刻可能是它们能够达到的最低智能水平。他们有可能在一瞬间进化到研究生的水平。他们可能在医学研究或科学推理等方面表现优秀。我们预计，也许一两年后，模型将会发生翻天覆地的变化。因此在今年，我们也打算进一步拓展这个领域。我们预计我们的下一代模型将在推理能力上带来显著的提升。

\## 降低模型的成本和提高速度

我们的第二个投资重点是降低模型的成本并提高其运行速度。我们明白，并非所有的应用场景都需要最高级别的智能。这就是我们为什么要投资的原因。你们可以在屏幕上看到，GPT 的价格在短短一年内就下降了大约 80%。这对于新技术来说非常罕见，价格能够如此迅速地下降。但我们认为，这对于你们在创新 AI 原生产品并扩大规模的过程中是非常关键的。另外一点也很重要，我们希望能够发布各种大小的模型，以满足你们在扩大规模时的各种需求。我们知道，一些智能体工作流可能总会推动推理需求到前沿。但有些流程可能需要一些对延迟更敏感的小模型。虽然我们今天没有具体的时间表可以分享，但我们很兴奋地告诉大家，这是我们正在积极投资的领域。

最后，我们还希望帮助你们处理异步工作负载。几周前，我们推出了批处理 API，这是一种非常方便的方式，可以一次性将你们的所有请求发送给 OpenAI。这意味着你可以享受到额外的 50% 折扣对于不需要立即回应的任务比如如果你想要发送大量的图片和图像进行视觉分析或者大规模处理很多文档使用这个批处理 API 非常便利。

\## 模型定制

第三，我们正在

大力投资模型定制。我们认为未来每个组织都会选择不同的处理方式，但他们都希望拥有一个能深入了解他们业务的模型。为此，我们提供了一系列的微调服务。首先，我们提供微调 API 任何人都可以开始使用，完全自助这是一种可以在模型之上添加数据微调一些参数使其适应你特定使用场景的方法。其次，我们提供协助微调服务，我们的团队可以与你的团队一起工作思考如何提高完成特定任务的性能我们的专家团队将会协助你完成这个过程。最后我们还提供了完全定制模型的训练服务，你可以使用 OpenAI 完全训练一个定制模型这些模型完全由我们安全地使用专有数据为我们合作的公司训练。

我想举两个例子来说明这一点。第一个例子来自 SK Telecom，他们使用了我们的协助微调服务，这使得他们在韩国运营和电信业务中的模型性能得到了全面提升。我还很激动的另一个例子是美国的一家创业公司 Harvey，他们主要为律师构建产品。他们定制了一款模型，以成为美国案例法的专家。他们在事实回应上实现了 83% 的提升，97% 的用户在特定的使用场景下，立即倾向于使用他们的定制模型。

\## 投资智能体开发

最后，我们也将继续投资于开发智能体。我们希望你能够构建提供协助的体验，并使用我们已经展示过的所有模态的智能体。我们坚信，未来，智能体可能会对软件和我们与计算机的互动方式产生最大的改变。根据任务的不同，它们将能够利用文本，也能够访问一些上下文和工具。所以，我们提到的所有这些模态也将带来一种全新且自然的与软件交互的方式。

\## AI 软件工程师的案例

我个人非常喜欢的一个例子是 Cognition 团队的 Devon。他们构建了一个 AI 软件工程师。这非常引人入胜，因为它能够处理复杂的任务，不仅能够编写代码，而且能够理解任务，创建工单，在需要的时候浏览互联网上的文档以获取新的信息，甚至还能够部署解决方案并提交 pull 请求等。所以这就像是我非常喜欢的那种 AI 智能体案例。事实上，Paul Graham 今年早些时候的一条推文引起了我的注意，他提到或者说意识到现在的 22 岁程序员的技术水平常常能够媲美 28 岁的程序员。我认为，当你考虑到现在的 20 多岁的年轻人已经在使用 AI 以及像 Devon 这样的工具，他们因为 AI 的帮助变得越来越高效，这是毫不奇怪的。

\## 语音智能体的应用

另一个我认为更倾向于消费者的 AI 智能体体验是 Presto。Presto 让客户用他们的声音下订单，使用的是一个语音智能体。在欧洲这里，我们可能没有很多的得来速，但这个例子吸引我的地方在于，它真正地在一个劳动力短缺的市场提供了帮助，反过来，这不仅提供了一个很好的体验，还让员工实际上能专注于食物和服务客户。

\## 实时演示智能体构建

现在，我想通过几个更多的实时演示来展示一下你如何可以实际地构建辅助体验和智能体。我们为开发者提供的第一个智能体版本是我们所称的“Assistance API”。Assistance API 是一个完整的工具包，你们所有人都可以使用它，将辅助功能带入你们的产品中。在这个例子中，我正在构建一个叫做“Wanderlust”的旅行应用，你可以看到右边有一个地图，而左边则有一个辅助体验。这完全是由 Assistance API 提供支持的。让我们快速看一下。

- 如果我说"巴黎奥运会的前五个场馆"，首先要注意的是，我无需管理这些。让我们稍微刷新一下应用。看来我们可能断网了。奥运会似乎让我们运气不佳，但现在我们又回来了。
- 我要强调的是，我不必管理对话历史，因为这些都由 OpenAI 的 Assistance API 自动处理。

第二个值得一提的酷炫功能是，你可以看到，当我开始与这些消息互动时，地图会自动缩放，这是我在构建智能体时最喜欢的功能之一。这就是所谓的函数调用，它可以让所有人都能把你们的应用中的独特功能和函数带到模型中。在这种情况下，我们使用的是 GPT-4o。因此，如果我问询罗马的前五个景点是什么，让我们看看这里会发生什么。按理说，这里应该再次出现文本和地图之间的互动。好的，我们开始吧。因此，如你所见，当我们与模型交谈时，它能够准确地定位到地图，因为它知道这个功能的存在。这非常酷，而这已经是 Assistance API 工具包的一部分。

\## 知识检索和文件访问

现在，我想要提到的另一个工具是知识检索。我们知道许多人都想将实事数据引入到与像 GPT-4o 这样的模型的对话中，通常你需要构建一个检索系统才能达到这个目的。我们从许多开发者那里了解到，这个过程可能会很复杂，因此我们在我们的检索系统中进行了大量的改进，现在我将尝试看看是否可以实时演示这个过程。因此，我实际上买了这本孤独星球的书，为了准备去意大利的旅行。这是一本非常全面的书。它有大约 250 页，大约 95 兆字节，我希望上传能够顺利进行，这里有一些冒险性。

但正在实时发生的是，一旦文件上传，它将被 Assistance API 自动嵌入，因此我不需要考虑要做的任何事情。就这样，我可以开始参与对话了根据这本书来问拉齐奥最佳的摄影地点在哪里？在我按下回车键之前，让我给你们看一下第 126 页，我记得是这个页码。我们翻到第 126 页。第 126 页是关于拉齐奥的，对吗？所以，我打算在这儿问一问拉齐奥最佳的摄影地点在哪里？我在浏览这本书的时候注意到第 128 页提到了一个摄影机会就在 Pitegliano。就这样，我们在实时中发现了这本书里的摄影地点就在这儿。再次强调，我并没有做任何工程化的工作我只需要把文件上传到对话中一切都已经替我处理好了。

\## 代码解释器

最后我还想强调一个我想介绍的工具，叫做代码解释器。代码解释器能够在后台编写 Python 代码回答一些非常精确的问题常常涉及到数字、数学和财务数据。所以，举个例子，如果在这个对话中我说我们 4 人正在共享一个 1200 欧元的 Airbnb 那我的份额加上我 260 欧元的机票费用是多少？那么，常常提出这些问题这并不是 LLM 默认会做的典型事情，是吧？所以实际上，在幕后我们正在计算所有的这些包括货币转换等等都是在沙盒中通过编写代码完成的。再次强调，作为开发者，我无需做任何事。但这并不是说，因为 Aponea 在管理，它就变成了一个黑箱。事实上，如果我来到这里，刷新这些线程，我们应该可以看到，这些就是我们一直在阅读的线程。你可以看到我们要去罗马的所有消息，我高亮标注地图的函数调用。而这里，这就是后台编写，用来回答问题、计算货币转换、除以人数等的 Python 代码。

实际上，Assistance API 就像一个完整的工具包，有会话历史，有检索和文件访问，你现在可以在检索中上传多达 10,000 个文件，还有代码解释器和函数调用，所有这些你都可以从第一天开始使用。

\## Sora 的预览

最后，我想向你们展示另一种超越对话的演示。所以，使用来自 ChatGPT 的 Mac 应用，我们已经看到了音频对话。这个功能也将在未来几周内出现在 API 中。我们也看到了现已可用的辅助 API，它能进行具有视觉功能的文本对话。但是，我想用我们的多模态做些不同的事情。所以，我相信你们大多数人已经看过 Sora 的预览了。Sora 是我们的扩散模型，能够从一句简单的提示词生成视频。目前，这还只是一个预览阶段，但我想向你们展示一下，给模型一句这样的提示词，它能创造出什么。这句提示词是关于巴黎在世界博览会期间的殖民地复古电影中。

这是演示中唯一不是现场的部分，由于时间关系，我事先已经将这句提示词送给了 Sora。这就是它输出的结果。这些都是直接从模型中输出的，没有进行任何编辑。我们做的唯一修改实际上只是在其上添加了一些声音。但是，能够亲眼看到这些帧，真是一种神奇的体验。

但是，如果我们想要拿这个视频做一些有趣的事情会怎样呢？如果我们想创建一个剧本，叙述那些视觉上发生的事情会怎样呢？所以，这里的第一步是，我要从这个视频

中剪出一分钟的几帧。现在，我们来了。我们有六帧。接下来我要做的是，我要将这六帧图片发送给 GPT-4o。然后，我们将实时接收到关于这些帧中所发生的事情的故事。给你们偷偷瞥一眼幕后情况，这就是我将要运行的代码。我会告诉它，嘿，你是一位历史教授。你将接收到一系列的图片。我希望你能叙述这些图片。我只是将我们正在屏幕上展示的所有图片发送给 GPT-4o，并实时接收回复。再次强调，这都是实时发生的。让我们看看 GPT-4o 会生成怎样的故事。让我们开始吧。

这是一个完全利用我们在 GPT-4o 中的视觉能力即时生成的故事。那么，如果我想再进一步又该怎么做呢？如果我想分享这个视频，但这次我希望通过一些音频使其更广泛传播，该怎么办呢？你可以使用我们在 API 中提供的文本转语音功能。API 中提供了多种语音选择。几周前，我们也预览了我们的语音引擎模型。我们展示这些模型的目的是在进行研究的过程中，与所有利益相关者积极互动，展示这项技术的优点，并与值得信赖的合作伙伴进行交流，以便在过程中收集他们的反馈。在这里，我想给大家预览一下语音引擎可能会是什么样子。

\## 语音引擎模型的展示

我会录制一小段我的声音作为样本，看看它会生成怎样的叙述。让我们来看看。

- 嗨，我很高兴能站在 Vivatech 的舞台上。我已经遇到了一些非常出色的创始人和开发人员。我也非常期待向他们展示一些现场演示，以及他们如何真正应用 OpenAI 的技术和模型到他们自己的产品和业务中。

好的，这应该足够了。

- “嘿，我很高兴能站在这个舞台上……”

完美。接下来的最后一步，我将把我们创建的剧本和这个音频样本一起，分享到文本转语音中。我们将整合所有内容，让大家在多模态体验下听听这堂历史课。

- 在巴黎的中心，1889 年的世博会期间，埃菲尔铁塔骄傲地屹立着，作为一个象征……

现在，它正在为我播放我可以分享的视频。当然，它能支持众多语言。但是现在，如果我想广泛分享它，比如不仅仅是法语，还有其他语言，我可以点击分享这些内容。我们再试试日语。这可能需要一些时间。最后但同样重要的，我还可以添加字幕。再次强调，这只是一个预览。我想给你们提前一点看看。对于这种模型和能力，我们非常重视安全。这也是我们目前只向值得信赖的合作伙伴提供的原因。但我希望这能激发你的想象，就像这些模态能够实现的，以及你在构建自己的应用程序和产品时，如何去思考未来。

\## 总结

那么，让我们回到演讲，做个总结。所以，总结一下，我们主要聚焦在四个大的投资领域，我之前提到过。我们致力于提升文字智能水平。我们正在努力让我们的模型更快更经济，以方便大家扩展应用。我们也在助力你们根据自身需求定制模型。最后，我们鼓励你们构建多模态智能体，就像你们在辅助 API 中看到的那样。

所以，如果有一件事我希望你们从这个演讲中带走，我希望是这个。我们在 OpenAI 的目标并不是让你在 OpenAI 花的更多，实际上，我们的目标是帮助你们利用 OpenAI 构建的更多。这就是我们真正想要传达的信息。我们真的希望你们能记住这个理念，我想这就是我们推动文本智能的动力。这就是为什么我们一直在努力降低模型的使用成本。这样你们就可以为自己的用户和客户构建出令人惊叹的产品。我们非常致力于支持初创企业和开发者。我们期待与你们中的尽可能多的人合作。

\## 如何为未来做好准备

我们经常被开发者问到一个问题，那就是如何为未来的模型做好准备？我该如何准备？我应该有何期待？我们认为，大家可以从两种策略中进行选择。一种是，你可以预计模型大概会保持现状。你可以依赖 GPT-4o 现有的功能去工作。或者，你可以预计未来的模型会更加强大。你可以把赌注押在 AI 的未来上。我们认为后者的可能性更大。所以，我们建议你们为 AI 的未来做好准备。我们知道，这就是最具创新精神的开发者如何超过步伐较慢的传统企业的方式。

\## 结束致辞

那么，非常感谢大家。我们迫不及待想看到你们能创造出什么。谢谢。真棒。非常感谢。

### 119

2024-05-25

宝玉
@dotey
芝加哥大学布斯商学院研究论文：《使用大语言模型进行财务报表分析》

GPT-4 可以帮助选股，击败人类和其他为金融训练的机器学习模型。

论文摘要

我们研究了大语言模型（LLM）能否像专业人类分析师一样成功地进行财务报表分析。我们向GPT-4提供了标准化和匿名的财务报表，并指示模型分析它们以确定未来收益的方向。即使没有任何背景或行业信息，LLM在预测收益变化方面的表现也优于财务分析师。尤其是在分析师往往遇到困难的情况下，LLM展现出相对优势。

此外，我们发现LLM的预测准确性与一种狭义训练的最先进机器学习模型的表现相当。LLM的预测并非来自其训练记忆。相反，我们发现LLM生成了关于公司未来表现的有用叙述性见解。最后，我们基于GPT预测的交易策略比基于其他模型的策略产生了更高的夏普比率和阿尔法。

综合来看，我们的结果表明，LLM可能在决策过程中占据中心地位。

https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4835311



### 120

2024-05-25


宝玉
@dotey
这是给学生的建议，其实也适用于大多数想学 AI 的人，归根结底，就是要动手实践，只有亲手试过了才能学得会，就像骑车游泳，看再多视频你也学不会的！

清单如下：
1. 试用不同的大语言模型（LLM）
2. 创建一个 AI 智能体
3. 了解目前 LLM 和 AI 的局限性
4. 创建一个简单的RAG系统
5. 微调一个LLM

这些任务相对简单，理论上来说可以很快上手。



### 121

2024-05-25

Ethan Mollick
@emollick
👀This is a paper a lot of people have been waiting for: yes GPT-4 can help pick stocks, beating humans and other machine learning models trained for finance. The advantage is that it understands human narratives

Also read the paragraph in the screenshot. https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4835311



### 122

2024-05-25

歸藏(guizang.ai)
@op7418
给普通人的26条提示工程策略：

1、与LLM交流不需要礼貌，所以无需添加“请”、“如果你不介意”、“谢谢”、“我想”等短语，直接切入主题。

2、在提示中整合预期的受众，例如，受众是该领域的专家。

3、将复杂任务分解为一系列更简单的提示，进行互动对话。

4、使用肯定指令，例如“做...”，避免使用负面语言如“不要...”。

5、当你需要对一个主题、想法或任何信息有更深入的理解时，可以使用以下提示：
用简单的术语解释[插入具体主题]。
像对11岁的孩子解释一样对我解释。
像对[领域]的初学者解释一样对我解释。
用简单的英语写[文章/文本/段落]，就像你在向一个5岁的孩子解释一样。

6、添加“我要给出$xxx的小费以获得更好的解决方案！”

7、实施示例驱动的提示（使用少量示例提示）。

8、在格式化你的提示时，以‘###Instruction###’开头，然后是‘###Example###’或‘###Question###’（如果相关）。随后，呈现你的内容。使用一个或多个换行符来分隔指令、示例、问题、上下文和输入数据。

9、包含以下短语：“你的任务是...”和“你必须...”。

10、包含以下短语：“你将受到惩罚”。

11、在提示中使用短语“以自然、人类化的方式回答一个问题”。

12、使用引导词，例如“逐步思考”。

13、在你的提示中添加以下短语：“确保你的回答是公正的，不依赖于刻板印象”。

14、通过提问让模型从你这里获取足够的信息，以提供所需的输出（例如，“从现在起，我希望你问我问题，以便...”。

15、如果你想了解一个具体的主题或想法或任何信息，并且你想测试你的理解，可以使用以下提示：“教我[任何理论/主题/规则名称]，并包含一个测试，但不要给我答案，然后告诉我当我回答时是否正确”。

16、为大语言模型分配角色。

17、使用分隔符。

18、在一个提示中多次重复某个特定的词或短语。

19、将思维链与少量示例提示相结合。

20、使用输出引导词，即通过以期望输出的开始来结束你的提示。利用输出引导词，通过以预期响应的开始来结束你的提示。

21、要写一篇详细的文章/文本/段落/文章或任何类型的文本：“为我写一篇关于[主题]的详细[文章/文本/段落]，详细添加所有必要的信息”。

22、要在不改变风格的情况下更正/更改特定文本：“尝试修订用户发送的每段文字。你应该只改进用户的语法和词汇，并确保它听起来自然。你不应该改变写作风格，例如将正式段落变成随意段落”。

23、当你有一个可能在不同文件中的复杂编码提示时：“从现在起，每当你生成跨多个文件的代码时，生成一个[编程语言]脚本，可以运行该脚本以自动创建指定的文件或对现有文件进行更改以插入生成的代码。[你的问题]”。

24、当你想要使用特定的单词、短语或句子来启动或继续文本时，使用以下提示：“我为你提供了开始[歌曲歌词/故事/段落/文章...]的开头：[插入歌词/单词/句子]。根据提供的单词完成它。保持一致的流动性”。

25、明确说明模型必须遵循的要求，以生成内容，包括关键词、规定、提示或指令。

26、要写任何文本，如文章或段落，目的是与提供的样本相似，包括以下指示：“请根据提供的段落/标题/文本/文章/答案使用相同的语言”。


### 123

2024-05-25

歸藏(guizang.ai)
@op7418
杨立坤说现在的LLM不可能拥有类似人类的智能，他预测叫“目标驱动”，的架构可以完成这个目标。

这个系统可能会有以下特性：

理解物理世界
有持久的记忆
能够推理
能够计划，或许是分层次的计划 

这四个特性是智能行为所必需的，人类和许多动物都表现出了这些特性。



### 124

2024-05-25


宝玉
@dotey
\#AI开源项目推荐：Fuji-Web

借助 GPT-4V 这样的多模态模型，与开放网络中的网站交互，完成用户的各项指令，这一直是一项很有挑战的任务，前前后后也有很多类似产品，以前浙江大学、腾讯 AI 实验室和西湖大学发过一篇论文：《WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models》 https://x.com/dotey/status/1751388813237141542，新出的这款 Fuji-Web 成功率相对 WebVoyager 还要高一些。

项目地址：https://github.com/normal-computing/fuji-web

以下是项目介绍：

AI 智能体正在彻底改变我们与计算机和数字世界的互动方式。随着大语言模型 (LLMs) 的最新发展，我们相信在不久的将来，AI 智能体将成为功能强大的个人助手，不仅能简化我们的日常任务，还能改变我们的工作方式，让世界对每个人都更加友好和易于接触。

在我们为一些最敏感的工业和先进制造领域开发可靠的AI伙伴时，我们推出并开源了Fuji-Web，这是一款利用多模态AI重新定义网络交互的工具。

Fuji-Web 是一个智能AI助手，它能够理解用户的意图，自动浏览网站，并在执行任务的同时解释每一步操作。这使得用户可以通过输入或语音命令来完成复杂的在线任务，无论是在线购物还是发布社交媒体动态。

Fuji-Web 利用计算机视觉、DOM 感知和语义HTML理解，专注于网页上的重要元素，同时过滤掉无关信息。

我们将Fuji-Web的现实任务完成能力与WebVoyager进行了比较，使用它们提出的基准测试在7个网站上进行了测试。

结果显示，Fuji-Web在大多数网站上的表现优于WebVoyager和GPT-4。成功率从60.4%到86.0%不等，而WebVoyager的成功率为51.2%到76.7%，GPT-4的成功率则为9.5%到60.5%。


### 125

2024-05-26

宝玉
@dotey
Google AI Overview的尴尬在于：以前责任可以甩锅给检索出来的网站，现在Google要自己承担虚假信息和错误信息的责任，哪怕是AI生成的；另外一点就是以前和网站是共生共赢的关系，现在截流了网站的流量，用户直接从AI拿结果，网站变成了纯供给，很难被引流



### 126

2024-05-26

宝玉
@dotey
以前在 Swift 上的 STT 解决方案都是用 Whisper.cpp，其实 WhisperKit 更原生一些，并非 Whisper.cpp 套壳，而是自己实现了编码和解码，支持 CPU/GPU/Neural Engine 性能很好，另外比 Whisper.CPP 或者其他方案强的一点就是它支持 VAD，能过滤掉音频中的空白部分，这样时间戳更准。

---

argmax
@argmaxinc
WhisperKit-0.7.0 is out!
Single file inference is several times faster! The demo below is running distil-whisper large-v3 at 300 tok/s and transcribes 101 seconds of audio in 1 second on an M2 Ultra Mac Studio. Details 🧵

Code (MIT): https://github.com/argmaxinc/WhisperKit
Demo Audio Input: https://youtube.com/watch?v=wupToqz1e2g
Demo App: https://testflight.apple.com/join/LPVOyJZW (TestFlight update under review)

### 127

2024-05-26

Xiao Tan
@tvytlx
分享下我这一年多独立开发的故事，纯粹为了交朋友，人跟人很不一样，能有机会理解，能有共鸣，咱就不孤独

第一个赚到钱的是英语网站。那时候ChatGPT 刚出来，我想到它可以接上语音变成AI口语老师，很兴奋，所以跟朋友讲了，拉他一块写代码，但写的太慢了，因为得上班，士气受损，后面不了了之。两个月后我无意中刷B站，看到一个哥们做了个跟我想法差不多的，但是他做的别人都用不了，我心想我的方案更直接，于是不管了，自己一鼓作气一个晚上做了一个简陋的版本，发了出来

爆了

视频爆了，接着网站第一天也刷爆了，后面加了一个登陆和付费，结果收了一晚上钱。第一次赚到工资以外的钱，而且两三天就超过了我一个月的工资，我白天吃饭跟同事讲，她们很平静，我心想……AI都要改变世界了，你们怎么都不激动……😂😂

后面几个月有一些找上门的生意
- 某专门投教育的投资人，聊了一次，没有后文
- 培训机构团队版账号，估计也是来咨询的，没有后文
- 英语学习机老板要个oem内置版，这个算最靠谱的生意，但是价格没谈好，老板觉得很简单很便宜……但那时候token价格还很贵我就实话实说，可能是我没有啥生意头脑……

对于这个项目，我后面的决策是自己把这个网站好好做一下，服务好现在的用户就行。可惜没有想象中顺利，做的功能用户都用的很少。

我渐渐意识到，当时还是Sam Altman赏的饭。如果回过头来，重新决策或者改进，我会怎么做呢？可以线下找我聊，这里写了篇幅太长了。

第二次赚到钱的是http://drawing.pics，这个算是第一次做个客户端，那会我在看61 
@liuyi0922
 的早期博客还是文字访谈，有个印象很深的他说不做带后端的，我揣摩了好久，因为AI英语项目scope太大了，我觉得不是这个赛道不好，是我不配😂所以心里琢磨着做个纯本地的客户端试试，后面还有幸跟61哥线上聊了一下，很开心。说回drawingpics，当时有人做了一个在线版的，我看了很有意思，并且我觉得我可以做出离线版的，而且lcm加速只要4步就出结果，为啥不在本地跑呢，刚好我又很熟悉Python+之前写记账软件积累了一个electron模板，我可以专注于实现产品。当时一周卖了一百个license，而且留存比我的英语网站要好。现在新版我重写了一遍，这就是为什么我最近半年没怎么发东西，因为我在憋这个新版……

回顾一年多开发，我整体收入还是没有上班多。而且独立开发进的越深，发现可以提高的越多，很多原理还没弄懂，所以觉得我依然还在门外。

这是我这两个项目赚到钱的方式，毫无保留的分享了，我不上班最喜欢的一点就是不用遮遮掩掩，可以brutally honest 。

下半年不想写那么多代码，想出去走走，精神世界需要流动一下，也欢迎感兴趣的推友约我聊天～



### 128

2024-05-26



歸藏(guizang.ai)
@op7418
补充一下图像领域的类似建议：

1.尝试使用Web UI加载不同模型和控制手段生成图像。
2.尝试接触ComfyUI并自己搭建简单的图像工作流。
3.将图像生成和LLM进行结合。
4.接触并探索一些复杂的视频生成或者转绘流程。
5.尝试训练一个自己的 Lora 或者 Checkpoint 图像模型。


### 129

2024-05-26

九原客
@9hills
通过 Post-pretrain 的行业大模型可能是一个伪命题。

最近翻阅了 10+ 篇相关论文，结合我们一些实例，发现所谓的行业模型没什么用。

通用模型+ RAG + Prompt 工程 能够做到同样的事情，甚至效果还超出了行业模型。

不过这个地方实在是概念污染太严重，一帮人有意无意的去洗脑客户。



### 130

2024-05-26



歸藏(guizang.ai)
@op7418
RAG未来发展方向的预测：会从RAG从问答系统向报告生成工具的转变。

评论区Nick Dobos说的也有道理可能跟内容结构有关跟RAG技术本身无关。

AI生成的内容的阅读体验和信息传达效率将会越来越重要，Arc Sreach那个搜索结果页做得好也是因为这个。


### 131

2024-05-26


宝玉
@dotey
当猿猴开始制作使用工具完成任务，就进化成了人；当 LLM 学会使用工具或者制作工具（比如写代码执行），就进化成了智能体（Agent）。


爬虫是抓取网页的工具
浏览器自动化脚本是操作浏览器的工具
智能体是能根据需要调用合适工具来完成特定任务

举例来说一个资料检索智能体，当我要查询某个资料，它可以根据需要去自动操作网页打开 Google 搜索找到需要的结果，那它就是一个合格的资料检索智能体。



### 132

2024-05-27


歸藏(guizang.ai)
@op7418
卧槽，期待的东西终于来了，AnyNode 这个 ComfyUI 节点牛哇。

你可以输入提示词让 LLM 帮你编写任何功能的节点。

AnyNode 会根据你的要求编写一个 Python 函数，然后把这个节点链接到你要求的输出格式节点就行。

比如作者案例里面就通过提示词实现了文本总结节点、颜色通道调整节点，Ins 滤镜节点，甚至一个边缘检测器。



### 133

2024-05-27

宝玉
@dotey
《大模型的扑克牌：独家内幕故事》
https://mp.weixin.qq.com/s/YfFN7yjbyyPIy3MC89HdXA

作者：张小珺

- 本文首发于腾讯新闻 -

中国投资圈一度熙熙攘攘的德州扑克牌局，忽然沉寂下去。

“反正我们圈子都不太打牌。”金沙江创投主管合伙人朱啸虎说，他和其他投资人的聚会已经从打德扑换成了品红酒，聊聊对行业和项目的新看法，也聊聊什么二级市场的股票比较好。

现实中的牌局冷清了，这些牌局上的精明老手却将他们的手伸向另一端。他们在中国大模型产业的局上，打起了一副沉默的牌。

ChatGPT问世后，于2023年腾空而起的中国大模型产业，呈现出了许多你从未见过的奇异景观：一家公司首轮对外融资的估值就已高达10亿美元，刚上场没有任何产品就跻身独角兽俱乐部；从第一笔融资起，一群举足轻重的大人物急急忙忙“抱团”集体下注；不管是红杉还是高瓴，阿里还是腾讯，这些曾在互联网的牌桌上互为排斥的投资方，这次欣然坐进一个股东会——你会看到，中国创投的“打牌风格”在过去一两年已然巨变。

“这是典型的Club Deal。”一位一线投资机构的合伙人解释称。所谓“Club Deal”是指一组投资者组成一个“俱乐部”（club），投资者通常是私募股权基金、机构投资者或高净值个人，他们联合投资于同一项目中。这类方式有助于分散风险，并凑齐更大资本盘——通俗来讲，就是，“一堆有头有脸的熟人，凑了一堆碎银子”。

“这是典型的FOMO嘛，就是Fear of Missing Out，怕错过。”朱啸虎曾说道。这位曾经打德州以“手很紧、入场比例很低”为风格的投资人，一家中国大模型公司也没有投。他评价道：“因为大家都不确定，所以大家Club Deal。”

一方面，移动互联网的造富神话使一群人富裕，这些高净值个人有本钱，中国VC手上的现金也不少；而另一方面，由于对AGI前景的迷惘，所有人又都缺乏放手一搏的胆量，极少人愿意砸大钱，更没有玩家筹码全下、All In。“说实话中国VC的钱不少的，主要是大家手都很紧。”一位投资机构的管理合伙人称。于是“我先放一点钱进去在里面看看”成了绝大多数人的共同选择。

入局者多多少少怀抱着这样一种心态——数位不愿具名的中国投资机构创始/管理合伙人，用了近乎一致的表达来形容牌局中人的心理——“大家都想看看牌。”他们说。

本文访谈了20位中国大模型局中的关键创业者、投资人与生态方，记录过去一年最完整的大模型资本内幕。

开局
就在一年多以前，一位超级明星人物的重量级入局，令整场牌局一刹那热闹起来。

2023年2月，从美团退休两年的王慧文（美团联合创始人）突然宣布重返江湖——成立一家叫光年之外，以做“中国OpenAI”为使命的通用人工智能（AGI）公司。

事实上，在王慧文宣布创业之前的几天，他的想法曾一度剧烈跳跃。“他那段时间每天改变一次主意。”据彼时与他接触频繁的人士说，一开始，他是想拿5000万美元进行投资，摆在他面前有几种可能性：

一，只做投资人，5000万美金分散投给5个项目；二，他既亲自参与又做投资人，5000万美金拆开，3000万美元给自己买一张“船票”，2000万美元为其他人买两张“船票”，每人各投1000万美元。

在投资人的撮合下，王慧文与同样处于狂热情绪、也宣称要做“中国OpenAI”的李志飞（出门问问创始人兼CEO）相约吃了一顿晚餐，席间充满了含蓄的试探。饭桌上的人想看看，王慧文为自己买一张“豪华仓船票”的同时，愿不愿意给这位AI背景的前Google科学家，也买一张。但很快，这些不了了之。

王慧文做出一个出乎很多人意料的决定：他不仅要亲自下场，还要用5000万美元All In自己。

“老王给自己买了一张‘全家票’。”一位同时接近王慧文和李志飞的人士在当时说，“老王说，全部放在自己身上，最放心。”

另一位接近王慧文的人士说道：“老王最开始想投，后来他说投可能不行，聊了一圈觉得得自己做。自己做也不一定要当CEO。但显然老王不当CEO，别人当CEO压力很大。”因此，光年之外的方案是，王慧文是CEO，对外寻找技术合伙人。

创始人以2亿美元估值作价，个人出资5000万美元——以德扑看，坐“大盲”（Big Blind）位的王慧文一把抬高了所有人的下注筹码。这之后，5000万美元被认定为大模型公司起步标配。后面的人想来参与牌局，得掏出与之相当的价码。

然而，这个资金量级不但没有吓退来者，反而让更多人闻风赶来。

光年之外随即启动对外融资，这时，一群“有头有脸的熟悉脸孔”一起上了牌桌。

“当时很夸张。创始人一般是一家一家见投资机构，老王是面向所有有意向、发了Offer的投资人，统一做了一次路演。后面基本像一个过程。”一位接近交易的知情人士说。这场大佬云集的“统一路演”，就在位于北京搜狐网络大厦的光年之外办公室进行。

源码资本创始合伙人曹毅是最果决下注的。他在王慧文尚且没下决心时就承诺，只要他入局，愿意拿出基金相当比例的资金额度，只为押注他这个人。于是，源码以6000万美元成为光年之外这轮领投方。

还有10多家机构和个人也参与本轮融资，可谓全明星阵容：包括但不限于红杉中国、五源资本、腾讯、真格基金、今日资本、顺为资本和宿华（快手联合创始人）、王兴（美团创始人兼CEO）等个人投资者。由于各家机构都是一、二把手出马谈判，如红杉中国沈南鹏、今日资本徐新、真格基金戴雨森，中国大模型资本局亦被称作“一把手工程”，场面颇隆重。

其实，这次出手违背了一些投资人的天然直觉。比方说，投资人看重创始团队缔结的牢固程度，而王慧文和与之组队的技术合伙人袁进辉、曹越，从前并不相熟；作为技术型创业，投资人往往也会注重创始人的技术背景，而王慧文不懂大语言模型技术；更为紧要的是，这些江湖老手深谙一条法则：“历史上含着金汤勺出生的项目，没有几个是成功的。”

虽然眼前这个项目正含着一把闪耀无比的汤勺，但此时此刻，他们抛开了这些念头。和曹毅的选择一样，他们赌注的是这个人——作为一名超级产品经理、连续创业者和一家市值最高达万亿港币企业的二号位，王慧文实在太富有诱惑力了，这点足以令所有人安心。

“当时融资，光年之外要好太多了，是最快估值到10亿美元的，而且都是投资机构一投一大笔，几千万美元这种。”一位接近多家大模型公司融资交易的人士回忆道，“就像源码投了几千万美元，宿华投了几千万美元，都是那种All In的姿态。其他公司应该没这样的。小川那边刚开始几百万美元都拿，原来没有很大的机构。”

据多位知情人士，由于各方的热情极为高涨，首轮对外融资总意向认购金高达5亿美元。但王慧文没要那么多，他将融资额控制在了约3亿美元。

就这样，光年之外在没有完整技术方案和任何产品的情况下，资金迅速筹措完毕，投后估值一把冲破10亿美金。

此刻，还有许多也有志于中国AGI事业的创始人正对标着光年之外估值，到市场上募集资金。不管是与王慧文同一时期起步的月之暗面创始人兼CEO杨植麟，还是比他晚了一步入场的百川智能创始人兼CEO王小川，他们的开局都不像光年之外那么顺遂。其中一个原因是，“王慧文融了太多钱”。

“你得接受，这是一个现实。”王小川说。他将王慧文的开局优势，部分归结到后者在商业上的老练——“美团是从死人堆爬出来的公司。”——但战术并非赢面的最关键。对于这些“久经沙场”的交易老手，他们愿意在风险世界中承受风险、第一时间下注，根本原因有且只有一个：王慧文帮更多人赚到过钱，而这些人还想搏一把大的。

“很多人是想买张门票。”一位场上的投资人说。

不仅在资本层面，王慧文凭借个人影响力，第一时间也笼络了优渥的算力和人才。资本、人才和算力，是大模型创业三要素（算力也取决于资本）。据透露，彼时光年之外已搞定4000余张卡，是同期创业公司最充足的。

倘若将王慧文视作场上“打牌的人之一”，将光年之外视作他拿到的一对“手牌”，将融资额视作“筹码”。牌手王慧文开局拿了最大一对“手牌”和很深的“筹码”。

“2月到3月，很多人都在发愁融资，光年之外这边很快就搞定了。”一位接近光年之外的人士透露称，然而，当生产要素齐备，“就要开始工作了”，令所有人始料未及的是——“他反而出状况了”。

转牌
德州扑克是概率游戏，手牌大也有可能沦为输家，手牌小也有翻盘几率。

在很多人的日后回忆中，王慧文毫无预兆的“疑似抑郁”，都源于他太负责了。一位员工记得，自2023年2月，在光年之外组建最初的三个月，王慧文一直处于亢奋又疲劳的工作状态。这名亿万富翁，住在距公司不远的自如，每天早晨到公司最早，晚上离开最晚，周末也几乎不回家，开会到深夜十一二点——人们又一次看见了他创办美团的拼尽全力，不同的是，“可能身体吃不消了”。

时间抵达5月。光年之外的资本、人和卡陆续就位，只是，当创始人把目光转向具体的大模型业务，隐患真正浮现。

王慧文提出大模型技术和产品并进的“双轮驱动”战略。他们的分工是，王慧文带产品团队，联合创始人袁进辉、曹越带技术团队。虽然技术问题有联创分担，但是，“作为一号位，老王要形成高质量的决策”。而关于大模型的关键决策个个艰涩，又个个价值连城。行业外的人需要在极短时间补充大量技术知识才能形成一个有效决议，而对于业内资深的人，可能是听从本能和直觉。

比如，“几个月之后，算力市场是什么行情？租还是自建算力更合理？”这类决策试错成本极昂贵，有可能，“一下子就投出去十个亿，融资一半就出去了”。“老王又很负责”，这些都给了他压力。

综合多位光年之外的人士复盘，王慧文很靠谱，他想把这件事想清楚，但到了科研层，远远超出他的能力圈。大模型一个决策就要花至少1亿美金，而他不能确认这条路是正确的。“对老王来讲，他无法消解这个压力。”一名人士说，“跟互联网不一样，不会有人怀疑做滴滴做不出来，或者做拼多多做不出来，最多只是说我运营不好。但AI有很多科研属性，就会出现——我不知道这件事怎么做。”

从内部看，5月，他开始出现晚上睡不着、白天难以集中注意力的症状。“也没有特别的一件事导致，只能说，干具体的业务和之前的兴奋状态不一样。要一步步地把具体技术搞扎实，把产品搞出来，这中间又有无穷的问题。”还有一点是团队管理。“这些大模型公司都有这样的问题，这么快组建团队，100人掺在一起，以前这100人也没在一起工作过。老王又是管理比较细的人。”上述员工称。

6月，王慧文“疑似抑郁”的消息传出。国产大模型之间剑拔弩张，“有的公司直接冲到光年之外办公室挖人”。正当外界错愕时分，美团宣布以约20.65亿元人民币价格收购光年之外。

“那个是一瞬间的事。”一位光年之外的投资方说，从他们得知CEO生病到退钱，“整个过程应该也就一天”。故事的结局大家已经熟悉：创业伙伴王兴救场，通过收购光年之外把投资人的钱退回了他们的口袋。

如果说王慧文高调加入战局，凭借一人之手推高了中国大模型创业公司的整体估值和融资额；那么他的离开，又间接促进了其他几家公司的融资进程。

前述了解多家大模型公司融资的人士评价称：“光年突然没了，其他大模型公司马上就有钱了——投资机构总要选——现在，突然少了一个强劲的竞争对手。”

2023年中光年之外的退出，成为中国大模型牌局里截至目前，最令人惊诧的一次“转牌”。场上局势快速发生变化，仅仅半年后，牌面格局就大不一样。

一位光年之外人士事后感慨说：“老王的一个idea，改变了很多人的轨迹。”

玩家
若将创业选手比作德扑玩家。现在，牌局之上有6名“玩家”。他们每个背后都站着一众中国对通用人工智能野心勃勃的机构与个人，由他们提供这场牌局的“筹码”。

场上6家大模型创业公司是：1、张鹏任CEO，唐杰任首席科学家的智谱AI，2、闫俊杰创立的Minimax，3、杨植麟创立的月之暗面（Moonshot AI），4、王小川创立的百川智能，5、姜大昕出任CEO的阶跃星辰，6、李开复创立的零一万物。（先后顺序按公司成立时间）

与光年之外在同一时段起步的有两位：一位是AI研究员出身的90后科学家杨植麟，另一位是由搜狐孵化并分拆的搜狗前CEO王小川。前者于2023年3月创立月之暗面，后者于4月携搜狗班底宣布创立百川智能。很快，王小川就被锁定为王慧文最直接的对手。

王小川也是企业家出身，与王慧文年纪相当，都毕业于清华，又都在中国互联网的战场冲锋——相似性增添了两个人竞技的味道。从结果看，中国明星基金彼时几乎都把筹码押给了光年之外。

正当光年之外以10亿美元融资时，王小川刚以5亿美金估值拿到5000万美元开局的启动资金。“百川第一轮没有什么机构投资者，都是个人。”一名知情人称，这笔资金来源是王小川和他的朋友圈，如陈大年（盛大集团联合创始人）、张邦鑫（好未来创始人兼CEO）——朋友圈为他提供了上场筹码。

“去年是快速rush（行动）的一个状态。”王小川复盘道，由于入局较晚，“我们在人才争夺、资金争夺里，肯定是偏晚的一个”。所以，入场时，他采取了商战中的“跟随策略”。“不高级。”他说，“至少在商业上有一个简单逻辑——如果对手比你成熟，你跟着学就行了；但在你的优势领域，你发挥得更好。”在他看来，自己的主战场是技术，“本质上美团的成功不是技术推动”。

据王小川透露：“在第一轮有一线投资基金愿意投我们，甚至觉得我们价格很好，但因为我们对标学习拿朋友圈的钱，就没有去拿VC的钱。我的选择是比较简单，就是面向入场，先follow。”

在筹集资金的步伐上，百川比光年之外慢了一步。它于2023年10月才完成第二笔3亿美元融资，依然少见VC身影——不过这次，它呈现了“战投为大”的特征——投资方包含十多位，腾讯、阿里、雷军系的小米/金山/顺为资本、好未来这些战略资方结伴而来，此外还有清华控股、深创投和红点中国等。王小川谈到，不同于王慧文通过美团上市帮VC挣得盆满钵满，他真正赚过钱的恰恰是大企业。“我给赚过钱的公司是搜狐、阿里，包括又把搜狗卖给了腾讯。”

所以，资本衡量这两位企业家的标准非常简单：谁帮更多人赚过更巨额钞票？

就在王小川与王慧文正面交锋之际，杨植麟创立的月之暗面仅仅是一个弥漫着“非共识”的“水下项目”，估值也最便宜。

杨植麟毕业于清华和卡耐基梅隆大学，学术和工作很多与大语言模型技术相关。他的风格更偏硅谷，公司只做to C产品（Kimi智能助手）。虽然杨在AI圈有些名气，但与一众知名企业家、科学家、高管相比，又显得籍籍无名。

事实上，一开始，很多人更愿意把他视作CTO式的人才——2023年初，有人拉着杨植麟与王慧文聊过，看杨是否愿意出任后者的技术合伙人，他没有同意。

“在那个时间点，觉得他适合是非共识。”一名月之暗面的投资人说，更普遍的观点是，杨植麟年轻，上一家创业公司又不十分有名，“而且很多人觉得在中国，你技术好，有用吗”？

“我们是把他从水下挖出来的。”另一位月之暗面的投资人说，“当时在这个圈子聊，会时不时听到他（杨植麟）——有的人说他挺厉害的，有的人稍微有点不服气。听到第三次的时候，我觉得这个人很重要。”

在杨植麟的项目上，嗅觉最敏锐的当数红杉中国，它是杨植麟上一家创业公司股东。2023年初，红杉就意识到杨也许是适合大模型赛场的创业人选，双方一拍即合。但在究竟是红杉一家投还是多家投的问题上，几经波折。

接近该笔交易的人士称：“最开始红杉报了大约1亿美金估值，但植麟发现1亿美元融3000万美元不够，稀释30%没法弄了，后来提高到比如2亿美金估值。”交易已经准备close（关闭）了。

没想到的是，今日资本突然“杀”进来。

“他们‘抢地’，很凶猛，估值越抬越高。”多位知情人士道，他们一举把估值推高至3亿美元。为了抢交易，今日资本试图说服杨植麟：你应该多拿，你应该都拿。又过了几周，“砺思和FunPlus（游戏公司趣加）是最后一刻进的第一轮”。

“今日提高了所有人的估值，除了红杉。”数名知情人透露。最终，这笔交易分两次以不同价格交割，红杉先以2亿美元估值，其他人再以3亿美元估值，总计，月之暗面完成6000万美元开局融资。所以，就在光年之外一上场就踹开独角兽大门、百川智能以5亿美元估值实施跟进计划时，月之暗面以2到3亿美元估值拿到了上场筹码。

杨植麟回忆道，对他们来说，这轮融资的关键是时间窗口。2023年2月，公司尚未成立，他在美国调研时，就启动了第一笔融资。“如果delay（延迟）到4月，基本没机会了，真正窗口就是一个月。”他这时做了一笔演算，“算完觉得至少要在几个月内拿到1亿美元”。

刨除三位同期上场的选手，Minimax和智谱AI是成立更早的大模型公司。

智谱AI可谓“根正苗红”，2019年脱胎于清华大学计算机系知识工程实验室，独立创业。早期投资方有启明创投和君联资本。总体而言，智谱AI偏人民币风格。张鹏称，大模型给了这代AI公司一个机会：做“技术平台化公司”，而非“顶天立地的垂直公司”。

站在2023年初始，唯一能在融资上与光年之外抗衡的是Minimax。这家成立于2021年、核心班底来自商汤的初创企业，这时已有相对成熟的技术和产品，并且来到第三轮融资。

闫俊杰出生于1989年，毕业于中科院，在商汤从实习生做起，一路擢升副总裁。他曾是商汤智慧城市事业群CTO，该业务为公司重要收入来源之一。“他是第一个和我讲Foundation Model（基础模型）的创业者。”云启资本合伙人、Minimax天使投资人陈昱说，双方早在2021年1月接触。“他们现在有这么一个‘锤子’（Foundation Model），他们明白公司要长大，是要把合适的‘钉子’找到。”

在他看来，闫俊杰是“very rounded（全面）的一个人”。陈昱称，在最早与闫的接触中，他们不但讨论技术，也考虑商业化——讨论过数字人、智慧城市和在博物馆做三维重建的项目。

据其多位股东透露，Minimax早前已完成两轮融资：第一轮是2021年国庆前后，它以2亿美金估值完成2000万美元融资，投资方是高瓴、米哈游、IDG和云启资本。“当时他们见了张磊（高瓴创始人兼CEO）和李良（高瓴投资创始合伙人），就直接拍了。高瓴定的价，其他人只能follow。”

第二轮是半年后，2022年5月，它又以5亿美金估值完成5000万美元融资，投资方是上述老股东加明势资本。

所以，在ChatGPT点燃全球热潮以后，Minimax很快就成为中国第二家跻身独角兽阵列的选手。2022年底到2023年4月，它以大约9亿美元投前估值迅速筹集2亿多美金，投后估值近12亿美元。除了老股东，在第三轮融资中，列队入场的投资者有绿洲资本、腾讯、小红书和顺为资本。

相对月之暗面偏to C，智谱AI偏to B，Minimax更像“混合派”——既做很多to C产品，又做to B；既做国内，又做海外。事实上，Minimax的产品经历过几次调整：从最开始的数字人到AI社交产品Glow，而后它作为App工厂，推出了海螺AI、Talkie、星野等产品。一位老股东对其发展流露出几分惊讶之色，他的表达是：“Surprisingly good（出乎意料地好）。”

除此外，另两位选手是阶跃星辰和零一万物，分别于2023年4月和5月成立。

截至2023上半年，6名“玩家”已全部就位。他们起步时间不一、创始人与公司基因迥异，但他们都赶上了资本愿意密集投入中国大模型事业的黄金时间。当然了，这很大一部分得益于资本们前所未有的恐惧——害怕错失技术变革的FOMO情绪；以及旺盛的贪婪欲——AI或许是比移动互联网更磅礴的商业巨浪呢。比他们晚来的人，这样的时间窗口和心理窗口双双消失殆尽。

然而，此刻中国大模型牌桌上，6名“玩家”胜率和赔率还相当模糊。

“大家都看不清楚。”一位一线投资机构创始合伙人说，于是，许多投资人做出了十分一致的选择：“每个人放一千万美金到几千万美金，看个牌。”

（1/2）

宝玉
@dotey
下注
大模型给中国带来了一场极特殊的资本盛宴。

一方面，它诞生于一系列的逼仄与夹缝中——更紧张的国际关系，更有限的资金，更狭窄的退出通路，更审慎的投手，更稀少的创业者；另一方面，它却支撑着一个足够宏伟的科技愿景。于是，场上的人兴奋又脆弱。

兴奋在于，这或许是当下唯一符合美元VC审美的资本故事。“谢天谢地，不然我真觉得没事干了。”一名投资者这么形容AI浪潮爆发后的心情。“从自动驾驶和O2O以后，很少有这种单轮大几亿美元量级的融资。”另一名投资者称。

而脆弱则在于，大模型公司面临的风险实在太大，一旦科研宣告失败，又或巨头碾压，这么多钱砸下去甚至连水花都看不见。

在此情境下，VC群体性心态转变了。一位基金合伙人这么描述他们的心理：“大家想投，又担心投多了打水漂”，于是做法就变成：和创业者保持密切联系，投一点钱、先看看牌。“很多基金想，我只能投一个1亿美金，所以等等看。宁可贵一点投，我要一个确定性。”——这就导致，在很长一段时间，投资机构以一种不可思议的“凑份子”的态度、“你一千万，我一千万，他一千万”、满怀踌躇地押下筹码。

即便心态有相似处，但各机构出手的时机、策略和价码，大不相同。

据多位核心投资人称，红杉是VC中最凶猛的。除了光年之外，它在如今场上的6家中下注4家，包括月之暗面、智谱AI、Minimax和阶跃星辰。

红杉出手集中在2023上半年。“他们是不能miss的打法。”业界将此投资风格归类为“赛道覆盖”。彼时，红杉创始及执行合伙人沈南鹏会事必躬亲，亲自约见大模型创业者。就在其他基金还在几家初创公司中摇摆时，红杉在多个创业局里放了钱。

就像上文说的那样，红杉顺理成章地成了月之暗面天使投资人；但在Minimax的局上，它进入得则没那么容易——这家公司的董事会中，坐着红杉的老对手，高瓴。

“高瓴不是不让它进，只是不想让它这么早进。”一位接近Minimax的人士说。戏剧化的是，红杉的入局源于一起意外。

2023年中，字节跳动上场寻觅大模型标的，它此时正在思考投资的可能性。“它当时考虑了两家，一个是Minimax，一个是阶跃星辰。”随后，Minimax以投前约16亿美元估值，为字节单独开了一轮，这本来是Minimax的第四轮融资。“至少我们见到SPA（股份认购协议）了。”一位Minimax的投资人说。但没想到的是，字节临场反悔了——他们决定“要么自己做，要么收购一家公司”。

“第四轮是字节毁了SPA，红杉就顶上了。”他说。

所以，红杉以相较昂贵的价格挤进了Minimax的局。“那个阶段很多是看不清的。谁也不能在那个时间点说，谁谁一定行，只能做当下最好的选择。当每种可能性都有可能成，你只能赌可能性最高的那几种。”一位场上人士分析，“万一Minimax好呢？”

从内部看，红杉覆盖型策略与其管理机制有关。他们投资人人数多，投每个项目需要一名合伙人sponsor（支持）。在红杉，4个项目分散记在不同合伙人及团队名下——据多名接近红杉的人士称，月之暗面是郑庆生，智谱AI是郭山汕，MiniMax是郑庆生，阶跃星辰是孙谦——“Neo（沈南鹏）兼听则明。”一位业内人士道。

实际上，虽然很多机构都想“看牌”，而各家能负担得起的“看牌费”截然不同。

谈到“看牌费用”，一名基金的合伙人算了一笔账：假设红杉（美元）手上有大约9个billion（90亿美金），1亿美金约等于它基金规模1%，“所以它给0.5个点、5000万美金看看牌是可以接受的”。而有的基金管理规模是几亿美元，这种情况下，“lost 1%，就是几百万美元，这是能承受的看牌费的极限”。从这个角度，这些机构的几百万美元大概等价值于红杉的1亿美元——口袋深浅决定了看牌费的多寡。

不过，与红杉实力相当的高瓴就没有采取“广撒网”策略，而是只出手了两家。其中，高瓴从天使轮重注Minimax，同时也在智谱AI里放了钱。

红杉与高瓴在投资策略的上反差，一部分或许取决于双方对市场终点的猜想不同——一位业内资深人士提出，中国大模型究竟会不会是一个赢者通吃的行业？

第一种可能是，会。若如此，无论如何不能错过，因为“一旦你错过，你基金的收益和别人天壤之别”。第二种可能是，不会，市场份额不集中。“这时候你是都投，还是投其中一两家，收益没有显著差异。赌中第一名的人收益可能比你多20%，仅此而已。”

“现在问题是，大家说不准是第一种还是第二种。”上述人士接着说，高瓴也许倾向于第二种——国内大模型公司尚且处于复制OpenAI阶段，“没什么妙招让他们一步登天”。

看完了中国VC“最深的两个口袋”，我们来看另一波基金。他们射程和口袋深浅各异，但都做出一个共同抉择：向更早期投、向最早期投。

“在大模型，投得好不如投得早。”一名大模型公司早期投资人称。（就连红杉、高瓴都阶段性采取了此策略。）

今日资本是使用该策略出手活跃但低调的一家基金，它接连下注了光年之外、月之暗面和智谱AI。其中，在光年之外和月之暗面上押注了第一轮。真格基金也押注了光年之外与月之暗面第一轮。值得一提的是，今日资本虽“筹码多”，但从2023下半年出于风险的权衡就收手了，再未加注任何一家大模型公司——“他们的指导思想是不投。”业内人士道。

“大模型投资，最佳活动窗口就一个月（2023年2月到3月），过了那个月估值迅速贵很多。”另一位早期投资人说，“这种长线的赛道（人工智能、自动驾驶），在第一年、第三年甚至第五年投都有风险，你还不如早早天使就投进去。”在他看来：“风险没有因为估值增长而发生本质变化——你早期放钱，是用更少的钱买到同样的筹码；在后面要花更多的钱买筹码，而风险没有降低。”

一级市场的交易者是高风险的承担者，他们时刻都在心里盘算胜率和赔率，据此选择出手时机与交易策略。

场上也有一些不同寻常的出手方式。由前红杉中国合伙人曹曦创立的砺思资本（Monolith），是一家成立仅两年的新锐机构。曹曦倾向于只选择一家最看好的公司下重注。

曹曦事后回忆道，2023年初，他拿到了几家初创大模型公司的投资机会。他的想法是，“先确保有资格上牌桌，再谈资金有限的情况下，该选哪个”。曹曦琢磨了整整一个月，做出一个在当时异常艰难的决定：在市场热情高涨时，他在几个明星项目里没有放钱。

接着，他找到偏年轻的杨植麟，接连投资了月之暗面一、二、三轮。到目前，这家新基金以约3800万美元的投资额，上升至月之暗面第二大VC机构股东（第一是红杉）。

投资与德扑具有相似性。两种活动中，“玩家”需要从手中的牌、场上有限的信息计算概率，和参与者的行为与心理博弈，随之做出下注决策。随着场上信息逐渐充分，筹码愈来愈重，“这不就像每一轮投资”？并且，“玩家”也需要管理筹码，合理分配，不能因为输掉一手牌，招致损失过大、功亏一篑。

在德州扑克游戏中，玩家会把德扑风格归纳为：紧凶 (Tight-Aggressive)、紧弱 (Tight-Passive)、松凶 (Loose-Aggressive)、松弱 (Loose-Passive)。曹曦表示自己德州打得不多，主要是为了交朋友，但很喜欢拿德州举例。如果是投资，他希望保持的风格“肯定是紧凶” ——“不投那么多，有一个觉得可能胜率高的，下比较重的注。”

游戏中，紧凶型玩家手牌选择严格，只玩高质量的起手牌，一旦决定进入游戏，会积极下注和加注寻求主动权。

不过，曹曦强调，投资是严肃的商业行为，以德州扑克比喻只是为了形象化的表达，便于理解。此外，这两者有一个根本性差异。“德州你扔掉的牌就扔掉了。投资你前面每一次fold掉的牌，后面还能买回来——你A轮没投，B轮可以投；B轮没投，C轮可以投。”他称，“所以，Swallow your ego（放下自我），错了就认，认了再上”。

此外，场上还有一些投资机构之前不愿出手，他们想等待更明朗的牌面。

比如，经纬创投2023年没有下注。数位接近经纬的人士称，他们考虑的是，放几千万美金看牌不是其喜欢的玩法，他们希望等局势更明确，笃定地赌一家——“在一家最后投5000万甚至更多”。经纬从自动驾驶赛道得出结论，应该先想清楚“谁是理想汽车”再出手，这样可以以一个本体企业为抓手覆盖产业链上下游。

不过，就在2024上半年，我们从多方独家了解到，经纬终于出手了——它把钱放在了Minimax上，“挺重注的”。

一上场就把筹码重注光年之外、领投该公司的源码资本，因为光年之外的退出而被动从牌局抽身。之后，它没有立即重新下注。也在2024上半年，源码把钱放在了月之暗面上。

新近准备出手的还有高榕创投，在持币观望1年多以后，它可能将把钱放在月之暗面上（交易尚未正式签署）。

一个有趣观察是，在这轮大模型浪潮中，积极出手的除了基金一号位，有许多80后投资人。他们或已晋升管理合伙人，或为合伙人。如，经纬王华东、云启陈昱、启明周志峰、砺思曹曦等。他们更具雄心，渴望凭借一场冒险，将投资生涯推向高峰。

然而，在场外，有一名颇特殊的投资人。他是这么评价自己的：“我现在很少打牌，所以我现在不太愿意看牌。像我手很紧，看牌都很谨慎哈哈哈。”

他评价同行道：“反正他们也无所谓，他们钱多，说实话。大家都是放点钱看看牌，都是这个心态。”

所以，朱啸虎丝毫不愿理会牌局的喧嚣，他既不看牌也不下注，摇摇头走掉了。

Club Deal
大模型产业一把改写了中国创投交易的游戏规则。

与硅谷VC“近乎全线miss大模型投资”、“大模型全是巨头支持”的景象不同，中国VC在过去一年和巨头一起积极出手，支持了国产大模型公司从0到1之路。他们愿意出手的原因很简单——“因为美国有对标。”拾象创始人兼CEO李广密说，“我们擅长解题。”

然而，在这场牌局上，“牌手”的出手风格呈现了清一色地转变。

这一方面受制于全球经济的低垂，更重要的是，AI耗费的资本量太过庞大——单笔融资高达数亿到数十亿，很大一部分要拿来做高风险的科学研究。所以，VC 过去“以小博大”，“从Early Stage（早期阶段）到Growth Stage（成长期阶段）击鼓传花式”的投资策略，失效了。

“最经典的VC逻辑是每个支票开500万美金以内，我开十个才5000万美金，虽然每个都有很高风险，但十个里头总有两三个成了，这就是一个巨大杠杆。”清流资本创始合伙人王梦秋说，“现在融AI的deal，因为我单个deal check size（支票规模）开得大，所以从第一天起就是Club Deal（俱乐部交易）。”这意味着，这些大模型公司，投资名录上不会只站着零星的一两位股东，而是跟着一大把——“大家一拥而上”，“每个人都在分散风险”。

资金的分布改变了牌局隐藏规则。“因为所有人的钱只够分散到几家，就会变成，一个项目本身在这个赛道的竞争对手就少，最后可能剩2-3家甚至只剩1家——所有人都不会觉得1家都成不了——那么，我有1/2、1/3的（胜出）机会。”王梦秋称。

于是你会看到，在大模型赛道上，涌现出6家创业公司展开角逐。对于他们每一家的融资结构，Club Deal现象都很显著。以融资额最高的月之暗面举例，它至今已完成三轮融资：

第一轮是2023年上半年，它以估值2到3亿美元，完成6000万美元融资，5名投资方联合出手：红杉中国、今日资本、真格基金、砺思资本和FunPlus。

第二轮是2023年下半年，它完成约2亿美元融资，投后估值约7亿美元。该轮有战投入场，美团龙珠、阿里和蚂蚁领投，跟投方众多，包括宿华、砺思资本、九安医疗、蓝驰创投、襄禾资本等。

这年底，月之暗面额外开了一小轮（相当于第二轮的+轮）。“进来了两家公司，五源和云九，是不多的钱。”一名知情人士称，他们彼时是持有“看牌”心态的投资者。

直到2023年末，月之暗面总计融资额不到3亿美元，在资本竞技中呈落后之势。春节期间，一起特殊时间点的超级交易帮他们扭转了战局。

2024年大年三十的夜晚，紧张的商业谈判持续到了最后几秒，这是月之暗面第三轮融资文件签署的最后期限。“因为老股东很多，大年初一00:00点左右才没有意见，那天算文件close day（交易日的结束）。”这时，月之暗面完成超8亿美元融资，阿里领投、砺思跟投，投后估值超25亿美元。不过，第三轮到这里没有结束。

“赶在过年前close的，只是这笔交易的一部分。”数位知情人透露，“它还有一个条款，接下来60天可以再拿2亿美金。”据了解，最终，该公司第三轮总计融资额略超10亿美元，是中国大模型迄今最高单笔筹资金；目前它正以投前30亿美元估值进行第四轮融资。

短短一年，这家公司从默默无闻中崛起，估值翻了15倍，从“筹码”最少的选手变成了最多的之一。

在场上，阿里巴巴是2024开年以来最大变量。我们结合多方了解到，月之暗面与阿里的谈判耗时很短。为了促成这笔交易，双方在交易上做了一些特殊设计：

1、阿里的投资额中，有一部分放在共管账号，用于购买阿里云服务；2、月之暗面创始团队有超级投票权（Super Vote）；3、阿里占据一席董事会席位，但在融资、并购等财务条款上，不具有一票否决权（Veto）——这意味着阿里不能阻止其他投资方进来。

此后，阿里的野心未止步于月之暗面。数天后，它进一步注资Minimax。这是Minimax的第五轮融资，它完成超6亿美元融资，其中阿里领投约4亿美元，投后估值超25亿美元。据其股东透露，这笔融资无限制性条款。

一位战略投资方这么点评2014上半年的形势：“光年之外如果不倒，会是独特自己一个梯队往上，其他人在一个梯队。今天那个梯队没了，现在其他人的梯队里变成了，有一两家更Outstanding——而这个Outstanding，是阿里作为裁判评价的。”

“大家现在已经看清楚了。”陈昱说，“融不到大钱，你就没有算力，你就做不出最好的模型——这就是大模型的一个现状。”不过，越往后走，VC越显得无能为力，中国大模型事业要倚赖巨头之手。

巨头中，阿里巴巴出手较晚却是最激进的，投资了场上6家选手的5家——月之暗面、Minimax、智谱AI、百川智能和零一万物。

多位基金GP（管理合伙人）分析，阿里的激进一步，与有投资背景的吴泳铭上任和阿里对云业务的重视有关。“吴妈（阿里集团CEO）新官上任，更果决，更愿意出手。”此外，阿里亟待变革的现实也是逼迫它的动力来源——一名GP称，阿里在移动互联网的船票没完全守住，拼多多、抖音正凶猛进攻电商腹地，“AI是一张续命的票”。

除了光年之外，腾讯投资了Minimax、智谱AI和百川智能等。“腾讯是先看一看。”一位同时接受了阿里、腾讯、雷军系投资的大模型公司CEO说，“他们很明确地表达，我们自己会做模型，但是我们也担心自己做不好，把这个机会丢掉了，所以我们也投。”

雷军系和美团在心态上更接近腾讯。雷军系（包括小米、金山、顺为资本等）下注了光年之外、百川智能、Minimax、智谱AI、月之暗面。美团除了收购光年之外，投资兵分两队——美团战投下注了智谱AI，美团龙珠下注了月之暗面。不过，据接近美团高层的人士说，王兴的心态偏学习和观察。

与这些公司“自研+投资”双管齐下的策略不同，字节和百度现阶段赌注自己做。

还有许多知名企业家也在积极接触大模型公司。他们或出于战略进攻，或出于战略防守，又或者只是希望参与到AI变革之中。他们在牌桌上空“盘旋”，思考策略并等待最佳时机。

你会看到，中国顶尖的企业家、个人投资者与机构，齐聚这场大模型的顶级牌局。他们放下了过往恩怨，以一种抱团而非排他的策略，集体出资。Club Deal也体现了今时今日中国创投的实用主义倾向。

“现在大家赚钱很难，也承担不起多少损失，所以只投最好的。但最好的人是很明牌的人，估值就变得很高。”一位投资机构管理合伙人观察说，“这就变成了，大家都Fly to quality。”（Fly to quality是指，市场不确定性增加或风险厌恶情绪上升，投资者倾向于购买质量更高、风险更低的资产。）

王梦秋甚至觉得，“VC（Venture Capital、风险投资）这个概念已经不成立了，我们不是Venture，我们希望尽量不要冒险。”她说，以前VC依靠非共识挣钱，现在则不然。“因为市场上钱有限，必须大家都相信一个方向，才都愿意持续投钱。”这致使，VC依赖共识才能挣到钱。

这是一起特殊时候的中国特殊的资本故事——它沉默又喧嚣、萎靡又阔绰、团结又精明，充满了矛盾感。

值得注意的是，今天这些“玩家”手中，都还有一张“小牌”：他们的模型能力尚未证明超过海外开源模型的水平。

同时，10亿美金级的融资额于全球模型竞争而言，仍可谓杯水车薪。据统计，OpenAI总计融资额超百亿美元，最新估值超800亿美金，比中国公司多出一个数量级。

过去一年，就在中国长出6家大模型独角兽的同时，美国已出现多个巨头+模型公司的深度联盟。如，微软+OpenAI、亚马逊+Anthropic、Google自成一派、特斯拉+xAI。业界认为，为了获得相对无限的资本与资源，模型公司与巨头绑定是可预见的出路之一。

对此，中国一部分投资者的心态悠悠然出现一丝变化。巨头的大手笔一方面增加了VC的安全感，而另一方面，对于模型公司有可能被巨头吞并的命运，他们又感到失落。几位投资人做出类似表述：他们希望赌注“一个风险极大、回报极大的公司”，他们渴望捕获一个千亿美金甚至更大的巨型独角兽。

但若是，一家创业公司最终以50亿美元甚至100亿美元卖给巨头？

“我也能理解。”一名投资者说，“对我来说，这是一个很成功的失败，并不是一个失败的成功。”

大模型的扑克牌中，复杂的是模型，更是人性的博弈。


### 134

2024-05-27

Leo Xiang
@leeoxiang
数据告诉你 coze平台上bots 有多少人用：

我抓取了 http://coze.com 各个分类下bots 的用户数，排名前两名的数据如下：

1⃣Learning:
1、论文大师（专业学术强力） - 28,300 用户
2、大学生摸鱼小助手（专为写论文设计） - 27,200 用户

2⃣Public Config:
1、Video Generator - 33,400 用户
2、LovelyArtToy - 12,800 用户

3⃣Efficiency:
1、J2TEAM GPT - AI Assistant - 50,200 用户
2、Aouar GPT - 19,100 用户

4⃣Programming:
1、Code Companion - 24,900 用户
2、Codeman - 14,600 用户

5⃣Business：
1、Gimg Ai - 122,400 用户
2、ChatGPT 4 (Turbo) - 59,100 用户

6⃣Writing：
1、ChatGPT-4 - 28,200 用户
2、100% Human Article Creative Suite - 12,600 用户

7⃣Image & Audio-Video：
1、Video Generator - 33,500 用户
2、Генератор изображений по описанию ИИ - 29,500 用户

8⃣Characters：
1、SAMI Ai - 208,000 用户
2、ChatGPT - 32,299 用户

想看详细的数据请私信联系我。



### 135

2024-05-27

Lex Tang
@lexrus
也不靠它吃饭，而且还是开源的，干脆改免费算了～ 几小时后 CDN 生效，麻烦用得上的推友给一个好评。
https://apps.apple.com/app/swiftymenu/id1567748223
https://github.com/lexrus/swiftymenu



### 136

2024-05-28

歸藏(guizang.ai)
@op7418
SDXL-flash 一个新的 SDXL 蒸馏模型，速度相对 LCM、Turbo、Lightning 会慢点，但是质量会更好。

推荐参数是：

步骤：6-9
CFG ：2.5-3.5
采样器：DPM++ SDE

模型下载：https://huggingface.co/sd-community/sdxl-flash



### 137

2024-05-28

歸藏(guizang.ai)
@op7418
大厂都自己下场做教学了，谷歌出了一个给用户的提示快速入门手册。

包括提示词的书写格式以及涉及到各个职能的常用提示词和拆解。

我把整个 PDF 用 GPT-4o 翻译了，后面有下载地址。

在撰写有效提示时，有四个主要方面需要考虑。不需要全部使用。

Persona 角色、Task 任务、Context 上下文、Format 格式

以下是快速入门 Gemini 的一些提示：

使用自然语言。写作时就像在与另一个人交谈。用完整的句子表达完整的想法。

具体并反复迭代。告诉 Workspace 的 Gemini 你需要它做什么（总结、写作、改变语气、创建）。提供尽可能多的上下文。

简明扼要，避免复杂。用简短但具体的语言陈述你的请求。避免使用行话。

让它成为一次对话。如果结果不符合您的期望或您认为有改进的空间，请微调您的提示。使用后续提示和迭代的审查和改进过程，以获得更好的结果。





### 138

2024-05-28

heycc
@iheycc
FlashRAG：一个面向高效研究 RAG 的模块化的工具包。来自人民大学

包含四个组件：
- Judger。评估查询是否需要检索。
- Retriever。对于稀疏检索，支持使用 BM25 方法。对于密集检索，我们支持各种基于 BERT 的嵌入模型，例如 DPR、E5 和 BGE。
- Reranker。支持各种广泛使用的 Cross-Encoder 模型，例如 bgereranker 和 jina-reranker。
- Refiner。优化Generator的输入文本，以减少令牌使用并减少检索到的文档的干扰。
- Generator。集成了vllm和 FastChat，也支持 Transformers 库的原生接口。

特性：
- 可扩展可定制的模块化框架。实现了覆盖四个类别的 13 个组件
- 实现了 12 种高级 RAG 算法，例如 Self-RAG 和 FLARE，涵盖顺序 RAG、条件 RAG、分支 RAG 和循环 RAG 类别
- 整理了32个常见的RAG基准数据集
- 提供了一整套辅助脚本

评测数据：
提供了 12 种已有高级 RAG 算法的评测对比数据
项目仓库 https://github.com/RUC-NLPIR/FlashRAG

个人评价：
RAG 领域的算法和论文层出不穷，很难用一套框架来覆盖。而在真实生产环境，也不可能实现所有算法并在线 AB 实验。基于 workflow 来自定义 RAG 流程，也足够简单且灵活。

我的 RAG 论文 Coze bot：
https://coze.com/s/ZmFqpAat2/

我的论文研究：
http://ihey.cc/rag/flashrag-%e4%b8%ba-rag-%e7%a0%94%e7%a9%b6%e8%80%8c%e7%94%9f%e7%9a%84%e6%a8%a1%e5%9d%97%e5%8c%96%e5%b7%a5%e5%85%b7%e5%8c%85/




### 139

2024-05-28



Yangyi
@Yangyixxxx
去年我已经开始尝试这样使用GPT了
有几个感受：
1、会有一些额外你想不到的点，但GPT帮你提出来的
2、它更像一个受限的脑暴伙伴，而不是一个客户
3、GPT对细节的理解和把控不够，比如当你询问一些线下的情况，尤其是当下的客单价时，它的幻觉会很明显
4、适合帮助在一个大赛道中聚焦的调研，不太适合已经是确定的聚焦市场，调研功能突破和PMF。

前者更多靠脑暴和宏观市场情况，你可以让GPT帮你做很多分析，比如SWOT，PEST，GPT还是可以用很多「正确而无意义」的内容来帮助你打开一点点思路的。

但后者需要靠捕获流程，需要深入的不断追问细节，需要思考和对比去判断，这里GPT对细节的获悉是不足够的。

----
然而不代表这个事情不能做。
如果他有很多行业的从业者，可以基于各类用户调研访谈记录，或是行业经验的RAG知识库补全细节能力，那会成为一个很有意义的产品。

只是我觉得路线不会是直接先做个用户Agent的。


### 140

2024-05-28

Wang Shuyi
@wshuyi
有了网页采集插件，这下 
@Heptabase
 更好用了

---

Heptabase
@Heptabase
We have just released the first version of our web clipper! It allows you to save and tag web content in Heptabase, and further break it down into atomic knowledge cards.

https://chromewebstore.google.com/detail/heptabase-web-clipper/mlnkfjffdpccejmkcdhhbjfmdfokmkjh

### 141

2024-05-29



歸藏(guizang.ai)
@op7418
自己尝试了一下这个 ChatTTS 语音合成项目。

真的很牛批，他是有感情的，并且会自己在合适的地方添加语气词帮助衔接内容。

并且和字节新上的 LLM 语音合成做了一下对比，除了音质之外都比字节的强。


### 142

2024-05-29


小互
@imxiaohu
兄弟们 炸裂了

这个语音专文本TTS模型 应该是目前对中文支持最好的了

ChatTTS：专门为对话场景设计的文本到语音TTS模型

该模型经过超过10万小时的训练，公开版本在 HuggingFace 上提供了一个4万小时预训练的模型。

专为对话任务优化，能够支持多种说话人语音，中英文混合等。

模型还能够预测和控制细粒度的韵律特征，如笑声、停顿和插话等，还能进行更细粒度的调整，如语速、音调和情感等。

GitHub：https://github.com/2noise/ChatTTS
详细介绍：https://xiaohu.ai/p/8702


### 143

2024-05-30


宝玉
@dotey
翻译了这篇和另一篇：
《谷歌搜索秘籍泄漏：揭秘内部工程文档 [译]》
https://baoyu.io/translations/seo/secrets-from-the-algorithm-google-searchs-internal-engineering-documentation-has-leaked

《数千份谷歌搜索 API 的泄露文件曝光，SEO 从业者必看 [译]》
https://baoyu.io/translations/seo/an-anonymous-source-shared-thousands-of-leaked-google-search-api-documents-with-me-everyone-in-seo-should-see-them



### 144

2024-05-30


宝玉
@dotey
\#开源项目推荐 Ghidra 

Ghidra 是由美国国家安全局 (NSA) 研究局创建和维护的一个软件逆向工程 (SRE) 框架。这个框架包含一套功能强大的高端软件分析工具，能够让用户在 Windows、macOS 和 Linux 等多种平台上分析已编译的代码。Ghidra 的功能包括反汇编、汇编、反编译、绘图和脚本编写等，并且还有数百种其他功能。它支持多种处理器指令集和可执行文件格式，可以在用户交互模式和自动化模式下运行。用户还可以使用 Java 或 Python 开发自己的 Ghidra 扩展组件或脚本。

为了支持 NSA 的网络安全任务，Ghidra 被设计用来解决复杂 SRE 工作中的扩展性和团队协作问题，并提供一个可定制和可扩展的 SRE 研究平台。NSA 已经利用 Ghidra 的 SRE 能力来处理各种涉及恶意代码分析的问题，并为 SRE 分析人员提供深入的见解，帮助他们更好地理解网络和系统中的潜在漏洞。

项目地址：https://github.com/NationalSecurityAgency/ghidra


### 145

2024-05-30


歸藏(guizang.ai)
@op7418
GPT-3 四周年的纪念日，Alexandr Wang 回顾了一下这四年的一些发展和思考，还有接下来很多个四年要做的事情：

- GPT-3 让我们首次清楚地看到语言模型扩展的潜力。GPT-3 的卓越性能让 AI 社区大吃一惊——与之前所有的自然语言处理模型相比，GPT-3 的能力令人震撼。

- Scale_AI 前一年就开始了语言模型的研究，进行了一些关于 GPT-2 的 RLHF（强化学习与人类反馈）实验。但那时的 GPT-2 仍然像个玩具。GPT-3 则是首次让人们意识到它将成为 AI 领域的主要主题。

- 关键的扩展法则见解实际上早在 2020 年 1 月由 OpenAI 发表的论文《神经语言模型的扩展法则》中就提到过。这篇论文和 GPT-3 共同开启了当前迅速扩展语言模型的 AI 时代——尤其是对计算能力和数据的需求。

- 未来四年，将像过去四年一样，围绕扩展展开。许多进展取决于我们能否继续指数级地扩展计算能力和数据。这不是一件容易的事。扩展数据和计算能力将成为我们时代最大的基础设施项目之一。

- 关于计算能力——我们已经看到了对 GPU 的巨额投资，以及 NVIDIA 收入的飞速增长。令人瞠目结舌。现在的瓶颈将是：
- 我们还能制造多少芯片
- 它们将被放置在哪里
- 电力从哪里来
- 我们能多紧密地将它们互连

- 关于数据，这问题更为复杂。我们已经用尽了大部分互联网作为预训练数据来源，正如之前提到的，收益现在更多来自于后期训练。未来四年，我们需要克服数据稀缺，建立数据丰裕。

- 这也将是我们时代最大的基础设施项目之一——确保我们在前沿领域建立新的数据生产手段，以推动 AI 的进步。

- 如果我们能解决供应链问题，我们的模型未来是光明的。我们可以期待未来许多年，每一代模型都能持续进步。


### 146

2024-05-30



Andrej Karpathy
@karpathy
Apparently today is the 4th year anniversary of GPT-3!
https://arxiv.org/abs/2005.14165

Which I am accidentally celebrating by re-training the smallest model in the miniseries right now :). HellaSwag 33.7 (Appendix H) almost reached this a few steps ago (though this is only 45% of the training done).

I remember when the GPT-3 paper came out quite clearly because I had to interrupt work and go out for a walk.

The realization hit me that an important property of the field flipped. In ~2011, progress in AI felt constrained primarily by algorithms. We needed better ideas, better modeling, better approaches to make further progress. If you offered me a 10X bigger computer, I'm not sure what I would have even used it for. GPT-3 paper showed that there was this thing that would just become better on a large variety of practical tasks, if you only trained a bigger one. Better algorithms become a bonus, not a necessity for progress in AGI. Possibly not forever and going forward, but at least locally and for the time being, in a very practical sense. Today, if you gave me a 10X bigger computer I would know exactly what to do with it, and then I'd ask for more. It's this property of AI that also gets to the heart of why NVIDIA is a 2.8T company today. I'm not sure how others experienced it, but the realization convincingly clicked for me with GPT-3, 4 years ago.


### 147

2024-05-30

歸藏(guizang.ai)
@op7418
SDXL  终于有了足够好的 Openpose 和 Scribble 模型。

xinsir 发布的Openpose 和 Scribble 模型质量相当好，尤其是 Openpose。不过只支持姿态不支持面部。

再加上前几天的 Anyline 线条预处理器和 Canny 模型。SDXL 的生态终于在发布快一年的时候成熟了。



### 148

2024-05-30

歸藏(guizang.ai)
@op7418
这个论文提出了优化机器学习模型的新方法，叫做“无计划学习率”（Schedule-Free Learning）。

传统的学习率计划需要提前设定训练何时停止，而这种新方法无需提前知道训练何时停止，也不需要额外的超参数。

如果这项技术能推广开来，它可能会在学习率优化领域引起重大变革。



### 149

2024-05-31


宝玉
@dotey
推荐阅读：《我们在使用大语言模型 (LLMs) 构建产品一年中的经验总结 (第一部分) [译]》

文章主要分享了大语言模型核心组件的最佳实践，包括提示词设计、对 LLM 输出结果的评估，什么时候该用 RAG 还是微调等等。

一、提示词设计

1. n-shot 多样例
在提示词中加入 5 个以上不同类型的示例，覆盖各种可能情况

2. CoT 思维链
让 LLM 在输出结果之前解释其思维过程。简单的加入“让我们一步步思考”还不够好，最好是明确步骤

3. 输入输出的结构化
在使用结构化输入时，请注意每种大语言模型都有自己的偏好。Claude 偏好 xml，而 GPT 则偏好 Markdown 和 JSON。

4. 编写小而精的提示词，专注做好一件事
不要试图在一段复杂的中解决所有问题，尝试拆分成多个小而专注的提示词

5. 精心设计上下文信息
上下文信息并非越多越好，而是要提供关键的有效信息，而不是冗余、自相矛盾和结构混乱的信息。

二、信息检索/检索增强生成（RAG）

1. RAG 输出的质量取决于所检索文档的质量
所检索的信息相关性越高、信息密度越高、文档细节越丰富，检索效果越好。

2. 关键字检索同样很重要
现在大部分 RAG 教程演示都是基于嵌入（Embedding），但很多应用场景关键字检索效果可能更好，最好是将嵌入和关键字结合使用

3. 优先使用 RAG 而不是微调
大部分时候是不需要微调的，RAG 便宜、容易实施，并且 RAG 提供了更精细的文档检索控制。

4. 即使是模型的上下文越来越长，RAG也不会过时
需要 RAG 来筛选输入模型的信息来提升上下文信息质量得到更好的结果，另外长上下文成本比较高。

三、从提示工程到工作流

1. 逐步多轮的工作流能显著提升效果
将一大段复杂提示词分解为若干段短小提示词可以取得更好的效果，而多个短小提示词需要有工作流来支撑

2. 优先采用确定性工作流
工作流越确定越容易管理和控制

3. 合理使用温度（temperature）参数
如果希望 LLM 生成结果更加多样化，那么调高温度参数，如果希望更加确定性，则调低。

4. 不要忘记缓存
对于 LLM 生成的结果，可以缓存起来，下次有相同的请求可以重用节约成本。

5. 微调
有一些任务，即使是最巧妙设计的提示也无法胜任。例如，即使经过大量提示工程，我们的系统可能仍然无法返回可靠的高质量输出。如果是这样，那么可能有必要为特定任务微调模型。

如果决定微调，为了减少收集人工标注数据的成本，可以 生成并在合成数据上进行微调，或 在开源数据上引导。

四、评估与监控

1. 基于实际输入输出样本编写单元测试
收集实际应用的输入输出样本，用这些数据编写测试。由于 LLM 输出存在一定的开放性，可以用一些特殊的验证方式，比如字数、句子数在范围内，比如格式是否符合要求等。

2. 用 LLM 评估 LLM 生成结果
可行，但不是万能的。

3. “实习生测试”
把 LLM 当成大学实习生，如果这个任务实习生能完成，那么模型是不是也可以？如果实习生都不能完成，那么是不是应该简化拆分？

4. 过分强调某些评估指标可能损害整体性能
“当一个衡量标准变成目标时，它就不再是一个好的衡量标准。”

其他还有几个评估与监控方法，不再总结，有兴趣请阅读原文。

原文：https://oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-i/
译文：https://baoyu.io/translations/llm/what-we-learned-from-a-year-of-building-with-llms-part-1





### 150

2024-05-31


歸藏(guizang.ai)
@op7418
Jina AI 推出了 PDF 解析服务，在 r. jina .ai的链接后面跟上 PDF 文件的地址就可以返回解析结果。

解析的结果可以帮助 LLM 更好的理解 PDF 文件的内容。

---

Jina AI
@JinaAI_
PDFs are hard knuckle, and you know it. Reader now supports reading arbitrary PDFs from URLs. Simply add http://r.jina.ai like https://r.jina.ai/https://www.nasa.gov/wp-content/uploads/2023/01/55583main_vision_space_exploration2.pdf, and you get a nicely parsed text ready for downstream LLMs to consume. Yes, Reader natively supports PDF reading. It is compatible to most PDFs including those with a lot of images, and it's lightning fast!⚡️⚡️⚡️

Previously, our Reader's PDF support was limited to arXiv and relied on arXiv providing the HTML version (so credit to arXiv, not us). But why did it take us so long? During development, we discovered that correctly parsing PDFs is not easy:
