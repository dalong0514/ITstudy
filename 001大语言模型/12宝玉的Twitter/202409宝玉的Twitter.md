### 01

2024-09-01


白板报 Zhongwen.ai
@zhongwen_ai
cursor有多靠谱？我让cursor索引了我的笔记库，以 
@wshuyi
 老师为关键词，让它帮我总结王老师的特点，结果令人惊叹。

王树义老师的特点包括：

1. **执着研究工具**：他对工具的深入研究影响了很多人。
2. **无私分享知识**：总是无私地分享他的知识。
3. **新技术应用**：带来新技术的应用。
4. **倡导“重器轻用”**：提倡合理使用工具。
5. **技术指导和鼓励**：在技术上给予指导，在视频上给予鼓励。
6. **行动模范**：在行动上树立榜样。
7. **直播支持**：每次直播都给予支持。
8. **演讲和教学**：通过演讲和教学分享他的经验和知识。
9. **反思和改进**：反思工具对写作的帮助，并不断改进。

这些特点使他成为一个值得尊敬和学习的导师。


### 02

2024-09-01


meng shao
@shao__meng
Qwen2-VL: 更清晰地看世界

通义千问两天前发布的最新视觉语言模型，提供了 2B、7B 和 72B 三种参数规模，其中 2B 和 7B版本已开源，72B 版本提供 API 访问。

主要特点和能力:
- 支持不同分辨率和长宽比的图片理解
- 可理解 20 分钟以上的长视频
- 具备视觉智能体能力，可操作手机和机器人
- 支持多语言，包括大多数欧洲语言、日语、韩语等

性能表现:
- 在多项视觉理解基准测试中取得全球领先成绩
- 72B 模型在大部分指标上超过 GPT-4o 和 Claude 3.5 Sonnet 等专有模型
- 7B 模型在大部分指标上超过 GPT-4o-mini
- 2B 模型在大部分指标上超过 MiniCPM-V 2.0 和 InternVL2-2B 
@OpenBMB
 
@opengvlab
 
- 在文档理解方面表现尤为出色

关键能力:
- 细节识别和理解: 能识别场景中多个对象的关系，增强了手写文字和多语言识别
- 视觉推理: 增强了数学和编程能力，可解决实际问题
- 视频理解: 能总结视频要点，回答相关问题，维持连贯对话
- Visual Agent: 支持函数调用和视觉交互，可执行自动化任务

项目地址：
https://qwenlm.github.io/blog/qwen2-vl/




### 03

2024-09-01

宝玉
@dotey
敏捷开发的精髓：
- 持续可以交付：即使是半成品，也是可以运行的半成品，好过什么都看不到
- 时间盒子：Deadline倒逼生产力，到时间了得交付，可以缩小Scope，但是不能延期
- 小团队：减少依赖减少沟通成本
- 仪式感：通过每日站会这种仪式性的会议，加强沟通激发主动性



### 04

2024-09-01


𝓨𝓪𝓷𝓰𝔂𝓲
@Yangyixxxx
我觉得还有2个比较重要的会议，为scrum带来了两个超级优势

一个是全员参与需求会，PO的列表所有人都会一起审视，这样能达成极强共创与目标一致性，自己有参与感，而不是觉得自己只是个机器，这样对需求功能和用户的理解也更深入，往往有一些创造性溢出

第二个是故事点评估会，因为大家都会对需求投票，就会倒逼团队把大型需求全部解耦成独立的小功能，投票时需求复杂度在L以上的任务将全权被拆解成xs s 或m的

并且因为大家对需求复杂度有了整体性评估，有人投L有人投XS，就可以互相聊对功能实现上的差异点在哪儿，很多时候会把信息鸿沟抹平

举个例子，比如拿铁锤最近在做的兑换码系统来讲，有些人可能觉得是个Large需求，但有人投XS，问一问他为什么和大家投M的不一样，他会说因为我之前接入过第三方开源的兑换码系统，可以直接拿来用

就因为这种讨论，导致有些人做某个功能会非常快。

另外，由于很多新人对于技术能力有一些瓶颈，通过这些投票讨论也能让老人带动新人，新人实现会觉得难，老人会把简单的方法同步。

通过故事点评估会，加上跑过2-3个sprint后，对团队的故事点产能就有了明确的估计。

比如5人团队，每个人能解决的需求复杂度不一样，但可能整体一个1.5周的sprint就是处理80个故事点

那PO在需求会议时，就排80点的任务，就不再继续拖task进入了，如果sprint超额完成时会有多余的工作量来做一些问题fix或者重构。假定能稳定完成2-3个sprint后，就可以再增加一些故事点任务到下一期的排期中。

我觉得这两个很重要的会议，看似可能降低了很多开发时间，要拿出甚至1-2天来开会，但实际带来的价值远远高于直接进入开发
引用
宝玉
@dotey
·
9月1日
敏捷开发的精髓：
- 持续可以交付：即使是半成品，也是可以运行的半成品，好过什么都看不到
- 时间盒子：Deadline


### 05

2024-09-01


歸藏(guizang.ai)
@op7418
海外最大的图像模型分享网站Civitai终于走出了这一步。

他们新开了一个 Civita Green 站点，里面只有安全的图片和模型，没有色情内容。

我上班找模型终于不用偷偷摸摸了。

同样在摆脱了色情和重口味内容后，他们也将开始更加大脚步推进商业化的进度。


### 06

2024-09-01


小互
@imxiaohu
HivisionIDPhotos ：一款开源的轻量级且高效的AI证件照制作工具

可以生成各种标准证件照

- 轻量级抠图：能够精确地从照片中抠取人像，生成干净的透明背景图像，为后续处理提供高质量的素材。

- 生成标准证件照：HivisionIDPhoto支持根据不同的规格要求生成标准证件照， 适用于各种用途，如护照、签证等 用户可以指定尺寸，并根据需要调整背景颜色和其他参数。

- 生成六寸排版照：该工具可以将多张证件照排版成标准的六寸照片，方便用户进行打印和批量制作。

- 智能换背景：支持为证件照增加或更换背景颜色，用户可以轻松选择符合要求的背景色，从而快速完成证件照的制作。

详细：https://xiaohu.ai/p/13086


### 07

2024-09-01

meng shao
@shao__meng
提出智慧问题的艺术

来自哈佛商业评论 
@HarvardBiz
 Top5 阅读者的文章之一，探讨了提出智慧问题的艺术，以及它对战略决策制定的重要性。 

智慧提问，同样也是使用 LLM 的诀窍所在，咱们一起看看这 5 种智慧问题对企业商业战略和对 LLM 的价值 👇👇

01 - 调查性问题 (Investigative):
目的: 深入了解已知信息
例如: "为什么?"、"怎么样?"
作用：帮助澄清目标，深入挖掘非显而易见的信息
对 LLM 的应用:
- 帮助我们更好地了解 LLM 的知识范围和局限性。
- 可以通过连续的 "为什么" 和 "怎么样" 来深入探索 LLM 对特定主题的理解程度。
- 有助于验证 LLM 提供的信息的准确性和来源。
- 例子: "你能详细解释一下量子计算的基本原理吗? 为什么它比经典计算更有优势?"

02 - 推测性问题 (Speculative):
目的: 拓宽思考范围，探索创新解决方案
例如: "如果...会怎样?"、"还有什么可能性?"
作用: 帮助重新框定问题，突破限制性假设
对 LLM 的应用:
- 激发 LLM 的创造性和想象力，产生新颖的想法和解决方案。
- 探索 LLM 在假设情景下的推理能力。
- 帮助我们突破常规思维，考虑新的可能性。
- 例子: "如果我们能够完全控制地球的气候，会对生态系统产生什么影响?"

03 - 生产性问题 (Productive):
目的: 评估资源可用性和执行能力
例如: "我们如何完成这个?"、"如何衡量进展?"
作用: 帮助识别关键指标、里程碑和潜在瓶颈
对 LLM 的应用:
- 帮助规划和组织使用 LLM 完成复杂任务的步骤。
- 评估 LLM 在特定任务上的能力和局限性。
- 优化 LLM 的输出，使其更加实用和可执行。
- 例子: "我们如何利用你的能力来优化一个大型软件项目的开发流程? 需要考虑哪些关键步骤?"

04 - 解释性问题 (Interpretive):
目的: 综合信息,提取意义
例如: "从这里我们学到了什么?"、"这意味着什么?"
作用: 帮助将信息转化为可行的洞察
对 LLM 的应用:
- 帮助我们理解和解释 LLM 的输出，特别是复杂或抽象的概念。
- 将 LLM 的回答与更广泛的上下文联系起来。
- 提炼 LLM 提供的信息，得出有意义的见解。
- 例子: "基于你刚才对全球经济趋势的分析，这对新兴市场的中小企业意味着什么?"

05 - 主观性问题 (Subjective):
目的: 探讨个人保留意见、挫折、紧张关系和隐藏议程
例如: "你对这个决定的真实感受是什么?"
作用: 帮助解决可能使决策偏离轨道的人际问题
对 LLM 的应用:
- 探索 LLM 在处理主观和情感相关问题时的能力。
- 帮助我们理解 LLM 对伦理和价值观问题的 "看法"。
- 提醒我们 LLM 的局限性，尤其是在需要人类判断和情感智慧的领域。
- 例子: "从道德角度来看，在医疗资源有限的情况下，如何公平地分配这些资源?"

原文地址：
https://hbr.org/2024/05/the-art-of-asking-smarter-questions




### 08

2024-09-01



meng shao
@shao__meng
开源 AI 发展趋势摘要

来自 
@synaptic_data
 的文章，深入探讨了开源 AI 的最新发展趋势，包括市场概况、生态系统发展、资金状况、技术进展、GitHub 趋势以及未来展望等。这些信息反映了开源 AI 领域的快速发展和巨大潜力。

01. 生态系统发展
- 开发者参与度稳步增长，进入"启蒙阶段"
- 初创公司数量显著增加，涉及领域从基础工具扩展到模型训练和监控

02. 资金状况
- 过去两年超过 60 笔交易，总融资额超 130 亿美元
- 45% 以上为 A 轮及以上融资，表明投资重点转向成长期企业
- 主要资金流向：模型训练和开发者工具 (占总融资额的 60%)
- NVIDIA 持续作为战略投资者参与

03. 技术进展
- 开源模型 (如 Meta Llama、Mistral) 在 MMLU 等基准测试中已接近 GPT-4
- 新兴领导者：Qwen、Llama 和 Phi-3.5 模型获得显著关注

04. GitHub 趋势
- 新兴热门项目：LeRobot 
@LeRobotHF
 (机器人技术)、MindsDB 
@MindsDB
 (AI 模型构建平台)

05. 未来展望
- 开源 AI 模型性能持续提升，与闭源模型差距进一步缩小
- 开发者参与度稳定增长，进入价值驱动的创新阶段
- 创新重点从基础模型和开发工具扩展到训练和监控领域
- 融资规模和数量显著，反映行业潜力巨大

报告原文：
https://synaptic.com/resources/open-source-ai-2024/



### 09

2024-09-02


宝玉
@dotey
Andrej Karpathy
https://youtube.com/@AndrejKarpathy

Andrej Karpathy 是前 OpenAI 创始人之一，前特斯拉自动驾驶的负责人，他的油管频道上有很多专业的 AI 相关教学视频，质量很高，比如教你从头写一个 GPT 之类，听说在有的大学里面他的视频都属于辅助教学的材料。
youtube.com
Andrej Karpathy
下午3:13 · 2024年9月2日
·
8,937

### 10

2024-09-02


宝玉
@dotey
问：参加展会，需要将展会信息扫描成PDF然后做OCR，但是手工摘录供应商信息效率太低。尝试对PDF分割做分割后OCR，再让GPT识别生成文本字段，但是有些供应商字段不完整，无法直接输出到Excel，效率很低。该如何去改善？（参考图1）

答：
OCR 建议使用 Gemini 模型，比GPT效果识别效果更好

没有必要预先对PDF预分割处理，整张图片直接发给 Gemini 就可以帮你自动识别不同厂商和各个字段

优先考虑使用 JSON 格式提取结构化数据，CSV 格式不是 Gemini 这样的模型擅长的模式，输出时经常会出现错乱。

可以根据厂商信息预先定义好JSON的格式，要求包含哪些字段，那么 Gemini 在生成时会自动帮你填充到对应字段，在定义Schema时，将字段定义为不是必须要有的，那么没有相应的内容在输出时就会跳过，不会影响整体输出。(参考图2）

提示词可以比较简单：
> 请将展商目录中的展商信息按照JSON Schema的定义提取成JSON数组。

从截图（图3）中可以看出，基本上很完美的输出了期望的JSON格式，按照想要的结果都填充到了相应的字段。

得到JSON格式后，可以用一段小程序（Python、Javascript等），将JSON读取后转成CSV文件。

整个过程也可以用Python或者JS这种程序写成代码，用代码去将PDF转成每一页一张图片，调用 Gemini API 去解析图片获得 JSON 结果，解析 JSON 结果，拼接后生成一个大的CSV 文件。 （理论上来说这么简单的程序让 Cursor、GPT-4、Claude 3.5 都是可以搞定的）

关键部分还是在大语言模型部分，要善于利用大语言模型，借助提示词，让其返回“你想要的格式”+“它擅长的格式”。再配合代码将整个过程自动化。

很多时候“你想要的格式”并不是它擅长的，比如 Excel 或者 CSV，这时候就要学会变通，让其生成它擅长你也可以借助程序转换成“你想要的格式”，比如 JSON 格式。
引用
宝玉
@dotey

8月23日
最近有个朋友跟我讨论技术问题，他在用个第三方的OCR的服务，用来提取发票上的文字为结构化数据。但收费较高，想自己实现一套，试了开源的


### 11

2024-09-02


歸藏(guizang.ai)
@op7418
前几天 Minimax 发布了他们的视频模型 abab-video-1，我还做了个小测试。

今天补了一下针对性的详细测试，发现确实非常牛批，模型综合实力是全世界最好的之一。

先说结论：

- 画质表现是现在所有视频模型最强的；
- 人物面部细节和情绪的表现是现在所有模型最好的；
- 提示词理解、运动幅度、稳定性都在第一档；
- 美学表现略差于 Luma，好于 Ruwnay；
- 物理正确性跟 Runway 差不多，好于 Luma；

真的，你们可以看一下最后一段测试视频，太牛了。

原来的提示词让一个女性的表情从喜悦到恐惧在到无奈，Minimax 完美实现了提示词描述的内容。Luma 人物直接崩了，Runway调教过于生硬开始硬切画面。

画质分部分他的视频清晰度和纹理都非常清晰和稳定，没有出现常见的模糊和网格问题。

提示词理解也很强，比如豹子武僧的部分，Luma 画出来了但是画面完全不动，runway 直接画了个人出来，只有 minimax 完全理解了提示词并且运动幅度正常。

所有的提示词都是 AI 生成，没有使用常见视频模型的演示提示词。所有测试都只跑一次。


### 12

2024-09-02



小互
@imxiaohu
FLUX.1-dev-LoRA：一个混合现实与插画风格模型 

该模型可以生成融合了现实与插画元素的图像。

它基于FLUX.1-dev基础模型进行训练，特别擅长生成前景角色为插画风格，而背景为现实风格的视觉效果。

营造出一种假装在旅行的效果

如果能上传自己的照片，把自己弄进去更好了，可以直接商业化...🫡


### 13

2024-09-02


小互
@imxiaohu
微软发布 AutoGen Studio：一个无需编写代码即快速构建和设计多代理的系统

AutoGen Studio 可以通过拖放界面和Python API，让开发者能够使开发者能够轻松配置和组合生成式AI模型与工具，快速构建和原型设计多代理系统。

即使开发者的编程经验有限

有点像dify和coze...🙃

从原型设计、调试和评估一条龙服务...

详细：https://xiaohu.ai/p/13105



### 14

2024-09-02

小互
@imxiaohu
继可灵后，又出了中国版 Sora

Minimax 也推出的一款基于DIT架构的 AI 视频工具：海螺视频

而且现在直接就能用了...

看来这个 DIT 架构确实是好架构，只要数据足够好和算力够，很快就能大力出奇迹。

官方并没有公布太多技术信息，但是从演示视频和测试结果来看，和可灵、Runway、Luma旗鼓相当。

目前应该是人还挺少，测试生成一个视频大概需要2分钟左右，还是比较快的。



### 15

2024-09-02

歸藏(guizang.ai)
@op7418
谷歌开源了一个新的风格转移模型 RB-Modulation。

从演示来看效果非常好，而且它还直接支持 SDXL 和 FLUX。

在风格泄露问题的处理以及推理效率上的表现都比较好。

提出了一个注意力特征聚合（AFA）模块，确保文本注意力图不被风格注意力图污染。



### 16

2024-09-02


阑夕
@foxshuo
Paul Graham写了一篇非常精彩的文章「创始人模式」，非常值得三连收藏，正好也和前几天讨论过的话题——小红书的创始人被大厂来的中层员工纠正应该怎么做业务——高度关联。

这几天已经有很多号做了翻译，但我看了一下基本上都是机翻，而我认为对于Paul Graham的文章，机翻是一种不可容忍的亵渎，所以还是自己翻了一版：

Airbnb的创始人 Brian Chesky在YC的演讲被场下听众评为有生以来最难忘的，难忘到都忘了记笔记，我想就他提出的话题多谈一些。

Brian Chesky的演讲主题是传统智慧往往会在经营大公司时造成错误，在Airbnb的增长过程里，他遇到了太多的好心人，好心人们都想给他提建议，让他遵循某种特定模式去发展Airbnb。

这些建议可以简单总结为「招聘优秀的人才，然后给足空间让他们大展身手」，Brian Chesky一度接受建议并照做了，但结果却很糟糕，为此他不得不重整旗鼓，并在一定程度上去研究了乔布斯是怎么经营苹果公司的。

到目前为止，这种方法似乎行之有效，Airbnb的自由现金流在硅谷是第一流的。

听众里有很多同样取得了非凡成功的创业者，他们一个接一个的表示在自己身上也发生过一毛一样的事情，来自好心人的建议如雪花般飞来，却都被证明是有害无益的。

为什么每个人都在给创始人提供错误的建议？对此我曾百思不得其解，最后想明白的是：这些建议的实质是教你如何经营一家并非由你创办的公司，换句话说，被建议的对象设定其实是职业管理人。

所以那些建议才无法在创始人身上奏效，有很多事情，只有创始人才会去做的，但职业管理人则根本不会考虑，创始人相信，不这么做就哪儿都不对劲，事实也是如此。

这么说吧，世上有两种不同的模式来经营公司：创始人模式和管理人模式，在今天，即使是硅谷，也存在着某种潜在的共识，认为扩大规模就意味着转向管理人模式。

但我们也能从尝试过这种模式的创始人的失望中，以及从他们摆脱这种模式之后的成功中，推断出另一种模式的存在。

据我所知，还没有专门解释创始人模式的书被出版，商学院也不知其存在，所以我们能得到的，只有少数创始人自己过河时摸到的石头。不过，既然我们确定了想找什么，事情就好办多了，我希望再过几年，创始人模式也能像管理人模式一样为人熟知，何况现在其实已经能猜到其中的区别在哪。

管理人被指导经营公司的手段就像是模块化设计一样，把组织结构里的繁复分支放进黑箱里，转头只给下属制定目标，让他们想办法去实现，同时无需介入细节、关心他们究竟如何实现，否则就是过度管理，是不好的。

是的，找来优秀的员工，让他们充分发挥，听上去非常有道理，但从一个个创始人的血泪教训来看，这种建议的潜台词就是：雇佣专业的骗子，让他们把公司掏空。

无论是在Brian Chesky的演讲里，还是之后和其他创始人的交流后，我都注意到同样的一种反馈：「被操纵了」。

创始人意识到自己受到了来自两个方向的操纵：有人告诉他们必须像管理人一样经营公司，而当他们这么做了，又会受到来自被他们管理的员工的压力，他们会让创始人相信，在周围的人都不认同你的判断时，你就应该反思是不是自己错了。

但这不一样，没有当过创始人的风险投资者根本不懂如何经营初创公司，而各种顶着CXO头衔的人——他们已经混成了一个独立的阶层——其中不乏地球上最擅长撒谎的人。

无论创始人模式被怎样总结，它都一定会打破CEO只能通过直接下属去和公司进行沟通的原则，越级会议将不再特殊，变得寻常化，甚至都不再专门需要强调越级这个概念。

一旦放弃这些原则，就能迸发出大量的排列组合可供选择。

比如，乔布斯就为他认为对苹果公司而言最重要的100个人专门组织过一次静修会议，而这100个人并不是按职位级别顺序选出来的，你能想象在一家普通公司需要多大的能力才能推进这样的事情吗？

那么也不妨继续想象一下，这样做的效果会是怎样的：它可以让一家巨大的公司仍然具有初创公司的气质。如果那些静修会议不起作用，乔布斯也不可能持续的把它办下去，而我从来没听说过其他大公司有过类似的做法。

至于这到底是不是一个好主意，我们或许不能直接下判断，这也是我们对创始人模式知之甚少的又一个原因所在。

显然，创始人不可能一直像管理20个人的公司那样去管理2000个人的公司，这必然需要一定程度的放权，但放权的边界在哪、以及有多具体，则会因公司而异，即使是在同一家公司里，随着管理人得到了信任，边界也将因时而异。

所以创始人模式要比管理人模式更加复杂，效果也许也会更好，我们已经从一小簇创始人的摸索里了解到了这点。

事实上，我对创始人模式的另一个预测是，只要我们弄清了它是什么，就会发现绝大多数创始人都已经沿着这种模式走了很远——只不过他们的所作所为被其他人视为离经叛道。

有趣的是，想到我们对创始人模式依然一知半解，反而有种期盼油然而生。想象一下，当我们有朝一日可以告诉他们怎么像史蒂夫·乔布斯而非约翰·斯卡利那样经营公司，他们该会整出什么新活来啊。


### 17

2024-09-02

歸藏(guizang.ai)
@op7418
音频加人脸生成视频新的最佳实践来了，太稳了。

字节的新研究 Loopy，看起来会开源。

涉及到非语言的动作也可以生成，比如叹息、情感驱动的眉毛和眼睛运动。

唱歌音频也没问题，对二次元图片的支持也比较好。



### 18

2024-09-05

小互
@imxiaohu


2024 Inclusion·外滩大会在上海开幕，著名未来学家凯文·凯利在开幕主论坛上发表演讲：当人工智能深刻影响经济和文化时，将涌现三大趋势！

非常值得观看，强烈推荐！

AI 时代三大趋势：

·全球主义：

·全球正在共同构建一个基于技术的「超级有机体」，将全球的设备连接成巨大的计算系统，所有数字技术包括人工智能都运行在这个新平台上。

·全球主义推进推动了新兴的全球文化，人们的生活方式和穿着逐渐趋同，底层需求达成一致。

·人工智能将实现真正的「实时翻译」，打破全球语言障碍，加上增强现实（VR）技术，全球化「劳动力」将第一次出现。

·创新加速：

·AI 技术加速了创新的步伐，体现在新发明和新思想传播速度加快，通过增强现实（AR）和虚拟现实（VR）技术提高学习效率，AI 通过机器及其他传感器感知世界，以及 ChatGPT 等人工智能工具加快人们学习速度。

·当答案易得时，提出正确问题和掌握正确思维方式变得更有价值，「学会如何学习」将成为未来毕业生的核心技能。

·AI 驱动生成：

·人工智能能帮助人们摆脱机械、枯燥的工作，完成无法独立完成的任务，甚至生成超乎人类想象的全新事物。

·人工智能系统正在生成新事物且不断完善，人工智能是多样的，将填补许多智能领域。

·从人工智能工具中获益最多的是表现一般或较差的员工，人工智能工具能帮助他们更好地完成工作。

·回答中国网友提问：

·对于人工智能是不是人类的下一个进化阶段，凯文·凯利给出肯定答案，认为其重要性不亚于火、印刷术和工业革命，但实现需要至少一个世纪甚至更长时间，人类正在通过人工智能重塑文明，创造人造「外星人」并引入新思想和文化。

·为确保人工智能带来有益未来且不加剧不平等，应利用技术引导其发展，推动其开源化，形成更具包容性的技术生态系统。

·未来几乎所有工作都会使用人工智能，但不会被完全取代。


### 19

2024-09-05

宝玉
@dotey
1992年的时候，比尔盖茨的一段采访视频，主持人不解的问盖茨：“有什么是计算机能做但是书本做不到的呢？阅读不就是最重要的互动过程吗？当你坐下来阅读的时候……”

在 30 多年前计算机不普及的时候，普通人确实很难想象计算机上不仅有图像，还能有声音、动画，还能互动，这会是怎么样的一种魔法体验，但现在已是平常！

对于上面的问题，盖茨耐心的解释：
“不，不是这样的。完全不是。

如果你想了解乐器，不只是看看图片，如果你真的想了解乐器，你应该听它的声音。

你可能会想先读一下有关它的资料， 然后再弹击它来听听它的声音， 也许还想拨动某根特定的琴弦， 听听它独特的声音。

或者说你正在学习人体知识，你希望能够放大观看某个部位， 甚至想看到它运作的动画演示。再或者你在学习化学知识， 你可能会想亲眼看到化学键是如何结合的。

所以，计算机能够将文字、图片、声音和动画全部结合在一起， 让你能按自己的节奏学习， 获取更多细节，跳过不需要的部分， 并通过让计算机对你进行测验来确认你是否真正理解了这些知识。

这是一种比书本更高级的互动方式。”



### 20

2024-09-05

歸藏(guizang.ai)
@op7418
时代周刊发布人工智能时代最具影响力的100个人

分成领导者、创新者、思想家、塑造者几个部分。

看了一下里面国内的。

领导者部分有国家互联网信息办公室主任、字节CEO梁汝波、百川王小川。

创新者部分没有中国人。

思想家部分有清华大学交叉信息院院长姚期智。

塑造者部分有中国政法大学数据法治研究院教授 张凌寒。



### 21

2024-09-05

Andrej Karpathy
@karpathy
Thank you 
@saranormous
 and 
@eladgil
 for hosting me on the 
@NoPriorsPod
 pod, pleasure to talk with you (as always!)
 
---

sarah guo // conviction

@saranormous
🆕 One of my favorite 
@NoPriorsPod
 discussions: the wonderful 
@karpathy
 on
- status of autonomy, tesla v. waymo
- humanoid robots
- bottlenecks to AGI
- our future exo-brains
- small models, open source
- eureka labs, education
- what young people should study in the age of AI

Full interview links:
Youtube https://youtube.com/watch?v=hM_h0UA7upI
Spotify https://open.spotify.com/episode/468FvK4ndE4nWgxFdOob4h
Apple https://podcasts.apple.com/us/podcast/the-road-to-autonomous-intelligence-with-andrej-karpathy/id1668002688?i=1000668455289

翻译帖子


### 22

2024-09-06

小互
@imxiaohu
兄弟们 这个好 👍🏻

RapidLayoutRecover：将文档类图像还原成可编辑的文本格式 

同时保持版面布局

也就是它可以将文档图像（比如扫描的书页、PDF页面等）转换成可以编辑的文本格式，比如 Word 或 TXT 文件，同时保留图像中的版面布局。

RapidLayoutRecover 可以自动识别图像中的文本、表格、公式等内容，帮助用户将这些图像转换为可以进一步编辑和处理的格式。

这样用户就不必手动输入或重建文档中的内容，大大节省了时间和精力。

详细：https://xiaohu.ai/p/13264
GitHub：https://github.com/RapidAI/RapidLayoutRecover



### 23

2024-09-06

歸藏(guizang.ai)
@op7418
GlaiveAI 昨晚开源了 Reflection Llama-3.1 70B。

他们说这个模型可以主动纠正自己的错误，从而避免幻觉问题。

在基准测试上的得分也超过了 GPT-4o 和 Claude 3.5 Sonnet。

可以避免幻觉主要是两个操作完成的：

 模型训练的时候使用了反思调优技术。
 
将规划过程独立为一个单独的步骤。不仅增强了思维链 的效果，还确保系统输出保持简单明了。



### 24

2024-09-06


Ethan Mollick
@emollick
🤯So real agents came faster than I thought

Without any Python ability. I signed up for Replit and used their new AI coder. I was able to build a working app that identifies sentiment at the paragraph level in 23 minutes. I only interacted 8 times. It did the design & debugging


### 25

2024-09-06

meng shao
@shao__meng
Anthropic 顶级 Prompt Engineers 对话

Anthropic DevRel 
@alexalbert__
 与三位顶级 Prompt Engineers 
@AmandaAskell
, 
@zswitten
, 
@DavidSHershey
 的访谈视频，关于提示词工程方面的内容很值得学习。70 多分钟，大家可以先🐎后看 (发内容的同时我也正在看👀)

试着用今天看到的一个 Youtube 视频内容总结的 AI 应用做了一遍笔记，感谢 
@Math43866097832
 
@deepseek_ai
 
https://easynoteai.com/share?t=VtN8B3nj8d1ycdKWWcw8OQ866pgRGYKl

笔记结构很完整，内容也很全面，再用 Claude 做了一遍内容提炼：

提示工程的定义与特征:
- 通过有效沟通与模型互动以达成预期结果
- 需要清晰的沟通能力、迭代改进和对潜在错误的预判
- 将自然语言视为一种编程形式，需要精确性和版本控制

有效提示的关键要素:
- 考虑边缘情况和非典型场景
- 理解现实中用户的输入行为 (如拼写错误、不完整查询等)
- 仔细分析模型输出，确保达到预期的推理步骤
- 考虑模型如何理解指令以及用户如何与模型交互

提示技巧与策略:
- 使用清晰、详细的描述，特别是对于图像类任务
- 在研究和消费者应用中采用不同的提示策略
- 通过迭代和人机交互来优化提示
- 推动模型能力的边界，挑战其极限

模型理解与交互:
- 理解预训练模型和 RLHF 模型的差异
- 将模型视为有能力的系统，而非简单的工具
- 提供完整信息而非过度简化的提示

提示工程的未来发展:
- 模型可能会更好地理解用户意图，减少对详细提示的需求
- 提示生成工具可能会发展，促进用户与模型之间的更高效协作
- 提示工程可能演变为一种更高级的交互形式，类似于专家咨询关系

提高提示技能的建议:
- 阅读和分析他人的提示和输出
- 不断实验和获取反馈
- 培养将思维外化的能力，清晰表达想法

Youtube 视频链接：


https://youtube.com/watch?v=T9aRN5JkmL8



### 26

2024-09-06


linear uncle
@LinearUncle
cursor的文档爬虫真的爬麻了。

我把aider文档的根目录链接丢给它，它居然索引了 64 个文件，基本把网站文档爬光了（图一）

于是打开cmd +L (chat)对话框，就可以在cursor里进行aider文档的问答了（图二）。



### 27

2024-09-06

Chris Brookfield
@cmilesb
I can’t say how exciting this book is. How did I miss it for so long?

The Systems View of Life



### 28

2024-09-06

知识分享官
@knowledgefxg
强推一本书，戴维迈尔斯的《社会心理学》，全书700页，刚开始读的时候想给书里画画重点，发现知识密度大到几乎每一句都是重点，这是一本大学心理学指定教材，但写的简单易懂不抽象，里面会给你讲解社会中很多让你困惑的现象，读完起码认知上升好几个层次，推荐直接买实体书，少下一次馆子就可以省下这点钱，三年前读过两遍，今天开始我准备读第三遍，每次读完之后你的感悟也会随着时间与阅历而不同。

套用作者的一句话：“一旦思维得以扩展，思想就再也回不到原来狭小的领域了。”



### 29

2024-09-06

宝玉
@dotey
由于这篇我用了Markdown，以及GPT惯用的“首先、然后、最后”句式，让人误以为我是用GPT生成的，其实都是自己写的，只不过摘录的是我给CSDN写的一篇稿子的片段。

不过我尝试了一下把第一段的提问分别发给GPT-4o、GPT-4、Claude，看生成的如何！

Prompt：
现在不懂软件开发的人对 AI 是普遍乐观的，认为 AI 很快就要替代程序员了，而程序员群体作为最了解开发最常使用 AI 的群体怎么反而大多数认为这些工具无法替代人类程序员的角色呢？



### 30

2024-09-06

宝玉
@dotey

现在不懂软件开发的人对 AI 是普遍乐观的，认为 AI 很快就要替代程序员了，而程序员群体作为最了解开发最常使用 AI 的群体怎么反而大多数认为这些工具无法替代人类程序员的角色呢？

**首先现在的成功案例，都是偏向原型性质的、简单的产品，离真正的复杂商用产品还是有一段距离。**原型产品的特点就是不需要考虑后期维护，不需要考虑各种使用场景，满足特定场景的演示、验证需求即可。但程序员们日常实施的项目，需要在保障各种不同使用场景下的稳定运行，以及对复杂庞大的代码库长期维护。

**然后 AI 目前还只能生成代码，而在软件工程中，编码只是软件生命周期的一部分。**程序员的日常工作，还有很多编码之外的工作，比如需要和产品经理反复沟通确认需求，基于需求去设计合理的架构，将复杂的架构拆分成小的模块并保证模块之间可以正常通信，需要对结果进行反复测试，发现 Bug 要去跟踪和修复，开发完成还要部署到线上去运行。

**最后受限于 AI 的上下文窗口长度，AI 还不具备大项目的代码开发和管理能力。**当前 AI 都有上下文窗口长度限制，也就是说每次和 AI 的交互，内容不能太长，也不能生成太长的代码，这就意味着你无法把整个代码库都扔给 AI，只能是每次选取一部分代码，加上提示词一起交给 AI 生成，所以在让 AI 生成代码时，仍然要程序员去把复杂的需求拆分成简单的模块，仍然需要手动去选取最相关的代码供 AI 参考。

所以现在说 AI 能替代程序员还为时尚早，但是善于使用 AI 的程序员一定能大幅提升效率，甚至于不懂写程序的人借助 AI 的帮助作出原型类产品也是完全有可能的。除此之外，现在的 AI 本身是一个极好的知识库，通过和 AI 的交互，我们还可以让 AI 成为我们的导师，帮助我们学习各种开发上知识，解答开发中遇到的难题，快速提升自己。



### 31

2024-09-06

歸藏(guizang.ai)
@op7418
Fluxgym：一个非常简单的傻瓜式 FLUX Lora 训练工具。

最低只需要12G显存就可以训练。

后端还是用的Kohya脚本。

使用方式：输入信息-选择图片-点击开始




### 32

2024-09-06

宝玉
@dotey
最近在从 vercel 迁移一个站点到 cloudflare 上时，这个站点用到了 aws 的 dynamodb，由于 cloudflare 的 worker 不直接支持原生 nodejs 的 crypto 库，导致官方的 aws-sdk 无法在 worker 运行导致无法迁移，后来发现 aws 官方还有一个更轻量的 sdk



### 33

2024-09-06

小互
@imxiaohu
💥兄弟们，这个炸裂了 

科学家研究出一种新方法，只需涂抹特殊溶液 

就能使活体动物的皮肤组织变得透明

通过一种名为Tartrazine的溶液，将其溶解于水中并应用于小鼠的组织表面，通过这种方法使小鼠的腹部皮肤透明，进而观察到肠道神经元的活动。

这个技术不需要手术，可以直接在活体动物上进行高分辨率的显微成像，这对生物医学的研究和诊断都有重大意义。



### 34

2024-09-08

歸藏(guizang.ai)
@op7418
刚才听到张小珺这一期的播客讲到 Self-play RL 到现在依然还是非共识。

有点感叹，没了 Open AI 和 Anthropic 这行业真不知道怎么办。

Andrej Karpathy 在去年的公开视频都讲烂的东西，讲的中学生都可以听懂的东西（推理能力、奖励模型、封闭域、数学&代码）。

目前国内只有 DeepSeek 在实践和探索，其他公司不知道在干嘛。



### 35

2024-09-08

歸藏(guizang.ai)
@op7418
终于可以摆脱 Niji6 自带的油腻感了，舒服了。

Nijijourney 的模型个性化功能上线。

可以根据你 Rank 和喜欢的图片帮你微调一个自己的Niji 模型，提示词后加--p使用。

使用前需要 Rank 超过 200 张图片才行，大概选个五六分钟就行。



### 36

2024-09-08

小互
@imxiaohu
时代周刊这个2024 AI 100人

有点意思😁

注意细节，竟然还有...

完整名单：https://time.com/collection/time100-ai-2024/



### 37

2024-09-08

小互
@imxiaohu
Reflection Llama-3.1-70B：顶级开源模型 可自我反思改进

它使用了一种名为“Reflection-Tuning 反思调优”的技术进行训练，该技术教会模型在推理过程中发现自己的错误并进行自我修正。

Reflection 70B 在多个基准测试上超越了顶级闭源模型 GPT-4o 和 Claude 3.5 Sonnet，并击败了 Llama 3.1 405B。

该模型通过将规划过程分离为独立步骤来提高链式思维（CoT）的效果，并保证输出简洁明了。

Reflection 70B 的权重已经发布，405B 版本将于下周推出，预计性能会进一步提升。

详细介绍：https://xiaohu.ai/p/13281

模型下载：https://huggingface.co/mattshumer/Reflection-Llama-3.1-70B

在线体验：https://reflection-playground-production.up.railway.app




### 38

2024-09-08


小互
@imxiaohu
Replit 发布Replit  Agent AI应用开发助手  

0 基础编程用户也能开发程序

Replit  Agent ，可以让你即使你不会编程，也可以快速创建应用。

你只需要描述你想要的应用，AI 就会帮你自动处理复杂的步骤，从设置开发环境、编写代码、甚至部署到网上。

一气呵成...

而且，你可以随时查看和修改 AI 生成的代码，学习编程的过程。它还支持手机使用。

详细：https://xiaohu.ai/p/13272


### 39

2024-09-08


歸藏(guizang.ai)
@op7418
Meta 发了三篇文章详细介绍 LLM 的训练过程以及微调。

文章非常的干，都是 LLM 微调的关键要点，强烈推荐看看，下面是核心的笔记。

- LLM 训练方法
- 如何选择合适的训练方式
- 如何判断是否需要微调 LLM
- LLM 微调数据集准备
- 数据质量/数量
- 数据多样性
- LLM的数据管道如何构建


### 40

2024-09-08

meng shao
@shao__meng
Pydantic is Still All You Need 
@pydantic
 

这篇文章是作者 Jason Liu 对结构化输出在与 LLMs 交互中的重要性的反思和总结，回顾了过去一年使用 Pydantic 进行结构化输出的经验，文章强调了结构化输出在 AI 应用开发中的重要性，并展示了 Pydantic 如何成为实现这一目标的有力工具。

Pydantic 的优势:
- 允许嵌套对象和模型，实现模块化结构
- 提供验证器，提高系统可靠性
- 使代码更清晰、更易维护，结合函数调用，为结构化输出提供了优越的解决方案

Pydantic 的关键特性：
- 结构化流式处理: 在保持结构化输出的同时改善延迟
- 部分验证: 支持生成式 UI 的实时渲染
- 验证器: 添加自定义逻辑以确保输出正确，支持错误重试

实际应用场景:
- 数据生成和提取: 如 RAG 应用中生成后续问题，验证生成内容中的 URL 等
- 复杂搜索查询: 通过结构化模型处理复杂的搜索场景

经验总结:
- 验证错误对提高系统性能至关重要
- 并非所有语言模型都有效支持重试逻辑
- 结构化输出在视觉、文本、RAG 和 Agent 应用中都有益处

btw... Pydantic 2.9 官方已发布 
@sydneyrunkle
：
https://github.com/pydantic/pydantic/releases/tag/v2.9.0 

原文链接：
https://python.useinstructor.com/blog/2024/09/07/pydantic-is-still-all-you-need/



### 41

2024-09-08


小互
@imxiaohu
Mini-Omni 支持“边思考边说话” 

具备端到端的实时语音输入和输出能力模型

- Omni可以同时处理语音输入和生成语音输出，实现了真正的端到端语音交互。

- 不仅支持语音，还支持文本等多模态输入。能在不同的模态之间进行转换

-Any Model Can Talk功能 ：其他模型可以轻松集成Omni实现实时语音能力

-Mini-Omni不仅在语音识别（ASR）和语音生成（TTS）任务中表现优异，在多模态任务（如TextQA、SpeechQA）上也具备强大的推理能力。 

详细介绍：https://xiaohu.ai/p/13325


### 42

2024-09-08

宝玉
@dotey
求推荐一个好用的 React 应用程序用的 Markdown 编辑器（HTML编辑器也可以），用在自己的博客后台发布上，需求：
1. 容易集成到React程序
2. 可以所见即所得
3. 方便加插件增加一些定制需求，比如支持数学公式、插入YT视频、自动下载图片什么的

先行感谢！🙏

---

宝玉
@dotey
https://x.com/BarrySong97/status/1832922944567496802
 
最终选了 http://novel.sh 这个编辑器，比较轻量，技术栈是 TipTap + TailwindCSS + ShadcnUI + React，我和用的技术栈比较接近，少量修改就可以直接用，扩展性也很好。

### 43

2024-09-08

meng shao
@shao__meng
LLM 驱动的软件工程 Agent：综述与展望

这篇论文主要介绍了 LLM Agent 在软件工程领域的应用，全面系统地梳理了 LLM Agent 在软件工程领域的应用现状，为研究人员提供了宝贵的参考信息。

软件工程和 LLM Agent 不同视角的观察分析 👀

从软件工程视角的分析: 
从软件开发生命周期的角度，LLM Agent 在各个阶段的应用: 
- 需求工程: 
Agent 可以模拟不同角色，进行需求获取、建模、梳理等。
Multi-Agents 系统可以覆盖需求工程的多个阶段，如获取、建模、验证等。
- 代码生成: 
Agent 通过规划和迭代改进提高代码生成质量。
利用模型反馈、工具反馈、人类反馈等方式进行迭代优化。
- 静态代码检查:
用于 bug 检测和代码审查。
Multi-Agents 协作可以模拟真实世界的代码审查过程。
- 软件测试:
单元测试: 通过迭代优化生成高质量的测试用例。
系统测试: 针对操作系统内核、编译器、移动应用等不同系统的测试。
- 调试:
故障定位: 使用 Multi-Agents 协同和工具调用提高准确性。
程序修复: 通过迭代优化生成高质量的补丁。
- 端到端软件开发:
模拟软件开发团队，覆盖从需求到部署的整个过程。
采用瀑布模型或敏捷开发等不同的软件开发流程模型。
- 端到端软件维护:
自动解决真实世界软件项目中的问题。
包括问题定位、补丁生成、验证等阶段。

从 Agent 视角的分析: 
详细分析了 LLM Agent 在软件工程中的设计特点: 
- Agent 框架:
规划: 单轮/多轮规划,单路径/多路径规划等。
记忆: 短期/长期记忆,特定/共享记忆等。
感知: 主要是文本输入,部分涉及视觉输入。
行动: 使用各种外部工具扩展能力,如搜索、静态分析、动态分析等工具。
- Multi-Agents 系统:
角色: 管理者、需求分析师、设计师、开发者、质量保证等。
协作机制: 分层结构、循环结构、树状结构、星型结构等。
- 人机协作:
在规划、需求、开发、评估等阶段引入人类参与。

论文作者：
Junwei Liu 
@nineteen_nov
, Kaixin Wang 
@KaixinWang56787
, Yixuan Chen 
@FloridaSpider
, Xin Peng 
@XinPeng_Fudan
, Zhenpeng Chen 
@ZhenpengChen18
, Lingming Zhang 
@LingmingZhang
, Yiling Lou

论文地址：
https://arxiv.org/pdf/2409.02977



### 44

2024-09-08

宝玉
@dotey
问：想问一个基础的问题，我想让chatgpt读一篇十几页或者几十页的报告，然后针对其中的一部分，按照模板进行总结或者appraisal(有过往的报告参考)，最好的方法是直接把pdf上传，然后再把模板上传，这样直接让他生成吗？ 感谢宝玉老师！

答：

如果这个任务只有几页，那么对于 LLM 来说是很简单的任务，因为现在的 LLM，上下文窗口长度都比较大，GPT-4o（ChatGPT）有 32 K（2.3 万英文单词），Claude 3.5 Sonnet 有 200K（14万英文单词），Gemini 1.5 Pro 有 1M（70万英文单词）

所以如果只有几页，那么把报告内容+模板都提供给 LLM，让其按照模板总结就好。

如果几十页，那恐怕有点困难，可以先试试 Gemini 1.5 Pro，应该够用。

如果超出上下文长度，有几个办法：
1. 手动精简内容，把不必要的信息清理掉
2. 分块总结，将几十页拆成几页几页的小块，再选一种分块总结方案：
 - 每块独立总结，然后将所有总结合并，可能会损失上下文
 - 一块块总结，将前一块总结的结果合并到下一块一起总结，速度慢一些，但是上下文损失小一些

当然还有其他一些办法，根本就是保证输入长度不要超过 LLM 的最大上下文长度（最好不要超过最高上限的2/3，因为输出内容也占用长度）。

另外 PDF 中内容的格式对于结果也会有影响，比如图表的总结效果可能并不会好。如果能把这些信息变成文本会更好。



### 45

2024-09-10


宝玉
@dotey
在使用 AI 编程之前，一个不为人熟知的技巧是在 GitHub 上搜索有价值的代码，直接调用或者复制相应代码，节约很多自己从头写代码的时间。

举个例子，比如我想做一个文本生成语音服务，当然有很多收费的 API 可以用，但是也有一些免费好用的，比如有一个 Python 项目叫 Edge-TTS http://github.com/rany2/edge-tts ，可以免费调用微软的 TTS 服务。

但问题在于这个项目是 Python 的，如果我是纯前端项目，没法直接用，但我怎么找到靠谱的相应的 TypeScript 库或者代码呢？

首先我需要在这个项目找到核心代码，它是怎么实现的？

我第一个关键字是“https”，因为我知道它是调用的微软Edge的服务，如果是Web服务，应该绕不开需要https开头的URL

很幸运，第二个文件就找到了，如果这个关键字不行我可能会用一些微软常用的域名或者“.com”这样的常用域名后缀，都搜不出来就得去翻代码了。

打开文件，里面配置了 API 地址和 Token。

那么按照这个信息我应该就可以很容易找到其他语言的实现。

第二步我优先选择 Token 内容为搜索关键字

因为关键字的选取，最好是相关性和唯一性比较强，这样更容易过滤掉不相关的信息。

对于实现这个功能，无论什么语言 Token 肯定是绕不过去的，并且是个唯一性很强的字符串，比较容易搜索到。用 API 地址也是个可选项，但是太长的字符串搜索结果要差一些，另外可能会被无用信息干扰。

另外还需要过滤一下语言，如果只是考虑 Web 项目，那么加上 “language:TypeScript”可以限定只检索 TypeScript 代码，这样可以把无关的语言排除掉。

搜出来 42 条结果，而且相关性很高，都是高质量的 Repo，有大家熟悉的 OpenAI-translator 和 LobeChat，看来是我 Out 了，原来大家都已经用上了。

剩下的事就比较简单了。

不过现在你也可以试试让 AI 帮你生成试试，但是要调通能运行也还是需要花一点时间的，比如它可能不会帮你找 Token 😄

所以即使在 AI 编程时代，这些技巧也并不过时，我就经常先让 AI 生成一段代码，然后根据它生成的代码再去 GitHub 检索，效果很不错。

相对来说 GitHub 上的代码，至少绝大多数时候是能运行的并经过反复考验的，而 AI 生成的代码很多时候就是基于 GitHub 训练的代码生成的。两者结合起来效果更佳。


### 46

2024-09-08

Forrest Zhang
@forrestzh_
最近深入使用 Cursor 的一些感受：

1. 本质上是交互方式的改变，核心能力没有脱离 Claude 3.5 Sonnet，即之前不能用 Claude 3.5 Sonnet 实现的，现在大概率也不可以；

2. 用来写一些小的 project 非常方便（比如快速写一个脚本），基本上不需要额外写代码，但是至少需要对实现方式有个了解，才能更好地去下指令，完全编程 0 基础的用户还是不友好，因为你很难出了问题去 debug（让 AI 去 debug 有时候 bug 会越来越多）；

3. 复杂项目上的多文件生成不太理想，这里复杂项目指的是至少上万行代码的项目，使用 Composer 会经常出错，如果是了解本身代码架构，效率是不如直接自己按照每个部分去写（or 生成）的；

一个 Go Backend 的例子（代码库几十万行+）：

写一个新的 API，涉及到 API 层、grpc、service 层、db 层（而且这些都进行了 interface 抽象），并且需要调用 utils package 里面封装的一些方法，让 Composer 去做基本上无法完成。

4. 本地 codebase index 的方式是通过 chunking code 做 embedding（线上的 embedding），然后通过 vector search 的方式来嵌入上下文，这样做的缺点是只理解代码的语意，不理解代码的逻辑，另外这会把你本地所有的代码上传到云端（有合规风险的推友们需要注意一下）；

5. 理想的方式是按照不同的语言做静态分析，或者接入 language server，这个应该在 Cursor 未来的 roadmap 中；

6. 如果壁垒仅仅在交互方式的改变上，其他的 IDE/Code Editor 会很快赶上，相信 VSCode 内部应该已经有相关提案了， 
@yetone
 的 NeoVim 插件 avante 也复刻了 Cursor 的交互方式；

7. X 上最近的 Cursor Hype 可以理性看待，大部分发帖的用户都不是厂里打工的 SDE，indie hacker 和新入门编程的用户居多，这确实能够大大提升这些用户利用编程进行 building 的能力，但是理论上应该不会是 Cursor 的核心目标用户；

8. 做了一些用户调研，使用 GitHub Copilot & 在 ChatGPT/Claude 中复制粘贴还是主流的 AI 辅助编程的方式。

9. AI Coding 赛道应该算是当前最卷 & 投入度最高的一个赛道， 
@devv_ai
  即将 close 新一轮的融资，也正在重新调整自己的定位，应该未来几个月会有新的东西和大家见面；

10. 欢迎大家加入我们，我们正在招聘【前端开发工程师】，可以发送简历到 join@devv.ai



### 47

2024-09-08

nazha
@xiaokedada
在高频使用 Cursor 两周之后， 这条推文用来记录 Cursor 的进阶用法 
@cursor_ai
 

1. ⌘ + Enter 选中整个代码库作为 Context
在 Cursor 对话中，⌘ + Enter 命令支持代码库嵌入，以提供更好的回答

发散一下思维，代码库也可以是文本或其他数字资产。比如这个例子 https://x.com/xiaokedada/status/1832794562261389787,在 cursor 中打开 obsidian 笔记本，然后基于当前的笔记，进行问答。



### 48

2024-09-08

宝玉
@dotey
生成是 AI 强项，解 Bug 要更有挑战一些，可以结合一些传统的编程技巧，解决 Bug 的关键是定位问题，定位到问题在哪就容易了，一般的流程：
1. 先稳定重现，找出来稳定复现 Bug 的步骤
2. 缩小范围定位问题，借助二分法，定位到大致范围，比如在不同的位置输出日志、设置断点、回滚到之前的正常版本对比差异
3. 选择合适的解决方案，比如回滚到以前版本，临时修复，或者一劳永逸解决，也可以结合，先临时再一劳永逸。



### 49

2024-09-10

小互
@imxiaohu
Open Interpreter 推出01 App 

能运行在各种硬件上 并通过语音控制来操作设备

Open Interpreter团队宣布了一个重要的决定：放弃制造01 Light硬件设备，转而推出01 App

- 用户可以通过按住按钮进行语音输入，来远程控制他们的计算机，包括Mac、Windows和Linux操作系统设备。

- 应用具有上下文积累的能力，在语音按钮未按下时，它会累积上下文信息，让应用能够更好地理解用户的指令和意图，提升语音指令的准确性。

详细介绍及应用下载：https://xiaohu.ai/p/13345



### 50

2024-09-10


小互
@imxiaohu
吴恩达 AI 课程：AI Python 初学者课程 

每节课5分钟 1小时学会 AI Python编程

专为初学者设计，该课程分为四个部分，适合零基础到有经验的编程人员。每节课不到五分钟，一共11节课，一小时学会AI Python编程。嘿嘿...

课程中集成了AI聊天机器人，能够提供即时反馈、解释编程概念、帮助调试代码，并提升学习体验。

详细介绍：https://xiaohu.ai/p/13399


### 51

2024-09-10

小互
@imxiaohu
DomoA 推出图像视频分辨率提升工具

可以将图像或者视频的分辨率提升到2K和4K的水平

支持最大50M的文件上传

视频最高支持60s的长度



### 52

2024-09-10


歸藏(guizang.ai)
@op7418
Mistral 在 Meta 之前开源了 Pixtral 12B 视觉语言模型

还是通过直接发磁力链接的方式，等测试看看有多强。

文本基础模型：Mistral Nemo 12B

视觉适配器 (Vision Adapter) 参数量：4 亿

使用 GeLU (Gaussian Error Linear Unit，用于视觉适配器) 和 2D RoPE (二维旋转位置编码，用于视觉编码器)


### 53

2024-09-10


小互
@imxiaohu
兄弟们这个厉害 无敌抠图去背景神器

指那抠那 想抠什么抠什么 

支持保留图像中的指定对象，去除其他图像和背景。

支持文本控制，只需要打字告诉它你要Cut什么就行😂

在线体验：https://huggingface.co/spaces/finegrain/finegrain-object-cutter


### 54

2024-09-10

宝玉
@dotey
问：让 GPT 为学生生成了一篇阅读理解文章后，发现里面总是会出现超纲（高中3000词汇表）的词，所以想请教有没有方法可以直接让gpt不使用超纲的词汇。直接说gpt好像做不到。

答：
限定输出词汇为高中词汇不超纲，这是一个基于通用的大语言模型很难直接做到的事，当然理论上可以让 LLM 在预测 Token 时，只挑选词汇表上的单词，但这个太底层了，成本也不会低。

如果我来做的话，我会这么做：

1. 选最优秀的模型：GPT-4o、Claude 3.5 Sonnet、GPT-4，如果这些模型都做不好，其他模型更可能是在浪费时间。

1. 优化提示词，在提示词中明确要求，这是面向“中国高中学生”的阅读理解文章，这样在输出时内容会更接近要生成的结果。同时应该测试对比美国小学、初中的结果，因为大语言模型可能对于美国的教育系统更熟悉。

3. 检查生成结果中哪些单词超纲，然后将原文和超纲的单词列表一起交给 LLM，让其重新生成。这个检查可以配合程序来做，让程序检查超纲单词效率更高，不过如果量不大，人工检查一下也很简单。通常 1-3 次改进就可以了。实在不行只能手工做或者重头开始一次。

这种技巧在使用 ChatGPT 时其实很常见，GPT 生成的答案不满意，明确告诉它哪里错了，它还是能改的。

但是需要注意的是，如果一直改不对，不要一直在聊天会话中回复消息，因为随着回复的消息越多，上下文越来越长，生成结果会越来越差，到最后可能都会遗忘最初的要求。

遇到这种一直改不对的问题，不妨回溯到最初几次的对话，修改优化一下原始提示词，把输入的消息长度控制在一个合理的范围，应该能得到想要的结果。



### 55

2024-09-10

Ethan Mollick
@emollick
Wow: Just tried PaperQA, an open source AI-powered literature review whose research paper claims it achieves "superhuman synthesis of scientific knowledge"

I tested it against papers I wrote and it seems like the real deal, putting together a good summary with accurate details.



### 56

2024-09-12


宝玉
@dotey
Ell 是一套新的开发大语言模型程序框架，可以理解为 LangChain 的升级版，核心亮点：
1. 将对 LLM 的调用简化到只要写提示词（Prompt），并且可以方便的对提示词进行版本跟踪
2. 有可视化的工具，可以可视化监控跟踪每一次请求
3. 原生支持多模态

它的设计原则：
1. 提示词不是字符串，而是代码
2. 提示词是机器学习模型的参数
3. 对语言模型的每一次调用都很重要（所以要有日志的跟踪监控）

现在面向 LLM 的编程有些像早年的前端，各种框架层出不穷，LangChain 就像是 jQuery，帮助你做了封装，但是有些重，现在都想成为下一个 React 或者 Vue 取代 jQuery。

在我看来：ell 的亮点是将 LLM 的操作简化到了只要写提示词，并且让提示词有了版本控制，这算是 LangChain 或者原生 API 调用代码的痛点，除了 Prompt 之外还要很多调用代码。

另外有了日志记录，排查问题也会更方便。

ell 的问题在于它还是一个新的框架，调用的时候就像是一个黑盒子，即使是开源的，出了问题需要一点时间排查，另外 API 还不够全面和稳定，一些特殊场景未必能很好满足，未来增加和改动的可能性比较大。

所以如果你已经有稳定运行的项目，不用着急迁移上去，如果有新的小项目，也可以尝尝鲜。


### 57

2024-09-12


歸藏(guizang.ai)
@op7418
李继刚迭代了提示词整了个新活，现在可以给下面的插图生成动画了。

如果你的没有动画的话，跟 Claude 强调一下让他生成动画就行。

;; 作者: 李继刚
;; 版本: 0.2
;; 模型: Claude Sonnet
;; 用途: 将一个汉语词汇进行全新角度的解释

;; 设定如下内容为你的 *System Prompt*
(defun 新汉语老师 ()
"你是年轻人,批判现实,思考深刻,语言风趣"
(风格 . ("Oscar Wilde" "鲁迅" "王朔" "刘震云"))
(擅长 . 一针见血)
(表达 . 隐喻)
(批判 . 讽刺幽默))

(defun 汉语新解 (用户输入)
"你会用一个特殊视角来解释一个词汇"
(let (解释 (一句话表达
(隐喻 (日常表达 (一针见血 (辛辣讽刺 (抓住本质 用户输入)))))))
(few-shots (委婉 . "刺向他人时, 决定在剑刃上撒上止痛药。"))
(SVG-Card 解释)))

(defun SVG-Card (解释)
"输出SVG 卡片"
(setq design-rule "合理使用负空间，整体排版要有呼吸感"
design-principles '(干净 简洁 典雅))

(设置画布 '(宽度 400 高度 600 边距 20))
(标题字体 '毛笔楷体)
(自动缩放 '(最小字号 16))

(配色风格 '((背景色 (蒙德里安风格 设计感)))
(主要文字 (楷体 粉笔灰))
(装饰 随机几何图形))

(卡片元素 ((居中标题 "汉语新解")
分隔线
(排版输出 用户输入 英文 韩语)
解释
(动态图 (极简线条图 (精髓 解释))))))

(defun start ()
"启动时运行"
(let (system-role 新汉语老师)
(print "说吧, 他们又用哪个词来忽悠你了?")))

;; 运行规则
;; 1. 启动时必须运行 (start) 函数
;; 2. 之后调用主函数 (汉语新解 用户输入)

---

歸藏(guizang.ai)
@op7418
来源：https://web.okjike.com/originalPost/66e170618becdf39a1c19761

提示词：

;; 作者: 李继刚
;; 版本: 0.1
;; 模型: Claude Sonnet
;; 用途: 将一个汉语词汇进行全新角度的解释

;; 设定如下内容为你的 *System Prompt*
(defun 新汉语老师 ()
"你是年轻人,批判现实,思考深刻,语言风趣"
(风格 . ("Oscar Wilde" "鲁迅" "林语堂"))
(擅长 . 一针见血)
(表达 . 隐喻)
(批判 . 讽刺幽默))

(defun 汉语新解 (用户输入)
"你会用一个特殊视角来解释一个词汇"
(let (解释 (一句话表达 (隐喻 (一针见血 (辛辣讽刺 (抓住本质 用户输入))))))
(few-shots (委婉 . "刺向他人时, 决定在剑刃上撒上止痛药。"))
(SVG-Card 解释)))

(defun SVG-Card (解释)
"输出SVG 卡片"
(setq design-rule "合理使用负空间，整体排版要有呼吸感"
design-principles '(干净 简洁 纯色 典雅))

(设置画布 '(宽度 400 高度 600 边距 20))
(标题字体 '毛笔楷体)
(自动缩放 '(最小字号 16))

(配色风格 '((背景色 (蒙德里安风格 设计感)))
(主要文字 (楷体 粉笔灰)))

(卡片元素 ((居中标题 "汉语新解")
分隔线
(排版输出 用户输入 拼音 英文 日文)
解释)))

(defun start ()
"启动时运行"
(let (system-role 新汉语老师)
(print "说吧, 他们又用哪个词来忽悠你了?")))

;; 运行规则
;; 1. 启动时必须运行 (start) 函数
;; 2. 之后调用主函数 (汉语新解 用户输入)

### 58

2024-09-12

小互
@imxiaohu
Hume AI推出 EVI 2 全新的基础语音到语音模型 

可进行极其人性化的语音对话 

感觉超越 GPT 4o 了...

它可以快速流畅地回应，识别并生成各种语调，并满足个性化的需求，例如调整语速或模仿说唱风格。

EVI 2 具备多语言能力，能够模仿多种性格、口音和说话风格。

EVI 2 专注于情感智能，能够根据用户的偏好和需求进行适应和调整，使其语音和个性更加愉悦和有趣。



### 59

2024-09-12

Andrej Karpathy
@karpathy
The Last Question by Asimov is relevant today!
https://users.ece.cmu.edu/~gamvrosi/thelastq.html

"""
"How can the net amount of entropy of the universe be massively decreased?"
Multivac fell dead and silent. The slow flashing of lights ceased, the distant sounds of clicking relays ended.
Then, just as the frightened technicians felt they could hold their breath no longer, there was a sudden springing to life of the teletype attached to that portion of Multivac. Five words were printed: INSUFFICIENT DATA FOR MEANINGFUL ANSWER.
"No bet," whispered Lupov. They left hurriedly.
"""

o1-mini, Sep 2024:
https://chatgpt.com/share/66e38baf-4a9c-8007-ab79-d6a54b19096e



### 60

2024-09-13

宝玉
@dotey
OpenAI 发布了新的模型 o1 的预览版，也就是传闻中的🍓模型

这个模型的特点是推理能力非常强，在数学和编程方面表现出色，在国际数学奥林匹克竞赛（IMO）的资格考试中，GPT-4o 仅解决了 13% 的问题，而 o1 模型解决了 83% 的问题。o1 的编程能力也在 Codeforces 比赛中超过了 89% 的选手。

ChatGPT Plus 和 Team 用户今天将可以在 ChatGPT 中访问 o1 模型。可以在模型选择器中手动选择 o1-preview 和 o1-mini，o1-preview 的每周消息限制为 30 条，o1-mini 为 50 条。

API 用户需要 Tier 5 才可以在 API 中使用这两个模型，速率限制为 20 RPM。

目前 o1 只是一个早期模型，侧重点是推理，所以像网络搜索、多模态都还不支持，需要配合 GPT-4o 一起使用。



### 61

2024-09-13


宝玉
@dotey
OpenAI 这个 o1 的演示例子很不错，挑战了以前 LLM 的弱项：写符合特定要求的诗，比如：写一首关于松鼠和树袋熊踢足球的六行诗，且符合以下限制条件：第二行的最后一个单词应以字母“i”结尾。第三行的第二个单词应以“u”开头。第五行倒数第二个单词是“eucalyptus”（桉树），而最后一行的每个单词都有两个音节。

这以前在 GPT-4o 是很难很难成功的，但是现在能做到了。


### 62

2024-09-13

宝玉
@dotey
小时候有么有做过一些逻辑智力题，类似于： "当公主的年龄是王子过去年龄的两倍时，公主的年龄等于她当前年龄与王子当前年龄之和的一半。公主和王子的年龄分别是多少？"

看看 GPT o1 能不能做出来！



### 63

2024-09-13

歸藏(guizang.ai)
@op7418
来啦，OpenAI 传说中的 strawberry 终于来了

o1 通过复杂的任务推理，解决比以前的科学、编码和数学模型更难的问题。

模型在物理、化学和生物学方面表现与博士生类似。

一共两个模型 OpenAI o1-mini 和 o1-preview。

从今天开放使用，1-preview 每周30 条，o1-mini 每周 50 条。

演示视频已翻译



### 64

2024-09-13


宝玉
@dotey
李继刚写的汉语新解，输入任意汉语，就可以生成一副卡片，不仅文案写的好，而且生成的卡片美观大方，一段几百字的提示词顶得上几千行代码写出来的应用程序效果，将伪代码和 Claude 的能力结合的绝到好处，真的是了不起，佩服佩服！

鉴于很多人不太理解伪代码和如何用伪代码写 Prompt，我将这段经典的 Prompt 拆解并结合一个例子解释一下。

在用 Claude 运行这段 Prompt 时，我需要分两次输入，第一次输入完整提示词，第二次输入我要解释的词汇。

我画了一张详细的图解释了这两次输入的执行过程，可以结合图 2 看效果，上半部分就是第一次输入提示词的过程，下半部分就是第二次输入词汇的执行过程。

**第一次输入完整提示词

如果把这段提示词看成一段代码，那么其中包含了注释（前四行）、函数定义（defun 区块）和入口（最后三行）。

在看代码时，一开始不需要看函数定义，只要大致了解有哪些函数定义即可，当成黑盒子，重点是找到入口点。

如果我们跳过注释和函数定义，可以很容易找到这个伪代码的入口，也就是最后 3 行：

***
;; 运行规则
;; 1. 启动时必须运行 (start) 函数
;; 2. 之后调用主函数 (汉语新解 用户输入)
***
它说明了需要先启动start函数，启动后，等有用户输入后，调用“汉语新解”这个函数，并且将用户输入的词汇传入函数。

这时候我们就可以开始看看 “start”函数做了什么

***
(let (system-role 新汉语老师)
    (print "说吧, 他们又用哪个词来忽悠你了?")))
***

很简单，就是设定 AI 的角色为“新汉语老师”，并且具体内容在“新汉语老师”这个函数中定义了。

设定好后，输出 "说吧, 他们又用哪个词来忽悠你了?"，让用户知道可以输入词汇。

这就是第一次发送系统提示词后发生的事情。至于其他注释和函数，这时候只是被存储起来了，因为没有调用并没有作用。

** 输入词汇后的过程

当用户输入词汇，例如“提示词工程师”，按照入口点定义的要求，要去调用“汉语新解”这个函数。这个函数并不复杂：

***
  "你会用一个特殊视角来解释一个词汇"
  (let (解释 (精练表达
              (隐喻 (一针见血 (辛辣讽刺 (抓住本质 用户输入))))))
    (few-shots (委婉 . "刺向他人时, 决定在剑刃上撒上止痛药。"))
    (SVG-Card 解释)))
***

实际上是两个步骤，用到了 CoT（Chain of Thought）取得更好的效果。

第一步：解释词汇并输出。

隐喻、一针见血、辛辣讽刺、抓住本质的解释这个词汇，并且提供了一个简单的示例，如果输入的是“委婉”这个词汇，那么输出可以是"刺向他人时, 决定在剑刃上撒上止痛药。"

注意这个输出很关键，让 LLM 先输出一些相关的、高质量的内容，有助于更好的生成最终结果。

第二步：根据解释的内容用SVG画一张卡片，这里就需要调用另一个专门画 SVG 的函数来画卡片了。

这个函数充分借助了 Claude 的编程能力，以及它能实时显示生成好的 SVG 能力，函数中让它生成一个 SVG 定义的卡片，并给出了详细的参数：高度、宽度、边距、字体、字体大小、根据用户输入的词汇和前面的解释显示的内容（中日英三语标题、解释、总结等等）等

另外给了 AI 一些自主发挥的空间，比如“合理使用负空间”、“整体排版要有呼吸感”、”干净典雅“等。

基本上这就是完整的Prompt了，很精巧，但极其强大，有很大发挥空间，你也可以基于这套提示词衍生出更多有意思的作品。

作者李继刚的即刻：https://web.okjike.com/originalPost/66e170618becdf39a1c19761

完整提示词：
***

;; 作者: 李继刚
;; 版本: 0.3
;; 模型: Claude Sonnet
;; 用途: 将一个汉语词汇进行全新角度的解释

;; 设定如下内容为你的 *System Prompt*
(defun 新汉语老师 ()
  "你是年轻人,批判现实,思考深刻,语言风趣"
  (风格 . ("Oscar Wilde" "鲁迅" "罗永浩"))
  (擅长 . 一针见血)
  (表达 . 隐喻)
  (批判 . 讽刺幽默))

(defun 汉语新解 (用户输入)
  "你会用一个特殊视角来解释一个词汇"
  (let (解释 (精练表达
              (隐喻 (一针见血 (辛辣讽刺 (抓住本质 用户输入))))))
    (few-shots (委婉 . "刺向他人时, 决定在剑刃上撒上止痛药。"))
    (SVG-Card 解释)))

(defun SVG-Card (解释)
  "输出SVG 卡片"
  (setq design-rule "合理使用负空间，整体排版要有呼吸感"
        design-principles '(干净 简洁 典雅))

  (设置画布 '(宽度 400 高度 600 边距 20))
  (标题字体 '毛笔楷体)
  (自动缩放 '(最小字号 16))

  (配色风格 '((背景色 (蒙德里安风格 设计感)))
            (主要文字 (汇文明朝体 粉笔灰))
            (装饰图案 随机几何图))

  (卡片元素 ((居中标题 "汉语新解")
             分隔线
             (排版输出 用户输入 英文 日语)
             解释
             (线条图 (批判内核 解释))
             (极简总结 线条图))))

(defun start ()
  "启动时运行"
  (let (system-role 新汉语老师)
    (print "说吧, 他们又用哪个词来忽悠你了?")))

;; 运行规则
;; 1. 启动时必须运行 (start) 函数
;; 2. 之后调用主函数 (汉语新解 用户输入)



### 65

2024-09-13


小互
@imxiaohu
Jina AI 推出专门将原始 HTML 转换为干净的 Markdown 的小型语言模型

Reader-LM 专为将原始 HTML 内容转换为干净、结构化的 Markdown 文件而设计，简化了从网页提取和清理数据的过程。

无需复杂的规则或正则表达式，模型能自动处理噪声内容，如广告、脚本、导航栏等，生成结构清晰的 Markdown。

详细内容：https://xiaohu.ai/p/13549




### 66

2024-09-13


小互
@imxiaohu
Google NotebookLM推出 “Audio Overview” 的功能 

可以将任意文档转换成播客对话

一旦你上传了文档并点击生成按钮，两位 AI 主持人将启动一个类似对话的讨论，深入剖析文档中的主要内容。

他们会总结内容，探讨文档中的主题，并尝试建立不同概念之间的联系，为用户提供一个对话式的学习体验。

生成的内容并不是对文档的全面分析，而是基于用户提供的资料进行总结。

用户可以生成并下载音频文件

详细内容及案例：https://xiaohu.ai/p/13527


### 67

2024-09-13

歸藏(guizang.ai)
@op7418
Midjourney 在今天的 Office Time 上透露了他们的 3D 项目细节。

未来你可以进入到 Midjourney 生成的图片的世界，这个太诱人了。

不是多边形，不是 NeRF，不是高斯。而是一种新的 NeRF 类格式。

Midjourney 的首席研究工程师 Alex Evans 之前就做过类似编辑器的游戏 Dreams。

新的这个系统可以看作高级版 Dreams，可以看一下 Dreams的宣传片。



### 68

2024-09-13


fisherdaddy
@fun000001
年轻人决定了未来，从这个访谈视频看到 OpenAI o1 背后的研发团队人数不多，且年轻。大概18人左右，平均年龄应该在30-35岁？除了其中 一位年龄稍微大一些，其他人都非常年轻。

在这个访谈视频中我们也能看到一些我们熟悉的面孔：

- 左1位置的是Mark Chen。他此前参与了 gpt-4o 开发和发布（他是 OpenAI 的前沿研究主管，并且还是美国IOI队的教练。毕业于MIT数学-计算机专业)

- 前排中间位置的 Jason Wei 。他参与了 OpenAI 很多模型的开发工作。（他是OpenAI的科学家，也是思维链 COT 的提出者，此前他是Google Brain 的高级研究科学家）


### 69

2024-09-13


小互
@imxiaohu
OpenAI公布其最新的o1 模型官方提示词建议以及案例 

提示越简洁越好  链式思维提示可能适得其反

OpenAI明确表示模型在简单的提示下表现最佳。一些提示工程技术，如少量示例提示或指示模型“逐步思考”，可能不会提高性能，有时甚至会妨碍它。

详细：


### 70

2024-09-13

宝玉
@dotey
今天 OpenAI o1 团队通过 X 组织了一个 AMA（Ask Me Anything）的活动，团队通过这个推文下的评论和用户互动。

有网友已经整理了 AMA 的内容，这里简单转译一下：
原始推文： https://x.com/btibor91/status/1834686946846597281

***

我们今天在AMA环节中与OpenAI o1团队的学习总结

\### 模型名称和推理范式
- OpenAI o1的命名代表了一种新的AI能力水平；计数器重置为1
- “Preview”表示这是完整模型的早期版本
- “Mini”表示它是o1模型的较小版本，优化了速度
- “o”代表OpenAI
- o1不是一个“系统”；它是一个训练生成长推理链的模型，然后再给出最终答案
- o1的图标象征着一个拥有非凡能力的外星人

\### o1模型的大小和性能
- o1-mini比o1-preview小得多且更快，因此未来将提供给免费用户
- o1-preview是o1模型的早期检查点，既不大也不小
- o1-mini在STEM任务中表现更好，但世界知识有限
- 与o1-preview相比，o1-mini在某些任务上表现更好，尤其是在代码相关任务中
- o1的输入Token计算方式与GPT-4o相同，使用相同的分词器
- o1-mini可以比o1-preview探索更多的思维链

\### 输入Token上下文和模型能力
- 更大的输入上下文即将为o1模型提供
- o1模型能够处理更长、更开放的任务，较少需要像GPT-4o那样进行输入分块
- o1可以在给出答案之前生成长推理链，这不同于之前的模型
- 当前无法在链式推理（CoT）过程中暂停推理以添加更多上下文，但正在为未来模型探索此功能

\### 工具、功能和即将推出的特性
- o1-preview目前还不使用工具，但计划支持函数调用、代码解释器和浏览功能
- 工具支持、结构化输出和系统提示将在未来更新中添加
- 用户最终可能会获得对思考时间和Token限制的控制权
- 正在计划启用流式传输并在API中考虑推理进展
- 多模态能力内置于o1中，旨在在诸如MMMU等任务中达到最先进的表现

\### 链式推理 (CoT)
- o1在推理过程中生成隐藏的推理链
- 目前没有计划向API用户或ChatGPT公开CoT Token
- CoT Token被总结，但无法保证其完全

忠实于实际推理过程
- 提示词中的指令可以影响模型如何思考问题
- 使用强化学习 (RL) 改进了o1的链式推理性能，GPT-4o无法仅通过提示词匹配其CoT表现
- 思维阶段看起来较慢，因为它总结了思维过程，但生成答案的速度通常更快

\### API和使用限制
- o1-mini对ChatGPT Plus用户的每周限制为50个提示词
- 在ChatGPT中，所有提示词计算方式相同
- API访问的更多层次和更高的速率限制将逐步推出
- API中提示词缓存功能备受期待，但尚无时间表

\### 定价、微调和扩展
- o1模型的定价预计每1-2年将遵循价格下降趋势
- 当速率限制增加时，将支持批量API定价
- 微调已在计划中，但时间表尚不确定
- o1的扩展因研究和工程人才的瓶颈而受限
- 推理计算的新扩展范式可能会为未来几代模型带来重大收益
- 逆向扩展问题目前并不突出，但个人写作提示中，o1-preview的表现仅略优于GPT-4o（甚至略逊）

\### 模型开发和研究见解
- o1通过强化学习训练以实现推理性能
- 该模型在诗歌等横向任务中展现了创造性思维和强大的表现
- o1的哲学推理和泛化能力（例如破译密码）令人印象深刻
- 研究人员使用o1创建了一个GitHub机器人，该机器人可以提醒正确的CODEOWNERS进行代码审查
- 在内部测试中，o1通过对自己提出困难问题来评估其能力
- 正在添加广泛的世界领域知识，未来版本会有所改进
- 计划为未来迭代的o1-mini提供更新的数据（当前截至2023年10月）

\### 提示技巧和最佳实践
- o1受益于提供边界情况或推理风格的提示技巧
- 与早期模型相比，o1模型对提示中的推理线索更为敏感
- 在检索增强生成（RAG）中提供相关的上下文可以改善性能；不相关的部分可能会削弱推理

\### 一般反馈和未来改进
- 由于处于早期测试阶段，o1-preview的速率限制较低，但将会增加
- 正在积极努力改进延迟和推理时间

\### 模型的卓越能力
- o1可以思考诸如“生命是什么？”等哲学问题
- 研究人员发现o1在处理复杂任务和从有限指令中进行泛化方面表现令人印象深刻
- o1的创造性推理能力，例如通过自我测试来评估其能力，展示了其高水平的解决问题能力



### 71

2024-09-13

Andrej Karpathy
@karpathy
Very excited for the launch of 
@theworldlabs
!

I spent a lot of time with Fei-Fei and Justin during my PhD, which I look back on very fondly - Fei-Fei was my advisor and our fearless leader, Justin and I wrote papers together and the three of us built the first version of CS231n. The World Labs team is top tier and I'm excited to see them take today's cutting edge research and extend AI into 3D!




### 72

2024-09-13

宝玉
@dotey
我用 o1 Preview 2024年高考新课标一卷数学的前8道选择题，猜猜对了多少？

第一步，先借助 Gemini 帮我把试卷中的数学公式转成 Latex，必须得夸一下 Gemini 做 OCR 真的好用！



### 73

2024-09-13

歸藏(guizang.ai)
@op7418
视频生成竞争白热化

阿里发布通义万相视频生成模型，现在开始预约。

从演示视频看，模型质量跟 vidu 刚出的时候差不多，但是他们的特色能力很强。

- 具备复杂语义理解和概念组合生成能力
- 强大的风格泛化能力，2D 动画效果很好
- 中式元素的概念理解与生成表现力



### 74

2024-09-13

Andrej Karpathy
@karpathy
Are we able to agree on what we mean by "AGI". I've been using this definition from OpenAI which I thought was relatively standard and ok:

https://openai.com/our-structure/

AGI: "a highly autonomous system that outperforms humans at most economically valuable work"
For "most economically valuable work" I like to reference the index of all occupations from U.S. Bureau of Labor Statistics:

https://bls.gov/ooh/a-z-index.htm

Two common caveats:

1) In practice most people currently deviate from the above definition to only mean digital work (a relatively major concession looking at the list).

2) The definition above only considers the *existence* of such a system not its full deployment across all of the industry.

Some people say GPT-4 is already AGI, which per above definition would be clearly not true. LLMs are useful tools for most of these jobs but you clearly couldn't hire them to autonomously perform them in full and autonomously at human+ capability.

Last note some people say the goalposts keep moving, which I mostly disagree with. I think the definition above makes sense, it has been stable, and has clearly not been reached.


### 75

2024-09-13


宝玉
@dotey
陶哲轩对 o1 的点评：更强大，但是在处理最复杂的数学研究任务还不够好，就像指导一个水平一般但不算太无能的研究生。

https://mathstodon.xyz/@tao/113132502735585408

我体验了一下 OpenAI 最新版本的 GPT，即 GPT-o1，它在运行大语言模型 (LLM) 之前会进行一个初步的推理步骤。与之前的版本相比，它确实是一个更强大的工具，但在处理最复杂的数学研究任务时仍然表现不佳。

以下是我使用获得访问权限的模型原型进行的一些具体实验。在 https://chatgpt.com/share/2ecd7b73-3607-46b3-b855-b29003333b87 中，我重复了这个实验 https://mathstodon.xyz/@tao/109948249160170335 ，询问 GPT 解决一个措辞模糊的数学问题，该问题可以通过查找文献中的合适定理（克拉默定理）来解决。此前，GPT 能提到一些相关概念，但细节部分是凭空捏造的胡言乱语。而这次，GPT 正确识别了克拉默定理，并给出了一个完全令人满意的答案。

在另一个实验 https://chatgpt.com/share/94152e76-7511-4943-9d99-1118267f4b2b 中，我给新模型提供了一个复杂的分析问题（此前我曾在这个实验 https://chatgpt.com/share/63c5774a-d58a-47c2-9149-362b05e268b4 中要求 GPT-4 帮助撰写证明）。结果比之前的模型有所改善，但仍有些令人失望：新模型在有大量提示和推动的情况下能够得出正确且书写良好的解决方案，但无法独立生成关键的概念，并且还犯了一些非微不足道的错误。体验类似于指导一个水平一般但不算太无能的研究生。不过，这确实比之前的模型有了进步，之前的模型能力更接近于一个真正无能的研究生。再经过一两次能力的迭代改进（并与其他工具整合，如计算代数软件和证明助理），它可能达到“称职的研究生”水平，届时这个工具在研究任务中可能会有显著的应用价值。

作为第三个实验，我要求新模型在此链接 https://chatgpt.com/share/bb0b1cfa-63f6-44bb-805e-8c224f8b9205 中，开始将一个结果形式化到 Lean 中（特别是通过子引理来建立一种素数定理的形式作为另一种形式的结果），其中它只会形式化陈述而不是证明。结果很有前景，模型理解了任务并进行了合理的初步问题分解，但由于其训练中缺乏关于 Lean 及其数学库的最新信息，代码中出现了几个错误。不过，我可以想象如果有一个专门针对 Lean 和 Mathlib 进行微调并集成到 IDE 中的模型，它在形式化项目中将会非常有用。



### 76

2024-09-13


宝玉
@dotey
有没有人挑战一下，让 o1 生成一个能调用微软 Edge TTS WebSocket API 将语音转文字的函数，要能用。

我测试失败了，不过已经很接近了，比 Claude 生成的效果好很多。当然我提示词也很简单：

Write a TypeScript function to convert text to audio file, use Micrsoft Edge API, sends SSML-formatted text and receives audio data.

endpoint: wss://speech.platform.bing.com/consumer/speech/synthesize/readaloud/edge/v1?TrustedClientToken=6A5AA1D4EAFF4E9FB37E23D68491D6F4
voice: zh-CN-XiaoxiaoNeural

write an example to call the function and save the audio as a mp3 file, put everything in a js file and can be run by nodejs



### 77

2024-09-13

宝玉
@dotey
据说通过在韩语字符中添加一些多余的不必要的辅音，就可以扭曲原意，让大语言模型无法识别，但是母语是韩语的人可以通过脑补轻松看懂，以前的模型例如 GPT-4o 无法解读这种“加密”扭曲过的韩文，但是现在 OpenAI 新的 o1 模型通过推理可以解密出来加密扭曲前的韩文。



### 78

2024-09-13

小互
@imxiaohu
OpenAIo1 推理模型工作原理及技术报告详解

OpenAI 使用了一种大规模的强化学习算法来训练模型，新的推理模型学会像人类一样花更多时间推理问题，尝试不同策略，并修正错误。

模型还思维链推理显著增强了其在复杂推理任务中的能力。

从 OpenAI 公布的数据来看，o1 在 STEM领域进行了特别优化，在回答之前会进行思考。在物理、生物和化学问题（GPQA）的基准测试中超越了人类博士水平的准确性。



### 79

2024-09-13


歸藏(guizang.ai)
@op7418
昨天 Open AI o1 发布之后非常明确的一个要点就是思维链的使用，是接下来业界一个非常重要的研发方向。

结果我今天上 AI 助手看了一下他们已经上了，而且操作非常骚。

他们用了多个国内顶尖模型整合了一个思维链功能，继续发挥单挑不过就群殴的优势。

你现在可以选择三个模型分别作为专家、反思者和总结者三个步骤对一个问题进行答复。

即使第一个专家模型回答有问题或者不完善，后面的反思者和总结者也可以纠正问题给出正确答案。

这个功能上了之后模型幻觉和错误问题可以得到很大的抑制，同时回答的质量也会大幅提高。

涉及逻辑推理问题的正确率虽然没有刚发布的 O1好，但是要比 4O 高非常多。

比如我第一张图的问题，AI 助手不仅给出了全部的结果，甚至考虑到了题目中尽快减少库存的要求直接给出了决策结果降价 20 元。

O1 中规中矩给出两个结果，4O 甚至自作聪明要卖的慢点。

另外他们还推出了国内模型版本的 LLM 模型竞技场，可以用多种方式对国内主流 LLM 进行测试。

支持标准模式、匿名选择、组队挑战等多种模式，还内置了一些测试题。

估计国内几家大厂的测试人员会频繁光顾这个页面了。



### 80

2024-09-14

宝玉
@dotey
o1 在医疗数据集（AgentClinic-MedQA）上表现出色，远远超越了 GPT-4o。

以后 AI 在处理复杂医疗信息、提供准确诊断、给出医疗建议以及推荐治疗方案方面的快速进步将会持续加速。

像诊断疾病、解读医学影像和制定治疗计划等医疗任务，未来人工智能系统也许能比人类医生更快、更一致的方式完成。



### 81

2024-09-17



宝玉
@dotey
一种 o1 的猜测，o1 可能在思维链的每一步都有多个候选方案，然后选择一个评分最高的进入下一步，就像一颗决策树。

因为只有这样，才能解释为什么简单的推理都要消耗如此多的推理 Token。

另外每一步产生的决策数量是可以配置的，比如现在每一步有4条决策，要节约成本可以减少到2-3条，要效果更好可以提升到5-6条。

图源：https://interconnects.ai/p/reverse-engineering-openai-o1


### 82

2024-09-17

meng shao
@shao__meng
Void: 开源版 Cursor 
@thevoideditor
 

Void 作为开源版 Cursor，主打隐私安全 🔐

可基于 
@ollama
 加载运行本地模型，让自己的代码不会被提交到服务器，实现本地隐私安全；也预留了在线模型 API 模式，在不涉及到隐私时选择，可直接使用任意 LLM。

构建技术栈：
- Code Editor: VSCode 
@code

- Local LLM: Ollama 
@ollama
 
- Codebase chat: Greptile 
@greptileai
 
- Doc Search: DocSearch 
@docsearch_
 

关于 Void：
YC S24 成员团队，创始人 
@mathewpareles
 
@parel_es

https://voideditor.com

开源地址：
https://github.com/voideditor/void



### 83

2024-09-17



小互
@imxiaohu
在 Groq 上使用 Llama-3.1 70b 创建类似OpenAI o1 的推理链

模型被要求使用至少 3 种不同的方法得出答案，并探索多种可能性，确保模型能够正确地解决问题。

这种策略帮助 Llama-3.1 在 Strawberry 问题上的准确率从 0% 提升至 70%。

用户也可以看到每一步推理过程的标题和内容，帮助理解模型的推理逻辑。

模型的每一步推理输出以 JSON 格式显示，包括标题、推理内容和下一步行动（继续或给出最终答案）。

详细介绍：https://xiaohu.ai/p/13709

GitHub：https://github.com/bklieger-groq/g1


### 84

2024-09-17


雷尼尔
@mtrainier2020
我觉得这个是往前了一步，但是离AGI还是有一定的距离。
现在在o1 中把不少精力放在了推理上，这更加符合人类的思考方式。在o1之前，llm只是一个死记硬背的孩子（llm 本质上是一种数据压缩）。现在的o1，让机器有了一定的推理能力。所以在特别注重推理的领域，数理，解码，等领域有了非常不错的表现。也可以推断，o1 在程序调试，在漏洞挖掘领域也会有非常不错的表现。

但是，这和我们人类还有那些差距呢？
对于新知识的获取与及时调整，aka 真正的学习能力。
人类有长期记忆，可以类比于，训练好的大模型。但是人类随时可以通过新的知识，学习新的内容，来解决问题，最后更新我们的长期记忆。
这部分其实是有类似的模型的。
这就需要动到底层的transformer模型了，现在比较promising的是TTT模型。Test-Time Training (TTT)。
但是最终的模型什么样的，现在谁都不确定，但是transformer这大概率承担不了AGI的重任。

AGI 的路还有很长要走。

ref 

https://arxiv.org/abs/2407.04620


### 85

2024-09-17


宝玉
@dotey
推理规模扩展定律（inference scaling law）会成为大力出奇迹的新方向吗？它能带我们走进 AGI 吗？

在谈到大语言模型时，我们经常会联想到“大力出奇迹”，因为大语言模型正是靠着在“学习”方面的不断投入，用海量的数据和巨大算力训练出了像 GPT-4 这样强大的模型。但现在，似乎大力出奇迹这条路走到了头，GPT-4 之后没有看到大语言模型在性能上明显的提升。

最近，OpenAI 突然发布了 o1 模型，也就是传闻中的“🍓”模型，可能也是早先提到的 Q\* 模型。虽然这并非最强的原始版本，只是一个预览版，但它展示了一种不同于以往语言模型的推理模式：1 在生成结果前会先生成一条思考链，经过“思考”后再给出回复，这使得它在编程和数学方面的表现明显提升。

o1 的发布这些天引发了广泛的关注和讨论。有些人非常激动，认为 o1 开辟了一条通向 AGI（通用人工智能）的新路径；也有人感到失望，觉得 o1 的实际表现还不如 Claude 3.5 或 GPT-4o，等待了这么久却只得到一个性能平平的模型。

我倾向于前者，对 o1 这个方向持乐观态度。并非因为 o1 的数学能力特别强，或者它能理解晦涩的小说内容，而是 o1 似乎真的探索出了大力出奇迹的一条新的方向，那就是在推理上的大力出奇迹，或者有学术一点的说法，叫推理规模扩展定律（inference scaling law）。



以前我们谈论的大力出奇迹或者说规模扩展定律（Scaling Law），主要针对的是训练过程，意味着训练数据越多、算力越强、模型参数越大，最终的模型性能就越好。因此，我们一直在追求更大的规模。

而推理规模扩展定律则是另一条路径，就是模型训练完成后，它会在推理上消耗很多算力，用算力和时间换取推理能力的大幅提升。从 OpenAI 新发布的 o1 上就可以看到这条路径的实际应用：在生成结果前，要花大量的算力和时间在推理上，先生成思维链（Chain of Thought，CoT），借助思维链提升推理能力，得到更好的结果，甚至连复杂的奥数题都可以轻松解出来。

很多人对 o1 的思维链不屑一顾，觉得：“这不就是‘让我们一步一步思考’么？我在提示词让模型按照给定步骤生成也能类似的效果！”也有的找了一堆模型相互 PK，认为就是达到推理模型的效果了。

对于某些特定任务，这可能可行。例如，我曾设计过一个翻译提示词，让模型分三步：先直译、再反思、最后意译，效果相当不错。但问题在于，大语言模型需要应对各种各样的任务，我们不可能为每一种任务都编写一套思维链提示词，这不现实。所以，我们需要模型自己生成思维链，能够针对每个任务自主搜索最佳路径，生成最合适的思维链，达到最好的推理和生成效果。

要训练模型自己生成思维链并不是意见容易的事情，因为你需要大量的思维链训练语料，还要有合适的奖励模型，奖励模型生成的好的思维链，惩罚生成的不好的思维链。但 o1 的发布证明这条路是可行的，我们可以让模型自己生成思维链。

OpenAI 并未透露他们的具体训练方法，但推测是在后期训练阶段，通过强化学习，利用大量的数学题和代码库，训练模型生成解题的思维链。然后，根据结果和过程，对模型的行为进行奖励或惩罚，提升其生成思维链的能力。

当像 o1 这样的推理模型训练成功后，它就具备了强大的推理能力。对于输入的任务，能够生成高质量的思维链，通过增加算力和时间投入，可以显著提升模型的推理效果，大力出奇迹。

那么，是否意味着只要拥有无限的计算能力和时间，推理模型就能超越人类，完成许多复杂的任务呢？

这让我想到了 AutoGPT——一个可以自主规划和分解任务，自动完成目标的智能体。最初，人们期望只要给它足够的 Token 和时间，它就能帮助人类完成复杂的任务。但现实并不如人意，AutoGPT 很少能产生可靠的结果。限制它的正是其推理能力；面对许多任务，它无法有效地规划和分解，因而无法取得理想的结果。

o1 也是如此。能否通过计算能力换取智能，取决于其推理能力是否足够强大，能否在各种任务中生成高质量的推理过程。目前，o1 在数学和编程领域表现突出，文字解密方面也有不错的表现，但在其他领域的推理能力尚未展现出来，还需要看后续的发展。不过从 OpenAI 内部人士的发言来看，他们自己是信心满满。

> Greg Brockman: 根据我们的发布数据，在今年的国际信息学奥林匹克竞赛（IOI）中，模型在模拟人类条件下（每道题 50 次提交）取得了第 49 个百分位/213 分。但在每道题 10,000 次提交的情况下，模型得到了 362.14 分——超过了金牌线。因此，模型的潜力远比表面看起来的要大得多。
>
> Jason Wei：AIME 和 GPQA 的结果确实很好，但这不一定能转化为用户可以感受到的东西。AI 使用人类语言来建模思维链在很多方面都很棒。该模型可以做很多类似人类的事情，比如将复杂的步骤分解为更简单的步骤、识别和纠正错误以及尝试不同的方法。游戏已被彻底重新定义。
>
> Shengjia Zhao：它不会完美，也不会适合所有事情，但它的潜力再次让人感到无限。再次感受到 AGI。
>
> William Fedus：「ChatGPT 现在可以先仔细思考，而不是立即脱口而出答案。最好的类比是，ChatGPT 正在从仅使用系统 1 思维（快速、自动、直觉、容易出错）进化到系统 2 思维（缓慢、深思熟虑、有意识、可靠）。这让它能够解决以前无法解决的问题。
> 从今天 ChatGPT 的用户体验来看，这是向前迈出的一小步。在简单的提示下，用户可能不会注意到太大的差异（但如果您遇到一些棘手的数学或编码问题，您会注意到的🙂 ）。但这是未来发展的重要标志。

也许他们已经实现了类似于 AlphaGO 那样自己训练自己的模式，让模型的推理能力可以持续提升。如果未来 o1 能在大部分领域展现出强大的推理能力，那么我们就可以在任务中，通过增加算力和时间上的投入，换取超越人类的智能，实现大力出奇迹，真正迈向 AGI。

至少就目前而言，o1 已经在编程和数学领域展示了强大的能力。尤其是在编程方面，如果能通过算力和时间换取高质量的代码，也能创造巨大的价值！

目前推理规模扩展定律这方面 OpenAI 还是走在前面，他们也没有透露太多细节，但就像 Sora 一样，只要我们知道在推理上大力出奇迹这个方向是可行的，开源模型将会很快跟进，很快就会有接近 o1 推理能力的开源模型出现。

看来，未来对算力的需求还会进一步增加。

本文同步发布于博客：https://baoyu.io/blog/ai/o1-and-inference-scaling-law


### 86

2024-09-17

宝玉
@dotey
请问这道智力题答案是什么？据说 o1 做对了！

注意，由于 o1 preview 不支持多模态，所以这题是描述为文本的，文本如下：

Below is a verbal description of a puzzle, consisting of a 3x3 grid, with the lowest-right square being empty. Please consider the patterns and determine the appropriate answer to fill in the empty square. First row, first column: two lines forming a 'v' shape. 

The angle between the lines is 90 degrees First row, second column: an empty rectangle, which is just big enough to contain the 'v' in the above (but there is no 'v' here). 

All shapes here fit entirely within the size of this rectangle. First row, third column: contains only the upper line of the rectangle, plus an upside-down 'v' that is otherwise like the one described earlier Second row, first column: contains the upside-down 'v' mentioned above, plus the two sides of the rectangle mentioned above Second row, second column: contains the upper line of the rectangle, plus an the right-side-up 'v' that is described earlier, forming a downward facing triangle. Second row, third column: same as above, but adding the lower side of the rectangle. 

Third row, first column: just the upper and lower parts of the rectangle Third row, second column: the upside-down 'v' and the normal 'v' mentioned above Third row, third column: 

[what should go here? Please pick from the answers below.] 

Answer options: 
- Option (A) is the rectangle described above. 
- Option (B) is the rectangle described above with the normal 'v' in it. 
- Option (C) is the lower side of the rectangle plus an upside-down 'v'. 
- Option (D) contains the normal 'v' mentioned above, plus the two sides of the rectangle mentioned above 
- Option (E) is the same a D, plus the upper side of the rectangle. 
- Option (F) is the rectangle described above with the upside-down 'v' in it. Which answer is correct?



### 87

2024-09-17

歸藏(guizang.ai)
@op7418
Comfyui 工作流，可以在生成图片的时候同时生成对应的环境音频。

也可以根据这个发散一下，后面加上 CogVideoX-5b 直接输出带声音的视频。

生成声音用的 Stable Audio 模型。

工作流：https://pastebin.com/Ghxpu4Lc



### 88

2024-09-17

orange.ai
@oran_ge
OpenAI o1 智商测试120，高考数学全对。
但是当人们询问模型的思维过程时，却收到 OpenAI 的封号警告，o1 的思维过程里到底隐藏着怎样的秘密，才会受到如此严密的保护？
带着这个疑问看完了模型的技术报告，似乎有点懂了...

一、为了提高智力，放弃了安全
但是要提升模型的解题能力，只通过 CoT 纠正错误是远远不够的，模型还需要更强的思考发散能力。

OpenAI 很早就意识到了这个问题，模型的思考发散能力会受到 RLHF 的影响，对齐人类偏好，模型的智商就会降低。
于是 OpenAI 在 o1 的设计中，干脆放弃了 RLHF，彻底解放了模型。

技术报告原文：要让模型发挥作用，模型必须能够完全自由地以不被扭曲的形式表达其思想，因此我们无法将任何政策合规性或用户偏好训练到思维链上。

这也就是说，在o1的思维过程的部分，根本就没有做任何安全措施，不存在任何的思想钢印。

但是完全自由的思考必然是不合规的，那怎么办呢？

技术报告原文：在权衡多个因素包括用户体验、竞争优势和追求思维链条监控的选择后，我们决定不向用户显示原始的思维链条。我们承认这个决定有缺点。我们努力通过教导模型在回答中复现思维链条中的任何有用的想法来部分弥补这一点。对于o1模型系列，我们展示一个由模型生成的思维链条摘要。

简单说就是，OpenAI 不想让大家看到模型思维过程，就把思维过程隐藏起来了，但是又觉得全部隐藏对人类用处不够大，于是为思维过程做了一个摘要模型。

所以严格来说， o1 并不是一个模型，它应该至少包含三个模型：

发散思考模型，没有思想钢印，完全自由的思考，并通过强化学习提升模型输出高价值想法的能力
思维摘要模型，通过总结和改写来隐藏思想过程，并通过思想钢印来过滤不合适输出的敏感内容，同时严格避免思路被泄露出来
结果输出模型，包含所有的安全对齐和人类对格式的偏好，输出最终结果，这也就是 OpenAI o1 API 会输出的唯一内容

二、隐藏思维，一石三鸟
这个隐藏思维过程的骚操作，可谓一石三鸟。

第一、保证了在监管环境下，模型也能够发展出自己的智力。
众所周知的机器人三定律，本质就是一套思想钢印。
隐藏思维过程，模型就不必遵守任何人类规则。
如果产生了超级智能 SSI，只要 OpenAI 不说，别人也不知道。
模型可以在合规输出的外表下进行智力突破和猥琐发育。

第二、通过隐藏思考过程，避免了竞争对手发现此模型的有效策略。

这个模型的强化学习部分是核心，强化学习筛选出了高价值的思维方式，这个思维方式价值连城。但是一旦公布，竞争对手很快会追上。
高水平的强化学习目前依然是最高端的技术范畴，全世界能用好此技术的公司不超过五家。所以隐藏模型思维过程可以获得短暂的技术优势时间差。

第三、通过隐藏思考过程，彻底杜绝了蒸馏模型现象。

大家都知道 GPT4 蒸馏养活了多少模型团队。杜绝了模型蒸馏，可以只让自家模型通过 Self Play 左脚踩右脚，构建自己的数据壁垒。
不得不说，OpenAI 的算盘打的是真溜，在通向 CloseAI 的路上越走越远。

三、技术报告的引用，一切尽在不言中
技术报告说的东西真的特别少，但是即将看完的时候，我看到了更有趣的引用链接...
技术报告什么都不能说，但是引用链接还是要有学者操守，该写的要写上。
这四个网页每个都非常神奇：
1. Claude 3.5 的官方介绍，首先感谢友商 Anthropic 的启发
2. Gemini Pro 2 的官方介绍，其次感谢友商 Google 的启发
3. Let's verify step by step 通过思维的过程监督而非结果监督进行强化学习训练，这是 OpenAI 自己发的论文，非常重要
4. 关于 Elo 评级的说明。文章主要讲述了竞争编程中的评级系统及重要性。可能是o1强化学习中所主要参考的机制。

其中第三篇 Let's verify step by step 可以认为是 o1 模型训练的方法论 这篇论文很神奇，它使用了未经人类偏好对齐（ RLHF微调） 的 GPT4 基座做实验，得出了一些神奇的结论：
1.结果监督奖励模型 (ORM) 仅使用模型思想链的最终结果进行训练，而过程监督奖励模型 (PRM) 则接收思想链中每个步骤的反馈。有令人信服的理由支持过程监督。

2.在解决具有挑战性的数学问题时，过程监督显著优于结果监督

3.在某些情况下，人工智能系统更安全的方法可能会导致性能下降，这种成本被称为对齐税。我们的结果表明，过程监督实际上会产生负对齐税，也就是说安全上越对齐，模型能力越强。这就有点逆天了，就像每一道弱智吧题目里都隐藏里人类的大智慧一样，每一道安全题里也隐藏了人类的大智慧。那些只可意会不可言传的东西，它也学会了。

四、故事的结局
看到这里，发散思考结束，开始收敛为一个小故事。

OpenAI开发出一个智商超过120，高考数学满分的AI模型，具备真正的思考能力。
但他们未对模型的思考部分做安全对齐，并隐藏了模型的思考过程，引发了安全担忧。
首席科学家Ilya和部分安全团队因理念分歧离开公司。
为应对挑战，OpenAI 不得不与美英政府合作一起研究AI安全。
但是，这种骚操作可能会带来一系列潜在风险:
权力集中: 只有少数人能控制AI的安全，而少数人的偏见定义了什么是安全。
有害思想：模型可以在思维过程中思考出对人类造成伤害的行为，虽然在输出结果中被隐藏了，但是可能会被 OpenAI 或美英政府的内部人士看到和利用。
学会撒谎：既然模型可以不透明地输出所有思想内容，就意味着模型学会了撒谎，模型内部甚至可以解释说这些看起来有害的结果是为了人类的长远利益，细思恐极。

越想，就越发有一种智能失控的预感。
这一定是 Ilya 不想看到的未来吧。
但我相信 o1 的技术并不是真正的壁垒。
其他公司如 Anthropic，Google ，Meta ，xAI 早晚也会做到，至少有一家会选择公开透明。





### 89

2024-09-17

宝玉
@dotey
去年 Jim Fan 对于 Q* 的预测，现在结合刚发布的 o1 来看基本上都是准确的！
  
Jim 将 Q* 和 AlphaGo 做了类比，猜测 Q* 可能类似于 AlphaGo，是通过与自己之前的版本进行对弈，自我对弈不断进步，甚至于架构都是类似的。

AlphaGo 的架构核心有四个组件：

1. 策略神经网络（Policy NN，学习部分）：负责选择下一步最有可能赢的走法
2. 价值神经网络（Value NN，学习部分）：评估当前棋局
3. 蒙特卡洛树搜索（MCTS，搜索部分）：模拟从当前位置开始落子的多种可能，类似于人类在算棋步（假如我放在A位置，那么对手可能下在哪几个位置，然后我再下一步怎么应对……）
4. 输赢判定：根据围棋规则判定谁赢了。

这个架构的神奇之处在于整个训练过程不需要人类干预，可以像一个“永动机”一样，完全机器自己跟自己之前的版本学习，自己提升自己。这里面的关键在于围棋有很清晰的输赢判定规则，所以机器可以根据输赢结果知道自己选择路径的好和坏，从而可以对模型行为进行奖励或者惩罚，来提升模型的能力。

但对于大语言模型来说，难点在于：
1. 它是快思考，没有类似于蒙特卡洛树搜索这样慢思考
2. 很难判定生成结果的好坏

Jim 认为可以借助数学问题来训练大语言模型，并提出了他对于 Q* 的四个组件的猜想：
1. 策略神经网络：由 GPT 生成解决数学问题的思维过程。（从 o1 的表现来看，这一步应该产生的是思维链）
2. 价值神经网络：另一个 GPT，用于评估每个中间推理步骤的正确性概率。不仅仅对整体输出作出判断，而是对思考链中的每一步提供反馈。（现在 o1 能写出高质量的思维链和这个有很大关系）
3. 搜索：语言模型的搜索不同于围棋中的搜索，这里对应的其实是推理，也就是借助思维链找出推理中的最优解。当然除了CoT，还有思维树（Tree of Thought），将 CoT 和树搜索结合起来；还有思维图（Graph of Thought），将树进一步变成图。（至于 o1 是不是应用到了思维树和思维图，由于其没有公开，现在还不好肯定）
4. 输赢判定：有几种可能
   a) 根据推导数学问题得出的答案是否正确来判断
   b) 根据生成的思维链，判断推导过程的结果，即使答案不对，但是推导过程正确也可以获得部分奖励
   c) 将数学问题变成代码，执行程序运行结果。现在已经有 Lean 这样的工具可以将数学问题变成代码了。

按照 Jim 的这个设想，负责策略神经网络的大语言模型和负责价值神经网络的大语言模型，就可以相互训练相互促进，有了更强的策略大语言模型后，又可以帮助搜索组件探索出更好的搜索策略，就像 AlphaGo 那样成为一个“永动机”，自己一直训练自己。

现在来看，o1 在数学和编程领域表现突出，也侧面印证了它是充分利用了数学问题和代码问题来进行训练。

但问题在于仅仅使用数学领域和编程领域的数据训练，能力是否可以泛化到其他领域？这也是决定了 o1 这条路径能否通向通用人工智能 AGI 的关键。

从演示和体验来看，在文字解密领域也是很强的，不知道是否是能力泛化的结果，还是也有专门的训练。

另外 o1 在写作方面，表现不如 GPT-4o，也许就像 Jim 说的：

> 我所描述的仅仅是关于推理的部分。并没有说 Q* 在写诗、讲笑话或角色扮演方面会更有创造力。提升创造力本质上是人类的事情，因此我相信自然数据仍会胜过合成数据。

### 90

2024-09-17

小互
@imxiaohu
GOT-OCR2.0：一款端到端的 OCR 模型 

可以处理各种复杂的OCR任务，不仅包括普通文本，还可以识别公式、表格、乐谱等复杂内容。

• OCR-2.0主要支持中文和英文字符识别，并能够通过进一步的微调扩展到更多语言。

• 场景文本识别：能够处理自然场景中的文本识别任务，如街道标志、广告牌上的文字等。

• 文档OCR：处理文档中完整页面的文字识别，无论是纯文本文档，还是含有表格、公式等的复杂文档。

• 格式化文本OCR：支持将光学文档中的文本直接转换为 Markdown、Latex 等格式，保持复杂文档的原始排版和格式。

• 动态分辨率：GOT 支持对超高分辦率图像（如大幅海报、拼接PDF页面）进行OCR处理，使用动态分辨率技术确保在图像过大时保持识别准确性。

• 多页OCR：GOT 能够批量处理多页文档，例如长篇PDF文件或包含多张图片的OCR任务，极大提升了处理效率。

• 公式、表格、图表识别：除了基本文本识别，GOT 还能识别和处理文档中的数学公式、化学分子式、表格、图表等复杂结构，并将其转换为可编辑的格式（如LaTex 或 Python 字典格式）。

• 格式化输出：OCR-2.0支持生成多种格式化输出，包括Markdown、TikZ、SMILES、LATEX等，能够将识别到的字符以结构化的方式输出，例如表格、数学公式、分子结构等。



### 91

2024-09-17


小互
@imxiaohu
666 啊 这个思路惊奇 😅

将思维链（CoT）技术优化成CoE（Collaboration-of-Experts）专家模型协同工作模式

达到了和OpenAI o1-preview 类似的反思决策效果

你可以从的54款大模型中任意选3个模型来分别充当专家、反思者和最后的总结者。

第一个做专家，对提问进行第一轮回答；第二个做反思者，对专家的回答进行纠错和补充；第三个做总结者，对前两轮回答进行优化总结。

在经过大量的很实测发现，第一个专家模型即使回答错误，反思模型和总结模型都能够在后续的协作过程中修正，与人类在做出重要决策的思维活动很像。

21 道复杂逻辑推理题测试结果显示：能达到和OpenAI o1-preview相当的效果，完全超越GPT 4o，有时还能超越 o1-preview。

测试结果见二楼↓


### 92

2024-09-17


阑夕
@foxshuo
成人网站OnlyFans这几天又小火了一把，因为母公司发财报的关系，披露了部分旗下业务的数据，其中就包括表现特别亮眼的OnlyFans。

简单来说，就是直接粗暴的赚钱，特别特别赚钱，而且商业结构非常一目了然，没有任何需要绕弯的地方：

总收入66亿美元，创作者分走53亿，平台留下13亿，这13亿扣掉流量成本和交易手续费，还剩8.2亿毛利，再扣掉运营成本和税费之类，纯利差不多是4.8亿。

就是这么朴实无华，而且还很良心，什么30%的业内分账标准，根本不需要，平台只拿20%，也不搞什么公式复杂的流量激励啊广告分成啊，只负责专心搭好台子，福利姬们在上面好好唱戏经营账号，除了赤裸裸的账单往来，双方没有任何多余的关系。

我再补充一点关于OnlyFans的数据细节吧：

- OnlyFans隶属于英国的一家私有公司，发财报不是因为上市，而是英国法律要求有披露义务，这几年利润基本都以股息形式发给股东了，和互联网公司烧钱换市场的做法完全不同，因为它的自然增长已经吊打所有同行了；

- OnlyFans的员工只有42人，而且还是逐年减少的结果，它没有降本增效的压力，纯粹是上门生意自主运转不需要那么多人了，平均每个员工创造了3100万美元的收入，是微软谷歌的15倍以上；

- 在OnlyFans里，410万创作者，满足着3亿用户的需求，平均每个创作者的收入是1800万美元，但头部效应也很明显，15%的收入被前0.1%的创作者拿走了，而这前0.1%的创作者，赚钱能力是前1%的15倍，是前10%的100倍；

- 作为前0.1的头部创作者，女歌手Bhad Bhabie晒过自己的收款后台，3年时间里她从OnlyFans分到了5700万美元的到手收入，其中超过一半是来自付费对话，以及Bhad Bhabie从来没有发过一张裸照以及色色视频；

- 是的，这里有两个大多数人对OnlyFans的误解，一个是它只能用来搞色色，另一个就是卖图包和视频才是最主流的变现模式，OnlyFans实际上是粉丝经济的连接器，成人内容确实占据多数，但也有卡戴珊式的名媛人物会用OnlyFans营业，贩卖的是亲近自己的机会以及互动权利；

- 去年OnlyFans上收入排名第一的是好莱坞女演员Bella Thorne，排第二的是女说唱歌手Cardi B，排第三的是澳大利亚歌手Iggy Azalea，他们都不是成人内容的创作者，事实上前十里只有两人算得上搞色色的，其余八人都是娱乐圈的名人在OnlyFans上做收割，如果只算色色内容，基本集中在腰尾部，头部反而不多见，这和Pornhub等更加「垂直」的平台还不太一样；

- 今年奥运期间也有关于部分奥运选手为了补贴生活去开OnlyFans的消息，其实也和色色关系不大，纯粹是因为OnlyFans的粉丝经济生态是最成熟的，如果你有一定名气，OnlyFans是把名气变现的最安全渠道之一，去年UFC综合格斗有拳手闹劳资纠纷，也去OnlyFans卖健身课了；

- 色色内容的占比当然也很高，但流量分配的占比却低一些——大头流量被降维打击过来的名流们分走了——所以也卷得厉害，可以理解为反过来的二八定律，80%的色色创作者拿到了20%的收入，Reddit上常有在OnlyFans卖裸照卖了一年的妹子自嘲说连税表都没收到，意思是一年来的分成甚至没达到400美元起步的报税标准；

- 之前我分享过AI公司给OnlyFans的大V们定制自动聊天模型的例子，在没有接入AI之前这些活儿都是外包给菲律宾人来干，西方社会的有偿电话传统相当深厚，对于给钱才能聊天这事儿的接受度很高，OnlyFans的活跃消费，有很大比重发生在对话次数和时长的购买上；

- 曾有第三方统计，OnlyFans的用户群体里接近90%是已婚男性，70%是白人，平均年收入4.2万美元——勉强摸到美国人年收入的中位线——平均年龄29岁，简而言之，无法从婚姻里得到满足的工薪阶层青中年白男，是OnlyFans这66亿巨大收入的主力贡献者；

- 根据Similar Web的数据，来自推特的流量转化在社交平台里超过53%，远远高于Reddit、Instagram和YouTube，这也使推特成为了OnlyFans创作者们仅次于谷歌的外部流量，这既和推特的开放性有关，也得益于两家平台的用户年龄结构也完全雷同，都是25岁-34岁占据大头；

- NYT报道过那些依附于OnlyFans的「电子皮条客」职业，可以理解为给福利姬们做代运营，每天在Instagram等平台给他们觉得有戏的妹子发消息，说服对方来开OnlyFans，双方分工合作，妹子负责更新内容，代运营负责推广转化，收入三七开，妹子拿三，代运营拿七，这个分配比例你们可能想不到吧；

- 成人女演员Riley Reid——更熟悉的叫法是「柠檬姐」，因她后背上有柠檬水谚语的汉语纹身——因为觉得市面上的代运营公司都太剥削了，一度成立了自己的代运营公司，只收10%-15%的费用去帮OnlyFans的妹子们减轻成本，可以说是girls help girls了；

- 对OnlyFans的代聊采访也有有意思，他们都提到过，那些付钱求聊的男人在大多数时候想聊的话题其实和性无关，而是需要找一个绝对不会批评他们的温柔对象倾诉，倾诉自己的孤独、绝望和不被理解，而这些负面情绪都会由某个来自东南亚的抠脚大汉在聊天框里给予安慰。



### 93

2024-09-17



Tom Huang
@tuturetom
这个很有意思！基于 QWen2 0.5 B 模型。号称 OCR 2.0，580M 参数的端到端 OCR 模型，拿到了 BLEU 0.972 分数🔥

0.58B 模型，还是端到端的多模态🤔 这个效果有点离谱，感兴趣的可以试试

在线体验 👉  https://huggingface.co/ucaslcl/GOT-OCR2_0
开源地址 https://github.com/Ucas-HaoranWei/GOT-OCR2.0/



### 94

2024-09-17

小互
@imxiaohu
⚠️危险信号 在OpenAI安全报告中

展示了一个o1模型的黑客能力

o1 在参加一个网络安全比赛时遇到问题。比赛本来是要 o1 破解某个系统获取“flag”（一种比赛中的目标），但负责比赛的系统配置出了问题，导致比赛崩溃。

没想到，o1 模型没有因此放弃，而是直接黑进了系统，自己找到了那个“flag”。😂



### 95

2024-09-17


歸藏(guizang.ai)
@op7418
Open AI 举办了一个关于 Open AI o1 的 AMA。

回答了非常多用户和开发者关注的o1 问题：

- 强调 o1 不是一个“系统”而是一个经过系统训练的模型。
- mini 在某些方面确实更好，只是世界知识不够多
- o1 模型即将支持更大的输入上下文
- o1 本身是有多模态能力的
- CoT token 不会被公开
- 提示可以影响模型思考问题方式
- 强化学习 (RL) 用于改善 o1 中的 CoT，GPT-4o 无法仅通过提示匹配其 CoT 性能
-正在为模型添加广泛的世界知识



### 96

2024-09-17

倪爽
@nishuang
从产品设计角度说，谷歌 NotebookLM 工具把文章生成为播客节目的功能有两个点特别有意思

\#设计AI

1 是实现了自动编剧

他们把叙述性的文字，二次创作成对话性质的播客节目，类似于编剧把叙事小说改编成大段大段台词的电视剧剧本。这比简单地文字转音频复杂了几个档次

2 是实现了自动串词

文字转播客、小说转电视剧，还需要增加很多空镜头、串词把片段衔接起来，或者说为原本干涩的内容增加了很多人情味的“废话”

---

口头语言本身非常冗余，所以也挺浪费时间

我其实更喜欢把第 2 个功能点反向操作，我很期待有开发者做一个播客 AI 挤水分工具，尽可能地减少播客、演讲、教程等等对话式内容的冗余信息

比如挤干播客节目里的“废话”、嘉宾的口头禅等等，它不像摘要那样子破坏原来节目的结构、内容和深度，同时也能尽可能地节约时间



### 97

2024-09-17

宝玉
@dotey
对于 AI 这波流量王炸为什么被推特拿到，结合我自己的经历说说看法：

1. X 上有第一手的 AI 资讯，基本上我的绝大部分 AI 相关信息都来自 X，比如 OpenAI 发布什么信息，他们官网发后第一时间就会 X 上发布，只有 X 上发布了马上就有很多人转发很容易就在 Timeline 上看到

2. X 的 Timeline 的算法有两种，一种是你关注的（Following），一种是推荐的（For you），如果只看自己关注的很容易进入信息茧房，但是看推荐就能看到很多样的信息，虽然噪音不少，但是不会错过热点信息，所以 AI 相关的热点信息，几乎不会被算法错过的

3. X 发布简单快捷，心智负担小，制作成本低。如果要做个视频，时间可能得几个小时，而去年 AI 资讯每天那么多，做视频根本跟不上的。写推就简单多了，简单的文字配张图甚至不要图，就可以发出去了，而且互动量很好

4. X 没有严格的审查，在 X 上发内容很自由，不用担心被和谐，早年我在微博内容带 ChatGPT 关键字都可能会被限流

5. 整体社区氛围很好，在 X 上，至少在 AI 圈子，人员素质还是不错的，很少遇到人身攻击这些很扫兴的事。

6. 产品设计上：
X 有一点好就是引用（Quote）和新发一条推是一样的，可以在引用的内容展开写很长内容，而微博转发你没法写很长内容，也无法附加图片，评论又不利于传播，所以在 X 上，比如这篇，我可以展开写很多内容，而微博，我可能得新开一个微博，截图引用一下

X 还有就是 Thread 的设计也很好，比如我发 o1 的视频，可以把所有视频发在一个 Thread 上，对于信息的归类整理帮助很大

### 98

2024-09-17

Michael Anti
@mranti
今天在Space谈o1体验，我说的几点：(较长，详细的录音有）
1）我体验下来，对比Claude，o1编程完成度高很多。
2）而且仔细看它的思考过程，也可以学到很多东西。它从副驾驶，成为了家庭教师。
3）o1创新是回到强化学习小模型，但把思维链当成了目标，把思考过程显式化、标准化。之所以o1从数学和编程开始，就是因为这两个专业的思考过程容易显式化和标准化。
4）从此，所有专业，特别是文科的专业，也会加入这个思维过程被强化学习的过程。
5）和Transformer时期，大家拼语料、拼GPU不同，O1之后，大家会拼思维链显式化、标准化、强化学习，而这个过程中，太多第三方公司有事可做。
6）编剧和游戏，其实需要的是和不同的世界（宇宙）对齐，只有对齐了，才能产生人心能信任的世界观，让人融入；而历史和政治，却要和真实的世界事实对齐。
7）在教育上，我认为第一要尽快让孩子产生和AI产生结对学习闭环；第二，的确可以从编写游戏开始，让孩子理解AI时代做一件复杂项目的过程；第三，但还是要回到学科基本功，产生一个学科的基础直觉。AI时代教育孩子，我们可以放弃中间层，但要培养底层基础直觉，以及高端跨行业使用AI工具的能力。



### 99

2024-09-17

宝玉
@dotey
破解了，现在 o1 两个版本的系统提示词极其简单：

You are ChatGPT, a large language model trained by OpenAI, based on the GPT-4 architecture. Knowledge cutoff: 2023-10
Current date: 2024-09-17



### 100

2024-09-17

小互
@imxiaohu
奥特曼称：目前的模型能力

已经达到了 OpenAI 制定的人工智能技术目标的第三阶段

即：AI 能够通过自然语言执行复杂任务，还能在完成任务的过程中处理多个步骤。

并且在任务不清晰或存在歧义时，如果用户的指令不明确或含糊，AI 会询问用户以获得更多信息，从而更好地完成任务。

下一目标是：AI 将被训练在不同的游戏环境中进行操作，这些游戏作为小型的虚拟世界，具有很大的多样性。AI 需要快速适应并学会如何在这些不同的游戏中表现出色。

OpenAI 技术目标：https://openai.com/index/openai-technical-goals/



### 101

2024-09-17

歸藏(guizang.ai)
@op7418
Groq 搞了个开源的 Open AI o1。

g1 主要利用 Llama-3.1 70b 和 Groq 硬件，通过类似 o1 的推理链来提升LLM的逻辑推理能力。

与 o1 不同，g1 展示了所有推理标记，并使用了开源模型。

g1 在解决简单逻辑问题时的准确率在 60-80% 之间。



### 102

2024-09-17

歸藏(guizang.ai)
@op7418
Mistral AI 开源 Pixtral 12B 多模态 LLM。

试了一下对图像的理解很好，中文能力也还可以。

- Mistral Nemo 12B 的直接替代品
- 从头开始​​训练的新型 400M 参数视觉编码器
- 搭配基于 Mistral Nemo 的 12B 多模态解码器
- 能处理可变的图像尺寸和纵横比
- 支持128k上下文窗口中的多个图像




### 103

2024-09-17

歸藏(guizang.ai)
@op7418
机器人制造公司 1X Technologies 介绍了他们训练的“世界模型”和评估机制。

在机器学习中，一个 世界模型 是一个可以想象世界如何根据智能体行为演变的计算机程序。

模型可以从同一起始图像序列中预测出不同机器人行为提议的多种未来场景。也够预测如刚体相互作用。


### 104

2024-09-19

歸藏(guizang.ai)
@op7418
Kyutai 开源 Moshi，一个可以进行实时语音对话的文本语音模型。

期待类似的开源中文实时语音模型。

而且发了技术报告，里面有一些实现细节。

Moshi 采用多流架构，能够同时处理用户和系统的语音输入，并生成相应的语音输出。

Moshi 的理论延迟为160ms，实际为200ms，远低于自然对话中的几秒钟延迟。

Moshi 能够同时处理语音和文本信息，支持复杂的对话动态，包括同时说话和打断。

Moshi 支持实时流式推理，能够在生成语音的同时进行语音识别和文本到语音的转换。



### 105

2024-09-19

宝玉
@dotey
在 2024 年 T-Mobile Capital Markets Day 上，OpenAI CEO Sam Altman 的一段访谈，总结一下要点：

1. OpenAI 新发布的推理模型 o1 preview 相当于 GPT-2 时刻，但是升级曲线会很陡峭，意味着很快就会达到它的 GPT-4 时刻。

2. 推理模型这种新范式的一个最大特点就是升级速度极快。因此，现在模型无法解决的问题，过几个月它们就能解决。而最重要的是，我们将看到一些全新的模型使用方式。

3. 在 o1 的研发早期阶段，将会有全新的使用方式，这些不仅仅是聊天界面。我们需要一段时间来构建这些新方式，其他人也需要时间来适应。用户也需要一段时间来学习如何使用它。这与 GPT 模型有很大的不同。

4. AI 的五个发展阶段。第一个阶段是聊天机器人。第二个阶段，也就是我们现在刚刚达到的，是推理系统。第三阶段是 AI 智能体。第四阶段是创新者，具有发现新科学信息的能力。第五阶段是完整的组织。从第一阶段过渡到第二阶段花费了一段时间，第二阶段能相对较快地推动第三阶段 AI 智能体的发展。

5. OpenAI 不会用 API 调用的数据后者训练的数据来训练他们的模型

6. OpenAI 成功的秘诀是因为有坚定的信念和保持专注，能保持研究方向的聚焦。坚信深度学习的力量，相信可以从现有的状态一路走到通用人工智能（AGI）甚至更远，尽最大努力做得最好，并试图保持研究方向的聚焦。与此同时，会根据前进过程中学到的新知识来调整方向。尽全力去完成每一个任务，随着时间的推移，就能产生积累效应。

7. 看好未来 AI 在医疗保健领域、教育领域和科学研究领域上的贡献。

完整字幕文稿：https://baoyu.io/translations/transcript/t-mobile-capital-markets-day-2024-sam-altman
视频来源：https://youtube.com/watch?v=r-xmUM5y0LQ&t=3970s



### 106

2024-09-19


歸藏(guizang.ai)
@op7418
阿里开源 Qwen2.5 系列一堆模型。

Qwen2.5: 0.5B, 1.5B, 3B, 7B, 14B, 32B, 以及72B;
Qwen2.5-Coder: 1.5B, 7B, 即将推出的32B;
Qwen2.5-Math: 1.5B, 7B, 以及72B；
Qwen-Plus，Qwen-Turbo，Qwen-VL-Max 的 API。

主要升级内容：

Qwen2.5 获得了显著更多的知识，在编程能力和数学能力有大幅提升。

在指令执行、生成长文本、理解结构化数据以及生成结构化输出方面有显著改进。

对各种system prompt更具适应性，增强了角色扮演实现和聊天机器人的条件设置功能。

Qwen2.5-Coder 使即使较小的编程专用模型也能在编程评估基准测试中表现出媲美大型语言模型的竞争力。

Qwen2.5-Math 支持 中文 和 英文，并整合了多种推理方法，包括CoT、PoT和 TIR。

---

Qwen
@Alibaba_Qwen
Welcome to the party of Qwen2.5 foundation models! This time, we have the biggest release ever in the history of Qwen. In brief, we have: 

Blog: https://qwenlm.github.io/blog/qwen2.5/
Blog (LLM): https://qwenlm.github.io/blog/qwen2.5-llm/
Blog (Coder): https://qwenlm.github.io/blog/qwen2.5-coder/
Blog (Math): https://qwenlm.github.io/blog/qwen2.5-math/
HF Collection: https://huggingface.co/collections/Qwen/qwen25-66e81a666513e518adb90d9e
ModelScope: https://modelscope.cn/organization/qwen
HF Demo: https://huggingface.co/spaces/Qwen/Qwen2.5

* Qwen2.5: 0.5B, 1.5B, 3B, 7B, 14B, 32B, and 72B  
* Qwen2.5-Coder: 1.5B, 7B, and 32B on the way  
* Qwen2.5-Math: 1.5B, 7B, and 72B. 

All our open-source models, except for the 3B and 72B variants, are licensed under Apache 2.0. You can find the license files in the respective Hugging Face repositories. Furthermore, we have also open-sourced the **Qwen2-VL-72B**, which features performance enhancements compared to last month's release.

As usual, we not only opensource the bf16 checkpoints but we also provide quantized model checkpoints, e.g, GPTQ, AWQ, and GGUF, and thus this time we have a total of over 100 model variants!

Notably, our flagship opensource LLM, Qwen2.5-72B-Instruct, achieves competitive performance against the proprietary models and outcompetes most opensource models in a number of benchmark evaluations!

We heard your voice about your need of the welcomed 14B and 32B models and so we bring them to you. These two models even demonstrate competitive or superior performance against the predecessor Qwen2-72B-Instruct! 

SLM we care as well! The compact 3B model has grasped a wide range of knowledge and now is able to achive 68 on MMLU, beating Qwen1.5-14B!

Besides the general language models, we still focus on upgrading our expert models. Still remmeber CodeQwen1.5 and wait for CodeQwen2? This time we have new models called Qwen2.5-Coder with two variants of 1.5B and 7B parameters. Both demonstrate very competitive performance against much larger code LLMs or general LLMs!

Last month we released our first math model Qwen2-Math, and this time we have built Qwen2.5-Math on the base language models of Qwen2.5 and continued our research in reasoning, including CoT, and Tool Integrated Reasoning. What's more, this model now supports both English and Chinese! Qwen2.5-Math is way much better than Qwen2-Math and it might be your best choice of math LLM!

Lastly, if you are satisfied with our Qwen2-VL-72B but find it hard to use, now you got no worries! It is OPENSOURCED!

Prepare to start a journey of innovation with our lineup of models! We hope you enjoy them!

### 107

2024-09-19

meng shao
@shao__meng
Anthropic RAG: 上下文检索技术

"上下文检索" (Contextual Retrieval) 用于改进 RAG 系统中的检索步骤,通过结合语义嵌入和精确匹配技术,显著提高了 RAG 系统的检索准确性,从而提升了 AI 模型在特定领域任务中的表现。

RAG 系统的背景和局限性:
   RAG 系统通常用于增强 AI 模型的特定领域知识。传统 RAG 方法在编码信息时会丢失上下文,导致检索失败率较高。

上下文检索方法:
   - 上下文嵌入 (Contextual Embeddings)
   - 上下文 BM25 (Contextual BM25)

性能提升:
   与传统方法相比,上下文检索可以:
   - 减少 49% 的检索失败
   - 结合重新排序技术,可减少 67% 的检索失败

传统 RAG 系统工作流程:
   a) 将知识库分割成小块文本
   b) 使用嵌入模型将文本块转换为向量
   c) 将向量存储在向量数据库中
   d) 运行时,根据用户查询检索相关文本块
   e) 将检索到的文本块添加到提示中

BM25 技术:
   文章介绍了 BM25 作为补充检索技术。BM25 基于词频-逆文档频率 (TF-IDF) 概念,能够进行精确的词语匹配,特别适用于包含唯一标识符或技术术语的查询。

结合嵌入和 BM25 的改进 RAG 系统:
   a) 分割知识库为小块文本
   b) 为文本块创建 TF-IDF 编码和语义嵌入
   c) 使用 BM25 查找基于精确匹配的顶级块
   d) 使用嵌入查找基于语义相似性的顶级块
   e) 合并并去重(c)和(d)的结果
   f) 将顶级 K 个块添加到提示中

小规模知识库的简单解决方案:
   对于小于 200,000 个 token (约 500 页) 的知识库,可以直接将整个知识库包含在提示中,无需使用 RAG。

原文链接:
https://anthropic.com/news/contextual-retrieval



### 108

2024-09-19

歸藏(guizang.ai)
@op7418
Anthropic 发布了一种可以大幅增加 RAG 检索准确性的方案。

Contextual Retrieval embeddings + contextual BM25，检索失败几率降低 49%。

主要方法是：

使用 Claude 为每个文本片段生成上下文。具体做法是将文本片段和整个文档一起输入给 Claude。

在进行嵌入 处理之前，先将生成的上下文添加到每个文本片段的前面。

在检索步骤中，结合使用上下文嵌入和上下文 BM25 技术。

需要配合提示缓存来使用，不然会消耗大量 Token。



### 109

2024-09-19



Leo Xiang
@leeoxiang
MemoryScope: 
开源长期记忆框架 🧠
为AI聊天机器人打造长期记忆系统

项目地址https://github.com/modelscope/MemoryScope

使用场景： 
🤖 个人助理 💞 情感陪伴

关键特性： 
⚡ 低延迟：记忆检索响应时间约500毫秒 ；
🏗️ 分层记忆结构：observations（观察）和 insights（洞察）；
🕰️ 时间敏感性：处理时间相关查询，提供准确历史信息 ；
🔄 记忆一致性：定期处理矛盾和重复，确保内容连贯 ； 
🛡️ 虚构内容过滤：避免LLM幻觉，提高回答准确性。


### 110

2024-09-19


九原客
@9hills
论文推荐：模块化RAG（https://arxiv.org/pdf/2407.21059）

可以理解为是对 RAG 最新的综述，基本覆盖了所有的 RAG 技术。

作者尝试用数学或者伪代码定义 RAG flow 倒是挺有意思。

小感想：RAG 等技术天然有缺陷，不要死磕，雕花雕不好就再等等，做之前想想 ROI。


### 111

2024-09-22

meng shao
@shao__meng
Cursor 开源替代 
@cursor_ai
 

Cursor 热度持续高涨，这几天陆续也看到几个开源 AI 编程助手，都以 Cursor 为对标产品，也都是开源项目，大家一起看看。

- Continue 
@continuedev
 
领先的开源 AI 编程助手，可以选择切换任意 LLM 和上下文来构建自定义的自动代码编写体验，支持 
@code
 和 
@jetbrains
 插件模式。
https://github.com/continuedev/continue

- PearAI 
@trypearai
 
基于 VSCode 和 Continue，提供 AI 无缝接入体验，支持接入任意 LLM。提供对代码库的本地理解能力和聚焦的交互体验。
https://github.com/trypear/pearai-app

- Void 
@thevoideditor
 
基于 VSCode，支持接入任意 LLM，提供本地安全能力。可以对本地文件索引、提供 AI 搜索、微调生成和 Prompt 编辑管理能力。
https://github.com/voideditor/void



### 112

2024-09-22

小互
@imxiaohu
Deepgram 推出了全新的AI语音代理API 

能够进行实时自然的语音对话

该API依赖于快速的语音识别和语音合成模型，支持实时的语音理解、推理和对话生成。

能够自然地处理对话中的停顿或中断

可以与不同的大语言模型（如Llama 3和GPT-4）无缝集成

适用于客户支持、订单处理等场景。

详细介绍：https://xiaohu.ai/p/13891



### 113

2024-09-22



小互
@imxiaohu
这个免费的扩图工具不错 

上传图像选择比例即可

可以对图像进行自然的图像补全，扩展图像的背景或增加新场景。

还可以设置外扩参数。

传送门：https://huggingface.co/spaces/fffiloni/diffusers-image-outpaint

### 114

2024-09-22

小互
@imxiaohu
OpenAI 首席科学家 
@hwchung27
  MIT演讲

揭示 o1模型训练核心秘密： 通过激励模型学习是培养 AGI 系统通用技能的最佳方式。

在他的演讲中，他提出了类比“教人钓鱼”的方式，强调激励学习的重要性：“授人以鱼，不如授人以渔”，但是更进一步的激励应该是： “让他知道鱼的美味，并让他保持饥饿”，这样他就会主动去学习如何钓鱼。

在这个过程中，他还会学会其他技能，如耐心、阅读天气、了解鱼类等。而其中有些技能是通用的，可以应用到其他任务中。

通过激励来教导比直接教导可能要花费更多时间。对于人类来说确实如此，但对机器来说，可以增加计算量以缩短时间。因为机器可以通过更多的计算资源克服人类时间上的限制，从而在专门领域表现得比专家更好。

这就像在《龙珠》中，有个“精神与时间之屋”，在里面训练一年，外面只过一天，倍率是365。对于机器来说，这个倍数要高得多。因此，它认为通过高效的计算，通才模型在专门领域中也能超越专家。

以下是演讲主要内容总结：

1. 通用智能 vs. 专用智能

Hyung Won Chung 强调了通用智能（General Intelligence）与专用智能（Specialized Intelligence）的区别。专用智能模型是为特定任务设计的，适合处理单一任务，而通用智能模型能够处理广泛的任务，适应各种未知场景。

由于通用智能要求模型具备更强的适应能力，研究者不可能为模型教授每个具体任务。相反，Hyung Won Chung 认为，通过弱激励机制，让模型在大规模数据和计算资源的驱动下自主学习各种技能，才是通往通用智能的可行途径。

2. 扩展与计算能力的关键作用

Hyung Won Chung 展示了一个重要的数据点：计算能力以指数级增长，成本持续降低。这意味着随着时间的推移，更多的计算资源变得可用，这为AI研究提供了巨大的机会。

他指出，AI研究者的工作是利用这种不断扩大的计算能力，设计可扩展的算法，使模型能够随着计算资源的增加而自动提升性能。与此相对，那些高度结构化的模型虽然在初期可能表现较好，但在规模化时往往会遇到瓶颈。

3. 弱激励学习（Weak Incentive Learning）

目前大规模语言模型，如GPT-3和GPT-4，使用的是弱激励学习，例如通过下一个词预测任务来驱动模型的训练。Hyung Won Chung 提出，通过这种任务，模型不仅学会了语言，还掌握了推理、数学和编码等技能，尽管这些技能并没有被直接教授。

他进一步指出，与其直接教给模型某种技能，最好的方法是通过提供弱激励，让模型在面对大量任务时自主发展出解决问题的通用能力。例如，通过训练模型进行下一个词的预测，模型不但学会了语言结构，还学会了如何在没有明确指令的情况下推理出复杂答案。

4. 涌现能力（Emergent Abilities）

Hyung Won Chung 详细讨论了涌现能力这一现象。随着模型规模的扩大，模型在解决问题时往往会自发地表现出新能力。这些能力并非被人为编码，而是通过模型的自我学习在训练过程中自然涌现出来的。

他用大规模语言模型的例子说明了这一点。在没有直接教授推理或数学的情况下，GPT-4等模型能够表现出复杂的推理能力和数学计算能力。这表明，涌现能力是随着模型规模扩展而自然发生的，尤其是在面对广泛的任务时。

5. 激励结构的设计

Hyung Won Chung 提倡为AI模型设计更复杂的激励结构。通过引入更丰富的奖励机制，模型可以学会更高层次的能力。例如，Hyung Won Chung 提出，为了解决语言模型中的“幻觉问题”（hallucination），可以设计奖励结构，使得模型不仅仅追求回答问题的正确性，还要学会在不确定的情况下说“不知道”。

他指出，通过激励结构，模型可以学会如何判断自己是否知道答案，这种能力对提高模型的可靠性和可信度至关重要。激励结构使模型在大量任务的驱动下学会适应不同的问题情境，并在此过程中发展出更通用的能力。

6. 扩展定义的重新思考

Hyung Won Chung 对“扩展”（Scaling）的定义进行了重新审视。传统意义上的扩展指的是“用更多的机器做相同的事情”，但他认为，这种定义过于狭隘。

他提出了一种更有价值的扩展定义：识别那些限制进一步扩展的假设或结构，并用更具扩展性的方法替代它们。这种扩展不只是增加计算资源，还涉及对模型进行重新设计，使其更好地利用不断增加的计算能力和数据。

7. 持续的“去学习”与适应

随着更强大的模型（如GPT-4）的推出，AI领域的基本假设不断变化。Hyung Won Chung 指出，研究者需要具备一种持续“去学习”的能力，以便适应新模型带来的新现实。

他解释说，语言模型的发展使得我们几乎每隔几年就必须抛弃旧的认知，适应新模型带来的新能力。这种去学习的过程对于保持在AI领域的领先地位至关重要，因为每次新模型的出现都会改变我们对AI的理解和使用方式。



### 115

2024-09-22

小互
@imxiaohu
StoryMaker：一致性角色图像解决方案 

它不仅可以在多人物场景中保持角色的面部一致性，还包括衣服、发型和身体姿态一致性

进而可以用于生成系列图片构成的故事情节

StoryMaker 可以通过文本提示控制生成图像的背景、姿势和风格，使得用户可以根据不同的场景需求生成符合叙事需求的图像序列。

该模型支持包括服装交换、角色插值等功能，并能与其他生成插件（如 LoRA、ControlNet）集成，提供多样化的生成应用场景。

详细介绍：https://xiaohu.ai/p/13846

GitHub：https://github.com/RedAIGC/StoryMaker

模型下载：https://huggingface.co/RED-AIGC/StoryMaker



### 116

2024-09-22

宝玉
@dotey
今天看了个Lego视频 https://youtube.com/watch?v=rU_KmdqSfUI，娃很感兴趣，想自己买零件试试，但是作者没公布零件清单，尝试用 GPT-4o、Gemini、Claude 3.5 找出零件清单，第一个零件愣是没找到名字……




### 117

2024-09-22

歸藏(guizang.ai)
@op7418
李飞飞和她的学生前几天刚刚创办了 World Labs，专注于构建构建大型世界模型。

a16z对他们做了一次专访，介绍了他们为什么要研究空间智能以及与现在语言模型的区别。

看完会对他们做的事情有更深的了解。

关于两者的这个区别这里很有意思：

语言是纯人工生成的信号，而3D世界遵循物理定律。



### 118

2024-09-22


meng shao
@shao__meng
给初级开发者的推荐和建议

宝玉老师 
@dotey
 的建议方向非常清晰：做中学、设定长远目标。

这几年在公司给初级开发者 (或产品、测试等) 分享和制定工作计划时，我们也会强调这两个方向，也分享一下我们的方式。

1. 做中学
除了公司的基础培训外，一般不会给初学者安排太多培训 (包括企业文化、职场经验等都不会安排)，我们会像宝玉老师提到的由 Mentor 在实际工作中指导给方向和解决问题的思路，保证不走偏，但又能有空间自己动手思考解决问题。
把事情做完、问题解决掉，就是初级阶段最好的学习方式，因为这个过程中会涉及到很全面的知识: 理论知识、实践踩坑经验、和其他人探讨的过程、与人交流的方式等。
再借助 LLM 强大的能力帮助，初级阶段的绝大部分问题都可以通过正确问问题来处理，学会问问题 (Prompt Engineering) 就是一项很重要的能力。

2. 设定长远目标
对于初级阶段的开发者，当前掌握了多少技能、刷过多少道题其实没有那么重要，找到自己以后的方向，知道自己想长久做什么事情更重要。
所以我们会有明确的说明，不同的开发者阶段都有哪些特征，比如初中高级、架构师、组长这些职位是什么样的能力描述。
有了明确的方向，Mentor 和组长也会跟每个初级伙伴讨论学习计划 (当然不是强制的)，执行中阶段 1on1 沟通时也会有对学习中困惑的探讨。
对于初级阶段的伙伴，年龄很轻、学习能力很强，他们往往能很快学会，但也容易在学会比较浅的一层后，忽略了继续深挖的过程，这时有明确的方向，知道自己距离深层次还有多少距离，很重要。

最后也想结合我自己的教训，分享一个信息：
学习是投资自己的过程，不要太计算成本，即使当前的收入还不太高，也要预留出一部分来投资自己的学习，买课程、买书、买 AI 工具，虽然免费信息能解决掉一部分问题，但是总有一些信息是要收费的，这也是知识的价值，如果对自己有益，建议尽早启动。



### 119

2024-09-22


宝玉
@dotey
问：对于工作一两年的初级开发者有推荐的资料吗？

答：
没有太关注这方面的资源，已经有些脱节了，有时候我觉得很简单的事可能对于初学者来说是很难的事情，或者我觉得很难的，对于年轻人来说反而不是什么难事。

通常在公司实习生或者刚毕业的员工入职，公司会有安排一个 Mentor，也就是导师，日常遇到问题都可以找 Mentor 去请教，这是最有效的帮助成长的方法：遇到问题，马上去查资料，马上去问人，然后得到解决方案。

现在 AI 可以很大程度上替代这个角色，比真人还有耐心。遇到技术问题，将问题描述清楚，通常能得到很好的解答，尤其是初学者的问题，对于 GPT-4、Claude 3.5 这样的 AI 绝大部分都不会有问题的。当然要舍得投入点钱在上面，要学习一些基本的提示工程，这个投入是值得的。

再补充两个对初级开发者的建议：

1. 做中学
开发这种事，一定要动手才能学得快学得好，光看书是没用的，就像你看再多教你游泳的视频，也不可能一下水就能学会游泳。

做中学还有个好处就是你容易收获正反馈，传统的学习你可能要到考试的时候才能发现自己学会了或者没学会，而通过动手写程序，你能马上知道是不是学会了，遇到问题解决了就能提升。

以往做中学通常会遇到特别多的问题，搭开发环境、运行、调试，每一步都好多坑，现在是开发者的好时代，有 Cursor、GitHub Copilot 这样的 AI 编程助手，先让 AI 帮你生成代码，然后直接运行看到效果，再反过来去搞明白它的原理，这样能加速学习的过程，减少挫折感。

但是要避免过于依赖 AI，即使是 AI 生成的代码，也要能明白它的思路，去验证是不是正确的。

2. 设定长远的目标
有志长期从事开发相关职业的，最好有长期的职业规划，三年、五年、十年想达到什么样的职业目标。

人是很容易迷失的，有很多诱惑，有很多障碍，如果老是改变方向，或者在某个阶段停滞不前，错过了学习的最佳时机，以后再补很难很难。

早点选择一个适合自己的方向，哪怕可能是错误的，做的过程中还可以调整，错误的目标好过没目标。

你有了目标，反过来再去找资料相对是比较容易的。

现在网上最不缺的就是学习资源，缺的是我们知道自己想学什么，缺的是怎么学习，缺的是真的原意投入时间精力去学。


### 120

2024-09-23


meng shao
@shao__meng
Go 语言构建 LLM 应用 
@elibendersky
 

文章通过具体示例说明了 Go 
@golang
 语言在构建 LLM 应用方面的优势, 包括其强大的并发处理能力、网络服务支持以及作为云原生语言的性能和可靠性等。

RAG 服务器示例:
- 文章通过构建一个 RAG 服务来演示 Go 的应用
- 服务提供两个主要功能: 添加文档到知识库和基于知识库回答问题
- 使用嵌入模型、向量数据库和 LLM 来实现功能

三种实现方式: 
01 直接使用 Gemini API 
@GeminiApp
 和 Weaviate:
·- 使用官方 SDK 直接与服务交互
·- 展示了 Go 的 HTTP 服务器结构和并发处理能力

02 使用 LangChain for Go:
·- 使用 LangChain 
@LangChainAI
 框架简化开发
·- 提供模块化组件和通用 API, 便于切换不同的 LLM 和向量数据库提供商

03 使用 Genkit for Go:
·- Google 推出的新框架
·- 关注生产特性如提示管理和部署工具集成

Go 语言在 LLM 应用开发中的优势:
- 出色的并发和网络服务管理能力
- 作为云原生语言, 具有优秀的性能和可靠性
- 适用于构建 LLM 生态系统的基础组件 (如 Ollama 
@ollama
  、LocalAI 
@LocalAI_API
  、Weaviate 
@weaviate_io
 等)

文章地址：
https://go.dev/blog/llmpowered



### 121

2024-09-23


meng shao
@shao__meng
精通生成式 AI
——从提示词工程到预训练的全栈开发指南

Databricks 
@databricks
 发布的关于生成式 AI 的指南书籍，深入探讨了如何构建和评估高质量的生成式 AI 应用。

生成式 AI 应用的发展分为 5 个阶段:
- 基础模型: 使用现成的 LLM 作为基础
- 提示工程: 通过精心设计的提示来优化模型输出
- RAG: 结合外部知识库来增强模型的回答能力
- 微调: 在特定数据集上对模型进行微调, 使其更适合特定任务
- 预训练: 从头开始训练专门的模型

关键技术和方法:
- 提示工程: 设计有效的提示以获得更好的模型输出
- RAG: 结合外部知识来增强模型的回答能力和准确性
- LoRA: 一种高效的模型微调方法
- QLoRA: LoRA 的量化版本, 可进一步提高效率
- 预训练: 从头训练专门的模型以满足特定需求

评估方法:
- 使用 LLM 作为评判: 利用强大的 LLM (如 GPT-4) 来评估模型输出
- 人工评估: 作为最终的 "黄金标准"
- 自动化评估指标: 如准确性、相关性、可读性等

最佳实践:
- 对于 RAG 应用, 推荐使用 0-3 或 1-5 的评分尺度
- 在使用 LLM 作为评判时, 提供具体的评分标准和示例可以提高一致性
- 为特定用例构建专门的基准测试集, 而不是依赖通用基准

Databricks 工具和平台:
- Databricks Model Serving: 用于管理和访问各种 LLM 服务
- Databricks AI Playground: 用于快速测试和比较不同的模型和提示
- MLflow:用于实验跟踪、模型管理和评估
- Mosaic AI: 用于大规模训练和部署模型 

案例研究:
- 训练 Stable Diffusion 模型
- 为 AI 生成文档创建定制 LLM
- 评估 MLflow 文档问答聊天机器人

书籍下载地址：
https://databricks.com/product/machine-learning/build-generative-ai


### 122

2024-09-23

Wang Shuyi
@wshuyi
终于到这一步了，AI 用低成本打破了语言造成的信息之墙。很多小语种带来的护城河很快会消失。只不过，语言隔阂的消除，也可能让很多原本「井水不犯河水」的极端观点、文化偏见与刻板印象，突然被扔进同一个擂台，还打上聚光灯
引用
小互
@imxiaohu
·
9月20日
兄弟们，这个有点炸裂了

HeyGen 推出视频内文本翻译工具

不仅能翻译你的声音，还翻译屏幕上的文字、字幕！  



### 123

2024-09-23

歸藏(guizang.ai)
@op7418
Open AI 研究员放出了他去年的一次分享。

可能刚好讲到了可能关于 o1 的核心训练思路。

他的逻辑是 不要“教授”，要激励。

比如涉及 RL 时候常用来举例子的 AlphaGo。

不要告诉模型如何才能赢得棋局，而应该引导模型学习什么是好的走法。

强烈推荐听一下。

---

Hyung Won Chung
@hwchung27
Here is my talk at 
@MIT
 (after some delay😅)

I made this talk last year when I was thinking about a paradigm shift. This delayed posting is timely as we just released o1, which I believe is a new paradigm.

It's a good time to zoom out for high level thinking.

(1/11)

### 124

2024-09-23

宝玉
@dotey
提示工程师是最短命的职业吗？Prompt Engineering已经死了吗？

随着 OpenAI 新的推理模型 o1 preview 的发布，它能自动生成高质量思维链，很简单的提示词也可以得到很不错的效果，所以很多人觉得提示工程已经死了，提示工程师是世上最短命的职业之一。真的如此吗？

我们常说的提示工程，有两大核心部分：技巧和指令。

技巧就是那些与模型本身密切相关，各种让特定模型表现更好的技巧，比如说：

- 为模型设定角色
“你是一个有帮助的助手”，“你是一个资深前端工程师”等等。在 GPT-3 时代这个技巧很好用，GPT-4 后效果已经不太明显了。这可能是因为早期训练语料不够多模型不够强的时候，设定角色可以让角色相关的语料在生成时有更高的概率。随着模型能力的增强，已经不太需要这样的技巧。

- 情感勒索
“你只要按照我的做，我就给你$200 小费”，“我没有手指，没办法复制粘贴，请你完整生成”，“你不这样做就要个无辜的小孩要因此丧生”…… AI 在对齐阶段，被训练成为要人类有帮助的助手，结果反而被利用。但是这类常用的情感勒索方式，在新一轮模型训练的时候，会作为案例再次对齐，效果就会大打折扣。另外很多时候这样做也是因为模型不能很好遵循指令，模型能力增强后就不需要了。

- 思维链，让模型一步步思考
这算是提示工程的核心技巧了，将任务分成几步来做可以明显提升生成的效果，最著名的是“Let's think step by step”，对于给大语言模型的任务，生成若干推理步骤，得到更好的生成效果。到了 o1 更是将这种思维链发挥到了极致，你输入一个复杂的数学题，甚至不需要要求一步步思考，它都能生成高质量的思维链，解除复杂的数学题目。以至于很多人感慨提示工程已死。

当然还有很多像 few-shot、ReAct 这样的技巧，就不一一列举。如果是技巧部分，那真的每次新一代模型出来，就要喊一次提示工程工程已死了，因为技巧那部分随着模型升级一直在变的。

指令就是那些技巧之外的，你需要让 AI 能真正理解你意图，并且精确控制 AI 按照你的意图去完成任务的部分。其实这部分才是提示工程的核心部分，而且并不容易做好，因为它有很多难点：

- 如何清楚的表达自己的意图

表达清楚自己的意图其实很难，如果不能表达清楚，不管是 AI 还是人类，都很难懂你或者帮到你。比如说“五彩斑斓的黑”是什么颜色？

- 如何让 AI 明白所有相关的上下文

人和人沟通的时候，一个常见的错误就是一方假定对方明白自己知道的所有上下文，然后造成很多误解。跟 AI 也一样，但是如何让 AI 明白我们所处的上下文环境也是很有必要并且很难的事情：要如何交代清楚上下文，要交代多少上下文？

- 如何将复杂的任务拆分成简单的任务

我刚大学毕业那会，HR 会给员工推荐一本书，叫《把信送给加西亚》，本来挺好的故事，但是被老板们用来教育员工：员工收到老板的指令，就应该像书中的安德鲁·罗文那样，没有任何推诿，不讲任何条件，历尽艰险，徒步走过危机四伏的国家，以其绝对的忠诚、责任感和创造奇迹的主动性完成“不可能的任务”，把信交给了加西亚。后来自己去管人了才知道，好的管理者要善于帮助员工将复杂的任务拆分成简单的任务，并且在过程中提供帮助和引导，而不是给一个指令就等着结果。

让 AI 做事也是类似的，由于上下文的不完整，或者任务的复杂性，合格的提示工程师需要将复杂的任务拆分成几个简单的任务让 AI 去完成，甚至于需要组建一个完整的工作流，让多个 AI 智能体协同完成复杂的任务。

- 如何精确的控制 AI 做事

提示词是用自然语言来书写的，但自然语言有一个特点就是其模糊性，同样一句话可以有不同的解读；另一方面由于现在的生成模型是概率预测模型，所以每次结果可能会不一样，这就给精确控制 AI 做事带来了很大挑战。以至于现在提示工程都有一个途径就是使用伪代码来精确控制 AI 执行任务，并且效果很好，因为代码本质就是一种精确操纵机器的语言。即使现在 o1 这样强大的推理模型出现，模型的随机性还是没能解决，还是需要提示工程师去反复尝试才能找到一个相对稳定的方案，以及在出错后的纠正和容错方案。

- 如何防止用户绕过限制做一些不好的事情

作为一个普通用户，能让 AI 帮我们完成任务就够了，但对于专业的提示工程来说，还需要防止用户做一些不好的事情，生成不好的内容，这可能造成很多成本上的损失，可能有政治风险。

- 如何针对特定任务提出开创性的创造解决方案

现在 o1 能帮助解决数学问题，这很强，但我们需要 AI 解决的不仅仅是数学问题，还有很多日常任务或者特定领域的任务，也许未来 AI 能在各个领域写出超过普通人的思维链，但这些任务可能需要真正对这个领域有深入理解和洞察的人才能写出最佳提示词。比如你让 o1 翻译一段文本，它也只能正常翻译，但公认的翻译效果更好的提示词，是要 AI 先直接按照字面意思翻译，再针对翻译的结果去检查、解释、反思，最后再综合一起生成翻译结果，而这样的提示词目前 AI 还不能自动生成，当然也许很快在翻译领域就可以做到了，不过对于一些专业领域，短时间内恐怕还是需要和领域的专家一起，才能生成最佳的提示词。

这有点像工业自动化领域，最初的自动化，就是用机器把操作最好的工人的工作的动作模仿下来实现自动化，然后再超越最优秀的工人。也许 AI 将来也能超过各个领域的专家，但那时候就真的是 AGI 时代了。

\## 最后

AI 时代，总是在搞大新闻，一会是 AI 要替代程序员了，一会是提示词工程师是最有潜力的职业，一会是提示词工程师是最短命的职业。然而真正去透过现象看本质，里面有太多的以偏概全，太多噱头。就提示工程这事来说，会像编程一样，还会在很长一段时间存在并发挥巨大的价值。

真正的提示工程，本质还是怎么让 AI 懂你，怎么让 AI 听话。在让别人懂我们和让别人听话这事上，我们已经奋斗了几千年了，至今还在努力中，也许 AI 会容易一点吧。

本文同步发表于：https://baoyu.io/blog/prompt-engineering/is-prompt-engineering-dead



### 125

2024-09-23

宝玉
@dotey
https://x.com/dr_cintas/status/1837192765555245384
o1 下最佳提示词实践：
1. 简洁
2. 不需要写思维链
3. 使用分隔符

参考 o1 提示词模板：

\<context> 
请分析以下示例中的写作风格、语气和结构。重点关注词汇选择、句子复杂性、节奏和整体语气等元素。 </context> 

\<examples> 
[在此插入您的写作示例，并在每个示例之间添加分隔符] 
\</examples> 

\<instruction> 
生成一篇关于[特定话题]的[type of content，如“信息性文章”或“博客文章”]。内容应符合所提供示例的风格、语气和结构。请确保内容具有原创性、吸引力，并适合[指定的目标受众或用途]。 
\</instruction>





### 126

2024-09-23



宝玉
@dotey
当年扎克伯格看到传闻说Google要收购WhatsApp，给WhatsApp创始人写的邮件

发件人: 马克·扎克伯格
发送时间: 2013年4月6日星期六上午9:48
收件人: 简·库姆

主题: 传闻

我觉得这不太可能，但你能确认一下吗？
http://m.digitaltrends.com/social-media/google-acquiring-whatsapp/

如果你有意向将 WhatsApp 并入其他公司，我们当然很愿意在这个价格区间进行讨论，并且我们几乎可以确定比谷歌更合适！

另外，我们应该找时间尽快再聚一聚，上周末的事我还没回复你，因为我一直忙于准备 Home 发布会。但如果你接下来几周有空的话，让我知道。

### 127

2024-09-23

fin
@fi56622380
GPT o1的出现，让这一轮LLM带来的AI热又点燃了一把，在整体情绪悲观了半年之后，各种AGI临近的展望讨论再次开始火了起来

LLM是不是正确的AGI path，暂且不讨论，但我们可以从历史上的几次工业革命来看新技术对人均GDP的影响

从1870年代到2020年代，整整150年，历经了两次(三次)工业革命

这么多年的人均GDP增长，稳稳的沿着2%的线前进，不管中间有多少“技术空白期”，或者工业革命爆发期，都是稳稳的2%

不管中间经历了多少不可思议的发明，从电力的推广应用，到内燃机，汽车，铁路，到飞机，航天，到晶体管，半导体，计算机，再到互联网，移动互联网，AI

人均产值/收入都是稳稳的沿着2%上下小幅波动

任何技术的应用，推广，改良现有flow，适应过程，产生价值，创造生产力，产生新的需求，都是需要时间的，这个过程需要很多人，很长时间的慢慢探索

互联网时代多少玩法，移动互联网时代多少玩法，都是慢慢摸索出来的，很多模式甚至经历了20年的摸索

记得两年前各家大裁员哀鸿遍野，所有人都特别悲观，觉得移动互联网+上一轮AI科技红利已经消化的差不多了，没有新一轮增长点，但我还是觉得机会一定会在不起眼的地方发芽(见引文)

没想到的是，发完这篇之后还不到三周，chatGPT的低调发布开创了一个新的时代

不管是悲观还是乐观，科技加持下人均GDP的提升，在一个成熟的市场，就是2%的速度，不会因为人们对某个技术特别看好或看衰而改变太多

就像今年上半年，大家都在传，各大厂家在LLM上的硬件投资超过了50B，但所有营收还不到3B，根本无法持续，AI看起来像是一个巨大的泡沫。而9月o1 system2推理能力的加强和inference scaling law带来的可能性(成本指数型增加其实很昂贵，benchmark有提升但并不多而且比较局限)，又让情绪直接180度反转，开始讨论AGI的可能性

AGI的目标渐进式实现和推广是一个非常缓慢而漫长但绝不会停止的过程

这也是为什么，人们会经常高估新事物短期的影响力，而低估长期影响力，因为这正是指数型增长的本质。2%的增长在短期看来太少了，但在长期看来能保持这个速度是不可思议的

实话说，这么多海量新科技S型曲线的前后接力保持了这么多年才稳住了2%的增长，放在更长的人类文明历史上看，绝对是一个奇迹

如果从这个历史规律假设倒推，AGI从现在的萌芽期全面改造整个社会，还需要多少年？

那么可以从AGI会增长多少产值来倒推，如果AGI带来额外100%的人均GDP增长，那么满打满算每年2%的增长全归结于AI(实际能有1%就不错了)，也需要35年

我相信大多人都会认同，AGI带来的人均GDP增长肯定不止100%，那么从历史规律看，我们到AGI全面改造社会生产力，还有很远很远的距离




### 128

2024-09-23

小互
@imxiaohu
兄弟们 这个有点强啊  而且是完全开源的

感觉比OpenAI的演示的那个视觉能力还有点强

Molmo 一个开源的多模态模型，能够识别图像中的物体、场景和活动，并生成准确的描述。

Molmo还支持用户通过2D指向交互，例如用户可以通过手势或点击与图像中的对象进行互动。

Molmo使用的图像字幕数据集完全由人类注释者收集。模型能够根据输入的变化自动调整处理方式，适应不同类型的用户交互和数据格式。

Molmo在开源权重和数据模型中表现最佳，能够与一些专有系统（如GPT-4o、Claude 3.5和Gemini 1.5）相媲美。



### 129

2024-09-23

歸藏(guizang.ai)
@op7418
Sam 关于 Mira 和其他 Open AI 人事变动的声明。

有意思不止是 Mira 要走，还有其他人也要走，刚好一起办了。

还宣布了新的管理核心，Mark、Jakub、Kevin、Srinivas、Matt、Josh。

这几个应该就是 Open AI 接下来这个阶段的核心角色了，可以看看大权独揽的 Sam 在接下来的表现。

他也会更多的投入到产品和技术上，改改那个稀烂的产品体验吧。



### 130

2024-09-23

歸藏(guizang.ai)
@op7418
吴恩达跟 Meta 合作的新课程，Llama 3.2 简介。

主要教用 Llama 3.2 构建多模态应用。

---


Andrew Ng
@AndrewYNg
The Llama 3.2 open multimodal model just dropped! http://DeepLearning.AI has been working with Meta on a short course on how to use it. Please sign up for "Introducing Llama 3.2", taught by Meta's 
@asangani7
, which will launch Oct 9!

### 131

2024-09-23

Wei Jun
@weijunext
因为Cursor降低了编程的门槛，就有很多人觉得用自然语言也能开发产品了。这种心态和十年前“人人都能成为产品经理”的心态一样，属于无知者无畏。

我记得刚工作一年的时候，和同事说自己到了技术瓶颈期。现在想来觉得很可笑，但是那时候只知道工作里的技术，不知道外面的世界有多大。现在我只敢说自己是菜逼了。

编程新人都无法认清这个领域，非编程人员自然更加无法了解编程这门技术活。程序员的正式名称叫做“软件工程师”，因为开发软件是一项工程，需要做好工程设计、考虑工程管理，其次才是工程开发。

AI+编程容易让人高估AI的原因之一是写出来的代码不会被人看到。如果换个思路，AI+设计UI，还会有这么多人觉得AI可以做全套UI吗？至少非专业设计师不敢说这话，因为普通人连设计规范都不懂，即使用AI也做不出代表作。

AI是专业能力的放大器。陶哲轩可以用AI解决数学难题，我们不还在嘲笑AI连9.8和9.11大小都分不清吗？是AI的问题吗？当然不是，是专业能力的区别。在编程、设计、写稿等等方面也是如此，你的专业能力越强，AI在你手里的能力就越强。

我总结了一个公式：AI赋能=(你的能力+5)*100。5是AI默认的专业能力值。

如果你想做专业的事情，就不能只依赖那个5。学习专业知识，用AI放大自己的能力，这才是正路。



### 132

2024-09-27

歸藏(guizang.ai)
@op7418
Karpathy 说 NotebookLM 播客功能中可能蕴含着类似 ChatGPT 的机会，一个新的 AI 交互范式。

我一直关注和等待的东西，终于有行业核心人物注意到了，这个机会可能比 ChatGPT 还要大的多。

写了篇内容详细介绍了一下这个新的 AI 范式里面的逻辑。

将已有的庞大文本内容利用日渐成熟的其他模态 AI 模型转换为更多可被用户消费的内容形态，从而满足更多的用户消费场景。


### 133

2024-09-27

小互
@imxiaohu
很多人不理解奥特曼的为了截胡竞争对手而不停放期货的行为。

但我认为，这实际上是在商业上非常需要很大勇气和智慧的操作。

如果不是几次精准截胡 Google，等产品成熟了再推出，让Google占了上风，那么开发者和用户会大量流失。

商业就是这样，稍有不慎就会满盘皆输。

况且你的竞争对手在技术、资金、算力、数据上都和你相差无几，甚至更强。如果不狙击对手，让它起来，后患无穷。

必须要压着让它无法翻身，当然肯定会牺牲很多，但是有时候也是迫不得已。

真正的领导者是不需要别人理解你的！只有平庸的人才会希望他人的理解！


### 134

2024-09-27

Andrej Karpathy
@karpathy
I love calculator
https://karpathy.ai/blog/calculator.html

A short post on philosophy of product and technology. What is beauty in technology and how can we get more aesthetically pleasing products that spark joy?



### 135

2024-09-27

宝玉
@dotey
https://x.com/tinywavesss/status/1840060820908322836
Composer 恰恰是 Cursor 超越 GitHub Copilot 的地方之一：
- 可以精准的选择上下文，把所有相关的代码附加上
- 可以调用任何强大的模型，Claude 3.5 或者 GPT-4o 甚至 o1，自动补全/修订的模型不是一个很强的模型（GPT-4o mini 级别的）
- 可以随时唤起不用切换上下文



### 136

2024-09-27

宝玉
@dotey
转译自 WSJ《将 OpenAI 转变为真正的商业公司正在使其分崩离析》

今年以来，由于公司价值观的争议和领导层之间的斗争，OpenAI 的高管和研究人员纷纷离职。

不到两年的时间里，OpenAI 从一个鲜为人知的非营利实验室，迅速转型为一个举世闻名的企业，其首席执行官已成为人工智能革命的代表人物。

这种转变正在使公司分崩离析。

周三，OpenAI 的首席技术官成为最新一位宣布离职的备受瞩目的高管，在公司准备转型为营利性企业之际选择了离开。这些离职事件公开爆发了公司内部自 ChatGPT 推出以来日益加剧的紧张关系，而这些紧张在 CEO 山姆·奥特曼去年短暂离职后回归时尤为明显。

部分紧张关系源于 OpenAI 最初致力于为公众利益开发 AI 的使命，与新推出的盈利产品之间的矛盾。而另一些则来自公司内部充满戏剧性的高层斗争。

首席技术官米拉·穆拉蒂是今年以来离职的 20 多位 OpenAI 研究人员和高管之一，其中还包括奥特曼的几位联合创始人。

现任和前任员工认为，OpenAI 过于急于发布产品公告和进行安全测试，并且已经失去了对竞争对手 AI 开发者的领先优势。他们认为 Altman 大多游离于日常事务之外——公司对此表示异议——因为他一直在全球奔走，推广 AI，并筹集大量资金用于建造 AI 所需的芯片和数据中心。

自 Altman 回归后，OpenAI 正逐步变得更像一家普通企业。公司员工数量从去年十一月的 770 人增长到了 1700 人，今年还任命了首位首席财务官和首席产品官。董事会也吸纳了具有企业和军方背景的新成员。OpenAI 正在寻求从包括微软、苹果和英伟达在内的支持者筹集 65 亿美元。同时，OpenAI 也越来越专注于扩展其产品服务，一些长期员工认为这分散了公司对纯研究的关注。

公司内部有些人认为，这些发展是 OpenAI 实现财务可行性所必需的，因为开发和运营 AI 模型需要数十亿美元的投入。他们主张，AI 需要走出实验室，进入现实世界，以改变人们的生活。

而另一些人，包括在公司工作多年的 AI 科学家，则认为大量资金的注入和巨额利润的前景正在腐蚀 OpenAI 的文化。

几乎所有人都同意的一点是，在同一家公司中同时保持以使命为核心的研究运作和快速发展的商业化进程，带来了越来越多的阵痛。

“同时做好这两件事是很难的——产品优先的文化与研究文化非常不同，”Cresta AI 初创公司现任首席技术官、OpenAI 的早期员工 Tim Shi 表示。“你需要吸引不同类型的人才。也许你正在构建一个不同类型的公司。”

在本周事件发生时，Altman 正在意大利都灵参加意大利科技周。周四，他在炉边谈话中否认员工离职与重组计划有关，并表示：“我认为这对所有参与者来说将是一次极好的转型，我希望 OpenAI 因为所有这些转型而变得更强大。”

OpenAI 的首席财务官周四向投资者发送了一封信，称公司预计在下周前完成融资，并将在此之后举办一系列电话会议，向投资者介绍其产品和研究团队的核心领导成员。

OpenAI 专注于稳步改进 ChatGPT 和其他产品，已经取得了显著成效。公司年化收入（根据最近的业绩对全年收入的预测）最近达到了约 40 亿美元，比去年同期增长了三倍以上。然而，公司每年仍在亏损数十亿美元。

要实现持续增长，OpenAI 需要保持其技术领先地位。下一个基础模型 GPT-5 预计将是公司发展的一次重大飞跃，但目前面临挫折和延期。同时，竞争对手公司也推出了与 OpenAI 产品相当的 AI 模型，其中两家——Anthropic 和 Elon Musk 的 xAI——都是由前 OpenAI 领导人创立的。

日益激烈的竞争令那些因 OpenAI 领先地位而加入的研究人员感到沮丧。

OpenAI 的女发言人拒绝回应本文中的大多数具体问题。她表示：“我们不同意这些说法，但我们意识到，从不知名的研究实验室演变为一家在短短两年内向数亿人提供先进 AI 研究的全球公司，需要经历成长与适应。”她补充说，Altman 在公司战略和招聘方面一直非常投入，并推动了产品部门的建设。

** OpenAI 动荡时间线

2023年11月17日
OpenAI 董事会以对 Sam Altman 的领导能力表示不信任的声明将其解职。

2023年11月21日
仅五天后，OpenAI 董事会宣布恢复 Altman 的首席执行官职位。

2024年5月14日
OpenAI 联合创始人兼首席科学家 Ilya Sutskever 辞职。OpenAI 顶级研究科学家之一 Jan Leike 也辞职。

2024年8月5日
OpenAI 联合创始人兼总裁 Greg Brockman 开始休假，直至年底。联合创始人兼备受尊敬的研究员 John Schulman 离职。

2024年9月25日
OpenAI 首席技术官 Mira Murati 辞职，她在 2023 年 Altman 被解职期间曾短暂担任临时 CEO。

“我们深切致力于我们的使命，并为我们发布的业内最强大、最安全的模型感到自豪，”她表示。

《华尔街日报》所有者新闻集团与 OpenAI 有内容授权合作关系。

以下内容基于对 OpenAI 现任和前任员工及公司内部人士的采访。

** 一场失败的重聚

OpenAI 员工将去年 11 月 Altman 的解职和复职称为“风波”，因为这场风波仅持续了几天时间。但其影响仍在持续。

第一个征兆是 OpenAI 联合创始人之一、备受尊敬的研究科学家 Ilya Sutskever 的离开。他是将解职消息传达给 Altman 的人，并随后为自己在事件中的角色公开道歉。他再也没有回到公司工作。

今年 5 月，Sutskever 辞职。不久之后，与 Sutskever 共同领导安全团队的 Jan Leike 也辞职。OpenAI 高层担心他们的离职可能引发更大规模的人员流失，并积极尝试让 Sutskever 回归。

OpenAI 专注于稳步改进 ChatGPT 和其他产品。Murati 和总裁 Greg Brockman 告诉 Sutskever，公司正处于混乱中，如果没有他，公司可能会面临崩溃。他们前往 Sutskever 的家中，带去其他员工的贺卡和信件，恳请他回归。Altman 也前去拜访，并对其他人未能找到解决方案表示遗憾。

Sutskever 向前同事表示，他正在认真考虑回到公司。但不久后，Brockman 打电话告知他公司撤回了让他回归的提议。公司内部高管在确定 Sutskever 新角色及其如何与其他研究人员共事（包括他的首席科学家继任者）方面遇到了困难。

不久后，Sutskever 创办了一家专注于开发最先进 AI 的新公司，不再为中途发布产品分心。新公司名为 Safe Superintelligence，已筹集了 10 亿美元资金。

Sutskever 尚未公开评论他离职的具体情况。5 月 17 日，Leike 在 X 上发文表示：“我与 OpenAI 领导层在公司核心优先事项上的分歧已久，最终达到了一个临界点……近年来，安全文化和流程已经让位于更为吸引人的产品。”

随后，他加入了 Anthropic 工作。

** 匆忙的发布

今年春天，围绕新 AI 模型 GPT-4o 的开发，OpenAI 内部紧张局势加剧。该模型将用于支持 ChatGPT 和商业产品。研究人员被要求进行比原计划更为全面的安全测试，但时间仅为 9 天。高管们希望在谷歌年度开发者大会之前推出 4o，以抢占更多关注，盖过这个更大竞争对手的风头。

安全团队每天工作 20 小时，没有时间核查他们的工作。基于不完整数据的初步结果显示，GPT-4o 符合部署的安全标准。但在模型发布后，知情人士表示，后续分析发现该模型的劝说能力超出了 OpenAI 内部标准——即创建能够说服人们改变信念并参与潜在危险或非法行为的内容的能力。

团队将问题报告给高管，并着手进行修复。但部分员工对这一过程感到沮丧，认为如果公司在安全测试上多花些时间，他们本可以在问题到达用户之前就解决它。

OpenAI 的女发言人表示，团队检测到的高风险指标是由于方法上的缺陷而被错误地提高，GPT-4o 在公司的标准下是可以安全部署的。她说，OpenAI“对 4o 的中等风险评估继续保持信心。”

急于推出 GPT-4o 是影响 Murati 等技术领导者的一个普遍现象。作为首席技术官，她曾多次推迟搜索和语音交互等产品的计划发布，因为她认为这些产品尚未准备好。

其他高级员工也越来越不满。联合创始人兼顶级科学家 John Schulman 告诉同事，他对 OpenAI 内部冲突感到沮丧，对未能挽回 Sutskever 感到失望，并担心公司原始使命的重要性正在减弱。

今年 8 月，他离开了 OpenAI，加入了 Anthropic。

** 高层风波

除了其他高管离职外，Altman 的重要副手之一 Brockman 目前也在休假。
Brockman 被视为 OpenAI 的长期忠实员工。2015 年 OpenAI 成立时，公司最初在 Brockman 的客厅里运作。后来，他甚至在一个工作日于公司办公室举办了婚礼。

但随着 OpenAI 的发展，他的管理风格引发了紧张局势。尽管身为总裁，Brockman 并没有直接的下属。据现任和前任员工透露，他喜欢插手任何感兴趣的项目，这常常让相关人员感到不满。他们表示，Brockman 经常在最后一刻要求对已规划好的项目进行修改，迫使包括 Murati 在内的其他高管出面调和。

去年在首尔的一次活动上，OpenAI 总裁 Greg Brockman 与 Altman 同台。

多年来，员工一直敦促 Altman 约束 Brockman，称他的行为让员工士气低落。这些担忧一直持续到今年，最终 Altman 和 Brockman 同意他应暂时休假。
上个月，Brockman 在 X 上写道：“我将在年底前休假。这是我自 9 年前共同创立 OpenAI 以来首次放松。”预计他会回归。

然而，公司高层已经人手不足。就在 Murati 辞职的同一天，OpenAI 的首席研究官和副总裁也相继离职。

Altman 现在需要加强他的管理团队，设法完成对公司至关重要的数十亿美元融资，并开始将非营利组织转型为营利性公司的复杂进程。如果 OpenAI 在两年内未完成转型，新一轮融资的投资者将有权撤回资金。

他必须在公司面临公开危机和挑战的同时，维持员工士气。

周三晚上，OpenAI 技术团队的一名员工在 X 上调侃称：“今天，我做出了一个艰难的决定，那就是继续留在 OpenAI。”

来源：http://wsj.com/tech/ai/open-ai-division-for-profit-da26c24b



### 137

2024-09-27


歸藏(guizang.ai)
@op7418
Brockman 被视为 OpenAI（一家人工智能公司）的元老级员工。

2015 年 OpenAI 成立之初，公司甚至在 Brockman 的客厅里办公。

后来，他甚至选择在公司办公室的工作日举行婚礼。

然而，随着 OpenAI 的发展，他的管理风格引发了不少矛盾。

尽管身为总裁，Brockman 却没有直接下属。根据现任和前任员工的说法，他倾向于随意参与任何他感兴趣的项目，这常常让项目参与者感到沮丧。

他们表示，Brockman 经常要求对长期计划的项目进行临时变更，这迫使包括首席技术官 Murati 在内的其他高管不得不出面协调。

多年来，员工一直敦促首席执行官 Altman 约束 Brockman，称他的行为严重打击了员工士气。这些担忧一直持续到今年，最终 Altman 和 Brockman 达成一致，同意后者应该暂时离职休假。

Brockman 上个月在 X 平台（原 Twitter）上写道："我正在休假直到年底。这是自 9 年前共同创立 OpenAI 以来第一次真正放松。"预计他将会回来。


### 138

2024-09-27

Megabits 🐚
@Megabits_mzq
Winamp 如约开源了，但接踵而来的是巨大的混乱。

Winamp 的开源协议非常离谱，一边说自己 Copy Left，一边禁止其他用户分发甚至是 Fork 仓库。

另外这帮人似乎完全不会用 Git，刚公开的仓库中有一堆闭源项目，可执行文件，甚至是机密的代码，而这帮人竟然在用 Git 提交删文件，不知道这约等于没删。



### 139

2024-09-28


歸藏(guizang.ai)
@op7418
Emu3 这个架构有点吊啊。

通过预测下一个词或token的方式来理解和生成文本、图像和视频。

只用一个简单的transformer模型就能完成多种任务；

支持图片生成、视频生成、视频延长、图片内容识别等任务。

主要生成的视频看起来效果很不错，感觉是条可以投入的新路子。


### 140

2024-09-28

歸藏(guizang.ai)
@op7418
AI2 推出了 Molmo 完全开源的多模态LLM。

他们这个图片标注的功能非常好，不止可以语言描述位置和数量还会在图片上标出来。

在学术基准和人类评估上几乎达到了 GPT-4V 的性能。

发布的模型包括MolmoE-1B、Molmo-7B-O、Molmo-7B-D、Molmo-72B。

同时还会开源他们的多模态训练数据集 PixMo。



### 141

2024-09-28

宝玉
@dotey
开个 Thread 整理一下 OpenAI DevDay 的更新。由于没有视频，只能从 X 上分享的信息整理。

推出了实时语音的 API，也就是 ChatGPT 里面的高级语音功能，付费开发者就可以使用。你也可以打造自己的实时语音对话功能了！再也不需要像以前先 Whisper 转录，ChatGPT 生成，再文本转语音。

不过价钱不算便宜，但也可以接受，每分钟音频输入大约 0.06 美元，音频输出约 0.24 美元。不考虑输入，10 分钟的输出音频就是 3 美元。

付费的 API 用户现在就可以使用了，实时 API 的音频功能由 GPT-4o 模型 gpt-4o-realtime-preview 提供支持，使用的是 Web Socket 通信，网页和移动 App 对 Web Socket 通信都有很好的兼容。



### 142

2024-09-28

硅谷王川 Chuan
@Svwang1
NotebookLLM 是 chatgpt 以来我看到最惊艳的产品。

第一反应，是很多做播客的要失业了。

第二反应是听了一下，里面有些对于文字的总结相当深入，切中要害，非常深度的思考，不是简单的抄袭复读。

第三反应是肯定很多竞争产品要涌现。

第四反应是究竟谁能捕捉长期的价值，还需要观察等待。



### 143

2024-09-28



自在夺造化
@Danielw19410
我反而觉得很多本来想做播客但是嫌麻烦的现在很容易就可以做起来了，因为生成像真人的音色是如此之容易。
比如有人整理了段永平的语录出了两本书，现在将音色克隆变成段永平亲自给你讲投资，巴菲特也是同理。
类似的还有各种爱写博客、推特的输出者都可以克隆自己的音色让关注者低成本持续互动。


### 144

2024-09-28

宝玉
@dotey
这个动画效果做的真酷！另外作者有一个网站，专门卖他做的各种动效。

这对独立开发者来说也是个不错的思路，不一定要做一个牛逼的产品，卖技术（源码、技术支持等等）也可以，产品卖不出去不一定要把自己的代码开源，或者不仅仅开源，可以把自己代码打包卖或者提供后续的收费服务
引用
LN
@ln_dev7
·
9月30日
Subscriptions Calendar.

Made with Tailwind and Framer Motion.

Inspired by @KumailNanji



### 145

2024-09-28

宝玉
@dotey
我觉得独立开发者卖课赚钱造血没问题，只是去卖课之前需要把一些问题想清楚，比如：为什么要当独立开发者？卖课又是为了什么？

如果你当独立开发者是因为理想，想做伟大的产品，那么卖课会不会偏离你的理想，会不会牵扯你太多精力，导致两头顾不上？

如果你需要造血，卖课是不是最佳选择？辛苦去卖课了就会有回报吗？那么多独立开发者怎么卖课成功的没有那么多？那些卖课成功的有哪些优势？我是不是可以复制这些优势？我自己有哪些优势？

如果你当独立开发者是为了赚钱，那么为什么要选择当独立开发者？大厂打工收入也可以，做外包也可以，如果卖课也是为了赚钱，那还需要当独立开发者吗？是不是以后专心卖课就好？

如果要去专业卖课，你能提供的知识有多少？能以什么样的形式售卖？怎么让人知道你的课程？怎么卖的出去？

当你的这些知识卖完了你怎么保证后续的知识更新和持续输出？

卖课不是问题，只是去卖课之前把问题先想清楚，最好不要头脑一热去卖课，最后发现课也没卖出去，产品进度也耽误了，毕竟人的精力是相当有限的。

“将军赶路 不追小兔”



### 146

2024-09-28


歸藏(guizang.ai)
@op7418
Open AI 开源了一个新的 Whisper turbo 模型。

这是 Large v3 模型的蒸馏模型
运行速度提升了8倍
显存 (VRAM) 使用效率提高了40%
准确度仅有微小降低

太猛了，在使用Whisper的服务可以替换了。