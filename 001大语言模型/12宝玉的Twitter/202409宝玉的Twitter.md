### 01

2024-09-01


白板报 Zhongwen.ai
@zhongwen_ai
cursor有多靠谱？我让cursor索引了我的笔记库，以 
@wshuyi
 老师为关键词，让它帮我总结王老师的特点，结果令人惊叹。

王树义老师的特点包括：

1. **执着研究工具**：他对工具的深入研究影响了很多人。
2. **无私分享知识**：总是无私地分享他的知识。
3. **新技术应用**：带来新技术的应用。
4. **倡导“重器轻用”**：提倡合理使用工具。
5. **技术指导和鼓励**：在技术上给予指导，在视频上给予鼓励。
6. **行动模范**：在行动上树立榜样。
7. **直播支持**：每次直播都给予支持。
8. **演讲和教学**：通过演讲和教学分享他的经验和知识。
9. **反思和改进**：反思工具对写作的帮助，并不断改进。

这些特点使他成为一个值得尊敬和学习的导师。


### 02

2024-09-01


meng shao
@shao__meng
Qwen2-VL: 更清晰地看世界

通义千问两天前发布的最新视觉语言模型，提供了 2B、7B 和 72B 三种参数规模，其中 2B 和 7B版本已开源，72B 版本提供 API 访问。

主要特点和能力:
- 支持不同分辨率和长宽比的图片理解
- 可理解 20 分钟以上的长视频
- 具备视觉智能体能力，可操作手机和机器人
- 支持多语言，包括大多数欧洲语言、日语、韩语等

性能表现:
- 在多项视觉理解基准测试中取得全球领先成绩
- 72B 模型在大部分指标上超过 GPT-4o 和 Claude 3.5 Sonnet 等专有模型
- 7B 模型在大部分指标上超过 GPT-4o-mini
- 2B 模型在大部分指标上超过 MiniCPM-V 2.0 和 InternVL2-2B 
@OpenBMB
 
@opengvlab
 
- 在文档理解方面表现尤为出色

关键能力:
- 细节识别和理解: 能识别场景中多个对象的关系，增强了手写文字和多语言识别
- 视觉推理: 增强了数学和编程能力，可解决实际问题
- 视频理解: 能总结视频要点，回答相关问题，维持连贯对话
- Visual Agent: 支持函数调用和视觉交互，可执行自动化任务

项目地址：
https://qwenlm.github.io/blog/qwen2-vl/




### 03

2024-09-01

宝玉
@dotey
敏捷开发的精髓：
- 持续可以交付：即使是半成品，也是可以运行的半成品，好过什么都看不到
- 时间盒子：Deadline倒逼生产力，到时间了得交付，可以缩小Scope，但是不能延期
- 小团队：减少依赖减少沟通成本
- 仪式感：通过每日站会这种仪式性的会议，加强沟通激发主动性



### 04

2024-09-01


𝓨𝓪𝓷𝓰𝔂𝓲
@Yangyixxxx
我觉得还有2个比较重要的会议，为scrum带来了两个超级优势

一个是全员参与需求会，PO的列表所有人都会一起审视，这样能达成极强共创与目标一致性，自己有参与感，而不是觉得自己只是个机器，这样对需求功能和用户的理解也更深入，往往有一些创造性溢出

第二个是故事点评估会，因为大家都会对需求投票，就会倒逼团队把大型需求全部解耦成独立的小功能，投票时需求复杂度在L以上的任务将全权被拆解成xs s 或m的

并且因为大家对需求复杂度有了整体性评估，有人投L有人投XS，就可以互相聊对功能实现上的差异点在哪儿，很多时候会把信息鸿沟抹平

举个例子，比如拿铁锤最近在做的兑换码系统来讲，有些人可能觉得是个Large需求，但有人投XS，问一问他为什么和大家投M的不一样，他会说因为我之前接入过第三方开源的兑换码系统，可以直接拿来用

就因为这种讨论，导致有些人做某个功能会非常快。

另外，由于很多新人对于技术能力有一些瓶颈，通过这些投票讨论也能让老人带动新人，新人实现会觉得难，老人会把简单的方法同步。

通过故事点评估会，加上跑过2-3个sprint后，对团队的故事点产能就有了明确的估计。

比如5人团队，每个人能解决的需求复杂度不一样，但可能整体一个1.5周的sprint就是处理80个故事点

那PO在需求会议时，就排80点的任务，就不再继续拖task进入了，如果sprint超额完成时会有多余的工作量来做一些问题fix或者重构。假定能稳定完成2-3个sprint后，就可以再增加一些故事点任务到下一期的排期中。

我觉得这两个很重要的会议，看似可能降低了很多开发时间，要拿出甚至1-2天来开会，但实际带来的价值远远高于直接进入开发
引用
宝玉
@dotey
·
9月1日
敏捷开发的精髓：
- 持续可以交付：即使是半成品，也是可以运行的半成品，好过什么都看不到
- 时间盒子：Deadline


### 05

2024-09-01


歸藏(guizang.ai)
@op7418
海外最大的图像模型分享网站Civitai终于走出了这一步。

他们新开了一个 Civita Green 站点，里面只有安全的图片和模型，没有色情内容。

我上班找模型终于不用偷偷摸摸了。

同样在摆脱了色情和重口味内容后，他们也将开始更加大脚步推进商业化的进度。


### 06

2024-09-01


小互
@imxiaohu
HivisionIDPhotos ：一款开源的轻量级且高效的AI证件照制作工具

可以生成各种标准证件照

- 轻量级抠图：能够精确地从照片中抠取人像，生成干净的透明背景图像，为后续处理提供高质量的素材。

- 生成标准证件照：HivisionIDPhoto支持根据不同的规格要求生成标准证件照， 适用于各种用途，如护照、签证等 用户可以指定尺寸，并根据需要调整背景颜色和其他参数。

- 生成六寸排版照：该工具可以将多张证件照排版成标准的六寸照片，方便用户进行打印和批量制作。

- 智能换背景：支持为证件照增加或更换背景颜色，用户可以轻松选择符合要求的背景色，从而快速完成证件照的制作。

详细：https://xiaohu.ai/p/13086


### 07

2024-09-01

meng shao
@shao__meng
提出智慧问题的艺术

来自哈佛商业评论 
@HarvardBiz
 Top5 阅读者的文章之一，探讨了提出智慧问题的艺术，以及它对战略决策制定的重要性。 

智慧提问，同样也是使用 LLM 的诀窍所在，咱们一起看看这 5 种智慧问题对企业商业战略和对 LLM 的价值 👇👇

01 - 调查性问题 (Investigative):
目的: 深入了解已知信息
例如: "为什么?"、"怎么样?"
作用：帮助澄清目标，深入挖掘非显而易见的信息
对 LLM 的应用:
- 帮助我们更好地了解 LLM 的知识范围和局限性。
- 可以通过连续的 "为什么" 和 "怎么样" 来深入探索 LLM 对特定主题的理解程度。
- 有助于验证 LLM 提供的信息的准确性和来源。
- 例子: "你能详细解释一下量子计算的基本原理吗? 为什么它比经典计算更有优势?"

02 - 推测性问题 (Speculative):
目的: 拓宽思考范围，探索创新解决方案
例如: "如果...会怎样?"、"还有什么可能性?"
作用: 帮助重新框定问题，突破限制性假设
对 LLM 的应用:
- 激发 LLM 的创造性和想象力，产生新颖的想法和解决方案。
- 探索 LLM 在假设情景下的推理能力。
- 帮助我们突破常规思维，考虑新的可能性。
- 例子: "如果我们能够完全控制地球的气候，会对生态系统产生什么影响?"

03 - 生产性问题 (Productive):
目的: 评估资源可用性和执行能力
例如: "我们如何完成这个?"、"如何衡量进展?"
作用: 帮助识别关键指标、里程碑和潜在瓶颈
对 LLM 的应用:
- 帮助规划和组织使用 LLM 完成复杂任务的步骤。
- 评估 LLM 在特定任务上的能力和局限性。
- 优化 LLM 的输出，使其更加实用和可执行。
- 例子: "我们如何利用你的能力来优化一个大型软件项目的开发流程? 需要考虑哪些关键步骤?"

04 - 解释性问题 (Interpretive):
目的: 综合信息,提取意义
例如: "从这里我们学到了什么?"、"这意味着什么?"
作用: 帮助将信息转化为可行的洞察
对 LLM 的应用:
- 帮助我们理解和解释 LLM 的输出，特别是复杂或抽象的概念。
- 将 LLM 的回答与更广泛的上下文联系起来。
- 提炼 LLM 提供的信息，得出有意义的见解。
- 例子: "基于你刚才对全球经济趋势的分析，这对新兴市场的中小企业意味着什么?"

05 - 主观性问题 (Subjective):
目的: 探讨个人保留意见、挫折、紧张关系和隐藏议程
例如: "你对这个决定的真实感受是什么?"
作用: 帮助解决可能使决策偏离轨道的人际问题
对 LLM 的应用:
- 探索 LLM 在处理主观和情感相关问题时的能力。
- 帮助我们理解 LLM 对伦理和价值观问题的 "看法"。
- 提醒我们 LLM 的局限性，尤其是在需要人类判断和情感智慧的领域。
- 例子: "从道德角度来看，在医疗资源有限的情况下，如何公平地分配这些资源?"

原文地址：
https://hbr.org/2024/05/the-art-of-asking-smarter-questions




### 08

2024-09-01



meng shao
@shao__meng
开源 AI 发展趋势摘要

来自 
@synaptic_data
 的文章，深入探讨了开源 AI 的最新发展趋势，包括市场概况、生态系统发展、资金状况、技术进展、GitHub 趋势以及未来展望等。这些信息反映了开源 AI 领域的快速发展和巨大潜力。

01. 生态系统发展
- 开发者参与度稳步增长，进入"启蒙阶段"
- 初创公司数量显著增加，涉及领域从基础工具扩展到模型训练和监控

02. 资金状况
- 过去两年超过 60 笔交易，总融资额超 130 亿美元
- 45% 以上为 A 轮及以上融资，表明投资重点转向成长期企业
- 主要资金流向：模型训练和开发者工具 (占总融资额的 60%)
- NVIDIA 持续作为战略投资者参与

03. 技术进展
- 开源模型 (如 Meta Llama、Mistral) 在 MMLU 等基准测试中已接近 GPT-4
- 新兴领导者：Qwen、Llama 和 Phi-3.5 模型获得显著关注

04. GitHub 趋势
- 新兴热门项目：LeRobot 
@LeRobotHF
 (机器人技术)、MindsDB 
@MindsDB
 (AI 模型构建平台)

05. 未来展望
- 开源 AI 模型性能持续提升，与闭源模型差距进一步缩小
- 开发者参与度稳定增长，进入价值驱动的创新阶段
- 创新重点从基础模型和开发工具扩展到训练和监控领域
- 融资规模和数量显著，反映行业潜力巨大

报告原文：
https://synaptic.com/resources/open-source-ai-2024/



### 09

2024-09-02


宝玉
@dotey
Andrej Karpathy
https://youtube.com/@AndrejKarpathy

Andrej Karpathy 是前 OpenAI 创始人之一，前特斯拉自动驾驶的负责人，他的油管频道上有很多专业的 AI 相关教学视频，质量很高，比如教你从头写一个 GPT 之类，听说在有的大学里面他的视频都属于辅助教学的材料。
youtube.com
Andrej Karpathy
下午3:13 · 2024年9月2日
·
8,937
 


### 10

2024-09-02


宝玉
@dotey
问：参加展会，需要将展会信息扫描成PDF然后做OCR，但是手工摘录供应商信息效率太低。尝试对PDF分割做分割后OCR，再让GPT识别生成文本字段，但是有些供应商字段不完整，无法直接输出到Excel，效率很低。该如何去改善？（参考图1）

答：
OCR 建议使用 Gemini 模型，比GPT效果识别效果更好

没有必要预先对PDF预分割处理，整张图片直接发给 Gemini 就可以帮你自动识别不同厂商和各个字段

优先考虑使用 JSON 格式提取结构化数据，CSV 格式不是 Gemini 这样的模型擅长的模式，输出时经常会出现错乱。

可以根据厂商信息预先定义好JSON的格式，要求包含哪些字段，那么 Gemini 在生成时会自动帮你填充到对应字段，在定义Schema时，将字段定义为不是必须要有的，那么没有相应的内容在输出时就会跳过，不会影响整体输出。(参考图2）

提示词可以比较简单：
> 请将展商目录中的展商信息按照JSON Schema的定义提取成JSON数组。

从截图（图3）中可以看出，基本上很完美的输出了期望的JSON格式，按照想要的结果都填充到了相应的字段。

得到JSON格式后，可以用一段小程序（Python、Javascript等），将JSON读取后转成CSV文件。

整个过程也可以用Python或者JS这种程序写成代码，用代码去将PDF转成每一页一张图片，调用 Gemini API 去解析图片获得 JSON 结果，解析 JSON 结果，拼接后生成一个大的CSV 文件。 （理论上来说这么简单的程序让 Cursor、GPT-4、Claude 3.5 都是可以搞定的）

关键部分还是在大语言模型部分，要善于利用大语言模型，借助提示词，让其返回“你想要的格式”+“它擅长的格式”。再配合代码将整个过程自动化。

很多时候“你想要的格式”并不是它擅长的，比如 Excel 或者 CSV，这时候就要学会变通，让其生成它擅长你也可以借助程序转换成“你想要的格式”，比如 JSON 格式。
引用
宝玉
@dotey
·
8月23日
最近有个朋友跟我讨论技术问题，他在用个第三方的OCR的服务，用来提取发票上的文字为结构化数据。但收费较高，想自己实现一套，试了开源的


### 11

2024-09-02





### 12

2024-09-02





### 13

2024-09-02





### 14

2024-09-02





### 15

2024-09-01





### 16

2024-09-01





### 17

2024-09-01





### 18

2024-09-01





### 19

2024-09-01





### 20

2024-09-01





### 21

2024-09-01





### 22

2024-09-01





### 23

2024-09-01





### 24

2024-09-01





### 25

2024-09-01





### 26

2024-09-01





### 27

2024-09-01





### 28

2024-09-01





### 29

2024-09-01





### 30

2024-09-01





### 31

2024-09-01





### 32

2024-09-01





### 33

2024-09-01





### 34

2024-09-01





### 35

2024-09-01





### 36

2024-09-01





### 37

2024-09-01





### 38

2024-09-01





### 39

2024-09-01





### 40

2024-09-01





### 41

2024-09-01





### 42

2024-09-01





### 43

2024-09-01





### 44

2024-09-01





### 45

2024-09-01





### 46

2024-09-01





### 47

2024-09-01





### 48

2024-09-01





### 49

2024-09-01





### 50

2024-09-01





### 51

2024-09-01





### 52

2024-09-01





### 53

2024-09-01





### 54

2024-09-01





### 55

2024-09-01





### 56

2024-09-01





### 57

2024-09-01





### 58

2024-09-01





### 59

2024-09-01





### 60

2024-09-01





### 61

2024-09-01





### 62

2024-09-01





### 63

2024-09-01





### 64

2024-09-01





### 65

2024-09-01





### 66

2024-09-01





### 67

2024-09-01





### 68

2024-09-01





### 69

2024-09-01





### 70

2024-09-01





### 71

2024-09-01





### 72

2024-09-01





### 73

2024-09-01





### 74

2024-09-01





### 75

2024-09-01





### 76

2024-09-01





### 77

2024-09-01





### 78

2024-09-01





### 79

2024-09-01





### 80

2024-09-01





### 81

2024-09-01





### 82

2024-09-01





### 83

2024-09-01





### 84

2024-09-01





### 85

2024-09-01





### 86

2024-09-01





### 87

2024-09-01





### 88

2024-09-01





### 89

2024-09-01





### 90

2024-09-01





### 91

2024-09-01





### 92

2024-09-01





### 93

2024-09-01





### 94

2024-09-01





### 95

2024-09-01





### 96

2024-09-01





### 97

2024-09-01





### 98

2024-09-01





### 99

2024-09-01





### 100

2024-09-01





### 101

2024-09-01





### 102

2024-09-01





### 103

2024-09-01





### 104

2024-09-01





### 105

2024-09-01





### 106

2024-09-01





### 107

2024-09-01





### 108

2024-09-01





### 109

2024-09-01





### 110

2024-09-01





### 111

2024-09-01





### 112

2024-09-01





### 113

2024-09-01





### 114

2024-09-01





### 115

2024-09-01





### 116

2024-09-01





### 117

2024-09-01





### 118

2024-09-01





### 119

2024-09-01





### 120

2024-09-01





### 121

2024-09-01





### 122

2024-09-01





### 123

2024-09-01





### 124

2024-09-01





### 125

2024-09-01





### 126

2024-09-01





### 127

2024-09-01





### 128

2024-09-01





### 129

2024-09-01





### 130

2024-09-01





### 131

2024-09-01





### 132

2024-09-01





### 133

2024-09-01





### 134

2024-09-01





### 135

2024-09-01





### 136

2024-09-01





### 137

2024-09-01





### 138

2024-09-01





### 139

2024-09-01





### 140

2024-09-01





### 141

2024-09-01





### 142

2024-09-01





### 143

2024-09-01





### 144

2024-09-01





### 145

2024-09-01





### 146

2024-09-01





### 147

2024-09-01





### 148

2024-09-01





### 149

2024-09-01





### 150

2024-09-01





### 151

2024-09-01





### 152

2024-09-01





### 153

2024-09-01





### 154

2024-09-01





### 155

2024-09-01





### 156

2024-09-01





### 157

2024-09-01





### 158

2024-09-01





### 159

2024-09-01





### 160

2024-09-01





### 161

2024-09-01





### 162

2024-09-01





### 163

2024-09-01





### 164

2024-09-01





### 165

2024-09-01





### 166

2024-09-01





### 167

2024-09-01





### 168

2024-09-01





### 169

2024-09-01





### 170

2024-09-01





### 171

2024-09-01





### 172

2024-09-01





### 173

2024-09-01





### 174

2024-09-01





### 175

2024-09-01





### 176

2024-09-01





### 177

2024-09-01





### 178

2024-09-01





### 179

2024-09-01





### 180

2024-09-01





### 181

2024-09-01





### 182

2024-09-01





### 183

2024-09-01





### 184

2024-09-01





### 185

2024-09-01





### 186

2024-09-01





### 187

2024-09-01





### 188

2024-09-01





### 189

2024-09-01





### 190

2024-09-01





### 191

2024-09-01





### 192

2024-09-01





### 193

2024-09-01





### 194

2024-09-01





### 195

2024-09-01





### 196

2024-09-01





### 197

2024-09-01





### 198

2024-09-01





### 199

2024-09-01





### 200

2024-09-01





