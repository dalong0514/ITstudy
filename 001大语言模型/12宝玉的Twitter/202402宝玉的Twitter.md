### 01

2024-02-04


Andrej Karpathy
@karpathy
Early thoughts on the Apple Vision Pro (I ended up buying directly in store last evening). I'm about 3 hours in, between late last night and this morning.

The first major thing that must be said is WOW - the visual clarity is way beyond anything that came before. But, a bit unexpectedly, this is so in some strange mixed way - your surroundings (the passhtrough) are a bit blurry and even a tiny bit laggy. But anything rendered fully virtually, e.g. a screen is very sharp and easily readable. Super cool. I mean, just the simple experience of arranging a few windows around your living room and moving around them is incredible. I feel very creative thinking through and designing my ideal setup of all the apps in my space. Mind is blown and goes places.

The second major thing is a bit less upbeat. This launch is not like the other Apple launches. It is off-brand. It is selectively and inconsistently either highly polished, or highly raw/undercooked, poorly throught through, janky or even straight up buggy. It's like some parts of the org get an A+ and some get an F.  Or it's like some of them had 4 years to work on their part, and some had 4 months. It's like it was rushed a bit to "just ship" and basic UI/UX interactions weren't finished, thought-through or debugged.

Jank
Let me describe a bit some of the jank. The setup was a bit too long and janky for me. At one early point you're asked to bring your unlocked iPhone close, but you can't unlock your iPhone because your face is obviously covered so FaceID doesn't work... ?. Then I had some error connecting the phone to it so I had to go through "manual" setup. Then the sound wasn't working until I rebooted. Then I got an iMessage from a friend and I was shown a notification inside the Vision Pro about it, but when I clicked into iMessage app, it was fully empty - where is the message? When launching Guest Mode to show a friend, nothing tells you that you're supposed to also press the digital crown to activate. Very simple interactions are buggy - e.g. in the app store when I select an app to preview it and then hit back, I'm forced to for some reason go back 10 times through previously previewed apps to get back to the main screen, some bug or something. My Disney+ app never opened, it just spins forever, I'm not sure how to launch this app. When you launch Apple TV, there is zero indication or recognition of the fact that you're inside Vision Pro. No featured content, no custom content, no text indicating anything, no nothing. I'm not sure, I thought there would be a few surround videos or something? Also my brain: "$3500 for a Vision Pro? Yes two please! $9.99 for AppleTV+? Absolutely not." More generally, as you access Apple apps, a lot of them are just ignoring that you're inside a Vision Pro, and just pretending like nothing happened. I'd want new Spatial Content and interactions to be 100% front and center and featured. The "copy pasting" of stuff seems pervasive.

The raw Spatial Computing OS is there, but it's almost like the OS is all there is. The apps that take advantage in any way of "Spatial Computing" seem few and are somehow also hard to find and/or not prominently featured. There's the little blue guy app who you can poke and he laughs. There's the jet engine app, which is kind of cool, but I wasn't actually really learning anything, it felt gimmicky, like an early demo. There are some really cool environments, but why are there only 5 of them?. There's what seems to be some early grifter content on the app store, from people trying to sell you e.g. a super basic looking watch app that just shows time, for $2.99. The ability to look at your laptop and just "connect" worked the second time, and it was glorious, wow. Your screen just shows up in your living room and you can use the keyboard/mouse. Very cool.

The Vision Pro is sadly a little bit too heavy and it doesn't "disappear" due to this, even with the double strap (which is essential). I feel a bit pressure from the device on my head. But it's okay, we're at the edge of what is possible. A bunch of other small things. The world shakes a little bit with every step, especially if you land a bit harder on a heel. You have to unlearn and relearn some UIUX, because your eye gaze is now your active pointer. So you can't just look somewhere else a bit too early, before you "click" it. It's very cool that the eye tracking is so high quality.

Anyway, I'm rambling. Conclusions. The hardware itself and the core Spatial Computing OS aspects exceed my expectations. I loved sprawling on my couch, opening up a few windows, and I half-watched a movie while scrolling through web. I loved pacing around my room arranging my digital work/entertainment space. I FaceTimed a friend and we laughed about how silly my digital avatar looks, haha. I pulled up Music and played the only thing I have in it - that U2 album that was given to everyone back in 2014. nice. I'm very happy with this early preview of what could be possible, and using the current experience as a prompt to explore it.

Few recommendations to Apple come to mind: 1) eliminate simple bugs and jank. 2) fight early grifter content by featuring very very prominently any apps that are actually good, don't use dark patterns, are ideally free to try, and acknowledge in any way that the user is in a Vision Pro. 3) Consider a free subscription of AppleTV+, or maybe a $100 app gift card to those who purchase Vision Pro, so people don't lock up (?). It feels bad to pay that much money just to get in, and then immediately feeling like you're blocked behind additional pay walls, for experiences that could very well be very very raw and undercooked. 4) In general, feature a lot more prominently any content that is actually designed for spatial computing. I don't want to just put up iPad apps around me.

I am simultaneously wearing a revolution in computing, and the software to actually show me around is not just absent but what is there is mildly janky and annoying.

Ok, this concludes the section where I just "wing it" based on what I'm seeing, going in fairly blind, over the first ~3 hours. I will now do a bit more research, read more, watch some videos/tutorials, and come back for round 2.


### 02

2024-02-04

Yangyi
@Yangyixxxx
看完了视频，有两个观点收获比较大，人工+GPT4整理了一下：
第一个观点是提及AI来临时，人类将在三个方面出现价值溢价：

真正的创造力（Real Creativity）：虽然生成式AI能够模拟创造性的任务，如写作、艺术设计等，但它基于已有的数据和模式生成内容，缺乏真正的创新和创造力。因此，在需要原创思维和创新解决方案的领域，人类的创造力价值将会增加。

技术深度（Technical Skills）：尽管生成式AI的目标之一是简化技术任务，使非技术人员也能利用AI工具解决问题，但复杂的AI系统的设计、开发和维护仍然需要深厚的技术知识和专业技能。因此，具备这些技术深度的专业人士将变得更加宝贵。

领导力（Leadership）：无论技术多么先进，领导力和人际交往能力在组织中始终占据核心地位。领导者的角色不仅仅是指挥和管理，更包括激励团队、塑造企业文化、制定战略方向等，这些是AI当前无法复制的能力。

第二个观点谈及AIGC在企业场景使用时，企业应该采取一个集中和系统化的方法，这种方法应该聚焦于创造真正的商业价值和战略性的应用，而不是进行大量分散且缺乏集中目标的试点项目。
这个观点和国内实施落地时是有巨大差异的，或许是因为演讲者是一个高层视角看待问题的。但如果从以点及面的维度来思考这件事，就又是一致的。

数据整合（Data Integration）：成功实施生成式AI需要将来自不同来源和格式的数据整合到一个统一的平台或系统中。这不仅涉及技术挑战，如数据格式的统一、不同数据源的同步和数据质量的保证，还涉及组织层面的挑战，比如跨部门的数据共享和协作。

模型定制（Model Customization）：虽然生成式AI模型如GPT-3或GPT-4等提供了通用的能力，但为了满足特定的业务需求和应用场景，企业通常需要对这些模型进行定制。这包括训练模型以理解特定的行业术语、适应特定的业务流程，以及确保模型输出与企业的策略和价值观相符。

操作可扩展性（Operational Scalability）：在初期试点阶段，一个AI解决方案可能表现良好，但当尝试在整个组织或更大范围内推广时，可能会遇到性能、安全性和管理的问题。确保解决方案的可扩展性，包括能够处理更大数据量、服务更多用户、并且维持高性能和稳定性，是实施的一个重要挑战。

麦肯锡构建的知识管理工具是一个例证，展示了如何集中资源开发一个针对性强、以价值为驱动的生成式AI应用。这个工具利用生成式AI来提高顾问的工作效率和学习能力，通过自动化信息检索和知识提炼过程，让顾问能够更快地访问、理解和应用公司内外的广泛知识资源。这不仅提升了工作效率，也促进了组织内的知识共享和创新。

通过集中精力在一个或几个具有战略意义的项目上，企业可以更有效地投入资源，解决上述实施挑战，从而实现更大的业务影响和更高的投资回报。这种方法强调了在整个项目生命周期中，从规划和设计到实施和扩展，都需要持续的关注和投入，确保生成式AI技术能够为企业带来真正的商业价值。

### 03

2024-02-04


徐老猫
@raycat2021
很多人没想到的是，管理咨询机构麦肯锡如今主要的业务是AI战略转型。
麦肯锡向客户提供数字化转型的practice叫McKinsey Digital，已经占整个公司客户工作的一半，有数千名员工，近来主要就是协助客户实现向AI战略的转型。
这是去年12月麦肯锡公司发布在油管上的一个演讲，主讲人就是负责该业务的高级合伙人Zemmel。
他说过去半年里，他受邀参与的董事会会议比过去5年加一起还要多，“我敢断言，地球上每个董事会都在讨论人工智能的问题。”
这个半小时的视频可以了解麦肯锡是如何切入AI业务的。Zemmel的举手投足是典型的麦肯锡专家，精干善言又有几分学者气。
就如过去一样，麦肯锡是一个流动校园，很多合伙人、员工在做了几个案子后就会将屁股挪到甲方。撒豆成兵形成了一个严严实实的网络。
https://youtube.com/watch?v=USYxquYyGeQ

### 04

2024-02-04

宝玉
@dotey
阿里通义千问的多模态口碑不错👍🏻 根据它官网的描述：
* 显著提升与图像相关的推理能力；
* 在识别、提取和分析图像及其内含文本中的细节方面有明显增强；
* 支持百万像素以上的高清晰度图像以及各种宽高比的图像。

相比于开源版本的Qwen-VL，这两个模型在多个文本-图像多模态任务中与Gemini Ultra和GPT-4V的表现相当，显著超越了之前开源模型的最佳结果。值得一提的是，Qwen-VL-Max在中文问题回答和中文文本理解任务上超越了OpenAI的GPT-4V以及谷歌的Gemini。下文展示了实验结果及真实用例。

https://qwenlm.github.io/zh/blog/qwen-vl/


### 05

2024-02-04

宝玉
@dotey
在今天的2023 年第四季度财报电话会议中，马克 - 扎克伯格解释 Meta 为什么要开源其 AI 技术。

Meta开源其 AI 技术是出于推动技术创新、提升模型质量、建立行业标准、吸引人才、增加透明度和支持其长期战略的考虑。这不仅有助于 Meta 在竞争激烈的 AI 领域保持领先地位，也有助于推动整个行业的前进。

1. **促进行业创新**: 通过开源AI模型，Meta可以鼓励全球的开发者、研究人员和公司利用这些技术进行创新。这种共享精神有助于加速AI技术的进步，并推动新应用和服务的开发。

2. **提高模型质量**: 开源允许更广泛的社区参与到模型的测试和改进中来。来自全球的贡献可以帮助发现并修复错误，提出改进意见，从而提高模型的性能和可靠性。

3. **建立行业标准**: 通过将自己的技术开源，Meta有机会塑造行业标准和最佳实践。这种影响力可以确保Meta在AI领域的技术和方法得到广泛接受和使用，从而加强其市场地位。

4. **吸引和保留人才**: 开源项目通常对研究人员和开发者具有吸引力。通过贡献于开放且受尊重的项目，Meta可以吸引顶尖人才加入，这对于维持其在AI领域的竞争优势至关重要。

5. **提升安全性和透明度**: 开源AI模型可以提高透明度，让外部研究人员和公众能够更好地理解模型的工作原理和潜在影响。这有助于识别和缓解与AI应用相关的风险和伦理问题，从而增强公众对AI技术的信任。

6. **支持长期战略**: Meta开源AI技术也是其长期战略的一部分，旨在确保公司在AI和机器学习领域的长期领导地位。通过开源，Meta可以推动整个生态系统的发展，为自己的产品和服务创造更多的创新机会。

完整内容参考：https://s21.q4cdn.com/399680738/files/doc_financials/2023/q4/META-Q4-2023-Earnings-Call-Transcript.pdf
译文：https://baoyu.io/translations/meta/mark-zuckerberg-explains-why-meta-open-sources-its-ai


### 06

2024-02-04


Quinn Leng
@quinn_leng
非盈利机构 AllenAI 发布了真正完全开源 LLM “OLMo”，不止模型权重，还包含完整的训练代码、数据集和训练过程，而此前不论是 LLama 或 Mistral 都只公布部分细节。OLMo 为了打破 Nvidia GPU 的垄断，特地在 AMD 和 NVDA GPU 上都训练了一次，证明 LLM 训练是可以用 AMD 的。https://allenai.org/olmo/olmo-paper.pdf


### 07

2024-02-04

宝玉
@dotey
转译：蒂姆·库克为何全力以赴支持苹果视觉专业版

​​在苹果园区，这位科技巨头的 CEO 分享了一款“惊艳绝伦”的新设备的诞生历程，这款设备可能彻底改变我们的生活和工作方式。一线大导演们已经亲身体验并盛赞不已——詹姆斯·卡梅隆表示：“我的体验宛如宗教启示”——但普通的 iPhone 用户是否会愿意花费 3500 美元购买这样一个头戴式设备呢？

图一：首次公开亮相苹果视觉专业版的 CEO 蒂姆·库克，地点在他位于加州库比蒂诺的办公室。摄影：诺曼·吉恩·罗伊。

初次见面 蒂姆·库克体验苹果视觉专业版的那一刻，这个设备还没有被命名为“苹果视觉专业版”。那已是六七年甚至八年前的事了。那时，苹果园区尚未建成，我们现在正坐在这个令人叹为观止的圆形建筑里，围坐在一张漂白橡木的桌旁。外面刚下过雨，云层在松树、柑橘树和枫树间散去，阳光在草地上的池塘中反射，景致令人着迷。用他那柔和的阿拉巴马州罗伯茨代尔口音，库克向我回忆起那一次，多年前的那个瞬间。
那是在马里亚尼 1 号，一个普通的低层建筑，坐落在老无限循环园区的边缘，窗户被遮住。这个地方极其隐秘，被称为苹果的“黑色行动”设施之一。在苹果数以千计的员工中，几乎无人能进入此地。那里有多道上锁的门，每一步都紧紧锁住你的前后。但作为 CEO 的库克可以自由进出。他漫步通过那些被限制的房间，在那里，可折叠的 iPhone、带伸缩键盘的 MacBook 或透明电视等设备梦想成真。这些设备，几乎全部都不会离开这栋建筑，它们被储存在锁好的 Pelican 箱子里，而这些箱子又放在上锁的橱柜中。

图二：摄影：诺曼·吉恩·罗伊。

这座大楼对苹果来说，可谓是充满传奇色彩。正是在这里，iPod 和 iPhone 应运而生。正是在这栋大楼，库克发现了工业设计团队正在秘密研发一款几乎无人知晓的新产品。苹果视觉产品组的副总裁迈克·洛克威尔在库克进入时就在场，见证了这一刻。库克对我描述，这就像一个庞大的“装置”。他被邀请坐下，随后一个巨大、笨重的机器被放置在他的脸上。这个装置粗糙而庞大，像个巨型盒子，内嵌有六层屏幕，摄像头从四面伸出，像触须一样。库克回忆说：“那时候你根本无法真正穿戴它，它远非可穿戴设备。”同时，装置两侧的大风扇发出持续而深沉的嗡嗡声。这个装置的线缆蜿蜒地铺满地面，延伸至另一个房间，与一台超级计算机相连。随着按钮被按下，灯光亮起，CPU 和 GPU 开始以每秒数十亿次的速度运作……而此刻的蒂姆·库克仿佛置身月球之上！

他仿佛真的坐在那里，置身月球！与阿波罗11号任务的宇航员巴兹·奥尔德林和尼尔·阿姆斯特朗一同，他环顾四周，见证了古老月尘在星空下的幽灵般荧光。那景象壮观而令人叹为观止。在远处，可以看到蓝色的地球——这一切奇迹的发源地。

但库克不只是身处月球，他同时也在那个秘密的房间里，那栋神秘的大楼中。他能看见洛克威尔和其他苹果的员工，也能看到自己的双手。那一刻，他仿佛领悟到了什么，宇宙似乎在向他传达某种信息。他明白，这个包裹在他头上的原始装置，将彻底改变计算、娱乐、应用程序和记忆的未来。他深知，苹果必须将这个产品定位为其下一个重大产品类别。
“我多年来一直知道我们会达到这一步，”苹果首席执行官蒂姆·库克说。“我不确定具体时间，但我深信我们终将实现这一目标。”
库克当时并不清楚，他的工程师团队是如何将那些原本需要超级计算机、风扇和多屏幕的复杂装置，缩减为仅比意大利面盒稍重的眼镜大小。库克对我说：“我早就知道我们终将实现这一目标。”他补充说：“具体时间我不确定，但我坚信这一天总会到来。”

这个梦寐以求的时刻终于来临。首款视觉专业版，一个外形像大号鞋盒的完美白色立方体，将于周五正式上市。成千上万的苹果粉丝和先锋用户早已抢先预订。吸引这部分小众市场并不难。但库克和他的高管团队深知，要让更多人相信，在他们的日常生活、工作、娱乐、冥想，乃至记录不可思议的家庭记忆时，花费3500美元购买这款空间感知型电脑是必要的。这款头戴设备让你看起来仿佛置身于“矩阵”的滑雪场景，目前还无法使用如 Netflix 和 YouTube 这类流行应用。尽管如此，引人尝试苹果视觉专业版并不难，但让人真正购买可能就是另一回事了。幸运的是，对苹果来说，几乎每一个在发布前就试用过这款设备的人都如同获得了新生，对其功能赞不绝口。

“我会说，我的体验堪比宗教启示，”当我询问詹姆斯·卡梅隆他第一次体验苹果视觉专业版时，他这样告诉我。“最初我是持怀疑态度的，毕竟我不会对苹果盲目崇拜，但事实上，我被深深震撼了。”著名导演乔恩·费儒也有相似感受，他对我说，这项技术以及它对叙事艺术的影响让他震惊。（费儒为苹果专门制作了一段内容，展示了设备的3D效果，一只恐龙仿佛从屏幕中跃出，让人觉得它随时会向你扑来。）“我对现在能讲述的新故事感到兴奋，这是过去无法实现的。”他说。当我联系到资深科技作家 Om Malik 时，他更是激动地说：“太惊艳了！简直难以置信！”他兴奋地表示。“你能感受到宇宙的震动！”至于我接触过的其他人，他们对试用苹果视觉专业版的感受也各不相同：投资者感叹“哇！”，设计师惊呼“哇！”，分析师赞叹“哦！”，制片人则是“啊！”

当我走近那座全玻璃墙壁、似乎悬浮在空中的巨大圆顶的史蒂夫·乔布斯剧院时，脑海中回荡着众人的惊叹声和赞叹声。这是我第一次来到被昵称为“SJT”的地方，它是对那位伟大梦想家乔布斯的致敬。那时，一位苹果员工拿着一个像午餐盒大小的Pelican盒子走出来，我立刻知道里面装的是什么。没错，正是那种设备。看到他，我想起几个月前第一次与苹果接触时，我对盒子里的东西毫无兴趣。

完全不感兴趣。

我没有关注库克六月份关于苹果视觉专业版的发布会。对那些分析博客和社交媒体上的猜测也是一带而过，就像我对哈里和梅根的新闻那样。我在库克做发布会的同一间屋子里告诉他这一点，因为我已经见识过这一幕，知道每个阶段的样子，也预见了结局。

这件设备与虚拟现实头盔的差别，就像孩子的Schwinn自行车和Gulfstream G800私人飞机的差别一样巨大。

回想2013年，在洛杉矶的一间会议室里，我第一次戴上了Oculus VR头盔（这家公司后来被Facebook收购，Facebook又更名为Meta）。确实很酷，我也发出了惊叹声，当我在玩一个像毕加索在鸦片作用下设计的方块风格的游戏时，也不禁发出了一连串的感叹。但没过多久，我就感到了幽闭恐惧，到了中途，我甚至开始怀疑自己是否已经脱离了现实世界，只活在虚拟的世界里。在随后的十年中，尽管图形变得更加细腻，处理器也更快，但每次体验新的VR设备——无论是Rift、Vive、Quest、Quest 2还是Quest 3——我总是有同样的感受。我试过一两次之后，这些设备就被我束之高阁，放进了抽屉、橱柜或地下室的箱子里，因为我不想再体验那种戴着头盔时的幽闭感。

去年八月，我受邀参观苹果在洛杉矶的办公室，这里原是 Beats 的总部。本以为我会体验到的仅仅是又一款 VR 设备。坐在一间装饰着白橡木家具、地板光亮照人的时尚房间里，我脑海中只有一个念头：回家要多久，是否该绕过那个时候拥挤如梦魇的 405 高速。我坐在灰色沙发上，一名苹果员工让我戴上面前的 Apple Vision Pro。我不情愿地照做，心想尽快结束这一切。果然，像往常使用 VR 头盔一样，周围的世界一下子消失了。但这仅持续了几秒，一道数字幕布缓缓拉开，真实的世界呈现在眼前。我可以看见自己的手臂和腿，接着，五彩斑斓的苹果应用图标就像幻影般浮现。

这款设备与普通的 VR 头盔截然不同，就如同儿童的施温自行车与海湾流 G800 私人喷气机的差异。我回想起第一次在 iPod 上滑动手指，或在第一代 iPhone 上用手指和拇指放大图片的时刻。通过 Vision Pro，我只需看着一个应用图标，轻轻捏合手指，应用便会启动，清晰地出现在我眼前。我可以用手势轻松切换图片，用指尖移动物体。与其他需要用笨拙控制器的 VR 头盔不同，Apple Vision Pro 让你的眼睛无缝地变成了鼠标。“这真是令人震撼，”库克在听说我的体验后说道。“我们生活在三维世界中，却总是与平面内容打交道。”

在那次初体验中，我仿佛置身于俄勒冈州著名的胡德山火山，我能听到也能看到成千上万的雨点落入镜湖，感觉就像亲临其境，唯一缺少的，就是雨后泥土的那股清新气息。我亲手触碰了空中清晰逼真的图形，不需要鼠标或键盘。我还首次见识了空间视频，简直令人叹为观止。感觉视频中的人物就在你面前，仿佛能触手可及。我观看了宽达100英尺的电影片段，其清晰度和锐利度超越了任何IMAX影院。但最让我震撼的是，我能看到我周围的世界，那个房间的每一个角落。我没有感到被封闭或产生幽闭恐惧。我就在那里，仿佛身处万象之中。

那天，我离开了苹果公司的办公室，来到了附近的咖啡馆。当我打开我那台相对较新的笔记本电脑时，感觉它就像是从苏联时代遗留下来的古董。

“你知道，我们最常见的反应之一就是，人们会说‘等一下，我需要时间来消化刚才发生的事情’，” 苹果公司全球市场高级副总裁格雷格·“乔兹”·乔斯威亚克在苹果园区的午餐时分享道。“多酷啊！有多少产品能让人体验后哑口无言呢？”

“最开始，我其实是怀疑的，”导演詹姆斯·卡梅隆说。“我不是盲目崇拜苹果的，但这次体验真的让我大吃一惊。”

直到第二次演示，我才真正感到震惊。几个月后，我再次访问洛杉矶的办公室。两名苹果员工引导我进入一个房间。我戴上了苹果视界专业版眼镜，幕布拉开的那一刻，我看到了他们。这次不同的是，我手里拿着一杯茶。在演示过程中，我端起茶喝了一口，这时我的手指出现了短暂的闪烁，仿佛我身处一个与现实无异的模拟世界中出现了小故障。

“等等，我这是看到了什么？”我困惑地问。“这是真的吗，还是……”

“不，你看到的是我们的实时渲染视频，”一名员工解释说。我当时愣住了。我原以为自己看到的是真实世界，数字奇迹只不过是叠加在现实之上。我以为苹果视界专业版是透明的，只是在上面加了一层技术。实际上，情况正好相反。

“我觉得这不仅仅是进步，简直是革命性的，”当我和卡梅隆谈及我的体验时，他这样对我说。“我之所以这么说，是因为我已经在虚拟现实领域工作了18年。”他解释说，之所以看起来如此逼真，是因为苹果视界专业版向我的眼睛投射了4K图像。“这就像是把一台75英寸电视的清晰度投射到你每个眼睛里，总共有2300万像素。”作为对比，普通的4K电视大约只有800万像素。苹果工程师并不是简单地从4K显示屏上切下一块放进苹果视界专业版，而是将两倍于你眼球大小的像素压缩进了这么小的空间。对于像卡梅隆这样在这个领域深耕了二十年的专家来说，这种技术“解决了一切问题”。

尽管拥有令人赞叹的2300万像素，图像清晰到令人难以分辨真实与数字合成，但苹果仍有一些难题未能解决 — 至少目前是这样。

硅谷有个关于史蒂夫·乔布斯的老故事，大约发生在25年前。故事发生在那栋不显眼的 Mariani 1 黑色行动大楼，几年后，库克在这里首次见到了苹果视觉专业版原型。在90年代末，乔布斯领导的工程团队在此努力打造第一代 iPod，他们挑战极限，施展各种工程技巧，试图制作出一个尽可能小的 iPod 原型。当原型做到极致小巧时，他们将其呈现给乔布斯。这些原型价值连城，但乔布斯审视后，却说还要更小。工程师们回答已经做到极限了，乔布斯却将原型扔进鱼缸 — 溅起水花 — 并在它沉下去时说：“看那些气泡？说明还能更小。”

“这儿有 M2 芯片…R1 芯片…几乎零延迟…5000项专利…历经七年…” 苹果工业设计副总裁理查德·霍华斯用浓重的莱斯特口音说着，他指着我面前摆放的苹果视觉专业版拆解部件。但我脑海中只有那个鱼缸故事和 iPod 原型，思考着如果乔布斯今天还在，他会不会把这个设备扔进鱼缸，然后说：“看，还有气泡，可以更小！”

苹果视觉专业版最受诟病的一点是其体积和重量。它重约20盎司，虽然听起来不多，但你得知道，这相当于五根黄油棒的重量 — 想象一下整天带着这么重的东西在脸上。虚拟现实先驱卡罗琳娜·克鲁兹-内拉告诉我，佩戴设备的感觉极大影响人们对技术的接受度。“我从事 VR 行业已超过30年，只有当我们摘掉脸上笨重的‘潜水面罩’，使其变得更加轻便不显眼时，我们才能实现这项技术的大规模普及，”克鲁兹-内拉说。“而这些‘潜水面罩’的体积和重量问题，不可能在短短一年内得到解决。”

Apple Vision Pro 是否能成为商业上的成功，这个问题至关重要。虽然苹果的高层只是简单地对我说他们对目前的销售数据“感到兴奋”，但华尔街的分析师们估计，该公司在网上预售的第一个周末就售出了大约18万台。摩根士丹利预测，接下来五年内，其年销量将提升至200万至400万台，成为苹果的一个新产品种类。但像 Ming-Chi Kuo 这样的苹果供应链分析师却认为，它可能暂时只会是一个小众产品。不过，我所咨询的几乎所有分析师都相信，它最终会大受欢迎。“我们认为，几年后它的外观将类似太阳镜，价格也会降至1500美元以下，”投资公司 Wedbush Securities 的高级分析师 Dan Ives 对我说。

苹果全球市场营销高级副总裁 Greg Joswiak 表示：“这就像我们把手伸进未来，带回了这款产品。” “你是在将未来戴在自己的脸上。”

我甚至不用特意询问 Howarth 关于产品重量的问题，他自己就提到了这一点。他在解释产品的各个部件是由镁、碳纤维和铝（他的发音是英式英语，我作为英国人很欣赏）制成时，提到这些是地球上最轻的材料，目前还没有更轻更小的替代品。“我们已经做到极致，无法让它更轻更小，”Howarth解释说。我在苹果的其他同事那里也听到了类似的看法。“这就像我们把手伸进未来，带回了这款产品，”Joswiak对我说。“你是在将未来戴在自己的脸上。”Rockwell 也向我表示：“我们将尽可能多的技术集成进这个小巧的产品中。”

“你甚至可以躺在沙发上，把显示屏放到天花板上观看，”库克对我说。“我就是这样在天花板上观看了《Ted Lasso》第三季，效果惊人！”当我回家并开始使用我的 Apple Vision Pro 时，我也在天花板上观看了《Ford v Ferrari》，空间音效让我感觉就像 Ken Miles 的 Ford GT40 真的在房间里一样。“我觉得用它来冥想是一种前所未有的体验，我已经冥想很久了，”库克说。我一直不太会冥想，但他说得没错。“我还用它来提高工作效率，”库克补充道。

使用苹果 Vision Pro 虚拟键盘打字，就像用脚趾拿笔写字一样，虽然能做到，但并不实际。然而，当我戴上 Vision Pro 并打开我的 MacBook Pro 时，屏幕仿佛活跃在增强现实的空间里，让我能够流畅地工作。其实，你现在看到的这些文字，就是我在 Vision Pro 上通过 MacBook 输入的。我敢打赌，如果你此刻能看到我，一定会觉得我有点像 Minority Report 里的 Tom Cruise，当然，还多了几分帅气。至于那些空间视频，我已经录制了很多，记录着孩子们的嬉戏和谈话。这些看似平常的瞬间，在回放时却如此感人肺腑，仿佛我步入了一个鲜活的记忆之中。虽然难以用语言表达，但我时常回到名为 Mirror Lake 的地方，关闭所有通知，在水边静静地坐着，聆听雨声，享受片刻宁静，然后再回归工作。

使用这个设备确实有一些小怪癖。我最喜欢的是，当你在一个房间使用 Vision Pro，然后换到另一个房间打开同一个应用时，你需要四处寻找它。有时它竟然出现在天花板或地板上。有一天，我找不到我的文本应用，结果一转身，竟在浴室里发现了它（后来我才知道，按住数秒数字表冠可以重置应用）。但随着我这两周来对苹果 Vision Pro 的频繁使用，我逐渐意识到了一个显著的问题。这个问题不是重量（虽然有待减轻），也不是体积（随着技术进步会逐渐缩小），甚至不是它可能让我们更加孤独地消费内容（毕竟已有近半数美国人独自看电视）。也不是像 Meta、Netflix、Spotify 和 Google 这样的科技巨头尚未提供他们的应用（随着消费者基础的建立，内容创作者可能会改变态度，像迪士尼这样的公司已经开始支持这一设备，推出了包括 Star Wars 和 Marvel 在内的150部3D电影）。甚至价格也不是问题，因为苹果公司如果愿意，完全可以补贴 Vision Pro 的成本，对公司财务的影响不过是 Cook 沙发垫子里丢了一枚硬币而已。

我所关注的，是一个我看不到解决方案的问题。

我最初意识到这个问题是在苹果园区的 S.J.T 地下办公室。那时，我正坐在约书亚树沙漠的幽深剪影中，体验了一次令人印象深刻的演示。在《水果忍者》游戏中，我用双手切开飞来的水果。接着，我尝试了一款 DJ 应用，仿佛真的站在 DJ 台前，滑动音轨，调节音效，挠刮黑胶唱片。我甚至召唤出一个迪斯科球，仿佛置身于狂欢的舞者中。

一位硅谷投资者这样评价：“我承认这项技术非常先进，但我依然希望它不会成功。苹果现在越来越像一个隐藏在康复中心背后的高科技麻醉品贩子。”

在我的 DJ 表演中途，一位苹果员工提醒我结束体验。当我摘下 Apple Vision Pro，我突然有了一种领悟。这种感觉在家里也一样，当我浏览过去几周用这款设备记录下的孩子们的立体视频时，仿佛他们真的就在我眼前。当我完成这篇文章，眼前那个巨大的 Word 文档消失时，这种感觉又会涌现。

每当我摘下这款设备，其他所有的电子产品都显得平淡无趣：我那 75 英寸的 OLED 电视像是上世纪 90 年代的 CRT 电视一样过时；我的 iPhone 在它面前仿佛是古老的翻盖手机，甚至我周围的真实世界也变得平平无奇。这就是问题所在。就像我们无法想象没有立体声音响的驾驶体验，无法想象没有手机来沟通和记录生活，无法想象没有电脑来工作一样，我能预见到未来，我们将难以想象没有增强现实技术的生活。当我们被技术环绕，渴望这种眼镜就像现在对 iPhone 的依赖一样，甚至更渴望它带来的多巴胺刺激。

我深知 Apple Vision Pro 的沉浸感太强，但我仍然渴望透过它看世界。“我承认这项技术非常先进，但我依然希望它不会成功。”一位硅谷投资者曾对我说。“苹果现在越来越像一个隐藏在康复中心背后的高科技麻醉品贩子。”这话听起来很严厉，但他的感受代表了我们大多数人的心声：我们已成为智能手机的奴隶。他目睹了这一切的发展，了解每个阶段的情况，也预见了最终的结局。

几天后，我才意识到这个问题，所以没问库克 (Cook)，但我确实询问了他，科技是否进步得太快了。无论是人工智能 (AI)，空间计算，还是我们对技术的依赖，这一切是不是太超前了？我问库克：“这些技术的未来会是什么样子？”

“确切预测很难，”他回答。

“但你们正在创造它，”我说。“你们不应该能预见它的未来吗？”

库克向我解释：“我们的做法是，对某个创意充满激情后，就开始探索这个想法，看它会引领我们去哪里。”他继续说道：“当然，我们有自己的发展规划和明确的视角。但其中很大一部分也在于探索和不断摸索。”他总结道：“有时候，一系列的小发现会意外地串联起来，引领我们走向意想不到的方向。”（顺着相连的点前进，这是库克的前任经常谈论的主题。）

关键的问题是，我们即将步入的空间计算时代，能否真正改善我们的生活，还是它将变成又一个我们离不开的技术，一个没有增强现实就无法想象的世界？我觉得乔斯维亚克 (Joswiak) 的话说对了一半，他曾说：“这就像我们伸手到未来，拿到了这个产品。你是在把未来戴在脸上。”但我认为情况恰恰相反，是苹果 (Apple) 正在引领我们走向未来，进入一个全新的计算时代。我们中的有些人正全速前进，而另一些人则似乎被迫跟随，有些不情愿。但不管如何，我们都在向前走。我们将前往月球，仰望黑暗星空下古老尘埃的幽幽荧光，届时我们会意识到，这就是计算、娱乐、应用程序及记忆的未来。这个缠绕在我们头部的设备，将彻底改变我们的一切。​​​​

来源：https://vanityfair.com/news/tim-cook-apple-vision-pro



### 08

2024-02-04

宝玉
@dotey
来自卡耐基梅隆大学的论文：《Agile But Safe: Learning Collision-Free High-Speed Legged Locomotion》

敏捷而安全：无碰撞高速足式机器人运动的学习

论文摘要：
在复杂环境中活动的足式机器人（即多脚机器人）需要同时具备高效任务执行的敏捷性和避免与障碍物或人发生碰撞的安全性。

目前的研究或是开发速度较慢（低于1.0米/秒）的保守型控制器以确保安全，或是专注于提升敏捷性而忽略了可能发生的危险碰撞。

本文提出了一个名为“敏捷而安全”（Agile But Safe, ABS）的基于学习的控制框架，使四足机器人能够在保证安全的同时实现敏捷运动。

ABS框架包括一个敏捷策略和一个恢复策略，前者用于在障碍物间灵活移动，后者则用来预防可能的失败，两者共同实现了高速且安全的导航。

ABS中策略的切换是由一个经过学习的控制理论型“到达-避免价值网络”控制的，该网络不仅决定了策略的切换，还作为一个目标函数引导恢复策略，以闭环的方式确保机器人的安全。

训练过程包括敏捷策略、到达-避免价值网络、恢复策略和外部感知表示网络的学习，所有这些都是在模拟环境中完成的。这些经过训练的模块可以直接应用于真实世界，通过机器人自带的感应和计算系统，在充满静态和动态障碍物的狭小室内外空间中实现高速且无碰撞的导航。

论文：https://arxiv.org/abs/2401.17583
项目首页：https://agile-but-safe.github.io


### 09

2024-02-07

歸藏
@op7418
elvis写了一篇非常详细的文章来介绍 RAG 生态的所有部分，还会添加清晰易懂的参考文献列表以及技术性编程教程帮助提高 RAG 系统的性能。

主要内容来自《大语言模型的检索增强生成：一项调查》这篇论文，我简要总结了一下文章每个部分的内容，感兴趣可以去看原文：

检索增强生成（Retrieval Augmented Generation, RAG）技术，旨在通过结合外部知识源，如数据库，来提升大语言模型（LLMs）的能力。它主要用于解决领域知识的缺失、事实性问题和生成错误。RAG特别适用于那些需要最新知识、又不需针对每个特定任务重复训练LLM的应用场景，比如对话代理和知识密集型任务。

RAG如何工作

RAG通过接收输入的提示信息，从资源如维基百科中检索相关文档，再将这些文档作为上下文来生成回答。这种方法使LLMs能够访问最新的信息，并生成更准确、更可控、更相关的内容。它能及时适应不断变化的信息，这对于LLM来说至关重要，因为它们的知识库本身是静态的。

RAG系统的发展

RAG系统已经从初级阶段（Naive RAG）发展到高级阶段（Advanced RAG）和模块化阶段（Modular RAG），以解决性能、成本和效率的限制。高级RAG通过优化不同阶段，如预检索、检索和检索后处理，来提高检索质量。模块化RAG则通过调整不同的功能模块来适应特定问题的背景，提供了更大的灵活性。

RAG系统的关键组成

检索：包括提升语义表示、对齐查询与文档，以及调整检索器输出以符合LLM的偏好。
生成：涉及将检索到的信息转化为连贯的文本，并在检索后对LLM进行微调。
增强：在生成任务中融合检索到的段落的上下文，包括不同阶段和增强数据源。
RAG与模型微调
RAG适合用于集成新知识，而模型微调则有助于提升模型的性能和效率。这两种方法可以互补，结合提示工程（Prompting Engineering），能够优化LLM在复杂和可扩展应用中的表现。

RAG的评估

RAG系统的评估基于检索到的上下文质量和生成的内容质量。评估指标包括规范化折扣累计增益（NDCG）、命中率、F1值和精确匹配（EM）等。评估重点是上下文的相关性、答案的准确性和相关性，以及抗噪声能力和信息整合能力。

RAG面临的挑战与未来展望

RAG目前面临的挑战包括适应更广泛的上下文窗口、提高对虚假信息的抵抗能力、理解规模化定律，以及开发可投入生产的系统。此外，人们也在关注多模态RAG和为评估制定更细致的标准。

RAG工具

构建RAG系统可以使用包括LangChain和LlamaIndex在内的工具，以及针对不同目的的专业工具。云服务提供商也在提供以RAG为中心的服务，以促进RAG应用的发展。

原文链接：https://promptingguide.ai/research/rag


### 10

2024-02-07

Leonie
@helloiamleonie
For best results, I assumed you should combine fine-tuning & RAG.

But according to this paper, fine-tuning doesn't add more knowledge when you already have RAG.

But don't forget that fine-tuning serves more purposes than knowledge injection.

Paper: https://arxiv.org/pdf/2312.05934.pdf


### 11

2024-02-07

宝玉
@dotey
转译：麻省理工学院和IBM发现智能AI策略，避开传统繁复计算。这项技术有望显著降低AI训练所需的数据量。

自牛顿的时代以来，我们认识到自然界的基本法则可以通过一组关键而广泛的方程来描述。现在，研究人员发现了利用受大脑启发的神经网络来更高效地解决这些方程的新方法，这一发现在科学和工程的许多领域都有潜在的应用价值。

在现代科学和工程领域，偏微分方程是用来建模那些涉及多个变化速率的复杂物理系统的工具，比如同时跨越空间和时间变化的系统。它们能够模拟诸如飞机翼周围气流的流动、空气中污染物的扩散或是恒星坍缩成黑洞等多种现象。

传统上，科学家们通过使用高精度数值方法来解决这类复杂方程，但这些方法通常既耗时又需要大量的计算资源。

目前，我们有了一种更简便的选择，即所谓的数据驱动替代模型。这类模型，包括神经网络，在接受数值求解方法生成的数据训练后，能够预测其可能的输出结果。然而，这些模型仍然需要大量的数值求解数据进行训练，随着模型大小的增加，所需的数据量呈指数级增长，这使得该策略难以扩展，佐治亚理工学院的计算科学家拉斐尔·佩斯托里指出。

在一项新研究中，研究人员提出了一种开发替代模型的新策略。这种策略利用物理模拟器来训练神经网络，以便它们能够匹配高精度数值系统的输出。其目标是利用领域内的专家知识——本例中是物理学——来生成准确结果，而不是单纯依赖大量计算资源来暴力求解问题。

通过实验，研究人员探索了他们称之为物理增强深度替代模型（PEDS）在三种物理系统上的应用，包括扩散（如染料在液体中的扩散）、反应-扩散（如化学反应后的扩散过程）和电磁散射。

这项研究表明，这些新模型在解决偏微分方程问题时的准确度可比其他神经网络高出三倍，而且这些模型只需要大约1000个训练点。这至少将达到5%目标误差所需的训练数据量减少了100倍。

佩斯托里表示：“这个想法很直观——让神经网络负责学习，让科学模型处理科学问题。PEDS的实践表明，将两者结合起来的效果远超各自单独的效能。”

PEDS模型的潜在应用前景广泛，包括加速模拟工程中随处可见的复杂系统，如天气预报、碳捕获技术和核反应堆等。

该项研究成果已在《自然机器智能（Nature Machine Intelligence）》杂志上发表。

https://spectrum.ieee.org/mathematical-model-ai


### 12

2024-02-07


宝玉
@dotey
\#开源项目推荐： awesome-indiehackers

了不起的独立开发者们

https://github.com/johackim/awesome-indiehackers

### 13

2024-02-07

宝玉
@dotey
看到一个有意思的80年代调试磁带驱动器故障的小故事

转译：我听过的最棒的调试故事 

回到80年代初期，我的父亲在Storage Technology工作，这是一个如今已经不存在的公司，专门生产磁带驱动器和用于高速驱动这些磁带的气动系统——考虑到那个年代，这是非常先进的技术。

他们巧妙地设计了磁带驱动系统，允许一个中心驱动器——我们称之为‘A’驱动器——连接至七个‘B’驱动器，并通过附加在A驱动器上的一小块RAM中运行的简易操作系统，协调这些B驱动器间的数据读写任务。

每次启动A驱动器时，都需要向连接到A驱动器的外设驱动器插入一张软盘，以便将操作系统加载到A驱动器的RAM中。这个操作系统非常基础，运行在一个8位微控制器上。

这套系统主要面向那些拥有庞大数据集的企业客户，比如银行和杂志社，它们需要打印大量的地址标签或银行对账单。

有一次，一个客户遇到了麻烦。在打印过程中，一台特定的A驱动器突然停止工作，导致整个打印作业暂停。要恢复驱动器，操作人员必须重新启动整个系统——如果这种情况发生在六小时的打印作业中间，不仅会浪费大量宝贵的计算时间，而且整个作业进度也会大大落后。

于是，Storage Technologies派出了技术人员。尽管他们竭尽全力，但在测试环境中却无法复现这个故障：这个问题似乎只在执行大型打印任务时发生。因此，怀疑是硬件故障，他们更换了所有可能的部件——RAM、微控制器、磁盘驱动器，以及磁带驱动器的其他所有部件——但问题依旧存在。

于是，技术人员向总部求助，请求派遣一位专家。

这位专家带着一把椅子和一杯咖啡，坐在了专为计算机设置的房间里——毕竟，那个时代的计算机还需要专用的房间。他在操作人员准备大型打印任务时静静观察，直到系统崩溃——正如所预期的那样。所有人都望向这位专家，但他对发生的原因一无所知。他指示重新准备打印任务，并再次坐下等待。

经过大约六小时的等待，系统再次崩溃。他仍然不清楚具体原因，只注意到崩溃发生在房间内人较多时。他又一次指示重新开始，并耐心等待。

在第三次系统崩溃时，他发现了一些规律。每当操作人员更换另一台与此无关的驱动器上的磁带时，系统就会崩溃。更重要的是，他注意到，只要有人走过地板上的某个特定瓷砖，崩溃就会发生。

这种地板由高约6到8英寸的支柱支撑的铝质瓷砖组成，旨在将庞大的电线网络隐藏于地砖之下，防止操作人员不小心绊倒重要的电线。瓷砖紧密拼接，防止任何碎片掉入电线空间。

专家发现问题所在：一块铝质地砖发生了扭曲。当操作人员踩在这块扭曲地砖的角落时，地砖边缘相互摩擦。地砖连接处的塑料摩擦产生微小火花，进而产生射频干扰。

尽管如今的RAM已经能够有效屏蔽射频干扰，但在当时，RAM对此类干扰的防护远不充分。专家最终确定，正是这种射频干扰导致了RAM和操作系统的损坏。

专家联系维护部门，亲自更换了那块地砖，问题终于得到了解决。

https://patrickthomson.tumblr.com/post/2499755681/the-best-debugging-story-ive-ever-heard



### 14

2024-02-06

歸藏
@op7418
阿里开源了Qwen1.5模型，包括六种尺寸的基础模型和聊天模型：0.5B、1.8B、4B、7B、14B 和 72B。

还提供量化模型，包括 Int4 和 Int8 GPTQ 模型，以及 AWQ 和 GGUF 量化模型。

他们说在测试中，70B模型的评分超过了Claude2.1，以及GPT-3.5，距离GPT-4还有一些距离。最高支持32K上下文。

博客里有更详细的介绍和测试：https://qwenlm.github.io/blog/qwen1.5/


### 15

2024-02-07

歸藏
@op7418
字节研究院发布的这个视频控制方式Boximator，看起来效果相当不错。
你可以选择需要运动的物体，然后绘制他结束的位置和运动路径，他就会严格按照你绘制的位置和路径运动。

这个控制方式比 Runway 的运动笔刷还要再进一步，你可以精确控制物品结束运动的位置。

演示里用的视频模型也是字节研发的PixelDance视频生成模型。

🔍项目简介：

我们提出了Boximator，这是一种用于精细运动控制的新方法。Boximator采用了两种约束机制：硬性约束（hard box）和软性约束（soft box）。

用户可以利用硬性约束选取视频中某一帧（称为条件帧）的特定对象，然后通过这两种约束方式来大致或严格地指定该对象在未来画面中的位置、形状或运动轨迹。Boximator可以作为现有视频合成模型的一个附加组件。在训练过程中，为了保留原模型的知识，我们选择冻结了原始权重，只对控制模块进行训练。
为了解决训练过程中的挑战，我们引入了一种创新的自我追踪技术，这大大简化了学习框选对象与其关联的过程。

经过实验证明，Boximator在视频质量方面（即FVD，一种视频质量评价标准）达到了行业领先水平，相较于两个基础模型有所提升，并在引入框选约束后进一步增强了效果。其在运动控制上的强大能力，通过包围盒对齐指标的显著提升得到了验证。
人类评估也显示，用户更偏好Boximator生成的视频效果，而不是基础模型的输出。

项目地址：https://boximator.github.io


### 16

2024-02-07

宝玉
@dotey
推荐阅读：RAG 系统开发中的 12 大痛点及解决方案

痛点 1：缺失内容
痛点 2：关键文档被遗漏
痛点 3：文档整合的长度限制 —— 超出上下文
痛点 4：提取困难
痛点 5：格式错误
痛点 6：缺乏具体细节
痛点 7：回答不全面
痛点 8：数据摄入的可扩展性问题
痛点 9：结构化数据的问答
痛点 10：从复杂 PDF 文档提取数据
痛点 11：备用模型策略
痛点 12：大语言模型的安全性

原文：https://towardsdatascience.com/12-rag-pain-points-and-proposed-solutions-43709939a28c
译文：https://baoyu.io/translations/rag/12-rag-pain-points-and-proposed-solutions


### 17

2024-02-07

宝玉
@dotey
推荐Obsidian + Excalidraw，安装个中文手写字体（比如“字语青梅硬笔”）


### 18

2024-02-14

歸藏
@op7418
Andrej Karpathy 关于自己从 Open AI离职的声明：

大家好，确实，我昨天刚刚离开了OpenAI。

首先要说的是，这并非因为发生了什么特别的事件或问题，也不涉及任何戏剧性的变故（不过，大家继续提出的各种阴谋论还是挺有趣的:））。

其实，过去大约一年在OpenAI的经历非常棒——团队实力强大，同事们非常棒，而且OpenAI的发展规划也极具吸引力，我相信我们都有很多值得期待的事情。目前，我打算专注于我的个人项目，看看能碰到什么新奇的事。那些一直关注我的朋友，可能对我接下来会做什么已经有所预期了;) 再会！

2024-02-14

Andrej Karpathy
@karpathy
Hi everyone yes, I left OpenAI yesterday. First of all nothing "happened" and it’s not a result of any particular event, issue or drama (but please keep the conspiracy theories coming as they are highly entertaining :)). Actually, being at OpenAI over the last ~year has been really great - the team is really strong, the people are wonderful, and the roadmap is very exciting, and I think we all have a lot to look forward to. My immediate plan is to work on my personal projects and see what happens. Those of you who’ve followed me for a while may have a sense for what that might look like ;) Cheers

### 19

2024-02-14

歸藏
@op7418
苹果发布了一个可以利用LLM 生成动画的框架Keyframer。

Keyframer允许用户通过自然语言提示来创建静态2D图像的动画。

它使用GPT-4生成CSS动画代码，支持用户通过多种编辑器类型直接编辑生成的动画。

用户可以通过顺序提示和请求LLM生成的设计变体来迭代他们的设计。

论文链接：https://arxiv.org/pdf/2402.06071.pdf


### 20

2024-02-16

歸藏
@op7418
LangChain 的 LLM 应用开发平台LangSmith正式开放给了所有人使用，同时宣布获得了Sequoia 领投的 A 轮融资。

LangSmith 是一个统一的 DevOps 平台，用于开发、协作、测试、部署和监控LLM应用程序。

新的品牌形象和网站搞得也很不错，这里尝试：https://langchain.com/langsmith



### 21

2024-02-16


orange.ai
@oran_ge
Sora - 创造物理世界模拟器的希望之路
2024年2月16日，OpenAI 发布了 Sora，一个革命性的视频生成模型。
Sora 的作品10x地好于竞品。
Sora 的技术原理和竞品完全不同。
Sora 的目标一开始就不是生成视频，而是研究一种模拟世界的通用方法。
文本可以帮助你理解 Sora：


### 22

2024-02-16

宝玉
@dotey
翻译了OpenAI关于Sora相关的技术报告：《Video generation models as world simulators | 视频生成模型：构建虚拟世界的模拟器》

这篇技术报告主要介绍了两方面内容：(1) OpenAI如何将各种类型的视觉数据转化为统一的表示形式，从而实现生成模型的大规模训练；(2) 对 Sora 模型能力和局限性的定性评价。

报告中没有包含模型和实施的详细信息。

Sora 属于扩散型 Transformer（diffusion transformer）。

我们知道，传统的 Transformer，主要有Encoder和Decoder，Encoder是将文本编码成 Token，从而可以将自然语言变成可以统一处理的数字或代码。而 Decoder 则是将 Token 反向解码成文本。

而 Sora 也是类似的思路，只不过它编码的结果不是Token，报告里面叫 Patches（中文暂译做补片），Encoder 将视频压缩为低维潜空间，再将其分解为 Patches。同样 Sora 也能从 Patches 反向解码成视频图像。（参考图一）

Sora 同时还是一种扩散模型，能将有噪声的图像块，基于 Prompt 还原出清晰的图像。（参考图二）

另外，报告中特地提到了：“我们的研究显示，扩展视频生成模型的规模是向着创建能够模拟物理世界的通用工具迈出的有前途的一步。”

据说微软前一段时间给OpenAI搞了五千亿个视频用于训练。

原文：https://openai.com/research/video-generation-models-as-world-simulators
译文：https://baoyu.io/translations/openai/video-generation-models-as-world-simulators


### 23

2024-02-16

歸藏
@op7418
卧槽，Open AI的大招终于来了，发布视频生成模型 Sora，从演示来看视频生成时长、运动幅度以及稳定性均碾压现在的所有视频生成模型。

Sora能够创作出长达一分钟的视频，不仅保证了视频的视觉质量，还能准确响应用户的指令。将在今天想有限的访问者开放。

模型优势：

Sora能够创造出包括多个角色、特定动作类型以及对主题和背景的精确细节描述的复杂场景。这款模型不仅能理解用户在指令中提出的需求，还能洞察这些元素在现实世界中是如何存在和表现的。

这款模型对语言的理解非常深刻，使其能够精准地识别用户的指令，并创造出表情丰富、情感生动的角色。此外，Sora还能在同一视频内制作多个镜头，同时确保角色的形象和整体的视觉风格保持一致。

工作原理：

Sora是一种扩散模型(diffusion model)，它通过从类似静态噪声的视频出发，逐步去除噪声，从而在多个步骤中生成视频。

Sora不仅能一次生成整个视频，还能延长已有视频的长度。我们通过使模型能够预见多个画面帧，解决了确保视频中主题即使暂时离开画面也能保持一致的难题。

Sora采用了类似于GPT模型的变压器架构(transformer architecture)，这为其带来了优异的扩展性能。

在Sora中，视频和图像被表示为一系列小块数据，称为“补丁”(patches)，每个补丁都类似于GPT中的“令牌”(token)。通过统一数据表示方式，我们能够在之前不可能的更广泛视觉数据范围内训练扩散变压器，包括不同的时长、分辨率和长宽比。

Sora基于DALL·E和GPT模型的研究成果。它采用了DALL·E 3中的重标记技术(recaptioning technique)，为视觉训练数据生成详细描述的标题。因此，模型能更准确地遵循用户在生成视频中的文字指令。

除了能从文字指令生成视频外，Sora还能将现有静止图像转化为视频，准确地动态展现图像内容并关注细节。此外，它还能扩展现有视频或填补视频中缺失的画面。

了解更多：https://openai.com/sora


### 24

2024-02-16

宝玉
@dotey
推荐阅读：《AI 或许真的能助力中产阶级重塑辉煌》

人工智能（AI）并不一定会夺走我们的工作。相反，它为我们提供了一个机遇，那就是将专业知识推广至更广泛的劳动者群体。

原文：https://noemamag.com/how-ai-could-help-rebuild-the-middle-class/
译文：https://baoyu.io/translations/ai/how-ai-could-help-rebuild-the-middle-class


### 25

2024-02-17

宝玉
@dotey
Jim Fan 对 Sora 的点评👍🏻：
- Sora 代表了文本生成视频的 GPT-3 时刻
- Sora 必须学习一些隐式的文本到 3D、3D 变换、光线追踪渲染和物理规则，才有可能精确地模拟视频像素。它必须理解游戏引擎的概念，才有可能生成视频。
- 我们不应仅仅关注 GPT-3 的缺点。更应该思考，随着技术进步，GPT-4 将会带来哪些可能性。

以下内容为原推转译

***

我注意到了一些直言不讳的对 Sora 反对声音：“Sora 并没有在学习物理，它仅仅是在二维空间里对像素进行操作。”

对于这种把问题简单化的看法我必须表示不同意见。这种说法就像是在说“GPT-4 并不学习编码，只是在随机选择字符串而已”。实际上，Transformer 的工作只是在操作一连串的整数（即 Token ID）。神经网络的工作，也仅仅是在处理浮动数字。这种观点显然是片面的。

当我们大规模扩展从文本到视频的训练时，Sora 所展现的软物理仿真实际上是一种随着规模扩大而出现的特性。

- GPT-4 必须学会某种内部的语法、语义和数据结构，才能生成可执行的 Python 代码。它并不是直接存储 Python 的语法结构。
- 类似地，Sora 必须学习一些隐式的文本到 3D、3D 变换、光线追踪渲染和物理规则，才有可能精确地模拟视频像素。它必须理解游戏引擎的概念，才有可能生成视频。
- 如果我们不考虑交互的话，UE5 就是一个（极其复杂的）生成视频像素的过程。同样，Sora 也是一个过程，它通过端到端的 Transformer 来生成视频像素。这两者在抽象层次上是相同的。
- 不同之处在于，UE5 是通过手工制作和精确设计的，而 Sora 则是通过数据学习和直观感受来实现的。

Sora 会取代游戏引擎开发者吗？绝对不会。它对物理的理解虽然是一种新的尝试，但仍然不够成熟，远远达不到完美。它经常会产生一些与我们对物理常识的理解不一致的幻觉。目前，它对物体间互动的理解尚不到位 —— 观看下面的视频中的不自然错误就能明白。

Sora 代表了文本生成视频的 GPT-3 时刻。回想 2020 年，尽管 GPT-3 模型存在不少问题，需要大量的提示工程，但它首次引人瞩目地展示了在上下文中学习这一涌现性质。

我们不应仅仅关注 GPT-3 的缺点。更应该思考，随着技术进步，GPT-4 将会带来哪些可能性。


### 26

2024-02-17

歸藏
@op7418
杨立昆关于前几天自己对视频模型发言的补充说明。
他表示仅仅能够根据文字提示生成逼真的视频并不代表模型理解了物理世界。
生成视频的过程与基于世界模型的因果预测完全不同。

虽然可以想象出的视频种类繁多，但视频生成系统只需创造出一个合理的样本就算成功。
而对于一个真实视频，其合理的后续发展路径就相对较少，生成这些可能性中的具代表性部分，尤其是在特定动作条件下，难度大得多。
再者，生成这些视频后续内容不仅成本高昂，实际上也毫无意义。

更理想的做法是生成那些后续内容的抽象表达，去除与我们可能采取的行动无关的场景细节。
这正是JEPA（联合嵌入预测架构）的核心思想，它并非生成型的，而是在表示空间中进行预测。
我们在VICReg、I-JEPA、V-JEPA的研究以及其他人的工作表明，与重建像素的生成型架构（如变分自编码器（Variational AE）、掩码自编码器（Masked AE）、去噪自编码器（Denoising AE）等）相比，联合嵌入架构能够产生更优秀的视觉输入表达。
我们发现，使用这些学习到的表达作为下游任务中受监督头部的输入（无需对基础网络进行微调），联合嵌入架构在效果上超过了生成型架构。


Yann LeCun

@ylecun
Let me clear a *huge* misunderstanding here.
The generation of mostly realistic-looking videos from prompts *does not* indicate that a system understands the physical world.
Generation is very different from causal prediction from a world model.
The space of plausible videos is very large, and a video generation system merely needs to produce *one* sample to succeed.
The space of plausible continuations of a real video is *much* smaller, and generating a representative chunk of those is a much harder task, particularly when conditioned on an action.
Furthermore, generating those continuations would be not only expensive but totally pointless.
It's much more desirable to generate *abstract representations* of those continuations that eliminate details in the scene that are irrelevant to any action we might want to take.
That is the whole point behind the JEPA (Joint Embedding Predictive Architecture), which is *not generative* and makes predictions in representation space. 
Our work on VICReg, I-JEPA, V-JEPA, and the works of others show that Joint Embedding architectures produce much better representations of visual inputs than generative architectures that reconstruct pixels (such as Variational AE, Masked AE, Denoising AE, etc).
When using the learned representations as inputs to a supervised head trained on downstream tasks (without fine tuning the backbone), Joint Embedding beats generative.

See the results table from the V-JEPA blog post or paper:
https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/

https://x.com/ylecun/status/1758740106955952191?s=20


### 27

2024-02-17

宝玉
@dotey
问：Sora 和之前 Runway 那些在架构上有啥区别呢？

答：简单来说 Runway 是基于扩散模型（Diffusion Model）的，而 Sora 是基于 Diffusion Transformer。

Runway、Stable Diffusion 是基于扩散模型（Diffusion Model），扩散模型（Diffusion Model）的训练过程是通过多个步骤逐渐向图片增加噪点，直到图片变成完全无结构的噪点图片，然后在生成图片的时候，基于一张完全噪点的图片，逐步减少噪点，直到还原出一张清晰的图片。

文本模型像 GPT-4 则是 Transformer 模型。Transformer 则是一套编码器和解码器的架构，将文本编码成数字向量，然后解码的时候从数字向量还原出文本。

Sora 则是一个融合了两者的 Diffusion Transformer 模型。通过 Transformer 的编码器 - 解码器架构处理含噪点的输入图像，并在每一步预测出更清晰的图像版本。编码器负责对含噪点的输入进行编码，而解码器则负责生成更清晰图像的预测。

GPT-4 被训练以处理一串 Token，并预测出下一个 Token。Sora 不是预测序列中的下一个文本，而是预测序列中的下一个“Patch”。

在文本预测生成中，基本单位是 Token，Token 很好理解，就是一个单词或者单词的一部分。Patch 的概念相对不那么好理解，不过今天看到一篇文章，作者举了个很好的例子。

想象一下《黑暗骑士》的电影胶片，将一卷胶片绕在一个金属盘上，然后挂在一个老式电影院的投影机上。

你把电影胶卷从盘中展开，然后剪下最前面的 100 帧。你挑出每一帧——这里是小丑疯狂大笑，那里是蝙蝠侠痛苦的表情——并进行以下不同寻常的操作：

你拿起一把 X-acto 精细刻刀，在第一帧电影胶片上剪出一个变形虫状的图案。你像处理精密仪器一样小心翼翼地用镊子提取这片形似变形虫的胶片，然后安全地保存起来。之后，你处理下一帧：在接下来的胶片上切出同样位置、同样形状的变形虫图案。你再次用镊子小心地取出这个新的变形虫形状的胶片——形状与前一个完全相同——并将其精确地放置在第一个之上。你这样做，直到完成所有的 100 帧。

你现在有了一个色彩斑斓的变形虫，沿着 Y 轴扩展。这是一座可以通过投影机播放《黑暗骑士》的小片段的胶片塔，就好像有人在投影机前握着拳头，只让电影的一小部分影像从拳心通过。

然后，这座胶片塔被压缩并转化为所谓的“Patch”——一种随时间变化的色块。

Patch 的创新之处——以及 Sora 之所以显得如此强大——在于它们让 OpenAI 能够在大量的图像和视频数据上训练 Sora。想象一下从每一个存在的视频中剪出的 Patch——无尽的胶片塔——被堆叠起来并输入到模型中。

以前的文本转视频方法需要训练时使用的所有图片和视频都要有相同的大小，这就需要大量的预处理工作来裁剪视频至适当的大小。但是，由于 Sora 是基于“Patch”而非视频的全帧进行训练的，它可以处理任何大小的视频或图片，无需进行裁剪。

因此，可以有更多的数据用于训练，得到的输出质量也会更高。例如，将视频预处理至新的长宽比通常会导致视频的原始构图丢失。一个在宽屏中心呈现人物的视频，裁剪后可能只能部分展示该人物。因为 Sora 能接收任何视频作为训练输入，所以其输出不会受到训练输入构图不良的影响。

在结合前面提到的 Diffusion Transformer 架构，OpenAI 可以在训练 Sora 时倾注更多的数据和计算资源，从而得到令人惊叹的效果。

另外 Sora 刚发布视频时，能模拟出咖啡在杯子里溅出的液体动力学，以至于有人以为是连接了游戏引擎，但实际上 Sora 还是基于生成式模型，这是因为 Sora 在训练时，使用了大量的视频数据，这些视频中包含了大量的物理规则，所以 Sora 能够模拟出液体动力学。这类似于 GPT-4 在训练时，使用了大量的代码来作为训练数据，所以 GPT-4 能够生成代码。

有两篇论文：
《Scalable Diffusion Models with Transformers》https://arxiv.org/abs/2212.09748
《Patch n' Pack: NaViT, a Vision Transformer for any Aspect Ratio and Resolution》https://arxiv.org/abs/2307.06304

包含更多专业细节。

顺便说一下，两篇论文好像都来自Google，并且似乎Sora项目是在这两篇论文发表后才启动的。

还有电影胶片+变形虫的例子来自《How Sora Works (And What It Means)》
https://every.to/chain-of-thought/sora-and-the-future-of-filmmaking
译文：https://baoyu.io/translations/sora/sora-and-the-future-of-filmmaking

本文收录于：https://baoyu.io/blog/ai/sora-vs-runway



### 28

2024-02-17

歸藏
@op7418
这是构成Sora基础之一的Diffusion Transformer论文作者关于Sora的一些猜测和技术解释。

这个老哥可能是除了这篇论文的另一个作者（现在在Open AI工作）之外最懂Diffusion Transformer的人了，非常值得关注。
有趣的是这篇论文曾经在2023年的计算机视觉会议(CVR2023)上因“缺少创新性”而遭到拒绝，短短一年时间就变成了Sora这怪物模型的理论基础。

-------------正文开始-------------

以下是我对Sora技术报告的解读，其中包含了一些可能并不准确的猜测。首先，我非常感谢团队分享了极为有价值的见解和设计决策——Sora确实令人惊叹，它将彻底改变视频生成领域。

我们目前所了解到的情况如下：

架构：Sora基于我们的扩散变换器（Diffusion Transformer，简称DiT）模型构建，该模型已发表在2023年国际计算机视觉会议（ICCV 2023）上。简单来说，它是一个结合了变换器（Transformer）主干的扩散模型： DiT = [变分自编码器（VAE）编码器 + 视觉变换器（ViT）+ 去噪扩散概率模型（DDPM）+ VAE解码器]。 根据报告，这个模型似乎没有太多额外的复杂设计。

“视频压缩网络”：这看起来就像是一个在原始视频数据上训练的变分自编码器（VAE）。在实现良好的时间一致性方面，标记化（Tokenization）可能扮演着关键角色。顺便提一下，VAE本质上是一个卷积网络，所以从技术上说，DiT实际上是一个混合模型。 ;)

当Bill和我参与DiT项目时，我们并未专注于创新（详见我之前的推特🤷‍♂️），而是将重点放在了两个方面：简洁性和可扩展性。这些优先事项带来的不仅仅是概念上的优势。

简洁性代表着灵活性。关于标准的视觉变换器（ViT），人们常忽视的一个亮点是，它让模型在处理输入数据时变得更加灵活。例如，在遮蔽自编码器（MAE）中，ViT帮助我们只处理可见的区块，忽略被遮蔽的部分。同样，Sora可以通过在适当大小的网格中排列随机初始化的区块来控制生成视频的尺寸。而UNet并不直接提供这种灵活性。

 👀猜测：Sora可能还使用了Google的Patch n’ Pack（NaViT）技术，使DiT能够适应不同的分辨率、持续时间和长宽比。

可扩展性是DiT论文的核心主题。首先，经过优化的DiT在每Flop的实际运行时间上比UNet要快得多。更重要的是，Sora证明了DiT的扩展法则不仅适用于图像，现在也适用于视频——Sora复制了在DiT中观察到的视觉扩展行为。 

👀猜测：在Sora报告中，第一个视频的质量相当差，我怀疑它使用的是基础模型尺寸。粗略计算一下：DiT XL/2的GFLOPs是B/2模型的5倍，所以最终16倍计算模型可能是3倍DiT-XL模型的大小，这意味着Sora可能有约3亿参数——如果这是真的，这并非一个不合理的模型大小。这可能意味着，训练Sora模型可能不需要像人们预期的那样多的GPU——我预计未来的迭代速度会非常快。

关键的收获来自于“新兴模拟能力”部分。在Sora出现之前，人们不清楚是否可以自然形成长篇连贯性，或者是否需要复杂的以主题为导向的生成流程，甚至物理模拟器。OpenAI已经证明，尽管不完美，但这些行为可以通过端到端训练来实现。然而，有两个关键点尚未被讨论。

1. 训练数据：关于训练数据的来源和构建完全没有提及，这可能意味着数据很可能是Sora成功的关键因素。

 👀猜测：关于来自游戏引擎的数据已有许多猜测。我也预计可能会包括电影、纪录片、电影长镜头等。质量非常重要。我非常好奇Sora从哪里获取这些数据的（肯定不仅仅是YouTube，对吧？）。

2.（自回归的）长视频生成：Sora的一大突破是能够生成非常长的视频。制作2秒视频和1分钟视频之间的差异是巨大的。 在Sora中，这可能是通过联合帧预测实现的，允许自回归采样，但一个主要的挑战是如何解决错误累积，并在时间上保持质量和一致性。是需要一个非常长的（并且是双向的）上下文来进行条件化？还是说仅仅通过扩大规模就可以减少问题？这些技术细节可能非常重要，希望未来能够被逐渐揭示。

扩散变换器（DiT）在Sora中的应用效果非常出色。我们纽约大学的团队最近发布了一款新的DiT模型，名为SiT。它保持了与DiT完全相同的架构，但在性能上有所提升，收敛速度更快。我对它在视频生成方面的表现也非常感兴趣！

DiT论文地址：https://arxiv.org/abs/2212.09748


### 29

2024-02-19

宝玉
@dotey
这篇推文对 Sora 懂物理引擎的说法的驳斥的很专业。

像 Sora 这样的 Diffusion Transformer，底层是基于机器学习的随机梯度下降加上反向传播（SGD + backpropagation），这就意味着 Sora 是没有逻辑推理能力的，本质上也是将训练的数据压缩成模型的权重，在训练过程中，不断更新参数，从而让预测的时候误差降到最小。

就好比🪰找💩，总是朝着气味最浓的方向去寻找，就像梯度下降算法根据梯度的方向更新参数，以逐步接近损失函数的最小值。

基于这样的模式，是无法学会物理规律的，就好比将所有行星运动的数据拿来训练，也无法推导出广义相对论。

具体建议参阅原推，完整内容转译如下：

***

让我们来看看OpenAI的Sora被誉为数据驱动物理引擎这一说法有多么荒谬：

这就好比是收集了行星运动的数据，将其喂给一个预测行星将出现位置的模型，然后得出这个模型内部实现了广义相对论的结论。

爱因斯坦花费多年时间才推导出重力理论的方程。如果有人认为随机梯度下降加上反向传播（SGD + backpropagation）就像一个小爱因斯坦在模型训练过程中解决问题，那这个人对于机器学习的理解显然是有待商榷的。

不论你拥有什么学位，如果你认为SGD加上反向传播就能使模型像小爱因斯坦一样，仅凭输入输出对就能理解一切，那你对机器学习的工作方式了解不够。

爱因斯坦在理论推导中不得不对现实做出多项假设，比如光速恒定，时空是可以弯曲的，然后他推导出了微分方程，其解答揭示了黑洞、引力波等重大发现。

他运用因果推理将不同的概念连接起来。

然而SGD加上反向传播并不进行这样的推理。它只是简单地将信息压缩成模型的权重，并不进行逻辑推理，只是按照某种规则更新参数，以达到最小误差的配置。

机器学习（ML）的统计学习过程可能会陷入所谓的低误差“盆地”，这意味着它无法探索新的概念或理论，因为一旦陷入这些低误差区域或局部最小值，就难以重新开始探索。

因此，SGD加上反向传播往往会找到那些似乎有效但实际上非常脆弱的解决方案，这些解决方案在一定条件下看似工作正常，但很容易崩溃。

这也是为什么深度学习系统在实际应用中既不可靠又难以训练的原因。你必须不断地更新和重新训练它们，这在现实操作中是非常繁琐的。

梯度下降的过程可以比作一只苍蝇寻找气味源头的过程：苍蝇会沿着空气中化学物质浓度梯度向下移动，从而找到气味的来源。但如果它仅依赖这种方式，很容易就会迷路或陷入困境。

在机器学习中，模型的可调参数就是“苍蝇”，训练数据就是气味的来源，而通过目标函数测量的误差就是“气味”。模型的权重调整的目的是为了向着“气味”（这里指低误差，相当于浓郁的气味）移动。

认为一个机器学习模型仅通过训练行星运动的视频就能内部学习到广义相对论，这种想法更是荒谬。

这完全是对机器学习工作原理的一种误解。




### 30

2024-02-19

歸藏
@op7418
[整理]基于Sora是否真的像Open AI说的一样是个世界模型，又吵起来了。

基本上就是两派一派类似杨立昆的论点，模型必须理解底层理论从底层理论推导出来物理现象才能叫世界模型。

另一派的意思是只要他表现出来相当程度的物理世界的表现，那就有继续优化的机会，就有可能变成完整的世界模型。

◆Gary Marcus和Jeroen Baert就表示：

Open AI演示的多视角的例子清楚地显示出在不同视角下，细节或物体并没有实现匹配对齐。这些图像仅仅是基于同一指令独立生成的。模型并不是通过移动一个或若干虚拟摄像机来“构建”一个三维空间的。

什么类型的物理引擎会在同一场景中产生不一致的视角效果呢（当然，复杂的遮挡等因素除外）？一般来说，标准的做法是先建立一个三维空间的模型，然后从特定的视角对其进行渲染。

大大削弱了JimFan和 OpenAI 把 Sora 当作传统物理模拟器的论点。

◆JimFan的回复是：

这是一个合理的批评。关于这个问题，有两种可能的解释：（1）模型会出现这样的错误，可能是因为它根本没有学习物理规律，只是简单地将像素混合在一起；（2）模型内部可能实现了一个物理引擎，但这个引擎的性能还不够成熟。比如，Unreal Engine的第一版在处理流体和可变形物体等方面的表现，与第五版相比就差很多。第一版的渲染效果也更差，且在物理上不够精确。

我更倾向于第二种解释，但如果能有更多实验和系统性研究来验证这一点，那将会非常有帮助。

◆同时他转了一个支持他论点的老哥Nando de Freitas的解释：

生命，以其惊人的结构，实际上是在不断增长的宇宙无序中创造出秩序的过程。例如，您可以参考这篇简明的介绍文章：https://newscientist.com/article/2323820-is-life-the-result-of-the-laws-of-entropy/。就像细胞一样，神经网络在训练过程中也需要消耗能量以减少无序，从而更好地进行预测和泛化。实际上，我们甚至将这种损失称为负熵。像生命一样，网络也是更大环境的一部分，它从环境中获取数据和反馈。同样，这个过程也会给宇宙带来大量无序（比如TPU和GPU产生的热量）。总的来说，我们具备了智能（生命的一种涌现属性）的所有要素，包括对物理的理解。如果有人能把这个论点表述得更清晰一些，我会非常感激。

一个有限尺寸的神经网络要想预测任何情况下将会发生的事情，唯一的办法就是通过学习内部模型来实现这种预测，包括对物理规律的直观理解。

基于这种直觉，我找不到任何反对 JimFan 的理由。

随着我们获取更多高质量的数据、电力、反馈（也就是微调、基础化），以及能够高效吸收数据以降低熵的并行神经网络模型的发展，我们很可能会有能够比人类更好地推理物理的机器，并且有望教会我们一些新的东西。

顺便一提，我们也是神经网络的环境，我们消耗能量来创造秩序（例如提高用于神经网络训练的数据集的质量）。

这些都是源自波尔兹曼、薛定谔等人的古老思想。它们奠定了理论基础。现在，关键是要构建代码、进行实验，并且必须负责任和安全地进行，因为这些技术非常强大。

◆Gary Marcus的回复：

一个使用了较大“n”值的ngram模型可以通过预测人们描述世界时使用的句子来合理地表达对世界的看法，但这并不意味着ngram模型真的拥有一个关于世界的模型。事实上，它并没有。

这个观点过于泛泛，不足以作为判断的依据。

可能让情况看起来有些混乱的是，这种像素混合的处理很可能是在大量由游戏引擎生成的帧序列上进行训练的。

但这并不意味着在其内部真的有一个游戏引擎。

◆ASM的观点比较理性：

我也倾向于支持（2）这一观点。Sora可能正通过某种初步的归纳过程来“学习”物理原理，这有点像幼儿通过观察物体掉落来学习重力的原理。举个例子，在“咖啡中的船只”这个视频里，我们看到波浪在中央区域是湍流的，而在边缘则相对平静。我认为在训练素材中应该没有类似的视频。

然后Gary Marcus说跟LLM他是有幻觉的而且模型无法自我纠正，ASM回复确实，这些都是目前人工智能领域面临的重要挑战。但考虑到人工智能技术的快速发展，你真的认为找出减少错误生成和加强事实核验的方法是不可能的吗？我们目前所处的阶段，只是这一历史性的、强大技术发展过程的起步阶段。




### 31

2024-02-20

宝玉
@dotey
推荐阅读：一文看Sora技术推演

https://mp.weixin.qq.com/s/3RnrO7fSMizEl3mN3SXG5w




### 32

2024-02-20

宝玉
@dotey
Computation Cost

一分钟长度、每秒30帧的视频，平均每帧包含256个token，总计将产生460ktoken，34B模型，需要7xA100资源推理

Dit XL 输入512x512， 训练需要TPU v3-256， 按照TFLOPS换算约等于5500个A100。  那么Sora需要的训练和微调的资源会是多少？





### 33

2024-02-20

宝玉
@dotey
翻译是一个很大的领域，其中有很多细分领域，字幕翻译是相对技术含量比较高的一块，不仅仅需要翻译，还需要考虑文本的时间轴，以及如何借助AI在翻译质量、自动化、价格之间取得平衡是很有挑战的事，有蛮多可以挖掘的地方。

当然对于喜欢不停挖坑的工程师来说，每次决定要开始一个项目之前，更应该回归到软件工程的第一环：可行性分析。

问自己一些问题：

为什么要开始这个项目？为什么这个项目比上一个项目更重要？

这个项目的价值在哪里？我能从这个项目中得到什么？
学习技术？赚钱？提升个人品牌？

将来怎么打算？

铁锤人-独立开发
@lxfater
我在考虑是否要放弃做视频翻译，因为无论如何优化音频翻译，口型，其实对学习没有什么意义。

有这个时间还不如直接做书本翻译了，这样以后学习不缺学习视频，也不缺翻译教材了。翻译教材必须用到本地大模型了，要不然费用不可估计。

大家如何看呀？


### 34

2024-02-20


Leonie
@helloiamleonie
Advanced Retrieval-Augmented Generation (RAG) techniques address the limitations of naive RAG pipelines.  

A recent survey on RAG classifies advanced RAG techniques into pre-retrieval, retrieval, and post-retrieval optimizations. 
🔗 Paper: https://arxiv.org/pdf/2312.10997.pdf 

My latest article gives an overview of advanced RAG techniques:  

🦙 Pre-retrieval includes techniques like sliding windows, enhancing data granularity, adding metadata, or optimizing index structures, such as sentence window retrieval.  

🦙 Retrieval includes optimizing the embedding models (e.g., fine-tuning) or advanced retrieval techniques like hybrid search  

🦙 Post-retrieval includes reranking or prompt compression.  

We also implement a naive RAG pipeline using 
@llama_index
 and then enhance it to an advanced RAG pipeline using the following: 
• Sentence window retrieval (as a pre-retrieval optimization) 
• Hybrid search (as a retrieval optimization) 
• Re-ranking (as a post-retrieval optimization)  

💻 Jupyter Notebooks: https://github.com/weaviate/recipes/tree/main/integrations/llamaindex/retrieval-augmented-generation 

Read more on 
@TDataScience
: https://towardsdatascience.com/advanced-retri

### 35

2024-02-20

歸藏
@op7418
杨立昆被世界模型的辩论整麻了。

我从未想到，看着那么多从未对AI（人工智能）或ML（机器学习）做出过任何贡献的人，其中有些人极度自负，深陷达宁-克鲁格效应（Dunning-Kruger effect）。
他们以各种方式指责我，说我对AI和ML的认识是错误的、愚蠢的、盲目的、无知的、误导的、嫉妒的、偏见的、脱节的等等，这种情景非常有趣。

Dunning-Kruger效应：指的是人们在特定领域内错误地高估自己的知识或能力。这种现象通常发生在缺乏自我意识的情况下，导致他们无法准确评估自己的技能。

### 36

2024-02-20

歸藏
@op7418
就知道会有这个，AnimateLCM-SVD-xt 利用了 LCM 技术蒸馏的 SVD 模型，只需要四步就能生成不错的视频，相比原来的模型生成时间缩短了好几倍。

遵循 AnimateLCM 论文中提出的策略，一致性蒸馏稳定视频扩散 Image2Video-XT (SVD-xt)。 AnimateLCM-SVD-xt 可以通过 2~8 个步骤生成 25 帧的高质量图像调节视频，分辨率为 576x1024。

AnimateLCM-SVD-xt 通常能在无需依赖分类器的自由引导下，仅通过四个步骤就生成高质量的演示。因此与普通的 SVD 模型相比，可以节省 25 x 2 / 4 = 12.5 倍的计算资源。

模型地址：https://huggingface.co/wangfuyun/AnimateLCM-SVD-xt



### 37

2024-02-04

歸藏
@op7418
Meta 发布了一个可以利用 AI 自动剪辑视频的 Agents LAVE。
这玩意再加上 Sora 这样的视频生成模型，一些简单的短视频以及广告视频基本上就不需要人工介入了，大家以后刷的估计都是生成出来的视频了，想要啥有啥。

我下面会简单介绍一下这个剪辑工具的界面组成和 Agents 设计：

-----------工具界面及交互（图 1）-----------

A 区域主要是输入提示词以及展示 LLM 详细的剪辑逻辑。

B 区域是素材库，你可以鼠标 Hover 后获得 LLM 帮你总结的这段视频的内容，不需要播放查看， AI 也会自动生成的素材标题。

E 区域就是传统的视频时间轴，AI 剪辑的视频就在这里，你也可以手动调整。

-----------Agents 设计（图 2）-----------

1️⃣系统提示前言：

角色分配：一个开场段指示Agents担任视频编辑助理，负责根据用户命令生成行动计划。

动作描述：在角色分配之后，描述了Agents可以执行的一系列动作。每个动作对应于LAVE支持的编辑功能。详细说明了每个动作的功能和用例，帮助Agents选择适当的响应以满足用户的命令。

格式指导：最后，指导Agents以一致的格式输出行动计划：首先确定用户的编辑目标，然后列出逐步计划，列举建议的行动以实现该目标。

其他系统提示：

在前言之后，附加了最近的对话历史，以及最新的用户输入。这种组合形成了发送给LLM以生成行动计划的完整提示。

2️⃣制定行动计划后，将其提交给用户进行批准：

与批量批准不同，每个行动都由用户依次批准。这种方法允许用户执行一个行动，观察其结果，然后决定是否继续进行下一个行动。LAVE从行动计划中解析每个行动描述，并将其转化为相应的后端函数调用。

3️⃣LAVE支持五种LLM功能：

1）素材概览，2）创意头脑风暴，3）视频检索，4）故事板，5）剪辑修剪。前四种功能可通过Agents访问，而剪辑修剪可通过双击编辑时间轴上的剪辑时出现的窗口进行。

其中，基于语言的视频检索是通过向量存储数据库实现的，而其余功能则是通过LLM提示工程实现的。所有功能都是基于自动生成的语言构建的。

生成视觉叙述：以每秒一帧的速率对视频帧进行采样。然后使用建立在Vicuna-V1-13B 的LLaMA-V1-13B模型 的fine-tuned检查点LLaVA v1.0对每帧进行标题标注。

检索功能利用向量存储：通过使用OpenAI的text-embedding-ada-002将每个视频的视觉叙述（标题和摘要）进行嵌入。

将视频整合成共同的主题：提供用户视频收藏中主题的摘要。提示包括一个功能指令，然后是画廊视频的视觉叙述。然后将此提示发送到LLM以生成概览，随后在聊天界面中呈现给用户进行审阅。

基于用户的所有视频进行视频编辑创意：提示结构以功能指令开头。如果提供了创意指导，会在提示中包含用户的创意指导，以引导头脑风暴。

根据用户提供的叙述在序列中剪辑视频片段：与以前的功能不同，它只影响时间轴上的视频。与头脑风暴类似，系统会检查用户提供的叙述中是否有任何创意指导。

4️⃣LAVE应用构建：

LAVE系统实现为全栈Web应用程序。前端UI采用React.js开发，而后端服务器采用Flask。对于LLM推理，主要使用OpenAI的最新GPT-4模型。然而，为了将行动计划映射到功能，使用了gpt-4-0613检查点，专门针对函数调用的使用进行了微调。

论文地址：https://arxiv.org/pdf/2402.10294.pdf


### 38

2024-02-21


Andrej Karpathy
@karpathy
New (2h13m 😅) lecture: "Let's build the GPT Tokenizer"

Tokenizers are a completely separate stage of the LLM pipeline: they have their own training set, training algorithm (Byte Pair Encoding), and after training implement two functions: encode() from strings to tokens, and decode() back from tokens to strings. In this lecture we build from scratch the Tokenizer used in the GPT series from OpenAI.

https://x.com/karpathy/status/1759996554747027865?s=20

Andrej Karpathy
@karpathy
The actual link to the lecture:
https://youtube.com/watch?v=zduSFxRajkE

(at the end of the thread here (sorry) otherwise X really really dislikes external links and would bury this post. I could eventually upload here too, for now X is missing a lot of very nice features, chapters especially)

歸藏
@op7418
Andrej Karpathy 提出了一个工作流希望自动将长视频内容转换为带对应示例的播客文章。现在虽然也有一些类似工具但是都做的不好。

同时他还把前几天自己的视频教程转成了文字内容，觉得视频太浪费时间的可以看文本。

AK 设想的完整工作流：

一个有趣的大语言模型 (Large Language Model) 挑战是：将我的2小时13分钟的分词器视频转换成一本书的章节（或者博客文章）形式，专门讨论分词。具体步骤如下：

为视频添加字幕或解说文字。
将视频切割成若干带有配套图片和文字的段落。
利用大语言模型的提示工程技术，逐段进行翻译。
将结果输出为网页形式，其中包含指向原始视频各部分的链接。

从更广泛的角度来看，这样的工作流程可以应用于任何视频输入，自动生成各种教程的“配套指南”，使其格式更加便于阅读、浏览和搜索。这听起来是可行的，但也颇具挑战。

LLM Tokenization课程文字版本：

https://github.com/karpathy/minbpe/blob/master/lecture.md



歸藏
@op7418
Open AI传奇研究员Andrej Karpathy的新课，教你理解和构建GPT Tokenizer。

他可以把相当复杂的LLM概念用非常好理解的方式讲出来。希望了解LLM的强烈建议听一下他的课，包括一些历史课程。

用GPT-4翻译了一下这节课，感兴趣可以听一下。字幕文件下载和历史课程会放在下面⬇️

歸藏
@op7418
补充一下视频介绍：

分词器是大语言模型（LLM）处理流程中一个独立且关键的环节。它们有专属的训练数据集、采用特定的训练算法——字节对编码（Byte Pair Encoding），训练完成后，分词器能够执行两个核心功能：encode() 函数将普通文本字符串转换为词元，而 decode() 函数则能将词元还原为原始文本字符串。在这场讲座中，我们将一步步揭开 OpenAI GPT 系列分词器的构建过程。

我们将发现，许多大语言模型(LLM)表现出的异常行为和问题，其实都源于标记化(tokenization)这一环节。我们会针对这些问题进行详细讨论，探究标记化为何成为问题的关键所在，以及为什么最理想的情况是有人能够找到办法，完全去除这一处理阶段。

https://x.com/op7418/status/1760105492356190368?s=20

视频文件和字幕下载在这里：
https://pan.quark.cn/s/9b4f07af69b7

### 39

2024-02-21

宝玉
@dotey
VisFusion：根据视频进行3D建模还原
论文标题：VisFusion: Visibility-aware Online 3D Scene Reconstruction from Videos

摘要：我们推出了一种名为VisFusion的创新技术，旨在通过单目视频实现在线3D场景的可见性感知重建。我们的方法不同于传统的重建技术，后者通常只是简单地将视图中的特征为每个体素堆叠起来，而不考虑其是否可见。VisFusion通过计算图像对中投影特征的相似度矩阵，精确推断出每个体素的可见性，从而优化了特征融合过程。我们遵循了一种从粗糙到精细的流程，其中包括了一个体积稀疏化步骤。与其他方法不同，我们不是全局固定阈值稀疏化体素，而是在每个视线上针对局部特征体积进行稀疏化处理，确保每条视线至少保留一个体素，以捕获更多细节。这些稀疏的局部体积随后与全局体积结合，实现在线重建。我们还提出了一种粗到细的TSDF（Truncated Signed Distance Function，截断符号距离函数）预测方法，通过跨尺度学习其残差，显著提高了TSDF的预测性能。通过基准测试，我们的方法在保留更多场景细节方面展现出了卓越的性能。

论文地址：https://arxiv.org/abs/2304.10687
项目地址：https://huiyu-gao.github.io/visfusion


### 40

2024-02-21

Vince He
@iarrp
这两天重看了一篇论文《AlphaCodium：引领代码生成新境界，从提示工程到流程工程》。

研究量化了使用流程工程替代单一步骤的提示工程在解决复杂任务时的显著效果提升。实验结果是在代码编程任务上，基于 GPT-4 的任务完成率从 19% 提升到了 44%。

发现两个问题。

第一个问题，论文中的任务执行流程显然是经过人工精心设计的。即便如此，看似前后任务完成率提高了 25% 之多，但整体的编程任务完成率仍旧低于 50%。

第二个问题，过程中为了判断代码生成方案的正确性，使用模型参与评估和裁决。随之导致了多轮重复迭代，引入了高额的 Token 消耗（即使是比前一代方法有所优化）。对于科学研究来讲可以不计成本，但对于实际应用来讲是个不得不考虑的问题。

使用 LLM 来参与过程评估并不是什么创新，在 RAG 评估中时常能看到类似的技术方案，但我对此始终存疑。对于 AlphaCodium 这个方法来说，就像是公司由于不信任一群不可靠的人做事，于是请来了另一个同样不可靠的人来监督他们工作一样。但在现实中的公司不会这么干，一个正常的管理者会将这些不可靠的人全部换掉。

我比较认同文章中提出的概念：流程工程（Flow Engineering），我们团队最近的工作重心也在这个方向。相较于通过单步编写过度复杂的提示词（包括使用 COT 这类高级提示词技术），通过人类经验设计拆解成多个固定步骤进行执行，会产生更好的效果。同时也是比 Agent 自主推理框架更可靠的方案。

但最终不足 50% 的任务完成率以及不可控的成本，更多表现出来的是 LLM 在面向复杂且严肃的生产力应用时的“无能为力”。这是由于在实际应用落地中，大部分生产力情景下对“容错率”都有相当高的要求，暂时抛开成本不谈，这可能是 LLM 近一年在各行业落地过程中遇到的最大阻碍。

距离 ChatGPT 发布一年多，在社交媒体新闻还在轮番渲染“AI 颠覆行业”“OpenAI 王炸升级”之时，对比之下，我现在看待生成式 AI 技术时显得有些悲观，也包括最近新发布的 SORA。

我现在的判断是，在当下这代模型架构下，即使你给模型喂饱整个世界最高质量的数据，在概率预测推导的技术本质下它只可能表现出“看起来好像有智能”和“不仔细看好像很真实”。

在这个前提下，对于生成式 AI 应用和技术工程中的启发是：我们应该多考虑“避短”而不是想方设法“补短”（比如 LLM 的幻觉问题，“幻觉”这个词本身就存在误导性）。仔细审视 AI 的能力，从本质上理解它的能力边界，让它去做可胜任的工作。

宝玉老师的论文翻译地址：http://t.cn/A6jtfOp4


### 41

2024-02-21

宝玉
@dotey
世界模型的概念是 Runway 先提出来的（至少从公开的信息来看），他们想打造一个超越纯文本大语言模型的世界模型，融合文本、音频、图像和视频，让模型自己拥有自己的心智图谱，理解真实世界的样子，探索世界中的“为什么”和“怎么办”。

结果 OpenAI 做了 Runway 想做还没做好的事情……

以下内容是基于字幕文本整理：

在探索人工智能的未来时，我们经常寻找那些能够突破现有技术极限的革新模型。想象一下，如果下一代AI模型采用的是一种更类似于我们心爱的宠物——比如我的狗狗Reuben——的思考方式，这将会怎样改变我们对创新的看法？

大语言模型（LLMs），比如能够创作诗歌、文章甚至电影剧本的AI，已经深入人心。这些模型的工作原理基于预测文本序列中的下一个词元，因此它们对句子的理解越深，生成新句子的能力就越强。随着这些模型在预测能力上变得更加精准，它们对世界及其模式的理解也日益加深，引领我们进入一个由大模型和大数据驱动的全新人工智能时代，扩展了它们的世界知识。

然而，LLMs的局限性在于，它们只能理解语言信息。这引出了一个有趣的思考：如果我们将这种大数据和大模型的策略应用于视频内容生成，会发生什么呢？这就是通用世界模型（GWMs）的概念。GWMs不仅需要文本数据，还需要视频、图像和音频等多种形式的数据来全面理解世界的运作。这些丰富的信息源能够帮助模型为自己构建一种心智地图，类似于我们心爱的宠物Reuben对世界的理解方式。

Reuben通过观察和经验，建立了一个基于他所了解的世界的内部模型。他知道哪条路可能会带他去公园，哪条路边可能有他不喜欢的狗，以及在哪里可以找到他喜欢的零食。通过这些数据——视觉、听觉和事物间的关系——Reuben学会了如何预测某些结果并相应地调整他的行为。这种能力，与通用世界模型的目标不谋而合。

令人兴奋的是，这些模型有能力将其对世界的理解推广到新的和未曾见过的情境中。这意味着，它们不仅能够根据已知信息预测未来，还能够探索世界的“为什么”和“怎样”，从而获得比大语言模型更为深入的理解。

总的来说，通用世界模型的兴起预示着一个更加丰富、更接近于人类或我们的宠物如Reuben的心智世界的AI未来。通过模拟这种复杂的、基于多种数据源的理解方式，AI的下一阶段将更加贴近于我们对世界的理解和互动方式，开启了真正的创新时代。

视频来源：https://research.runwayml.com/introducing-general-world-models


### 42

2024-02-21

宝玉
@dotey
推荐阅读：《万字长文深度解析Sora的核心技术，解密OpenAI掌控时空的秘密武器》
by 
@FeiArt_AiArt
 

转自作者微博：我仔细翻阅了Sora引用的论文，仔细拼凑出了Sora训练的核心秘密——时空图像块（Space timepatches）。如果不理解时空图像块的概念，那就不可能理解Sora为什么能降维打击现在的AI视频生成技术。

其实Sora并没有那么神秘，它核心的Diffsion Transfomer技术也不是#OpenAI#首创的。但Sora创造性地将多种技术结合在一起，并结合自身超强的工程能力和顶级海量算力，最终造就了Sora的成功。

https://weibo.com/ttarticle/p/show?id=2309405003442207719529


### 43

2024-02-21

宝玉
@dotey
推荐阅读：《新手如何为演讲制作精美的幻灯片》

1. 选择好看的字体
字体堪称设计界的隐形杀手锏，它是我首推的提升演示文稿吸引力的简单快捷方式。即便你别无所作，一个匹配的字体本身就能大幅度提升内容的个性魅力，而且探索新字体的过程充满乐趣（不过要注意，这可能会让你上瘾，就像购买那些你并不需要的域名一样，你会发现自己乐此不疲地寻找字体！）。

2. 利用好图片编辑工具
要制作出漂亮的幻灯片，你并不需要变成图形设计领域的专家！我自己甚至都不认为是一名设计师，因为对于很多设计工作我都无能为力，而且我大量依赖已有的设计素材。我真正的优势仅仅在于，我从青少年时期开始，就已经在摸索 Photoshop 和网页设计了。

3. 简约胜于繁复

优秀的设计理念往往是“少即是多”。设计元素和效果的魔力虽然吸引人，但过度堆砌就像 90 年代大量使用 Word Art 和 Clip Arts 一样，反而失去了本质。

原文：A beginner’s guide to making beautiful slides for your talks
https://ines.io/blog/beginners-guide-beautiful-slides-talks/
译文：https://baoyu.io/translations/design/beginners-guide-beautiful-slides-talks


### 44

2024-02-21

宝玉
@dotey
转译自彭博社：《Google 和 Microsoft 将在 AI 领域占据主导地位，原因是计算成本的急剧上升》
——在人工智能这个领域，初创公司难以承受日益增长的运营成本。

Sam Altman 谋求筹集约 7 万亿美元来制造人工智能芯片的雄心，不仅揭示了他的宏伟目标，也反映了两个现实：首先，建立 AI 所需的基础设施成本高昂；其次，目前大部分价值仍然集中在少数几家大型科技公司手中，而且这种集中趋势还在加剧。

尽管 ChatGPT 在 2022 年末的推出引发了激烈的竞争，并吸引了众多新的初创企业投身于热门的生成式 AI 市场，但许多新入场的公司可能会在未来一年左右的时间内退出市场或被大公司并购。高昂的经营成本让它们难以独立存活。

以 Sasha Haco 为例，她是 Unitary 的 CEO，该公司专注于检测社交媒体视频中的违规内容。若使用 OpenAI 的视频扫描 AI 工具，其成本将是向客户收费的 100 倍之多。因此，Unitary 开发了自己的模型，这本身就是一种风险与机遇并存的挑战。她的初创公司需要向 Microsoft Corp. 和 http://Amazon.com Inc. 的 Amazon Web Services 这样的云服务供应商租用稀有的 AI 芯片。Haco 表示，自 2020 年以来，这些芯片的价格已经翻倍，且很难预订。“有时我们无法获取我们所需的资源，因此不得不支付高达 10 倍的价格，”她说。

Unitary 设法克服了这些困难，但 Haco 坦言，目前还没有任何一个生成式 AI 初创公司找到了一种方法，能够像大型科技公司那样，以低成本扩大规模运营。另一位位于旧金山的 AI 创始人向我透露，一些不得不租用 AI 芯片和云计算资源的同行发现，他们唯一能盈利的方式是“如果客户不使用他们的产品”。

startup http://Dialogue.ai 的 CEO Ronald Ashri 将其比喻为“电力”：“你连接到一个基础模型，就像是接入了电力，你不断地消耗它。这种消费是我们向客户提供解决方案中最大的单项成本。”

生成式 AI 初创企业可以通过两种方式来构建他们的技术。一种是自主开发类似 OpenAI 的 GPT-4 或 Google 的 Gemini 这样的基础模型，这需要数亿美元的投资。另一种是在现有的模型基础上进行开发，这种方式只需数千万美元的投资，而且绝大多数 AI 初创企业都采用了这种方法。

这种现状揭示了一个现实：尽管市场竞争激烈，但高昂的计算成本和技术门槛使得只有少数大型科技公司能够在 AI 领域长期占据主导地位。对于初创公司而言，除非能够找到创新的低成本运营模式，否则在这个竞争激烈的市场中生存下来将是一个巨大的挑战。

在这两种情况下，主要的受益者是云计算巨头：微软、亚马逊以及 Alphabet Inc.（谷歌的母公司），还有 AI 芯片生产商英伟达公司。Vaire Computing 的 CEO Rodolfo Rosini 表示：“目前，所有这些初创企业都在向风险资本家筹集资金，然后将这些资金投向云服务公司和英伟达。”这就是为什么英伟达的股价在过去一年里翻了一番多，市值逼近 2 万亿美元的原因。

你可能会以为，大型科技公司会对 AI 初创企业充满兴趣，急于收购他们的新人才和新想法。但实际情况并非如此简单。大多数新兴的生成式 AI 初创企业并没有足够的 AI 研究人员，这让它们在招募人才方面显得不那么吸引人，因为它们依赖于更大的第三方模型。这些初创企业通常由普通的软件工程师组成。

此外，像 Meta Platforms Inc. 这样的大型科技公司已经在自己的 AI 研发上投入了大量资金。伦敦 AI 专注风险投资公司 Air Street Capital 的创始人 Nathan Benaich 指出，许多这样的公司去年还在大幅削减成本。

更大的挑战来自于监管方面。面对近期更为严格的反垄断执法浪潮，大型科技公司对于任何重大的 AI 交易都持谨慎态度，以避免反垄断的法律风险。因此，它们转而选择投资。根据市场研究公司 Pitchbook 的高级分析师 Brendan Burke 提供的数据，大型科技公司对 AI 初创企业的投资在 2023 年达到了超过 246 亿美元，较 2022 年的 44 亿美元大幅上升，此举旨在规避监管审查。

现在，随着美国联邦贸易委员会开始调查其中一些投资案例 — 包括微软对 OpenAI 的数十亿美元投资和亚马逊对 Anthropic 的投资 — 这种情况可能会重新倾向于传统的并购方式，Burke 表示。

在风险资本投资者和初创企业中，对于来年将会发生多少并购活动的看法不一。最可能发生的情况是：监管压力将阻止对那些估值超过 10 亿美元的领先 AI 初创企业进行收购，如 Perplexity、Cohere、http://Character.ai 和 Inflection。他们将会吸引投资 — 至少在目前是这样 — 而一些规模较小的企业可能会被并购，剩下的新兴企业在成本压力下可能会倒闭。

这将导致一个与今天非常相似的竞争格局，其中最大的玩家将继续扩大。这对于大型科技公司而言无疑是一场胜利，对消费者来说也是如此，因为他们将继续享受到便宜的 AI 服务。但这对于竞争和社会来说则是一种损失。当影响我们生活各个方面的通用人工智能被少数几家公司所主导时，这给予了这些公司巨大的权力和影响力。避免这种结果发生将是更好的选择。

来源：https://bloomberg.com/opinion/articles/2024-02-19/artificial-intelligence-microsoft-google-nvidia-win-as-computing-costs-surge


### 45

2024-02-21

歸藏
@op7418
k_zer0s老哥对Groq的LPU为什么能有这么快的推理速度做了相对详细的解释：

Groq的LPU在处理请求和响应方面，速度超越了Nvidia的GPU。

不同于Nvidia GPU需要依赖高速数据传输，Groq的LPU在其系统中没有采用高带宽存储器（HBM）。它使用的是SRAM，其速度比GPU所用的存储器快约20倍。

鉴于AI的推理计算相较于模型训练需要的数据量远小，Groq的LPU因此更节能。在执行推理任务时，它从外部内存读取的数据更少，消耗的电量也低于Nvidia的GPU。

LPU的工作原理与GPU截然不同。它采用了时序指令集计算机（Temporal Instruction Set Computer）架构，这意味着它无需像使用高带宽存储器（HBM）的GPU那样频繁地从内存中加载数据。这一特点不仅有助于避免HBM短缺的问题，还能有效降低成本。

如果在AI处理场景中采用Groq的LPU，可能就无需为Nvidia GPU配置特殊的存储解决方案。LPU并不像GPU那样对存储速度有极高要求。Groq公司宣称，其技术能够通过其强大的芯片和软件，在AI任务中取代GPU的角色。


### 46

2024-02-21

歸藏
@op7418
字节发布了一个用类似 SDXL Turbo 的模型SDXL-Lightning，只需几步即可生成高质量的 1024px 图像。

包括了 unet 模型和 Lora 模型都已经发布，Lora 模型可以用在其他 SDXL  模型上。感兴趣可以试试。

模型下载：

https://huggingface.co/ByteDance/SDXL-Lightning



### 47

2024-02-21


歸藏
@op7418
见鬼了，谷歌居然开源LLM模型了，Meta要慌了。

Gemma 采用了和Gemini一样技术的开源LLM，同时质量也比同规模的模型要强。

下面是一些要点：

◈ 两种尺寸的模型权重：Gemma 2B和Gemma 7B。每种尺寸都有预训练和指导调整的变体。

◈ 一个生成式人工智能工具包，为使用Gemma创建更安全的人工智能应用提供指导和必要工具。

◈ 通过原生Keras 3.0为所有主要框架（JAX、PyTorch和TensorFlow）提供推理和监督微调（SFT）的工具链。

◈ 准备好的Colab和Kaggle笔记本，以及与Hugging Face、MaxText、NVIDIA NeMo和TensorRT等流行工具的集成，使得开始使用Gemma变得非常容易。

◈ 预先训练和经过调整的Gemma模型可以在您的笔记本电脑、工作站或Google Cloud上运行，并可以轻松部署到Vertex AI和Google Kubernetes Engine（GKE）。

◈ 跨多个人工智能硬件平台的优化确保了行业领先的性能，包括NVIDIA GPU和Google Cloud TPU。

◈ 允许所有组织进行负责任的商业使用和分发，无论规模大小。

◈未来还会发布Gemma更大模型变体。

了解更多：https://blog.google/technology/developers/gemma-open-models

歸藏
@op7418
Boris Dayma 对谷歌 Gemma 技术报告的一些总结，觉得技术报告太长懒得看的可以看看：

◆这个模型的架构（architecture）和llama非常相似。

◆7B模型使用了惊人的6T tokens！

◆词汇量巨大。

◆在前馈神经网络（FFN）中使用了GeGLU，我希望他们能对那里使用的维度进行更深入的分析。一般人倾向于使用维度的4倍，但我更喜欢2.5-3倍之间。

◆他们使用三明治规范化（Sandwich-Norm）让我感到意外，我认为Normformer在位置编码上更为高效。

◆采用了16路模型分片和16路数据分片的方法：我需要学习他们是如何配置这些设置的，以及如何确保训练性能最优化。

◆我本希望了解他们使用了哪种精确度（bfloat16？还是注意力logits转换为float32？）。

◆他们使用的是哪种优化器？难道只有我在使用Shampoo吗？

关于测试7b模型的体验：

◆我喜欢预训练模型未经审查的特点。它表现非常出色，可能是下游任务微调的极佳选择。

◆我发现微调后的模型确实很好，但比mistral-7b-instruct-v0.2更加审查过滤。

◆在我的一些用例（如Craiyon的提示）中，我发现Mistral的效果更佳。我认为gemma的指导模型可能过度微调了。我希望Mistral指导模型的创建配方是公开的，这样我们就可以将其应用到gemma的预训练模型上。我需要测试其他开源的指导型变体（我并不完全相信基准测试，除了lmsys）。

◆我希望模型的安全性处理可以与指导模型分开，这样我们就可以拥有一些未经审查的指导模型，同时通过类似llama guard的模型来处理安全性，避免对模型本身造成干扰。

◆我认为这些模型将对JAX生态系统大有裨益，因为迄今为止开源的大语言模型（LLM）实现大多是基于Pytorch的。我迫不及待地想要重新深入研究Keras！

◆我非常高兴这些模型的权重被发布出来，并且我们得到了一些技术细节，而不仅仅是展示其能力的橱窗 🙏。


### 48

2024-02-22

Andrej Karpathy
@karpathy
\# on technical accessibility

One interesting observation I think back to often:
- when I first published the micrograd repo, it got some traction on GitHub but then somewhat stagnated and it didn't seem that people cared much.
- then I made the video building it from scratch, and the repo immediately went through hockey stick growth and became a verty often cited reference for people learning backpropagation.

This was interesting because the micrograd code itself didn't change at all and it was up on GitHub for many months before, stagnating. The code made sense to me (because I wrote it), it was only ~200 lines of code, it was extensively commented in the .py files and in the Readme, so I thought surely it was clear and/or self-explanatory. I was very happy with myself about how minimal the code was for explaining backprop - it strips away a ton of complexity and just gets to the very heart of an autograd engine on one page of code. But others didn't seem to think so, so I just kind of brushed it off and moved on.

Except it turned out that what stood in its way was "just" a matter of accessibility. When I made the video that built it and walked through it, it suddenly almost 100X'd the overall interest and engagement with that exact same piece of code. Not only from beginners in the field who needed the full intro and explanation, but even from more technical/expert friends, who I think could have understood it if they looked at it long enough, but were deterred by a barrier to entry.

I think as technical people we have a strong bias to put up code or papers or the final thing and feel like things are mostly self-explanatory. It's there, and also it's commented, there is a Readme, so all is well, and if people don't engage then it's just because the thing is not good enough. But the reality is that there is still a large barrier to engage with your thing (even for other experts who might not feel like spending time/effort!), and you might be leaving somewhere 10-100X of the potential of that exact same piece of work on the table just because you haven't made it sufficiently accessible. 

TLDR: Step 1 build the thing. Step 2 build the ramp. 📈
Some voice in your head will tell you that this is not necessary, but it is wrong.


### 49

2024-02-22

宝玉
@dotey
\#AI开源项目推荐：google/gemma.cpp

Google发布了用于自家开源的大语言模型 Gemma 的轻量级独立 C++ 库，可以方便的通过程序调用，理论上来说可以很容易通过Nodejs、Swift等语言调用。

项目地址：https://github.com/google/gemma.cpp


宝玉
@dotey
Google刚刚发布了开源大语言模型 Gemma，这是对标 LLAMA 2 的开源大语言模型。

Gemma是一系列基于创建Gemini模型所使用的相同技术与研究的、在其领域内技术领先的轻量级开源模型。

从今天开始，Gemma将向全球用户提供两种规模版本：2B（20亿参数）和7B（70亿参数），能够支持各种工具和系统，同时能在开发者的笔记本电脑及工作站上顺畅运行。

测试地址：https://huggingface.co/chat/
模型地址：https://huggingface.co/models?other=gemma&sort=trending&search=google
博客：https://blog.google/technology/developers/gemma-open-models/

### 50

2024-02-22

Andrej Karpathy
@karpathy
Seeing as I published my Tokenizer video yesterday, I thought it could be fun to take a deepdive into the Gemma tokenizer. 

First, the Gemma technical report [pdf]: 
https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf 
says: "We use a subset of the SentencePiece tokenizer (Kudo and Richardson, 2018) of Gemini for com- patibility. It splits digits, does not remove extra whitespace, and relies on byte-level encodings for unknown tokens, following the techniques used for both (Chowdhery et al., 2022) and (Gemini Team, 2023). The vocabulary size is 256k tokens."

The tokenizer.model file is with this code release:
https://github.com/google/gemma_pytorch/blob/main/tokenizer/tokenizer.model

I decoded this model protobuf in Python and here is the diff with the Llama 2 tokenizer:
https://diffchecker.com/TRnbKRMH/

Notes:
- vocab size is quite large: 32K -> 256K
- add_dummy_prefix is False. Different from Llama but consistent with GPT. This is a bit more consistent w.r.t. "leave the data alone", as there is no preprocessing step that adds a space to the encoding text.
- the model_prefix is the path of the training dataset, which is amusing to look at: "/cns/mf-d/home/gemini-data-access/tokenizers/final_v1_51GB_run1/bpe_coverage_0_999995_v5/255969".  Seems to indicate the tokenizer training corpus was ~51GB (?).
- a lot of user_defined symbols (i.e. special tokens) are present, e.g. "hardcoding" a sequence of up to 31 newlines as tokens, and a large number of other unclear tokens. I tried decoding the octal representations but it's not clear what's happening here. Also a lot of more special tokens for what look like html elements, e.g. <table>, <tr>, <td>, <i>, <b>, etc. Not 100% sure what the unused tokens are for, maybe this is pre-allocated space to make easier future finetunes that try to add more special tokens, as there is no need to resize vocabularies and perform model surgeries (?).

TLDR this is basically the Llama 2 tokenizer, except bigger (32K -> 256K), with a lot more special tokens, and the only functional departure is that add_dummy_prefix is turned off to False. So e.g. tokenizing:

"hello world" becomes:
[17534, 2134]
['hello', '▁world']

which otherwise would have been preprocessed to " hello world" (note leading space) and tokenized as:
[25612, 2134]
['▁hello', '▁world']

cool


### 51

2024-02-22

宝玉
@dotey
\#AI开源项目推荐：Enjoy

这次推荐的不是李笑来老师的人人都能用英语，而是他这个repo下面一个叫Enjoy的Electron程序，包含了语音转文本、翻译、视频下载等等商业级的功能，还是开源的。

本地运行了一下，main 分支没跑起来，但是v0.1.0-alpha.12能跑，拿个视频测试了一下，识别的结果不错，另外我才知道Whisper已经原生支持词级的时间戳生成了。所以Enjoy甚至能支持单词跳动。

这是我目前见过的最好的Whisper开源项目。（如果有更好的欢迎推荐）

https://github.com/xiaolai/everyone-can-use-english


### 52

2024-02-22

宝玉
@dotey
很荣幸受王又又邀请，今天和她以及《宇宙探索编辑部》副导演吕启洋（Ash）一起聊聊了一下当前火爆的话题 Sora，看 Sora 如何改变我们的生活。

我把技术相关的一些问题整理成了文字，希望能够帮助大家更好地理解 Sora。我将问题大约整理成了四类：
1. Sora 的技术科普
2. Sora 产品相关问题
3. Sora 的价值和应用
4. Sora 有关的八卦闲聊

注意，这里的回答都是我个人的观点，一部分也借鉴了大家在帖子中讨论的结果，很多答案不一定准确，仅供参考。也欢迎指正其中错误或者提出不同观点。

\## Sora 的技术科普

\### Sora 是什么？能干什么？

简单来说，Sora 是一种能用文本生成最长 60 秒视频的技术，也可以用来生成图片，因为图片本质上是一帧的视频。

\### Sora 跟之前的 AI 视频生成工具有什么升级？跟市面上其他的例如 Runway、Pika、SVD 这些 AI 视频生成工具有什么区别？

"之所以 Sora 引发极大关注，主要在于它生成视频质量要比之前的高很多，不仅时间最长能到 60 秒，而且它可以支持镜头切换、画面人物和背景稳定、很高画质。

Pika 是基于 Diffusion 模型，把图片和视频训练成毫无意义的马赛克图片，再从空白马赛克图片能反向扩散生成图片和视频，有两种主要模式，一种是基于图片关键帧扩展成视频，例如已有视频的风格变换；一种是对视频的训练，但是由于显卡限制，只能一次训练特定分辨率的几秒视频，一次也只能生成几秒钟的视频。

LLM、ChatGPT 是 Transformer 模型，预测 Token 生成文本内容，Token 可以理解为字和词。

Sora 则是基于 Diffusion Transformer 模型，结合了扩散模型和 Transformer 模型，不过它是预测生成的不是文本 Token，而是“时空补丁（spacetime patches） ”，可以理解为一个几帧（一秒不到）的视频的一个小块。

主要优势是训练的时候不受视频和显卡约束，生成的时候也更加多样，可以灵活组合时空补丁。"

\### 使用成本：现在可以生成 60 秒视频，60 秒视频的成本是多少？对算力有什么要求？

现在"DALL-E 3 HD Image 价格 $0.08；Runway Gen-2 价格是$0.05/秒。

Sora 没有公布相关数据，纯猜测：Sora 的推理大约需要 ~8xA100，生成视频预估一秒一分钟，半小时成本约 ~$10"

\### 有可能可以生成音乐（音频）么？如果不行难点在哪？

未来应该是可以的，现在没有是因为：
- 需要根据视频中的环境、物体类型、物体之间的碰撞、所在位置发出不同的声音
- 需要多种声源叠加
- 音乐不仅要质量高，还需要和视频中的场景融合
- 人物对白需要和人物的位置、口型、表情对齐

\## Sora 产品相关问题

\### 是否需要建模还是通过其他方式使用？什么时候能落地商用？

不需要本地搭建，预计会提供两种方式：ChatGPT 集成、API 调用；但生成视频的成本偏高、耗时也比较长；可能会限制次数或者提供更高一档的订阅。

预计三个月到半年内会逐步放开。

\### 在不同的时间使用相同的要求语，会生成相同的视频吗？能支持后续微调修改或者输入更确定的边界条件生成么？当前模型架构有能力支持这些么？

同样的提示词每次都不会相同，但是 seed 相同应该可以做到相似；

Sora 支持图片生成视频和视频生成视频，但人物是否可以做到一致还需要产品发布后才能下结论。

\### 什么时候可以生成更长时间的视频，比如 30 分钟、60 分钟甚至更长？

生成视频时间越长对显存要求越高，但是按照现在技术发展的速度，乐观估计 1 年后应该可以到 5-10 分钟，30 分钟 60 分钟预计在 3-5 年的时间。

\### 生成视频的版权归谁？

根据图片生成的规则来推测，应该是归创作者所有，但是生成的作品本身不能侵权。

\### 虚拟 vs 现实：如何判断那些视频是拍的？哪些是 Sora 做的？以后还有啥会是真的呢？深度伪造问题：会不会更容易被诈骗，如何反诈？

现在的视频都有水印，未来应该会有检测工具。

另外仔细看是能看出视频中不符合逻辑的地方，例如蚂蚁只有 4 条腿，人的手会变形等等。

我们其实早已经历过：照片不是真的、电视不是真的、电影不是真的，人民群众的鉴别水平也会同步提升。

伪造和鉴别伪造是长期攻防战。

\### Sora 接下来的发展前景演进趋势？

1. 成本降低（更快更便宜）；
2. 质量提升（时长、画质、镜头切换、一致性、符合物理规律）；
3. 新的能力：声音、和 GPT 的融合，完全的多模态；

\### 能不能用来做动画片？

短片完全没问题，复杂场景和更长时间的还不行，未来可期。

\## Sora 的价值和应用

\### Sora 有哪些应用场景？实用性有多大？商业应用价值？

我从四个方面总结了 Sora 的价值和应用：

1. 首先它能放大了普通人的表达能力，张小龙说汽车是双腿的延伸，ChatGPT 就是双手的延伸，Sora 就是我们表达的综合延伸，也就是传说中的“嘴替”

这意味着我们可以更好的来表达自己的想法，不再受限于自己的写作能力、画画能力、摄影能力、视频剪辑能力，甚至是演讲能力。

2. Sora 是一种低成本的视频工具

Sora 将极大的降低了视频制作的成本，这意味着更多的人可以用更低的成本来制作视频，这对于视频创作者来说是一个很大的利好。

3. 新的人机交互方式，动态生成视频

Sora 已经演示了生成我的世界这样游戏的能力，也许未来我们可以用 Sora 来动态生成游戏的剧情、任务、场景。另外，我们也可以让 Sora 动态对新闻、文章生成视频，而不需要去阅读。

4. 情感上的寄托

生成已故亲人的视频，保留他们的记忆。数字伴侣。

\### Sora 赚钱逻辑在哪里？

取决于围绕 Sora 创造的价值：
- 情感价值：卖课缓解焦虑、提供娱乐、情感寄托
- 艺术价值：微电影
- 内容价值：小说二创、卖素材、教学、讲故事、游戏生成、广告
- 生态价值：Prompt、更加易用小工具、绕过限制
- 降本增效：快速 MVP 验证想法、广告、电商、电影分镜

\### 普通人怎么用好？如何利用 Sora 做点副业？

- 用起来，学会怎么用，知道它能做什么，边界在哪里
- 选一个适合自己的方向，提前准备好相关素材或者开发项目
- 技术人员可以准备开始筹备产品、工具：收集 Prompt、基于 API 二次开发

\## Sora 有关的八卦闲聊

\### 名字真的是起源于天元突破的 op 空色デイズ吗？

我倾向于是。

\### 现在的热度是 (为了融资、股价) 的概念炒作？还是真实有用的？

真实有用，可以马上应用到短视频，例如 OpenAI 在 Tiktok 的账号，视频以假乱真

\### 您在网上看到或者听说的一些比较夸张脱离实际的说法？

"Sora"关键原材料之---马来酰亚胺树脂来自于四川绵阳一家公司。
Sora 懂物理
Sora 连接了游戏引擎
Sora 是 AGI 的关键里程碑，几年内就能实现 AGI

\### 在全球顶尖公司之间 Sora 的竞争力如何？中国在这个领域的发展情况？在中国做这个的公司有哪些？中国和欧美的差距在哪里？

OpenAI 已经投入了一年多，领先业界半年到一年，甚至更多，具体体现在：
- 技术的领先，目前技术还没公开，其他公司要破解需要时间
- 大模型的优势，他们有最先进的模型可以帮助训练，例如自动生成高质量的视频标注
中国应该很快能追赶上——人才、数据、算力都有，但是只有少数大厂才有机会，对人才、数据、算力要求都太高

目前不清楚是否中国公司已经有做这个方向的，但是字节、阿里、腾讯、百度在 AI 视频领域都有深厚积累

中国和欧美的差距主要在于对 AI 技术方向上的把握，但这也不仅仅是中国的问题，目前全世界所有其他公司都跟随 OpenAI 的步伐；另外就是算力上还不能完全自给自足。

\### 新一次产业革命？有网友指出，短短几年内，被追捧的高热度“划时代”技术有 web3、区块链、元宇宙、谷歌眼镜、波士顿机器人、vision pro、chatgpt 等等，这次确认要再次划时代了吗？

看怎么定义吧，从文本生成视频领域来说，一定是划时代的！真正的文本生成视频领域的 GPT 时刻。
- ChatGPT 文本生成
- Stable Diffusion、MIdJourney、DALL-E 图像生成
- Sora 文本生成视频

\### Sora 在硅谷的体感热度？在业内的真实反响？目前 AI 视频生成赛道的创业者、投资者们心态如何，将会如何应对？

- 反响热烈，正面评价居多
- 预计 Diffusion 方向会比较难拿到投资
- 创业者需要重新考虑方向，例如视频编辑、转向基于 Sora 的接口开发应用

\### 跟芯片有什么关系？

未来几年视频生成会继续热门，继续需要大量的算力，也就是需要大量的显卡，但未来显卡应该不会只有 NVIDIA 一家独大，应该会有更多的公司参与进来，这样的话，显卡的供应会更充足，价格会更加合理，性能也会更高。

\## 总结

以上就是今天访谈的主要内容，完整的视频地址在：https://weibo.com/6498373231/O1E3dzFky

另外以上很多内容总结自我在 Twitter 和微博上开的讨论帖，很多观点（例如 Sora 生成亲人视频）确实是我之前没有想到的，这也算是将大家讨论的内容的一个总结。谢谢各位的参与！

X 讨论帖：https://twitter.com/dotey/status/1759861034708251116
微博讨论帖：https://weibo.com/1727858283/O1tUdnbt8

本文同步发布于：https://baoyu.io/blog/ai/will-sora-change-our-life



### 53

2024-02-22

宝玉
@dotey
http://geogebra.org 这个学几何的网站上面的交互做的很不错，很多复杂的几何借助动画很容易就解释清楚了！

https://geogebra.org/m/hmk8vfke


### 54

2024-02-22

宝玉
@dotey
《现阶段 AI 的价值和盈利方向？》

这个来源于之前我在聊 Sora 的时候，总结了 Sora 的价值和可能的盈利方向，我把这部分内容单独摘出来再整理一下。

https://baoyu.io/blog/ai/ai-values-and-how-to-make-money-with-ai



### 55

2024-02-22

歸藏
@op7418
Andrej Karpathy 提出了一个工作流希望自动将长视频内容转换为带对应示例的播客文章。现在虽然也有一些类似工具但是都做的不好。

同时他还把前几天自己的视频教程转成了文字内容，觉得视频太浪费时间的可以看文本。

AK 设想的完整工作流：

一个有趣的大语言模型 (Large Language Model) 挑战是：将我的2小时13分钟的分词器视频转换成一本书的章节（或者博客文章）形式，专门讨论分词。具体步骤如下：

为视频添加字幕或解说文字。
将视频切割成若干带有配套图片和文字的段落。
利用大语言模型的提示工程技术，逐段进行翻译。
将结果输出为网页形式，其中包含指向原始视频各部分的链接。

从更广泛的角度来看，这样的工作流程可以应用于任何视频输入，自动生成各种教程的“配套指南”，使其格式更加便于阅读、浏览和搜索。这听起来是可行的，但也颇具挑战。

LLM Tokenization课程文字版本：https://github.com/karpathy/minbpe/blob/master/lecture.md



### 56

2024-02-23

宝玉
@dotey
推荐阅读，来自Meta的《V-JEPA：迈向 Yann LeCun 先进机器智能（AMI）愿景的新里程碑》

我们人类对周遭世界的认知大多来源于观察——尤其是在生命的早期阶段。就拿牛顿的第三定律来说：甚至婴儿或是猫，在将物品从桌上推下观察其落下后，都能直观感受到“物体上抛必将下落”的道理。这种认知不需长时间的教导或阅读海量书籍就能获得。你的内部世界模型——基于对世界的心理构建的理解——帮你预测了这一切，并且极其高效。

“V-JEPA 是让机器更实际理解世界、实现更广泛推理与规划能力的一大步。”Meta 的副总裁兼首席 AI 科学家 Yann LeCun 表示，他在 2022 年首次提出了 Joint Embedding Predictive Architectures（JEPA）概念。“我们旨在打造能够像人类一样学习、通过构建内部世界模型来适应和有效规划，以完成复杂任务的先进机器智能。”

原文：https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/
译文：https://baoyu.io/translations/meta/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture


### 57

2024-02-23

宝玉
@dotey
推荐阅读：《Sora物理悖谬的几何解释》by 顾险峰 老顾谈几何

部分节选：

局部合理与整体荒谬的矛盾

目前Sora相邻令牌间的拼接做得很合理，但是整体拼接的视频却可能出现各种悖谬。这意味着局部拼接与整体拓展之间的鸿沟。

我们观察“幽灵椅子”视频，如果我们将视野限制在屏幕中间的一个局部区域，则视频非常合理。仔细检测不同令牌区间直接的连接，也非常连续光滑。但是整个椅子如鬼魅般悬空，这与日常经验相悖。这种“局部合理，整体荒谬”的生成视频，意味着Transformer学会了Token间局部的连接概率，但是缺乏时空上下文的大范围整体观念。在这个视频中，整体观念来自于物理中的重力场，虽然局部看不出来，但是整体上无时不在。

https://mp.weixin.qq.com/s/HSZMbiFuNvTmBv26csZFGg


### 58

2024-02-23

歸藏
@op7418
Emad 昨晚的一个判断：

“长远来看，所有的算力都会用来生成媒体内容而不是语言处理。

语言模型的性能提升速度非常快，大部分应用将转向边缘计算。同时，大型企业的参与将推动通用语言模型的定价趋近于零。”

Groq 的出现就是一个表现，虽然现在还有各种问题，并没有真正降低成本。




### 59

2024-02-23


歸藏
@op7418
【好文推荐】《优化 Stable Diffusion XL 的终极指南》

详细介绍和测试了 SDXL 的模型优化方式，可以让 SDXL 在低显存显卡上稳定运行。同时大幅提高生成速度降低图像质量的损失。

推荐有部署和优化 SDXL 需求的朋友收藏阅读，写的真的很好。

--------详细介绍-------

该文详细介绍了如何优化Stable Diffusion XL (SDXL)以在任何显卡上获得最佳质量和性能。文章的核心目标是通过不同的优化技术，使SDXL能够在仅使用6GB内存的情况下生成图像，从而允许使用低端显卡。

作者使用Hugging Face的diffusers库进行脚本编写和开发，旨在让读者了解和应用这些优化技术，以便在各种应用中，如Automatic1111的Stable Diffusion web UI或特别是ComfyUI中，充分利用它们。

测试使用RunPod平台在Secure Cloud上生成了一个搭载RTX 3090显卡的GPU Pod进行。文章比较了不同优化技术的性能，包括感知图像质量、生成每张图像所需时间、以及使用的最大内存量。

优化技术包括CUDA和PyTorch版本选择、注意力机制优化、FP16、TF32、以及多种管道优化技术，如模型CPU卸载、批处理处理、Stable Fast、DeepCache和TensorRT。

文章的结论部分提供了一个表格，总结了所有测试的结果，并提供了在寻求质量、速度或在内存限制下运行推理过程时的建议。

例如，FP16优化通过使用半精度浮点格式显著降低了内存使用量并提高了计算速度，而Stable Fast项目通过运行时优化显著提高了推理速度。DeepCache通过使用缓存系统在保持较小的内存使用增加的同时，大幅减少了推理时间，但可能会略微降低图像质量。

总的来说，这篇文章为那些希望在不同硬件配置下优化Stable Diffusion XL性能的开发者提供了一份详尽的指南，展示了通过各种优化技术实现性能提升的可能性。

文章地址：https://felixsanz.dev/articles/ultimate-guide-to-optimizing-stable-diffusion-xl

[Ultimate guide to optimizing Stable Diffusion XL - Félix Sanz](https://www.felixsanz.dev/articles/ultimate-guide-to-optimizing-stable-diffusion-xl)

### 60

2024-02-23

宝玉
@dotey
转译自CNN：《普林斯顿大学利用人工智能突破核聚变控制难题，成功率大幅提升！》

致力于核聚变能源的科学家表示，他们已经找到了一种方法，通过使用人工智能来克服迄今为止最大的挑战之一。

核聚变被视为几乎无尽的清洁能源，若实现，将成为应对气候危机的革命性方案。然而，尽管科学家们成功实现了短暂的聚变反应，但如何维持聚变能量和解决过程中的不稳定等诸多挑战，仍然是科研中的难题。

聚变能的实现途径多样，最常见的方法是使用氢的同位素作为燃料，在一个甜甜圈形状的设备内——被称为托卡马克（tokamak）——将温度升至极高，以产生一种类似“热浆汤”的等离子体状态。

然而，这种等离子体必须被精确控制，它极易被机器的强大磁场“扯出”而逃逸，这些磁场本是设计用来约束等离子体的。

周三，普林斯顿大学及其等离子体物理实验室的研究人员在《自然》杂志上报告，他们发现了一种用人工智能预测并实时防止这些潜在不稳定性发生的方法。

该研究团队在圣地亚哥的 DIII-D 国家聚变设施进行实验，发现他们的 AI 控制系统能够提前最多 300 毫秒预测等离子体可能的“撕裂”。若无此干预，聚变反应可能会突然终止。

“这些实验为使用 AI 解决等离子体不稳定性——长期以来阻碍聚变能发展的难题——提供了坚实的基础，”普林斯顿的发言人表示。

普林斯顿大学的机械与航空工程教授、该研究的共同作者 Egemen Kolemen 表示，这些发现无疑是核聚变研究向前迈出的一大步。

“这是个重大的障碍 — 干扰。我们期望任何反应堆都能够全天候、连续运行多年，而不出现任何问题。” Kolemen 对 CNN 说，“这类干扰和不稳定会带来巨大的麻烦，因此，开发出这样的解决方案，让我们更有信心地说，我们能够无故障地运行这些设备。”

聚变能，这个让太阳和其他恒星闪耀的奥秘，几十年来一直是科学家梦寐以求的能源。当两个本应互相排斥的原子被迫融合时，聚变能便诞生了。这与我们今天广泛使用的核裂变——一种通过分裂原子来释放能量的过程——截然不同。

本月早些时候，英国牛津附近的科研团队刷新了核聚变能的纪录，他们仅用0.2毫克的燃料就维持了69兆焦的聚变能量长达5秒。换句话说，这段短暂的实验时间内产生的能量，足以供应大约12,000个家庭使用。

尽管这一实验的能量输入仍超过了产出，但加利福尼亚的一个团队在2022年12月首次实现了所谓的“点火”，即实现了聚变能量的净输出，并已成功重复了这一成就三次。

虽然聚变能的商业化应用看似遥不可及，但科学家们的这些突破为我们展示了一条通往清洁能源未来的希望之路。要避免气候变化带来的更严重影响，科学家强调，本十年内实现温室气体的大幅削减至关重要。

来源：https://cnn.com/2024/02/21/climate/nuclear-fusion-ai-climate-solution/index.html


### 61

2024-02-26

歸藏
@op7418
Mistral 正式发布 Mistral Large在基准测试中仅次于GPT-4，超过其他所有模型。

Mistral Large具有新的功能和优势：

它在英语、法语、西班牙语、德语和意大利语方面拥有母语般流利的能力，并对语法和文化背景有细致的理解。

其32K令牌的上下文窗口允许从大型文档中精确地寻找信息。

它精确的指令跟随能够让开发者设计他们的管理政策 - 我们用它来建立 le Chat 的系统级管理。

它本身就能够进行函数调用。这一点，再加上在la Plateforme上实现的受限输出模式，使得应用程序开发和技术栈现代化能够大规模进行。

支持在La Plateforme、Azure和私有部署。

了解更多：https://mistral.ai/news/mistral-large/



### 62

2024-02-26

宝玉
@dotey
如果要写一个Prompt，让LLM帮你识别编程语言，其实可以让ChatGPT（GPT-4）帮你写Prompt，效果不错。

第一步，直接把你要写让它写的Prompt告诉它，比如说：
“请帮我为GPT-3.5的API写一个Prompt，要求是输入一段代码，输出是一个JSON数组，包含可能得语言”

Help me to write a Prompt (System Message) for GPT-3.5 API, the input is a string with a peace of code, the task is identify the possible programming languages. output should be a JSON array so I can parse it.

注意要说清楚模型，如果是GPT-4的Prompt，可以简洁很多。

第二步，如果你对结果不满意，让它继续修改，满意为止，比如它第一次生成的Prompt只是返回一个字符串数组，但是我希望能包含每个语言的可能性，这样我可以排序过滤。所以我就可以进一步提要求：

“Please optimize the prompt, add score for each language, so I can sort and filter”

第三步：测试你的Prompt

如果测试结果不满意，可以回到第二步继续完善或者直接重新开始。

注意：如果是已经写了一段Prompt想优化，可以带上你写好的Prompt让它基于已有Prompt优化。

参考会话：https://chat.openai.com/share/e/3cac495e-f1bf-4609-a26e-80fa695229e2

参考Prompt：

Given a string containing a piece of code, analyze the syntax and features of the code to identify the possible programming languages it could be written in. For each identified language, assign a confidence score between 0 and 1, where 1 indicates the highest confidence that the code snippet belongs to that language. Output your guesses and their corresponding confidence scores in a JSON array format. Each element in the array should be an object containing the language and its confidence score.

Consider common programming languages such as JavaScript, TypeScript, Python, Ruby, Java, C, C++, Go, Rust, Swift, and any others you deem possible based on the input. 

For example, if the input code is "print('Hello, world!')", you should recognize this could be Python or Ruby, among other possibilities. Assign a confidence score to each language based on the syntax and features of the provided code snippet, and output your response in the following format:

[
  {"language": "Python", "score": 0.9},
  {"language": "Ruby", "score": 0.6}
]

Now, analyze the following code snippet, identify the possible programming languages, assign a confidence score to each, and output the results in the specified JSON format:


### 63

2024-02-26


歸藏
@op7418
从最近的人工智能研究成果来看，与以前的单一模型不同，有越来越多的多组件结构的复杂系统正在发挥作用。

伯克利人工智能研究这篇文章就详细分析了复合人工智能系统的趋势及其对AI开发者的意义。

我也翻译并总结了一些关键内容，完整翻译和原文在最后面👇。

1️⃣为何选择复合人工智能系统？

1.系统设计更易于改进某些任务，许多应用中，扩大规模的回报相比成本来说更低，系统设计的迭代通常比等待训练运行要快得多。

2.系统可以更具动态性，开发人员需要将模型与其他组件（如搜索和检索）结合，以纳入实时数据

3. 通过系统更易于提升控制和信任，使用AI系统而非单一模型，可以帮助开发者更紧密地控制行为

4.性能目标差异较大。每个AI模型都有其固定的质量水平和成本，但应用程序通常需要调整这些参数。

2️⃣复合AI系统的关键挑战

设计空间：给定任务的可能系统设计范围非常广泛，开发者需要在系统组件间分配有限的资源，如延迟和成本预算

优化：通常，在ML中，最大化复合系统的质量需要协同优化组件以便它们协同工作

运营：对于复合AI系统来说，机器学习操作（MLOps）更具挑战性。值得关注的问题包括监控、数据运营、安全性等。

3️⃣新兴的AI系统范式有哪些？

设计AI系统：组合框架和策略，许多开发者都在使用“大语言模型编程”框架，将多次调用AI模型和其他组件整合到应用程序中。

自动优化质量：DSPy是第一个旨在优化由大语言模型调用和其他工具组成的系统以最大化目标指标的框架。

运营：LLMOps和DataOps，AI应用程序一直需要仔细监控模型输出和数据管道，以可靠地运行。

优化成本：FrugalGPT和AI网关，广泛的AI模型和服务使得为应用程序选择合适的模型变得具有挑战性。

### 64

2024-02-26


宝玉
@dotey
我给年轻人的建议：重点不是你要不要做副业，而是你有没有设置长远的职业目标。不需要很长远，但三五年的目标是要有的。

因为副业是手段，不是目的。如果你的目标是赚钱（虽然不见得是个好目标），那么副业短期也许可以帮助你一些，但如果你的目标是技术上成长，也许不是最有效的方式。

设定了职业目标后，然后要做的就是看看你的本职工作和目标的重合度有多少？怎么尽可能的让自己的本职工作去达成自己的职业目标。

由于我们每天大部分时间都是做的本职工作，所以能最大化的利用好本职工作助力你的职业目标是最经济有效的。

举例来说，你的目标是三年内成为一个资深的前端工程师，但是你本职工作是全栈工程师，那么就应该就可能选择前端相关的工作，或者去调到一个做前端的岗位，这样才能最大化的帮你成长。

如果你发现的本职工作和职业目标匹配度很低，也许是时候要考虑换个工作了。

但无论你的本职工作和你的职业多么匹配，总有一些事情是在工作之内学习不到的，比如产品设计你不会参与、项目管理没机会、技术方案选的不是你喜欢的。那么这时候，你做一些副业side project就可以很好的弥补这些不足。

我们年轻的时候有的是时间和精力，缺的是知识和技能还有经验，最大化的利用好主业和副业帮助自己成长才是王道。

如Fenng所说，副业相对适合年纪大的人，这也是事实，毕竟本职工作上成长的空间越来越小了也越来越熟练了，就得多搞搞副业了。

Xiaowen
@iamshaynez
《软技能》里有一段说的很对，讲投资的。

一个最常被问到的场景：如果我手里只有 1000 美元，应该怎么投资。

答案是：投资自己，让自己的知识继续增长，直到能换到更多的钱为止。

---

每个人都是自己的一人公司，打工的本质是公司购买了你提供的服务，而这家公司，是你唯一客户（收入占比 100%）。

你自己的能力能换多少钱，这是职业市场上定价来的，相对也公平，在自己的能力的定价还不尽如人意的前提下，我不认为大部分人在副业里能得到大于主业的回报的。（反正我是没希望……）


### 65

2024-02-26

fin
@fi56622380
视角有一定道理（局部优化），但可能忽略了定量，而定量很重要。软件/IT行业（数字化信息化）的本质就是提升效率的过程，AI只是继续延续了这个过程

当提效工具和企业现有服务结合起来，就会影响企业的走向了。因为当结合起来效率的提升如果够大，就会产生范式转移，这是个量变到质变的过程

就像上一轮AI热潮最典型的推荐系统兴起，改变了社交app和电商的格局，相应的产值也扩大了太多。小红书和抖音就是最典型的例子，都是推荐系统应用的天花板水平。小红书在部分信息获取渠道上，可能在目前工具里有独特的难以取代的生态位


### 66

2024-02-26

歸藏
@op7418
微软的论文，基于已经发布的内容和他们自己的逆向工程，全面回顾了 Sora 的背景、相关技术、新兴应用、当前的局限性和未来的机遇。

非常全面和条理，建议全文阅读。

论文简介：
本文基于公开的技术报告和对Sora的逆向工程分析，全面评述了该模型的发展背景、相关技术、应用领域、当前面临的挑战以及文字到视频AI模型的未来趋势。

文章首先回顾了Sora的发展历程，并深入探讨了构建这一“虚拟世界模拟器”的关键技术。随后，文中详细介绍了Sora在电影制作、教育、市场营销等多个行业中的应用及其可能带来的影响。

我们还讨论了要大规模部署Sora所需解决的主要挑战和限制因素，例如如何确保视频生成的安全性和公正性。

最后，文章探讨了Sora以及视频生成模型的未来发展方向，以及该领域的进步如何可能为人类与AI的互动开辟新的方式，从而提高视频制作的效率和创造力。

论文地址：https://arxiv.org/abs/2402.17177v1


### 67

2024-02-26

歸藏
@op7418
受NVIDIA's Chat with RTX启发做的项目chat-with-mlx。

支持自动下载本地模型，并且可以同本地文件进行交互，支持多种语言，包括英语、西班牙语、中文和越南语。

该项目的一个关键特点是易于集成，用户可以轻松集成任何HuggingFace和MLX兼容的开源模型。

感兴趣可以试试：https://github.com/qnguyen3/chat-with-mlx


### 68

2024-02-26

Andrej Karpathy
@karpathy
Setting up my shiny new fully maxed out Space Black MacBook Pro M3 Max 128GB 16-inch (upgrading from an M1 Air). I always like to set up the new one with a clean slate, from scratch - this time I will not allow my dev configuration to get out of hand. Then we'll talk to it.


### 69

2024-02-26

宝玉
@dotey
这篇Sora逆向论文的全文翻译：“Sora：探索大型视觉模型的前世今生、技术内核及未来趋势”

https://baoyu.io/translations/ai-paper/2402.17177-sora-a-review-on-background-technology-limitations-and-opportunities-of-large-vision-models

摘要

Sora，一款由 OpenAI 在 2024 年 2 月推出的创新性文转视频生成式 AI 模型，能够依据文字说明，创作出既真实又富有想象力的场景视频，展现了其在模拟现实世界方面的巨大潜能。本文基于公开技术文档和逆向工程分析，全面审视了 Sora 背后的技术背景、应用场景、当前面临的挑战以及文转视频 AI 技术的未来发展方向。文章首先回顾了 Sora 的开发历程，探索了支撑这一“数字世界构建者”的关键技术。接着，我们详细探讨了 Sora 在电影制作、教育、市场营销等多个领域内的应用潜力及其可能带来的影响。文章还深入讨论了为实现 Sora 的广泛应用需克服的主要挑战，例如保证视频生成的安全性和公正性。最后，我们展望了 Sora 乃至整个视频生成模型技术未来的发展趋势，以及这些技术进步如何开创人机互动的新方式，进而提升视频创作的效率和创新性。


### 70

2024-02-26

Gorden Sun
@Gorden_Sun
LayerDiffusion：能让Stable Diffusion生成透明图片
训练时在潜空间加入了Alpha透明通道的编码，使用这个潜空间进行训练或微调，可以让任意SD模型都能生成透明图片。可以生成透明图片，可以把前景和背景分离，也是一种有潜力的生成动画的方法。
目前只有论文，作者是ControlNet作者，后续肯定会开源。
论文：https://arxiv.org/abs/2402.17113
Github：https://github.com/layerdiffusion/LayerDiffusion

