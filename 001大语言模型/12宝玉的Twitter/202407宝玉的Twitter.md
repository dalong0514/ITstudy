### 01

2024-07-02

宝玉
@dotey
腾讯的多智能体翻译工具已经可以免费在线试用了，而且是使用的 GPT-4 的 API，你可以上传txt或者pdf文件，然后会自动帮你翻译，并且整个过程都可以从右边的 Chatbox 看到。

注意上传后要手动选一下目标语言。使用地址见原推。

Longyue Wang
@wangly0229
🚀 Exciting News! 🚀

✨TransAgents, the cutting-edge virtual multi-agent translation company powered by advanced LLMs, is now live! 🌍

Experience our demo system at http://transagents.ai and kickstart your own AI venture with LLMs today. For a limited time, we're offering free credits for trial!


[app](https://transagents.ai/)

Chinese

English

### 02

2024-07-02

歸藏(guizang.ai)
@op7418
七年前最先进的图像技术也只能生成这些 32x32 的小图。谁能想到今天会有 Gen-3 这种视模型呢。

可能再过七年 Gen 3 看起来也会傻傻的。
引用
Andrej Karpathy
@karpathy
·
7月2日
I feel like I have to once again pull out this figure. These 32x32 texture patches were state of the art image generation in 2017 (7 years ago). What does it look like for Gen-3 and friends to look similarly silly 7 years from now.  x.com/runwayml/statu…



### 03

2024-07-02



小互
@imxiaohu
Runway Gen-3 Alpha 文本到视频模型已开放

所有人都可以使用了…

### 04

2024-07-02

宝玉
@dotey
\#开源项目推荐: mupdf.js

对Python熟悉的同学都知道PyMuPDF，是一个功能强大的PDF解析操作库，其实这个库也有JS版，而且是官方出的，可以用在浏览器上（基于WebAssembly和Worker）和 Nodejs 上，性能很不错。

比如截图中这个PDF渲染的例子，并不是用的浏览器自带的PDF预览，而是用mupdf.js解析，然后再用canvas和html元素渲染出来的。

另外 mupdf 除了Python和JS版，还有 .Net 和 Java 版。

演示地址：https://mupdf.com/wasm/demo/
项目地址：https://github.com/ArtifexSoftware/mupdf.js
官网地址：https://mupdf.com



### 05

2024-07-02


歸藏(guizang.ai)
@op7418
Langchain 出的 RAG 教程。

教学内容包括：查询转换、假设文档嵌入（HyDE）、路由机制、查询构建、索引策略、不同的检索技术，以及生成阶段的细节。

最终，通过将所学知识应用于 Neo4J 的实际场景。

---

LangChain
@LangChainAI
Learn RAG with Langchain 🦜⛓️‍💥

This is a *great* guide to all things RAG!

Covers query transformation, HYDE, routing, query construction, indexing, retrieval, generation, and of course....

GraphRAG with Neo4j!

https://sakunaharinda.xyz/ragatouille-book/intro.html


### 06

2024-07-02

小互
@imxiaohu
未来计算机构想： 一种端到端的神经网络计算机

Andrej Karpathy 提出了一个概念：一种完全由神经网络驱动，不再依赖任何传统的软件代码的计算机。

设备的输入（如音频、视频、触摸等，也可以是自然语言输入）直接传递给神经网络，输出则直接显示为结果，可能是音频/视频，也可能是交互界面在屏幕上。

这种简化的架构意味着整个计算过程完全依赖于神经网络的处理能力。

我感觉这个构想是可以实现的，上周参加豆包的MarsCode编程助手发布会讨论的时候，就讨论过这个想法。

就是现在其实已经基本具备了这种雏形，目前的AI能力已经可以通过自然语言文本生成音频、视频、交互界面等可以直接展示的结果，无需在进行复杂的编码了。

这种有点更像人类大脑的运作方式，能够从数据中学习和适应，然后自动产生具体的声音、画面和解决方案。

通过直接进行神经网络产出你想要的结果，将彻底改变计算机的工作方式：  

1、无需编程：计算机不再需要将指令编写代码再进行运行，神经网络可以根据用户的需求和指令，直接生成程序甚至结果。

 2、高效执行：直接从想法到结果的端到端神经网络方案，使得计算效率更高、运行速度更快。 

3、自我进化：计算机可以持续学习和自我更新，不断的适应和响应环境变化和用户的各种需求。

4、云端运行：无需在制造各种硬件设备，只需一块屏幕或者虚拟显示，即可在云端持续运行，随时响应。

但是这也意味着将耗费惊人的算力和能源...



### 07

2024-07-02

歸藏(guizang.ai)
@op7418
Mann-E Dreams 一个新的 XL 模型，生成的图片质量非常高。

使用 MJ 的图像训练，生成速度也很快，只需要 8 步。

CFG 值建议 2-4，分辨率 768x768 和 832x832 都行，采样器推荐 DPM++ SDE Karras。




### 08

2024-07-02

宝玉
@dotey
微博推出了 AI 小助手，可以代替博主回复评论，但有时候也会自作主张帮博主做出一些承诺，比如图二中那样，有人问博主去不去参加深中通道试运营典礼，结果 AI 小助手给人家回复：“那咱们明天见，路上小心驾驶哦💪”，搞得人信以为真，结果等不到博主！

Meta 也在测试类似功能，所以小札也被问到类似问题，如果 AI 分身被问到一些“观点”类的问题，该怎么处理？既要有用，又不能乱说话闯祸。

小札说这是“艺术”，确实是艺术，但怎么才能科学的解决这个问题呢？



### 09

2024-07-02



歸藏(guizang.ai)
@op7418
看来 Llama3 400B 已经训练完成。

Whatsapp 上出现了 Llama3 405B 的选项。


### 10

2024-07-02


小互
@imxiaohu
炸裂了 兄弟们 😑

使用Runway Gen 3 制作的3D巨幅字幕

类似电影片头那种高大上的效果

提示词：

Prompt："Blizaine "这个单词以大型 3D 字母出现在夜晚的城市街道上，字母上播放着各种超级英雄电影场景的纹理，让人联想到 MARVEL MCU 的前奏。镜头运动从极度特写开始，拉近到很远的距离，因此只能看到单词的一小部分，然后缓慢倾斜摇镜头并旋转，露出整个单词和上面的电影场景。电影感十足"。

Prompt: “The word "Blizaine" in large 3D letters on a city street at night with various superhero movie scenes playing on the letters as textures, reminiscent MARVEL MCU intro. Camera Movement starts with an extreme closeup, zoomed very far in so only small section of the word can be seen, then slow angled dolly-out and rotate, revealing the entire word with movie scenes on them. Cinematic.”

---

小互
@imxiaohu
Runway Gen-3 Alpha 详细使用教程

以及提示词指南大全，包括摄像机风格、灯光效果、运动状态类型以及风格美学、文本风格等。

详细内容：https://xiaohu.ai/p/10762

### 11

2024-07-02


小互
@imxiaohu
全球首款集成GPT-4o 的智能眼镜发布 

支持视觉能力和语音提示

可以根据用户所看到的内容和识别到的人或物体提供实时回答。

---

小互
@imxiaohu
该眼镜采用模块化设计，可更换不同样式的传统框架。

此外，它还具备 LED 通知灯，并将整合 Google Gemini 和 Anthropic 的 Claude AI 模型。 

 Solos AirGo 3 音频眼镜不含相机，售价为 249 美元。

详细功能及技术细节介绍：https://xiaohu.ai/p/10683



### 12

2024-07-02



歸藏(guizang.ai)
@op7418
他们的提示词重写逻辑很有意思，能够根据不同的输入和配置生成最优的提示词，且能自动调整以满足模型的令牌数限制。

它灵活地接受不同类型的实体输入（字符串或列表），处理多个示例和文档，并根据模型的最大Token限制计算剩余的Token数，从而确保生成的提示词在Token限制范围内。

---

歸藏(guizang.ai)
@op7418
微软昨晚重磅开源了强大无比的 RAG 方案——GraphRAG。

在社区摘要应用中，GraphRAG 在全面性和多样性上以 70-80% 的胜率大幅领先于传统 RAG。

GraphRAG 是一种基于图的 RAG 工具，通过 LLM 从文档集合中自动提取丰富的知识图谱，助力处理私有或未知数据集的问答。

---


歸藏(guizang.ai)
@op7418
项目页面：

microsoft/graphrag

A modular graph-based Retrieval-Augmented Generation (RAG) system


### 13

2024-07-03

宝玉
@dotey
Fish Speech 这个是效果真的不错，生成速度很快，克隆出来的声音也很逼真

测试地址：
https://fish.audio/zh-CN/text-to-speech/



### 14

2024-07-03

宝玉
@dotey
\#开源项目推荐：React-Tweet

这是 Vercel 出的一个可以在你的 React 项目中，在网页内嵌入一条推文。不止是可以用在 React 项目，它也提供了 API 可以帮你根据 ID 抓取推文内容、评论数、图片等信息。并且是完全免费的，不需要申请开发者账号，也不需要给 X 交钱。

但是它获取时只能获取140内的文本内容，超过140的长文无法完整获取，因为也不能获取 Thread 或者回复。

原理不复杂，用的一个隐藏的 API http://cdn.syndication.twimg.com/tweet-result，传入 id、lang 和 Token 等三个基本参数就可以。其中算 Token 的算法很简单，验证也不严谨。

项目地址：https://github.com/vercel/react-tweet



### 15

2024-07-03

歸藏(guizang.ai)
@op7418
Gorq 现在已经支持 Whisper v3 的语言转文字推理，速度巨快。

感觉可以大力出奇迹搞一个 GPT 实时语音出来。



### 16

2024-07-03



小互
@imxiaohu
Meta AI发布一看端到端生成高质量的 3D 资产生成模型 

不到一分钟时间即可根据文本生成高质量3D模型

生成的结果优于现有解决方案，速度是该领域现有工作的 3-10 倍。



### 17

2024-07-03

小互
@imxiaohu
Suno 推出了 iOS 客户端

可以在手机上收听和创建音乐了。 

支持通过文字和语音（例如哼唱）来创建音乐，整理和管理创作的音乐作品。

还可以根据分类查找收听别人创作的音乐，有点像音乐APP了...

下载：http://suno.com/ios （目前只支持美区）



### 18

2024-07-03


宝玉
@dotey
转译：《如何使用ChatGPT撰写科学研究论文？- Dr Asma Jabeen》

ChatGPT是一种AI语言模型，可以根据用户提供的输入生成文本。它可以作为一种工具，帮助撰写科学研究论文。撰写科学研究论文不仅需要对主题的深入了解，还需要批判性思维、解决问题的能力、分析和数据解释技能。因此，使用ChatGPT时，应将其与您的专业知识、经验和技能相结合。

本文将讨论使用ChatGPT撰写科学研究论文的9个重要步骤。

1. 收集研究材

在使用ChatGPT之前，您需要收集和整理撰写科学研究论文所需的所有研究材料，包括文章、书籍、期刊以及其他计划使用的资料。

2. 与ChatGPT进行头脑风暴

使用ChatGPT对研究主题进行不同角度的头脑风暴，并据此编写最终版本。

3. 确定研究问题

确定您在研究论文中要解决的研究问题或假设。

4. 进行文献综述

使用ChatGPT搜索与研究主题相关的科学文献，突出显示并指定与研究问题和假设相关的文献。

5. 总结重要的研究文章

利用ChatGPT总结您标注的研究文章的关键内容。

6. 识别文献中的研究空白

通过ChatGPT进行头脑风暴，找出文献中的研究空白。

7. 分析数据

对通过调查或其他方式收集的数据进行分析，然后使用ChatGPT帮助解释数据并生成支持您发现的可视化图表。

8. 创建研究论文的提纲

使用ChatGPT组织您的研究论文，创建提纲并逻辑地结构化您的论点。使用ChatGPT生成论文的各个部分，如引言、方法、结果和讨论部分，但务必仔细审查其生成的内容。

9. 编辑和校对您的论文

使用ChatGPT编辑和校对论文的语法、标点和拼写错误，但请仔细检查和审阅，以确保内容的流畅、准确、清晰和研究的真实性。

按照上述9个步骤，您可以使用ChatGPT撰写研究论文。

关于使用ChatGPT撰写科学研究论文的4个事实

1. ChatGPT无法独立完成科学研究论文的写作。科学知识、人类专业知识、批判性思维和分析能力对于论文写作至关重要。ChatGPT可以作为一个生成内容的助手。

2. ChatGPT是研究辅助工具，但不能取代人类研究人员。

3. ChatGPT可以协助进行数据分析和解释，但仍需人类输入以确保数据的准确性。

4. ChatGPT生成的内容可能存在错误，因此审查其生成的内容以确保准确性非常重要。
引用
Dr Asma Jabeen
@DrasmaJabeen1
·
7月2日
ChatGPT for research paper writing #AcademicTwitter https://drasmajabeen.com/chatgpt-for-scientific-research-paper-writing/



### 19

2024-07-02

小互
@imxiaohu
Fish Speech：完美支持中英日语言的开源TTS模型 

语音处理接近人类水平

模型使用约十五万小时三语数据训练，对中文支持非常的完美。

---

小互
@imxiaohu
该项目由 fishaudio 开发，作为一个仅有亿级参数的模型，Fish Speech 设计高效轻量，可以在个人设备上轻松运行和微调，成为您的私人语音助手。

详细介绍及更多演示：https://xiaohu.ai/p/10779
GitHub：https://github.com/fishaudio/fish-speech


### 20

2024-07-03

歸藏(guizang.ai)
@op7418
Perplexity  发布升级版的专业搜索，提供更复杂的问题解决能力。

Pro Search 使用更多步骤推理来解决复杂问题。Pro Search 还会分析搜索结果并根据其发现采取智能行动。

Pro Search 的代码执行能力得到了增强。使其在数据分析、调试和内容生成方面更快、更强大。

专业搜索现在可以免费使用。

---

小互
@imxiaohu
Perplexity发布 Pro Search 高级搜索功能

支持多步推理、先进的数学和编程能力

Pro Search可以通过多步推理来处理更复杂的问题。它不仅仅是提供简单的答案，而是能够综合分析搜索结果，并基于其发现采取智能行动。这包括启动后续搜索，逐步构建在之前结果的基础上。

Pro Search通过整合Wolfram|Alpha引|擎，显著提升了其数学和编程计算能力。这使其在数据分析、调试和内容生成方面变得更快更强大。

•复杂数学问题：以空前的准确性和速度解决复杂的数学问题。

• 代码执行：代码执行能力增强，使得数据分析、调试和内容生成更加高效。

### 21

2024-07-04

Andrej Karpathy
@karpathy
I'm playing around with generative AI tools and stitching them together into visual stories. Here I took the first few sentences of Pride and Prejudice and made it into a video.

The gen stack used for this one:
- 
@AnthropicAI
 Claude took the first chapter, generated the scenes and the individual prompts to to the image generator.
- 
@ideogram_ai
 took the prompts and generate the images
- 
@LumaLabsAI
 took the images and animated them
- 
@elevenlabsio
 for narration
- 
@veedstudio
 to stitch it together

(Many of these choices are just what I happened to use for this one while exploring a bunch of things). Anyway honestly it was pretty messy and there is a ton of copy pasting between all of the tools, and even this little video with 3 scenes took me about an hour.

There is a huge storytelling opportunity here for whoever can make this convenient. Who is building the first 100% AI-native movie maker?

### 22

2024-07-04

宝玉
@dotey
一家法国的 AI 实验室 Kyutai，刚刚发布一个对标 GPT-4o 的开源实时语音多模态模型，能够听、说、看，而且从演示看，也可以随时打断，可以模仿法国口音说英语，可以说悄悄话。效果比 GPT-4o 要差一点，但是已经很接近了。

重要的是：

- 他们的模型训练管道和架构非常简单且具有很大的可扩展性，像 Kyutai 这样的只有 8 人的小团队在 4 个月内就能完成。合成数据在这方面起到了巨大的推动作用

- 专注于本地设备：Moshi 可以在本机运行。

- 低延迟：延迟在 300 毫秒以下，同时语言模型质量保持 Llama 8B 或更，可以在你提问尚未结束时模型就能回答，或者在你打断模型讲话时它能做出反应。模型中进行预测编码，并即时更新你要说的话

他们的论文和模型权重将很快发布。可以预见未来像 GPT-4o 这样的实时语音技术将会普及。

他们的官网：https://kyutai.org



### 23

2024-07-04

歸藏(guizang.ai)
@op7418
快手又整了个大活！

开源了面部表情迁移到图片生成视频的技术，控制的非常好。

感觉对 AI 视频生成中人物表演和数字人非常有帮助。

支持各种风格的图片，同时可以对面部运动幅度进行微调，也支持常见的动物面部迁移。



### 24

2024-07-04


meng shao
@shao__meng
BeyondPDF  
@omkizzy
 

BeyondPDF 是一个智能、免费、完全私有本地化的基于 MacOS 的 PDF AI 预览和检索应用。

作者将一个轻量级的 Embedding 模型从 
@huggingface
 获取转换为 CoreML，并完全不使用第三方库 (vectordb + tokenizer 都是直接使用原始代码)，安装包本身只有 42MB，包括机器学习模型，所以它很轻量，占用空间合理。

用 MacOS 的朋友们可以体验看看。

下载地址：
https://omkaark.github.io/BeyondPDFInfo/



### 25

2024-07-04

小互
@imxiaohu
2024上半年《人工智能现状报告》

Retool 刚刚发布了最新2024上半年《人工智能现状报告》

收集了约750名技术人员的意见，包括开发者、数据团队和各行业的领导者，了解如何利用人工智能产生真正的影响。

主要发现：

Al情绪变化

• 在2023年的报告中，大多数受访者对AI持谨慎态度，认为其略微被高估。2024年，这种情绪并没有显著变化，各个角色的平均评分仍在5分左右（“合理评价"到”略高估"）。

• 受访者认为，虽然AI有巨大的潜力，但目前仍处于相对不成熟阶段，很多应用没有真正发挥其价值。

AI应用现状

• 大部分受访者表示，他们的公司还未达到AI应用的最高水平。仅有约30%的受访者认为他们的公司在AI应用方面处于“运行”或"飞行”阶段。

• 在不同的行业中，咨询（46%）、房地产（46%）和消费品（37%）领域的AI应用程度最高。

。非营利组织和材料行业的受访者表示，他们在AI应用方面落后。

投资和生产力

• 绝大多数受访者每周至少使用一次AI工具，56.4%的人几乎每天使用。小公司（1-9名员工）和较大公司（1000-4999名员工）的每日使用率分别为72%和43%。

。在不同角色中，产品和工程部门的日常使用率最高，分别为68%和62.6%，设计部门最低，为39%。

• 经常使用AI工具的受访者报告生产力显著提高，64.4%的日常用户报告生产力显著提高，而每周用户和偶尔用户的比例分别为17%和6.6%。



### 26

2024-07-04

宝玉
@dotey
非常值得一看的视频，OpenAI 联合创始人 Andrej Karpathy 在2024年加州大学伯克利分校人工智能黑客马拉松颁奖典礼上的主题演讲。

OpenAI 联合创始人 Andrej Karpathy 解释了新的计算范式：

“我们正在进入一个新的计算范式，大语言模型就像CPU一样，使用Token而不是字节，并且有一个上下文窗口而不是RAM。

这就是大语言模型操作系统（Large Language Model OS, LMOS）。”

Andrej在演讲中分享了他对黑客马拉松的热情，强调这种活动带来的巨大能量和创造力，尤其是年轻人们在其中展现出的创新精神。他指出，人工智能领域在过去15年中经历了巨大的发展，从最初的学术研讨到现在的广泛应用，这种变化令人瞩目。尤其是大语言模型的兴起，彻底改变了计算的范式，使得计算不仅仅是处理字节，而是处理语言和上下文，这为人工智能的应用打开了新的大门。

他回顾了自己在OpenAI的经历，描述了公司从八个人在公寓里工作到如今成为市值近千亿美元的行业巨头的历程。通过一个个小项目的积累和发展，OpenAI最终实现了巨大的突破。Andrej特别强调了项目经验的重要性，指出很多看似不起眼的小项目最终可能会带来意想不到的巨大影响。

他还提到“一万小时”定律，强调成功源于反复的实践和大量的付出，只有通过持续不断地努力和项目驱动学习，才能在某个领域内获得真正的专业技能。他鼓励大家多做项目，通过项目来推动自己的学习和进步，并通过分享和发布项目来获取成就感和动力。

最后，Andrej展望了未来人工智能和技术的发展，指出我们正处在一个独特的时代，人工智能将进一步融入我们的生活，带来更多的可能性和挑战。他希望大家能够从小项目开始，不断积累经验，最终对世界产生积极的影响，共同塑造一个美好的未来。

完整文稿：https://baoyu.io/translations/transcript/openai-cofounder-andrej-karpathy-2024-uc-berkeley-ai-hackathon-speech




### 27

2024-07-04

Vince He
@iarrp
长上下文和 RAG 讨论时不需要总是对立，可以先通过 RAG 缩小检索范围，再结合长上下文模型。 技术上通过 parent-child 索引，小块匹配+大块召回。一方面可以利用 RAG 的检索优势，一方面利用上模型的总结和分析能力。
引用
Philipp Schmid
@_philschmid
·
7月3日
How good are LLMs in a long context, and do we need RAG? 🤔 Summary of a Haystack (SummHay) tries to solve the limitations of “Needle in a Haystack” by focusing on challenging information extraction. @GoogleDeepMind Gemini 1.5 pro performs the best 



### 28

2024-07-05


歸藏(guizang.ai)
@op7418
确实好用，不过页数太多的话会报错，可以把长PDF切分一下再用。

刚好把刚才的《理解深度学习》转成Markdown格式扔给Claude翻译了一下。

---

Gorden Sun
@Gorden_Sun
Doc2X：超强且免费的PDF解析工具
可以识别数学公式、表格、图片，公式的识别效果尤其优秀，图表的排版也很智能。
解析后支持导出为Markdown、LaTeX、Word文档、网页等格式。
每天有500页的免费额度。
使用地址：https://doc2x.noedgeai.com
下方图片是我解析阿里数学竞赛预赛题的效果。

### 29

2024-07-05

宝玉
@dotey
钢琴家朗朗也用 AI 辅助音乐创作  

朗朗说：与 AI 合作为我们打开了全新的可能。AI 可以为我们提供新的想法， 帮助音乐家们尝试不同的声音和音乐风格。 AI 将不再仅仅是一个工具， 它将变成创意过程中的合作伙伴， 就像是一名创作副驾驶。所以，未来的音乐创作，结合 AI， 前景非常看好。




### 30

2024-07-05

歸藏(guizang.ai)
@op7418
麻省理工这本《深入理解深度学习》的免费书可太好了。

深入讲解了深度学习的大部分概念。

而且每个章节都有搭配的PPT可以下载，还有对应练习的Python代码。

内容包括监督学习、神经网络、损失函数、正则化、卷积网络、Transformers、扩散模型、强化学习等。

---

这里下载PDF和课件：https://udlbook.github.io/udlbook/

之前下载过原书电子版「2023059Understanding-Deep-Learning5Ed」。（2024-07-07）

[Understanding Deep Learning](https://udlbook.github.io/udlbook/)

### 31

2024-07-06


歸藏(guizang.ai)
@op7418
快手再放大招！

可灵真成世界第一视频生成模型了。

发布一系列重磅更新：

基础模型升级，生成更高分辨率的视频
增加首尾帧控制
增加运镜控制，还有自动大师运镜
Web 端上线，限时免费

新模型的运动幅度和清晰度完全可以跟Gen3对标，同时美学表现也获得了提升。

控制方式更是吊打现有DiT模型。

---

歸藏(guizang.ai)
@op7418
快手今天还开源了自己的图像生成模型可图 Kolors。

可图在数十亿个文本图像对上训练
Kolors使用通用语言模型(GLM)作为文本编码器
中英文双语提示词支持
支持256个token的上下文长度

---

小互
@imxiaohu
「可灵视频模型」Web端平台及全新功能上线！

🔗立即体验Web端：http://klingai.kuaishou.com

文生视频：画质升级、单次10s视频生成

图生视频：画质提升、支持自定义首尾帧

运镜控制：提供丰富的镜头控制选项，预设多种大师级镜头模式

注：为了更好的视频操作体验，本次仅在Web端提供「自定义首尾帧」及「运镜控制」功能。

⚠️在限免期间，「高表现」生成模式每账号每日最多使用3次，「高性能」模式生成次数不限

### 32

2024-07-06

宝玉
@dotey
我今天翻译这字幕的时候，先用的 GPT-4o，中规中矩，后来试了下 Claude 3.5 Sonnet，要好很多。

GPT 4o 翻译结果：

我最近一直在思考过渡期的问题。 精神领袖Ram Dass有一个关于两波浪潮在海洋中前行的精彩故事，一大一小。当波浪接近陆地时，大浪看到了即将发生的事情。 它看到所有前面的波浪都在冲向岸边并被摧毁，于是忧心忡忡地对小浪说：“末日要来了！” 但小浪只是微笑着说：“别担心，我们会没事的。” 大浪坚持道：“你不明白，我们完了。”而小浪则完全平静地说：“不，我们没事。” “我可以用六个字来解释。你不是浪，你是水。”

Claude 3.5 Sonnet 翻译结果：

最近，我一直在思考人生的转变。这让我想起心灵导师拉姆·达斯曾经讲过一个发人深省的故事。故事是这样的：
海洋中有两朵浪花，一大一小，正朝着岸边涌去。眼看离岸越来越近，大浪忽然意识到了即将发生的事。它看到前方的浪花一个接一个拍打在岸边，瞬间消失不见。
大浪顿时慌了神，对小浪喊道："完了完了，我们就要到头了！"
小浪却笑眯眯地说："别担心，我们不会有事的。"
大浪急了："你不明白啊！我们马上就要消失了！"
小浪依然淡定自若，说道："不会的。我用六个字就能告诉你为什么。"
"什么意思？"大浪疑惑地问。
小浪答道："你本非浪，乃是水。"

原始英文：

I've been thinking a lot lately about transitions. The spiritual leader, Ram Dass, had a wonderful teaching about two wavestraveling through the ocean, one big and one small, and as the waves get closer to the land, the big wave sees what's about to happen. They see all the waves ahead of themare just crashing onto the shoreand devastated the big wave says to the small wave, he warns them the end is near. And the small wave just smiles and says, don't worry, we'll be fine. You don't understand the big wave insists, we're done for, and the smaller wave is just totally calmand says, no, we're not. And I can explain why in just six words.   You're not a wave, you're water.



### 33

2024-07-06

宝玉
@dotey
\#AI开源项目推荐 subtitler

不需要上传视频到服务器，直接在浏览器端就可以语音转录成文本字幕，以及对转录的字幕编辑，生成带字幕视频的开源网站。语音转字幕利用的是 WebGPU，在浏览器端执行 Transformer + Whisper 模型（目前只能支持 tiny 和 base 模型）。视频生成是基于一个库叫 MP4Box.js，借助 Web Worker，后台重新渲染视频，再借助一个FileSystemWritableFileStreamTarget的API，流式写入本地文件。

完全不需要下载任何客户端，只需要下载模型文件到浏览器缓存，缺点是目前模型无法太大，像 Whisper Large 模型几个 G 就不行了，所以实际使用时，只能转录标准的英文视频，其他语种恐怕支持不太好，至少中文效果不行。

纯浏览器端能做这么多事已经很厉害了，未来可期！

项目地址：https://github.com/dmtrKovalenko/subtitler

在线试用地址：https://subtitles.fframes.studio



### 34

2024-07-06

宝玉
@dotey
前几天梅琳达·盖茨在斯坦福毕业典礼上的演讲，挺不错的。

她用了一个充满哲理的故事贯穿其中：

海洋中有两朵浪花，一大一小，正朝着岸边涌去。眼看离岸越来越近，大浪忽然意识到了即将发生的事。它看到前方的浪花一个接一个拍打在岸边，瞬间消失不见。

大浪顿时慌了神，对小浪喊道："完了完了，我们就要到头了！"

小浪却笑眯眯地说："别担心，我们不会有事的。"

大浪急了："你不明白啊！我们马上就要消失了！"

小浪依然淡定自若，说道："不会的。我用六个字就能告诉你为什么。"

"什么意思？"大浪疑惑地问。

小浪答道："汝非浪乃水也。"

这个故事形象地描绘了如何在经历巨大的转变时，依旧保持自我本心。

她给斯坦福的毕业生们给了三条人生建议：

1. 以全然开放的心态面对人生的重要转变

当我们从学校毕业，难免会被各种标签束缚自己，名校毕业会觉得应该去改变世界，普通人会觉得这些离自己太远，其实我们不过就像故事里的大浪、小浪，都不过是水罢了。

2. 找到你的“小浪”

在那个关于浪花的故事里，小浪才是英雄，因为它帮助大浪用另一种方式看待事物。实际上，那个小浪并不小。它有着独到的见解，有一种大浪自己所没有的洞察。毕业生们，无论你是谁，无论你处于人生的哪个阶段，拥有“小浪”是极其宝贵的。在你人生的不同时期，不同的人会扮演这个角色。

3. 建立一个值得信任的关系网

生命中，有幸能遇到“小浪”那样的贵人，睿智、看透生活的本质，适当的时候给我们建议，同样我们自己也可以当“小浪”那样的人，给别人建议和帮助。就像梅琳达讲她自己在她的好朋友去世时，帮助她的好朋友 Emmy 度过悲伤，三年前她和比尔盖茨离婚的时候，正是 Emmy 陪在她身边，帮她度过难关。

希望你们能以彻底开放的心态迈向未来，被那些与你同行的更小、更睿智的浪花的智慧和洞察所鼓舞，致力于拓展你们已经开始在周围编织的信任网络。

完整的文稿：https://baoyu.io/blog/life/2024-stanford-commencement-speech-melinda-french-gates



### 35

2024-07-06


宝玉
@dotey
AI 生成视频让那些有创意但是没能力做视频的人有机会一展身手了

这是一个用 Runway Gen-3 生成的用食材制作动物的视频

---


Max
@maxescu
Runway Gen-3 is simply incredible.

One year ago, I was mesmerized by the idea of making images of animals out of food ingredients, and now, a year later, I can have them alive in video form.

Without further ado, I give you Foodies (Gen-3 version):



### 36

2024-07-06


小互
@imxiaohu
浦语灵笔 IXC-2.5：能看懂视频，完整书写文章、自动生成网站的多模态模型

浦语灵笔 IXC-2.5) 是由上海人工智能实验室开发的一个强大的多模态大模型。

使用7B LLM后端，具有与GPT-4V相当的能力

具有超高分辨率图像理解、精细的视频理解和多轮多图像对话能力。

此外，它还扩展了两个引人注目的应用：网页制作和高质量文本-图像文章创作。

可以利用逐步推理的方法生成连贯的长文本内容。创作的文章在逻辑和连贯性上达到高标准。

详细内容：https://xiaohu.ai/p/10891

在线体验：https://huggingface.co/spaces/Willow123/InternLM-XComposer


### 37

2024-07-06

宝玉
@dotey
吴老师推荐的这个网站 https://artificialanalysis.ai 很不错👍🏻

分析了各大模型的输出速度、价格、质量等信息，并用直观的图表列出



### 38

2024-07-02





### 39

2024-07-02





### 40

2024-07-02





### 41

2024-07-02





### 42

2024-07-02





### 43

2024-07-02





### 44

2024-07-02





### 45

2024-07-02





### 46

2024-07-02





### 47

2024-07-02





### 48

2024-07-02





### 49

2024-07-02





### 50

2024-07-02





### 51

2024-07-02





### 52

2024-07-02





### 53

2024-07-02





### 54

2024-07-02





### 55

2024-07-02





### 56

2024-07-02





### 57

2024-07-02





### 58

2024-07-02





### 59

2024-07-02





### 60

2024-07-02





### 61

2024-07-02





### 62

2024-07-02





### 63

2024-07-02





### 64

2024-07-02





### 65

2024-07-02





### 66

2024-07-02





### 67

2024-07-02





### 68

2024-07-02





### 69

2024-07-02





### 70

2024-07-02





### 71

2024-07-02





### 72

2024-07-02





### 73

2024-07-02





### 74

2024-07-02





### 75

2024-07-02





### 76

2024-07-02





### 77

2024-07-02





### 78

2024-07-02





### 79

2024-07-02





### 80

2024-07-02





### 81

2024-07-02





### 82

2024-07-02





### 83

2024-07-02





### 84

2024-07-02





### 85

2024-07-02





### 86

2024-07-02





### 87

2024-07-02





### 88

2024-07-02





### 89

2024-07-02





### 90

2024-07-02





### 91

2024-07-02





### 92

2024-07-02





### 93

2024-07-02





### 94

2024-07-02





### 95

2024-07-02





### 96

2024-07-02





### 97

2024-07-02





### 98

2024-07-02





### 99

2024-07-02





### 100

2024-07-02





### 101

2024-07-02





### 102

2024-07-02





### 103

2024-07-02





### 104

2024-07-02





### 105

2024-07-02





### 106

2024-07-02





### 107

2024-07-02





### 108

2024-07-02





### 109

2024-07-02





### 110

2024-07-02





### 111

2024-07-02





### 112

2024-07-02





### 113

2024-07-02





### 114

2024-07-02





### 115

2024-07-02





### 116

2024-07-02





### 117

2024-07-02





### 118

2024-07-02





### 119

2024-07-02





### 120

2024-07-02





### 121

2024-07-02





### 122

2024-07-02





### 123

2024-07-02





### 124

2024-07-02





### 125

2024-07-02





### 126

2024-07-02





### 127

2024-07-02





### 128

2024-07-02





### 129

2024-07-02





### 130

2024-07-02





### 131

2024-07-02





### 132

2024-07-02





### 133

2024-07-02





### 134

2024-07-02





### 135

2024-07-02





### 136

2024-07-02





### 137

2024-07-02





### 138

2024-07-02





### 139

2024-07-02





### 140

2024-07-02





### 141

2024-07-02





### 142

2024-07-02





### 143

2024-07-02





### 144

2024-07-02





### 145

2024-07-02





### 146

2024-07-02





### 147

2024-07-02





### 148

2024-07-02





### 149

2024-07-02





### 150

2024-07-02





### 151

2024-07-02





### 152

2024-07-02





### 153

2024-07-02





### 154

2024-07-02





### 155

2024-07-02





### 156

2024-07-02





### 157

2024-07-02





### 158

2024-07-02





### 159

2024-07-02





### 160

2024-07-02





### 161

2024-07-02





### 162

2024-07-02





### 163

2024-07-02





### 164

2024-07-02





### 165

2024-07-02





### 166

2024-07-02





### 167

2024-07-02





### 168

2024-07-02





### 169

2024-07-02





### 170

2024-07-02





### 171

2024-07-02





### 172

2024-07-02





### 173

2024-07-02





### 174

2024-07-02





### 175

2024-07-02





### 176

2024-07-02





### 177

2024-07-02





### 178

2024-07-02





### 179

2024-07-02





### 180

2024-07-02





### 181

2024-07-02





### 182

2024-07-02





### 183

2024-07-02





### 184

2024-07-02





### 185

2024-07-02





### 186

2024-07-02





### 187

2024-07-02





### 188

2024-07-02





### 189

2024-07-02





### 190

2024-07-02





### 191

2024-07-02





### 192

2024-07-02





### 193

2024-07-02





### 194

2024-07-02





### 195

2024-07-02





### 196

2024-07-02





### 197

2024-07-02





### 198

2024-07-02





### 199

2024-07-02





### 200

2024-07-02





### 201

2024-07-02





### 202

2024-07-02





### 203

2024-07-02





### 204

2024-07-02





### 205

2024-07-02





### 206

2024-07-02





### 207

2024-07-02





### 208

2024-07-02





### 209

2024-07-02





### 210

2024-07-02





### 211

2024-07-02





### 212

2024-07-02





### 213

2024-07-02





### 214

2024-07-02





### 215

2024-07-02





### 216

2024-07-02





### 217

2024-07-02





### 218

2024-07-02





### 219

2024-07-02





### 220

2024-07-02





