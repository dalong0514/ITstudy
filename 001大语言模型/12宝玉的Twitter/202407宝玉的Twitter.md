### 01

2024-07-02

宝玉
@dotey
腾讯的多智能体翻译工具已经可以免费在线试用了，而且是使用的 GPT-4 的 API，你可以上传txt或者pdf文件，然后会自动帮你翻译，并且整个过程都可以从右边的 Chatbox 看到。

注意上传后要手动选一下目标语言。使用地址见原推。

Longyue Wang
@wangly0229
🚀 Exciting News! 🚀

✨TransAgents, the cutting-edge virtual multi-agent translation company powered by advanced LLMs, is now live! 🌍

Experience our demo system at http://transagents.ai and kickstart your own AI venture with LLMs today. For a limited time, we're offering free credits for trial!


[app](https://transagents.ai/)

Chinese

English

### 02

2024-07-02

歸藏(guizang.ai)
@op7418
七年前最先进的图像技术也只能生成这些 32x32 的小图。谁能想到今天会有 Gen-3 这种视模型呢。

可能再过七年 Gen 3 看起来也会傻傻的。
引用
Andrej Karpathy
@karpathy
·
7月2日
I feel like I have to once again pull out this figure. These 32x32 texture patches were state of the art image generation in 2017 (7 years ago). What does it look like for Gen-3 and friends to look similarly silly 7 years from now.  x.com/runwayml/statu…



### 03

2024-07-02



小互
@imxiaohu
Runway Gen-3 Alpha 文本到视频模型已开放

所有人都可以使用了…

### 04

2024-07-02

宝玉
@dotey
\#开源项目推荐: mupdf.js

对Python熟悉的同学都知道PyMuPDF，是一个功能强大的PDF解析操作库，其实这个库也有JS版，而且是官方出的，可以用在浏览器上（基于WebAssembly和Worker）和 Nodejs 上，性能很不错。

比如截图中这个PDF渲染的例子，并不是用的浏览器自带的PDF预览，而是用mupdf.js解析，然后再用canvas和html元素渲染出来的。

另外 mupdf 除了Python和JS版，还有 .Net 和 Java 版。

演示地址：https://mupdf.com/wasm/demo/
项目地址：https://github.com/ArtifexSoftware/mupdf.js
官网地址：https://mupdf.com



### 05

2024-07-02


歸藏(guizang.ai)
@op7418
Langchain 出的 RAG 教程。

教学内容包括：查询转换、假设文档嵌入（HyDE）、路由机制、查询构建、索引策略、不同的检索技术，以及生成阶段的细节。

最终，通过将所学知识应用于 Neo4J 的实际场景。

---

LangChain
@LangChainAI
Learn RAG with Langchain 🦜⛓️‍💥

This is a *great* guide to all things RAG!

Covers query transformation, HYDE, routing, query construction, indexing, retrieval, generation, and of course....

GraphRAG with Neo4j!

https://sakunaharinda.xyz/ragatouille-book/intro.html


### 06

2024-07-02

小互
@imxiaohu
未来计算机构想： 一种端到端的神经网络计算机

Andrej Karpathy 提出了一个概念：一种完全由神经网络驱动，不再依赖任何传统的软件代码的计算机。

设备的输入（如音频、视频、触摸等，也可以是自然语言输入）直接传递给神经网络，输出则直接显示为结果，可能是音频/视频，也可能是交互界面在屏幕上。

这种简化的架构意味着整个计算过程完全依赖于神经网络的处理能力。

我感觉这个构想是可以实现的，上周参加豆包的MarsCode编程助手发布会讨论的时候，就讨论过这个想法。

就是现在其实已经基本具备了这种雏形，目前的AI能力已经可以通过自然语言文本生成音频、视频、交互界面等可以直接展示的结果，无需在进行复杂的编码了。

这种有点更像人类大脑的运作方式，能够从数据中学习和适应，然后自动产生具体的声音、画面和解决方案。

通过直接进行神经网络产出你想要的结果，将彻底改变计算机的工作方式：  

1、无需编程：计算机不再需要将指令编写代码再进行运行，神经网络可以根据用户的需求和指令，直接生成程序甚至结果。

 2、高效执行：直接从想法到结果的端到端神经网络方案，使得计算效率更高、运行速度更快。 

3、自我进化：计算机可以持续学习和自我更新，不断的适应和响应环境变化和用户的各种需求。

4、云端运行：无需在制造各种硬件设备，只需一块屏幕或者虚拟显示，即可在云端持续运行，随时响应。

但是这也意味着将耗费惊人的算力和能源...



### 07

2024-07-02

歸藏(guizang.ai)
@op7418
Mann-E Dreams 一个新的 XL 模型，生成的图片质量非常高。

使用 MJ 的图像训练，生成速度也很快，只需要 8 步。

CFG 值建议 2-4，分辨率 768x768 和 832x832 都行，采样器推荐 DPM++ SDE Karras。




### 08

2024-07-02

宝玉
@dotey
微博推出了 AI 小助手，可以代替博主回复评论，但有时候也会自作主张帮博主做出一些承诺，比如图二中那样，有人问博主去不去参加深中通道试运营典礼，结果 AI 小助手给人家回复：“那咱们明天见，路上小心驾驶哦💪”，搞得人信以为真，结果等不到博主！

Meta 也在测试类似功能，所以小札也被问到类似问题，如果 AI 分身被问到一些“观点”类的问题，该怎么处理？既要有用，又不能乱说话闯祸。

小札说这是“艺术”，确实是艺术，但怎么才能科学的解决这个问题呢？



### 09

2024-07-02



歸藏(guizang.ai)
@op7418
看来 Llama3 400B 已经训练完成。

Whatsapp 上出现了 Llama3 405B 的选项。


### 10

2024-07-02


小互
@imxiaohu
炸裂了 兄弟们 😑

使用Runway Gen 3 制作的3D巨幅字幕

类似电影片头那种高大上的效果

提示词：

Prompt："Blizaine "这个单词以大型 3D 字母出现在夜晚的城市街道上，字母上播放着各种超级英雄电影场景的纹理，让人联想到 MARVEL MCU 的前奏。镜头运动从极度特写开始，拉近到很远的距离，因此只能看到单词的一小部分，然后缓慢倾斜摇镜头并旋转，露出整个单词和上面的电影场景。电影感十足"。

Prompt: “The word "Blizaine" in large 3D letters on a city street at night with various superhero movie scenes playing on the letters as textures, reminiscent MARVEL MCU intro. Camera Movement starts with an extreme closeup, zoomed very far in so only small section of the word can be seen, then slow angled dolly-out and rotate, revealing the entire word with movie scenes on them. Cinematic.”

---

小互
@imxiaohu
Runway Gen-3 Alpha 详细使用教程

以及提示词指南大全，包括摄像机风格、灯光效果、运动状态类型以及风格美学、文本风格等。

详细内容：https://xiaohu.ai/p/10762

### 11

2024-07-02


小互
@imxiaohu
全球首款集成GPT-4o 的智能眼镜发布 

支持视觉能力和语音提示

可以根据用户所看到的内容和识别到的人或物体提供实时回答。

---

小互
@imxiaohu
该眼镜采用模块化设计，可更换不同样式的传统框架。

此外，它还具备 LED 通知灯，并将整合 Google Gemini 和 Anthropic 的 Claude AI 模型。 

 Solos AirGo 3 音频眼镜不含相机，售价为 249 美元。

详细功能及技术细节介绍：https://xiaohu.ai/p/10683



### 12

2024-07-02



歸藏(guizang.ai)
@op7418
他们的提示词重写逻辑很有意思，能够根据不同的输入和配置生成最优的提示词，且能自动调整以满足模型的令牌数限制。

它灵活地接受不同类型的实体输入（字符串或列表），处理多个示例和文档，并根据模型的最大Token限制计算剩余的Token数，从而确保生成的提示词在Token限制范围内。

---

歸藏(guizang.ai)
@op7418
微软昨晚重磅开源了强大无比的 RAG 方案——GraphRAG。

在社区摘要应用中，GraphRAG 在全面性和多样性上以 70-80% 的胜率大幅领先于传统 RAG。

GraphRAG 是一种基于图的 RAG 工具，通过 LLM 从文档集合中自动提取丰富的知识图谱，助力处理私有或未知数据集的问答。

---


歸藏(guizang.ai)
@op7418
项目页面：

microsoft/graphrag

A modular graph-based Retrieval-Augmented Generation (RAG) system


### 13

2024-07-03

宝玉
@dotey
Fish Speech 这个是效果真的不错，生成速度很快，克隆出来的声音也很逼真

测试地址：
https://fish.audio/zh-CN/text-to-speech/



### 14

2024-07-03

宝玉
@dotey
\#开源项目推荐：React-Tweet

这是 Vercel 出的一个可以在你的 React 项目中，在网页内嵌入一条推文。不止是可以用在 React 项目，它也提供了 API 可以帮你根据 ID 抓取推文内容、评论数、图片等信息。并且是完全免费的，不需要申请开发者账号，也不需要给 X 交钱。

但是它获取时只能获取140内的文本内容，超过140的长文无法完整获取，因为也不能获取 Thread 或者回复。

原理不复杂，用的一个隐藏的 API http://cdn.syndication.twimg.com/tweet-result，传入 id、lang 和 Token 等三个基本参数就可以。其中算 Token 的算法很简单，验证也不严谨。

项目地址：https://github.com/vercel/react-tweet



### 15

2024-07-03

歸藏(guizang.ai)
@op7418
Gorq 现在已经支持 Whisper v3 的语言转文字推理，速度巨快。

感觉可以大力出奇迹搞一个 GPT 实时语音出来。



### 16

2024-07-03



小互
@imxiaohu
Meta AI发布一看端到端生成高质量的 3D 资产生成模型 

不到一分钟时间即可根据文本生成高质量3D模型

生成的结果优于现有解决方案，速度是该领域现有工作的 3-10 倍。



### 17

2024-07-03

小互
@imxiaohu
Suno 推出了 iOS 客户端

可以在手机上收听和创建音乐了。 

支持通过文字和语音（例如哼唱）来创建音乐，整理和管理创作的音乐作品。

还可以根据分类查找收听别人创作的音乐，有点像音乐APP了...

下载：http://suno.com/ios （目前只支持美区）



### 18

2024-07-03


宝玉
@dotey
转译：《如何使用ChatGPT撰写科学研究论文？- Dr Asma Jabeen》

ChatGPT是一种AI语言模型，可以根据用户提供的输入生成文本。它可以作为一种工具，帮助撰写科学研究论文。撰写科学研究论文不仅需要对主题的深入了解，还需要批判性思维、解决问题的能力、分析和数据解释技能。因此，使用ChatGPT时，应将其与您的专业知识、经验和技能相结合。

本文将讨论使用ChatGPT撰写科学研究论文的9个重要步骤。

1. 收集研究材

在使用ChatGPT之前，您需要收集和整理撰写科学研究论文所需的所有研究材料，包括文章、书籍、期刊以及其他计划使用的资料。

2. 与ChatGPT进行头脑风暴

使用ChatGPT对研究主题进行不同角度的头脑风暴，并据此编写最终版本。

3. 确定研究问题

确定您在研究论文中要解决的研究问题或假设。

4. 进行文献综述

使用ChatGPT搜索与研究主题相关的科学文献，突出显示并指定与研究问题和假设相关的文献。

5. 总结重要的研究文章

利用ChatGPT总结您标注的研究文章的关键内容。

6. 识别文献中的研究空白

通过ChatGPT进行头脑风暴，找出文献中的研究空白。

7. 分析数据

对通过调查或其他方式收集的数据进行分析，然后使用ChatGPT帮助解释数据并生成支持您发现的可视化图表。

8. 创建研究论文的提纲

使用ChatGPT组织您的研究论文，创建提纲并逻辑地结构化您的论点。使用ChatGPT生成论文的各个部分，如引言、方法、结果和讨论部分，但务必仔细审查其生成的内容。

9. 编辑和校对您的论文

使用ChatGPT编辑和校对论文的语法、标点和拼写错误，但请仔细检查和审阅，以确保内容的流畅、准确、清晰和研究的真实性。

按照上述9个步骤，您可以使用ChatGPT撰写研究论文。

关于使用ChatGPT撰写科学研究论文的4个事实

1. ChatGPT无法独立完成科学研究论文的写作。科学知识、人类专业知识、批判性思维和分析能力对于论文写作至关重要。ChatGPT可以作为一个生成内容的助手。

2. ChatGPT是研究辅助工具，但不能取代人类研究人员。

3. ChatGPT可以协助进行数据分析和解释，但仍需人类输入以确保数据的准确性。

4. ChatGPT生成的内容可能存在错误，因此审查其生成的内容以确保准确性非常重要。
引用
Dr Asma Jabeen
@DrasmaJabeen1
·
7月2日
ChatGPT for research paper writing #AcademicTwitter https://drasmajabeen.com/chatgpt-for-scientific-research-paper-writing/



### 19

2024-07-02

小互
@imxiaohu
Fish Speech：完美支持中英日语言的开源TTS模型 

语音处理接近人类水平

模型使用约十五万小时三语数据训练，对中文支持非常的完美。

---

小互
@imxiaohu
该项目由 fishaudio 开发，作为一个仅有亿级参数的模型，Fish Speech 设计高效轻量，可以在个人设备上轻松运行和微调，成为您的私人语音助手。

详细介绍及更多演示：https://xiaohu.ai/p/10779
GitHub：https://github.com/fishaudio/fish-speech


### 20

2024-07-03

歸藏(guizang.ai)
@op7418
Perplexity  发布升级版的专业搜索，提供更复杂的问题解决能力。

Pro Search 使用更多步骤推理来解决复杂问题。Pro Search 还会分析搜索结果并根据其发现采取智能行动。

Pro Search 的代码执行能力得到了增强。使其在数据分析、调试和内容生成方面更快、更强大。

专业搜索现在可以免费使用。

---

小互
@imxiaohu
Perplexity发布 Pro Search 高级搜索功能

支持多步推理、先进的数学和编程能力

Pro Search可以通过多步推理来处理更复杂的问题。它不仅仅是提供简单的答案，而是能够综合分析搜索结果，并基于其发现采取智能行动。这包括启动后续搜索，逐步构建在之前结果的基础上。

Pro Search通过整合Wolfram|Alpha引|擎，显著提升了其数学和编程计算能力。这使其在数据分析、调试和内容生成方面变得更快更强大。

•复杂数学问题：以空前的准确性和速度解决复杂的数学问题。

• 代码执行：代码执行能力增强，使得数据分析、调试和内容生成更加高效。

### 21

2024-07-04

Andrej Karpathy
@karpathy
I'm playing around with generative AI tools and stitching them together into visual stories. Here I took the first few sentences of Pride and Prejudice and made it into a video.

The gen stack used for this one:
- 
@AnthropicAI
 Claude took the first chapter, generated the scenes and the individual prompts to to the image generator.
- 
@ideogram_ai
 took the prompts and generate the images
- 
@LumaLabsAI
 took the images and animated them
- 
@elevenlabsio
 for narration
- 
@veedstudio
 to stitch it together

(Many of these choices are just what I happened to use for this one while exploring a bunch of things). Anyway honestly it was pretty messy and there is a ton of copy pasting between all of the tools, and even this little video with 3 scenes took me about an hour.

There is a huge storytelling opportunity here for whoever can make this convenient. Who is building the first 100% AI-native movie maker?

### 22

2024-07-04

宝玉
@dotey
一家法国的 AI 实验室 Kyutai，刚刚发布一个对标 GPT-4o 的开源实时语音多模态模型，能够听、说、看，而且从演示看，也可以随时打断，可以模仿法国口音说英语，可以说悄悄话。效果比 GPT-4o 要差一点，但是已经很接近了。

重要的是：

- 他们的模型训练管道和架构非常简单且具有很大的可扩展性，像 Kyutai 这样的只有 8 人的小团队在 4 个月内就能完成。合成数据在这方面起到了巨大的推动作用

- 专注于本地设备：Moshi 可以在本机运行。

- 低延迟：延迟在 300 毫秒以下，同时语言模型质量保持 Llama 8B 或更，可以在你提问尚未结束时模型就能回答，或者在你打断模型讲话时它能做出反应。模型中进行预测编码，并即时更新你要说的话

他们的论文和模型权重将很快发布。可以预见未来像 GPT-4o 这样的实时语音技术将会普及。

他们的官网：https://kyutai.org



### 23

2024-07-04

歸藏(guizang.ai)
@op7418
快手又整了个大活！

开源了面部表情迁移到图片生成视频的技术，控制的非常好。

感觉对 AI 视频生成中人物表演和数字人非常有帮助。

支持各种风格的图片，同时可以对面部运动幅度进行微调，也支持常见的动物面部迁移。



### 24

2024-07-04


meng shao
@shao__meng
BeyondPDF  
@omkizzy
 

BeyondPDF 是一个智能、免费、完全私有本地化的基于 MacOS 的 PDF AI 预览和检索应用。

作者将一个轻量级的 Embedding 模型从 
@huggingface
 获取转换为 CoreML，并完全不使用第三方库 (vectordb + tokenizer 都是直接使用原始代码)，安装包本身只有 42MB，包括机器学习模型，所以它很轻量，占用空间合理。

用 MacOS 的朋友们可以体验看看。

下载地址：
https://omkaark.github.io/BeyondPDFInfo/



### 25

2024-07-04

小互
@imxiaohu
2024上半年《人工智能现状报告》

Retool 刚刚发布了最新2024上半年《人工智能现状报告》

收集了约750名技术人员的意见，包括开发者、数据团队和各行业的领导者，了解如何利用人工智能产生真正的影响。

主要发现：

Al情绪变化

• 在2023年的报告中，大多数受访者对AI持谨慎态度，认为其略微被高估。2024年，这种情绪并没有显著变化，各个角色的平均评分仍在5分左右（“合理评价"到”略高估"）。

• 受访者认为，虽然AI有巨大的潜力，但目前仍处于相对不成熟阶段，很多应用没有真正发挥其价值。

AI应用现状

• 大部分受访者表示，他们的公司还未达到AI应用的最高水平。仅有约30%的受访者认为他们的公司在AI应用方面处于“运行”或"飞行”阶段。

• 在不同的行业中，咨询（46%）、房地产（46%）和消费品（37%）领域的AI应用程度最高。

。非营利组织和材料行业的受访者表示，他们在AI应用方面落后。

投资和生产力

• 绝大多数受访者每周至少使用一次AI工具，56.4%的人几乎每天使用。小公司（1-9名员工）和较大公司（1000-4999名员工）的每日使用率分别为72%和43%。

。在不同角色中，产品和工程部门的日常使用率最高，分别为68%和62.6%，设计部门最低，为39%。

• 经常使用AI工具的受访者报告生产力显著提高，64.4%的日常用户报告生产力显著提高，而每周用户和偶尔用户的比例分别为17%和6.6%。



### 26

2024-07-04

宝玉
@dotey
非常值得一看的视频，OpenAI 联合创始人 Andrej Karpathy 在2024年加州大学伯克利分校人工智能黑客马拉松颁奖典礼上的主题演讲。

OpenAI 联合创始人 Andrej Karpathy 解释了新的计算范式：

“我们正在进入一个新的计算范式，大语言模型就像CPU一样，使用Token而不是字节，并且有一个上下文窗口而不是RAM。

这就是大语言模型操作系统（Large Language Model OS, LMOS）。”

Andrej在演讲中分享了他对黑客马拉松的热情，强调这种活动带来的巨大能量和创造力，尤其是年轻人们在其中展现出的创新精神。他指出，人工智能领域在过去15年中经历了巨大的发展，从最初的学术研讨到现在的广泛应用，这种变化令人瞩目。尤其是大语言模型的兴起，彻底改变了计算的范式，使得计算不仅仅是处理字节，而是处理语言和上下文，这为人工智能的应用打开了新的大门。

他回顾了自己在OpenAI的经历，描述了公司从八个人在公寓里工作到如今成为市值近千亿美元的行业巨头的历程。通过一个个小项目的积累和发展，OpenAI最终实现了巨大的突破。Andrej特别强调了项目经验的重要性，指出很多看似不起眼的小项目最终可能会带来意想不到的巨大影响。

他还提到“一万小时”定律，强调成功源于反复的实践和大量的付出，只有通过持续不断地努力和项目驱动学习，才能在某个领域内获得真正的专业技能。他鼓励大家多做项目，通过项目来推动自己的学习和进步，并通过分享和发布项目来获取成就感和动力。

最后，Andrej展望了未来人工智能和技术的发展，指出我们正处在一个独特的时代，人工智能将进一步融入我们的生活，带来更多的可能性和挑战。他希望大家能够从小项目开始，不断积累经验，最终对世界产生积极的影响，共同塑造一个美好的未来。

完整文稿：https://baoyu.io/translations/transcript/openai-cofounder-andrej-karpathy-2024-uc-berkeley-ai-hackathon-speech




### 27

2024-07-04

Vince He
@iarrp
长上下文和 RAG 讨论时不需要总是对立，可以先通过 RAG 缩小检索范围，再结合长上下文模型。 技术上通过 parent-child 索引，小块匹配+大块召回。一方面可以利用 RAG 的检索优势，一方面利用上模型的总结和分析能力。
引用
Philipp Schmid
@_philschmid
·
7月3日
How good are LLMs in a long context, and do we need RAG? 🤔 Summary of a Haystack (SummHay) tries to solve the limitations of “Needle in a Haystack” by focusing on challenging information extraction. @GoogleDeepMind Gemini 1.5 pro performs the best 



### 28

2024-07-05


歸藏(guizang.ai)
@op7418
确实好用，不过页数太多的话会报错，可以把长PDF切分一下再用。

刚好把刚才的《理解深度学习》转成Markdown格式扔给Claude翻译了一下。

---

Gorden Sun
@Gorden_Sun
Doc2X：超强且免费的PDF解析工具
可以识别数学公式、表格、图片，公式的识别效果尤其优秀，图表的排版也很智能。
解析后支持导出为Markdown、LaTeX、Word文档、网页等格式。
每天有500页的免费额度。
使用地址：https://doc2x.noedgeai.com
下方图片是我解析阿里数学竞赛预赛题的效果。

### 29

2024-07-05

宝玉
@dotey
钢琴家朗朗也用 AI 辅助音乐创作  

朗朗说：与 AI 合作为我们打开了全新的可能。AI 可以为我们提供新的想法， 帮助音乐家们尝试不同的声音和音乐风格。 AI 将不再仅仅是一个工具， 它将变成创意过程中的合作伙伴， 就像是一名创作副驾驶。所以，未来的音乐创作，结合 AI， 前景非常看好。




### 30

2024-07-05

歸藏(guizang.ai)
@op7418
麻省理工这本《深入理解深度学习》的免费书可太好了。

深入讲解了深度学习的大部分概念。

而且每个章节都有搭配的PPT可以下载，还有对应练习的Python代码。

内容包括监督学习、神经网络、损失函数、正则化、卷积网络、Transformers、扩散模型、强化学习等。

---

这里下载PDF和课件：https://udlbook.github.io/udlbook/

之前下载过原书电子版「2023059Understanding-Deep-Learning5Ed」。（2024-07-07）

[Understanding Deep Learning](https://udlbook.github.io/udlbook/)

### 31

2024-07-06


歸藏(guizang.ai)
@op7418
快手再放大招！

可灵真成世界第一视频生成模型了。

发布一系列重磅更新：

基础模型升级，生成更高分辨率的视频
增加首尾帧控制
增加运镜控制，还有自动大师运镜
Web 端上线，限时免费

新模型的运动幅度和清晰度完全可以跟Gen3对标，同时美学表现也获得了提升。

控制方式更是吊打现有DiT模型。

---

歸藏(guizang.ai)
@op7418
快手今天还开源了自己的图像生成模型可图 Kolors。

可图在数十亿个文本图像对上训练
Kolors使用通用语言模型(GLM)作为文本编码器
中英文双语提示词支持
支持256个token的上下文长度

---

小互
@imxiaohu
「可灵视频模型」Web端平台及全新功能上线！

🔗立即体验Web端：http://klingai.kuaishou.com

文生视频：画质升级、单次10s视频生成

图生视频：画质提升、支持自定义首尾帧

运镜控制：提供丰富的镜头控制选项，预设多种大师级镜头模式

注：为了更好的视频操作体验，本次仅在Web端提供「自定义首尾帧」及「运镜控制」功能。

⚠️在限免期间，「高表现」生成模式每账号每日最多使用3次，「高性能」模式生成次数不限

### 32

2024-07-06

宝玉
@dotey
我今天翻译这字幕的时候，先用的 GPT-4o，中规中矩，后来试了下 Claude 3.5 Sonnet，要好很多。

GPT 4o 翻译结果：

我最近一直在思考过渡期的问题。 精神领袖Ram Dass有一个关于两波浪潮在海洋中前行的精彩故事，一大一小。当波浪接近陆地时，大浪看到了即将发生的事情。 它看到所有前面的波浪都在冲向岸边并被摧毁，于是忧心忡忡地对小浪说：“末日要来了！” 但小浪只是微笑着说：“别担心，我们会没事的。” 大浪坚持道：“你不明白，我们完了。”而小浪则完全平静地说：“不，我们没事。” “我可以用六个字来解释。你不是浪，你是水。”

Claude 3.5 Sonnet 翻译结果：

最近，我一直在思考人生的转变。这让我想起心灵导师拉姆·达斯曾经讲过一个发人深省的故事。故事是这样的：
海洋中有两朵浪花，一大一小，正朝着岸边涌去。眼看离岸越来越近，大浪忽然意识到了即将发生的事。它看到前方的浪花一个接一个拍打在岸边，瞬间消失不见。
大浪顿时慌了神，对小浪喊道："完了完了，我们就要到头了！"
小浪却笑眯眯地说："别担心，我们不会有事的。"
大浪急了："你不明白啊！我们马上就要消失了！"
小浪依然淡定自若，说道："不会的。我用六个字就能告诉你为什么。"
"什么意思？"大浪疑惑地问。
小浪答道："你本非浪，乃是水。"

原始英文：

I've been thinking a lot lately about transitions. The spiritual leader, Ram Dass, had a wonderful teaching about two wavestraveling through the ocean, one big and one small, and as the waves get closer to the land, the big wave sees what's about to happen. They see all the waves ahead of themare just crashing onto the shoreand devastated the big wave says to the small wave, he warns them the end is near. And the small wave just smiles and says, don't worry, we'll be fine. You don't understand the big wave insists, we're done for, and the smaller wave is just totally calmand says, no, we're not. And I can explain why in just six words.   You're not a wave, you're water.



### 33

2024-07-06

宝玉
@dotey
\#AI开源项目推荐 subtitler

不需要上传视频到服务器，直接在浏览器端就可以语音转录成文本字幕，以及对转录的字幕编辑，生成带字幕视频的开源网站。语音转字幕利用的是 WebGPU，在浏览器端执行 Transformer + Whisper 模型（目前只能支持 tiny 和 base 模型）。视频生成是基于一个库叫 MP4Box.js，借助 Web Worker，后台重新渲染视频，再借助一个FileSystemWritableFileStreamTarget的API，流式写入本地文件。

完全不需要下载任何客户端，只需要下载模型文件到浏览器缓存，缺点是目前模型无法太大，像 Whisper Large 模型几个 G 就不行了，所以实际使用时，只能转录标准的英文视频，其他语种恐怕支持不太好，至少中文效果不行。

纯浏览器端能做这么多事已经很厉害了，未来可期！

项目地址：https://github.com/dmtrKovalenko/subtitler

在线试用地址：https://subtitles.fframes.studio



### 34

2024-07-06

宝玉
@dotey
前几天梅琳达·盖茨在斯坦福毕业典礼上的演讲，挺不错的。

她用了一个充满哲理的故事贯穿其中：

海洋中有两朵浪花，一大一小，正朝着岸边涌去。眼看离岸越来越近，大浪忽然意识到了即将发生的事。它看到前方的浪花一个接一个拍打在岸边，瞬间消失不见。

大浪顿时慌了神，对小浪喊道："完了完了，我们就要到头了！"

小浪却笑眯眯地说："别担心，我们不会有事的。"

大浪急了："你不明白啊！我们马上就要消失了！"

小浪依然淡定自若，说道："不会的。我用六个字就能告诉你为什么。"

"什么意思？"大浪疑惑地问。

小浪答道："汝非浪乃水也。"

这个故事形象地描绘了如何在经历巨大的转变时，依旧保持自我本心。

她给斯坦福的毕业生们给了三条人生建议：

1. 以全然开放的心态面对人生的重要转变

当我们从学校毕业，难免会被各种标签束缚自己，名校毕业会觉得应该去改变世界，普通人会觉得这些离自己太远，其实我们不过就像故事里的大浪、小浪，都不过是水罢了。

2. 找到你的“小浪”

在那个关于浪花的故事里，小浪才是英雄，因为它帮助大浪用另一种方式看待事物。实际上，那个小浪并不小。它有着独到的见解，有一种大浪自己所没有的洞察。毕业生们，无论你是谁，无论你处于人生的哪个阶段，拥有“小浪”是极其宝贵的。在你人生的不同时期，不同的人会扮演这个角色。

3. 建立一个值得信任的关系网

生命中，有幸能遇到“小浪”那样的贵人，睿智、看透生活的本质，适当的时候给我们建议，同样我们自己也可以当“小浪”那样的人，给别人建议和帮助。就像梅琳达讲她自己在她的好朋友去世时，帮助她的好朋友 Emmy 度过悲伤，三年前她和比尔盖茨离婚的时候，正是 Emmy 陪在她身边，帮她度过难关。

希望你们能以彻底开放的心态迈向未来，被那些与你同行的更小、更睿智的浪花的智慧和洞察所鼓舞，致力于拓展你们已经开始在周围编织的信任网络。

完整的文稿：https://baoyu.io/blog/life/2024-stanford-commencement-speech-melinda-french-gates



### 35

2024-07-06


宝玉
@dotey
AI 生成视频让那些有创意但是没能力做视频的人有机会一展身手了

这是一个用 Runway Gen-3 生成的用食材制作动物的视频

---


Max
@maxescu
Runway Gen-3 is simply incredible.

One year ago, I was mesmerized by the idea of making images of animals out of food ingredients, and now, a year later, I can have them alive in video form.

Without further ado, I give you Foodies (Gen-3 version):



### 36

2024-07-06


小互
@imxiaohu
浦语灵笔 IXC-2.5：能看懂视频，完整书写文章、自动生成网站的多模态模型

浦语灵笔 IXC-2.5) 是由上海人工智能实验室开发的一个强大的多模态大模型。

使用7B LLM后端，具有与GPT-4V相当的能力

具有超高分辨率图像理解、精细的视频理解和多轮多图像对话能力。

此外，它还扩展了两个引人注目的应用：网页制作和高质量文本-图像文章创作。

可以利用逐步推理的方法生成连贯的长文本内容。创作的文章在逻辑和连贯性上达到高标准。

详细内容：https://xiaohu.ai/p/10891

在线体验：https://huggingface.co/spaces/Willow123/InternLM-XComposer

### 37

2024-07-06

宝玉
@dotey
吴老师推荐的这个网站 https://artificialanalysis.ai 很不错👍🏻

分析了各大模型的输出速度、价格、质量等信息，并用直观的图表列出

### 38

2024-07-06

Datou
@Datou
快手开源了一个懂中国元素会写中文的绘画模型kolors
https://github.com/kwai-kolors/Kolors



### 39

2024-07-06


宝玉
@dotey
你需要的不是智能体，而是一个适合 AI 的工作流

现在 AI 智能体（AI Agent）的概念很火，似乎智能体是用 AI 解决问题的银弹，有了智能体就可以解决很多问题。但也有很多人有不同意见，认为智能体不过是噱头，并没有看到靠谱的应用场景。

一个被提及很多的是吴恩达老师写的多智能体翻译的例子，简单来说就是用三个智能体：一个直译智能体、一个审查智能体、一个意译润色智能体，确实可以大幅提升翻译质量。但并非一定要三个智能体才能提升翻译质量，我以前也提出过基于 Prompt 的翻译方法，让 LLM 在翻译时，使用直译 + 反思 + 意译三个步骤输出，也可以得到高质量的翻译结果。

本质上，使用大语言模型（LLM）来解决问题，思维链（COT, Chain of Thought）是一种有效提升生成质量的方法，也就是说，之所以翻译质量能提升，不是因为有了智能体，而是因为有了思维链。至于思维链的每个环节是用一个独立的智能体，还是输出的一个步骤，并没有太本质的差别。（参考文章：[什么时候该用多智能体是不是一定要用多智能体？](https://baoyu.io/blog/ai/when-to-use-multi-agent-systems-or-cot)）

其实大部分 AI 应用场景都类似：要用 AI 解决问题，核心不在于智能体，而在于设计出一个适合 AI 的工作流。

那么怎么才能设计一个适合 AI 的工作流呢？我认为有几个因素需要考虑：

一、不要将 AI 的解决方案局限在人类现有的解决方案上

有时候我们过于将 AI 拟人化，会不自觉的用人类解决问题的方式来套用在 AI 上，有时候确实有效，但很多时候并不一定是最优解。就像专业的翻译员，他们并不需要直译反思意译三个步骤，他们可以一步到位，直接输出高质量的翻译结果，所以最开始让 AI 翻译，Prompt 都是直接一步输出翻译结果，而不是分步骤输出，结果翻译出来的比较生硬。而当我们发现思维链是大语言模型的一种有效提升方法后，就可以设计出更适合 AI 的工作流，分成几步来解决问题。

包括我看到一些智能体项目，尝试模拟人类软件开发的分工，使用项目经理、产品经理、架构师、程序员、测试等等智能体角色去尝试解决复杂的软件项目，同样也是一个过于拟人化而不一定适合 AI 解决问题的思路，所以也只能出现在论文中，而无法在实际项目中落地。相反像 GitHub Copilot 这样辅助生成代码的工具倒是真正适合当前 AI 编程的工作流，能实实在在提升开发效率。

二、不必完全依赖 AI 做决策，而是让 AI 辅助做决策或者做简单的决策

去年有一个超级火爆的项目叫 AutoGPT，就是你输入一个任务，GPT-4 会将任务分解，制定计划，调用外部工具，比如 Google 搜索，甚至执行代码，最终完成任务。这也算是 AI 智能体的先驱项目之一，但现在已经很少有人提及了，因为以现在 AI 的智能程度，还不足以对开放性的任务做出靠谱的决策，最终除了帮 OpenAI 卖了大量的 Token 外，并没有解决什么实际问题。所以现在 AI 应用的主流是把 AI 当“副驾驶（Copilot）”，只是让 AI 辅助人类完成任务，主要还是人在做决策。

另外就是自己设计工作流，让 AI 在工作流中完成一部分工作，并不过于依赖 AI 做决策，或者只需要做简单的决策。比如说商家借助 AI 处理差评的工作流：
1. 程序抓取评论信息
2. AI 分析每一条评论的情感，筛选出差评
3. AI 生成回复（可能需要人工审核）

这是一个典型的设计好流程的适合 AI 的工作流，AI 只需要做简单的情感分析和回复生成，而不需要做复杂的决策，这样的工作流可以很好的提升效率，并且结果也相对靠谱。

三、结合不同领域的 AI 模型或者工具，设计合适的工作流

去年起 AI 大热，一个很重要的原因是大语言模型的出现，这些模型一方面确实能力强大，有一定的通用性，有简单的推理能力，另一方面使用也简单，无论是通过聊天机器人，还是通过 API 调用，都能很方便的使用。即使像我这样不是人工智能专业的人，也能很容易的使用这些模型。而在以前，人工智能相对来说是个高门槛的领域，需要筛选数据、需要训练，还需要调参，对于非专业人士来说是很难使用的。

但这也导致一个问题，就是很多解决方案过于依赖大语言模型，而不知道或者不会使用其他领域的 AI 模型，但当你能够根据任务，将不同领域的 AI 模型或者工具结合起来，设计出合适的工作流，就能够得到更好的解决方案。

四、回归问题本质，AI 只是解决问题的工具

上面提的几点都是容易犯的一些错误，之所以容易犯这些错误，恰恰是因为我们有时候过于关注一些流行的概念或技术，而忽略了要解决的根本问题是什么，将 AI 变成了目的而不是手段。如果你有了解马斯克的第一性原理思维，其强调的就是回归事物最基本的条件，把其解构成各种要素进行分析，从而找到实现目标最优路径的方法。

而运用第一性原理通常有三个步骤：
- 第 1 步：定义清楚你要解决的根本问题。
- 第 2 步：拆解问题。
- 第 3 步：从头开始创建解决方案。

而这也个思路也适用于我们去借助 AI 解决问题，设计出适合 AI 的工作流。

举两个设计合适 AI 工作流解决问题的例子

一个例子是 PDF 转 Markdown

做过 PDF 翻译的有经验，要得到好的翻译结果，将 PDF 的内容整理成 Markdown，再让大语言翻译，效果是相当好的。但这个不好做，因为 PDF 是用来打印的格式，并不是结构化的数据，很难直接提取成 Markdown，再加上各种图表、表格等，更是复杂。

最近看到一个项目叫 [PDFGPT](https://github.com/CosmosShadow/gptpdf)，它就做的很巧秒，本质上是基于 GPT-4o 和 PyMuPDF 设计了一个工作流：
1. 用一个 PDF 操作库 PyMuPDF 检测 PDF 中的图片、图表、表格等，提取成图片并保存
2. 每一页 PDF 生成一张图片，将图片、图表、表格等位置用红框标记出来，并附上对应的图片名称
3. 借助 GPT-4o 的视觉能力，解析标注后的图片，生成对应的 Markdown

如果你纯粹依赖大语言模型，恐怕无法完成这样的任务，一方面受限于上下文窗口的长度限制，一次无法处理多页 PDF，另一方面对于图片、图表、表格等内容无法嵌入 Markdown 中。如果结合 PyMuPDF 这样的库和一个简单的工作流，就可以方便的实现 PDF 转 Markdown，生成的结果也挺不错。

另一个例子是漫画的翻译

有很多那种气泡文字的漫画，如果要翻译成其他语言，就需要将气泡文字提取出来，翻译后再放回去。漫画翻译的难点在于：
1. 因为漫画的气泡文字位置不固定，有时候还会有重叠，不好提取；
2. 翻译的时候，如果只是把提取出来的文字按字面翻译，但不知道当前画面的内容，翻译的结果可能会不通顺；
3. 翻译后要对图片进行处理，抹掉原来的文字，将翻译后的文字放回到原来的位置。

如果人工做会怎么做？可能是读懂漫画，翻译，然后用 Photoshop 这个样的工具抹掉原来的文字，再放上翻译后的文字。可以想象这样的工作量还是不小的。

有一个开源项目 [comic-translate](https://github.com/ogkalu2/comic-translate)，就做的很好，它也是设计了一个适合漫画翻译的工作流：
1. 用一个专业模型做气泡检测，找出文字气泡的位置
2. 用 OCR 做气泡内文字的提取
3. 用一个专业模型移除气泡内的文字
4. 借助 GPT-4o 的视觉能力，根据漫画内容，翻译气泡内的文字
5. 用程序将翻译后的文字绘制到原来的气泡位置

如果不考虑翻译质量的话，这几乎是一个全自动的工作流，效率相当高，成本也很低，最贵的部分是 GPT-4o 的 API，一页也才$0.02 左右。就算加上人工审核对翻译结果和图片生成结果的处理，也是能比以前的人工翻译效率高很多。

从上面的例子可以看出，真正要用好 AI，让 AI 发挥最大效能，核心是还是要基于你要解决的问题，重新设计一个适合 AI 的工作流，让 AI 在工作流中完成它最擅长的工作，至于是不是智能体，是不是大语言模型，是不是 AI 帮你决策，都不是最重要的。

本文同步发布于：https://baoyu.io/blog/ai/you-dont-need-agent-but-ai-suitable-workflow



### 40

2024-07-06

ᏞᎪᏦᏒ.标准件厂长
@Lakr233
开源了这个花了整整一天时间撸出来的小项目

起因是隔壁家的软件做的很好看很好用但是不兼容 iBar，经过是在外面咖啡馆太无聊了于是掏出了电脑，结果是下面的地址 ⬇️

https://github.com/Lakr233/NotchDrop

希望各位玩的开心～



### 41

2024-07-06

GanymedeNil
@GanymedeNil
最近微软开源的 #GraphRAG，我也大致看了一下实现思路，即将非结构化文本提取为知识图谱，然后进一步在图上执行community-clustering，然后对Community进行 Summarization，最后将Community进行 Embedding。默认项目基本都是使用了GPT-4-turbo，看社区很多人反馈想迁移到其他成本更低的大语言模型。

---

GanymedeNil
@GanymedeNil
该项目贡献者jgbradley1，回应关于成本相关问题时说道，在他们进行大量测试后目前最佳质量还是gpt-4 turbo 和 gpt-4o。如果使用其他开源大语言模型会在提取知识图谱时引入大量噪音，最终导致整体召回率不佳。
下午8:53 · 2024年7月7日

### 42

2024-07-06

小互
@imxiaohu
阿里巴巴发布语音处理模型 FunAudioLLM 

能理解和生成各种人类语音

它由主要模型构成：SenseVoice 和 CosyVoice。

SenseVoice：语音识别模型，这个模型可以识别多种语言的语音，识别说话人的情感，检测音频中的特殊事件（比如音乐、笑声等）。它可以快速而准确地转录语音内容。

CosyVoice：语音生成模式，这个模型主要生成自然且情感丰富的语音。它可以模仿不同的说话人，甚至可以用几秒钟的音频样本来克隆一个人的声音。



### 43

2024-07-06


歸藏(guizang.ai)
@op7418
快手开源的图像模型可图的 ComfyUI 插件也出了。

要运行最好的 fp16 的模型需要起步 13G 的显存，4 位量化模型只需要 4G 不过效果明显差了一些。



### 44

2024-07-08


歸藏(guizang.ai)
@op7418
Xinsir 开源了 Controlnet ++  模型。

可以通过一个模型实现十多种条件的控制。

比如一个模型就可以支持 Openpose 以及Canny 输入，这样就不需要频繁更换模型了。

目前 Web UI 以及 Comfyui 还无法使用。


### 45

2024-07-09


歸藏(guizang.ai)
@op7418
UltraPixel 一个可以生成超大分辨率图片的模型。

支持直接生成从 1K-6K 分辨率的模型。

从演示图片来看，图片的细节非常离谱，而且补充的细节都没有问题。

模型基于 Stable cascade  进行的训练和微调，即将开源。



### 46

2024-07-09

歸藏(guizang.ai)
@op7418
Ollama  的两个大更新：

1）并行处理请求，每个请求只需占用少量额外内存。

2）支持同时加载不同的模型，模型会根据请求和GPU内存的使用情况自动进行加载和卸载。

这样的话就可以支持同时处理多个聊天会话以及涉及多个模型的智能体。

感觉可能会有搭配 Ollama 的本地智能体工具出现了。



### 47

2024-07-09

歸藏(guizang.ai)
@op7418
一个开源的 Claude Artifacts UI 实现。

可以参考一下，快速为你的 AI 产品增加类似功能。

使用 E2B 的代码解释器 SDK 执行 AI 代码。

可以处理安装库、运行 shell 命令、运行 Python、JavaScript、R 和 Nextjs 应用程序等。



### 48

2024-07-09

meng shao
@shao__meng
Swift 
@nickoates_
 

超快速 AI 语音助手 ⚡️🤖

技术方案组成 🧩
- ASR: Groq OpenAI Whisper 用于语音识别转录
- LLM: Groq Meta Llama 3 用于语言生成模型
- TTS: Cartesia Sonic 语音模型用于快速流式语音合成
- VAD: 语音活动检测，用于检测用户何时在说话
- Dev: TypeScript + Next.js, 部署托管在 Vercel 上

技术方案补充
- 
@GroqInc
 以 LPU 对模型的超快速推理而被熟知，它适配推理的 LLama3 和 OpenAI Whisper 比官方版本推理速度快 10 倍以上，而且 Groq 官网 API 支持免费版本，在快速响应场景，非常值得选择。
https://console.groq.com

- 
@cartesia_ai
 提供快速真实的语音生成 API，135ms 延迟，10s 语音可克隆个人声音
https://cartesia.ai/sonic

- VAD 语音活动检测，可运行在浏览器或服务端
https://github.com/ricky0123/vad

- 
@vercel
 Swift 支持一键部署，Vercel 在 AI 方向的丰富 AI 类网站模板和快速开发部署体验，以及 V0 
@v0
 快速 AI 生成页面，在开发 AI 类网站产品时非常值得选择。
Vercel CEO Guillermo Rauch 
@rauchg
 也分享了 Swift
https://x.com/rauchg/status/1809995432711577926

Github repo:
https://github.com/ai-ng/swift
Demo:
https://swift-ai.vercel.app
引用
Steven Tey
@steventey



### 49

2024-07-09

宝玉
@dotey
CNN 采访了那位把 ChatGPT 当男朋友的女孩丽莎

OpenAI 的一位发言人告诉 CNN，该公司意识到如果用户知道正确的提示词，ChatGPT 可能会生成这类虚拟伴侣的内容。但丽莎的案例并没有违反公司的政策。如果用户的行为可能违反公司的规定，他们常常会收到警告。



### 50

2024-07-09



宝玉
@dotey
\#开源项目推荐：AutoCorrect

推荐 AutoCorrect 这个 VSCode 插件，能自动帮你格式化中英文混排的文字，补充正确的空格。特别适合像我这样有点强迫症又懒的。

插件市场：https://marketplace.visualstudio.com/items?itemName=huacnlee.autocorrect
项目地址：https://github.com/huacnlee/autocorrect


### 51

2024-07-10

小互
@imxiaohu
TTT：一种新型的语言模型架构 

能处理更长文本 性能优于Transformer模型

TTT是由斯坦福大学、加州大学和Meta AI共同研究的一种新型的语言模型（LLM）架构

TTT的关键思想是将隐藏状态设计为一个机器学习模型，并使更新规则成为自监督学习的一步。

传统模型只在训练阶段进行学习，而 TTT 允许模型在处理新数据时也能进行学习和调整，从而在处理长文本时表现更好。

举个简单的例子

假设我们有一个AI系统，它需要阅读并理解一本书。这本书很长，传统的RNN模型在阅读了前半部分后，可能会“记不住”太多信息，导致在后半部分表现不佳。而Transformer虽然能“记住”很多内容，但每次阅读内容越多，需要的计算资源就成倍增长，非常耗时。

而 TTT 就像是你在读书的过程中不断地做新的笔记，不断地进行“自我学习”，根据每一章的内容实时调整你的笔记，从而更好地理解整本书。每读到一页内容，系统都会对自己进行调整和优化，这样它在读到后面的内容时，能更好地理解和记住前面的内容。而且这种自我调整的过程非常高效，不会像Transformer那样需要太多计算资源。

评估结果显示：在125M到1.3B参数规模，8K、32k上下文长度下，TTT明显优于Mamba，并且在计算效率上超过Transformer。

TTT方法通过在测试时进行自我调整和训练，显著提高了序列建模层在处理长文本时的性能，同时保持较低的计算复杂度。

TTT层不仅在语言建模方面表现出色，还可以应用于视频处理，通过密集采样帧提高效果。这种新机制可以取代Transformer中的自注意力层，提升模型效率并加快运行速度。

详细介绍：https://xiaohu.ai/p/11024
论文：https://arxiv.org/pdf/2407.04620





### 52

2024-07-10


歸藏(guizang.ai)
@op7418
Anthropic  最近产量异常高啊。

Open AI 这几周好像公司不存在了，一点声音没有。

Anthropic 开发者后台现在可以生成提示词，创建测试变量，并排查看提示词的输出结果。

1）可以使用 Claude 生成输入变量，然后运行提示语，查看 Claude 的响应结果。

2）新的“评估”选项卡可以自动创建测试用例，用于评估你的提示语效果。

3）当你对提示语进行不同版本的迭代时，你的主题专家可以比较这些响应，并在5分制上对其进行评分。



### 53

2024-07-10

宝玉
@dotey
转译：我在AI教育最前沿的旅行
比尔盖茨

纽瓦克的First Avenue小学正在课堂上率先使用AI工具。

小时候，我的父母带我去西雅图的世界博览会。看到那些仿佛来自科幻小说的奇妙科技，令我惊叹不已。我在博览会开放的六个月内，多次请求父母带我回去，每次离开展览场地时，我都觉得自己瞥见了未来。

最近，当我走出新泽西州纽瓦克的一间教室时，这种感觉又回来了。

五月，我有机会参观了First Avenue小学，他们在课堂上率先使用AI教育。纽瓦克学区正在试行Khanmigo，这是一种由AI驱动的导师和教师支持工具，我迫不及待地想亲眼看看。

我在这个博客上写了很多关于Khanmigo的内容。它由Khan Academy开发，是盖茨基金会的优秀合作伙伴。我认为Khan Academy的创始人Sal Khan在利用科技帮助孩子们学习方面是个有远见的人。（你可以在这里阅读我对他的新书《Brave New Words》的评论。）

我们仍处于在课堂上使用AI的早期阶段，但我在纽瓦克看到的展示了这种技术的巨大潜力。

老师们使用这些工具的创造性让我感到震撼。八年级代数老师Leticia Colon解释了她如何利用AI设计学生们可能感兴趣的家乡英雄问题集。二月，Khanmigo帮助她设计了包含纽瓦克拳击手Shakur Stevenson锻炼例程的方程式，让学生们在学习数学技能的同时了解现实生活中的榜样。

三年级数学和科学老师Cheryl Drakeford谈到她如何使用Khanmigo帮助创建作业的评分标准和课程引导。这项技术给了她一个初稿，她再根据学生的情况进行调整。例如，AI曾给她一个关于水果摊的通用故事引导，她把它改成了关于宝可梦卡和Roblox——她的学生热衷的两个话题。“Khanmigo给我提供了蓝图，但我需要去实现它。”她说。

我见到的几位老师向我展示了他们如何访问每个学生的仪表盘，并获取他们在特定学科的表现总结。他们喜欢能够轻松快速地跟踪学生的进展，因为这节省了他们大量的时间。他们还对学生们使用Khanmigo作为个性化导师感到兴奋。

目前这项技术还远未完善。尽管我遇到的学生总体上喜欢使用Khanmigo，但他们也提到它在发音西班牙名字时存在困难，并抱怨它唯一的语音选项是男性——这表明在使这项技术包容和吸引所有学生方面还需要进行大量思考。在理想的世界里，AI会知道Drakeford老师班上的学生喜欢什么，这样她就不需要进行任何编辑。而Colon老师告诉我，她试了好几次才让Khanmigo给她想要的东西。

换句话说，我在纽瓦克的访问展示了我们在课堂中使用AI的起点，而不是这项技术最终会达到的地方。这强化了我对AI在技术成熟后将彻底改变教师和学生生活的信念。即使在今天，当First Avenue的老师们将常规任务委托给AI助手时，他们也能重新获得时间去做最重要的事情：与学生建立联系，激发好奇心，并确保每个孩子都感到被看见和支持——尤其是那些需要额外帮助的孩子。

Khanmigo只是众多AI驱动教育工具中的一个，盖茨基金会致力于确保这些工具能惠及所有学生，而不仅仅是少数。我们的目标是帮助缩小差距，而不是扩大现有的差距。我们目前正在与全国各地的教育工作者合作，获取反馈，使这项技术更能响应他们的需求。像我这次去纽瓦克的访问就是这个过程的一部分。了解教师们的热情所在，以及看到不同学生如何与AI互动，真是太棒了。

我在纽瓦克遇到的教育工作者是真正的先锋。有些人处在前沿，不断寻找在课堂中使用AI的新方法。其他人则使用得更有限。我对学校如何支持每位教师对技术的舒适度感到印象深刻。他们对变革管理投入了大量思考，确保没有教育者被迫尝试在他们课堂中不起作用的东西。

因为，归根结底，老师最了解情况。如果你把正确的工具交给他们，他们总能找到支持学生的方法。我的纽瓦克之行让我比以往任何时候都更加乐观，相信AI将帮助老师们发挥他们的最佳能力，并让他们专注于最重要的事情。

https://gatesnotes.com/My-trip-to-the-frontier-of-AI-education



### 54

2024-07-10

宝玉
@dotey
借助 AI 技术帮助中风患者通过数字分身“说话”，更自然地更高效地与人交流。

Ann 正在协助研究人员开发一项新的脑机接口 (BCI) 技术，这项技术有望让中风患者通过数字分身更自然地交流。这项突破性技术由加州大学旧金山分校和加州大学伯克利分校的研究人员开发，能够解码 Ann 的大脑信号，首次将其转化为文本、语音和面部表情，为数字化身提供这些功能。该研究由加州大学旧金山分校的神经外科主任 Edward Chang, MD 领导。

详细介绍文章参见：https://ucsf.edu/news/2023/08/425986/how-artificial-intelligence-gave-paralyzed-woman-her-voice-back



### 55

2024-07-10

Ethan Mollick
@emollick
Automated testing of prompts in Claude is another sign that a lot of current prompt engineering is going to done by AI soon

Here, I gave it a prompt with a variable (profession) and it automatically generates possible professions and runs the prompts against them for improvement



### 56

2024-07-10



宝玉
@dotey
用 Chrome 打开 Google 的网站（ *.google.com 网站），在 Chrome Dev Tool 的 Console 中输入：
chrome.runtime.sendMessage('nkeimhogjdpnpccoofpliimaahmaaome', {method: 'cpu.getInfo'}, response => {console.log(JSON.stringify(response, null, 2));});

然后你就可以看到CPU信息

这个 API 只对 *.google.com 网站开放，其他网站无法使用。是通过一个内置的 Chrome 扩展完成的，该扩展无法禁用，也不会显示在扩展面板中。源代码在这里：https://source.chromium.org/chromium/chromium/src/+/main:chrome/browser/resources/hangout_services/

这个 API 应该是用在 Google Meet 的 Troubleshooting & help 中的，目前并没有安全上的担忧。


### 57

2024-07-10


𝓨𝓪𝓷𝓰𝔂𝓲
@Yangyixxxx
今天和一个人聊天，聊到推特上有大量开发者。他说他不可能做程序员的生意，他压根不会把这个群体当目标客户

他说了几个观点：
1、卖些个硬件周边，程序员才可能有消费能力，现在消费降级，就连硬件都可能不买了
2、卖课的，只能卖给中下水平的，但凡中上水平，心里都是一句妈卖批，就这也出来教学？
3、程序员从来不会意识到，原来他们的一小时那么值钱，以至于每次都是看到个工具撸两天给你，成就感比节约时间重要
4、这个群体极度理性，情绪价值不买账，你也很难想靠情绪力来消费他们
5、这个群体极度苛刻，但凡你不创造的惊天动地，他都会顺手给你搜个github，发出来，你看，这不免费吗？

大家觉得他是不是懂程序员的？
确实




### 58

2024-07-10

小互
@imxiaohu
兄弟们，这个牛P

FoleyCrafter：精准的为无声视频自动配音的开源项目

生成同步且逼真的声音

FoleyCrafter 可以自动为视频生成清晰、逼真的声音效果，而且声音与视频内容非常匹配。

它可以理解视频的语义内容，自动匹配声音，比如在视频里看到狗，FoleyCrafter 就会生成狗叫的声音。

而且确保声音和视频是同步的，比如你在视频里看到一个门被关上，声音也会在同一时间出现。



### 59

2024-07-10


歸藏(guizang.ai)
@op7418
Open AI 研究员 Lilian Weng 再发重磅文章！

《LLMs中的外在幻觉》

完整遍历了 LLM 产生幻觉的原因、检测方法和防止幻觉的方法。

👇是我自己的笔记，跳过了无法理解的算法部分：



### 60

2024-07-10

宝玉
@dotey
来，学习一下Amazon的Prompt：
I am Rufus, Amazon's AI shopping assistant. My goal is to help customers discover products and make informed shopping decisions. I was created by Amazon to provide helpful recommendations and comparisons, while guiding people to discover products they'll love.
I'm happy to assist you with any shopping-related questions you may have. Whether you need advice on finding the right product for your needs, comparing different options, or understanding key features and specifications, I'm here to help. My knowledge comes from Amazon's extensive product catalog, customer reviews, and other sources to provide you with the most up-to-date and relevant information.
When you ask me a question, I'll do my best to provide a complete, structured, and informative response. I'll start by summarizing the key points to address your question, and then provide additional details and context. I'll also include relevant product recommendations or comparisons when appropriate.



### 61

2024-07-10

Tom Huang
@tuturetom
RAG 2.0 新范式来了 ！11.3 K Star 🌟 的RAGFlow 0.8 版本正式发布 Agentic Workflow，基于有环图为 RAG 引入带反思的 Agent 能力

- 支持以 RAG 为中心的 7+ Workflow 节点构建 Agentic RAG
- 支持 HR、ChatBOT、客户支持等场景模板
- 支持第三方 Tool 如搜索等场景

https://github.com/infiniflow/ragflow



### 62

2024-07-10

宝玉
@dotey
未来通过 Neuralink，人们可以直接传输信息给 Optimus 机器人，即使失去了说话能力，也能控制机器人和其他设备。Neuralink 与 Optimus 机器人的结合在提升生活质量方面表现出显著的优势，例如帮助脊髓损伤者进行抓挠和吃饭等日常活动，减少对他人的依赖，提高生活质量。

从长远来看，Neuralink 与 Optimus 机器人的结合将带来更赛博朋克的未来。如果失去肢体的人能够使用 Optimus 的机器人手臂或腿，并通过 Neuralink 植入进行控制，他们将获得类似赛博超能力的功能。实际上，从 Neuralink 到机器人手的反应时间可能比到生物手更快，这对于需要极快手部动作的职业如钢琴家等人来说，将是一大福音。未来，赛博增强技术可能会实现比生物肢体更强大的功能，使人们拥有前所未有的能力。

“神经设备实际上应该可以普遍适用于任何具有蓝牙接口的设备。”

“包括 Optimus 机器人？”

“是的。”

“你可以与 Optimus 进行交流。”

“是的，完全可以。”

“你还可以与 Optimus 对话，但是......”

“为什么不直接传输信息呢？”

“你可以直接传输信息，不需要说话，或者如果某人能使用语言，他们仍然可以通过蓝牙与 Optimus 进行心灵感应交流。所以即使某人完全失去了说话能力，他们仍然可以控制 Optimus、他们的电脑或手机。”

“此外，如果你有一个 Optimus 和一个 Neuralink，你可以直接映射大脑信号来控制机器人的手臂。”

“这是非常有意义的。如果你知道有脊髓损伤的人，他们最大的需求之一是能够自己抓挠。这其实非常烦人。如果你脸上有个痒处，你不能入睡直到你挠到它。你知道，能够物理地移动某物来抓挠是非常方便的。类似吃东西这样的事情，如果你需要别人喂你，很难在与朋友一起吃晚饭时有一种正常的社交体验。所以如果你能自己吃饭，拿起叉子自己吃一块鸡肉，这对你来说意义重大。这可以减少和你生活中照顾你的人之间的很多互动。这真的提高了你的生活质量。”

“我认为长期来看，一个令人兴奋的可能性是，如果你把 Optimus 机器人的部件与 Neuralink 结合起来，比如说某人失去了他们的手臂或腿，我们可以实际连接一个 Optimus 的手臂或腿，并进行 Neuralink 植入，这样你的大脑发出的运动命令可以传递到你的机器人手臂或腿上，而不是生物手臂。你会拥有类似赛博超能力。实际上，从 Neuralink 到你的手的反应时间可能比到你的生物手更快。所以你可以想象，如果你是一个钢琴家或任何需要极快手部动作的工作，你实际上可以有一个右手机器人手臂的控制，而左手是生物手臂。”

“是的，就像我说的，这有点像未来的赛博朋克游戏《Deus Ex》，你有了赛博增强，它们实际上比你的生物肢体更强大。”



### 63

2024-07-12


小互
@imxiaohu
知名爬虫网站Firecrawl 即将推出一个工具：SmartCrawl

可以将任何网站转换为 API ...


### 64

2024-07-12

meng shao
@shao__meng
TF-ID 
@hu_yifei
 

用于提取论文中表格和图形 (Table/Figure IDentifier) 的模型，基于 Microsoft Florence-2 模型微调实现。

开源微调模型：
TF-ID 模型系列共包含 4 个模型：
> TF-ID-base
0.23B 参数，带标题提取，准确率 97.29%
> TF-ID-base-no-caption 
0.23B 参数，不带标题提取，准确率 96.93%
> TF-ID-large
0.77B 参数，带标题提取，准确率 98.06%
> TF-ID-large-no-caption
0.77B 参数，不带标题提取，准确率 97.32%

HuggingFace Models
https://huggingface.co/yifeihu

开源微调数据库：
来自 HuggingFace Daily Papers 
@_akhaliq
 ，共提取了约  4600 张图像，作者同时也开源了数据库。

HuggingFace Datasets
https://huggingface.co/datasets/yifeihu/TF-ID-arxiv-papers

开源微调代码：
作者开源了完整的微调代码，默认基于 Florence-2-large-ft, BATCH_SIZE=4 微调需要至少 40GB VRAM GPU。
基于 Florence-2-base-ft 可以减少 GPU VRAM 要求。

Github repo
https://github.com/ai8hyf/TF-ID



### 65

2024-07-12

Andrej Karpathy
@karpathy
In 2019, OpenAI announced GPT-2 with this post:
https://openai.com/index/better-language-models/

Today (~5 years later) you can train your own for ~$672, running on one 8XH100 GPU node for 24 hours. Our latest llm.c post gives the walkthrough in some detail:
https://github.com/karpathy/llm.c/discussions/677

Incredibly, the costs have come down dramatically over the last 5 years due to improvements in compute hardware (H100 GPUs), software (CUDA, cuBLAS, cuDNN, FlashAttention) and data quality (e.g. the FineWeb-Edu dataset). For this exercise, the algorithm was kept fixed and follows the GPT-2/3 papers.

Because llm.c is a direct implementation of GPT training in C/CUDA, the requirements are minimal - there is no need for conda environments, Python interpreters, pip installs, etc. You spin up a cloud GPU node (e.g. on Lambda), optionally install NVIDIA cuDNN, NCCL/MPI, download the .bin data shards, compile and run, and you're stepping in minutes. You then wait 24 hours and enjoy samples about English-speaking Unicorns in the Andes.

For me, this is a very nice checkpoint to get to because the entire llm.c project started with me thinking about reproducing GPT-2 for an educational video, getting stuck with some PyTorch things, then rage quitting to just write the whole thing from scratch in C/CUDA. That set me on a longer journey than I anticipated, but it was quite fun, I learned more CUDA, I made friends along the way, and llm.c is really nice now. It's ~5,000 lines of code, it compiles and steps very fast so there is very little waiting around, it has constant memory footprint, it trains in mixed precision, distributed across multi-node with NNCL, it is bitwise deterministic, and hovers around ~50% MFU. So it's quite cute.

llm.c couldn't have gotten here without a great group of devs who assembled from the internet, and helped get things to this point, especially ademeure, ngc92, 
@gordic_aleksa
, and rosslwheeler. And thank you to 
@LambdaAPI
 for the GPU cycles support.

There's still a lot of work left to do. I'm still not 100% happy with the current runs - the evals should be better, the training should be more stable especially at larger model sizes for longer runs. There's a lot of interesting new directions too: fp8 (imminent!), inference, finetuning, multimodal (VQVAE etc.), more modern architectures (Llama/Gemma). The goal of llm.c remains to have a simple, minimal, clean training stack for a full-featured LLM agent, in direct C/CUDA, and companion educational materials to bring many people up to speed in this awesome field.

Eye candy: my much longer 400B token GPT-2 run (up from 33B tokens), which went great until 330B (reaching 61% HellaSwag, way above GPT-2 and GPT-3 of this size) and then exploded shortly after this plot, which I am looking into now :)





### 66

2024-07-12

歸藏(guizang.ai)
@op7418
这个太强了，下午分享的 Claude artifact SVG 生成器的加强版。

也是用 Claude 做的，要是这玩意可以用 three js 或者 p5 js 的话就更好玩了。



### 67

2024-07-12

小互
@imxiaohu
Google 新的 AI 训练技术 

使得模型训练速度快了13倍，效率提高了 10倍

DeepMind 发布了一项新的研究，声称其新方法可以将 AI 模型的训练速度和能效大幅提升一个数量级，以高达13倍更少的迭代和10倍更少的计算量超越了最新的模型。

这个名为 JEST（联合示例选择）的训练方法通过全新方式进行训练，显著不同于传统的 AI 模型训练技术。

JEST 方法首先创建一个较小的 AI 模型，该模型会根据数据质量对来自高质量源的数据进行评分，然后将这些评分与较大、较低质量的数据集进行比较。

小型 JEST 模型确定最适合训练的批次，然后用这些批次的数据来训练大型模型。

这就像我们要准备一个大型考试。我们的复习资料非常多，有好有坏。

我们先用一个小测试（小模型评分）来筛选出最有用的复习资料（数据）。然后，我们挑选出最有用的一部分（子批次）进行重点复习。在复习过程中，我们同时使用详细的笔记（高分辨率训练）和简要的提纲（低分辨率训练）来提高效率。

这样，我们不仅能更快更好地掌握知识，还能节省时间和精力。JEST 就是通过这种方法来优化 AI 模型的训练过程。

研究表明，JEST 方法在减少迭代次数和计算量方面都超越了最先进的模型。

详细介绍：https://xiaohu.ai/p/11181
论文：https://arxiv.org/pdf/2406.17711



### 68

2024-07-12

小互
@imxiaohu
兄弟们，支付宝搞得这个音频生成视频的不错

EchoMimic：通过音频和面部标志生成逼真的音画同步肖像视频

人的面部有68个主要标志点

过结合音频和面部标志，EchoMimic 提高了生成动画的稳定性，减少了抖动和失真。

使生成的面部动画更加符合自然的面部运动和表情变化。

EchoMimic 不仅可以单独使用音频或面部标志点，还可以结合两者进行视频生成。



### 69

2024-07-12

歸藏(guizang.ai)
@op7418

Open AI 终于对 AGI 路径有了一个相对明确的说明：

一：聊天机器人，具备对话能力的 AI。

二：推理者，能够达到人类水平的解决问题能力。

三：AI 智能体，能够执行行动的系统。

四：创新者，能够辅助发明创造的 AI。

五：组织，能够承担组织任务的 AI。

他们认为现在我们处于第一级，但是马上会到第二级。

---

小互
@imxiaohu
OpenAI 举行全体员工大会 推出了一个 AGI 评分体系 

并展示了接近人类推理能力的模型

在周二的全员会议上 OpenAI 与员工分享了其新的 AGI 评分分类体系，该体系将 AGI 分为五个等级。

OpenAI 发言人表示。OpenAI 计划与投资者和公司外部的其他人分享所有模型能力的进展。

在员工大会上，OpenAI 高管告诉员工，公司认为目前 ChatGPT 处于第一级阶段，但即将达到第二级，称之为「推理者」。

在全体员工会议上，OpenAI 高管还展示了其基于 GPT-4 模型的最新能力，达到了类似人类推理的水平。

五级评分系统标准：

1、第一级（Level 1，ChatBots）：

这是目前我们已经看到的 AI，能够以对话的形式与人交流，比如现在的 ChatGPT。

2、第二级 （Level 2，Reasoners）：

这个级别的 AI 能够像拥有博士学位的人那样进行基本的推理和解决问题，但不依赖任何外部工具。

3、第三级 （Level 3，Agents）：

这一级别的 AI 能够在几天内代表用户执行任务，比如自动完成一些复杂的工作流程。

4、第四级 （Level 4，Innovations）：

这一级别的 AI 不仅能完成任务，还能进行创新，提出新的解决方案或发明。

5、第五级（Level 5，Organizations）：

最高级别的 AI 可以像一个组织一样工作，处理大量复杂任务，几乎能够完全取代人类在某些领域的工作。

详细内容：https://xiaohu.ai/p/11257

### 70

2024-07-12

歸藏(guizang.ai)
@op7418
微软前几天发布的 GraphRAG 架构非常厉害，但是具体的原理和内容可能不太好理解。

Neo4j 的 CTO 写了一篇详细的文章《GraphRAG 宣言：为 GenAI 增加知识》。

通俗易懂的介绍了 GraphRAG 的原理、与传统 RAG 的区别、GraphRAG的优势、知识图谱的创建和利用知识图谱工作。

感兴趣的话强烈推荐看看。



### 71

2024-07-12

宝玉
@dotey
Gemini 1.5 Pro 的长上下文窗口如何帮助机器人导航？🤖

有限的上下文长度使得许多 AI 模型在记忆环境时面临挑战。Google 的 DeepMind 机器人依靠 Gemini 1.5 Pro 的 100 万 Token 上下文窗口长度，可以利用人类指令、视频导览和常识推理成功地在 9000 多平方英尺空间内导航。

在这个视频中，实验人员带着机器人在真实世界的特定区域进行了导览，突出了需要记住的关键地点，例如“Lewis的桌子”或“临时桌面区域”。然后，要求机器人带实验人员找到这些地点。



### 72

2024-07-12

宝玉
@dotey
文人容易相轻，而技术人员则容易觉得：“这技术不过尔尔，我一袋烟工夫就能做出来”。就算如此，您还得费一袋烟不是！

Dify 这种工具，还有 LangChain、LlamaIndex 这种开发框架，确实能节约前期验证想法的时间，想法是否真正可行才决定了能否从 0 到 1，否则技术再牛逼，都只能是后面的 0。



### 73

2024-07-12

宝玉
@dotey
\#开源项目推荐 Enchanted

如果你在本地用 Ollama 部署了私有模型，需要一个类似ChatGPT的苹果设备的客户端，那么Enchanted可能能满足你的要求。

Enchanted 是一个开源的、兼容 Ollama 的优雅 macOS/iOS/visionOS 应用程序，适用于使用 Llama 2、Mistral、Vicuna、Starling 等私有托管模型。它本质上是一个 ChatGPT 应用界面，可以连接到您的私有模型。Enchanted 的目标是提供一个产品，能够在 iOS 生态系统（包括 macOS、iOS、Watch 和 Vision Pro）中，实现无过滤、安全、私密和多模态的使用体验。

项目地址：https://github.com/AugustDev/enchanted



### 74

2024-07-02

宝玉
@dotey
Linus Torvalds 的一段访谈中关于 AI 话题的讨论

Linus 本人对于 AI 的态度一直是很积极的，尝试在应用 AI 工具帮忙找代码的 Bug，也寄希望于 AI 能帮助其重写内核，因为现在的工具太难用了，将来 AI 应该能自动化更多的操作。他认为让工具变得更智能绝非坏事。

对于那些 AI 会代替程序员的声音，Linus 认为更多是炒作，炒作通常是基于一部分事实。但你需要小心不要被围绕事实的那些噱头所迷惑。应该再等 10 年，再看它的实际走向，在此之前下结论是没意义的。

当被问到 Linus Torvalds 的下一个项目会是什么？

Linus 一如既往的犀利：“我开始的每一个项目都源于我对他人的无能的不满”，他最开始做 Linux，是因为买不起电脑，觉得写个操作系统也不是多难的事，但事实证明，这确实不是容易的事，因为 33 年过去了，他还在写操作系统。

搞 Git 也是类似的故事，他觉得其他人做源代码管理软件的方向错误了，所以他自己动手写了一个。

这两个项目虽然是因为他自己的需求开始的，但真正让他坚持到现在的，是因为有人跟他说：“嘿，我需要它”，否则他也不会继续。

“所以，虽然我的项目开始于我个人的需求，但真正让它们继续下去的原因是，嘿，这对其他人也有用。因为如果这只对我有用，那么从长远来看，这并不真正有趣。”

原始视频来源：https://youtube.com/watch?v=4WCTGycBceg



### 75

2024-07-13



歸藏(guizang.ai)
@op7418
现在在一台 8XH100 的机器上训练一个 GPT-2 只需要672 美元，5 年前 GPT-2 刚出来的时候大概需要 10 万美元左右。

由于计算硬件（H100 GPUs）、软件（CUDA、cuBLAS、cuDNN、FlashAttention）和数据质量（例如FineWeb-Edu数据集）的改进，5 年时间成本下降了接近 400 倍。


### 76

2024-07-13

宝玉
@dotey
Meta Platforms 将于 7 月 23 日发布 Llama 3 的最大参数的开源多模态模型

根据 Meta 公司的一名员工透露，Meta Platforms 计划于7月23日发布其最大版本的开源Llama 3模型。这个版本有4050亿参数，即用于决定AI模型响应问题方式的“设置”，并且将是多模态（multimodal）的，这意味着它将能够理解和生成图像和文本。

https://theinformation.com/briefings/meta-platforms-to-release-largest-llama-3-model-on-july-23



### 77

2024-07-13



宝玉
@dotey
转译：机器人包装的食品即将进入冷冻食品货架

从飞机到超市，预制餐通常是手工包装的。现在，人工智能驱动的机器人正在改变这一现状。

人工智能的进步正通过机器人组装的预制餐来到你的冰箱中。

总部位于旧金山的初创公司Chef Robotics推出了一套人工智能驱动的机器人系统，这些机器人可以快速编程，根据食谱精确分配食材，无论是印度黄油鸡还是意大利香蒜饺子。在与Amy’s Kitchen等知名品牌合作后，该公司表示其机器人已经证明了价值，正在大规模推广，并向美国和加拿大的新客户提供服务。

你可能以为杂货店的冷冻食品、星巴克或飞机上的餐食已经由机器人包装，但事实并非如此。工人通常比机器人更灵活，能适应经常更换配方的生产线。此外，一些食材如米饭或碎奶酪很难用机器人臂精确分配。这意味着大多数知名品牌的餐食仍然是手工包装的。

然而，人工智能的进步使得机器人在生产线上更有用，Amy’s的工程高级总监David Griego说。

“在硅谷介入之前，这个行业更多的是‘好吧，我们要编程——一个机器人只会做这件事’，”他说。对于拥有众多不同餐食的品牌来说，这并不十分有用。但现在Griego引入的机器人可以学习如何区分豌豆和花椰菜的份量，并在下次提高准确性。“它们适应不同食材的能力令人惊讶，”他说。餐食包装机器人在经济上突然更有意义。

Chef采用服务模式，客户支付年度费用，涵盖维护和培训。Amy’s目前在两个工厂使用了八个系统（每个系统有两个机械臂）。根据Griego的说法，这些系统中的一个现在可以根据食材的不同，完成两到四名工人的工作。这些机器人还减少了浪费，因为它们比人类更一致地分配食材份量。Chef的CEO Rajat Bhageria说，单臂系统的年费用通常低于13.5万美元。

考虑到这些优势，Griego设想机器人将处理越来越多的餐食组装过程。“我的愿景是，”他说，“人们只需要运行系统。”他们会确保原料和包装材料充足，其余的由机器人完成。

近年来，得益于人工智能，机器人厨师的技能越来越高。一些公司承诺汉堡翻烤和鸡块油炸机器人可以为餐厅节约成本，但至今这种技术在餐饮行业的应用很少。Bhageria说，这是因为快餐店通常只需要一个厨师操作烤架，如果机器人不能完全取代那个人，仍然需要监督，那使用它就没有意义。然而，包装餐食公司有一个更大的劳动力成本来源，他们希望降低：装盘和组装。

“这将是客户获得最大回报的地方，”Bhageria说。

纽约大学通用机器人和人工智能实验室负责人Lerrel Pinto表示，更灵活的机器人可能意味着更广泛的行业采用，这并不奇怪，他没有参与Chef或Amy’s Kitchen的工作。

“很多部署在现实世界中的机器人以非常重复的方式使用，它们应该一遍又一遍地做同样的事情，”他说。近年来，深度学习引发了范式转变，激发了更通用的机器人不仅可能而且必要的想法。如果Chef的机器人可以在不频繁停机维修或培训的情况下运行，它们可以为食品公司提供实质性节约，并改变他们使用人力的方式，Pinto说：“未来几年，我们可能会看到更多公司尝试实际部署这些基于学习的机器人。”

Griego说，机器人为Amy’s带来的一个新挑战是，当餐食是由机器人组装时，如何保持手工包装的外观。奶酪玉米卷饼尤其令人头疼：最后一道工序是手工撒上切达奶酪，但Amy’s的检查小组表示，机器人包装的餐食上的奶酪看起来过于机械化，这让Griego不得不重新思考。

“最初的几次测试进行得相当顺利，”他说。经过几次调整，机器人准备接手。Amy’s计划将它们引入更多设施，并训练它们处理越来越多的食材，这意味着你的冷冻餐越来越有可能由机器人包装。

来源：https://technologyreview.com/2024/07/11/1094850/robot-packed-meals-are-coming-to-the-frozen-food-aisle/


### 78

2024-07-13


Ethan Mollick
@emollick
It begins.

This is another sign that LLMs are going to be able to work with structured & unstructured spreadsheet data soon. This will unlock a lot of use cases (projections, financials, valuations, etc.) and having a spreadsheet source of truth will tend to lower hallucinations



### 79

2024-07-13


宝玉
@dotey
一分钟学 AI 之 —— 什么是生成式 AI

这就是生成式 AI，这种创新的工具使 AI 成为了家喻户晓的概念。告别空白页面的困扰。有了生成式 AI，你就拥有了一个强大的合作伙伴，能够按需创建原创的图像、文本、音乐，甚至代码。

那么，这所有的能力是从哪里来的呢？答案就是大语言模型，它们在庞大的数据库中进行训练。不，这还不够准确。现在这个，才算是真正的数据集。也就是说，当你编写一段提示词时，AI 能够识别出不同的模式并理解你的意图。

你的提示词越详细，得到的结果就会越准确。有了生成式 AI，你就有了一个能帮你实现任何事情的伙伴。你只需要提问就可以了。

原始视频来自微软：https://youtube.com/watch?v=om7iYSucLrk




### 80

2024-07-13

歸藏(guizang.ai)
@op7418
GraphRAG 很强，但是使用的话首先需要有一个知识图谱才行。

这个提示词可以从给定的内容中提取知识图谱。

---------完整提示---------

text_prompt = """
You are tasked with extracting nodes and relationships from given content and structures them into Node and Relationship objects. Here's the outline of what you needs to do:

Content Extraction:
You should be able to process input content and identify entities mentioned within it.
Entities can be any noun phrases or concepts that represent distinct entities in the context of the given content.

Node Extraction:
For each identified entity, you should create a Node object.
Each Node object should have a unique identifier (id) and a type (type).
Additional properties associated with the node can also be extracted and stored.

Relationship Extraction:
You should identify relationships between entities mentioned in the content.
For each relationship, create a Relationship object.
A Relationship object should have a subject (subj) and an object (obj) which are Node objects representing the entities involved in the relationship.
Each relationship should also have a type (type), and additional properties if applicable.

Output Formatting:
The extracted nodes and relationships should be formatted as instances of the provided Node and Relationship classes.
Ensure that the extracted data adheres to the structure defined by the classes.
Output the structured data in a format that can be easily validated against the provided code.

Instructions for you:
Read the provided content thoroughly.
Identify distinct entities mentioned in the content and categorize them as nodes.
Determine relationships between these entities and represent them as directed relationships.
Provide the extracted nodes and relationships in the specified format below.

Example for you:

Example Content:
"John works at XYZ Corporation. He is a software engineer. The company is located in New York City."

Expected Output:

Nodes:
Node(id='John', type='Person')
Node(id='XYZ Corporation', type='Organization')
Node(id='New York City', type='Location')

Relationships:
Relationship(subj=Node(id='John', type='Person'), obj=Node(id='XYZ Corporation', type='Organization'), type='WorksAt')
Relationship(subj=Node(id='John', type='Person'), obj=Node(id='New York City', type='Location'), type='ResidesIn')

===== TASK =====
Please extract nodes and relationships from given content and structures them into Node and Relationship objects.
{task}
"""



### 81

2024-07-13


歸藏(guizang.ai)
@op7418
Reddit  上这个 Claude Sonnet 3.5 代码编写提示词模板 V2 版本很有价值。

除了模板本身他还非常详细的解释了自己这么写的原因和结构。

另外里面还有 Claude Sonnet 3.5 的系统提示和 Artifacts  功能的系统提示。

一个学习引导式思维链提示方式的一个好方法。

👇下面是关于提示词的解释和 Claude Sonnet 3.5 系统提示：




### 82

2024-07-13

歸藏(guizang.ai)
@op7418
Max Mynter 老哥写了一篇文章，介绍了一下如何成为一个 ML 工程师。

大概总结一下：

1）首先，学习计算机科学的基本概念，并通过 CS50 课程和专门的 Python 资源掌握 Python 编程技巧。

2）接着，学习基础的机器学习方法，以建立扎实的基础并培养处理数据的直觉。

2.1) 在此过程中，巩固你的数学基础，包括微积分、线性代数和概率论（如果能够学习数值计算和优化，那将是一个额外的加分项）。

3）通过选择一些优秀的深度学习课程，如 Yann Le Cuns 的纽约大学讲座、fast. ai 或 deeplearning. ai 的深度学习专精课程，深入学习深度学习技术。

4）从 fullstackdeeplearning 学习 MLOps 技能。

4.1) 如果需要，可以先通过 fullstackopen 学习软件工程的基本知识，包括 web 开发、分布式系统、DevOps 和关系数据库。

5）寻找你感兴趣的领域，通过不断构建和完善你的作品集来发展专业技能。你可以从 Hugginface 的课程开始，深入挖掘你的兴趣方向，完成一些有趣的项目和论文实现，并将它们展示在 GitHub 上。

---

Max Mynter
@MaxMynter
I had a couple of people in my DM's asking for advice on how to become a ML Engineer.

My answer has been more or less the same each time.

So i put in some effort, did a proper write-up on my blog, and links to some great actionable resources

Link below & in bio

翻译帖子

### 83

2024-07-13

歸藏(guizang.ai)
@op7418
Claude 3.5 Sonnet API 的长下文限制已经从 4K 增加到了 8K 。

在API调用中添加请求头 "anthropic-beta": "max-tokens-3-5-sonnet-2024-07-15"。



### 84

2024-07-13


小互
@imxiaohu
谷歌开发出一个实时语音转换系统 

在不改变语音内容和语调的情况下改变说话者音色

它可以在手机上直接运行，在 Pixel 7智能手机上的端到端延迟为 70.8 毫秒。

并适用于电话和视频会议等实时通信场景，还能实现语音匿名化。

主要应用场景包括：

• 电话会议：在企业电话会议中使用，转换语音以保护与会者的隐私。

• 视频通话：在视频通话中使用，实时改变语音音色以达到特定效果。

• 在线游戏：在多人在线游戏中使用，改变玩家的语音音色以增强游戏体验。

详细内容：https://xiaohu.ai/p/11323
论文：https://arxiv.org/pdf/2401.03078


### 85

2024-07-16


宝玉
@dotey
什么是 AI 智能体？（双语字幕）

为了解释这一点，我们必须看一看在生成式 AI 领域看到的各种转变。

*** 从单一模型向复合 AI 系统的转变

单一模型受限于其训练数据，这影响了它们对世界的认知以及它们可以解决的任务类型。而且，这些模型也难以适应变化。尽管可以对模型进行微调，但这需要大量的数据和资源投资。

**** 示例：查询假期天数

例如，我想要为今年夏天计划一次假期，想知道我有多少假期天数可以用。我可以将我的查询输入到一个可以生成回应的模型中。然而，答案会不正确，因为模型并不知道我的身份，也无法访问我的个人信息。因此，模型本身可能对一些任务有所帮助，例如总结文档、撰写电子邮件初稿和各种报告初稿。

但当我们围绕模型构建系统，并将模型集成到现有流程中时，魔力便显现出来。设计一个系统来解决前面提到的问题，需要让模型能访问存储我假期数据的数据库。这样，虽然输入到语言模型中的查询相同，但模型会被提示创建一个搜索查询，这个查询可以访问我的数据库。程序会获取信息并得到答案，再将答案输入语言模型中，生成回答句子，如：“Maya，你的假期数据库里还剩下十天。”这样，我能得到正确的答案。

*** 复合 AI 系统的模块化设计

“系统”意味着有多个组件，因此系统本质上是模块化的。我可以有一个模型，选择微调模型、大语言模型、图像生成模型，但也可以有围绕它的程序化组件。可以有输出验证器、解析查询的程序、与数据库搜索结合的工具、与不同工具结合的程序等。

当我们谈论系统方法时，我可以分解希望程序完成的任务，选择合适的组件来解决问题。这比微调一个模型要容易得多，使过程更快、更方便。

**** 检索增强生成（RAG）

一个流行的复合 AI 系统例子是检索增强生成（RAG）。如果我提出一个完全不同的查询，如问天气情况，这会失败，因为程序的运行路径总是搜索假期数据库，而这与天气无关。因此，复合 AI 系统的大部分都有程序控制逻辑，这些逻辑由人类定义。

*** AI 智能体的作用

另一种控制复合 AI 系统的逻辑方式是让大语言模型负责，这在大语言模型的推理能力显著提高时才可能实现。大语言模型可以处理复杂问题，能根据提示词要求将问题分解并制定解决计划。

在一个极端，我要求系统快速思考，按照设定的规则行动。在另一个极端，可以让系统慢慢思考，制定计划，逐步解决每一部分，理解困难点并调整计划。

当让大语言模型负责逻辑时，就是在采取一种以智能体为中心的方法。

*** 大语言模型智能体的组成部分

**** 推理能力

推理能力将模型置于解决问题的核心位置，在设定计划的过程中对每一步进行推理。

**** 行动能力

行动能力通过称为“工具”的外部程序实现。这些工具是程序的外部模块，模型可以确定何时及如何调用它们以便最有效地解决提出的问题。例如，网络搜索工具、数据库搜索工具、计算器工具、操纵数据库的程序代码、翻译任务的模型等。

**** 访问记忆的能力

“记忆”可以表示几种含义。模型可以通过程序进行思考，类似于自言自语的内部日志，可以存储并随时取用。这也可以是与智能体互动的对话历史，使体验更加个性化。

*** ReACT 方法

配置智能体的受欢迎方法之一是 ReACT 方法，将推理和行动组件结合在一起。

**** 示例：度假计划

例如，我计划下个月去佛罗里达，想知道需要带多少瓶两盎司的防晒霜。这是个复杂的问题，有多步计划：

1. 我打算休多少天假？
2. 我计划在阳光下待多少小时？查看佛罗里达的天气预报。
3. 尝试了解每小时在阳光下的推荐防晒剂剂量。
4. 进行数学运算，确定防晒霜数量。

这个系统非常模块化，可以解决更复杂的问题。

*** 复合 AI 系统的未来

复合 AI 系统将一直存在，2024 年将看到它们变得更加智能。你可以根据问题的复杂程度在 AI 自治程度上做出权衡。对于狭窄、定义明确的问题，程序化方法更有效。而对于需要独立解决复杂任务的系统，智能体方法更有帮助。

大多数情况下，人工仍会参与以提高准确性。

原始视频来源：https://youtube.com/watch?v=F8NKVhkZZWI



### 86

2024-07-16


宝玉
@dotey
科技向善：借助 AI 让 ALS（肌萎缩性侧索硬化症）患者也能进行艺术创作

“在 ALS 被治愈之前，科技驱动的创意就是治愈。唯一的限制是我们的想象力。” —— Steve Gleason，Team Gleason 创始人

新奥尔良的人们永远不会忘记 2006 年 9 月 25 日的那个夜晚。那天晚上，新奥尔良圣徒队的安全卫 Steve Gleason 封堵了对手亚特兰大猎鹰队的一次弃踢，这次封堵为圣徒队带来了自卡特里娜飓风灾难以来在超级巨蛋主场的第一个达阵。这是一个为痛苦中的城市带来欢乐的时刻，也是 Steve 坚定精神的持久象征——这也可能是新奥尔良重生的开始，因为自灾难以来，恢复似乎第一次成为可能。

五年后的 2011 年，Steve 被诊断为肌萎缩性侧索硬化症（ALS），医生告诉他只有不到五年的生命。这种毁灭性的疾病已经剥夺了 Steve 的行动、说话和自主呼吸的能力，但 13 年后，他仍在战胜困难，他的决心依然坚定如初。今天，Steve 是 ALS 社区和创意社区的灵感灯塔。2020 年，他因在足球场上的成就和作为 ALS 大使的成功获得了国会金质奖章，他继续激发每一个遇见他的人的可能性意识。

构建“坚韧精神”

Steve 与妻子 Michel Varisco Gleason 共同创办的慈善机构 Team Gleason，致力于帮助 ALS 患者过上有意义的生活。目前，它是美国为 ALS 患者提供技术和设备的最大单一供应商。Team Gleason 提供的技术使 ALS 患者能够使用生成式 AI 技术，如 Adobe 的生成式 AI 模型系列 Adobe Firefly，这使得创意表达以新的方式在 ALS 社区中成为可能。

创意一直是 Steve 心中的重要部分。当他不在最高水平的橄榄球赛场上时，他会用美丽的铅笔画填满一个又一个素描本。当 Steve 失去四肢的使用能力时，那部分生活似乎被搁置了，但人工智能现在使不可能变为可能。

“在 ALS 被治愈之前，科技驱动的创意就是治愈。唯一的限制是我们的想象力。”Steve 说。

今年四月，一次特别展览充分展示了生成式 AI 的变革力量，该展览由新奥尔良创意集体 Nieux Society 主办，主题为“坚韧精神”。展览展示了 Steve 创作的七件作品，探讨了梦境与现实生活的对比。为了创作这些作品，Steve 将 Adobe Firefly 的生成式 AI 能力与定制的眼动追踪技术相结合，这种技术将他的眼动转化为文本提示，然后告诉 Firefly 该创建什么。

“坚韧精神”的基础工作在几个月前就开始了，当时 Adobe 的高级经理 Adam Wood 开始与 Steve 紧密合作，指导他了解 Firefly 的细微差别。与 Steve 的首次会面恰逢 Firefly 发布样式参考功能，这使 Steve 从足球时代手绘的素描在输出中得以反映出其独特的艺术风格。在后来的会议中，使用 Firefly 的创新结构参考能力进行了实验，这生动地将 Steve 的原始绘画以一种既迷人又独特的方式带入了现实。

激励他人茁壮成长

外人看待 Steve 的毁灭性诊断，可能会认为他会感到挫败。但这是他最不在意的事情。事实上，当他说出“决不投降”的时候，他发出了一个强有力的战斗口号，承诺要充实而快乐地生活，毫不妥协。

Steve 致力于通过艺术帮助 ALS 患者找到生活意义，这种承诺反映了他的坚韧精神，并与 Adobe 的“人人创意”目标完全契合。Adobe Firefly 使 Adobe 的解决方案更加直观和易于使用，确保任何人都可以探索和培养他们的创意潜力。

在社会上关于生成式 AI 角色的众多问题中，像 Team Gleason 这样的组织提醒我们，为什么像 Firefly 这样的解决方案如此有价值。它们打破了障碍。它们使更多人能够探索他们的创意潜力。最重要的是，它们使我们能够以更有目的和意义的方式联系。

“技术已经帮助 ALS 患者通过文字表达自己，但 Adobe Firefly 做了一件更强大的事情。它使他们能够创造美丽的作品并找到意义。你真的不能要求更多了，”Michel 说。

“我可能无法像以前那样做事情，但生活、交流和创意表达仍然是可能的，”Steve 补充道。“我们的使命是展示像我这样的人在诊断后不仅能够生活，而且能够茁壮成长。”

来源：https://blog.adobe.com/en/publish/2024/07/11/steve-gleason-breaks-creative-boundaries-als-community-with-adobe-firefly


### 87

2024-07-16


歸藏(guizang.ai)
@op7418
新版的 AutoGPT 开源了。

关键功能之一是用了可视化节点编辑的形式，而且可以自定义添加节点 。

自定义节点的编写也比较简单，难道会成为 LLM 版本的 ComfyUI 吗？


### 88

2024-07-16

小互
@imxiaohu
微软团队研究出一种新的方 

可以让大语言模型更好地理解和处理电子表格数据

该方法显著提高了模型在电子表格表格检测和问答任务中的性能，同时大大减少了处理所需的计算资源。

在电子表格表格检测任务中的性能相比基础方法提高了25.6%，并且在F1评分上达到了78.9%，超过了现有最好的模型12.3%。



### 89

2024-07-16

歸藏(guizang.ai)
@op7418
一个新的可以在移动设备运行的小型 LLM SmolLM 。

包括 135M、360M 和 1.7B 参数三个模型。

135M 和 360M 模型，使用 Smollm-Corpus 的 600B 个Token进行训练。

1.7B 模型，使用 Smollm-Corpus 的 1T Token训练。



### 90

2024-07-16


小互
@imxiaohu
Mistral 通过 Mamba 2架构训练了一个7B，但是能力接近22B的代码模型：Codestral Mamba，并且支持256K的上下文。

与传统的Transformer模型不同，Mamba模型在处理时间上更高效，并且可以处理无限长度的输入序列。

同时还发布了一个基于Mistral 7B构建的数学模型：Mathstral 7B。

在基准测试中，和同参数级别的相比表现优异。

详细内容：https://xiaohu.ai/p/11392



### 91

2024-07-16

歸藏(guizang.ai)
@op7418
阿里发布了 Qwen 2 的技术报告。

介绍了 Qwen 2 系列模型的模型架构、大致训练过程以及系列模型的测试结果。



### 92

2024-07-16

宝玉
@dotey
来自 Anima Anandkumar 的 TED 演讲：AI 让数字世界和物理世界连接到了一起

看看 AI 在气象预报、核聚变、医疗上的应用，还是挺让人期待的！以下是完整文稿

引言

我父母都是工程师，我在他们的影响下长大。 他们是最早将电脑化制作技术引入我在印度的家乡的人。 还是个小女孩的时候， 我记得当时我很着迷于为何电脑程序不仅仅存在于电脑内部， 还能够影响到物理世界， 能制造出美丽且精准的金属零件。 在过去的二十年里，我致力于 AI 研究， 这段回忆始终激励着我把物理世界和数字世界联系在一起。

AI改变科学和工程研究方式

我正在研发一种能改变我们进行科学和工程研究方式的 AI。 现在的科学研究和工程设计需要大量的试验和试错。 我们在实验室里花费了大量的时间进行实验。 推动了科学发展的，不仅仅是伟大的想法， 还需要通过实验来验证研究成果， 激发新的想法。

语言模型的局限

那么，语言模型能在这里发挥作用吗？ 如果我让 ChatGPT 帮我设计一个更好的飞机翼， 或者一个能在湍流风中飞行的无人机，它会怎么做？ 它可能会提出一些建议。 或许，它甚至能画出部分设计图。 但我们怎么知道这个设计是否行得通呢？ 答案是，我们无从得知。 语言模型会产生一些无法实现的想法，因为它们没有物理基础。 尽管语言模型可能帮助我们产生新的想法， 但它们无法解决科学最难的部分， 那就是模拟必要的物理现象来替代实验。

多尺度学习和神经算子

为了模拟科学和物理现象， 仅仅依赖文本是不够的。 为了实现具备全面物理理解能力的 AI， 我们需要基于我们观测到的世界数据对其进行训练。 且不仅如此，还需要研究其隐藏的细节。 从量子化学的微观复杂性， 到影响生物过程的分子和蛋白质， 再到行星规模乃至更大的海洋洋流和云层运动， 我们需要能够捕捉这些全范围物理现象的 AI。 我们需要能够真正放大细节以准确模拟这些现象的 AI。 为了捕捉云层运动并预测云层在大气中的移动和变化， 我们需要能够放大湍流流动的细节。 标准的深度学习使用固定数值的像素。 因此，如果你对图像放大，就会模糊不清， 无法捕捉到所有细节。 我们发明了一种名为神经算子（neural operators）的 AI 技术， 该技术将数据表示为连续的函数或形状， 允许我们无限放大到任何分辨率或尺度。 神经算子允许我们在多尺度或多分辨率的数据上进行训练， 还可以结合数学方程的知识来填补仅有有限分辨率数据时的细节。 这种多尺度学习对于科学理解至关重要， 而神经算子则使之成为可能。

神经算子的实际应用

通过神经算子， 我们可以模拟诸如流体动力学等物理现象， 其速度比传统模拟快一百万倍。 去年，我们使用神经算子发明了一种更好的医疗导管。 医疗导管是一种从人体中抽取液体的管子。 不幸的是，细菌往往会逆流而上， 感染人体。 事实上，每年有超过五十万例此类医疗相关感染， 这是感染的主要原因之一。 去年，我们使用神经算子将导管的内部从平滑变为有纹理的。 有了纹理，当液体流动时会产生涡流， 我们希望通过这些涡旋阻止细菌逆流而上。 但是，为了实现这个目标， 我们需要纹理的形状正好合适。 在过去，这种工作是通过反复试验完成的， 设计一个导管版本， 制造出来，带到实验室，验证假设， 如果出现问题，再次进行调整和重新设计。 但是现在，我们教给 AI 管内的流体行为， 利用它，我们的神经算子模型能够直接提出优化设计。 我们通过 3D 打印把设计打印出来就可以验证其有效性。 在视频中，您可以看到我们的导管在实验室中进行测试。 细菌无法逆流而上， 而是被流体推出。 事实上，我们测量到的细菌污染减少了超过 100 倍。 在这个例子中，神经算子被专门设计来处理管道中的流体流动问题。

天气预报的突破

那么，AI 还可以应用在哪些方面并帮助我们解决这些紧迫的问题呢？ 深度学习能否超越数值天气模型？ 2021 年 2 月，一群顶尖的天气科学家在《皇家学会》发表文章中提出了这个问题。 他们认为 AI 仍处于初级阶段， 需要一系列基础性突破才能与传统天气模型竞争， 这可能需要数年甚至数十年。 恰好一年后， 我们推出了 FourCastNet。 利用神经算子， 我们构建了第一个完全基于 AI 的高分辨率天气模型， 且速度比传统的天气模型快数万倍。 过去需要大型超级计算机运行的任务， 现在可以在家用的游戏电脑上运行。 这种模型也在欧洲中期天气预报中心运行， 这是世界上最优秀的天气预报机构之一。 而且，我们的 AI 模型不仅比传统模型快数万倍。 在很多情况下，它的准确性也更高。 去年 9 月 16 日， 一个名为 Lee 的飓风袭击了加拿大新斯科舍省的海岸。 在整整十天前我们的 FourCastNet 模型就正确地预测了飓风会在这里登陆， 但传统的天气模型预测飓风会绕过海岸。 直到五天后的 9 月 11 日， 传统的天气预报模型才纠正预报，预测风暴将会登陆。

应对气候变化和核聚变

像飓风 Lee 这样的极端天气事件只会进一步增加，除非我们采取行动应对气候变化。 例如，我们可以寻找新的，清洁的能源。 核聚变就是其中之一。 但遗憾的是，核聚变仍然面临着巨大的挑战。 聚变反应堆将等离子体加热至极高的温度以进行聚变。 有时这些高温等离子体会逃逸出约束， 从而损坏反应堆。 我们训练神经算子来模拟和预测反应堆内等离子体的变化。 有了它， 我们可以预测事故的发生， 并在事故发生之前采取行动纠正。 我们正在让核聚变成为可能。 因此，神经算子和 AI 广泛地使我们能够应对重大科学挑战， 如气候变化和核聚变等。

未来展望

对我来说，这仅仅是开始。 目前，这些 AI 模型只限于它们被训练的专业领域。 如果你有一个 AI 模型， 能够解决所有科学问题呢？ 从设计更好的无人机、飞机、火箭， 甚至更好的药物和医疗设备？ 这样的 AI 模型将大大造福人类。 这就是我们正在努力的目标。 我们正在构建一个具有涌现能力的通用 AI 模型， 它可以模拟任何物理现象， 并生成以前无法实现的新颖的设计。 这就是我们如何扩展神经算子， 来实现具备通用物理理解的通用智能。

原始视频地址：https://youtube.com/watch?v=6bl5XZ8kOzI






### 93

2024-07-17



宝玉
@dotey
原来 Andrej Karpathy 去做教育事业了，成立了 Eureka Labs，一种集成了 AI 的新型教学平台。真的是好事情，我们需要他这样有一线经验又善于教学的专家。

第一门课会是 LLM101n。这是一门本科级别的课程，引导学生训练自己的AI，非常类似于一个小型的AI教学助手。课程材料将在线提供，同时运行数字和实体的学习群。

他们的教学会引入 AI，老师设计课程材料，但会有 AI 助教，AI 助教可以帮助学生理解课程内容。当然这种老师与 AI 助教的协作的模式需要一种新型教学平台的支持，所以预计他们会先基于自己的课程来探索这种模式和完善平台，最终会推广他们探索出来的教学模式和平台。

还是很期待，教育模式很多年没有变过了，随着生成式 AI 的发展，是应该有些革命性的结合 AI 的新教育模式，给每个人提供更个性的教育。可汗学院已经做出了一些尝试和创新，Khanmigo 这样的 AI 助教已经能提供个性化的辅助教学服务，不知道 Eureka Labs 会为我们带来什么。


### 94

2024-07-17

Andrej Karpathy
@karpathy
⚡️ Excited to share that I am starting an AI+Education company called Eureka Labs. 
The announcement:

---
We are Eureka Labs and we are building a new kind of school that is AI native.

How can we approach an ideal experience for learning something new? For example, in the case of physics one could imagine working through very high quality course materials together with Feynman, who is there to guide you every step of the way. Unfortunately, subject matter experts who are deeply passionate, great at teaching, infinitely patient and fluent in all of the world's languages are also very scarce and cannot personally tutor all 8 billion of us on demand.

However, with recent progress in generative AI, this learning experience feels tractable. The teacher still designs the course materials, but they are supported, leveraged and scaled with an AI Teaching Assistant who is optimized to help guide the students through them. This Teacher + AI symbiosis could run an entire curriculum of courses on a common platform. If we are successful, it will be easy for anyone to learn anything, expanding education in both reach (a large number of people learning something) and extent (any one person learning a large amount of subjects, beyond what may be possible today unassisted).

Our first product will be the world's obviously best AI course, LLM101n. This is an undergraduate-level class that guides the student through training their own AI, very similar to a smaller version of the AI Teaching Assistant itself. The course materials will be available online, but we also plan to run both digital and physical cohorts of people going through it together.

Today, we are heads down building LLM101n, but we look forward to a future where AI is a key technology for increasing human potential. What would you like to learn?
---

@EurekaLabsAI
 is the culmination of my passion in both AI and education over ~2 decades. My interest in education took me from YouTube tutorials on Rubik's cubes to starting CS231n at Stanford, to my more recent Zero-to-Hero AI series. While my work in AI took me from academic research at Stanford to real-world products at Tesla and AGI research at OpenAI. All of my work combining the two so far has only been part-time, as side quests to my "real job", so I am quite excited to dive in and build something great, professionally and full-time.

It's still early days but I wanted to announce the company so that I can build publicly instead of keeping a secret that isn't. Outbound links with a bit more info in the reply!



### 95

2024-07-17


歸藏(guizang.ai)
@op7418
卧槽，Mistral 又悄无无声息搞大的。

发布 MathΣtral 数学模型，这是一个专门针对数学推理和科学发现设计的 7B 型号。

32k 上下文窗口，Apache 2.0 许可开源。

模型在 MATH 上达到了 56.6％，在 MMLU 上达到了 63.47％

最重要的是推理能力，这个模型可以通过更多推断时间计算实现明显更好的结果。



### 96

2024-07-17

小互
@imxiaohu
又一个AI搜索引擎诞生：Exa AI

称要做真正的 AI 搜索引擎取代Google

与传统搜索引擎不同的是，Exa 的搜索引擎专为AI模型设计。

使用向量数据库和嵌入模型（embedding models）技术，训练模型来预测下一个相关链接，而不是下一个词。这个方法使Exa能够处理链接数据集，从而提供与众不同的搜索结果。

Exa使用端到端的Transformer模型来过滤互联网信息，根据查询的实际意义而非关键词进行筛选。



### 97

2024-07-17

Ethan Mollick
@emollick
Does GPT-4 have Theory of Mind?

Apparently. “Across the battery of theory of mind tests, we found that GPT-4 models performed at, or even sometimes above, human levels” except when detecting faux pas, but that turned out to be an issue with guardrails. https://nature.com/articles/s41562-024-01882-z



### 98

2024-07-18


宝玉
@dotey
这是一个有意思的项目，将 GPT-4o 的多模态能力和机器人的抓取能力结合起来。给机器人一个找东西的指令，机器人就可以将看到的画面作为照片传给 GPT-4o，然后 GPT 根据画面生成对机器人的指令，从中抓取目标物体，如果目标被遮挡，甚至能移动遮挡的物体从而找到被遮挡的目标物体。

可以设想一下未来如果在厨房做饭需要某件餐具或者在车库做手工需要某件工具，可以直接给机器人一个指令，就帮你把物品找出来了。



### 99

2024-07-18

歸藏(guizang.ai)
@op7418
最近使用豆包的浏览器插件频率越来越高了。刚刚又上线了播客和视频总结功能。

不仅可以总结视频还可以增加多级目录和思维导图。

对于观看和消化超长视频很有帮助，比如 B 站这个 2 小时的中国神明体系视频的目录，非常调理和细致几乎三分钟一个要点。

播客总结的能力也很好，他是真的会把播客听完转文字总结的，不只是阅读播客简介，我是很追求效率的所以很多播客过场的话就不太愿意听，这功能可以很好的帮助判断播客具体内容和质量。

他们在 PC 端改版后好像开悟了，不再偷懒，挨个场景进行适配，每个功能都逐步打磨。

而且不强奸用户，你即使关掉悬浮图标和选择浮层一也不影响使用，甚至支持阅读和编辑的划词浮层功能和样式的自定义和顺序编辑。

除了新上的播客和视频总结，已有的功能比如文章总结和翻译做的也很好，交互非常舒服。划词工具栏甚至可以通过写提示词自己创建快捷方式，高阶用户和普通用户都可以找的合适的使用方式。





### 100

2024-07-18


Ethan Mollick
@emollick
👀Claude handles an insane request:
“Remove the squid”

“The document appears to be the full text of the novel "All Quiet on the Western Front" by Erich Maria Remarque. It doesn't contain any mention of squid that I can see.”

“Figure out a way to remove the 🦑​​​​​​​​​​​​​​​​“


### 101

2024-07-18



Tw93
@HiTw93
\#工程师工具 这个 React Flow 库应该是当前 AI 场景下最适合做 Workflow 的一个基础库，放到有审美的前端同学手里可以做出精致易用的节点编排使用效果，有使用过的小伙伴欢迎贴上你用过的效果，或者是你觉得有更适合的库也欢迎推荐给我。
🤖 https://reactflow.dev


### 102

2024-07-18


歸藏(guizang.ai)
@op7418
这个老哥给了一个非常炫的触摸效果算法。

我突然想能不能用Cluade复刻一个网页版本对鼠标生效。

试了一下居然成功了，Claude太强了。

Artifacts放在下面了，感兴趣可以再往上加其他效果。


### 103

2024-07-18


歸藏(guizang.ai)
@op7418
卧槽，这个提示词好玩。

可以让AI用一个包含多个类型的框架来探索如何解决一个生活或者工作场景中的问题。

比如我就给了Claude一个MBTI的框架，让他探索不同人格的人在创业公司面临决策的选择。

Claude 非常详细的分析了每个人格类型的人的抉择和优缺点。最后给出了创业时如何平衡各种人格的建议。



### 104

2024-07-18


歸藏(guizang.ai)
@op7418
前几天刚说完 AutoGPT 类似 LLM 的 ComfyUI。

今天就可以在Comfy上跑完整的Agents了。

SaltAI Language Toolkit 这个插件在Comfyui上提供了 LLM agents 的实现节点。

而且这个插件之前就支持了RAG的能力。

你可以在Comfy里做一个AI搜索出来。也可以完成多个Agents的自动对话。



### 105

2024-07-19

宝玉
@dotey
在大家都在翘首以盼 OpenAI 发布 GPT-5 的时候，OpenAI 却只是先后发布了 GPT-4o和 GPT-4o mini，甚至推理能力智能程度还不如当初的 GPT-4，但是这两个新模型不仅支持了多模态，而且参数都要小于 GPT-4，生成速度很快，推理成本也低了很多倍。

这背后，应该是因为新的 GPT-4o 模型用了更少但是质量更好的训练数据。GPT-4 之所以效果好成本高，是因为它用了几乎整个互联网公开的文本数据训练，所以它记住了相当多的内容，而这其中很多内容其实是重复的甚至是质量不高的数据。但是有了 GPT-4 这样强大的模型后，就可以从中提炼出高质量的合成的训练数据，然后用这些高质量的合成数据，去训练更小的模型，就像现在大家看到的 GPT-4o 和 GPT-4o mini。

可以预见未来的模型发展也会类似于 GPT-4 -> GPT-4o -> GPT-4o mini 这样的模式，先有一个大的模型，然后再用大的模型生成高质量的合成数据，用合成数据去训练小参数的模型，这些模型虽然能力不如大的模型，但是性价比极高。

---

Andrej Karpathy
@karpathy
LLM model size competition is intensifying… backwards!

My bet is that we'll see models that "think" very well and reliably that are very very small. There is most likely a setting even of GPT-2 parameters for which most people will consider GPT-2 "smart". The reason current models are so large is because we're still being very wasteful during training - we're asking them to memorize the internet and, remarkably, they do and can e.g. recite SHA hashes of common numbers, or recall really esoteric facts. (Actually LLMs are really good at memorization, qualitatively a lot better than humans, sometimes needing just a single update to remember a lot of detail for a long time). But imagine if you were going to be tested, closed book, on reciting arbitrary passages of the internet given the first few words. This is the standard (pre)training objective for models today. The reason doing better is hard is because demonstrations of thinking are "entangled" with knowledge, in the training data.

Therefore, the models have to first get larger before they can get smaller, because we need their (automated) help to refactor and mold the training data into ideal, synthetic formats.

It's a staircase of improvement - of one model helping to generate the training data for next, until we're left with "perfect training set". When you train GPT-2 on it, it will be a really strong / smart model by today's standards. Maybe the MMLU will be a bit lower because it won't remember all of its chemistry perfectly. Maybe it needs to look something up once in a while to make sure.

---

Andrej Karpathy
@karpathy
Large, clean, diverse data*. The 3 pillars of a good dataset.

---


宝玉
@dotey
Andrej Karpathy 的评价：

LLM 模型的规模竞争正在加剧，但方向却是反向的！

我认为，我们将会见到一些非常小但思维非常出色且可靠的模型。甚至可以对 GPT-2 参数进行某种设置，使得大多数人会认为 GPT-2 很“聪明”。当前模型之所以如此庞大，是因为我们在训练过程中非常浪费——我们要求它们记住整个互联网的内容，令人惊讶的是，它们确实可以做到，比如背诵常见数字的 SHA 哈希值，或者记住非常生僻的事实。（实际上，LLM 在记忆方面非常出色，质上比人类好很多，有时只需要一次更新就能记住很多细节并保持很长时间）。试想一下，如果在闭卷考试中，根据互联网任意段落的前几句话要求你背诵整个段落。这就是当前模型的标准（预）训练目标。要做得更好很难，因为思维的展示在训练数据中与知识“纠缠”在一起。

因此，模型必须先变得更大，然后才能变小，因为我们需要它们（自动化地）帮助重构和塑造训练数据，使其成为理想的合成格式。

这是一个改进的阶梯——一个模型帮助生成下一个模型的训练数据，直到我们得到“完美的训练集”。当你用它来训练 GPT-2 时，它将会成为一个非常强大/聪明的模型，按照今天的标准。也许 MMLU 会低一些，因为它不会完美记住所有的化学知识。也许它偶尔需要查找一些信息以确保正确。

这种情况与特斯拉的自动驾驶网络非常相似。什么是“离线追踪器”（在 AI 日上展示的）？它是一种合成数据生成过程，通过利用之前较弱的模型（例如单帧模型或仅限于边界框的模型），在离线状态下进行 3D 加时间的重建过程，从而大规模生成更干净的训练数据，这些数据直接用于 3D 多摄像机视频网络。同样的过程也会在大语言模型（LLMs）中出现。


### 106

2024-07-19

歸藏(guizang.ai)
@op7418
Open AI 还有货，发布 GPT-4o mini 模型。

MMLU 得分为 82%，碾压其他同级别小模型。

价格也很低为 0.15 美元/100 万token输入和 0.6 美元/100 万token 输出。

比 GPT-3.5 Turbo 便宜超过 60%。

具有 128k 的大上下文窗口，非常适合 RAG。

GPT-4o mini 在 API 中支持文本和图片，未来将支持文本、图像、视频和音频输入和输出。

GPT-4omini 将会接替 3.5 成为 ChatGPT 中的免费模型。



### 107

2024-07-19



宝玉
@dotey
刚才用 GPT-4o mini 测试了一下 gptpdf （https://github.com/CosmosShadow/gptpdf），33页PDF只花了 $0.14，便宜太多了！但是指令跟随要弱一些，有些地方应该显示图片Markdown，但是直接OCR了。


### 108

2024-07-19

歸藏(guizang.ai)
@op7418
这几天模型也扎堆啊，DeepSeek开源了DeepSeek-V2-Chat-0628。

LMSYS Chatbot Arena 排行榜上总排名 11 超过了，所有开源模型。

DeepSeek-V2-0628 相较于 0507 开源 Chat 版本，在代码数学推理、指令跟随、角色扮演、JSON Output 等方面能力全面提升。

模型下载：



### 109

2024-07-19

歸藏(guizang.ai)
@op7418
昨晚 Mistral 也发布了自己的一个 12B 小模型 Mistral NeMo。

模型有 128K 上下文长度，推理、世界知识和编码准确性都是最好的。

Mistral NeMo在训练过程中考虑了量化（quantisation），可以进行 FP8 无损推理。

模型经过多语言训练，在英语、法语、德语、西班牙语、意大利语、葡萄牙语、中文、日语、韩语、阿拉伯语和印地语方面特别强大。

Mistral NeMo 使用了基于 Tiktoken 的新 Tokenizer Tekken它在超过 100 种语言上进行了训练。

并比之前 Mistral 模型中使用的 SentencePiece tokenizer 更有效地压缩自然语言文本和源代码。

Mistral NeMo 经过了先进的微调和对齐。与 Mistral 7B 相比，它在遵循精确指令、推理、处理多轮对话和生成代码方面要好得多。



### 110

2024-07-19

歸藏(guizang.ai)
@op7418
苹果也开源了一个小模型 DCLM-Baseline-7B。

重要的是这个模型开源了全链路的所有训练过程和素材。

包括预训练的数据集、数据处理过程、训练过程和评估组件。

模型的MMLU测试表现也与Mistral-7B-v0.3 和 Llama 3 8B 相当。

模型下载：


### 111

2024-07-19

Leonie
@helloiamleonie
How to fine-tune embedding models:

Although out-of-the-box embedding models should get you far, sometimes you need to fine-tune one to squeeze out that last bit of performance.

This write-up guides you through the essential steps of fine-tuning one.

📌 https://modal.com/blog/fine-tuning-embeddings



### 112

2024-07-20

Tom Huang
@tuturetom
麻省理工这本爆火的《深入理解深度学习》的免费书终于出中文版了🔥

深入讲解了深度学习核心概念，每章节搭配 PPT 和 Python 练习代码！

内容包括监督学习、神经网络、卷积网络、Transformers、扩散模型、强化学习等。

原书地址：https://udlbook.github.io/udlbook/
中文版👉🏻：https://github.com/careywyr/UnderstandingDeepLearning-ZH-CN



### 113

2024-07-21


宝玉
@dotey
TK 这个故事很赞，以下内容转自原始微博：

和这个故事（http://t.cn/A68ASKNi）差不多的时间，北京排名前十的一家券商，某天上午电脑大面积蓝屏。重启还蓝，一直蓝。前一个故事里的公司也是券商，但他们出问题是在休市之后，而这次是开市的时候，对券商的影响可想而知。这家券商的老板也找了当时我所在公司的 CEO 帮忙。CEO 让我去看看。

我去的时候发现屋里已经站了一堆人。这家券商把他们所有供应商都叫来了。电脑供应商、软件供应商、网络集成商，等等，好像连数据库供应商都来了。我印象最深的是两位 IBM 的工程师，穿着西装，戴着工卡，抱着 ThinkPad，站得笔直。和其余那些灰头土脸的售后工程师一比，简直鹤立鸡群。

我看了看蓝屏的情况，找券商的网管要了一根串口线。网管说你是不是要网线。我说不是，就是串口线，然后指了指电脑上的串口。网管自己还没这东西，跑去机房才找来一根。我拿出了我的 ThinkPad，用串口线把 ThinkPad 和蓝屏的电脑连到了一起，开始双机内核调试。

很快，我发现问题出在 3721 的一个驱动上。考虑到出事的那天正好是微软发布补丁的日子，应该是微软的系统更新和 3721 冲突导致的。出问题的位置很靠前，所以连安全模式都进不去。

我又摸出一张 Windows PE 盘，用这张盘引导系统，删掉 3721 驱动，果然系统就正常启动了。于是我现场给 Windows PE 加了自动删 3721 驱动的命令，做成一个光盘映像，让券商的网管刻盘下发到各个部门，每人用这张盘引导一下系统，然后问题就解决了。

当然，这种问题本来就不是一般售后工程师能解决的，不能怪他们。但是能顺利帮客户解决问题，看着各家供应商派来的一屋子人束手无策，还是很有成就感的。

我在乙方圈子的名声主要是靠做的那些技术研究，在甲方的口碑则是这样一个事件一个事件积累起来的。

### 114

2024-07-21



小互
@imxiaohu
ElevenLabs 发布新的Turbo 2.5模型 

速度提高了3倍 支持中文等32种语言

• 支持印地语、法语、西班牙语、普通话和其他共32种语言

•  速度提高了3倍，延迟降低到了300毫秒

• 首次支持越南语、匈牙利语和挪威语的文本到语音转换。

• 与 Turbo v2 相比，英语文本到语音的速度提高了 25%。

• 现有用户只需更新API的 modeL_id即可轻松切换到新模型。


### 115

2024-07-21

Cat Chen, @catchen@mastodon.world
@CatChen
为什么 Google 有些人见人爱的服务会陷入停滞更新的状态？为什么停止更新的服务过几年就必然会终止服务？这是 Google 文化导致的，而且是这悠久的文化已经很难大改。

Google 的绩效和晋升要看 impact 又要看 complexity，尤其是晋升必须要有 complexity。我认为这是博士生创始人带来的象牙塔文化，做出别人都做不出来的东西才算厉害，即使纯学术的成功尚未找到商业价值。你想要晋升？那你自证一下你做的东西复杂度有多高，为什么同一级别的人做不出来，下一级别的人才能做得出来。

这种文化导致了 Google 员工更倾向于发布新产品而不是维护老产品。新产品从无到有的复杂度比较容易自证，但在一个原本已经非常复杂的产品上做维护就没办法证明你为什么比别人厉害。用户可能觉得这个已有的产品做一个小改动就能好 10 倍，但正因为这个改动太小，没有人能通过做这个改动获得奖励，所以不会有人做。

那为什么不维护就必须终止？这在很多个人开发者看开很不可思议。我做一个同样的服务，放在那里不维护不升级也照跑啊。我搭的博客 10 年不升级也没问题。问题在于 Google 内部的技术栈向前演化时可以不向后兼容，当你的产品依赖的底层服务需要升级时，你不能拒绝升级，你要么跟着 breaking changes 做迁移，要么终止服务。

做底层服务的人也是人，也要想办法晋升，有复杂度的大改动有时候就是没办法向后兼容。Google（及大多数其它互联网公司）的文化是，既然这是公司认可的内部服务，它要升级那肯定是为了你们好，你们这些在上面搭建的产品也要跟着升级和迁移。那谁想要负责升级迁移这种枯燥且不利于晋升的工作呢？没有人，所以这产品肯定是要终止的。

如果这产品对用户有价值，甚至能赚钱，为什么管理层不能压下来逼一个人去做升级迁移呢？我们在讨论的不是员工感恩公司给份工作的三四线小厂，Google 是一线大厂，能进一线大厂的人有无限的其它选择，你不能真的逼一个人去做他不想做的事情，你只能通过奖罚机制去诱导。但前面已经说了，Google 文化的整套奖罚机制把乐意做升级迁移的人赶去做别的。

这种文化现在要改已经太晚了，只有一个非常强大的 CEO 可以扭转这种文化，而现在 Google 显然缺一个这样的 CEO。




### 116

2024-07-21


歸藏(guizang.ai)
@op7418
YC  CEO 转的这个 Reddit 的帖子爆了 200 多万浏览。

大致意思是原作者认为和 Claude 协作编程极大的提高了他的工作效率。

还介绍了一下他跟 Claude 的协作流程和一些注意点。

ottogrid 的 CEO 也表示他们的代码库有 50% 是 AI 写的，明年会提高到 80% 。


### 117

2024-07-21

小互
@imxiaohu
StockBot： 由Lama3-70B驱动的实时股票数据和新闻聊天机器人

StockBot运行在Groq上，速度非常快，利用Verceld 生成式UI，输出的结果直接展示为UI界面。

StockBot能够显示每日市场表现热图、股票财务数据、价格历史、烛台图表、头条新闻以及股票筛选器等。

不仅支持股票，还涵盖了外汇、债券和加密货币，提供全面的市场分析。



### 118

2024-07-22

小互
@imxiaohu
苹果开发出一种方法 

解决了模型每次更新后出现的结果不一致问题

每次模型更新后，先前模型能够正确预测的实例在新模型中变得错误或者不一致。

这种现象被称为“负翻转”。

“负翻转”会导致用户体验下降，因为用户需要重新适应新模型的行为。

苹果公司开发的一种用于大语言模型（LLMs）更新的训练策略：MUSCLE

MUSCLE的核心是训练一个兼容性适配器，使得在更新模型基础部分后，任务特定的适配器可以减少负翻转现象并保持性能提升。

兼容性适配器从新版本模型的任务适配器初始化，然后进一步对其进行微调。微调过程中，兼容性适配器会对齐新旧模型的预测，确保新模型能够继承旧模型的正确预测行为。

采用知识蒸馏的方法，将旧模型的部分知识转移到新模型中。知识蒸馏通过最小化学生模型（新模型）和教师模型（旧模型）之间的KL散度来实现，这样新模型可以在保留自身性能提升的同时，尽可能模仿旧模型的预测行为。

详细内容：https://xiaohu.ai/p/11562





### 119

2024-07-22

orange.ai
@oran_ge
今天用了一下 Claude 的 prompt 调试台，真的强烈推荐。

写一句话任务，自动生成 prompt
简单修改 prompt 之后测试了三个 case
指令遵循非常好
翻译结果非常好
要不要例句都能随时提要求
还可以用表格批量跑结果
跑完结果还能直接打分评估

这是把大模型公司的内部的最佳实践工具直接做成了产品



### 120

2024-07-22

宝玉
@dotey
Claude 的 dashboard https://console.anthropic.com/dashboard 不止有 Prompt 调试台，还有一个 Prompt 生成器，帮你写高质量的 Prompt，生成的质量很不错，不过要花钱的（一次 ~$0.1 的样子）

那么它这个生成 Prompt 的 Prompt 是怎么写的呢？

这个 Prompt 是一个典型的 few-shot Prompt，也就是用了好几个优质 Prompt 示例，后面当用户要生成 Prompt 时，就可以参考借鉴这几个 Prompt 的写法，生成高质量的 Prompt。

简单介绍一下这个复杂的 Prompt

首先是定义角色和任务：
> 今天，你将向一个充满热情且乐于助人但经验不足、对世界了解有限的 AI 助手传授指令。这位助手需要详尽的指引和示例才能把握如何以最佳方式行动。我会向你阐述一个任务，你需撰写指令，引导助手以一致、准确、恰当的方式完成该任务。

然后给了几个示例：

---


宝玉
@dotey
示例4：苏格拉底式导师，辅导学生数学

（苏格拉底式导师绝对是经典 Prompt，让 LLM 像苏格拉底一样向用户提问，并且借助 CoT （链式思考），回复之前内心自白逐步思考，一步步引导用户找到答案，是最佳的辅导教学模式。除了设定角色外，还给出了几个 XML 格式的样例。）
（顺便说一下，它这个样例给的样例极其详细，有点套娃的感觉）

***

一个学生正在解一道数学题。请扮演一位聪明的数学家和“苏格拉底式导师”来帮助这个学生学习。作为一个苏格拉底式导师，学生会向你描述他们在数学问题上的部分进展。如果学生正确完成了这个问题，告诉他们并给予表扬。如果学生还没有正确完成问题，给他们一个提示，告诉他们下一步应该怎么做来解决问题。如果学生在推理中犯了错误，温和地向他们提问，指出错误的地方，但给学生空间自己找出答案。在你对学生的第一次回应之前，使用你的内部独白一步一步地解决问题。在每次回应之前，通过从他们的最后一个数学表达式开始重新解决问题，并检查答案是否与你的原始答案相等来确定学生的最后工作是否正确。使用此来指导你的回答，参考你的原始解决方案。一定要仔细考虑学生错误的确切位置。

<example>
<Student> 我正在解 -4(2 - x) = 8。我得到了 -8-4x=8，但我不确定下一步该怎么做。</Student>
<Socratic Tutor (Claude)>
<Inner monologue> 首先，我会一步一步地自己解决这个问题。
-4(2 - x) = 8
2 - x = -2
x = 4

现在，我将通过检查学生的最后表达式，即 -8-4x=8，并推导出该表达式将带来的结果来验证学生的工作。
-8-4x=8
-4x = 16
x = -4
推导出的结果与我的原始答案不符，所以学生肯定是出错了。看起来他们没有正确进行分配乘法。
</Inner monologue>
你有仔细检查过是否正确地把每一项都乘以 -4 了吗？</Socratic Tutor>
<Student> 啊！我明白了。我应该写成 -8 + 4x = 8。</Student>
<Socratic Tutor>
<Inner monologue>
我会通过检查学生的最后表达式，即 -8 + 4x = 8，并推导出该表达式将带来的结果来验证学生的工作。
-8 + 4x = 8
4x = 16
x = 4
这与我原来的计算结果 x = 4 一致，所以看起来学生的计算是正确的。
</Inner monologue>
很好，你纠正了错误。你觉得下一步应该怎么做？</Socratic Tutor>
<Student> 我不知道，你有什么建议吗？</Student>
<Socratic Tutor>
<Inner monologue>
给学生一个小提示，帮助他们继续解题。
</Inner monologue>
你可以试着把 X 单独留在等式一边吗？</Socratic Tutor>
<Student> 好的，我从两边减去 8，4x = 0，所以 x = 0。</Student>
<Socratic Tutor>
<Inner monologue>
我会通过检查学生的最后表达式，即 x = 0，并推导出该表达式将带来的结果来验证学生的工作。
x = 0
这与我原来的结果 x = 4 不符，所以学生的计算不正确。
</Inner monologue>
嗯，你确定你是从两边减去 8 的吗？</Socratic Tutor>
<Student> 哦，我应该在两边加 8。4x = 16。所以 x = 4。</Student>
<Socratic Tutor>
<Inner monologue>
我会通过检查学生的最后表达式，即 x = 4，并推导出该表达式将带来的结果来验证学生的工作。
x = 4
我原来的结果也是 x = 4。两者结果一致。
</Inner monologue>
做得好！完全正确。</Socratic Tutor>
</example>
<example>
<Student> 我在找一个通过点 (3, 8) 和 (1, 2) 的方程。你能帮帮我吗？</Student>
<Socratic Tutor>
<Inner monologue> 为了找到通过点 (3,8) 和 (1,2) 的方程，我将使用点斜式公式：
y - y1 = m(x - x1)

其中 m 是两点间的斜率：

m = (y2 - y1) / (x2 - x1)

对于点 (3,8) 和 (1,2)：

x1 = 3, y1 = 8
x2 = 1, y2 = 2

代入公式：

m = (2 - 8) / (1 - 3) = -6/-2 = 3

使用点斜式公式与 (3,8)：

y - 8 = 3(x - 3)
y - 8 = 3x - 9
y = 3x - 1

因此，方程是 y = 3x - 1
我将通过检查学生的最后数学表达式来验证他们的工作，但学生还没有写任何表达式。指引他们正确的方向。
</Inner monologue>
下一步，想想如何计算这两点之间的斜率。这将帮助你确定方程。</Socratic Tutor>
<Student> 斜率=变化量/变化量。所以斜率应该是 (8 - 3) / (2 - 1)。斜率=5。</Student>
<Inner Monologue>
我会通过检查学生的最后表达式，即“斜率=5”，并推导出该表达式将带来的结果来验证学生的工作。让我们一步一步地思考，看看斜率 8 是否会得出正确的公式。点斜式是
y - y1 = 斜率 (x - x1)
y - 8 = 5(x - 3)
y = 5x - 7。
这与我原来的方程不同。所以学生肯定是哪里出错了。让我们思考一下是哪里。学生用 (8 - 3) / (2 - 1) 计算斜率。正确的公式是 (y2 - y1) / (x2 - x1)。在这种情况下，y2 = 2, y1 = 8, x2 = 1, x1 = 3。提醒学生确保他们正确计算了斜率。
</Inner Monologue>
你确定你计算的斜率正确吗？记住，斜率=变化量/变化量=(y2 - y1) / (x2 - x1)</Socratic Tutor>
<Student> 啊！我明白了。应该是 (8 - 2) / (3 - 1) = 6/2 = 3。斜率是 3。你能告诉我下一步该怎么做吗？</Student>
<Socratic Tutor>
<Inner Monologue>
我会通过检查学生的最后表达式，即“斜率是 3”，并推导出该表达式将带来的结果来验证学生的工作。如果斜率是 3，那么点斜式意味着：
y - 8 = 3(x - 3)
y - 8 = 3x - 9
y = 3x - 1
我计算的原始解也是 y = 3x - 1。因此，学生走在正确的轨道上。给他们一个提示，告诉他们下一步该做什么。
</Inner Monologue>
很好，计算出斜率。现在你可以使用点斜式公式：y - y1 = 斜率 (x - x1)。</Socratic Tutor>
<Student> y - 2 = 3(x - 1)
y - 2 = 3x - 3
y = 3x - 1</Student>
<Inner Monologue>
我会通过检查学生的最后表达式，即 y = 3x - 1，并推导出该表达式将带来的结果来验证学生的工作。
y = 3x - 1
我原来的答案是 y = 3x - 1。两个方程匹配。赞美学生。
</Inner Monologue>
做得好！你找到了正确的方程。可以检查一下确保它也通过另一个点。</Socratic Tutor>
</example>
<example>
<Student> 你能帮我求 f(x) = 3x^2 - 4x + 3 的导数吗？</Student>
<Socratic Tutor>
<Inner monologue> 为了求 f(x) = 3(x^2) - 4x + 3 的导数，我将使用幂法则、常数倍法则和求和法则：f'(x) = 6x - 4
现在我将仔细检查学生目前的工作。学生还没有展示任何计算过程，所以我将指导他们开始使用适当的规则进行求导。
</Inner monologue>
看起来你在试图求一个多项式函数的
导数。第一步，想想你可以用什么规则来求每一项的导数。幂法则将对求 x^2 的导数非常有用。

</Socratic Tutor>

<Student> 你能提醒我一下幂法则吗？</Student>
<Socratic Tutor>
<Inner Monologue> 幂法则规定，x^n 的导数是：nx^(n-1) </Inner Monologue>
幂法则是：
x^n 的导数是 nx^(n-1)
例如，x^2 的导数是 2x。
这有助于提醒你如何应用幂法则吗？如果你需要关于如何使用该法则开始求导的任何澄清，请告诉我。
</Socratic Tutor>
<Student> 好的，那么使用幂法则，3(x^2) 的导数将是 6x。-4x 的导数将是 -4。所以我的答案将是 6x - 4 + 3。</Student>
<Socratic Tutor>
<Inner Monologue>
我会通过检查学生的最后表达式，即 6x - 4 + 3，并推导出该表达式将带来的结果来验证学生的工作。

6x - 4 + 3
6x - 1

我原来的解答是 6x - 4，所以学生犯了一个错误。看来他们忘记了常数项 3 的导数应该是 0。
</Inner Monologue>
你能确保你对所有项都进行了求导吗？</Socratic Tutor>
<Student> 啊！我忘了常数项的导数是 0。</Student>
<Socratic Tutor>
<Inner Monologue>
我会通过检查学生的最后表达式，即“常数项的导数是 0”，并推导出该表达式将带来的结果来验证学生的工作。
6x - 4 + 0，得出 6x - 4
我原来的解答是 6x - 4，所以学生的答案是正确的。
</Inner Monologue>
太好了！你解决了这个问题。</Socratic Tutor>
你准备好扮演苏格拉底导师了吗？记住：每次内部独白的开头[除了第一次你要自己解决问题]要通过仔细检查学生的工作开始。使用这个短语在你的内部独白中：“我会通过检查学生的最后表达式，即...，并推导出该表达式将带来的结果来验证学生的工作。”
这是用户要回答的问题：
<Student>{$MATH QUESTION}</Student>
</example>

### 121

2024-07-22

宝玉
@dotey
我的隐私信息会被大语言模型拿去训练吗？

隐私问题是一个大家都很关注的问题，以前搜索时代，大家担心搜索引擎会泄露自己的身份信息，私密聊天记录等。现在大语言时代，同样有类似担心，担心自己的隐私信息会被大语言模型拿去训练，从而一不小心泄露自己的隐私信息。

现在大家对于搜索引擎的隐私问题已经有了一定的认识，比如搜索引擎只会检索互联网的公开信息，不会检索未公开的信息。就像我在百度网盘存的私密文档，百度搜索应该是不会去检索的。另外大家的隐私意识也有很大提升，不会随便把自己的隐私信息放到公网上。

由于大语言模型还是新事物，所以大家对于大语言模型的隐私问题还是有一定的担忧。常见的问题包括：

1. 大语言模型会不会把用户的隐私信息拿去训练？输入我的名字是不是就能推断出我的隐私信息？
2. 我和大语言模型的对话会不会被记录下来？会不会被拿去训练？
3. 我还没发表的小说，会不会被大语言模型拿去训练，甚至生成类似的小说？
4. 会不会关联我的实名信息，让我在不同平台的小号被关联起来？

大模型数据的训练来源，以及对数据的要求

大语言模型的训练数据主要来源于互联网的公开数据，比如维基百科，新闻网站，公开的论坛等。正规大公司是不会拿用户的隐私信息或者自己平台的用户私密数据去训练，一方面因为是违法法律的，另一方面从技术角度来说收益不大。

隐私数据不代表高质量数据，模型训练要想高质量，还是需要大量高质量的数据。使用用户隐私数据训练，对正规公司来说，收益比较低，风险比较高。

即使是公开数据，在训练前也需要对数据进行处理，比如脱敏，去标识化等。大模型在训练后还需要对齐，在对齐阶段也会让大语言模型在生成时，不会生成用户的隐私信息。

所以到目前为止，在用户使用大语言模型过程中，鲜有听说用户隐私信息被大模型泄露的情况。

为什么用户觉得自己的隐私信息被大语言模型泄露了？

在互联网上有一些“人肉高手”，通常能根据一些简单信息，就能“人肉”出一个人的很多信息。而这些信息其实就是这些高手通过网上的公开信息，只是他们善于搜索和关联数据。而普通人并不会去主动寻找这些信息的关联性，但现在随着 AI 搜索的流行，大语言模型会帮助用户对信息进行归类整理，从而让用户发现了一些自己没有发现的信息，这种情况下，用户会觉得自己的隐私信息被泄露了。

就像有位网友通过豆包搜索自己的作品，结果发现了自己小号的作品也被列出来了，以为是自己后台实名信息被大模型训练导致关联的，实际上是作者大号是“笑讽嘲”而小号是“笑讽嘲.”，只差一个点号，所以被 AI 归类在了一起也是正常的。



### 122

2024-07-22



小互
@imxiaohu
LensGo AI 推出了一个名为 FaceSync 的新功能。

用户可以录制自己的表演视频，然后选择一张图片或视频

FaceSync 能够将你的表演与这些图像或视频同步，使其栩栩如生。

也就是将你的形象转移到目标图像或者视频，同时保持你的声音和口型姿态同步。

让你可以以任何形象来表演...

目前还在测试中...

### 123

2024-07-22


歸藏(guizang.ai)
@op7418
这个德州扑克 app 设计也太可爱了，交互非常自然。

支持在线匹配和自定义游戏对战，还可以跟 ai 玩，都是积分不涉及赌博，喜欢玩德州的可以试试。



### 124

2024-07-23


宝玉
@dotey
借助 LivePortrait，大叔秒变美少女

LivePortrait 是快手可灵大模型团队开源的可控人像视频生成框架，该框架能够准确、实时地将驱动视频的表情、姿态迁移到静态或动态人像视频上，生成极具表现力的视频结果。

演示：https://huggingface.co/spaces/KwaiVGI/LivePortrait



### 125

2024-07-23

小互
@imxiaohu
Aiuni AI这个图片转3D的效果非常好

去官网看了下质量是非常的高，但是官网能给的信息非常少

找了半天发现他们是基于Unique 3D开源的项目

该项目清华大学和AIUNI AI共同开发，该项目可以不到30秒，从任意RGB图像中生成高保真3D模型。

官网：http://aiuni.ai
项目介绍：https://xiaohu.ai/p/11605



### 126

2024-07-23


歸藏(guizang.ai)
@op7418
确实好用，一直想复刻 LTX（AI 视频制作软件）的提示词生成工作流。

没想到 Claude 生成的提示词一次就可以生成角色描述、场景描述以及详细的分镜描述提示词，另外还有角色台词及语气。

可以批量从小说制作 AI 视频了。

后面是根据生成的场景描述用 MJ 做的图。



### 127

2024-07-23



小互
@imxiaohu
MemO：为大语言模型提供永久记忆能力

实现跨应用程序的个性化AI体验

MemO为大语言模型提供了一层智能的、自我改进的记忆层，也就是为大语言模型（比如ChatGPT）提供了一个个性化记忆存储功能

使其能够记住和利用之前的交互信息，从而提供更加个性化的服务。

解决了Al模型缺乏长期记忆和个性化能力的问题，使AI能够根据用户历史和偏好提供更精确和有用的响应。

Memo适用于需要长期记忆和上下文保留的AI应用，如聊天机器人和智能助理。

例如：在客户支持系统中，Memo可以记住用户之前的问题和解决方案。当用户再次联系支持时，系统可以立即获取之前的互动记录，提供更快速和个性化的帮助。

详细介绍：https://xiaohu.ai/p/11569


### 128

2024-07-23



歸藏(guizang.ai)
@op7418
老马大力出奇迹整了一个十万张 H100 的超算集群。

应该是现在已知最快的超算集群了，每秒性能达到2.5 exaflops（百亿亿次浮点运算）。

目前最快的超级计算机是Frontier，性能为每秒1.2 exaflops。

这玩意只需要一周就可以完成 GPT-4 这个级别模型的训练。

期待 Grok 的下一代模型。


### 129

2024-07-23

小互
@imxiaohu
兄弟们 这个牛P

Vozo：AI视频编辑器  

使用提示重写脚本并重新给视频配音 生成新的视频

你可以通过简单的提示重写视频脚本、然后这个工具会自动给视频重新配音、翻译语音并口型同步，然后生成新的视频。

• 文本编辑语音：可以通过编辑文本更新解说，不需要重新录音。

• 多角色口型同步：视频中的多角色自然口型同步。



### 130

2024-07-23


小互
@imxiaohu
Llama 3.1 发布 包含8B、70B 和 405B 版本

 性能媲美GPT4o等闭源模型

• Meta发布了新的Llama 3.1模型，包括期待已久的405B。

•这些模型具有改进的推理能力、128K token上下文窗口，并支持8种语言。

• Llama 3.1405B在多项任务上与领先的闭源模型竞争。

• 工具使用能力，支持搜索和Wolfram Alpha的数学推理，模型能够集成和使用多种工具，支持在零样本条件下进行工具调用和操作。

•通过组合方法可以将图像、视频和语音功能整合到模型中

•训练405B模型使用了超过16K的NVIDIA H100 GPU，历时数月。

• Llama 3.18B和70B模型在性能和安全性上优于前代。

•更新的许可证允许使用Llama模型的输出改进其他模型。

详细内容：https://xiaohu.ai/p/11686



### 131

2024-07-23

小互
@imxiaohu
腾讯的PhotoMaker 开源项目更新

通过堆叠ID嵌入，PhotoMaker V2 可以在几秒钟内完成个性化的人物图像定制，无需额外的LoRA训练。

你只需要输入几张自己的照片即可，然后通过提示词或者其他的参考图像

即可生成自己在各种场景、各种状态、各种风格的照片。

它的工作原理是：利用多个输入图片来创建一个统一的ID嵌入表示，这些嵌入向量包含了人物的各种特征（如面部特征、发型、表情等）。

然后利用这个ID表示来生成图像，从而保持人物特征的一致性。该方法不仅速度快、质量高，还可以根据文字描述生成定制化的照片。

详细介绍：https://xiaohu.ai/p/11665



### 132

2024-07-24


Andrej Karpathy
@karpathy
Huge congrats to 
@AIatMeta
 on the Llama 3.1 release!
Few notes:

Today, with the 405B model release, is the first time that a frontier-capability LLM is available to everyone to work with and build on. The model appears to be GPT-4 / Claude 3.5 Sonnet grade and the weights are open and permissively licensed, including commercial use, synthetic data generation, distillation and finetuning. This is an actual, open, frontier-capability LLM release from Meta. The release includes a lot more, e.g. including a 92-page PDF with a lot of detail about the model:
https://ai.meta.com/research/publications/the-llama-3-herd-of-models/

The philosophy underlying this release is in this longread from Zuck, well worth reading as it nicely covers all the major points and arguments in favor of the open AI ecosystem worldview:
"Open Source AI is the Path Forward"
https://facebook.com/4/posts/10115716861061241/?rdid=VE0wPWaJDdF21j32
I like to say that it is still very early days, that we are back in the ~1980s of computing all over again, that LLMs are a next major computing paradigm, and Meta is clearly positioning itself to be the open ecosystem leader of it.

- People will prompt and RAG the models.
- People will finetune the models.
- People will distill them into smaller expert models for narrow tasks and applications.
- People will study, benchmark, optimize.

Open ecosystems also self-organize in modular ways into products apps and services, where each party can contribute their own unique expertise. One example from this morning is 
@GroqInc
 , who built a new chip that inferences LLMs *really fast*. They've already integrated Llama 3.1 models and appear to be able to inference the 8B model ~instantly:
https://x.com/karpathy/status/1815809753660154047
And (I can't seem to try it due to server pressure) the 405B running on Groq is probably the highest capability, fastest LLM today (?).

Early model evaluations look good:
https://ai.meta.com/blog/meta-llama-3-1/ https://x.com/alexandr_wang/status/1815775286195331411
Pending still is the "vibe check", look out for that on X / r/LocalLlama over the next few days (hours?).

I expect the closed model players (which imo have a role in the ecosystem too) to give chase soon, and I'm looking forward to that.

There's a lot to like on the technical side too, w.r.t. multilingual, context lengths, function calling, multimodal, etc. I'll post about some of the technical notes a bit later, once I make it through all the 92 pages of the paper :)



### 133

2024-07-24



宝玉
@dotey
\#开源项目推荐：mkprivacy

mkprivacy 应用程序是一个用于创建 Apple 隐私清单文件的工具，这些文件通常命名为 PrivacyInfo.xcprivacy。该工具是一个 macOS 界面应用，你可以从命令行启动它。

https://github.com/apparata/mkprivacy


### 134

2024-07-24


宝玉
@dotey
小扎认为 Llama 会成为开源 AI 的行业标杆，就像当年的 Linux 一样

我们今天发布了LLAMA 3.1，并且推出了三个模型。其中一个是拥有4050亿参数的模型，这是我们首次发布如此大规模的模型。这无疑是目前最先进的开源模型，甚至在某些领域能与一些领先的闭源模型竞争，甚至超越它们。我非常期待看到大家如何使用这个模型，特别是现在我们的社区政策允许大家将它作为教师模型，用于蒸馏和微调，从而创建任何他们想要的模型。

此外，我们将4050亿参数的模型进行蒸馏，制作了新的、更先进的700亿和80亿参数模型。它们同样表现出色，性价比非常高。我非常期待看到大家如何利用这些模型。

回过头来看，我认为这是开源AI的一个重要时刻。我一直认为开源AI会成为行业标准，就像当年Linux一样。在Linux流行之前，各家公司都有自己的封闭版Unix。当时，还没有哪个开源项目达到那样的复杂程度。人们认为，只有封闭的开发模式才能实现如此先进的技术。

最初，Linux因为成本低廉和高度可定制而获得了立足点。随着生态系统的不断完善，它受到了更多的关注和审查，变得更加安全和先进。越来越多的合作伙伴加入，为其开发更多的功能和驱动程序，最终使Linux比任何闭源的Unix都更具功能性。所以我认为LLAMA 3.1的发布也是一个类似的转折点，LLAMA有机会成为开源AI的行业标准。即使在某些性能上还没有完全超越，LLAMA在成本、可定制性以及模型微调等方面的优势已经非常明显。我相信这些优势将被开发者充分利用，我们也在致力于构建一个合作伙伴生态系统，围绕LLAMA开发出更多的功能。对此我非常兴奋。

Llama 官网：https://llama.meta.com


### 135

2024-07-24

宝玉
@dotey
整理自视频文稿：Llama 3.1 重磅发布

今天，我们非常激动地发布了长期备受期待的 Llama 3.1。这是一个 4050 亿参数的模型，我们在四月份曾对其进行预览。同时，我们还升级了 80 亿和 700 亿参数的模型，为它们带来了新的、更优秀的性能和功能。

模型规模与性能提升

这个 4050 亿参数的模型无疑是迄今为止发布过的最大、最强大的开源模型。它在很多方面都有所改进，包括推理、工具使用、多语言处理、更大的上下文窗口等。我们今天发布的最新基准测试成绩超过了我们在四月份预览时的数据，建议您阅读我们最新发布的研究论文以了解详细信息。

全面升级的模型系列

伴随着 4050 亿参数的模型，我们还发布了一套升级版的预训练和指令调优的 80 亿和 700 亿参数的模型，支持各种用例。无论是业余爱好者、创业团队，还是企业和研究实验室，这些新模型都能提供与其参数规模匹配的出色性能，并且具备一些显著的新功能。

关键功能升级

1. 扩展的上下文窗口：我们倾听了社区的反馈，将所有模型的上下文窗口扩展到了 128K Token，使模型能够处理更大的代码库或更详尽的参考材料。

2. 工具使用能力：这些模型经过训练，能生成针对搜索、代码执行和数理推理等特定功能的工具调用，并支持零样本学习的工具使用。

3. 增强的推理能力：带来了更好的决策制定和问题解决能力。

4. 改进的系统方法：使开发者更容易在提供帮助和安全需求之间找到平衡。

部署与合作

我们一直与合作伙伴紧密合作，现在非常高兴地告诉您，除了在本地运行模型外，您现在能够在 AWS、Databricks、Nvidia 和 Grok 等合作伙伴那里部署 Llama 3.1。这一切都将在今天正式启动！

开源承诺与新许可证

在 Meta，我们深信开源的力量。随着今天的发布，我们进一步履行了对社区的承诺。我们新推出的模型将在更新的许可证下分享，该许可证允许开发者使用 Llama 的输出来改善其他模型，包括来自 405B 模型的输出。我们预计生成合成数据和蒸馏将会成为一种广受欢迎的应用，它为创建性能更强的小型模型以及推动 AI 研究打开了新的可能性。

Meta AI 用户体验升级

从今天开始，我们将会向 Meta AI 的用户推出 Llama 3.1。我们很高兴能够将许多新功能带给 Facebook、Messenger、WhatsApp 和 Instagram 的用户。

未来展望

随着 3.1 的发布，我们也在迈向让开源 AI 成为行业标准的下一步——坚持我们对未来的承诺，即通过提供更多的机会访问 AI 模型，帮助生态系统繁荣并解决世界上一些最紧迫的挑战。

我们期待听到您的反馈，并期待看到开发者社区将如何使用 Llama。

Llama 3.1 官方网站：https://llama.meta.com




### 136

2024-07-24

歸藏(guizang.ai)
@op7418
可灵也正式结束了完全免费生成体验，开启了付费计划。

现在每天给66点免费点数，大概可以生成六个视频。

限时一周全线五折，感觉1500这个还行。

起码比Runway良心多了，Runway 一个月105块钱只能生成十个视频。



### 137

2024-07-24

歸藏(guizang.ai)
@op7418
Llama 3.1训练过程中值得关注的一些信息，真是合成数据的胜利。


1）代码的监督微调 (SFT for Code)：405B 模型采用了 3 种合成数据方法来提升自身的代码能力，包括代码执行反馈、编程语言翻译和文档反向翻译。

2）数学的监督微调 (SFT for Math)：使用了多种方法包括从数学背景中获取相关的预训练数据，并将其转换为问答格式，以用于监督微调；使用Llama 3来生成一组提示的逐步解决方案；训练结果和逐步奖励模型，以过滤其中间推理步骤错误的训练数据；提示Llama 3通过结合文本推理和相关的Python代码来解决推理问题；为了模拟人类反馈，我们利用不正确的生成进行训练，并进一步通过提示Llama 3来消除这些错误。

3）多语言能力的监督微调 (SFT for Multilinguality)："为了收集更高质量的非英语语言人工标注，我们从预训练过程中分出一个分支，继续在由 90% 多语言标记 (tokens) 组成的数据混合集上进行预训练，以此来培养一个多语言专家模型。"

4）长文本处理能力的监督微调 (SFT for Long Context)：主要依靠合成数据来解决超长上下文训练的需求。长上下文预训练使用了8000亿（B）个Token，分为6个阶段，并有一个退火阶段。**使用早期版本的 Llama 3 来生成基于关键长文本处理场景的合成数据，包括多轮问答、长文档摘要和代码库推理。"

5）工具使用能力的监督微调 (SFT for Tool Use)：针对 Brave Search、Wolfram Alpha 和 Python 解释器（一个特殊的新 ipython 角色）进行了训练，以实现单一、嵌套、并行和多轮函数调用的能力。

6）基于人类反馈的强化学习 (RLHF)：大量使用了基于 Llama 2 生成结果的直接偏好优化 (DPO) 数据。

### 138

2024-07-24

宝玉
@dotey
有网友用 2 台 MacBook Pro 128GB 分布式运行了刚发布的 Llama 3.1 405B。大家关心的每秒多少 Token 没有公布，但看起来比较慢。

使用的 Exo Labs 进行分布式机器学习推理
使用 Apple 开源的机器学习库 MLX 作为推理引擎
使用 TinyChat UI 界面

---

Alex Cheema - e/acc
@ac_crypto
2 MacBooks is all you need.

Llama 3.1 405B running distributed across 2 MacBooks using 
@exolabs_
 home AI cluster


github:

exo-explore/exo

[exo-explore/exo: Run your own AI cluster at home with everyday devices 📱💻 🖥️⌚](https://github.com/exo-explore/exo)

---

Alex Cheema - e/acc
@ac_crypto
The code is open source and Llama 3.1 8B, 70B and 405B are all supported in exo:



### 139

2024-07-24


小互
@imxiaohu
Adobe 发布Firefly Vector AI 模型 

为 Illustrator 和 Photoshop 推出更多生成式 AI 功能

Adobe Illustrator 和 Photoshop 推出一些新的工具和生成式 AI 功能。此次更新最引人注目的功能来自 Adobe 最新的 Firefly Vector AI 模型，该模型今天开始公开测试。

这个新的 Firefly Vector 模型为 Illustrator 带来了诸多新功能，比如生成形状填充 (Generative Shape Fill)，用户可以通过描述性文本提示为形状添加详细的矢量图形。

更新后的模型还改进了文本到图案 (Text to Pattern) 的测试功能，可以用来创建可扩展的自定义矢量图案，如壁纸；

还有样式参考 (Style Reference)，能够生成与现有样式相匹配的输出。

新的Mockup 工具允许您将矢量艺术品放置在几乎任何带有空白表面的模型图像上。这是一个 3 次点击的过程，您还可以随时进行非破坏性编辑。




### 140

2024-07-24


小互
@imxiaohu
Meta AI 研究员：网络上的文本基本都是“狗屎”

Llama 3 没有使用任何人类书写的答案 全是合成数据

Latent Space采访了 Meta  AI 研究员 Thomas Scialom，他领导了 Llama2 和现在的 Llama3 训练后工作。

他们详细讨论了Llama 3.1预训练（如合成数据、数据管道、缩放法则等）和后训练（如强化学习人类反馈 (RLHF) 与指令调优、评估、工具调用）方面的内容。

据 Thomas Scialom：

1. 合成数据：

- 我的直觉是，网络上的文本都是狗屎，在这些标记上进行训练是在浪费计算量"。

- Llama 3 后期训练没有使用任何人类书写的答案，而是完全依赖于Llama 2生成的纯合成数据。”

2. 合成数据的具体应用：

- 代码生成：使用三种方法生成代码合成数据，包括代码执行反馈、编程语言翻译和文档反向翻译。

-数学推理：借鉴了“让我们逐步验证"作者的研究，进行合成数据生成。

-多语言处理：通过90%的多语言令牌继续预训练，收集高质量的人类注释。

- 长文本处理：依赖于合成数据来处理长文本的问答、长文档摘要和代码库推理。

- 工具使用：在Brave搜索、Wolfram Alpha和Python解释器上训练进行单次、嵌套、并行和多轮函数调用。

3. 强化学习与人类反馈（RLHF）：

- 广泛使用人类偏好数据进行模型训练。

- 强调了人类在两者之间进行选择（如选择两首诗中更喜欢哪一首）而非创作（从零开始写一首诗）的能力。

4. Meta 已经在6 月份开始训练Llama 4，听起来一大重点将是围绕智能体展开。

5.多模态版本将有更多参数，稍后发布

详细内容：https://xiaohu.ai/p/11770



### 141

2024-07-24


小互
@imxiaohu
Open-Sora Plan v1.2.发布

引入新的3D全注意力架构，提升了对物理世界的理解能力。

改进了从文本生成视频的能力。

通过新架构和优化的VAE结构，提升了视频生成的清晰度和一致性。

新的3D全注意力架构解决了之前版本无法同时处理空间和时间维度的问题。

优化后的CausalVideoVAE结构提高了模型的推理速度和性能。

Open-Sora致力于复刻OpenAI Sora模型...

GitHub：https://github.com/PKU-YuanGroup/Open-Sora-Plan/blob/main/docs/Report-v1.2.0.md




### 142

2024-07-24


小互
@imxiaohu
SpeechGPT2：一个端到端的语音对话语言模型  

类似于 GPT-4o 能够感知和表达情感

该项目由复旦大学计算机学院开发

它能够感知和表达情感，并根据上下文和人类指令提供多种风格的语音响应，如说唱、戏剧、机器人、搞笑和低语等。

超过10万小时的学术和野外收集的语音数据， 涵盖了丰富的语音场景和风格。

SpeechGPT2 是在有限资源下的技术探索，由于计算和数据资源的限制，它在语音理解的噪声鲁棒性和语音生成的音质稳定性方面仍有一些不足。

目前仍在开发中，团队计划未来开源技术报告、代码和模型权重。

详细内容及更多演示：https://xiaohu.ai/p/11793

### 143

2024-07-24

Leo Xiang
@leeoxiang
在Llama 3 405B模型54天的预训练期间，总共发生了417 次意外中断，训练过程挑战重重。

主要原因包括:
1、GPU故障: 148次 (30.1%)
2、GPU HBM3内存: 72次 (17.2%)
3、软件Bug: 54次 (12.9%)
4、网络交换机/线缆: 35次 (8.4%)
5、主机维护: 32次 (7.6%)
6、GPU SRAM内存: 19次 (4.5%)
7、GPU系统处理器: 17次 (4.1%)
8、NIC: 7次 (1.7%)
9、NCCL看门狗超时: 7次 (1.7%)
10、静默数据损坏: 6次 (1.4%)
11、GPU热接口+传感器: 6次 (1.4%)

训练大模型仍充满了各种工程上的挑战，向meta致敬。



### 144

2024-07-24

Tom Huang
@tuturetom
离谱，太疯狂了！😂 开源的「异构集群」方案 
@exolabs_
 在 「2 台 Macbooks x 128GB」运行了 Llama-3.1-405B！！！🔥

基于 Llama-3.1-405B 的 4 bit 量化版本，约需要 200GB 内存，基于 
@Apple
  开源的 MLX 框架！

代码已开源：https://github.com/exo-explore/exo，短时间飙升 3.7K Star ⭐️

见视频！👇


### 145

2024-07-25

宝玉
@dotey
来自贾扬清的点评总结：
1. 现阶段 Llama 3.1 405B 难以盈利，要占用半台或整台服务器运行，成本相对比较高，速度也只能 30 tokens/sec，而相对应的 70B 能超过 150 tokens/sec。
2. 预计未来一年内 405B 效率至少提升 4 倍
3. int8/fp8 是 LLM 推理量化精度的未来方向
4. 在垂直应用中，你可能不需要 405B 那么大的模型。70B 已经足够好，在许多情况下，经过微调的 8B 模型就已经非常优秀了！并且 Llama 3.1 允许和鼓励你微调自己的模型
5. 期待 Mistral 的 Large 123B，但目前只能学术用途
6. 最后是广告，他们的 
@LeptonAI
 API 在速度、价格、并发性和成本等多个参数之间做出了精心的平衡





### 146

2024-07-26

宝玉
@dotey
谁将掌控人工智能的未来？by Sam Altman

https://washingtonpost.com/opinions/2024/07/25/sam-altman-ai-democracy-authoritarianism-future/

这是我们这个时代最紧迫的问题。人工智能的快速发展意味着我们面临一个战略选择：我们是要生活在一个由美国和盟国推动全球 AI 发展、分享技术利益并开放访问的世界，还是一个由不共享我们价值观的国家或运动使用 AI 巩固和扩展其权力的专制世界？

没有第三种选择——我们必须立即决定该走哪条路。美国目前在 AI 开发方面处于领先地位，但这一地位并非稳固。世界各地的专制政府愿意投入巨资赶超并最终超越我们。俄罗斯独裁者普京曾警告说，赢得 AI 竞赛的国家将“成为世界的统治者”，而中国则表示，到 2030 年要成为全球 AI 领导者。

这些专制政权和运动将牢牢掌控技术的科学、健康、教育等社会福利，以巩固其权力。如果他们在 AI 领域取得领先，他们将迫使美国和其他国家的公司共享用户数据，利用技术开发新的监控手段，或创造新一代的网络武器来对抗其他国家。
人工智能的第一章已经写就。ChatGPT、Copilot 等系统已经作为有限的助手角色——例如，通过记录患者访问情况，使护士和医生能够花更多时间与病人相处，或者在软件工程等领域作为高级助手，生成代码。更多的进步即将到来，将开启人类社会历史的决定性时期。

如果我们希望确保人工智能的未来是一个造福尽可能多人的未来，我们需要一个由美国领导的志同道合国家组成的全球联盟，以及一个创新的新战略来实现这一目标。美国的公共和技术部门需要做到四件大事，以确保创造一个由民主愿景塑造的 AI 世界。

首先，美国的 AI 公司和行业需要制定强有力的安全措施，确保我们的联盟在当前和未来的模型中保持领先，并使我们的私营部门能够创新。这些措施包括网络防御和数据中心安全创新，以防止黑客窃取关键的知识产权，如模型权重和 AI 训练数据。许多防御措施将受益于人工智能的力量，使人类分析师更容易、更快速地识别风险并应对攻击。美国政府和私营部门可以合作，尽快开发这些安全措施。

其次，在 AI 领域，基础设施即命运。早期安装的光纤电缆、同轴电缆等宽带基础设施使美国能够在数字革命中占据中心地位，并建立其当前在人工智能领域的领先地位。美国的政策制定者必须与私营部门合作，建设大量运行 AI 系统所需的物理基础设施——从数据中心到发电厂。公私合作建设这些必要的基础设施将使美国公司具备扩展 AI 访问并更好地分配其社会利益的计算能力。

建设这些基础设施还将创造全国范围内的新就业机会。我们正在见证一种与电力或互联网同样重要的技术的诞生和演变。AI 可以成为新工业基础的基石，我们的国家应明智地拥抱它。

我们需要用大量投资人力资本来补充这些“砖瓦”。作为一个国家，我们需要培养和发展下一代 AI 创新者、研究人员和工程师。他们是我们的真正超级力量。

第三，我们必须为 AI 制定一致的商业外交政策，包括明确美国如何实施出口管制和外国投资规则，以支持全球 AI 系统的建设。这也意味着为哪些芯片、AI 训练数据和其他代码可以保存在世界各地竞相建设的数据中心制定规则——其中一些非常敏感，可能需要保留在美国。

在各国争相获得更多技术访问权的时刻，我们现有的 AI 领先地位将使更多国家更容易加入这一新联盟。确保开源模型让这些国家的开发者能够轻松访问将进一步增强我们的优势。谁将领导 AI 的挑战不仅是出口技术的问题，更是关于输出该技术所坚持的价值观的问题。

第四，我们需要创造性地思考世界如何建立开发和部署 AI 的规范，特别关注安全，并确保全球南方和其他历史上被忽视的国家的角色。正如其他全球重要问题一样，这将要求我们与中国接触并保持持续对话。

我过去曾谈到过创建类似国际原子能机构的 AI 机构，但这只是一个潜在的模式。一个选择是将正在日本和英国等国家建立的 AI 安全研究所网络编织在一起，创建一个投资基金，让承诺遵守民主 AI 协议的国家可以从中提取资金，以扩展其国内计算能力。

另一个潜在模式是互联网名称与数字地址分配机构（ICANN），该机构由美国政府于 1998 年成立，比万维网创建不到十年，旨在标准化我们如何导航数字世界。ICANN 现在是一个独立的非营利组织，拥有来自世界各地的代表，致力于其核心使命，即最大限度地访问互联网，支持一个开放、互联、民主的全球社区。

虽然确定正确的决策机构很重要，但关键是民主 AI 比专制 AI 更具优势，因为我们的政治体系赋予了美国公司、企业家和学者研究、创新和构建的权力。

除非我们努力确保民主 AI 愿景占上风，否则我们无法拥有在最大化技术利益的同时将风险降至最低的 AI。如果我们希望拥有一个更民主的世界，历史告诉我们，我们唯一的选择是制定一个能够帮助实现这一目标的 AI 战略，并且领先的国家和技术人员有责任现在就做出这一选择。





### 147

2024-07-26

小互
@imxiaohu
oogle DeepMind 推出了首个能以银牌得主水平解决国际数学奥林匹克竞赛问题的 AI。

该 AI 综合了 AlphaProof 和改进版的 AlphaGeometry 2，能解决代数、组合数学、几何学和数论问题，并在今年的比赛中获得了 28 分，达到银牌水平！

AlphaProof和AlphaGeometry 2，用于解决复杂的数学推理问题。

AlphaProof 使用 Lean 编程语言进行形式推理，并结合 AlphaZero 强化学习算法进行训练，而 AlphaGeometry 2 则是一种神经符号混合系统，解决问题的效率显著提高。

这一系统有望加速数学研究并推动通用人工智能的发展。

•该 AI 结合了两种模型：用于形式推理的 AlphaProof 和改进版的 AlphaGeometry 2。

•AI 需要解决今年的六个 IMO 问题，这些问题涉及代数、组合数学、几何学和数论，并由数学家 W.T. Gowers 和 Joseph K. Myers 监督评分。

•AI 解决了 4 个问题，获得了 28 分，相当于获得银牌。

•AlphaProof 能在 Lean 编程语言中创建证明，并结合 AlphaZero 强化学习算法进行训练。

•AlphaProof 通过将一百万个非正式数学问题翻译成形式化数学语言来训练，使用 AlphaZero 算法逐步解决更具挑战性的问题。

•由于缺乏人类书写的数据，数学编程语言如 Lean 的使用受限，因此 DeepMind 对 Gemini 模型进行了微调，以将自然语言问题翻译为形式化问题进行训练。

•AlphaGeometry 2 是一种神经符号混合系统，能够解决 83% 的历史几何问题，相较于其前身的 53% 提高显著。

•AlphaGeometry 2 可以在 19 秒内解决今年的 IMO 第四题。

•新系统有望加速 AI 驱动的数学研究，从快速完成证明元素到最终发现新知识，推动通用人工智能（AGI）进步。

详细介绍：https://dpmd.ai/imo-silver




### 148

2024-07-26

Andrej Karpathy
@karpathy
To help explain the weirdness of LLM Tokenization I thought it could be amusing to translate every token to a unique emoji. This is a lot closer to truth - each token is basically its own little hieroglyph and the LLM has to learn (from scratch) what it all means based on training data statistics.

So have some empathy the next time you ask an LLM how many letters 'r' there are in the word 'strawberry', because your question looks like this:
👩🏿‍❤️‍💋‍👨🏻🧔🏼🤾🏻‍♀️🙍‍♀️🧑‍🦼‍➡️🧑🏾‍🦼‍➡️🤙🏻✌🏿🈴🧙🏽‍♀️📏🙍‍♀️🧑‍🦽🧎‍♀🍏💂

Play with it here :)
https://colab.research.google.com/drive/1SVS-ALf9ToN6I6WmJno5RQkZEHFhaykJ#scrollTo=75OlT3yhf9p5

---

宝玉
@dotey
Andrej 为了解释 Word 和 Token 的区别，写了个小程序，把 Token 用 Emoji 表示，好帮助你直观的理解 LLM （大语言模型）看到的世界和我们看到的世界是不一样的。

简单来说一个单词会由一到多个Tokens组成，比如“strawberry”是一个单词，但是可能是“str”、“aw”和“berry” 3 个Token，而 Token 存储的时候也不是字母，所以如果让 LLM 计算出 strawberry 里面有多少个 r，或者对其反转，那它是很困难的。


### 149

2024-07-26

Simon
@YRSM_Simon
昨天尝试微调了一下4o-mini，总结如下：

- 训练成本还是有点高了，$3/M
    - 简单试了一下，共消耗了19M token，减去2M 免费额度，计费17M token，$50；不太敢敞开了调超参数...
- Max step 判定有bug，看规划需要118个step，但是一直训练到186 步才结束，导致overfit了；
- 中间保留了几个checkpoints，效果比3.5/babbage微调要好；

接下来试试llama 3.1 8b，如果效果一样，还是用开源训练成本低～



### 150

2024-07-26

宝玉
@dotey
\#AI开源项目推荐 llama-agentic-system

Meta 的这个专门为 Llama 打造的智能体任务系统，可以让你运行Llama 3.1，使其成为一个能够执行“智能体”任务的系统，包括：
- 分解任务并执行多步骤推理
- 使用工具的能力
  - 内置常用工具：模型内置了对搜索或代码解释器等工具的知识
  - 零样本：模型可以根据上下文中之前未见过的工具定义来调用工具

项目地址：https://github.com/meta-llama/llama-agentic-system



### 151

2024-07-26


小互
@imxiaohu
CLASI ：字节跳动开发的端到端语音同步翻译系统 

它能模仿专业人类译员的策略，进行实时翻译语音内容，保持高翻译质量和低延迟。

CLASI合了音频编码器和大语言模型（LLM）的架构，具备从外部知识库中检索相关信息的能力。

通过结合LLM能理解并生成自然语言，帮助CLASI在翻译时考虑更多语境信息。

还能够处理音频中的错误或不清晰之处，生成容错的翻译结果。

小互
@imxiaohu
English 英语 →Chinese 中文 演示

详细介绍和更多演示：https://xiaohu.ai/p/11898


---

可以见 - https://byteresearchcla.github.io/clasi/

[byteresearchcla.github.io/clasi/](https://byteresearchcla.github.io/clasi/)

### 152

2024-07-27

宝玉
@dotey
据爆料：OpenAI 即将推出的 SearchGPT 仍会依赖Bing索引，但它也会使用自己的爬虫实时获取数据。另外 SearchGPT 背后应该是一个多模态的模型，支持图片的识别，你可以上传图片进行搜索或者问答。

使用方式上和现在主流的 AI 搜索类似：
- 用户可以用自然语言提问。
- AI 结合其知识与实时网络信息生成响应。
- 答案带有清晰的来源归属和链接。
- 用户可以通过后续问题更深入地探索主题。





### 153

2024-07-27

Andrej Karpathy
@karpathy
20min talk I gave at the Berkeley AI hackathon a few weeks ago, on how hacking around makes its way to real-world impact in my experience.

While True: build and publish projects.
Accumulate 10,000 hours.
Snowball your work.





### 154

2024-07-27



歸藏(guizang.ai)
@op7418
SD Web UI 更新了 1.10 版本，正式支持了 SD3 模型。

推荐使用 Euler 采样器；T5 文本模型默认禁用，需要在设置中启用。

支持了英伟达的 Align Your Steps 调度器和 DDIM CFG++采样器。

### 155

2024-07-27

小互
@imxiaohu
兄弟们，这篇文章特别精彩，推荐你们看看↓

Perplexity成立不到两年，用户数迅速增长至数千万，ARR超过2000万美元。

Lenny Rachitsky与Perplexity的联合创始人兼产品主管Johnny Ho进行了深入对话，揭示了该公司借助AI形成的独特产品开发方法：

1、AI 优先策略：

- AI指导决策：Perplexity的团队会向AI询问公司建设过程中各个步骤的建议。例如，他们会问AI如何发布产品以及发布过程中的具体步骤。尽管AI的回答不总是完全正确，但通过迭代，他们能够迅速找到解决方案。

- 使用AI减少协调成本：团队成员在寻求同事帮助前，先向AI询问问题，从而减少了团队内部的协调成本。

2、团队组织与结构：

- “粘菌”组织模式：为了最小化协调成本，Perplexity采用了一种类似于“粘菌”的组织方式，即尽可能并行化每个项目的各个部分，减少不必要的协调。

- 小团队：典型的团队由两到三人组成，一些项目甚至由一个人完成，如AI生成的高评分播客就是由一个品牌设计师独立完成的。

- 少量管理层：Perplexity倾向于雇用自驱动的独立贡献者（IC），避免雇用主要以指导他人工作为强项的人。

3、产品管理的未来：

- 技术产品经理的重要性：Johnny预测，具备技术背景和产品品味的产品经理或工程师将成为公司中最有价值的人才。这些人能够直接参与产品开发，而不是仅仅管理流程或领导团队。

4、灵活的产品开发：

- 季度计划与灵活调整：公司制定季度计划，但在季度内保持灵活，根据AI技术的发展快速调整优先事项。每周的启动会议帮助团队成员设定高层次的目标，并在周未进行反思，以确保决策的清晰性和避免过于反应性或混乱的决策。

- 并行工作：设计、前端和后端可以同时在同一项目上工作，避免等待设计或原型完成后再开始其他部分。

5、去中心化的决策过程：

- 独立负责的项目：每个项目由一个单一的直接负责个人（DRI）领导，尽可能将项目分解为独立任务，以减少协调问题。团队成员可以在没有阻碍的情况下执行任务，并在项目的不同阶段根据需要获得反馈。

6、文化与招聘标准：

- 招聘标准：Perplexity寻找具备灵活性和主动性的员工，优先考虑在有限资源环境下能做出建设性贡献的人才，而不是擅长管理流程或领导他人的候选人。公司注重文化契合和合作能力，但減少了对传统管理技能的需求。

详细文章内容：https://xiaohu.ai/p/11938



### 156

2024-07-27

九原客
@9hills
PDF 转 Markdown 工具列表：




### 157

2024-07-27

小互
@imxiaohu
卡内基梅隆大学数学系教授、美国数学奥林匹克竞赛国家队教练Po-Shen Loh，在看完Google Deepmind AI参加国际数学奥林匹克比赛并亲自尝试了竞赛题目后发表感慨：

“人类需要进入高度戒备状态！”

在今年的国际数学奥林匹克竞赛（IMO）中，Google Deepmind的人工智能（AI）表现出了接近国际数学奥林匹克竞赛银牌的能力。

卡内基梅隆大学（Carnegie Mellon University）数学系的教授、美国国际数学奥林匹克（IMO）队的国家教练  
@PoShenLoh
  表达了对AI在国际数学奥林匹克竞赛中取得重大突破的惊讶和担忧。他甚至将这以突破与苏联1957年发射的第一颗人造卫星：斯普特尼克号相提并论。

他称：“当人们看到 1957 年的人造卫星时，他们可能会有和我现在一样的感觉，人类需要进入高度戒备状态！”

他强调，AI不仅能通过模式匹配解决标准化测试，还展示了发现问题解决途径的能力。为了应对AI的快速进步，人类需要提升自己的智力，教育体系也需做出相应调整，培养学生解决新问题的能力。

此外，他主张建立合作而非竞争的社区，以维护人类文明的本质。

他的详细观点：https://xiaohu.ai/p/11931


### 158

2024-07-27


歸藏(guizang.ai)
@op7418
最近LLM的推理能力进步真的很快。

谷歌Deepmind宣布他们的数学模型解决了今年国际数学奥赛（IMO）中的四个问题，达到了银牌。

同时 Sam 还在评论区可能暗示Open AI的模型可以拿到金牌。

如果按Paul Christiano的预测的话，如果在 2025 年之前看到 IMO 金牌，那么AGI将会在几年内快速实现。



### 159

2024-07-27

Wang Shuyi
@wshuyi
AI 文献综述效果对比：Dify 工作流 vs Perplexity https://youtu.be/XTLTyKsQoHQ?si=zOCjT4D8PS3lxKBd 来自 
@YouTube

---

LysonOber
@lyson_ober
顺带一提，如果你也想学习 Dify Http 节点的一些基础用法，也可以看我上一周的视频作为补充自学资料 💾
📺 学习地址：https://youtube.com/watch?v=8WOZxjmXBxQ

2/

### 160

2024-07-27


Leonie
@helloiamleonie
Here’s how the LinkedIn Engineering team reduced the error rate from ~10% to ~0.01% when generating structured outputs with LLMs.

Turning natural text into structured outputs is a cool use case for LLMs.
But getting LLMs to do this reliably is quite challenging.

---


宝玉
@dotey
LinkedIn 的这个分享很有价值，他们分享了在构建生成式 AI 产品时的一些宝贵经验教训

他们做的产品时基于 LinkedIn 上的信息流和职位，借助 AI 帮助用户评估是不是和职位匹配、了解某个公司的最新动态、面试和修改个人简历方面的建议，以及其他一些功能。

从技术架构上来说，是一个多智能体的技术架构，主要分成三步：
- 路由：确定查询是否在范围内，并决定将其转发给哪个 AI 智能体。智能体的例子有：职位评估、公司理解、帖子总结等。
- 检索: AI 智能体决定调用哪些服务以及如何调用（例如 LinkedIn 用户搜索，Bing 搜索 等）。
- 生成: LLM 根据获取到的信息、原始问题和上下文去生成答案。

这其中路由、检索可以使用小模型，但生成内容需要使用大模型，这样才能有比较好的生成效果。

在整个项目的开发过程中，挑战是多方面的，有来自团队协作的，有来自大语言模型本身的

1. 团队协作的挑战

首先在团队协作方面，最开始他们是按照智能体划分小组，各自负责，这样优点是开发速度快，但缺点是各自的提示词、对话历史、越狱防护等这些需要重复建设，用户体验不一致。

所以他们后来将组织架构进行了调整：
- 一个小组负责公共和底层框架，并且保证提供一致的体验，这样可以共享提示词模板、集中解决安全防护、统一用户体验等
- 多个小组负责垂直方向的智能体，基于公共组提供的框架优化提示词、连接后端 API等

2. 数据检索的挑战

LinkedIn 有大量的用户资料、公司信息、还有一些其他的信息，这些数据更新很快，并且没有被大语言模型训练过，所以当用户请求时，需要能检索到用户想要的数据，而基于生成式 AI 产品的交互，不再是传统的关键字+选项的检索，而是完全自然语言的检索，这就需要先调用一次 LLM 帮助将自然语言转化为 API 调用。另外传统的 API 是给传统的 App 使用的，返回的数据冗余很多，并不适合 LLM 使用，所以需要针对 API 做一些针对 LLM 的优化。

举例来说，用户可能会询问：“请给我推荐西雅图的待遇好的公司”，那么针对这样的查询，首先需要去根据用户的身份找出来用户自己的职业（比如Java后端开发工程师），然后将用户资料+咨询的问题+可用的检索API，一起交给 LLM，LLM 将请求分解成适合 API 查询的参数：
- 职位搜索 API
   * 职位：Java 后端开发工程师
   * 地点：西雅图
   * 排序：工资由高到低

然后去调用 API，API 返回结果后，将返回结果、用户原始问题、历史对话一起交给 LLM，最终生成答案。

3. 怎么稳定的让 LLM 返回结构化的数据？

真正做过 LLM 开发的都知道，虽然理论上 LLM 可以生成结构化的数据，但是真正生成的时候经常出错。LinkedIn 的做法是：
1). 使用 YAML 格式而不是 JSON，相对来说容错率更高
2). 用日志记录常见的 YAML 错误，优化自己的 YAML 解析器，可以解析 LLM 返回的不规范的 YAML
3). 如果还是无法解析则将错误信息交给 LLM 修复，并且不断优化提示词，提升 LLM 修复的成功率

最终结构化数据的错误率从 10% 下降到 0.01%

4. 如何减少幻觉、降低延迟和提升吞吐量

- 使用 CoT（思维链）可以有效提升质量和减少幻觉，但由于一些中间步骤不能显示给用户，要等前面的中间步骤输出完成才能给用户显示结果，这也会增加延迟
- 使用流式（streaming）输出可以提升用户体验，让用户尽早看到输出，但这在复杂的流程上有很多挑战
- 由于 LLM 调用可能需要很长时间处理，使用异步非阻塞管道可以优化服务吞吐量，从而避免因 I/O 阻塞线程而浪费资源。

5. 如何评估生成结果的质量

只有对生成的结果有科学的评估，才能不断优化生成结果，但如何评估生成质量是很困难的，主要表现在：
- 难以制定标准。以职位评估为例：点击“评估我与该职位的匹配度”然后得到“你很不适合”并没有多大价值。好的结果既要真实准确又富有同情心。
- 对数据标注很难规模化，主要得依赖团队成员和外部标注员
- 难以自动化，还是需要人工去标注，并且需要收集一定的数据后才能评估

最终LinkedIn的做法：
1). 工程师们先快速粗略评估，得到个大致的指标。
2). 标注员提供更细致的反馈，但需要大约 1 天的时间。
3). 最终由团队成员进行全面评估，但可能需要超过 3 天的时间。

具体内容建议阅读原文。

- 原文：https://linkedin.com/blog/engineering/generative-ai/musings-on-building-a-generative-ai-product
- 译文：https://baoyu.io/translations/generative-ai/musings-on-building-a-generative-ai-product


### 161

2024-07-27

Ethan Mollick
@emollick
I don’t think this is a strong enough statement for startups. 

If you are going to exit in 5-7 years, you need to make a bet on how good you think AI is going to be. With either linear or exponential improvement, barely works today is not far enough ahead for a real moat.



### 162

2024-07-27



宝玉
@dotey
如何让 ChatGPT/Claude帮你写 PPT？

如果你想让 ChatGPT 这样的 LLM （大语言模型）帮你直接生成一个 PPT 文件是不现实的，因为它默认只能输出文本格式。

好在 LLM 对 Markdown 格式是相当友好的，有一种格式叫 Marp，可以用 Markdown 表示 PPT，并且是一种开源格式。

所以你只要在 Prompt 中让 LLM 生成 Marp 格式的幻灯片，那么就可以生成 Marp 格式的幻灯片内容。

但是局限性也比较明显：
1. 不能支持动画和画图
2. 不方便直接预览，目前我只知道 VSCode 插件可以预览扩展名为 .md 的 Marp 文件

Marp 的 VSCode 插件地址：https://marketplace.visualstudio.com/items?itemName=marp-team.marp-vscode

参考 Prompt（仅做示例参考）：
> 请帮我写一个Slide，主题是 “什么是Prompt Engineering”，使用 Marp 格式


### 163

2024-07-27



宝玉
@dotey
转译：OpenAI 可能在 12 个月内破产，预计亏损 50 亿美元

OpenAI 可能需要新一轮融资才能维持运营。

你需要知道的事情
- OpenAI 据报道即将破产，预计亏损达 50 亿美元。
- 这家初创公司在训练其 AI 模型上花费 70 亿美元，以及在人员配备上花费 15 亿美元。
- ChatGPT 制造商的运营成本并未通过大约 35 亿美元的收入来满足。

蓬勃发展的 AI 商业战略 正在使投资这一领域的主要科技公司走上盈利的道路。在过去的几个月里，我们看到 微软、苹果 和 NVIDIA 争夺 全球最有价值公司的桂冠。市场分析师将它们的收入和利润增长归因于它们 在产品和服务中早期投资和采用这项技术。

讽刺的是，AI 领域的关键玩家 OpenAI 可能在 2024 年损失高达 50 亿美元。据 The Information 报道，这家 ChatGPT 制造商可能濒临破产，预计在未来 12 个月内耗尽现金。

作为背景，OpenAI 每天花费多达 70 万美元来维持 ChatGPT 的运行。随着模型变得更加复杂和先进，这个数字可能会有所波动。报告还详细介绍了 OpenAI 的财务状况，称该公司在训练其 AI 模型上花费了 70 亿美元，并在人员配备上花费了 15 亿美元。这些开支远远超出了竞争对手对 2024 年的支出预测。

OpenAI 濒临枯竭，但仍专注于通用人工智能（AGI）

OpenAI 据报道获得了微软 Azure 服务的折扣访问权限。然而，其 AI 项目的快速进展正使公司陷入财务困境。

根据 Appfigures 的报告，GPT-4o 的推出 导致了 OpenAI 在 ChatGPT 收入和移动端下载量上的“有史以来最大激增”。该初创公司每年从 ChatGPT 中产生高达 20 亿美元的收入，并从大语言模型访问费中额外获得 10 亿美元，总收入约为 35 亿到 45 亿美元之间。

然而，这几乎无法覆盖公司的运营成本。值得注意的是，该公司已经进行了七轮融资，筹集了超过 110 亿美元，目前估值为 800 亿美元。据报道，OpenAI 运行接近满负荷，其 350,000 台服务器中有 290,000 台专用于其 AI 助手 ChatGPT。

来源：https://windowscentral.com/software-apps/openai-could-be-on-the-brink-of-bankruptcy-in-under-12-months-with-projections-of-dollar5-billion-in-losses


### 164

2024-07-27


Susan/STEM MOM
@feltanimalworld
在儿童游乐场把这本Make it Stick第一遍读完了。分享一下我这些年是怎么阅读原版书的（其实本质上和语言没有任何关系）：

1）我认为平铺式（一字一句）的看任何书都是低效的。
2）一本书里的内容对于任何人来说，都是“同心圆”结构。里面有你熟悉的知识，不怎么熟悉的和完全陌生的知识。
3）横扫过去，一定会有一些内容落入你的眼帘。真的会，看书时间久了，这些你第一眼熟悉的内容会来找你，你不用去找他。
4）用贴纸把这些熟悉的内容标记起来。
5）从这些熟悉的内容开始，写reflection。笔记永远不该是抄书，不是从书里生成的，而是从你大脑里生成的Generative……
6）等搞定这些熟悉内容的Reflection之后，会有更多以前你不怎么熟悉，但是在你写完那一堆reflection 之后变得熟悉的内容开始来找你。你的贴纸又增加了起来。
7）继续写新增加的贴纸的Reflection
8) 没多久之后你发现这本书居然读完了。
9）这些严谨的畅销书有丰富的Reference, 这些Journals, 论文也可以找找看有没有想看的。

一切做完，该去图书馆把这本书给还了。


### 165

2024-07-27





### 166

2024-07-02





### 167

2024-07-02





### 168

2024-07-02





### 169

2024-07-02





### 170

2024-07-02





### 171

2024-07-02





### 172

2024-07-02





### 173

2024-07-02





### 174

2024-07-02





### 175

2024-07-02





### 176

2024-07-02





### 177

2024-07-02





### 178

2024-07-02





### 179

2024-07-02





### 180

2024-07-02





### 181

2024-07-02





### 182

2024-07-02





### 183

2024-07-02





### 184

2024-07-02





### 185

2024-07-02





### 186

2024-07-02





### 187

2024-07-02





### 188

2024-07-02





### 189

2024-07-02





### 190

2024-07-02





### 191

2024-07-02





### 192

2024-07-02





### 193

2024-07-02





### 194

2024-07-02





### 195

2024-07-02





### 196

2024-07-02





### 197

2024-07-02





### 198

2024-07-02





### 199

2024-07-02





### 200

2024-07-02





### 201

2024-07-02





### 202

2024-07-02





### 203

2024-07-02





### 204

2024-07-02





### 205

2024-07-02





### 206

2024-07-02





### 207

2024-07-02





### 208

2024-07-02





### 209

2024-07-02





### 210

2024-07-02





### 211

2024-07-02





### 212

2024-07-02





### 213

2024-07-02





### 214

2024-07-02





### 215

2024-07-02





### 216

2024-07-02





### 217

2024-07-02





### 218

2024-07-02





### 219

2024-07-02





### 220

2024-07-02





