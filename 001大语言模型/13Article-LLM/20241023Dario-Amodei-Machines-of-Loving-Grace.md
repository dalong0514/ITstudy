## 20241023Dario-Amodei-Machines-of-Loving-Grace

[Dario Amodei — Machines of Loving Grace](https://darioamodei.com/machines-of-loving-grace)

Dario Amodei

Contents

Basic assumptions and framework

1. Biology and health

2. Neuroscience and mind

3. Economic development and poverty

4. Peace and governance

5. Work and meaning

Taking stock

---

Machines of Loving Grace1

How AI Could Transform the World for the Better

October 2024

I think and talk a lot about the risks of powerful AI. The company I'm the CEO of, Anthropic, does a lot of research on how to reduce these risks. Because of this, people sometimes draw the conclusion that I'm a pessimist or "doomer" who thinks AI will be mostly bad or dangerous. I don't think that at all. In fact, one of my main reasons for focusing on risks is that they're the only thing standing between us and what I see as a fundamentally positive future. I think that most people are underestimating just how radical the upside of AI could be, just as I think most people are underestimating how bad the risks could be.

In this essay I try to sketch out what that upside might look like—what a world with powerful AI might look like if everything goes right. Of course no one can know the future with any certainty or precision, and the effects of powerful AI are likely to be even more unpredictable than past technological changes, so all of this is unavoidably going to consist of guesses. But I am aiming for at least educated and useful guesses, which capture the flavor of what will happen even if most details end up being wrong. I'm including lots of details mainly because I think a concrete vision does more to advance discussion than a highly hedged and abstract one.

First, however, I wanted to briefly explain why I and Anthropic haven't talked that much about powerful AI's upsides, and why we'll probably continue, overall, to talk a lot about risks. In particular, I've made this choice out of a desire to:

Maximize leverage. The basic development of AI technology and many (not all) of its benefits seems inevitable (unless the risks derail everything) and is fundamentally driven by powerful market forces. On the other hand, the risks are not predetermined and our actions can greatly change their likelihood.

Avoid perception of propaganda. AI companies talking about all the amazing benefits of AI can come off like propagandists, or as if they're attempting to distract from downsides. I also think that as a matter of principle it's bad for your soul to spend too much of your time "talking your book".

Avoid grandiosity. I am often turned off by the way many AI risk public figures (not to mention AI company leaders) talk about the post-AGI world, as if it's their mission to single-handedly bring it about like a prophet leading their people to salvation. I think it's dangerous to view companies as unilaterally shaping the world, and dangerous to view practical technological goals in essentially religious terms.

Avoid "sci-fi" baggage. Although I think most people underestimate the upside of powerful AI, the small community of people who do discuss radical AI futures often does so in an excessively "sci-fi" tone (featuring e.g. uploaded minds, space exploration, or general cyberpunk vibes). I think this causes people to take the claims less seriously, and to imbue them with a sort of unreality. To be clear, the issue isn't whether the technologies described are possible or likely (the main essay discusses this in granular detail)—it's more that the "vibe" connotatively smuggles in a bunch of cultural baggage and unstated assumptions about what kind of future is desirable, how various societal issues will play out, etc. The result often ends up reading like a fantasy for a narrow subculture, while being off-putting to most people.

Yet despite all of the concerns above, I really do think it's important to discuss what a good world with powerful AI could look like, while doing our best to avoid the above pitfalls. In fact I think it is critical to have a genuinely inspiring vision of the future, and not just a plan to fight fires. Many of the implications of powerful AI are adversarial or dangerous, but at the end of it all, there has to be something we're fighting for, some positive-sum outcome where everyone is better off, something to rally people to rise above their squabbles and confront the challenges ahead. Fear is one kind of motivator, but it's not enough: we need hope as well.

The list of positive applications of powerful AI is extremely long (and includes robotics, manufacturing, energy, and much more), but I'm going to focus on a small number of areas that seem to me to have the greatest potential to directly improve the quality of human life. The five categories I am most excited about are:

Biology and physical health

Neuroscience and mental health

Economic development and poverty

Peace and governance

Work and meaning

My predictions are going to be radical as judged by most standards (other than sci-fi "singularity" visions2), but I mean them earnestly and sincerely. Everything I'm saying could very easily be wrong (to repeat my point from above), but I've at least attempted to ground my views in a semi-analytical assessment of how much progress in various fields might speed up and what that might mean in practice. I am fortunate to have professional experience in both biology and neuroscience, and I am an informed amateur in the field of economic development, but I am sure I will get plenty of things wrong. One thing writing this essay has made me realize is that it would be valuable to bring together a group of domain experts (in biology, economics, international relations, and other areas) to write a much better and more informed version of what I've produced here. It's probably best to view my efforts here as a starting prompt for that group.

我经常思考和探讨强大人工智能可能带来的风险。作为 Anthropic 的 CEO，我们公司在研究如何降低这些风险方面投入了大量精力。因此，有些人会得出结论，认为我是一个悲观主义者或「灾难预言家」，觉得人工智能主要会带来危险和负面影响。但我完全不这么想。事实上，我之所以格外关注风险，恰恰是因为这些风险是通往美好未来的唯一障碍。我认为，大多数人都低估了人工智能可能带来的巨大益处，就像他们低估了其潜在风险一样。

在这篇文章中，我试图勾勒出这种美好愿景 —— 如果一切顺利，拥有强大人工智能的世界会是什么样子。诚然，没有人能够准确预测未来，而且相比过去的技术变革，强大人工智能（powerful AI）的影响可能更加难以预料，所以这些必然带有推测性质。但我至少努力做出有见地和有价值的推测，即使大多数细节最终证明是错误的，这些推测也能展现未来的基本面貌。我之所以加入许多具体细节，主要是因为我认为一个具体的愿景比笼统抽象的描述更有助于推动讨论。

不过在此之前，我想简要解释为什么我和 Anthropic 较少谈论强大人工智能的益处，以及为什么我们可能会继续把重点放在讨论风险上。具体而言，我这样选择是出于以下考虑：

最大化影响力。人工智能技术的基本发展和许多（不是全部）益处似乎是必然的（除非风险导致一切崩溃），这主要是由强大的市场力量驱动的。相比之下，风险并非注定，我们的行动可以极大地改变风险发生的可能性。

避免给人宣传之嫌。如果人工智能公司一味强调人工智能带来的惊人益处，很容易给人一种在做宣传的印象，或者像是在试图转移人们对缺点的注意力。我也认为，从原则上讲，过分强调自己的优点对个人修养不利。

避免夸大其词。我经常对许多人工智能风险领域的公众人物（更不用说人工智能公司的领导者）讨论后通用人工智能（AGI）时代的方式感到不适，他们说话的语气仿佛自己肩负着像先知一样带领人们走向救赎的使命。我认为，把公司视为可以单方面塑造世界的力量是危险的，把实用的技术目标等同于宗教使命也是危险的。

避免「科幻」色彩。尽管我认为大多数人低估了强大人工智能的益处，但是在讨论激进的人工智能未来时，这个小圈子的人往往带着过度的「科幻」色彩（比如谈论意识上传、太空探索或者赛博朋克风格的场景）。我认为这会导致人们不太认真对待这些观点，觉得它们不够真实。需要说明的是，问题不在于所描述的技术是否可能实现（主文章会详细讨论这一点）—— 更多的是这种「基调」暗含了大量文化偏见，以及关于什么样的未来是理想的、各种社会问题将如何演变等未明说的假设。这样的描述往往最终像是某个小众群体的幻想，反而会让大多数人产生抵触情绪。

尽管存在上述种种顾虑，我依然认为有必要讨论强大人工智能可能带来的美好世界，当然在讨论时要尽量避免前面提到的那些问题。实际上，我认为构建一个真正令人振奋的未来愿景至关重要，而不是仅仅着眼于如何应对危机。强大人工智能的很多影响确实具有对抗性或危险性，但归根结底，我们需要有一些值得奋斗的目标，一个能让所有人都变得更好的共赢未来，一些能让人们搁置分歧、直面未来挑战的愿景。恐惧可以成为一种动力，但这还不够：我们更需要希望。

强大人工智能的积极应用领域非常广泛（包括机器人技术（robotics)、制造业、能源等等），但我将重点关注一些在我看来最有潜力直接改善人类生活质量的领域。以下是我最关注的五个方向：

生物学和身体健康（Biology and physical health)

神经科学和心理健康（Neuroscience and mental health)

经济发展和扶贫（Economic development and poverty)

和平与治理（Peace and governance)

工作与人生意义（Work and meaning)

相比大多数人的预期（除了科幻作品中描绘的「技术奇点」愿景注 2），我的预测可能显得相当激进，但这些都是我经过深思熟虑后的真诚看法。我说的这些很可能会有错（如上所述），但我至少尝试基于对各个领域可能的发展速度及其实际影响的系统分析来形成自己的观点。我很幸运在生物学和神经科学领域都有专业经验，同时我也是一位关注经济发展的知情者，尽管如此，我在很多方面仍可能存在认识偏差。写这篇文章的过程让我意识到，如果能够召集一群领域专家（包括生物学、经济学、国际关系等各个领域的专家），共同撰写一个比我现在这个版本更专业、更有见地的文章将会非常有价值。因此，最好将我的这篇文章视为一个抛砖引玉的尝试。

### Basic assumptions and framework

To make this whole essay more precise and grounded, it's helpful to specify clearly what we mean by powerful AI (i.e. the threshold at which the 5-10 year clock starts counting), as well as laying out a framework for thinking about the effects of such AI once it's present.

What powerful AI (I dislike the term AGI)3 will look like, and when (or if) it will arrive, is a huge topic in itself. It's one I've discussed publicly and could write a completely separate essay on (I probably will at some point). Obviously, many people are skeptical that powerful AI will be built soon and some are skeptical that it will ever be built at all. I think it could come as early as 2026, though there are also ways it could take much longer. But for the purposes of this essay, I'd like to put these issues aside, assume it will come reasonably soon, and focus on what happens in the 5-10 years after that. I also want to assume a definition of what such a system will look like, what its capabilities are and how it interacts, even though there is room for disagreement on this.

By powerful AI, I have in mind an AI model—likely similar to today's LLM's in form, though it might be based on a different architecture, might involve several interacting models, and might be trained differently—with the following properties:

In terms of pure intelligence4, it is smarter than a Nobel Prize winner across most relevant fields – biology, programming, math, engineering, writing, etc. This means it can prove unsolved mathematical theorems, write extremely good novels, write difficult codebases from scratch, etc.

In addition to just being a "smart thing you talk to", it has all the "interfaces" available to a human working virtually, including text, audio, video, mouse and keyboard control, and internet access. It can engage in any actions, communications, or remote operations enabled by this interface, including taking actions on the internet, taking or giving directions to humans, ordering materials, directing experiments, watching videos, making videos, and so on. It does all of these tasks with, again, a skill exceeding that of the most capable humans in the world.

It does not just passively answer questions; instead, it can be given tasks that take hours, days, or weeks to complete, and then goes off and does those tasks autonomously, in the way a smart employee would, asking for clarification as necessary.

It does not have a physical embodiment (other than living on a computer screen), but it can control existing physical tools, robots, or laboratory equipment through a computer; in theory it could even design robots or equipment for itself to use.

The resources used to train the model can be repurposed to run millions of instances of it (this matches projected cluster sizes by ~2027), and the model can absorb information and generate actions at roughly 10x-100x human speed5. It may however be limited by the response time of the physical world or of software it interacts with.

Each of these million copies can act independently on unrelated tasks, or if needed can all work together in the same way humans would collaborate, perhaps with different subpopulations fine-tuned to be especially good at particular tasks.

We could summarize this as a "country of geniuses in a datacenter".

Clearly such an entity would be capable of solving very difficult problems, very fast, but it is not trivial to figure out how fast. Two "extreme" positions both seem false to me. First, you might think that the world would be instantly transformed on the scale of seconds or days ("the Singularity"), as superior intelligence builds on itself and solves every possible scientific, engineering, and operational task almost immediately. The problem with this is that there are real physical and practical limits, for example around building hardware or conducting biological experiments. Even a new country of geniuses would hit up against these limits. Intelligence may be very powerful, but it isn't magic fairy dust.

Second, and conversely, you might believe that technological progress is saturated or rate-limited by real world data or by social factors, and that better-than-human intelligence will add very little6. This seems equally implausible to me—I can think of hundreds of scientific or even social problems where a large group of really smart people would drastically speed up progress, especially if they aren't limited to analysis and can make things happen in the real world (which our postulated country of geniuses can, including by directing or assisting teams of humans).

I think the truth is likely to be some messy admixture of these two extreme pictures, something that varies by task and field and is very subtle in its details. I believe we need new frameworks to think about these details in a productive way.

Economists often talk about "factors of production": things like labor, land, and capital. The phrase "marginal returns to labor/land/capital" captures the idea that in a given situation, a given factor may or may not be the limiting one – for example, an air force needs both planes and pilots, and hiring more pilots doesn't help much if you're out of planes. I believe that in the AI age, we should be talking about the marginal returns to intelligence7, and trying to figure out what the other factors are that are complementary to intelligence and that become limiting factors when intelligence is very high. We are not used to thinking in this way—to asking "how much does being smarter help with this task, and on what timescale?"—but it seems like the right way to conceptualize a world with very powerful AI.

My guess at a list of factors that limit or are complementary to intelligence includes:

Speed of the outside world. Intelligent agents need to operate interactively in the world in order to accomplish things and also to learn8. But the world only moves so fast. Cells and animals run at a fixed speed so experiments on them take a certain amount of time which may be irreducible. The same is true of hardware, materials science, anything involving communicating with people, and even our existing software infrastructure. Furthermore, in science many experiments are often needed in sequence, each learning from or building on the last. All of this means that the speed at which a major project—for example developing a cancer cure—can be completed may have an irreducible minimum that cannot be decreased further even as intelligence continues to increase.

Need for data. Sometimes raw data is lacking and in its absence more intelligence does not help. Today's particle physicists are very ingenious and have developed a wide range of theories, but lack the data to choose between them because particle accelerator data is so limited. It is not clear that they would do drastically better if they were superintelligent—other than perhaps by speeding up the construction of a bigger accelerator.

Intrinsic complexity. Some things are inherently unpredictable or chaotic and even the most powerful AI cannot predict or untangle them substantially better than a human or a computer today. For example, even incredibly powerful AI could predict only marginally further ahead in a chaotic system (such as the three-body problem) in the general case,9 as compared to today's humans and computers.

Constraints from humans. Many things cannot be done without breaking laws, harming humans, or messing up society. An aligned AI would not want to do these things (and if we have an unaligned AI, we're back to talking about risks). Many human societal structures are inefficient or even actively harmful, but are hard to change while respecting constraints like legal requirements on clinical trials, people's willingness to change their habits, or the behavior of governments. Examples of advances that work well in a technical sense, but whose impact has been substantially reduced by regulations or misplaced fears, include nuclear power, supersonic flight, and even elevators.

Physical laws. This is a starker version of the first point. There are certain physical laws that appear to be unbreakable. It's not possible to travel faster than light. Pudding does not unstir. Chips can only have so many transistors per square centimeter before they become unreliable. Computation requires a certain minimum energy per bit erased, limiting the density of computation in the world.

There is a further distinction based on timescales. Things that are hard constraints in the short run may become more malleable to intelligence in the long run. For example, intelligence might be used to develop a new experimental paradigm that allows us to learn in vitro what used to require live animal experiments, or to build the tools needed to collect new data (e.g. the bigger particle accelerator), or to (within ethical limits) find ways around human-based constraints (e.g. helping to improve the clinical trial system, helping to create new jurisdictions where clinical trials have less bureaucracy, or improving the science itself to make human clinical trials less necessary or cheaper).

Thus, we should imagine a picture where intelligence is initially heavily bottlenecked by the other factors of production, but over time intelligence itself increasingly routes around the other factors, even if they never fully dissolve (and some things like physical laws are absolute)10. The key question is how fast it all happens and in what order.

With the above framework in mind, I'll try to answer that question for the five areas mentioned in the introduction.

基本假设和概念框架

为了让本文的论述更加准确和有据可依，我们有必要先明确界定强大人工智能的含义（也就是说，什么样的水平才算是进入那个关键的 5-10 年时间窗口），同时建立一个分析框架来思考这种人工智能一旦出现后会产生的影响。

强大人工智能（我不太喜欢使用「通用人工智能」（AGI）这个术语）注 3 到底会是什么样子，以及它何时（或是否）会出现，这本身就是一个很大的话题。我之前已经公开讨论过这个问题，将来还可能专门写一篇文章来探讨（我可能很快就会写）。显然，很多人怀疑强大人工智能是否能在短期内实现，有些人甚至质疑它是否能够被创造出来。我认为最早可能在 2026 年就能看到它的出现，当然也有可能需要更长的时间。不过在本文中，我想暂时搁置这些争议，假设它会在合理的时间内出现，把重点放在它出现后的 5-10 年里会发生什么。我也想对这样一个系统的具体形态、能力和交互方式做出一些假设，尽管这些方面都可能存在不同观点。

当我谈到强大人工智能时，我指的是一个 AI 模型 —— 它在形式上可能类似于今天的大语言模型（LLM），虽然可能会采用不同的架构，可能涉及多个相互配合的模型，训练方式也可能不同 —— 它具备以下特征：

从纯粹的认知能力来看，它在大多数相关领域（如生物学、编程、数学、工程、写作等）都超过诺贝尔奖得主的水平。这意味着它能够证明尚未解决的数学定理，创作出极高水准的小说，从零开始编写复杂的程序代码等。

它不仅仅是一个「能对话的智能系统」，还具备人类在虚拟环境中使用的所有工具，包括文字、语音、视频、鼠标键盘控制以及网络访问等。它能够通过这些工具进行各种操作、沟通或远程控制，比如在网上执行操作、向人类发出或接收指令、采购物资、指导实验、观看和制作视频等。同样，它在所有这些任务上的表现都超过世界顶尖人才的水平。

它不是简单地被动回答问题，而是能够接受需要数小时、数天甚至数周才能完成的任务，然后像一位能干的员工一样独立完成这些任务，必要时会主动询问细节。

它虽然没有实体形态（只存在于计算机屏幕中），但能够通过计算机控制现有的物理工具、机器人或实验室设备；理论上甚至能够设计专门供自己使用的机器人或设备。

用于训练模型的计算资源可以重新配置来同时运行数百万个这样的智能体（这与预计 2027 年的计算集群规模相符），每个智能体能够以比人类快 10-100 倍的速度吸收信息和采取行动（注 5）。不过，它们可能会受到物理世界反应速度或者所使用软件响应时间的限制。

这数百万个智能体既可以各自独立处理不同任务，也可以在需要时像人类团队一样协同工作。通过特定优化（fine-tuning），某些群体可以在特定任务上发挥特长。

我们可以把这样的系统形象地比喻为「数据中心里的超级智者联盟」。

显然，这样的实体能够快速解决极其复杂的问题，但具体能有多快却不容易判断。在我看来，两种「极端」观点都是错误的。第一种观点认为，世界会在几秒或几天内发生翻天覆地的变化（即所谓的「技术奇点」），因为超级智能会不断强化自身，几乎瞬间就能解决所有可能的科学、工程和操作问题。这种观点的问题在于忽视了现实中的物理和实际限制，比如硬件制造或生物实验方面的约束。即使是一个由超级智者组成的联盟也无法逾越这些限制。智能确实强大，但它不是万能的魔法。

另一种极端观点则认为，技术进步已经趋于饱和，或者受制于现实世界数据或社会因素的制约，认为超人类智能带来的改变微乎其微（注 6）。这种观点在我看来同样站不住脚 —— 我能想到数百个科学甚至社会问题，如果有一大群真正聪明的头脑专注研究，进展速度会大大加快。特别是当这些智能体不仅能进行分析，还能在现实世界中付诸行动时（我们假设的这个智者联盟就具备这种能力，包括指导或协助人类团队）。

我认为现实可能介于这两种极端之间，在不同任务和领域中表现不同，细节上也相当复杂。我们需要新的思维框架来有效地分析这些细节。

经济学家常常谈论「生产要素」（factors of production)：比如劳动力、土地和资本这样的基本生产资源。「边际收益」这个概念说明了在特定情况下，某个要素是否会成为发展的瓶颈 —— 比如空军需要飞机和飞行员，如果飞机数量不足，即使增加再多飞行员也无济于事。我认为在人工智能时代，我们应该讨论「智能的边际收益」（注 7），也就是要找出哪些因素与智能相辅相成，以及当智能水平很高时，哪些因素会成为制约发展的瓶颈。我们还不习惯这样思考 —— 不习惯问「在某个具体任务中，更高的智能能带来多大帮助，需要多长时间才能见效？」—— 但这似乎是理解强大人工智能世界的正确方式。

我认为，以下这些因素可能会限制或补充智能的作用：

现实世界的响应速度。智能体需要与现实世界互动才能完成任务，也需要通过互动来学习（注 8）。但现实世界的运转有其固有速度。生物细胞和动物都有其固定的生长周期，因此相关实验需要一定时间，这个时间可能无法压缩。硬件研发、材料科学、人际沟通，甚至我们现有的软件系统都存在类似限制。此外，科学研究往往需要连续进行多个实验，后一个实验要在前一个实验的基础上推进。这意味着完成一个重大项目 —— 比如开发癌症治疗方法 —— 可能存在一个无法突破的最短时限，即使智能水平继续提高也无法进一步缩短。

数据瓶颈。有时候问题在于缺乏原始数据，在这种情况下，再高的智能也无能为力。今天的粒子物理学家已经非常聪明，提出了各种理论，但由于粒子加速器产生的数据非常有限，他们缺乏足够的数据来验证这些理论。即使他们拥有超人类智能，也未必能取得突破性进展 —— 除非能加快建造更大型加速器的速度。

系统的内在复杂性。有些现象本质上是不可预测或混沌的，即使是最强大的人工智能也难以比现今的人类或计算机做出更好的预测或分析。例如，即使是极其强大的人工智能，在处理混沌系统（如著名的三体运动问题）时，其预测能力也只能比现今的人类和计算机略微提高一点（注 9）。

人为约束。很多事情无法在不违反法律、不伤害人类或不扰乱社会的前提下完成。一个经过伦理约束的人工智能（aligned AI）不会去做这些事情（如果是一个没有伦理约束的人工智能，那我们就要回到讨论风险问题了）。人类社会中存在许多低效甚至有害的制度，但要在遵守临床试验法规、考虑人们改变习惯的意愿或政府行为等约束的同时改变这些制度并不容易。核能、超音速客机，甚至电梯都是很好的例子 —— 这些技术本身运作良好，但其影响力却因为法规限制或人们不必要的恐惧而大打折扣。

物理定律的限制。这是对第一个限制因素的更严格阐述。某些物理定律似乎是永远无法突破的。比如无法超光速运动，混合后的物质无法恢复原状（比如倒入咖啡的牛奶无法分离），芯片在每平方厘米的晶体管数量有上限，否则就会变得不稳定。在计算过程中，擦除每一个比特信息都需要消耗最小量的能量，这就限制了世界上计算密度的上限。

从不同的时间尺度来看，这些限制因素也有所不同。短期内看似不可突破的障碍，从长远来看可能会被智能系统找到应对方法。例如，智能系统可以帮助开发新的实验方法，让我们能在试管中获得过去只能通过活体动物实验才能得到的认知；或者帮助建造收集新数据所需的工具（比如更大型的粒子加速器）；或者在遵守伦理的前提下，找到更好的方式来应对人为限制（比如改进临床试验体系，在管理程序更简化的地区开展临床试验，或者改进科学方法本身，降低人体临床试验的必要性或成本）。

因此，我们可以这样设想：智能系统在初期会受到其他发展要素的严重制约，但随着时间推移，智能本身会逐渐找到方法来克服这些限制，虽然有些限制永远不会完全消除（比如基本物理定律就是绝对的）（注 10）。关键问题在于这一切会以多快的速度、按什么样的顺序展开。

带着这个分析框架，我将针对引言中提到的五个领域来探讨这个问题。

### 1. Biology and health

Biology is probably the area where scientific progress has the greatest potential to directly and unambiguously improve the quality of human life. In the last century some of the most ancient human afflictions (such as smallpox) have finally been vanquished, but many more still remain, and defeating them would be an enormous humanitarian accomplishment. Beyond even curing disease, biological science can in principle improve the baseline quality of human health, by extending the healthy human lifespan, increasing control and freedom over our own biological processes, and addressing everyday problems that we currently think of as immutable parts of the human condition.

In the "limiting factors" language of the previous section, the main challenges with directly applying intelligence to biology are data, the speed of the physical world, and intrinsic complexity (in fact, all three are related to each other). Human constraints also play a role at a later stage, when clinical trials are involved. Let's take these one by one.

Experiments on cells, animals, and even chemical processes are limited by the speed of the physical world: many biological protocols involve culturing bacteria or other cells, or simply waiting for chemical reactions to occur, and this can sometimes take days or even weeks, with no obvious way to speed it up. Animal experiments can take months (or more) and human experiments often take years (or even decades for long-term outcome studies). Somewhat related to this, data is often lacking—not so much in quantity, but quality: there is always a dearth of clear, unambiguous data that isolates a biological effect of interest from the other 10,000 confounding things that are going on, or that intervenes causally in a given process, or that directly measures some effect (as opposed to inferring its consequences in some indirect or noisy way). Even massive, quantitative molecular data, like the proteomics data that I collected while working on mass spectrometry techniques, is noisy and misses a lot (which types of cells were these proteins in? Which part of the cell? At what phase in the cell cycle?).

In part responsible for these problems with data is intrinsic complexity: if you've ever seen a diagram showing the biochemistry of human metabolism, you'll know that it's very hard to isolate the effect of any part of this complex system, and even harder to intervene on the system in a precise or predictable way. And finally, beyond just the intrinsic time that it takes to run an experiment on humans, actual clinical trials involve a lot of bureaucracy and regulatory requirements that (in the opinion of many people, including me) add unnecessary additional time and delay progress.

Given all this, many biologists have long been skeptical of the value of AI and "big data" more generally in biology. Historically, mathematicians, computer scientists, and physicists who have applied their skills to biology over the last 30 years have been quite successful, but have not had the truly transformative impact initially hoped for. Some of the skepticism has been reduced by major and revolutionary breakthroughs like AlphaFold (which has just deservedly won its creators the Nobel Prize in Chemistry) and AlphaProteo11, but there's still a perception that AI is (and will continue to be) useful in only a limited set of circumstances. A common formulation is "AI can do a better job analyzing your data, but it can't produce more data or improve the quality of the data. Garbage in, garbage out".

But I think that pessimistic perspective is thinking about AI in the wrong way. If our core hypothesis about AI progress is correct, then the right way to think of AI is not as a method of data analysis, but as a virtual biologist who performs all the tasks biologists do, including designing and running experiments in the real world (by controlling lab robots or simply telling humans which experiments to run – as a Principal Investigator would to their graduate students), inventing new biological methods or measurement techniques, and so on. It is by speeding up the whole research process that AI can truly accelerate biology. I want to repeat this because it's the most common misconception that comes up when I talk about AI's ability to transform biology: I am not talking about AI as merely a tool to analyze data. In line with the definition of powerful AI at the beginning of this essay, I'm talking about using AI to perform, direct, and improve upon nearly everything biologists do.

To get more specific on where I think acceleration is likely to come from, a surprisingly large fraction of the progress in biology has come from a truly tiny number of discoveries, often related to broad measurement tools or techniques12 that allow precise but generalized or programmable intervention in biological systems. There's perhaps ~1 of these major discoveries per year and collectively they arguably drive >50% of progress in biology. These discoveries are so powerful precisely because they cut through intrinsic complexity and data limitations, directly increasing our understanding and control over biological processes. A few discoveries per decade have enabled both the bulk of our basic scientific understanding of biology, and have driven many of the most powerful medical treatments.

Some examples include:

CRISPR: a technique that allows live editing of any gene in living organisms (replacement of any arbitrary gene sequence with any other arbitrary sequence). Since the original technique was developed, there have been constant improvements to target specific cell types, increasing accuracy, and reducing edits of the wrong gene—all of which are needed for safe use in humans.

Various kinds of microscopy for watching what is going on at a precise level: advanced light microscopes (with various kinds of fluorescent techniques, special optics, etc), electron microscopes, atomic force microscopes, etc.

Genome sequencing and synthesis, which has dropped in cost by several orders of magnitude in the last couple decades.

Optogenetic techniques that allow you to get a neuron to fire by shining a light on it.

mRNA vaccines that, in principle, allow us to design a vaccine against anything and then quickly adapt it (mRNA vaccines of course became famous during COVID).

Cell therapies such as CAR-T that allow immune cells to be taken out of the body and "reprogrammed" to attack, in principle, anything.

Conceptual insights like the germ theory of disease or the realization of a link between the immune system and cancer 13.

I'm going to the trouble of listing all these technologies because I want to make a crucial claim about them: I think their rate of discovery could be increased by 10x or more if there were a lot more talented, creative researchers. Or, put another way, I think the returns to intelligence are high for these discoveries, and that everything else in biology and medicine mostly follows from them.

Why do I think this? Because of the answers to some questions that we should get in the habit of asking when we're trying to determine "returns to intelligence". First, these discoveries are generally made by a tiny number of researchers, often the same people repeatedly, suggesting skill and not random search (the latter might suggest lengthy experiments are the limiting factor). Second, they often "could have been made" years earlier than they were: for example, CRISPR was a naturally occurring component of the immune system in bacteria that's been known since the 80's, but it took another 25 years for people to realize it could be repurposed for general gene editing. They also are often delayed many years by lack of support from the scientific community for promising directions (see this profile on the inventor of mRNA vaccines; similar stories abound). Third, successful projects are often scrappy or were afterthoughts that people didn't initially think were promising, rather than massively funded efforts. This suggests that it's not just massive resource concentration that drives discoveries, but ingenuity.

Finally, although some of these discoveries have "serial dependence" (you need to make discovery A first in order to have the tools or knowledge to make discovery B)—which again might create experimental delays—many, perhaps most, are independent, meaning many at once can be worked on in parallel. Both these facts, and my general experience as a biologist, strongly suggest to me that there are hundreds of these discoveries waiting to be made if scientists were smarter and better at making connections between the vast amount of biological knowledge humanity possesses (again consider the CRISPR example). The success of AlphaFold/AlphaProteo at solving important problems much more effectively than humans, despite decades of carefully designed physics modeling, provides a proof of principle (albeit with a narrow tool in a narrow domain) that should point the way forward.

Thus, it's my guess that powerful AI could at least 10x the rate of these discoveries, giving us the next 50-100 years of biological progress in 5-10 years.14 Why not 100x? Perhaps it is possible, but here both serial dependence and experiment times become important: getting 100 years of progress in 1 year requires a lot of things to go right the first time, including animal experiments and things like designing microscopes or expensive lab facilities. I'm actually open to the (perhaps absurd-sounding) idea that we could get 1000 years of progress in 5-10 years, but very skeptical that we can get 100 years in 1 year. Another way to put it is I think there's an unavoidable constant delay: experiments and hardware design have a certain "latency" and need to be iterated upon a certain "irreducible" number of times in order to learn things that can't be deduced logically. But massive parallelism may be possible on top of that15.

What about clinical trials? Although there is a lot of bureaucracy and slowdown associated with them, the truth is that a lot (though by no means all!) of their slowness ultimately derives from the need to rigorously evaluate drugs that barely work or ambiguously work. This is sadly true of most therapies today: the average cancer drug increases survival by a few months while having significant side effects that need to be carefully measured (there's a similar story for Alzheimer's drugs). This leads to huge studies (in order to achieve statistical power) and difficult tradeoffs which regulatory agencies generally aren't great at making, again because of bureaucracy and the complexity of competing interests.

When something works really well, it goes much faster: there's an accelerated approval track and the ease of approval is much greater when effect sizes are larger. mRNA vaccines for COVID were approved in 9 months—much faster than the usual pace. That said, even under these conditions clinical trials are still too slow—mRNA vaccines arguably should have been approved in ~2 months. But these kinds of delays (~1 year end-to-end for a drug) combined with massive parallelization and the need for some but not too much iteration ("a few tries") are very compatible with radical transformation in 5-10 years. Even more optimistically, it is possible that AI-enabled biological science will reduce the need for iteration in clinical trials by developing better animal and cell experimental models (or even simulations) that are more accurate in predicting what will happen in humans. This will be particularly important in developing drugs against the aging process, which plays out over decades and where we need a faster iteration loop.

Finally, on the topic of clinical trials and societal barriers, it is worth pointing out explicitly that in some ways biomedical innovations have an unusually strong track record of being successfully deployed, in contrast to some other technologies16. As mentioned in the introduction, many technologies are hampered by societal factors despite working well technically. This might suggest a pessimistic perspective on what AI can accomplish. But biomedicine is unique in that although the process of developing drugs is overly cumbersome, once developed they generally are successfully deployed and used.

To summarize the above, my basic prediction is that AI-enabled biology and medicine will allow us to compress the progress that human biologists would have achieved over the next 50-100 years into 5-10 years. I'll refer to this as the "compressed 21st century": the idea that after powerful AI is developed, we will in a few years make all the progress in biology and medicine that we would have made in the whole 21st century.

Although predicting what powerful AI can do in a few years remains inherently difficult and speculative, there is some concreteness to asking "what could humans do unaided in the next 100 years?". Simply looking at what we've accomplished in the 20th century, or extrapolating from the first 2 decades of the 21st, or asking what "10 CRISPR's and 50 CAR-T's" would get us, all offer practical, grounded ways to estimate the general level of progress we might expect from powerful AI.

Below I try to make a list of what we might expect. This is not based on any rigorous methodology, and will almost certainly prove wrong in the details, but it's trying to get across the general level of radicalism we should expect:

Reliable prevention and treatment of nearly all17 natural infectious disease. Given the enormous advances against infectious disease in the 20th century, it is not radical to imagine that we could more or less "finish the job" in a compressed 21st. mRNA vaccines and similar technology already point the way towards "vaccines for anything". Whether infectious disease is fully eradicated from the world (as opposed to just in some places) depends on questions about poverty and inequality, which are discussed in Section 3.

Elimination of most cancer. Death rates from cancer have been dropping ~2% per year for the last few decades; thus we are on track to eliminate most cancer in the 21st century at the current pace of human science. Some subtypes have already been largely cured (for example some types of leukemia with CAR-T therapy), and I'm perhaps even more excited for very selective drugs that target cancer in its infancy and prevent it from ever growing. AI will also make possible treatment regimens very finely adapted to the individualized genome of the cancer—these are possible today, but hugely expensive in time and human expertise, which AI should allow us to scale. Reductions of 95% or more in both mortality and incidence seem possible. That said, cancer is extremely varied and adaptive, and is likely the hardest of these diseases to fully destroy. It would not be surprising if an assortment of rare, difficult malignancies persists.

Very effective prevention and effective cures for genetic disease. Greatly improved embryo screening will likely make it possible to prevent most genetic disease, and some safer, more reliable descendant of CRISPR may cure most genetic disease in existing people. Whole-body afflictions that affect a large fraction of cells may be the last holdouts, however.

Prevention of Alzheimer's. We've had a very hard time figuring out what causes Alzheimer's (it is somehow related to beta-amyloid protein, but the actual details seem to be very complex). It seems like exactly the type of problem that can be solved with better measurement tools that isolate biological effects; thus I am bullish about AI's ability to solve it. There is a good chance it can eventually be prevented with relatively simple interventions, once we actually understand what is going on. That said, damage from already-existing Alzheimer's may be very difficult to reverse.

Improved treatment of most other ailments. This is a catch-all category for other ailments including diabetes, obesity, heart disease, autoimmune diseases, and more. Most of these seem "easier" to solve than cancer and Alzheimer's and in many cases are already in steep decline. For example, deaths from heart disease have already declined over 50%, and simple interventions like GLP-1 agonists have already made huge progress against obesity and diabetes.

Biological freedom. The last 70 years featured advances in birth control, fertility, management of weight, and much more. But I suspect AI-accelerated biology will greatly expand what is possible: weight, physical appearance, reproduction, and other biological processes will be fully under people's control. We'll refer to these under the heading of biological freedom: the idea that everyone should be empowered to choose what they want to become and live their lives in the way that most appeals to them. There will of course be important questions about global equality of access; see Section 3 for these.

Doubling of the human lifespan18. This might seem radical, but life expectancy increased almost 2x in the 20th century (from ~40 years to ~75), so it's "on trend" that the "compressed 21st" would double it again to 150. Obviously the interventions involved in slowing the actual aging process will be different from those that were needed in the last century to prevent (mostly childhood) premature deaths from disease, but the magnitude of change is not unprecedented19. Concretely, there already exist drugs that increase maximum lifespan in rats by 25-50% with limited ill-effects. And some animals (e.g. some types of turtle) already live 200 years, so humans are manifestly not at some theoretical upper limit. At a guess, the most important thing that is needed might be reliable, non-Goodhart-able biomarkers of human aging, as that will allow fast iteration on experiments and clinical trials. Once human lifespan is 150, we may be able to reach "escape velocity", buying enough time that most of those currently alive today will be able to live as long as they want, although there's certainly no guarantee this is biologically possible.

It is worth looking at this list and reflecting on how different the world will be if all of it is achieved 7-12 years from now (which would be in line with an aggressive AI timeline). It goes without saying that it would be an unimaginable humanitarian triumph, the elimination all at once of most of the scourges that have haunted humanity for millennia. Many of my friends and colleagues are raising children, and when those children grow up, I hope that any mention of disease will sound to them the way scurvy, smallpox, or bubonic plague sounds to us. That generation will also benefit from increased biological freedom and self-expression, and with luck may also be able to live as long as they want.

It's hard to overestimate how surprising these changes will be to everyone except the small community of people who expected powerful AI. For example, thousands of economists and policy experts in the US currently debate how to keep Social Security and Medicare solvent, and more broadly how to keep down the cost of healthcare (which is mostly consumed by those over 70 and especially those with terminal illnesses such as cancer). The situation for these programs is likely to be radically improved if all this comes to pass20, as the ratio of working age to retired population will change drastically. No doubt these challenges will be replaced with others, such as how to ensure widespread access to the new technologies, but it is worth reflecting on how much the world will change even if biology is the only area to be successfully accelerated by AI.

生物学与健康

在科学进步能直接、明确地改善人类生活质量这一方面，生物学可能是潜力最大的领域。上个世纪，人类已经征服了一些最古老的疾病（如天花），但仍有更多疾病需要克服，如果能战胜它们将是一项重大的人道主义成就。除了治愈疾病之外，生物科学理论上还可以从根本上提升人类的健康水平：延长健康寿命，增强人们对自身生理过程的掌控能力，以及解决许多我们目前认为无法改变的人类生理局限。

回顾前文讨论的「限制因素」框架，将智能技术直接应用于生物学领域时，主要面临数据、物理世界反应速度和内在复杂性这三大挑战（实际上这三个因素是相互关联的）。在涉及临床试验的后期阶段，人为约束也会成为一个重要因素。让我们逐一分析这些挑战。

在细胞、动物，甚至化学过程的实验中，物理世界的反应速度是一个天然的限制：许多生物学实验流程需要培养细菌或其他细胞，或者只是等待化学反应的进行，这可能需要数天甚至数周的时间，而且目前没有明显的方法可以加快这个过程。动物实验可能需要数月（有时甚至更长），人体实验通常需要数年（对于研究长期效果甚至可能需要数十年）。

与此相关的另一个问题是数据质量不足 —— 这里说的不是数据量不够，而是数据质量不够理想：我们总是缺乏那种清晰、明确的数据，能够将我们关注的生物学效应与其他成千上万个干扰因素区分开来，或者能够准确地进行因果关系研究，或者能够直接测量某些效应（而不是通过间接或不精确的方式来推测其结果）。即使是大规模的、定量的分子数据，比如我在研究质谱技术（mass spectrometry）时收集的蛋白质组学（proteomics）数据，也存在很多不确定性和信息缺失（比如这些蛋白质具体在哪种细胞中？在细胞的哪个部位？在细胞生长周期的哪个阶段？）。

造成这些数据问题的部分原因是生物系统本身的复杂性：如果你曾经看过描绘人体代谢生物化学过程的图表，你就会明白想要研究这个复杂系统中任何一个环节的独立作用有多么困难，更不用说想要以精确或可预测的方式来干预这个系统了。此外，除了人体实验本身所需的基本时间外，实际的临床试验还涉及大量行政程序和监管要求，这些（在包括我在内的许多人看来）都增加了不必要的时间成本，拖慢了研究进展。

考虑到这些困难，许多生物学家长期以来都对人工智能和「大数据」（big data）在生物学领域的价值持怀疑态度。在过去 30 年里，数学家、计算机科学家和物理学家将他们的专业知识应用到生物学领域，确实取得了不少成功，但并没有达到人们最初期待的那种革命性突破。虽然像 AlphaFold（其开发者刚刚获得了实至名归的诺贝尔化学奖）和 AlphaProteo（注 11）这样的重大突破在某种程度上减少了这种怀疑，但人们仍然普遍认为人工智能只能（而且将继续）在有限的场景下发挥作用。一种常见的说法是：「人工智能可以帮助我们更好地分析数据，但它既不能创造新数据，也不能提升数据质量。如果原始数据质量差，分析结果也不会好到哪里去。」

但我认为这种悲观的观点是对人工智能的误解。如果我们关于人工智能发展的核心假设是正确的，那么我们应该把人工智能看作一个虚拟的生物学家，而不是简单的数据分析工具。这个虚拟生物学家可以完成生物学家的所有工作，包括在现实世界中设计和执行实验（通过控制实验室机器人，或者像首席研究员（Principal Investigator）指导研究生那样告诉人类该做什么实验），发明新的生物学方法或测量技术等。正是通过加速整个研究过程，人工智能才能真正推动生物学的快速发展。我想特别强调这一点，因为这是我在讨论人工智能改变生物学能力时人们最常见的误解：我说的不仅仅是把人工智能当作数据分析工具。正如本文开头对强大人工智能的定义所言，我指的是使用人工智能来执行、指导和改进生物学家几乎所有的工作。

让我来具体说明这种加速效应可能来自哪里。在生物学领域，一个令人惊讶的现象是：绝大部分进展都源自极少数关键发现，这些发现通常与广泛适用的测量工具或技术相关（注 12），它们能够对生物系统进行精确但通用或可编程的干预。这样的重大发现大约每年只有一个，但它们共同推动了生物学超过 50% 的进展。这些发现之所以如此强大，是因为它们能够突破内在复杂性和数据限制的障碍，直接增进我们对生物过程的理解和控制能力。每十年仅仅几个这样的发现，就推动了我们对生物学基础科学的理解，并促成了许多最有效的医疗治疗方法的诞生。

以下是一些典型例子：

CRISPR（基因编辑技术）：这项技术能够在活体生物中编辑任何基因（即用任意基因序列替换原有的基因序列）。自从这项基础技术问世以来，科学家们一直在不断改进，使其能够精确定位特定类型的细胞，提高编辑准确性，减少错误编辑的发生 —— 这些改进都是确保该技术能在人类身上安全使用的必要条件。

各种显微镜技术，用于精确观察微观世界：包括配备各种荧光技术和特殊光学系统的先进光学显微镜，电子显微镜（electron microscopes），原子力显微镜（atomic force microscopes）等。

基因组测序和合成技术（genome sequencing and synthesis），其成本在过去几十年中大幅降低，降幅达到了数千倍。

光遗传学（optogenetics）技术，能够通过光照控制神经元的激活。

信使 RNA（mRNA）疫苗技术，理论上可以用来设计针对任何疾病的疫苗，并能快速调整（这项技术在新冠疫情期间广为人知）。

细胞疗法，例如 CAR-T 疗法，可以将患者体内的免疫细胞取出并进行「重新编程」，使其能够靶向攻击特定目标。

一些概念性突破，比如病原体致病理论，或者发现免疫系统与癌症之间的关联（注 13）。

我之所以详细列举这些技术，是想说明一个重要观点：如果有更多富有才华和创造力的研究人员，这类发现的速度可能会提高 10 倍或更多。换句话说，我认为在这些关键发现上投入更多智力资源会带来极高的回报，而生物学和医学领域的其他进展主要都是建立在这些基础性发现之上的。

为什么我会这样认为？这是基于我们在评估「智力投入的收益」时应该考虑的几个关键问题。首先，这些重大发现通常都是由极少数研究人员做出的，而且经常是同一批人反复取得突破，这表明是专业技能而非随机尝试在起决定性作用（如果是后者，那就意味着冗长的实验过程才是主要限制因素）。其次，很多发现实际上「早就可能」被发现：比如 CRISPR 是细菌免疫系统中一个自然存在的组成部分，早在 80 年代就已被发现，但科学家们花了 25 年才意识到它可以被改造用于通用基因编辑。还有很多发现之所以被推迟多年，是因为科学界没有给那些有前途的研究方向足够的支持（比如 mRNA 疫苗发明者的经历就是一个典型案例，类似的故事还有很多）。第三，很多成功的项目往往起源于小规模的研究或者最初并不被看好的想法，而不是那些获得大量资金支持的项目。这说明推动重大发现的关键在于创新思维，而不仅仅是资源的投入。

最后，虽然这些发现中有些存在先后顺序的依赖关系（即需要先有发现 A 提供的工具或知识，才能实现发现 B）—— 这确实可能导致实验过程的延迟 —— 但是很多，也许是大多数发现都是相互独立的，这意味着我们可以同时推进多项研究。这些事实，再加上我作为生物学家的经验，都强烈表明：如果科学家能够更聪明地梳理和连接人类已经掌握的海量生物学知识，还有数百个类似的突破正等待被发现（CRISPR 的例子就很能说明这一点）。虽然科学家们在过去几十年中投入了大量精力进行物理建模，但 AlphaFold/AlphaProteo 在解决重要问题时表现出了超越人类的能力，这提供了一个重要的证明（尽管仅限于特定领域的特定工具），为我们指明了未来的方向。

因此，我预估强大的人工智能至少能将这类发现的速度提高 10 倍，让我们在 5-10 年内实现原本需要 50-100 年才能达到的生物学进展（注 14）。为什么不是提高 100 倍呢？理论上这也许是可能的，但是顺序依赖性和实验时间会成为重要制约：要在 1 年内实现相当于 100 年的进展，就需要很多环节一次性就做对，包括动物实验、显微镜设计或昂贵实验设施的建设等。我对一个可能听起来很大胆的想法持开放态度，即我们可能在 5-10 年内获得相当于 1000 年的进展，但我非常怀疑在 1 年内获得相当于 100 年的进展是否可能。换句话说，我认为存在一个无法避免的固有时间成本：实验和硬件设计都有其固有的「响应时间」，需要进行一定最小次数的反复尝试才能获得那些无法通过纯逻辑推导得出的知识。不过，在这个基础上，我们可以通过大规模并行处理来加速进展（注 15）。

那么临床试验呢？虽然行政程序和审批流程确实造成了许多延误，但事实是，试验进展缓慢的主要原因（虽然不是全部原因！）在于我们需要严格评估那些效果并不显著或效果不确定的药物。令人遗憾的是，这种情况在当今的大多数治疗方法中都很普遍：一般来说，癌症药物只能延长患者几个月的寿命，同时还会产生需要仔细评估的严重副作用（阿尔茨海默病的药物也面临类似情况）。这就需要开展大规模研究（为了获得具有统计学意义的结果）和进行复杂的利弊权衡，而监管机构往往难以有效处理这些权衡，这又与行政程序的复杂性和各方利益的冲突有关。

但当某个治疗方法确实非常有效时，审批过程会快得多：对于效果显著的药物，不仅有快速审批通道，获得批准的难度也会大大降低。新冠疫情期间的 mRNA 疫苗在 9 个月内就获得了批准 —— 这比常规速度快得多。不过，即使是这样的速度仍然可以更快 —— 从理论上说，mRNA 疫苗本可以在大约 2 个月内就获得批准。但是，这种程度的延迟（药物从开始到完成大约需要 1 年），再加上大规模并行研发和适度的反复试验（多试几次），与我们期望在 5-10 年内实现根本性突破的预期是相符的。从更乐观的角度来看，人工智能驱动的生物科学可能会通过开发更好的动物和细胞实验模型（甚至是计算机模拟），来提高对人体反应的预测准确性，从而减少临床试验中反复试验的需求。这一点在开发抗衰老药物时尤其重要，因为衰老过程持续数十年，我们需要更快的研发反馈循环。

最后，关于临床试验和社会障碍，有一点值得特别指出：与其他一些技术相比，生物医学创新在实际应用方面有着特别出色的成功记录（注 16）。正如引言中提到的，很多技术尽管在技术层面运作良好，却常常受到社会因素的制约。这似乎暗示我们应该对人工智能的潜力持谨慎态度。但生物医学领域是独特的：虽然药物的研发过程可能过于繁琐，但一旦开发成功，这些药物通常都能顺利地推广使用。

综上所述，我的基本预测是：在人工智能的推动下，生物学和医学领域将实现一个惊人的跨越 —— 把人类生物学家原本需要 50-100 年才能达到的进展，压缩到 5-10 年内完成。我把这种现象称为「21 世纪的时间压缩」：也就是说，一旦强大的人工智能系统开发出来，我们将在短短几年内实现原本需要整个 21 世纪才能完成的生物学和医学进步。

预测强大的人工智能在短短几年内能够实现什么，本质上仍然充满不确定性。但是，如果我们换个角度，去思考「如果没有人工智能的帮助，人类在未来 100 年内能够实现什么」，这个问题就会变得更容易把握。我们可以通过几种实用的方法来估计人工智能可能带来的整体进展：回顾 20 世纪人类已经取得的成就，或者从 21 世纪前 20 年的发展趋势推断，又或者设想「如果有 10 项像 CRISPR 这样的技术突破和 50 项像 CAR-T 这样的治疗方法会带来什么样的改变」。这些都能帮助我们更实际地评估强大人工智能可能带来的进展。

下面我将列出一些可能实现的突破。这个预测并非基于严格的科学方法，具体细节很可能与未来的实际情况有所出入，但它能让我们对即将到来的变革程度有一个大致的认识：

可靠预防和治疗几乎所有自然传染病（注 17）。考虑到 20 世纪人类在对抗传染病方面取得的巨大进展，我们完全可以期待在这个「压缩的 21 世纪」中彻底解决传染病问题。信使 RNA（mRNA）疫苗和相关技术已经为我们开创了「为任何疾病开发疫苗」的可能。至于能否从全球范围内（而不是仅在某些地区）彻底根除传染病，这将取决于如何解决贫困和不平等等问题，我们会在第 3 节详细讨论这一点。

消除大多数癌症。在过去几十年里，癌症死亡率每年约下降 2%。按照目前人类科学发展的速度，我们有望在 21 世纪消除大多数癌症。现在已经有一些类型的癌症基本被攻克（例如使用 CAR-T 细胞疗法治疗某些类型的白血病），而我对那些能够在癌症早期进行精准治疗并防止其扩散的药物更加充满期待。人工智能还将使得根据每个病人的癌症基因组特征来制定个性化治疗方案变得可能 —— 虽然这种方法现在就能实现，但需要投入大量时间和专业人才，而人工智能可以帮助我们大规模推广这种治疗方式。我们有望将癌症的死亡率和发病率都降低 95% 以上。不过，由于癌症类型繁多且具有很强的适应性，它可能是这些疾病中最难彻底根除的。即使在未来，一些罕见的、难以治疗的恶性肿瘤可能仍会存在。

有效预防和治疗遗传性疾病。通过更先进的胚胎筛查技术，我们可能能够预防大多数遗传性疾病，同时某种更安全、更可靠的新一代基因编辑技术（在 CRISPR 基础上的改进）可能能够治愈已经出现的大多数遗传性疾病。不过，那些影响人体大部分细胞的全身性疾病可能是最后需要攻克的难关。

预防阿尔茨海默病。目前我们在查明阿尔茨海默病的致病机理方面仍面临很大困难（我们知道它与 β-淀粉样蛋白（beta-amyloid protein）有关，但具体机制非常复杂）。这正是那种可能通过更精密的测量工具来研究其生物学机制从而找到解决方案的问题。因此，我相信人工智能很有希望解决这个难题。一旦我们真正理解了其发病机制，就很可能通过相对简单的干预手段来预防这种疾病。不过，对于已经发生的阿尔茨海默病造成的大脑损伤，可能还是很难逆转。

改善其他疾病的治疗效果。这包括了一系列其他疾病，如糖尿病（diabetes)、肥胖（obesity)、心脏病、自身免疫疾病（autoimmune diseases）等。这些疾病大多看起来比癌症和阿尔茨海默病更容易解决，而且许多疾病的发病率已经在显著下降。比如，心脏病的死亡率已经降低了超过 50%，而像 GLP-1 受体激动剂（GLP-1 agonists）这样相对简单的治疗方法在对抗肥胖和糖尿病方面已经取得了显著成效。

生物特征的自主选择。过去 70 年里，人类在避孕、生育和体重管理等方面已经取得了很大进展。但我认为，在人工智能加速的生物学发展推动下，可能的改变会更加深远：人们将能够完全掌控自己的体重、外貌、生殖能力以及其他生理特征。我们把这种能力称为「生物自由」（biological freedom)：让每个人都能够自主选择想要成为什么样的人，按照自己理想的方式生活。当然，这里会涉及到全球范围内机会平等的重要问题，我们会在第 3 节详细讨论这一点。

人类寿命延长一倍（注 18）。这个预测可能听起来很大胆，但考虑到 20 世纪人类平均寿命就已经增加了近一倍（从大约 40 岁增加到 75 岁左右），那么在这个「压缩的 21 世纪」中将寿命再延长一倍达到 150 岁也是符合历史发展趋势的。当然，延缓实际衰老过程所需的干预手段，与上世纪用来预防（主要是儿童期）疾病导致的过早死亡的措施是完全不同的，但这种规模的变化并非没有先例（注 19）。实际上，现在已经有一些药物能够在不产生严重副作用的情况下，将实验鼠的最长寿命延长 25-50%。而且，某些物种（例如一些种类的乌龟）本来就能活 200 年，这说明人类显然还没有达到生命长度的理论极限。我认为，最关键的突破可能在于开发可靠的人类衰老生物标志物（biomarkers of aging），这些标志物必须能够准确反映衰老程度而不会被人为干预所扭曲，因为这将使我们能够快速开展实验和临床试验。一旦人类寿命达到 150 岁，我们可能就达到了一个临界点：为当今在世的大多数人赢得足够的时间，让他们有机会活到自己期望的年龄 —— 当然，这在生物学上是否可行还需要进一步验证。

让我们回顾这个清单，想象一下如果所有这些突破都能在未来 7-12 年内实现（这符合人工智能快速发展的预期时间表），世界将会发生怎样的变化。毫无疑问，这将是人类历史上一个划时代的人道主义胜利，它将一举消除困扰人类数千年的大多数疾病威胁。我的许多朋友和同事现在正在养育下一代，等到这些孩子长大后，我希望疾病这个词对他们来说就像坏血病、天花或黑死病对我们这一代人一样遥远陌生。这一代人不仅将享有更大的生理特征自主权和自我表达的自由，而且很可能能够活到他们期望的年龄。

这些变化之巨大，恐怕会让除了那少数预见到强大人工智能潜力的人之外的所有人都感到难以置信。举个例子：目前在美国，数千名经济学家和政策专家正在讨论如何维持社会保障（Social Security）和医疗保险（Medicare）体系的可持续性，以及更广泛地探讨如何控制医疗支出（这些支出主要来自 70 岁以上的人群，尤其是那些患有癌症等终末期疾病的患者）。如果这些生物医学突破能够实现，这些福利项目的状况很可能会得到根本性改善（注 20），因为工作年龄人口与退休人口的比例将发生显著变化。当然，这些问题解决后可能会出现新的挑战，比如如何确保这些新技术能够惠及更广泛的人群。但值得注意的是，即使人工智能只在生物学领域带来突破性进展，世界也将发生翻天覆地的变化。

### 2. Neuroscience and mind

In the previous section I focused on physical diseases and biology in general, and didn't cover neuroscience or mental health. But neuroscience is a subdiscipline of biology and mental health is just as important as physical health. In fact, if anything, mental health affects human well-being even more directly than physical health. Hundreds of millions of people have very low quality of life due to problems like addiction, depression, schizophrenia, low-functioning autism, PTSD, psychopathy21, or intellectual disabilities. Billions more struggle with everyday problems that can often be interpreted as much milder versions of one of these severe clinical disorders. And as with general biology, it may be possible to go beyond addressing problems to improving the baseline quality of human experience.

The basic framework that I laid out for biology applies equally to neuroscience. The field is propelled forward by a small number of discoveries often related to tools for measurement or precise intervention – in the list of those above, optogenetics was a neuroscience discovery, and more recently CLARITY and expansion microscopy are advances in the same vein, in addition to many of the general cell biology methods directly carrying over to neuroscience. I think the rate of these advances will be similarly accelerated by AI and therefore that the framework of "100 years of progress in 5-10 years" applies to neuroscience in the same way it does to biology and for the same reasons. As in biology, the progress in 20th century neuroscience was enormous – for example we didn't even understand how or why neurons fired until the 1950's. Thus, it seems reasonable to expect AI-accelerated neuroscience to produce rapid progress over a few years.

There is one thing we should add to this basic picture, which is that some of the things we've learned (or are learning) about AI itself in the last few years are likely to help advance neuroscience, even if it continues to be done only by humans. Interpretability is an obvious example: although biological neurons superficially operate in a completely different manner from artificial neurons (they communicate via spikes and often spike rates, so there is a time element not present in artificial neurons, and a bunch of details relating to cell physiology and neurotransmitters modifies their operation substantially), the basic question of "how do distributed, trained networks of simple units that perform combined linear/non-linear operations work together to perform important computations" is the same, and I strongly suspect the details of individual neuron communication will be abstracted away in most of the interesting questions about computation and circuits22. As just one example of this, a computational mechanism discovered by interpretability researchers in AI systems was recently rediscovered in the brains of mice.

It is much easier to do experiments on artificial neural networks than on real ones (the latter often requires cutting into animal brains), so interpretability may well become a tool for improving our understanding of neuroscience. Furthermore, powerful AI's will themselves probably be able to develop and apply this tool better than humans can.

Beyond just interpretability though, what we have learned from AI about how intelligent systems are trained should (though I am not sure it has yet) cause a revolution in neuroscience. When I was working in neuroscience, a lot of people focused on what I would now consider the wrong questions about learning, because the concept of the scaling hypothesis / bitter lesson didn't exist yet. The idea that a simple objective function plus a lot of data can drive incredibly complex behaviors makes it more interesting to understand the objective functions and architectural biases and less interesting to understand the details of the emergent computations. I have not followed the field closely in recent years, but I have a vague sense that computational neuroscientists have still not fully absorbed the lesson. My attitude to the scaling hypothesis has always been "aha – this is an explanation, at a high level, of how intelligence works and how it so easily evolved", but I don't think that's the average neuroscientist's view, in part because the scaling hypothesis as "the secret to intelligence" isn't fully accepted even within AI.

I think that neuroscientists should be trying to combine this basic insight with the particularities of the human brain (biophysical limitations, evolutionary history, topology, details of motor and sensory inputs/outputs) to try to figure out some of neuroscience's key puzzles. Some likely are, but I suspect it's not enough yet, and that AI neuroscientists will be able to more effectively leverage this angle to accelerate progress.

I expect AI to accelerate neuroscientific progress along four distinct routes, all of which can hopefully work together to cure mental illness and improve function:

Traditional molecular biology, chemistry, and genetics. This is essentially the same story as general biology in section 1, and AI can likely speed it up via the same mechanisms. There are many drugs that modulate neurotransmitters in order to alter brain function, affect alertness or perception, change mood, etc., and AI can help us invent many more. AI can probably also accelerate research on the genetic basis of mental illness.

Fine-grained neural measurement and intervention. This is the ability to measure what a lot of individual neurons or neuronal circuits are doing, and intervene to change their behavior. Optogenetics and neural probes are technologies capable of both measurement and intervention in live organisms, and a number of very advanced methods (such as molecular ticker tapes to read out the firing patterns of large numbers of individual neurons) have also been proposed and seem possible in principle.

Advanced computational neuroscience. As noted above, both the specific insights and the gestalt of modern AI can probably be applied fruitfully to questions in systems neuroscience, including perhaps uncovering the real causes and dynamics of complex diseases like psychosis or mood disorders.

Behavioral interventions. I haven't much mentioned it given the focus on the biological side of neuroscience, but psychiatry and psychology have of course developed a wide repertoire of behavioral interventions over the 20th century; it stands to reason that AI could accelerate these as well, both the development of new methods and helping patients to adhere to existing methods. More broadly, the idea of an "AI coach" who always helps you to be the best version of yourself, who studies your interactions and helps you learn to be more effective, seems very promising.

It's my guess that these four routes of progress working together would, as with physical disease, be on track to lead to the cure or prevention of most mental illness in the next 100 years even if AI was not involved – and thus might reasonably be completed in 5-10 AI-accelerated years. Concretely my guess at what will happen is something like:

Most mental illness can probably be cured. I'm not an expert in psychiatric disease (my time in neuroscience was spent building probes to study small groups of neurons) but it's my guess that diseases like PTSD, depression, schizophrenia, addiction, etc. can be figured out and very effectively treated via some combination of the four directions above. The answer is likely to be some combination of "something went wrong biochemically" (although it could be very complex) and "something went wrong with the neural network, at a high level". That is, it's a systems neuroscience question—though that doesn't gainsay the impact of the behavioral interventions discussed above. Tools for measurement and intervention, especially in live humans, seem likely to lead to rapid iteration and progress.

Conditions that are very "structural" may be more difficult, but not impossible. There's some evidence that psychopathy is associated with obvious neuroanatomical differences – that some brain regions are simply smaller or less developed in psychopaths. Psychopaths are also believed to lack empathy from a young age; whatever is different about their brain, it was probably always that way. The same may be true of some intellectual disabilities, and perhaps other conditions. Restructuring the brain sounds hard, but it also seems like a task with high returns to intelligence. Perhaps there is some way to coax the adult brain into an earlier or more plastic state where it can be reshaped. I'm very uncertain how possible this is, but my instinct is to be optimistic about what AI can invent here.

Effective genetic prevention of mental illness seems possible. Most mental illness is partially heritable, and genome-wide association studies are starting to gain traction on identifying the relevant factors, which are often many in number. It will probably be possible to prevent most of these diseases via embryo screening, similar to the story with physical disease. One difference is that psychiatric disease is more likely to be polygenic (many genes contribute), so due to complexity there's an increased risk of unknowingly selecting against positive traits that are correlated with disease. Oddly however, in recent years GWAS studies seem to suggest that these correlations might have been overstated. In any case, AI-accelerated neuroscience may help us to figure these things out. Of course, embryo screening for complex traits raises a number of societal issues and will be controversial, though I would guess that most people would support screening for severe or debilitating mental illness.

Everyday problems that we don't think of as clinical disease will also be solved. Most of us have everyday psychological problems that are not ordinarily thought of as rising to the level of clinical disease. Some people are quick to anger, others have trouble focusing or are often drowsy, some are fearful or anxious, or react badly to change. Today, drugs already exist to help with e.g. alertness or focus (caffeine, modafinil, ritalin) but as with many other previous areas, much more is likely to be possible. Probably many more such drugs exist and have not been discovered, and there may also be totally new modalities of intervention, such as targeted light stimulation (see optogenetics above) or magnetic fields. Given how many drugs we've developed in the 20th century that tune cognitive function and emotional state, I'm very optimistic about the "compressed 21st" where everyone can get their brain to behave a bit better and have a more fulfilling day-to-day experience.

Human baseline experience can be much better. Taking one step further, many people have experienced extraordinary moments of revelation, creative inspiration, compassion, fulfillment, transcendence, love, beauty, or meditative peace. The character and frequency of these experiences differs greatly from person to person and within the same person at different times, and can also sometimes be triggered by various drugs (though often with side effects). All of this suggests that the "space of what is possible to experience" is very broad and that a larger fraction of people's lives could consist of these extraordinary moments. It is probably also possible to improve various cognitive functions across the board. This is perhaps the neuroscience version of "biological freedom" or "extended lifespans".

One topic that often comes up in sci-fi depictions of AI, but that I intentionally haven't discussed here, is "mind uploading", the idea of capturing the pattern and dynamics of a human brain and instantiating them in software. This topic could be the subject of an essay all by itself, but suffice it to say that while I think uploading is almost certainly possible in principle, in practice it faces significant technological and societal challenges, even with powerful AI, that likely put it outside the 5-10 year window we are discussing.

In summary, AI-accelerated neuroscience is likely to vastly improve treatments for, or even cure, most mental illness as well as greatly expand "cognitive and mental freedom" and human cognitive and emotional abilities. It will be every bit as radical as the improvements in physical health described in the previous section. Perhaps the world will not be visibly different on the outside, but the world as experienced by humans will be a much better and more humane place, as well as a place that offers greater opportunities for self-actualization. I also suspect that improved mental health will ameliorate a lot of other societal problems, including ones that seem political or economic.

神经科学与心智发展

在上一节中，我主要讨论了身体疾病和一般生物学，而没有涉及神经科学或心理健康。但实际上，神经科学是生物学的一个重要分支，而心理健康与身体健康同等重要。事实上，从某种程度上说，心理健康对人类福祉的影响可能比身体健康更加直接。目前有数亿人因为成瘾（addiction)、抑郁症（depression)、精神分裂症（schizophrenia)、重度自闭症（low-functioning autism)、创伤后应激障碍（PTSD)、反社会人格障碍（psychopathy)（注 21）或智力障碍（intellectual disabilities）等问题而生活质量极低。还有更多数十亿人正在与各种日常心理问题作斗争，这些问题往往可以被视为上述严重临床障碍的轻微形式。与生物学领域一样，我们不仅可以解决这些问题，还可能从根本上提升人类的生活体验质量。

我之前为生物学建立的基本分析框架同样适用于神经科学。推动该领域发展的往往是为数不多的关键发现，这些发现通常与测量或精确干预的工具有关 —— 在前文提到的突破性技术中，光遗传学（optogenetics）就是一个神经科学的重要发现，最近的 CLARITY 技术和扩展显微镜技术（expansion microscopy）也是沿着相同方向的进展，此外许多通用的细胞生物学方法也可以直接应用于神经科学研究。我认为，这些技术进展的速度同样会被人工智能大大加快，因此「5-10 年内实现百年进展」的预期同样适用于神经科学领域，原因也是相似的。就像生物学一样，20 世纪神经科学取得了巨大进展 —— 比如，直到 1950 年代我们才真正理解神经元如何产生和传导电信号。因此，我们有理由期待，在人工智能的加速下，神经科学领域能在短短几年内取得突破性进展。

在这个基本框架之上，我们还需要补充一点：过去几年我们从人工智能本身的研究中获得（或正在获得）的一些见解，可能会帮助推进神经科学的发展，即使这些研究仍然完全由人类来进行。人工智能的「可解释性」（interpretability）研究就是一个很好的例子：虽然生物神经元的工作方式表面上看起来与人工神经元完全不同（生物神经元通过电位峰值和峰值频率来传递信息，这就带来了人工神经元中不存在的时间维度，而且还有许多与细胞生理学和神经递质有关的细节会显著影响它们的功能），但它们都面临着一个相同的基本问题：「如何让由简单单元组成的分布式、经过训练的网络，通过结合线性和非线性运算来完成重要的计算任务？」我强烈认为，在研究大多数有关计算和神经回路的重要问题时，单个神经元通信的具体细节可能并不那么重要（注 22）。举个例子：研究人员最近在研究人工智能系统可解释性时发现的一种计算机制，后来在小鼠大脑中也被发现了类似的机制。

与真实神经网络相比，在人工神经网络上进行实验要容易得多（研究真实神经网络常常需要通过手术来研究动物大脑），因此可解释性研究很可能成为帮助我们更好地理解神经科学的重要工具。此外，强大的人工智能系统可能比人类更擅长开发和使用这类研究工具。

除了可解释性研究之外，我们从人工智能领域学到的关于智能系统训练方法的知识，理应（虽然我不确定是否已经）在神经科学领域引发一场革命性的变革。当我还在从事神经科学研究时，很多人关注的问题在我现在看来是对学习过程的错误理解，因为那时候还没有「扩展假说」（scaling hypothesis）和「痛苦教训」（bitter lesson）这些概念。我们现在知道，一个简单的目标函数再加上大量数据就能产生令人难以置信的复杂行为，这使得理解目标函数和系统架构的固有倾向变得更加重要，而具体计算过程中的细节反而不那么关键了。虽然近年来我没有密切关注这个领域，但我感觉计算神经科学家们还没有完全领会这一点。对于扩展假说，我一直的理解是「啊哈 —— 这从宏观层面解释了智能是如何运作的，以及为什么它能在进化过程中如此容易地产生」，但我觉得大多数神经科学家并不这么看，部分原因是就连在人工智能领域内，扩展假说作为「智能的核心秘密」这一观点也尚未获得普遍认同。

我认为神经科学家们应该尝试将这个基本见解与人类大脑的特殊性质结合起来研究，这些特殊性质包括生物物理限制、进化历史、神经网络拓扑结构、以及运动和感觉系统的输入/输出细节等，从而尝试解决神经科学中的一些关键难题。虽然可能已经有一些科学家在这样做，但我觉得还不够普遍。而未来的人工智能神经科学家可能能够更有效地利用这种研究角度来加速科学进展。

我预计人工智能将从四个不同方向推动神经科学的发展，这些方向将共同促进心理疾病的治疗和大脑功能的改善：

1、传统研究方法的突破。这包括分子生物学、化学和遗传学领域的研究，基本上与第 1 节讨论的一般生物学研究类似，人工智能可能通过相同的机制来加速这些研究。目前已有许多药物可以通过调节神经递质（neurotransmitters）来改变大脑功能，影响警觉性或感知能力，调节情绪等。人工智能可以帮助我们开发出更多这样的药物，同时也可能加速我们对心理疾病遗传基础的研究。

2、精密的神经监测和干预技术。这指的是能够观察大量单个神经元或神经回路的活动，并能有针对性地改变它们行为的能力。光遗传学（optogenetics）和神经探针（neural probes）技术已经能在活体生物中实现这种监测和干预。此外，一些更先进的方法也已被提出，比如使用分子计时器（molecular ticker tapes）来记录大量单个神经元的放电模式，这些方法从理论上看是可行的。

3、先进的计算神经科学。如前所述，现代人工智能研究中的具体发现和整体理念都可能被有效地应用到系统神经科学的研究中，包括可能帮助我们揭示精神病（psychosis）或情绪障碍（mood disorders）等复杂疾病的真正成因和发展规律。

4、行为干预方法的创新。虽然之前主要关注神经科学的生物学层面，但不能忽视精神病学和心理学在 20 世纪已经发展出的大量行为干预方法。人工智能很可能能够加速这一领域的发展，既能帮助开发新的治疗方法，也能帮助患者更好地执行现有的治疗方案。从更广泛的角度来说，我们可能会看到「人工智能辅导员」的出现，这种系统可以持续帮助人们发挥最大潜能，通过分析个人的行为模式来帮助提高社交和工作效率。

我认为，这四个方向的进展会相互协同，就像在治疗身体疾病方面一样，即使没有人工智能的参与，也可能在未来 100 年内实现大多数心理疾病的治愈或预防 —— 因此在人工智能的加速下，可能在 5-10 年内就能完成。具体来说，我预测可能会出现以下突破：

1、大多数心理疾病有望得到治愈。虽然我不是精神病学专家（我在神经科学领域主要研究开发用于观察小规模神经元群的探针），但我认为像创伤后应激障碍（PTSD)、抑郁症、精神分裂症、成瘾等疾病都可能通过结合上述四个研究方向得到深入理解和有效治疗。这些疾病的根源可能是「生物化学异常」（尽管可能很复杂）和「神经网络高层功能异常」的某种组合。换句话说，这是一个系统层面的神经科学问题 —— 当然，这并不否定前面提到的行为干预方法的重要性。随着我们开发出更好的测量和干预工具，特别是那些可以用于活体人类研究的工具，我们可能会在这个领域取得快速进展。

2、某些涉及大脑结构异常的疾病可能更难治疗，但并非无解。比如，有证据表明反社会人格障碍与明显的大脑解剖结构差异有关 —— 患者的某些脑区比正常人更小或发育不足。这类患者通常从小就缺乏同理心；无论他们的大脑有什么不同，很可能是先天性的。某些智力障碍和其他类似情况可能也属于这种情况。重新构建大脑结构听起来确实很困难，但这可能是一个智力投入会带来高回报的领域。也许我们能找到某种方法，让成年大脑返回到更早期或更具可塑性的状态，从而进行重塑。虽然我对这种可能性的把握程度不高，但我的直觉是人工智能可能会在这个方向上带来创新性的解决方案。

3、从基因层面预防心理疾病似乎是可行的。大多数心理疾病都具有一定的遗传性，全基因组关联研究（genome-wide association studies，GWAS）在识别相关基因因素方面已经开始取得进展，这些因素通常涉及多个基因。就像预防身体疾病一样，我们可能可以通过胚胎筛查来预防大多数此类疾病。不过，与身体疾病相比有一个重要区别：心理疾病更可能是多基因性的（即由多个基因共同影响），这种复杂性意味着在筛查过程中可能会不小心筛除掉一些与疾病相关但实际上有积极作用的特征。不过有趣的是，近年来的全基因组关联研究似乎表明，这种相关性可能之前被高估了。无论如何，人工智能加速的神经科学研究可能会帮助我们更好地理解这些复杂关系。当然，对复杂特征进行胚胎筛查必然会引发社会争议，不过我猜测大多数人可能会支持对严重或致残性心理疾病进行筛查。

4、那些我们现在不认为是临床疾病的日常心理问题也有望得到解决。大多数人都存在一些日常心理问题，虽然这些问题还不至于被认为是临床疾病。比如有些人脾气暴躁，有些人注意力难以集中或总是感觉疲惫，有些人过分胆小或焦虑，或者不善于适应变化。现在已经有一些药物可以帮助提高警觉性或注意力，如咖啡因（caffeine)、莫达非尼（modafinil)、利他林（ritalin）等，但就像其他领域一样，未来可能会有更多突破。我们可能会发现更多类似的药物，也可能会开发出全新的干预方式，比如定向光刺激（就像前面提到的光遗传学技术）或磁场刺激。考虑到 20 世纪我们已经开发出了这么多能调节认知功能和情绪状态的药物，我对这个「时间压缩的 21 世纪」充满期待 —— 在这个时代，每个人都能让自己的大脑发挥更好的功能，享受更充实的日常生活体验。

5、人类的基本生活体验可以得到极大提升。进一步来说，很多人都经历过一些特殊时刻，比如顿悟般的启示、创造性的灵感迸发、强烈的同理心、深刻的成就感、超越性的体验、爱的感动、对美的感受，或者冥想带来的平静。这些体验的性质和出现频率因人而异，同一个人在不同时期的体验也会很不同，有时候某些药物也能诱发这些体验（但往往伴有副作用）。这些现象表明，人类可能的体验范围实际上非常广阔，而且我们可以让这些特殊的美好时刻在生活中占据更大的比重。我们可能还能全面提升各种认知能力。这可以看作是神经科学领域的「生物自主权」或「延长寿命」。

在科幻作品中描述人工智能时，经常会提到「意识上传」（mind uploading）的概念，也就是把人类大脑的模式和动态特征捕捉下来，并在计算机软件中重现。这个话题足够写一篇专门的文章，但简单来说，虽然我认为从理论上这几乎肯定是可能的，但在实践中，即使有强大的人工智能协助，它仍然面临着重大的技术和社会挑战，这些挑战可能无法在我们讨论的 5-10 年时间框架内解决。

总的来说，在人工智能的加速下，神经科学很可能能够极大地改善多数心理疾病的治疗效果，甚至实现完全治愈，同时大幅拓展人类的「认知和心理自主权」，提升人类的认知和情感能力。这种进步将会像前文描述的身体健康改善一样具有革命性的意义。虽然这些变化可能不会改变世界的外在面貌，但会让人类的主观体验变得更加美好和人性化，让每个人都有更多机会实现自我价值。我也相信，心理健康的改善将有助于缓解许多其他社会问题，包括那些表面上看起来属于政治或经济领域的问题。

### 3. Economic development and poverty

The previous two sections are about developing new technologies that cure disease and improve the quality of human life. However an obvious question, from a humanitarian perspective, is: "will everyone have access to these technologies?"

It is one thing to develop a cure for a disease, it is another thing to eradicate the disease from the world. More broadly, many existing health interventions have not yet been applied everywhere in the world, and for that matter the same is true of (non-health) technological improvements in general. Another way to say this is that living standards in many parts of the world are still desperately poor: GDP per capita is ~$2,000 in Sub-Saharan Africa as compared to ~$75,000 in the United States. If AI further increases economic growth and quality of life in the developed world, while doing little to help the developing world, we should view that as a terrible moral failure and a blemish on the genuine humanitarian victories in the previous two sections. Ideally, powerful AI should help the developing world catch up to the developed world, even as it revolutionizes the latter.

I am not as confident that AI can address inequality and economic growth as I am that it can invent fundamental technologies, because technology has such obvious high returns to intelligence (including the ability to route around complexities and lack of data) whereas the economy involves a lot of constraints from humans, as well as a large dose of intrinsic complexity. I am somewhat skeptical that an AI could solve the famous "socialist calculation problem"23 and I don't think governments will (or should) turn over their economic policy to such an entity, even if it could do so. There are also problems like how to convince people to take treatments that are effective but that they may be suspicious of.

The challenges facing the developing world are made even more complicated by pervasive corruption in both private and public sectors. Corruption creates a vicious cycle: it exacerbates poverty, and poverty in turn breeds more corruption. AI-driven plans for economic development need to reckon with corruption, weak institutions, and other very human challenges.

Nevertheless, I do see significant reasons for optimism. Diseases have been eradicated and many countries have gone from poor to rich, and it is clear that the decisions involved in these tasks exhibit high returns to intelligence (despite human constraints and complexity). Therefore, AI can likely do them better than they are currently being done. There may also be targeted interventions that get around the human constraints and that AI could focus on. More importantly though, we have to try. Both AI companies and developed world policymakers will need to do their part to ensure that the developing world is not left out; the moral imperative is too great. So in this section, I'll continue to make the optimistic case, but keep in mind everywhere that success is not guaranteed and depends on our collective efforts.

Below I make some guesses about how I think things may go in the developing world over the 5-10 years after powerful AI is developed:

Distribution of health interventions. The area where I am perhaps most optimistic is distributing health interventions throughout the world. Diseases have actually been eradicated by top-down campaigns: smallpox was fully eliminated in the 1970's, and polio and guinea worm are nearly eradicated with less than 100 cases per year. Mathematically sophisticated epidemiological modeling plays an active role in disease eradication campaigns, and it seems very likely that there is room for smarter-than-human AI systems to do a better job of it than humans are. The logistics of distribution can probably also be greatly optimized. One thing I learned as an early donor to GiveWell is that some health charities are way more effective than others; the hope is that AI-accelerated efforts would be more effective still. Additionally, some biological advances actually make the logistics of distribution much easier: for example, malaria has been difficult to eradicate because it requires treatment each time the disease is contracted; a vaccine that only needs to be administered once makes the logistics much simpler (and such vaccines for malaria are in fact currently being developed). Even simpler distribution mechanisms are possible: some diseases could in principle be eradicated by targeting their animal carriers, for example releasing mosquitoes infected with a bacterium that blocks their ability to carry a disease (who then infect all the other mosquitos) or simply using gene drives to wipe out the mosquitos. This requires one or a few centralized actions, rather than a coordinated campaign that must individually treat millions. Overall, I think 5-10 years is a reasonable timeline for a good fraction (maybe 50%) of AI-driven health benefits to propagate to even the poorest countries in the world. A good goal might be for the developing world 5-10 years after powerful AI to at least be substantially healthier than the developed world is today, even if it continues to lag behind the developed world. Accomplishing this will of course require a huge effort in global health, philanthropy, political advocacy, and many other efforts, which both AI developers and policymakers should help with.

Economic growth. Can the developing world quickly catch up to the developed world, not just in health, but across the board economically? There is some precedent for this: in the final decades of the 20th century, several East Asian economies achieved sustained ~10% annual real GDP growth rates, allowing them to catch up with the developed world. Human economic planners made the decisions that led to this success, not by directly controlling entire economies but by pulling a few key levers (such as an industrial policy of export-led growth, and resisting the temptation to rely on natural resource wealth); it's plausible that "AI finance ministers and central bankers" could replicate or exceed this 10% accomplishment. An important question is how to get developing world governments to adopt them while respecting the principle of self-determination—some may be enthusiastic about it, but others are likely to be skeptical. On the optimistic side, many of the health interventions in the previous bullet point are likely to organically increase economic growth: eradicating AIDS/malaria/parasitic worms would have a transformative effect on productivity, not to mention the economic benefits that some of the neuroscience interventions (such as improved mood and focus) would have in developed and developing world alike. Finally, non-health AI-accelerated technology (such as energy technology, transport drones, improved building materials, better logistics and distribution, and so on) may simply permeate the world naturally; for example, even cell phones quickly permeated sub-Saharan Africa via market mechanisms, without needing philanthropic efforts. On the more negative side, while AI and automation have many potential benefits, they also pose challenges for economic development, particularly for countries that haven't yet industrialized. Finding ways to ensure these countries can still develop and improve their economies in an age of increasing automation is an important challenge for economists and policymakers to address. Overall, a dream scenario—perhaps a goal to aim for—would be 20% annual GDP growth rate in the developing world, with 10% each coming from AI-enabled economic decisions and the natural spread of AI-accelerated technologies, including but not limited to health. If achieved, this would bring sub-Saharan Africa to the current per-capita GDP of China in 5-10 years, while raising much of the rest of the developing world to levels higher than the current US GDP. Again, this is a dream scenario, not what happens by default: it's something all of us must work together to make more likely.

Food security 24. Advances in crop technology like better fertilizers and pesticides, more automation, and more efficient land use drastically increased crop yields across the 20th Century, saving millions of people from hunger. Genetic engineering is currently improving many crops even further. Finding even more ways to do this—as well as to make agricultural supply chains even more efficient—could give us an AI-driven second Green Revolution, helping close the gap between the developing and developed world.

Mitigating climate change. Climate change will be felt much more strongly in the developing world, hampering its development. We can expect that AI will lead to improvements in technologies that slow or prevent climate change, from atmospheric carbon-removal and clean energy technology to lab-grown meat that reduces our reliance on carbon-intensive factory farming. Of course, as discussed above, technology isn't the only thing restricting progress on climate change—as with all of the other issues discussed in this essay, human societal factors are important. But there's good reason to think that AI-enhanced research will give us the means to make mitigating climate change far less costly and disruptive, rendering many of the objections moot and freeing up developing countries to make more economic progress.

Inequality within countries. I've mostly talked about inequality as a global phenomenon (which I do think is its most important manifestation), but of course inequality also exists within countries. With advanced health interventions and especially radical increases in lifespan or cognitive enhancement drugs, there will certainly be valid worries that these technologies are "only for the rich". I am more optimistic about within-country inequality especially in the developed world, for two reasons. First, markets function better in the developed world, and markets are typically good at bringing down the cost of high-value technologies over time25. Second, developed world political institutions are more responsive to their citizens and have greater state capacity to execute universal access programs—and I expect citizens to demand access to technologies that so radically improve quality of life. Of course it's not predetermined that such demands succeed—and here is another place where we collectively have to do all we can to ensure a fair society. There is a separate problem in inequality of wealth (as opposed to inequality of access to life-saving and life-enhancing technologies), which seems harder and which I discuss in Section 5.

The opt-out problem. One concern in both developed and developing world alike is people opting out of AI-enabled benefits (similar to the anti-vaccine movement, or Luddite movements more generally). There could end up being bad feedback cycles where, for example, the people who are least able to make good decisions opt out of the very technologies that improve their decision-making abilities, leading to an ever-increasing gap and even creating a dystopian underclass (some researchers have argued that this will undermine democracy, a topic I discuss further in the next section). This would, once again, place a moral blemish on AI's positive advances. This is a difficult problem to solve as I don't think it is ethically okay to coerce people, but we can at least try to increase people's scientific understanding—and perhaps AI itself can help us with this. One hopeful sign is that historically anti-technology movements have been more bark than bite: railing against modern technology is popular, but most people adopt it in the end, at least when it's a matter of individual choice. Individuals tend to adopt most health and consumer technologies, while technologies that are truly hampered, like nuclear power, tend to be collective political decisions.

Overall, I am optimistic about quickly bringing AI's biological advances to people in the developing world. I am hopeful, though not confident, that AI can also enable unprecedented economic growth rates and allow the developing world to at least surpass where the developed world is now. I am concerned about the "opt out" problem in both the developed and developing world, but suspect that it will peter out over time and that AI can help accelerate this process. It won't be a perfect world, and those who are behind won't fully catch up, at least not in the first few years. But with strong efforts on our part, we may be able to get things moving in the right direction—and fast. If we do, we can make at least a downpayment on the promises of dignity and equality that we owe to every human being on earth.

经济发展与贫困

前两部分讨论了如何开发新技术来治愈疾病和改善人类生活质量。然而，从人道主义的角度来看，我们需要思考一个重要问题：这些技术能让所有人受益吗？

研发出治疗疾病的方法只是第一步，要从世界上彻底消除疾病则是另一个更大的挑战。放眼更广阔的视角，许多现有的健康干预措施都还没有在全球范围内推广应用，同样的情况也适用于其他（非医疗领域的）技术进步。这反映出一个现实：世界上很多地区的生活水平仍然十分低下 —— 撒哈拉以南非洲的人均 GDP 仅约 2,000 美元，而美国则高达约 75,000 美元。如果人工智能 (AI) 只是进一步提升发达国家的经济增长和生活质量，却对发展中国家毫无帮助，那么这将是一个严重的道德缺失，也会让前两节中描述的人道主义成就大打折扣。理想的情况是，强大的 AI 应该在推动发达国家进步的同时，也帮助发展中国家缩小与发达国家的差距。

我对 AI 在解决不平等和促进经济增长方面的信心，不如它在开发基础技术方面的信心那么强。这是因为技术创新对智能投入能产生明显的高效益（包括克服复杂问题和数据匮乏的能力），而经济系统则涉及许多人为限制和内在的复杂性。我对 AI 能否解决著名的「社会主义计算问题」（即如何在没有市场机制的情况下进行经济计算）持谨慎态度，而且我认为即使 AI 有这种能力，政府也不会（也不应该）把经济政策的制定完全交给它。此外还存在其他挑战，比如如何说服人们接受那些有效但可能引起他们怀疑的治疗方法。

发展中国家面临的挑战因私营和公共部门普遍存在的腐败问题而变得更加复杂。腐败会造成恶性循环：它加剧了贫困，而贫困又会滋生更多腐败。由 AI 驱动的经济发展规划必须应对腐败、制度不健全以及其他诸多人为因素带来的挑战。

不过，我仍然看到了许多值得乐观的理由。人类已经成功消除了一些疾病，很多国家也实现了从贫穷到富裕的转变。显然，这些成就背后的决策都体现出对智能水平的高度依赖（尽管存在人为约束和复杂性）。因此，AI 很可能能够比现有方法做得更好。此外，可能还存在一些能够避开人为约束的针对性措施，这正是 AI 可以重点关注的方向。更重要的是，我们必须努力尝试。AI 企业和发达国家的政策制定者都需要尽其所能确保发展中国家不会被落下；这是一项重大的道德使命。因此在本节中，我会继续保持乐观的论述，但请始终牢记：成功并非必然，而是取决于我们所有人的共同努力。

以下是我对在强大 AI 技术出现后的5-10年内，发展中国家可能出现的变化进行的一些预测：

医疗卫生干预措施的推广。这可能是我最为乐观的领域。通过系统性的全球行动，人类已经成功消除了一些疾病：天花在20世纪70年代被完全根除，脊髓灰质炎和麦地那龙线虫病的年度病例已降至不到100例，几乎已经被消除。复杂的流行病学模型 (epidemiological modeling) 在疾病根除行动中发挥着重要作用，而智能水平超过人类的 AI 系统很可能能在这方面做得更好。医疗资源的配送和分配效率也可能得到极大提升。作为 GiveWell 的早期捐助者，我深知不同的医疗慈善机构之间存在很大的效率差异；我们希望借助 AI 加速后的行动能够达到更高的效率。此外，一些生物学领域的进展实际上简化了医疗资源的分配难度：例如，疟疾难以根除的原因之一是每次发病都需要进行治疗；如果能开发出只需接种一次的疫苗，整个防治工作就会简单得多（这样的疟疾疫苗目前正在研发中）。

还有一些更简单的疾病防控方法：某些疾病原则上可以通过控制传播媒介动物来根除。例如，我们可以释放携带特殊细菌的蚊子（这种细菌能阻止蚊子传播疾病，并能感染其他蚊子），或直接使用基因驱动技术 (gene drive) 来消除蚊子。这些方法只需要一到几次集中行动，而不是需要组织大规模的人群治疗活动。总的来说，我认为在 5-10 年内，即使是世界上最贫困的国家，也能实现相当比例（可能 50%）的 AI 驱动的健康改善。我们可以设定这样一个目标：在强大 AI 出现后的 5-10 年内，发展中国家的健康水平至少要实质性地超过当今发达国家的水平，即使它们在整体发展上仍然落后于发达国家。当然，实现这一目标需要在全球健康、慈善事业、政治倡导等诸多方面付出巨大努力，AI 开发者和政策制定者都应该为此提供支持。

经济增长方面，发展中国家能否在健康之外的整体经济层面也快速赶上发达国家？历史上是有这样的先例的：在 20 世纪最后几十年，一些东亚经济体维持了年均约 10% 的实际 GDP 增长率，最终成功赶上了发达国家。人类的经济规划者实现这一成功并非通过直接控制整个经济，而是通过几个关键政策工具（如推行出口导向型增长的产业政策，同时避免过度依赖自然资源带来的短期收益）。因此，由 AI 辅助决策的财政部和央行可能有望复制或超越这个 10% 的增长成就。一个重要的问题是，如何在尊重各国自主权的前提下，说服发展中国家政府采用这些 AI 系统——有些国家可能会热情欢迎，但其他国家可能会持怀疑态度。

从积极的角度来看，前面提到的许多医疗卫生干预措施很可能会自然促进经济增长：消除艾滋病、疟疾和寄生虫病将极大提升劳动生产力，此外还有神经科学领域的进步（比如改善情绪和提高注意力集中度）将在发达国家和发展中国家都带来显著的经济效益。同时，非医疗领域的 AI 加速技术（如能源技术、运输无人机、改良建筑材料、更高效的物流配送系统等）可能会自然地在全球推广开来；就像手机技术一样，仅通过市场机制就迅速普及到了撒哈拉以南非洲，而不需要依靠慈善援助。

然而从挑战的角度来看，尽管 AI 和自动化技术带来了诸多潜在优势，但它们也给经济发展带来了新的问题，特别是对那些尚未完成工业化的国家而言。如何确保这些国家在自动化程度不断提高的时代仍能持续发展和改善经济，这是经济学家和政策制定者面临的一个重要课题。

总的来说，我们可以设想一个理想目标：发展中国家实现 20% 的年度 GDP 增长率，其中 10% 来自 AI 辅助的经济决策，另外 10% 来自包括医疗在内的各类 AI 加速技术的自然传播。如果能实现这个目标，撒哈拉以南非洲地区将在 5-10 年内达到中国目前的人均 GDP 水平，同时大部分发展中国家地区的经济水平将超过当今美国的水平。但要特别强调的是，这只是一个理想场景，而不是必然会发生的结果：要让这种可能性更大，需要我们所有人共同努力。

食品安全[24]。在 20 世纪，农作物技术取得了重大进步，包括更高效的肥料和农药、更广泛的自动化应用和更有效的土地利用，这些都大幅提高了农作物产量，使数百万人远离了饥饿的威胁。目前，基因工程技术正在进一步改良多种农作物。如果我们能找到更多类似的技术突破，同时提高农业供应链的效率，就可能借助 AI 掀起第二次绿色革命，帮助缩小发展中国家与发达国家之间的差距。

应对气候变化。发展中国家将承受气候变化带来的更严重影响，这会阻碍它们的发展进程。我们期望 AI 能在多个领域推动技术进步，包括大气碳捕获技术 (atmospheric carbon-removal)、清洁能源技术，以及实验室培育肉类（能减少我们对碳排放密集型工厂化养殖的依赖）等，这些都有助于减缓或防止气候变化。当然，如前所述，技术并非制约气候变化治理的唯一因素——与本文讨论的所有其他问题一样，人类社会因素同样重要。但有充分理由相信，AI 增强的研究将为我们提供更经济、更高效的气候变化应对方案，这将大大降低采取行动的阻力，使发展中国家能够更专注于经济发展。

国家内部的不平等。我之前主要讨论了不平等作为一个全球性现象（这确实是其最重要的表现形式），但不平等现象在各个国家内部也同样存在。随着先进医疗干预手段的出现，特别是能显著延长寿命的技术或认知增强药物的发展，人们自然会担心这些技术会成为富人的专属。不过，我对发达国家的国内不平等问题持相对乐观的态度，主要有两个原因。首先，发达国家的市场机制运作更为完善，而市场通常能随着时间推移逐步降低高价值技术的成本。其次，发达国家的政治机构对公民诉求更加敏感，而且具有更强的执行力来推广全民普惠项目——我预计公民们会强烈要求获得这些能显著改善生活质量的技术。当然，这种诉求能否成功并非必然——这也是我们必须共同努力以确保社会公平的领域之一。此外还有一个更棘手的问题是财富不平等（这与获取救命和改善生活技术的机会不平等是不同的），我将在第5节中详细讨论这个问题。

技术抵制问题。在发达国家和发展中国家都存在一个共同的挑战：部分人群可能会拒绝接受 AI 带来的福利（这类似于反疫苗运动，或更广泛的反技术运动）。这可能会导致恶性循环，比如，那些最需要决策能力提升的人群反而选择拒绝使用能够帮助改善其判断力的技术，这会导致社会差距不断扩大，甚至可能形成一个长期处于劣势的社会群体（一些研究者认为这将威胁民主制度，我将在下一节详细讨论这个问题）。这种情况会削弱 AI 在其他方面取得的积极进展。这个问题很难解决，因为强制人们接受技术在道德上是不可接受的，但我们至少可以努力提高公众的科学素养——也许 AI 本身就能在这方面提供帮助。值得欣慰的是，历史经验表明，反技术运动的实际影响往往小于其声势：尽管批评现代技术的声音很普遍，但最终大多数人还是会接受这些技术，特别是在涉及个人选择时。个人通常会采用对自己有益的健康和消费类技术，而那些真正受到阻碍的技术，比如核能，往往是因为集体性的政治决策。

总的来说，我对于快速将 AI 在生物学领域的进展推广到发展中国家持乐观态度。我也希望 AI 能够帮助实现空前的经济增长率，使发展中国家至少达到当今发达国家的水平，尽管这个目标的实现还存在不确定性。关于技术抵制问题，虽然这在发达国家和发展中国家都让人担忧，但我认为这种抵制会随时间推移而减弱，而且 AI 可能会加速这个过程。当然，这个世界不会立即变得完美，发展落后的地区也不可能在最初几年就完全赶上来。但是通过我们的共同努力，我们有可能推动事态朝着正确的方向快速发展。如果我们能做到这一点，就能开始兑现我们对地球上每一个人的承诺——让所有人都能享有尊严和平等的生活。

### 4. Peace and governance

Suppose that everything in the first three sections goes well: disease, poverty, and inequality are significantly reduced and the baseline of human experience is raised substantially. It does not follow that all major causes of human suffering are solved. Humans are still a threat to each other. Although there is a trend of technological improvement and economic development leading to democracy and peace, it is a very loose trend, with frequent (and recent) backsliding. At the dawn of the 20th Century, people thought they had put war behind them; then came the two world wars. Thirty years ago Francis Fukuyama wrote about "the End of History" and a final triumph of liberal democracy; that hasn't happened yet. Twenty years ago US policymakers believed that free trade with China would cause it to liberalize as it became richer; that very much didn't happen, and we now seem headed for a second cold war with a resurgent authoritarian bloc. And plausible theories suggest that internet technology may actually advantage authoritarianism, not democracy as initially believed (e.g. in the "Arab Spring" period). It seems important to try to understand how powerful AI will intersect with these issues of peace, democracy, and freedom.

Unfortunately, I see no strong reason to believe AI will preferentially or structurally advance democracy and peace, in the same way that I think it will structurally advance human health and alleviate poverty. Human conflict is adversarial and AI can in principle help both the "good guys" and the "bad guys". If anything, some structural factors seem worrying: AI seems likely to enable much better propaganda and surveillance, both major tools in the autocrat's toolkit. It's therefore up to us as individual actors to tilt things in the right direction: if we want AI to favor democracy and individual rights, we are going to have to fight for that outcome. I feel even more strongly about this than I do about international inequality: the triumph of liberal democracy and political stability is not guaranteed, perhaps not even likely, and will require great sacrifice and commitment on all of our parts, as it often has in the past.

I think of the issue as having two parts: international conflict, and the internal structure of nations. On the international side, it seems very important that democracies have the upper hand on the world stage when powerful AI is created. AI-powered authoritarianism seems too terrible to contemplate, so democracies need to be able to set the terms by which powerful AI is brought into the world, both to avoid being overpowered by authoritarians and to prevent human rights abuses within authoritarian countries.

My current guess at the best way to do this is via an "entente strategy"26, in which a coalition of democracies seeks to gain a clear advantage (even just a temporary one) on powerful AI by securing its supply chain, scaling quickly, and blocking or delaying adversaries' access to key resources like chips and semiconductor equipment. This coalition would on one hand use AI to achieve robust military superiority (the stick) while at the same time offering to distribute the benefits of powerful AI (the carrot) to a wider and wider group of countries in exchange for supporting the coalition's strategy to promote democracy (this would be a bit analogous to "Atoms for Peace"). The coalition would aim to gain the support of more and more of the world, isolating our worst adversaries and eventually putting them in a position where they are better off taking the same bargain as the rest of the world: give up competing with democracies in order to receive all the benefits and not fight a superior foe.

If we can do all this, we will have a world in which democracies lead on the world stage and have the economic and military strength to avoid being undermined, conquered, or sabotaged by autocracies, and may be able to parlay their AI superiority into a durable advantage. This could optimistically lead to an "eternal 1991"—a world where democracies have the upper hand and Fukuyama's dreams are realized. Again, this will be very difficult to achieve, and will in particular require close cooperation between private AI companies and democratic governments, as well as extraordinarily wise decisions about the balance between carrot and stick.

Even if all that goes well, it leaves the question of the fight between democracy and autocracy within each country. It is obviously hard to predict what will happen here, but I do have some optimism that given a global environment in which democracies control the most powerful AI, then AI may actually structurally favor democracy everywhere. In particular, in this environment democratic governments can use their superior AI to win the information war: they can counter influence and propaganda operations by autocracies and may even be able to create a globally free information environment by providing channels of information and AI services in a way that autocracies lack the technical ability to block or monitor. It probably isn't necessary to deliver propaganda, only to counter malicious attacks and unblock the free flow of information. Although not immediate, a level playing field like this stands a good chance of gradually tilting global governance towards democracy, for several reasons.

First, the increases in quality of life in Sections 1-3 should, all things equal, promote democracy: historically they have, to at least some extent. In particular I expect improvements in mental health, well-being, and education to increase democracy, as all three are negatively correlated with support for authoritarian leaders. In general people want more self-expression when their other needs are met, and democracy is among other things a form of self-expression. Conversely, authoritarianism thrives on fear and resentment.

Second, there is a good chance free information really does undermine authoritarianism, as long as the authoritarians can't censor it. And uncensored AI can also bring individuals powerful tools for undermining repressive governments. Repressive governments survive by denying people a certain kind of common knowledge, keeping them from realizing that "the emperor has no clothes". For example Srđa Popović, who helped to topple the Milošević government in Serbia, has written extensively about techniques for psychologically robbing authoritarians of their power, for breaking the spell and rallying support against a dictator. A superhumanly effective AI version of Popović (whose skills seem like they have high returns to intelligence) in everyone's pocket, one that dictators are powerless to block or censor, could create a wind at the backs of dissidents and reformers across the world. To say it again, this will be a long and protracted fight, one where victory is not assured, but if we design and build AI in the right way, it may at least be a fight where the advocates of freedom everywhere have an advantage.

As with neuroscience and biology, we can also ask how things could be "better than normal"—not just how to avoid autocracy, but how to make democracies better than they are today. Even within democracies, injustices happen all the time. Rule-of-law societies make a promise to their citizens that everyone will be equal under the law and everyone is entitled to basic human rights, but obviously people do not always receive those rights in practice. That this promise is even partially fulfilled makes it something to be proud of, but can AI help us do better?

For example, could AI improve our legal and judicial system by making decisions and processes more impartial? Today people mostly worry in legal or judicial contexts that AI systems will be a cause of discrimination, and these worries are important and need to be defended against. At the same time, the vitality of democracy depends on harnessing new technologies to improve democratic institutions, not just responding to risks. A truly mature and successful implementation of AI has the potential to reduce bias and be fairer for everyone.

For centuries, legal systems have faced the dilemma that the law aims to be impartial, but is inherently subjective and thus must be interpreted by biased humans. Trying to make the law fully mechanical hasn't worked because the real world is messy and can't always be captured in mathematical formulas. Instead legal systems rely on notoriously imprecise criteria like "cruel and unusual punishment" or "utterly without redeeming social importance", which humans then interpret—and often do so in a manner that displays bias, favoritism, or arbitrariness. "Smart contracts" in cryptocurrencies haven't revolutionized law because ordinary code isn't smart enough to adjudicate all that much of interest. But AI might be smart enough for this: it is the first technology capable of making broad, fuzzy judgements in a repeatable and mechanical way.

I am not suggesting that we literally replace judges with AI systems, but the combination of impartiality with the ability to understand and process messy, real world situations feels like it should have some serious positive applications to law and justice. At the very least, such systems could work alongside humans as an aid to decision-making. Transparency would be important in any such system, and a mature science of AI could conceivably provide it: the training process for such systems could be extensively studied, and advanced interpretability techniques could be used to see inside the final model and assess it for hidden biases, in a way that is simply not possible with humans. Such AI tools could also be used to monitor for violations of fundamental rights in a judicial or police context, making constitutions more self-enforcing.

In a similar vein, AI could be used to both aggregate opinions and drive consensus among citizens, resolving conflict, finding common ground, and seeking compromise. Some early ideas in this direction have been undertaken by the computational democracy project, including collaborations with Anthropic. A more informed and thoughtful citizenry would obviously strengthen democratic institutions.

There is also a clear opportunity for AI to be used to help provision government services—such as health benefits or social services—that are in principle available to everyone but in practice often severely lacking, and worse in some places than others. This includes health services, the DMV, taxes, social security, building code enforcement, and so on. Having a very thoughtful and informed AI whose job is to give you everything you're legally entitled to by the government in a way you can understand—and who also helps you comply with often confusing government rules—would be a big deal. Increasing state capacity both helps to deliver on the promise of equality under the law, and strengthens respect for democratic governance. Poorly implemented services are currently a major driver of cynicism about government27.

All of these are somewhat vague ideas, and as I said at the beginning of this section, I am not nearly as confident in their feasibility as I am in the advances in biology, neuroscience, and poverty alleviation. They may be unrealistically utopian. But the important thing is to have an ambitious vision, to be willing to dream big and try things out. The vision of AI as a guarantor of liberty, individual rights, and equality under the law is too powerful a vision not to fight for. A 21st century, AI-enabled polity could be both a stronger protector of individual freedom, and a beacon of hope that helps make liberal democracy the form of government that the whole world wants to adopt.

和平与治理

假设前三节讨论的所有愿景都实现了：疾病、贫困和不平等现象得到显著改善，人类的基本生活水平也得到大幅提升。但这并不意味着导致人类苦难的所有主要原因都得到了解决。人类之间的互相威胁仍然存在。虽然技术进步和经济发展确实在推动着民主和和平的发展，但这种趋势并不稳定，经常会出现倒退，最近就有这样的情况。20 世纪初，人们曾天真地以为战争将成为历史；紧接着就爆发了两次世界大战。三十年前，Francis Fukuyama 提出了「历史的终结」和自由民主的最终胜利；但这个预言至今仍未实现。二十年前，美国的政策制定者认为与中国的自由贸易会随着中国的富裕而促进其民主化；但事实证明这完全没有发生，相反，我们现在似乎正在走向与一个日益强大的专制阵营的新冷战。而且有观点认为，互联网技术实际上可能更有利于专制统治，而不是像人们最初在「阿拉伯之春」时期所认为的那样有利于民主。因此，我们很有必要去理解强大的人工智能将如何影响这些关乎和平、民主和自由的议题。

遗憾的是，我并不认为人工智能会像推动人类健康发展和减少贫困那样，自然而然地促进民主和和平的发展。人类的冲突具有对抗性，从理论上说，人工智能既可以帮助「正义之士」，也可以被「作恶之人」利用。实际上，一些结构性因素令人格外担忧：人工智能很可能会带来更强大的宣传和监控技术，而这恰恰是独裁者最常用的统治手段。因此，要让事态朝着正确的方向发展，关键在于我们每个人的努力：如果我们希望人工智能能够促进民主和保护个人权利，就必须为之付出努力和争取。对于这一点，我的忧虑甚至超过了对国际不平等的担忧：自由民主的胜利和政治稳定性并非必然，甚至可能难以实现。这需要我们所有人像过去那样，做出巨大的牺牲和承诺。

就这个问题而言，我认为需要从两个方面来考虑：国际冲突和各国的内部治理结构。从国际层面来看，当强大的人工智能技术出现时，确保民主国家在世界舞台上占据主导地位至关重要。由人工智能支撑的威权统治带来的后果令人不寒而栗，因此民主国家必须有能力主导强大人工智能进入世界的方式，既要防止被威权主义国家压制，也要避免这些国家内部出现人权侵犯。

我认为目前最佳的解决方案是采取一种「协和战略」[26]，即由民主国家组成联盟，通过掌控供应链、快速发展以及限制或延缓对手获取芯片和半导体设备等关键资源，来获得明显的优势（即使这种优势是暂时的）。这个联盟可以采取双管齐下的方式：一方面利用人工智能建立强大的军事优势（强制手段），另一方面向更多国家提供共享先进人工智能技术的机会（激励措施），以换取他们对推进民主战略的支持（这种方式有点类似于历史上的「和平利用原子能计划」）。该联盟的目标是争取获得越来越多国家的支持，从而孤立那些最具对抗性的国家，最终使这些国家不得不接受与世界其他国家相同的条件：放弃与民主国家的竞争，以获得各种利益，避免与更强大的对手发生冲突。

如果我们能够实现这些目标，我们将创造一个由民主国家主导的世界。在这个世界中，民主国家将拥有足够的经济和军事实力，使其不会被专制政权破坏、征服或颠覆，并可能将他们在人工智能领域的优势转化为长期的领先地位。这种理想状态可能会带来一个「永恒的 1991 年」—— 也就是民主国家始终保持优势，Fukuyama 所设想的「历史终结」愿景得以实现的世界。但我必须再次强调，实现这一目标将面临巨大挑战，尤其需要私营人工智能公司与民主国家政府之间的紧密合作，同时在采取强制措施和提供激励措施之间作出极其审慎的权衡。

即便上述所有目标都实现了，我们仍然需要面对每个国家内部民主与专制势力之间的较量这个问题。虽然这个问题的发展难以预测，但在民主国家掌控最先进人工智能的全球环境下，我对人工智能可能会在世界各地自然而然地推动民主发展持谨慎乐观态度。特别是在这种情况下，民主国家政府可以利用他们在人工智能领域的优势来赢得信息领域的竞争：他们能够抵制专制政权的渗透和宣传活动，甚至可能通过提供专制政权无法在技术上封锁或监控的信息渠道和人工智能服务，来创建一个全球信息自由流动的环境。这种做法并不需要进行刻意的政治宣传，只需要防范恶意攻击，确保信息能够自由流通。虽然这种变化不会立竿见影，但这种公平的竞争环境很可能会逐步推动全球治理向民主方向发展，这主要基于以下几个原因。

首先，在其他条件不变的情况下，前文第 1-3 节提到的生活质量提升应该会促进民主的发展：历史经验至少在一定程度上证明了这一点。特别是我预计，随着心理健康、民众福祉和教育水平的改善，民主程度会随之提高，因为这三个因素都与人们对专制统治者的支持度呈负相关。总的来说，当人们的基本需求得到满足后，他们会追求更多的自我表达，而民主恰恰是自我表达的一种重要形式。与之相反，专制统治则是靠煽动恐惧和怨恨来维持其统治。

第二，在专制政权无法实施审查的情况下，信息的自由流动确实很可能会动摇专制统治的根基。未经审查的人工智能还能为个人提供强有力的工具来对抗压迫性政府。压迫性政府之所以能够维持统治，是通过阻止人们获得某种共识，防止人们认识到「皇帝的新装」的真相。例如，Srđa Popović 曾协助推翻了塞尔维亚的 Milošević 政府，他详细描述了如何从心理层面瓦解威权统治者的权力，如何打破人们对独裁者的盲从，以及如何凝聚反对独裁者的力量。如果每个人都能随身携带一个超越人类能力的 AI 版本的 Popović（他的这些技能似乎会随着智能的提升而变得更加有效），而且独裁者无法阻止或审查这样的 AI，那么这可能会给全世界的异见人士和改革者带来新的希望。我要再次强调，这将是一场漫长而艰巨的斗争，胜利并非必然，但如果我们能够正确地设计和开发人工智能，至少可以让追求自由的人们在这场斗争中占据优势。

就像我们在神经科学和生物学领域所做的那样，我们也可以探讨如何实现「超越常态」的进步 —— 不仅要思考如何避免独裁，还要考虑如何使民主制度比现在更加完善。即使在民主国家，不公正的现象仍然时有发生。法治社会向其公民承诺人人法律面前平等，人人享有基本人权，但显然在现实中并非所有人都能真正享有这些权利。即便是这种承诺的部分实现也值得我们感到自豪，但我们不禁要问：人工智能能否帮助我们做得更好？

举例来说，人工智能是否能够通过提高决策和程序的公正性来改进我们的法律和司法体系？目前，人们在法律和司法领域主要担心人工智能系统可能会产生歧视，这些担忧确实很重要，我们必须采取预防措施。但同时，民主制度的生命力在于能够利用新技术来改善民主机制本身，而不是仅仅应对可能的风险。如果能够真正成熟和成功地应用人工智能，就有可能减少偏见，为所有人提供更加公平的对待。

几个世纪以来，法律系统一直面临着这样一个困境：法律本应保持客观公正，但在本质上却带有主观性，必须依靠可能存在偏见的人来解释。试图将法律完全程序化的尝试并不成功，因为现实世界太过复杂，无法完全用数学公式来描述。因此，法律系统不得不依赖一些众所周知的模糊标准，比如「残酷和反常的惩罚」或「完全没有积极社会意义」这样的概念，然后由人来解释 —— 而这种解释往往会受到个人偏见、偏袒或随意性的影响。虽然加密货币中的「智能合约」（一种自动执行的数字协议）并未从根本上改变法律体系，因为普通的程序代码还不够智能，无法处理太多复杂的法律判断。但人工智能可能具备这样的能力：它是第一项能够以可重复和系统化的方式对复杂、模糊情况做出判断的技术。

我并不是建议用人工智能系统完全替代法官，但当公正性与理解和处理复杂现实情况的能力相结合时，这种技术应该能在法律和司法领域发挥重要的积极作用。至少，这些系统可以作为决策辅助工具，协助人类法官工作。在建立这样的系统时，透明度至关重要，而成熟的人工智能科技很可能能够提供这种透明度：我们可以对这类系统的训练过程进行广泛研究，还可以运用先进的可解释性技术来检视最终模型的内部运作机制，评估是否存在隐藏的偏见 —— 这是在人类身上完全做不到的。这样的人工智能工具还可以用来监督司法系统和执法部门是否侵犯公民基本权利，从而使宪法的各项规定能够得到更好的落实。

同样地，人工智能也可以用来整合民意，推动公民之间达成共识，化解冲突，找到共同立场，促进各方妥协。一些早期的尝试已经在计算民主项目（一个致力于将计算技术应用于民主实践的研究项目）中展开，包括与 Anthropic 公司的合作。显然，一个更加知情和理性的公民群体将会大大增强民主制度的力量。

另外，人工智能还有很大潜力来改善政府服务的提供方式 —— 比如医疗保障或社会服务等。这些服务理论上应该面向所有人开放，但实际上往往供给不足，且地区差异明显。这些服务包括医疗服务、机动车管理、税收、社会保障、建筑规范执行等多个领域。如果能有一个极其智能和全面的人工智能系统，既能用易于理解的方式帮助民众获取政府法定应当提供的各种服务，又能帮助他们更好地遵守那些往往令人困惑的政府规定，这将是一个重大突破。提升国家治理能力不仅有助于实现法律面前人人平等的承诺，还能增强民众对民主治理的信心。目前，政府服务质量低下是导致民众对政府普遍持怀疑态度的主要原因 [27]。

以上这些设想都还比较模糊，正如我在本节开始时所说的，我对这些设想的可行性远没有对生物学、神经科学和减少贫困等领域进展的信心那么大。这些想法可能显得过于理想化。但重要的是我们要有远大的愿景，要敢于构想宏伟蓝图并付诸实践。将人工智能视为自由、个人权利和法律面前人人平等的守护者，这样的愿景太过重要，值得我们为之奋斗。在 21 世纪，借助人工智能技术的政治制度可能会成为个人自由更有力的保护者，同时也会成为一个激励世界的典范，推动自由民主成为全世界都渴望采用的政府形式。

### 5. Work and meaning

Even if everything in the preceding four sections goes well—not only do we alleviate disease, poverty, and inequality, but liberal democracy becomes the dominant form of government, and existing liberal democracies become better versions of themselves—at least one important question still remains. "It's great we live in such a technologically advanced world as well as a fair and decent one", someone might object, "but with AI's doing everything, how will humans have meaning? For that matter, how will they survive economically?".

I think this question is more difficult than the others. I don't mean that I am necessarily more pessimistic about it than I am about the other questions (although I do see challenges). I mean that it is fuzzier and harder to predict in advance, because it relates to macroscopic questions about how society is organized that tend to resolve themselves only over time and in a decentralized manner. For example, historical hunter-gatherer societies might have imagined that life is meaningless without hunting and various kinds of hunting-related religious rituals, and would have imagined that our well-fed technological society is devoid of purpose. They might also have not understood how our economy can provide for everyone, or what function people can usefully service in a mechanized society.

Nevertheless, it's worth saying at least a few words, while keeping in mind that the brevity of this section is not at all to be taken as a sign that I don't take these issues seriously—on the contrary, it is a sign of a lack of clear answers.

On the question of meaning, I think it is very likely a mistake to believe that tasks you undertake are meaningless simply because an AI could do them better. Most people are not the best in the world at anything, and it doesn't seem to bother them particularly much. Of course today they can still contribute through comparative advantage, and may derive meaning from the economic value they produce, but people also greatly enjoy activities that produce no economic value. I spend plenty of time playing video games, swimming, walking around outside, and talking to friends, all of which generates zero economic value. I might spend a day trying to get better at a video game, or faster at biking up a mountain, and it doesn't really matter to me that someone somewhere is much better at those things. In any case I think meaning comes mostly from human relationships and connection, not from economic labor. People do want a sense of accomplishment, even a sense of competition, and in a post-AI world it will be perfectly possible to spend years attempting some very difficult task with a complex strategy, similar to what people do today when they embark on research projects, try to become Hollywood actors, or found companies28. The facts that (a) an AI somewhere could in principle do this task better, and (b) this task is no longer an economically rewarded element of a global economy, don't seem to me to matter very much.

The economic piece actually seems more difficult to me than the meaning piece. By "economic" in this section I mean the possible problem that most or all humans may not be able to contribute meaningfully to a sufficiently advanced AI-driven economy. This is a more macro problem than the separate problem of inequality, especially inequality in access to the new technologies, which I discussed in Section 3.

First of all, in the short term I agree with arguments that comparative advantage will continue to keep humans relevant and in fact increase their productivity, and may even in some ways level the playing field between humans. As long as AI is only better at 90% of a given job, the other 10% will cause humans to become highly leveraged, increasing compensation and in fact creating a bunch of new human jobs complementing and amplifying what AI is good at, such that the "10%" expands to continue to employ almost everyone. In fact, even if AI can do 100% of things better than humans, but it remains inefficient or expensive at some tasks, or if the resource inputs to humans and AI's are meaningfully different, then the logic of comparative advantage continues to apply. One area humans are likely to maintain a relative (or even absolute) advantage for a significant time is the physical world. Thus, I think that the human economy may continue to make sense even a little past the point where we reach "a country of geniuses in a datacenter".

However, I do think in the long run AI will become so broadly effective and so cheap that this will no longer apply. At that point our current economic setup will no longer make sense, and there will be a need for a broader societal conversation about how the economy should be organized.

While that might sound crazy, the fact is that civilization has successfully navigated major economic shifts in the past: from hunter-gathering to farming, farming to feudalism, and feudalism to industrialism. I suspect that some new and stranger thing will be needed, and that it's something no one today has done a good job of envisioning. It could be as simple as a large universal basic income for everyone, although I suspect that will only be a small part of a solution. It could be a capitalist economy of AI systems, which then give out resources (huge amounts of them, since the overall economic pie will be gigantic) to humans based on some secondary economy of what the AI systems think makes sense to reward in humans (based on some judgment ultimately derived from human values). Perhaps the economy runs on Whuffie points. Or perhaps humans will continue to be economically valuable after all, in some way not anticipated by the usual economic models. All of these solutions have tons of possible problems, and it's not possible to know whether they will make sense without lots of iteration and experimentation. And as with some of the other challenges, we will likely have to fight to get a good outcome here: exploitative or dystopian directions are clearly also possible and have to be prevented. Much more could be written about these questions and I hope to do so at some later time.

工作与意义

就算前文讨论的四个方面都取得了理想的成果 —— 我们不仅成功应对了疾病、贫困和不平等问题，而且自由民主制度在全球范围内占据主导地位，现有的民主国家也变得更加完善 —— 我们仍然面临着至少一个重要问题。有人可能会提出质疑：「没错，我们确实生活在一个科技发达、公平正义的世界里，这很好。但是，当 AI 承担了所有工作后，人类将如何找到人生的意义？更现实的问题是，人类又该如何维持基本的经济生存？」

在我看来，这个问题的复杂程度远超其他。这并不是说我对这个问题特别悲观（虽然确实存在一些挑战）。而是因为这个问题更加模糊，更难进行预测，它涉及到社会组织架构的宏观问题，这类问题通常需要经过漫长的时间，通过分散的方式才能逐步得到解决。举个例子，远古的采集狩猎部落可能认为，如果没有狩猎活动和与之相关的各种宗教仪式，生活就失去了意义。在他们眼中，我们这个衣食无忧的现代科技社会或许就是一个毫无生命意义的世界。他们可能也无法理解现代经济体系是如何满足所有人需求的，也不明白在这样一个高度自动化的社会中，人类究竟能发挥什么作用。

尽管如此，我们仍然有必要对这个问题做一些探讨。需要说明的是，这一部分内容虽然简短，但并不意味着我对这些问题不够重视。恰恰相反，正是因为这些问题还没有明确的答案，才显得如此简短。

让我们来谈谈「意义」这个话题。如果仅仅因为 AI 能比人做得更好，就认为自己所做的事情毫无意义，这种想法很可能是错误的。想想看，世界上大多数人在任何领域都不是最顶尖的，但这并没有影响他们享受生活。诚然，在当今社会，人们可以通过发挥各自的优势来做出贡献，并从创造的经济价值中获得成就感。但更重要的是，人们也会从那些完全不创造经济价值的活动中获得快乐。

比如说，我经常花时间玩电子游戏、游泳、户外散步或者和朋友聊天，这些活动都不会产生任何经济价值。我可能会花一整天时间来提高游戏水平，或者努力提升骑山地车的速度，尽管我很清楚世界上有人在这些方面比我强得多，但这丝毫不影响我的兴趣和热情。

我认为，人生的意义主要来自于与他人建立真诚的情感联系，而不是单纯的经济劳动。人们确实需要成就感，也渴望一定程度的竞争，这一点在 AI 主导的未来依然不会改变。届时，人们仍然可以像现在一样，投入数年时间去挑战某个困难的目标，制定复杂的策略，就像现在的科研工作者、追梦好莱坞的演员或创业者所做的那样 [28]。在我看来，就算某个地方的 AI 可能做得更好，就算这些努力不再能带来经济回报，这些都不会影响人们追求目标时的热情和意义感。

经济问题实际上比意义问题更为棘手。这里所提到的「经济」问题，是指在高度发达的 AI 驱动经济体系中，人类可能普遍难以发挥实质性作用的困境。这一问题比起第 3 节所讨论的不平等现象（尤其是新技术使用机会的差异）更具宏观性。

首先，从短期来看，我认同这样的观点：比较优势理论将继续确保人类在未来仍然发挥重要作用，并且实际上会提高人类的生产力，甚至可能在某种程度上帮助平衡人与人之间的机会差距。即使 AI 在某项工作中的 90% 任务上都表现更优秀，剩下的 10% 仍将让人类获得更大的价值提升空间，不仅带来更高的薪资待遇，还会创造出许多新的工作岗位来配合和扩展 AI 的能力，从而让这「10%」的工作量能继续为绝大多数人提供就业机会。事实上，即便 AI 在各个方面都能胜过人类，只要它在某些任务上仍然存在效率低下或成本过高的问题，或者人类和 AI 在资源使用方面存在本质差异，比较优势理论就仍然适用。在物理世界中，人类很可能在相当长一段时间内都将保持相对（甚至绝对）优势。因此，我认为即使在未来科技发展到能在数据中心里创造出「超级智能国度」的阶段后，人类经济模式依然可能在一段时期内继续发挥作用。

然而，从长远来看，我认为人工智能（AI）将变得效能更高且成本更低，届时现有的经济规则将不再适用。到那时，我们现行的经济体系将失去其原有意义，社会各界需要展开更广泛的讨论，共同探讨未来经济制度应当如何重构。

这听起来可能很疯狂，但事实是人类文明在过去已经成功经历了几次重大的经济形态转变：从狩猎采集到农业生产，从农业社会到封建制度，再从封建制度到工业化社会。我认为我们需要某种全新且更不寻常的模式，而这种模式是现今没有人能够准确描绘的。它可能简单如建立一个全民基本收入制度，但我觉得这只是解决方案中的一小部分。它可能是一个由 AI 系统主导的资本主义经济体系，这些系统基于人类价值观制定规则，通过某种次级经济体系来向人类分配大量资源（因为整体经济规模将会十分庞大）。也许经济将基于信用积分（Whuffie points）运行。又或者人类最终仍将以常规经济模型未能预料到的方式保持其经济价值。所有这些解决方案都存在诸多潜在问题，如果没有反复试验和实践，我们就无法判断它们是否可行。就像面对其他挑战一样，我们可能需要付出努力才能获得理想的结果：显然，经济发展也可能走向剥削或黑暗化的方向，这是我们必须防范的。关于这些问题还有很多值得讨论的地方，我希望将来能有机会详细探讨。

### Taking stock

Through the varied topics above, I've tried to lay out a vision of a world that is both plausible if everything goes right with AI, and much better than the world today. I don't know if this world is realistic, and even if it is, it will not be achieved without a huge amount of effort and struggle by many brave and dedicated people. Everyone (including AI companies!) will need to do their part both to prevent risks and to fully realize the benefits.

But it is a world worth fighting for. If all of this really does happen over 5 to 10 years—the defeat of most diseases, the growth in biological and cognitive freedom, the lifting of billions of people out of poverty to share in the new technologies, a renaissance of liberal democracy and human rights—I suspect everyone watching it will be surprised by the effect it has on them. I don't mean the experience of personally benefiting from all the new technologies, although that will certainly be amazing. I mean the experience of watching a long-held set of ideals materialize in front of us all at once. I think many will be literally moved to tears by it.

Throughout writing this essay I noticed an interesting tension. In one sense the vision laid out here is extremely radical: it is not what almost anyone expects to happen in the next decade, and will likely strike many as an absurd fantasy. Some may not even consider it desirable; it embodies values and political choices that not everyone will agree with. But at the same time there is something blindingly obvious—something overdetermined—about it, as if many different attempts to envision a good world inevitably lead roughly here.

In Iain M. Banks' The Player of Games29, the protagonist—a member of a society called the Culture, which is based on principles not unlike those I've laid out here—travels to a repressive, militaristic empire in which leadership is determined by competition in an intricate battle game. The game, however, is complex enough that a player's strategy within it tends to reflect their own political and philosophical outlook. The protagonist manages to defeat the emperor in the game, showing that his values (the Culture's values) represent a winning strategy even in a game designed by a society based on ruthless competition and survival of the fittest. A well-known post by Scott Alexander has the same thesis—that competition is self-defeating and tends to lead to a society based on compassion and cooperation. The "arc of the moral universe" is another similar concept.

I think the Culture's values are a winning strategy because they're the sum of a million small decisions that have clear moral force and that tend to pull everyone together onto the same side. Basic human intuitions of fairness, cooperation, curiosity, and autonomy are hard to argue with, and are cumulative in a way that our more destructive impulses often aren't. It is easy to argue that children shouldn't die of disease if we can prevent it, and easy from there to argue that everyone's children deserve that right equally. From there it is not hard to argue that we should all band together and apply our intellects to achieve this outcome. Few disagree that people should be punished for attacking or hurting others unnecessarily, and from there it's not much of a leap to the idea that punishments should be consistent and systematic across people. It is similarly intuitive that people should have autonomy and responsibility over their own lives and choices. These simple intuitions, if taken to their logical conclusion, lead eventually to rule of law, democracy, and Enlightenment values. If not inevitably, then at least as a statistical tendency, this is where humanity was already headed. AI simply offers an opportunity to get us there more quickly—to make the logic starker and the destination clearer.

Nevertheless, it is a thing of transcendent beauty. We have the opportunity to play some small role in making it real.

Thanks to Kevin Esvelt, Parag Mallick, Stuart Ritchie, Matt Yglesias, Erik Brynjolfsson, Jim McClave, Allan Dafoe, and many people at Anthropic for reviewing drafts of this essay.

To the winners of the 2024 Nobel prize in Chemistry, for showing us all the way.

回顾与展望

通过上述种种议题的探讨，我试图描绘这样一幅愿景：如果人工智能的发展一切顺利，我们将迎来一个既切实可行又远胜于当今的美好世界。这个愿景是否能够实现，我无法确定。即便有实现的可能，也需要无数勇敢而执着的人们不懈奋斗才能达成。每个人（包括 AI 公司！）都必须贡献自己的力量，既要防范潜在风险，又要充分发掘其中的机遇。

但这个世界值得我们为之奋斗。如果这一切真的能在未来 5 到 10 年内实现 —— 战胜大多数疾病，扩展生物和认知领域的自由，让数十亿人脱离贫困并享受科技进步的成果，见证自由民主和人权的复兴 —— 我相信每个亲历这一切的人都会被这些变革深深震撼。我说的不仅仅是亲身体验这些新技术带来的惊喜，尽管那必定令人赞叹。更重要的是，当我们共同见证那些长久以来的理想在眼前一一实现时的那份感动。我想，很多人都会为之落泪。

在写作这篇文章的过程中，我注意到一种有趣的张力。从一个角度来看，这里描绘的愿景确实非常激进，它完全超出了人们对未来十年的普遍预期，甚至可能会被很多人视为天马行空的幻想。有些人可能根本不认同这种愿景的价值，因为它所体现的价值观和政治选择并非人人都能接受。但有趣的是，这个愿景同时又显得如此理所当然 —— 似乎带着某种必然性，就好像无论我们从何种角度去构想一个美好的世界，最终都会殊途同归，指向这样一个相似的未来蓝图。

在 Iain M. Banks 的科幻小说《游戏玩家》[29] 中，故事的主人公来自一个名为 Culture 的社会，这个社会的理念与我前面所述的原则颇为相似。他造访了一个高度军事化的独裁帝国，在那里，统治者的地位是通过一种复杂的战争游戏竞争决定的。有趣的是，这个游戏极其复杂，玩家在游戏中采取的策略往往会反映出他们的政治理念和人生哲学。最终，主人公在游戏中战胜了皇帝，证明了他所代表的 Culture 价值观，即使在这个由崇尚残酷竞争、信奉适者生存的社会所设计的游戏中，也能成为制胜法则。Scott Alexander 在他的一篇广为流传的文章中也表达了相同的观点 —— 单纯的竞争最终会走向自我否定，反而会促使社会向着重视同理心与合作的方向发展。这与「道德的力量终将胜利」这一历史发展规律不谋而合。

我认为文化价值观是一条成功之道，因为它是由无数个小决策汇聚而成的，这些决策都具有明确的道德力量，能够将人们团结在同一面旗帜下。人类对于公平、合作、好奇心和自主权的基本直觉很难被质疑，而且这些正面特质会不断积累壮大，这一点是我们破坏性冲动所做不到的。很容易理解我们应该尽可能预防儿童死于疾病，进而也很容易接受所有儿童都应该平等地享有这项权利。在这个基础上，我们自然会达成共识：应该齐心协力，集思广益来实现这个目标。几乎没有人会反对对无故伤害他人的行为进行惩罚，由此也很容易接受这种惩罚应该对所有人公平一致。同样显而易见的是，每个人都应该拥有自主权，对自己的生活和选择负责。这些简单的直觉，如果顺着其逻辑发展下去，最终会引领我们走向法治、民主和启蒙价值观。就算这不是必然的结果，但从大势来看，这就是人类一直在前进的方向。人工智能的出现，则为我们加速这一进程提供了机会 —— 它让这个逻辑更加清晰，也让我们的最终目标更加明确。

然而，这是一件具有超越性之美的事物。我们很荣幸能在将其变为现实的过程中贡献一份力量。

特别感谢 Kevin Esvelt、Parag Mallick、Stuart Ritchie、Matt Yglesias、Erik Brynjolfsson、Jim McClave、Allan Dafoe，以及 Anthropic 的诸位同仁对本文初稿的悉心审阅。

谨以此文献给 2024 年诺贝尔化学奖的获得者们，正是他们为我们照亮了前行的道路。

### Footnotes

1 https://allpoetry.com/All-Watched-Over-By-Machines-Of-Loving-Grace

2 I do anticipate some minority of people's reaction will be "this is pretty tame". I think those people need to, in Twitter parlance, "touch grass". But more importantly, tame is good from a societal perspective. I think there's only so much change people can handle at once, and the pace I'm describing is probably close to the limits of what society can absorb without extreme turbulence.

3 I find AGI to be an imprecise term that has gathered a lot of sci-fi baggage and hype. I prefer "powerful AI" or "Expert-Level Science and Engineering" which get at what I mean without the hype.

4 In this essay, I use "intelligence" to refer to a general problem-solving capability that can be applied across diverse domains. This includes abilities like reasoning, learning, planning, and creativity. While I use "intelligence" as a shorthand throughout this essay, I acknowledge that the nature of intelligence is a complex and debated topic in cognitive science and AI research. Some researchers argue that intelligence isn't a single, unified concept but rather a collection of separate cognitive abilities. Others contend that there's a general factor of intelligence (g factor) underlying various cognitive skills. That's a debate for another time.

5 This is roughly the current speed of AI systems – for example they can read a page of text in a couple seconds and write a page of text in maybe 20 seconds, which is 10-100x the speed at which humans can do these things. Over time larger models tend to make this slower but more powerful chips tend to make it faster; to date the two effects have roughly canceled out.

6 This might seem like a strawman position, but careful thinkers like Tyler Cowen and Matt Yglesias have raised it as a serious concern (though I don't think they fully hold the view), and I don't think it is crazy.

7 The closest economics work that I'm aware of to tackling this question is work on "general purpose technologies" and "intangible investments" that serve as complements to general purpose technologies.

8 This learning can include temporary, in-context learning, or traditional training; both will be rate-limited by the physical world.

9 In a chaotic system, small errors compound exponentially over time, so that even an enormous increase in computing power leads to only a small improvement in how far ahead it is possible to predict, and in practice measurement error may degrade this further.

10 Another factor is of course that powerful AI itself can potentially be used to create even more powerful AI. My assumption is that this might (in fact, probably will) occur, but that its effect will be smaller than you might imagine, precisely because of the "decreasing marginal returns to intelligence" discussed here. In other words, AI will continue to get smarter quickly, but its effect will eventually be limited by non-intelligence factors, and analyzing those is what matters most to the speed of scientific progress outside AI.

11 These achievements have been an inspiration to me and perhaps the most powerful existing example of AI being used to transform biology.

12 "Progress in science depends on new techniques, new discoveries and new ideas, probably in that order." - Sydney Brenner

13 Thanks to Parag Mallick for suggesting this point.

14 I didn't want to clog up the text with speculation about what specific future discoveries AI-enabled science could make, but here is a brainstorm of some possibilities:

— Design of better computational tools like AlphaFold and AlphaProteo — that is, a general AI system speeding up our ability to make specialized AI computational biology tools.

— More efficient and selective CRISPR.

— More advanced cell therapies.

— Materials science and miniaturization breakthroughs leading to better implanted devices.

— Better control over stem cells, cell differentiation, and de-differentiation, and a resulting ability to regrow or reshape tissue.

— Better control over the immune system: turning it on selectively to address cancer and infectious disease, and turning it off selectively to address autoimmune diseases.

15 AI may of course also help with being smarter about choosing what experiments to run: improving experimental design, learning more from a first round of experiments so that the second round can narrow in on key questions, and so on.

16 Thanks to Matthew Yglesias for suggesting this point.

17 Fast evolving diseases, like the multidrug resistant strains that essentially use hospitals as an evolutionary laboratory to continually improve their resistance to treatment, could be especially stubborn to deal with, and could be the kind of thing that prevents us from getting to 100%.

18 Note it may be hard to know that we have doubled the human lifespan within the 5-10 years. While we might have accomplished it, we may not know it yet within the study time-frame.

19 This is one place where I am willing, despite the obvious biological differences between curing diseases and slowing down the aging process itself, to instead look from a greater distance at the statistical trend and say "even though the details are different, I think human science would probably find a way to continue this trend; after all, smooth trends in anything complex are necessarily made by adding up very heterogeneous components.

20 As an example, I'm told that an increase in productivity growth per year of 1% or even 0.5% would be transformative in projections related to these programs. If the ideas contemplated in this essay come to pass, productivity gains could be much larger than this.

21 The media loves to portray high status psychopaths, but the average psychopath is probably a person with poor economic prospects and poor impulse control who ends up spending significant time in prison.

22 I think this is somewhat analogous to the fact that many, though likely not all, of the results we're learning from interpretability would continue to be relevant even if some of the architectural details of our current artificial neural nets, such as the attention mechanism, were changed or replaced in some way.

23 I suspect it is a bit like a classical chaotic system – beset by irreducible complexity that has to be managed in a mostly decentralized manner. Though as I say later in this section, more modest interventions may be possible. A counterargument, made to me by economist Erik Brynjolfsson, is that large companies (such as Walmart or Uber) are starting to have enough centralized knowledge to understand consumers better than any decentralized process could, perhaps forcing us to revise Hayek's insights about who has the best local knowledge.

24T hanks to Kevin Esvelt for suggesting this point.

25 For example, cell phones were initially a technology for the rich, but quickly became very cheap with year-over-year improvements happening so fast as to obviate any advantage of buying a "luxury" cell phone, and today most people have phones of similar quality.

26 This is the title of a forthcoming paper from RAND, that lays out roughly the strategy I describe.

27 When the average person thinks of public institutions, they probably think of their experience with the DMV, IRS, medicare, or similar functions. Making these experiences more positive than they currently are seems like a powerful way to combat undue cynicism.

28 Indeed, in an AI-powered world, the range of such possible challenges and projects will be much vaster than it is today.

29 I am breaking my own rule not to make this about science fiction, but I've found it hard not to refer to it at least a bit. The truth is that science fiction is one of our only sources of expansive thought experiments about the future; I think it says something bad that it's entangled so heavily with a particular narrow subculture.