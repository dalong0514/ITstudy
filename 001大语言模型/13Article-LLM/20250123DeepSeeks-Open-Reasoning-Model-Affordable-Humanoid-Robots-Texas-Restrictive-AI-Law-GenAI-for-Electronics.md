## 20250123DeepSeeks-Open-Reasoning-Model-Affordable-Humanoid-Robots-Texas-Restrictive-AI-Law-GenAI-for-Electronics

[DeepSeek’s Open Reasoning Model, Affordable Humanoid Robots, Texas’ Restrictive AI Law, GenAI for Electronics](https://info.deeplearning.ai/deepseeks-open-reasoning-model-affordable-humanoid-robots-texas-restrictive-ai-law-genai-for-electronics-2?ecid=ACsprvv-Seed3U0LD7vNM2VnQ6ZANOQrOqjOOe_6h1sfInCcL-P8VkLvQ30GNQHZi69y0MRtGW3-&utm_campaign=The%20Batch&utm_medium=email&_hsenc=p2ANqtz-8-lgo0usHg6nXify_s1zfVZF56jzaM9Ts6YJA1z-ceF_3bPZRAiQZEav8lCB36rTBFp7b411k0NnIVvRPlH2JEW57gOg&_hsmi=343706145&utm_content=343704408&utm_source=hs_email)

Dear friends,

Greetings from Davos, Switzerland! Many business and government leaders are gathered here again for the annual World Economic Forum to discuss tech, climate, geopolitics, and economic growth. While the vast majority of my conversations have been on AI business implementations and governance, I have also been speaking about our latest AI climate simulator and about geoengineering. After speaking about geoengineering onstage at multiple events to a total of several hundred people, I've been pleasantly surprised by almost uniformly positive reactions. You can play with our simulator here.

大家好，我正在瑞士达沃斯！许多商业和政府领导人再次齐聚达沃斯，参加一年一度的世界经济论坛，共同探讨技术、气候、地缘政治和经济增长。虽然我参与的绝大多数对话都围绕人工智能（AI）的商业应用和治理展开，但也谈到了我们最新的 AI 气候模拟器和地球工程。在多个活动中，我向数百人介绍了地球工程，令我惊喜的是，几乎所有人都给出了积极的反馈。您可以在这里体验我们的模拟器。

[Planet Parasol | SAI Simulator](https://www.planetparasol.ai/?ssp_scenario=SSP2-4.5&temp_target=1.5&spatial_agg=WGI+Reference&decade_visualization=2091-2100&start_year=2035&ramp_up=10&var=tas)

Here's why I think we should seriously consider geoengineering: The world urgently needs to reduce carbon emissions, but it hasn't happened fast enough. Given recent emission trends, without geoengineering, there's no longer any plausible path to keeping global warming to the 1.5 degrees Celsius goal set by the Paris agreement. Under reasonable assumptions, we are on a path to 2.5 degrees of warming or worse. We might be in for additional abrupt changes if we hit certain tipping points.

我认为我们应该认真考虑地球工程，原因如下：全球迫切需要减少碳排放，但减排速度仍然不够快。鉴于目前的排放趋势，如果不采取地球工程手段，将全球变暖控制在《巴黎协定》设定的 1.5 摄氏度目标内，已经没有任何可行的方案。基于合理的假设，我们正面临升温 2.5 摄氏度甚至更糟糕的局面。如果我们触及某些临界点，还可能引发额外的剧烈变化。

If you tilt a four-legged chair by a few degrees, it will fall back onto its four legs. But if you tip it far enough — beyond its "tipping point" — it will fall over with a crash. Climate tipping points are like that, where parts of our planet, warmed sufficiently, might reach a point where the planet reorganizes abruptly in a way that is impossible to reverse. Examples include a possible melting of the Arctic permafrost, which would release additional methane (a potent greenhouse gas), or a collapse of ocean currents that move warm water northward from the tropics (the Atlantic Meridional Overturning Circulation).

如果你将一把四条腿的椅子倾斜几度，它会恢复到四腿着地的状态。但是，如果你将其倾斜足够大的角度 —— 超过其「倾翻点」—— 它会轰然倒塌。气候临界点与此类似，我们星球的某些区域，在被充分加热后，可能会达到一个临界状态，导致地球以一种不可逆转的方式发生剧变。例如，北极永久冻土可能融化，这将释放额外的甲烷（methane）（一种强效温室气体）；又如，将温暖海水从热带向北输送的洋流「大西洋经向翻转环流」（Atlantic Meridional Overturning Circulation）可能崩溃。

Keeping warming low will significantly lower the risk of hitting a tipping point. This is why the OECD's report states, "the existence of climate system tipping points means it is vital to limit the global temperature increase to 1.5 degrees C, with no or very limited overshoot."

将升温幅度控制在较低水平将显著降低触发临界点的风险。这就是为什么经合组织报告指出，「鉴于气候系统存在临界点，将全球气温升高限制在 1.5 摄氏度至关重要，并且不允许或仅允许极小的超调。」

Global temperature change map and graph comparing scenarios with and without SAI intervention.

全球温度变化地图和图表，对比了有和没有平流层气溶胶注入（Stratospheric Aerosol Injection，SAI）干预的情景。

The good news is that geoengineering keeps the 1.5 degree goal alive. Spraying reflective particles into the atmosphere — an idea called Stratospheric Aerosol Injection (SAI) — to reflect 1% of sunlight back into space would get us around 1 degree Celsius of cooling.

好消息是，地球工程技术让 1.5 摄氏度的温控目标仍有实现的希望。向大气中喷射反射粒子 —— 即平流层气溶胶注入（SAI）—— 将 1% 的阳光反射回太空，这将带来大约 1 摄氏度的降温效果。

Now, there are risks to doing this. For example, just as global warming has had uneven regional effects, the global cooling impact will also be uneven. But on average, a planet with 1.5 degrees of warming would be much more livable than one with 2.5 degrees (or more). Further, after collaborating extensively with climate scientists on AI climate models and examining the output of multiple such models, I believe the risks associated with cooling down our planet will be much lower than the risks of runaway climate change.

现在，这样做存在风险。例如，正如全球变暖对不同地区的影响不均衡一样，全球降温的影响也将如此。但是，平均而言，一个升温 1.5 度的行星会比升温 2.5 度或更高的行星更适合居住。此外，在与气候科学家就 AI 气候模型进行了广泛合作，并研究了多个此类模型的输出后，我认为降低地球温度的风险远低于气候变化失控的风险。

I hope we can build a global governance structure to decide collectively whether, and if so to what extent and how, to implement geoengineering. For example, we might start with small scale experiments (aiming for <<0.1 degrees of cooling) that are easy to stop/reverse at any time. Further, there is much work to be done to solve difficult engineering challenges, such as how to build and operate a fleet of aircraft to efficiently lift and spray reflective particles at the small particle sizes needed.

我希望我们能建立一个全球性的治理框架，以便集体决策是否实施地球工程，如果实施，那么实施的程度和方式。例如，我们可以从小型实验开始（目标是降温远小于 0.1 度），这些实验可以随时停止或逆转。此外，还有许多工作要做，以解决一些棘手的工程难题，例如如何建造和运营一支飞机编队，从而高效地提升并喷洒所需粒径的反光颗粒。

Even as I have numerous conversations about AI business and governance here at the World Economic Forum, I am glad that AI climate modeling is helpful for addressing global warming. If you are interested in learning more about geoengineering, I encourage you to play with our simulator at planetparasol.ai.

虽然我在世界经济论坛上参与了许多关于人工智能商业和治理的讨论，但我很高兴看到人工智能气候建模在应对全球变暖方面发挥着作用。如果您想进一步了解地球工程，我推荐您在 planetparasol.ai 尝试我们的模拟器。

I am grateful to my collaborators on the simulator work: Jeremy Irvin, Jake Dexheimer, Dakota Gruener, Charlotte DeWald, Daniele Visioni, Duncan Watson-Parris, Douglas MacMartin, Joshua Elliott, Juerg Luterbacher, and Kion Yaghoobzadeh.

我在此感谢在模拟器工作上的合作者：Jeremy Irvin，Jake Dexheimer，Dakota Gruener，Charlotte DeWald，Daniele Visioni，Duncan Watson-Parris，Douglas MacMartin，Joshua Elliott，Juerg Luterbacher 和 Kion Yaghoobzadeh。

Keep learning!

Andrew

### News

新闻

Bar chart comparing accuracy and percentile scores of DeepSeek models and OpenAI models across benchmarks.

一个条形图，展示了 DeepSeek 模型和 OpenAI 模型在不同基准测试中的准确率和百分位数得分。

#### DeepSeek Sharpens Its Reasoning

A new open model rivals OpenAI's o1, and it's free to use or modify.

DeepSeek 提升推理能力一个全新的开源模型，性能可与 OpenAI 的 o1 模型相媲美，并且可以免费使用或修改。

What's new: DeepSeek released DeepSeek-R1, a large language model that executes long lines of reasoning before producing output. The code and weights are licensed freely for commercial and personal use, including training new models on R1 outputs. The paper provides an up-close look at the training of a high-performance model that implements a chain of thought without explicit prompting. (DeepSeek-R1-lite-preview came out in November with fewer parameters and a different base model.)

最新进展：DeepSeek 发布了 DeepSeek-R1，这是一个大语言模型（Large Language Model），它在生成结果之前会执行复杂的推理过程。该模型的代码和权重可免费用于商业和个人用途，包括使用 R1 的输出训练新模型。相关论文详细介绍了这个高性能模型的训练过程，该模型无需明确提示即可实现思维链。DeepSeek-R1-lite-preview 版本已于 11 月发布，它拥有更少的参数，并且基于不同的基础模型。

How it works: DeepSeek-R1 is a version of DeepSeek-V3-Base that was fine-tuned over four stages to enhance its ability to process a chain of thought (CoT). It's a mixture-of-experts transformer with 671 billion total parameters, 37 billion of which are active at any given time, and it processes 128,000 tokens of input context. Access to the model via DeepSeek's API costs $0.55 per million input tokens ($0.14 for cached inputs) and $2.19 per million output tokens. (In comparison, o1 costs $15 per million input tokens, $7.50 for cached inputs, and $60 per million output tokens.)

工作原理：DeepSeek-R1 是 DeepSeek-V3-Base 的一个版本，它通过四个阶段的微调，增强了其处理思维链（CoT）的能力。它是一个混合专家 Transformer（mixture-of-experts Transformer），总共有 6710 亿个参数，其中 370 亿个参数在任何时候激活，并且它可以处理 128,000 个 Token 的输入上下文。通过 DeepSeek 的 API 访问该模型的费用为：每百万个输入 Token 0.55 美元（缓存输入为 0.14 美元），每百万个输出 Token 2.19 美元。相比之下，o1 的费用为：每百万个输入 Token 15 美元，缓存输入为 7.50 美元，每百万个输出 Token 60 美元。

The team members fine-tuned DeepSeek-V3-Base on a synthetic dataset of thousands of long-form CoT examples that were generated using multiple techniques. For instance, they prompted DeepSeek-V3-Base few-shot style with long CoTs as examples, prompted that model to generate detailed answers while evaluating and double-checking its own CoT steps, and hired human annotators to refine and process the results.

研究团队的成员们，使用多种技术生成了数千个长篇思维链（Chain-of-Thought，CoT）示例，并用这些示例组成了一个合成数据集，然后在这个数据集上对 DeepSeek-V3-Base 进行了微调。具体来说，他们首先使用少样本（Few-shot）方式提示 DeepSeek-V3-Base，将长篇的思维链（CoT）作为示例；然后，他们提示模型在生成详细答案的同时，评估并仔细检查其自身的思维链（CoT）步骤；最后，他们还聘请了人工标注员来进一步完善和处理模型输出的结果。

They used group relative policy optimization, a reinforcement learning algorithm, to improve the model's ability to solve challenging problems. For example, for math problems, they created rule-based systems that rewarded the model for returning the final answer in a particular format (an accuracy reward) and for showing its internal CoT steps within <think> tags (a format reward).

他们使用了基于群体的相对策略优化（group relative policy optimization），这是一种强化学习算法，旨在提升模型解决复杂难题的能力。例如，在处理数学问题时，他们构建了基于规则的系统，该系统会奖励模型以特定格式给出最终答案（准确性奖励），并奖励其在 <think> 标签内展示思维链（CoT）步骤（格式奖励）。

For further fine-tuning, they used the in-progress versions of R1 to generate around 600,000 responses to reasoning prompts, retaining only correct responses. They mixed in another 200,000 non-reasoning examples (such as language translation pairs) either generated by DeepSeek-V3-base or from its training dataset.

为了进一步微调，他们使用 R1 的开发版本生成了大约 60 万个针对推理提示的回答，并且只保留了正确的回答。他们还加入了另外 20 万个非推理示例（例如语言翻译对），这些示例一部分由 DeepSeek-V3-base 生成，一部分来自其训练数据集。

They fine-tuned the model using a final round of reinforcement learning. This step encouraged the model to further boost its accuracy on reasoning problems while generally improving its helpfulness and harmlessness.

他们通过最后一轮的强化学习对模型进行了微调。这个步骤旨在鼓励模型在推理问题上进一步提升准确率，并在整体上提高其帮助性和无害性。

Other models: DeepSeek researchers also released seven related models.

其他模型：DeepSeek 的研究人员还推出了另外七个相关的模型。

DeepSeek-R1-Zero is similar to DeepSeek-R1, but fine-tuned entirely using reinforcement learning. The researchers note that DeepSeek-R1-Zero was able to develop problem-solving strategies simply by being given incentives to do so. However, it was more likely to mix languages and produce unreadable outputs.

DeepSeek-R1-Zero 模型与 DeepSeek-R1 模型类似，但它完全是通过强化学习进行微调的。研究人员发现，DeepSeek-R1-Zero 仅仅是被赋予了解决问题的动机，就能够自行发展出相应的策略。不过，该模型也更容易出现语言混杂的情况，并产生难以理解的输出结果。

DeepSeek also released six dense models (with parameter counts of 1.5 billion, 7 billion, 8 billion, 14 billion, 32 billion, and 70 billion), four of them based on versions of Qwen, and two based on versions of Llama.

DeepSeek 还发布了六个参数稠密模型（参数量分别为 15 亿、70 亿、80 亿、140 亿、320 亿和 700 亿），其中四个基于 Qwen 模型，另外两个基于 Llama 模型。

Results: In DeepSeek's tests, DeepSeek-R1 went toe-to-toe with o1, outperforming that model on 5 of 11 of the benchmarks tested. Some of the other new models showed competitive performance, too.

结果：在 DeepSeek 的测试中，DeepSeek-R1 与 o1 展开了直接竞争，在 11 项基准测试中，有 5 项表现优于该模型。其他新模型也展现出不错的竞争力。

DeepSeek-R1 topped o1 on AIME 2024, MATH-500, and SWE-Bench Verified, while turning in competitive performance on Codeforces, GPQA Diamond, and MMLU. For instance, on LiveCodeBench, which includes coding problems that are frequently updated, it solved 65.9 percent of problems correctly, while o1 solved 63.4 percent correctly.

DeepSeek-R1 在 AIME 2024、MATH-500 和 SWE-Bench Verified 测试中表现最佳，同时在 Codeforces、GPQA Diamond 和 MMLU 上也取得了不错的成绩。例如，在 LiveCodeBench 上，该基准包含的编码问题会频繁更新，DeepSeek-R1 正确解决了 65.9% 的问题，而 o1 则为 63.4%。

It also outperformed two top models that don't implement chains of thought without explicit prompting. It bested Anthropic Claude 3.5 Sonnet on 19 of 21 benchmarks and OpenAI GPT-4o on 20 of 21 benchmarks.

该模型在没有明确提示的情况下，也胜过了另外两个未采用思维链（chains of thought）的顶尖模型。在 21 项基准测试中，它有 19 项的表现优于 Anthropic Claude 3.5 Sonnet，20 项的表现优于 OpenAI GPT-4o。

In DeepSeek's tests, DeepSeek-R1-Distill-Qwen-32B outperforms OpenAI-o1-mini across all benchmarks tested including AIME 2024 and GPQA Diamond, while DeepSeek-R1-Distill-Llama-70B beats o1-mini on all benchmarks tested except Codeforces.

DeepSeek 的测试表明，DeepSeek-R1-Distill-Qwen-32B 在所有测试基准上都胜过 OpenAI-o1-mini，包括 AIME 2024 和 GPQA Diamond。而 DeepSeek-R1-Distill-Llama-70B 则在除 Codeforces 外的所有测试基准上都胜过 o1-mini。

Why it matters: Late last year, OpenAI's o1 kicked off a trend toward so-called reasoning models that implement a CoT without explicit prompting. But o1 and o3, its not-yet-widely-available successor, hide their reasoning steps. In contrast, DeepSeek-R1 bares all, allowing users to see the steps the model took to arrive at a particular answer. DeepSeek's own experiments with distillation show how powerful such models can be as teachers to train smaller student models. Moreover, they appear to pass along some of the benefits of their reasoning skills, making their students more accurate.

重要性：去年末，OpenAI 的 o1 开启了推理模型的新趋势，这种模型无需明确提示即可实现思维链（Chain-of-Thought，CoT）推理。但是，o1 及其尚未广泛推出的继任者 o3 都隐藏了推理过程。相比之下，DeepSeek-R1 则完全公开其推理步骤，用户可以看到模型为了得出特定答案所采取的每一步。DeepSeek 自己的知识蒸馏实验表明，这种模型作为教师模型，在训练较小的学生模型时具有强大的能力。而且，它们似乎还能将自身的推理能力传递给学生模型，使其更加准确。

We're thinking: DeepSeek is rapidly emerging as a strong builder of open models. Not only are these models great performers, but their license permits use of their outputs for distillation, potentially pushing forward the state of the art for language models (and multimodal models) of all sizes.

我们认为：DeepSeek 正快速成为开源模型的有力构建者。这些模型不仅性能卓越，而且它们的许可协议允许使用其输出来进行知识蒸馏，这有望推动各种规模的语言模型（以及多模态模型）的技术水平进步。

#### Humanoid Robot Price Break

人形机器人价格分析

GIF of two humanoid robots walking, one on grass and the other on a paved surface.

人形机器人行走的 GIF，一个在草地上行走，另一个在铺好的路面上行走。

Chinese robot makers Unitree and EngineAI showed off relatively low-priced humanoid robots that could bring advanced robotics closer to everyday applications.

中国机器人制造商宇树科技（Unitree）和智引擎（EngineAI）展示了价格相对较低的人形机器人，有望让先进的机器人技术更贴近日常生活。

What's new: At the annual Consumer Electronics Show (CES) in Las Vegas, Unitree showed its G1 ($16,000 with three-finger hands, $21,000 with five-finger, articulated hands), which climbed stairs and navigated around obstacles. Elsewhere on the show floor, EngineAI's PM01 ($13,700 through March 2025 including articulated hands) and SE01 (price not yet disclosed) marched among attendees with notably naturalistic gaits.

最新进展：在拉斯维加斯举行的年度消费电子展（CES）上，宇树科技展示了其 G1，这款机器人配备三指手的版本售价 16,000 美元，而配备五指铰接手的版本则为 21,000 美元。G1 能够爬楼梯并在障碍物间灵活穿梭。在展会的其他区域，智引擎的 PM01（配备铰接手，截至 2025 年 3 月的售价为 13,700 美元）和 SE01（价格尚未公布）也吸引了众多目光，它们以非常自然的步态在人群中行走。

How it works: Relatively small and lightweight, these units are designed for household and small-business uses. They're designed for general-purpose tasks and to maintain stability and balance while walking on varied terrain.

工作原理：这些设备相对小巧轻便，专为家庭和小型企业应用而设计。它们旨在执行各种日常任务，并在不同地形上行走时保持稳定和平衡。

Unitree: A downsized version of Unitree's 6-foot H1, which debuted in 2023, the G1 stands at 4 feet, 3 inches and weighs 77 pounds. It walks at speeds up to 4.4 miles per hour and carries up to 5 pounds, and demo videos show it performing tasks that require manual dexterity such as cracking eggs. It was trained via reinforcement learning to avoid obstacles, climb stairs, and jump. A rechargeable, swappable battery ($750) lasts two hours. Unitree offers four models that are programmable (in Python, C++, or ROS) and outfitted with Nvidia Jetson Orin AI accelerators ($40,000 to $68,000). All models can be directed with a radio controller.

G1 是宇树科技在 2023 年推出的 6 英尺 H1 的缩小版，身高 4 英尺 3 英寸，重达 77 磅。它的行走速度可达每小时 4.4 英里，可携带重达 5 磅的物体，演示视频显示它可以执行需要灵巧性的任务，例如打鸡蛋。它通过强化学习训练，使其能够避开障碍物、爬楼梯和跳跃。可充电的可更换电池（售价 750 美元）续航时间为两小时。宇树科技提供了四种型号，它们可使用 Python、C++ 或 ROS 进行编程，并配备了 Nvidia Jetson Orin AI 加速器，售价在 40,000 美元至 68,000 美元之间。所有型号均可通过无线电控制器控制。

EngineAI: The PM01 is slightly larger and heavier than the G1 at 4 feet, 5 inches and 88 pounds. The SE01 is 5 feet, 7 inches and 121 pounds. Both units travel at 4.4 miles per hour and include an Nvidia Jetson Orin AI accelerator. They were trained via reinforcement learning to navigate dynamic environments and adjust to specific requirements. Pretrained AI models enhance their ability to recognize gestures and interact through voice commands. They include built-in obstacle avoidance and path-planning capabilities to operate in cluttered or unpredictable spaces. The robot can be controlled using voice commands or a touchscreen embedded in its chest. Rechargeable, swappable batteries provide two hours of performance per charge.

PM01 比 G1 略大且重，高 4 英尺 5 英寸，重 88 磅。SE01 高 5 英尺 7 英寸，重 121 磅。两款设备的速度均为每小时 4.4 英里，并配备 Nvidia Jetson Orin AI 加速器。它们通过强化学习（reinforcement learning）进行训练，以在动态环境中导航并适应特定要求。预训练的 AI（Artificial Intelligence）模型增强了它们识别手势和通过语音命令交互的能力。它们内置了避障和路径规划功能，以便在杂乱或不可预测的空间中运行。该机器人可以通过语音命令或胸前的触摸屏进行控制。可更换电池每次充电可支持两小时续航。

Behind the news: In contrast to the more-affordable humanoid robots coming out of China, U.S. companies like Boston Dynamics, Figure AI, and Tesla tend to cater to industrial customers. Tesla plans to produce several thousand of its Optimus ($20,000 to $30,000) humanoids in 2025, ramping to as many as 100,000 in 2026. Figure AI has demonstrated its Figure 02 ($59,000) in BMW manufacturing plants, showing a 400 percent speed improvement in some tasks. At CES, Nvidia unveiled its GR00T Blueprint, which includes vision-language models and synthetic data for training humanoid robots, and said its Jetson Thor computer for humanoids would be available early 2025.

新闻幕后：与中国推出的价格更亲民的类人机器人不同，美国的 Boston Dynamics、Figure AI 和 Tesla 等公司，其产品主要面向工业客户。Tesla 计划在 2025 年生产数千台 Optimus（售价 2 万至 3 万美元）类人机器人，并在 2026 年将产量提升至 10 万台。Figure AI 在宝马的制造工厂展示了其 Figure 02（售价 5.9 万美元），在某些任务中速度提升了 400%。在 CES 展上，Nvidia 发布了 GR00T 蓝图，其中包含用于训练类人机器人的视觉语言模型（vision-language models）和合成数据。Nvidia 还表示，其为类人机器人设计的 Jetson Thor 计算机将于 2025 年初上市。

Why it matters: China's push into humanoid robotics reflects its broader national ambitions. Its strength in hardware has allowed it to establish a dominant position in drones, and humanoid robots represent a new front for competition. China's government aims to achieve mass production of humanoid robots by 2025 and establish global leadership by 2027, partly to address projected labor shortages of 30 million workers in manufacturing alone. Lower price points for robots that can perform arbitrary tasks independently could be valuable in elder care and logistics, offering tools for repetitive or physically demanding tasks. .

重要性：中国大力发展人形机器人，体现了其更深远的国家战略意图。凭借强大的硬件实力，中国已在无人机领域占据领先地位，而人形机器人则代表着新的竞争领域。中国政府计划到 2025 年实现人形机器人的量产，并在 2027 年成为全球领导者，部分原因是预计仅制造业就将面临 3000 万的劳动力缺口。能够独立完成各种任务的低成本机器人，在老年护理和物流等领域具有巨大潜力，可以承担重复性或高强度的体力工作。

We're thinking: Although humanoid robots generate a lot of excitement, they're still in an early stage of development, and businesses are still working to identify and prove concrete use cases. For many industrial applications, wheeled robots — which are less expensive, more stable, and better able to carry heavy loads — will remain a sensible choice. But the prospect of machines that look like us and fit easily into environments built for us is compelling.

我们认为：虽然人形机器人引发了广泛关注，但它们仍处于早期研发阶段，各企业仍在积极探索并验证其具体的应用场景。对于许多工业应用而言，轮式机器人依然是更为稳妥的选择 —— 它们不仅成本更低，稳定性更高，而且能承载更重的货物。然而，能够像人类一样，轻松融入我们所处环境的机器，其前景无疑是极具吸引力的。

#### Learn More About AI With Data Points!

用数据点探索人工智能的奥秘！

AI is moving faster than ever. Data Points helps you make sense of it just as fast. Data Points arrives in your inbox twice a week with six brief news stories. This week, we covered Berkeley students developing a high-performing AI model for under $450. Subscribe today!

人工智能正以前所未有的速度发展。「数据点」栏目能帮你快速跟上它的步伐。「数据点」每周会两次发送到你的邮箱，为你带来六则简明的新闻报道。本周，我们关注了伯克利学生仅用不到 450 美元就开发出高性能人工智能模型的新闻。现在就订阅吧！

#### Texas Moves to Regulate AI

德克萨斯州正着手制定人工智能监管法规

Lawmakers in the U.S. state of Texas are considering stringent AI regulation.

美国德克萨斯州的立法者正在考虑制定严格的 AI 监管法规。

What's new: The Texas legislature is considering the proposed Texas Responsible AI Governance Act (TRAIGA). The bill would prohibit a short list of harmful or invasive uses of AI, such as output intended to manipulate users. It would impose strict oversight on AI systems that contribute to decisions in key areas like health care.

最新进展：德克萨斯州立法机构正在审议拟议的《德克萨斯州负责任 AI 治理法案》（TRAIGA）。该法案将禁止少数几种有害或侵入性的 AI 应用，例如用于操纵用户的输出结果。它还将对在医疗保健等关键领域辅助决策的 AI 系统进行严格监管。

How it works: Republican House Representative Giovanni Capriglione introduced TRAIGA, also known as HB 1709, to the state legislature at the end of 2024. If it's passed and signed, the law would go into effect in September 2025.

运作机制：共和党籍众议员乔瓦尼·卡普里廖内（Giovanni Capriglione）于 2024 年底向州议会提交了名为 TRAIGA 的法案，也称为 HB 1709。如果该法案获得通过并签署成为法律，将于 2025 年 9 月生效。

The proposed law would apply to any company that develops, distributes, or deploys an AI system while doing business in Texas, regardless of where the company is headquartered. It makes no distinction between large and small models or research and commercial uses. However, it includes a modest carve-out for independent small businesses that are based in the state.

这项拟议的法律将适用于任何在得克萨斯州开展业务、开发、分发或部署 AI 系统的公司，无论其总部设在哪里。该法律并未区分大型和小型模型，也未区分研究用途和商业用途。不过，它为位于得克萨斯州的独立小企业提供了一定的豁免。

The law controls "high-risk" AI systems that bear on consequential decisions in areas that include education, employment, financial services, transportation, housing, health care, and voting. The following uses of AI would be banned: manipulating, deceiving, or coercing users; inferring race or gender from biometric data; computing a "social score or similar categorical estimation or valuation of a person or group;" and generating sexually explicit deepfakes. The law is especially broad with respect to deepfakes: It outlaws any system that is "capable of producing unlawful visual material."

该法律管控在教育、就业、金融服务、交通、住房、医疗保健和投票等领域，对重要决策产生影响的「高风险」AI 系统。以下几种 AI 的应用将被禁止：操纵、欺骗或胁迫用户；通过生物识别数据推断种族或性别；计算「社会信用评分」或其他对个人或群体进行分类评估的类似系统；以及制作色情深度伪造内容。该法律在深度伪造方面尤其宽泛：它禁止任何「能够制作非法视觉内容」的系统。

Companies would have to notify users whenever AI is used. They would also have to safeguard against algorithmic discrimination, maintain and share detailed records of training data and accuracy metrics, assess impacts, and withdraw any system that violates the law until it can achieve compliance.

公司在使用 AI 时，必须通知用户。他们还必须防止算法歧视，维护并共享训练数据和准确性指标的详细记录，评估其对社会的影响，并撤回任何违反法律的系统，直到该系统能够符合法规要求。

The Texas attorney general would investigate companies that build or use AI, file civil lawsuits, and impose penalties up to $200,000 per violation, with additional fines for ongoing noncompliance of $40,000 per day.

德克萨斯州总检察长将调查开发或应用 AI 的公司，提起民事诉讼，并对每次违规处以最高 20 万美元的罚款；对于持续不合规的行为，每天还将处以 4 万美元的罚款。

The bill would establish a Texas AI Council that reports to the governor, whose members would be appointed by the governor, lieutenant governor, and state legislative leaders. The council would monitor AI companies, develop non-binding ethical guidelines for them, and recommend new laws and regulations.

该法案将成立一个德克萨斯州人工智能委员会，该委员会向州长汇报工作，其成员将由州长、副州长和州立法领导人共同任命。该委员会将负责监督人工智能公司，为它们制定不具约束力的伦理规范，并提出新的法律法规建议。

Sandbox: A "sandbox" provision would allow registered AI developers to test and refine AI systems temporarily with fewer restrictions. Developers who registered AI projects with the Texas AI Council would gain temporary immunity, even if their systems did not fully comply with the law. However, this exemption would come with conditions: Developers must submit detailed reports on their projects' purposes, risks, and mitigation plans. The sandbox status would be in effect for 36 months (with possible extensions), and organizations would have to bring their systems into compliance or decommission them once the period ends. The Texas AI Council could revoke sandbox protections if it determined that a project posed a risk of public harm or failed to meet reporting obligations.

沙盒：「沙盒」机制将允许已注册的 AI 开发人员在较少限制下临时测试和改进 AI 系统。向德克萨斯州 AI 委员会注册 AI 项目的开发人员将获得临时豁免，即使系统未能完全满足法规要求。这项豁免是有条件的：开发人员必须提交关于项目目的、风险和缓解计划的详细报告。「沙盒」状态将生效 36 个月（可延期），期限结束后，相关组织必须使系统合规或将其停用。如果德克萨斯州 AI 委员会认为某个项目存在公共危害风险，或者未能履行报告义务，则可以撤销「沙盒」保护。

Behind the news: Other U.S. states, too, are considering or have already passed laws that regulate AI:

实际上：美国其他州也在考虑或已经通过了监管人工智能的法律：

California SB 1047, aimed to regulate both open and closed models above a specific size. The state's governor vetoed the proposed bill due to concerns about regulatory gaps and overreach.

加利福尼亚州 SB 1047 法案，旨在监管特定规模以上的开放和封闭模型。该州州长出于对监管漏洞和监管过度问题的担忧，否决了这项拟议的法案。

Colorado signed its AI Act into law in 2024. Like the Texas proposal, it mandates civil penalties for algorithmic discrimination in "consequential use of AI." However, it doesn't create a government body to regulate AI or outlaw specific uses.

科罗拉多州在 2024 年正式颁布了《人工智能法案》。与德克萨斯州的提案相似，该法案规定，对于「人工智能的重大使用」中出现的算法歧视行为，将强制执行民事处罚。不过，该法案并未设立专门的政府机构来监管人工智能，也没有禁止任何特定的人工智能应用。

New York state is considering a bill similar to California SB 1047 but narrower in scope. New York's proposed bill would focus on catastrophic harms potentially caused by AI models that require more than 1026 FLOPs or cost $100 million or more to train). It would mandate third-party audits and protection for whistleblowers.

纽约州正在考虑一项与加利福尼亚州 SB 1047 法案相似，但范围更小的法案。纽约州提出的这项法案，将主要关注那些训练时需要超过 1026 FLOPs（Floating Point Operations Per Second，每秒浮点运算次数）或耗资 1 亿美元及以上的 AI 模型，它们可能造成的灾难性危害。该法案将强制要求进行第三方审计，并为举报人提供保护。

Why it matters: AI is not specifically regulated at the national level in the United States. This leaves individual states free to formulate their own laws. However, state-by-state regulation risks a patchwork of laws in which a system — or a particular feature — may be legal in some states but not others. Moreover, given the distributed nature of AI development and deployment, a law that governs AI in an individual state could affect developers and users worldwide.

重要性：美国在国家层面没有针对人工智能（AI）的专门监管。这使得各州可以自行制定法律。然而，各州分别监管可能会导致法律法规不统一， 某个系统或特定功能可能在这个州合法，在另一个州却不合法。由于人工智能的开发和部署具有分散性，某个州的人工智能管理法律可能会影响全球的开发者和使用者。

We're thinking: The proposed bill has its positive aspects, particularly insofar as it seeks to restrict harmful applications rather than the underlying technology. However, it imposes burdensome requirements for compliance, suffers from overly broad language, fails to adequately protect open source, and doesn't distinguish between research and commercial use. Beyond that, state-by-state regulation of AI is not workable. On the contrary, AI demands international conventions and standards.

我们认为：拟议的法案具有其积极意义，尤其在于它试图限制有害的应用，而非限制底层技术本身。然而，该法案对合规性提出了过高的要求，措辞过于宽泛，未能充分保护开源项目，并且没有区分研究用途和商业用途。此外，各州分别制定 AI 监管法规是不可行的。相反，人工智能（AI） 的发展需要国际公约和标准。

#### Generated Chip Designs Work in Mysterious Ways

生成的芯片设计为何如此神奇

Workflow for inverse design using deep learning to predict S-parameters and radiation in structures.

利用深度学习预测结构中的 S 参数（S-parameters）和辐射的反向设计工作流程。

Designing integrated circuits typically requires years of human expertise. Recent work set AI to the task with surprising results.

集成电路的设计通常需要多年的专业知识。最近的研究尝试使用 AI 进行这项任务，结果出人意料。

What's new: Emir Ali Karahan, Zheng Liu, Aggraj Gupta, and colleagues at Princeton and Indian Institute of Technology Madras used deep learning and an evolutionary algorithm, which generates variations and tests their fitness, to generate designs for antennas, filters, power splitters, resonators, and other chips with applications in wireless communications and other applications. They fabricated a handful of the generated designs and found they worked — but in mysterious ways.

新进展：Emir Ali Karahan、Zheng Liu、Aggraj Gupta 以及普林斯顿大学和印度理工学院马德拉斯分校的同事们，使用深度学习和一种进化算法（通过生成变体并测试其性能），为天线、滤波器、功率分配器、谐振器和其他在无线通信等领域应用的芯片生成设计。他们制造了一些生成的这些设计，发现它们可以工作，但工作原理尚不明确。

How it works: The authors trained convolutional neural networks (CNNs), given a binary image of a circuit design (in which each pixel represents whether the corresponding portion of a semiconductor surface is raised or lowered), to predict its electromagnetic scattering properties and radiative properties. Based on this simulation, they generated new binary circuit images using evolution.

工作原理：作者训练了卷积神经网络（CNN），输入一个电路设计的二值图像（其中每个像素代表半导体表面相应位置的凸起或凹陷），来预测其电磁散射特性和辐射特性。基于此模拟结果，他们利用演化算法生成了新的二值电路图像。

The authors produced a training set of images and associated properties using Matlab EM Toolbox. The images depicted designs for chip sizes between 200x200 micrometers (which they represented as 10x10 pixels) and 500x500 micrometers (represented as 25x25 pixels).

作者利用 Matlab 的 EM 工具箱生成了一组训练图像，并为每张图像关联了相应的属性。这些图像展示了芯片的设计图，其尺寸范围在 200x200 微米（用 10x10 像素表示）到 500x500 微米（用 25x25 像素表示）之间。

They trained a separate CNN on designs of each size.

他们针对每种尺寸的设计分别训练了一个独立的卷积神经网络（CNN）。

They generated 4,000 designs at random and predicted their properties using the appropriate CNN.

他们随机生成了 4,000 个设计，并使用对应的卷积神经网络（CNN）预测了这些设计的性能。

Given the properties, the authors used a tournament method to select the designs whose properties were closest to the desired values. They randomly modified the selected designs to produce a new pool of 4,000 designs, predicted their properties, and repeated the tournament. The number of iterations isn't specified.

根据这些属性，作者采用了一种锦标赛方法来挑选那些属性最接近期望值的设计方案。他们随机修改选定的设计方案，从而生成一个新的包含 4000 个设计方案的集合，并预测这些方案的属性，然后重复进行锦标赛。迭代的具体次数没有明确说明。

Results: The authors fabricated some of the designs to test their real-world properties. The chips showed similar performance than the CNNs had predicted. The authors found the designs themselves baffling; they "delivered stunning high-performances devices that ran counter to the usual rules of thumb and human intuition," co-author Uday Khankhoje told the tech news site Tech Xplore. Moreover, the design process was faster than previous approaches. The authors' method designed a 300x300 micrometer chip in approximately 6 minutes. Using traditional methods it would have taken 21 days.

作者制造了一些设计来测试它们的实际性能。这些芯片的性能与卷积神经网络（CNN）(Convolutional Neural Networks）的预测相似。作者发现这些设计本身让他们感到困惑；共同作者 Uday Khankhoje 对科技新闻网站 Tech Xplore 表示，它们「实现了惊人的高性能设备，与传统经验和人类直觉相悖」。此外，设计过程比以前的方法更快。作者的方法仅用大约 6 分钟就设计出一个 300x300 微米的芯片，而传统方法则需要 21 天。

Behind the news: Rather than wireless chips, Google has used AI to accelerate design of the Tensor Processing Units that process neural networks in its data centers. AlphaChip used reinforcement learning to learn how to position chip components such as SRAM and logic gates on silicon.

科技前沿：谷歌并没有采用传统的无线芯片设计，而是利用 AI 来加速其数据中心中用于处理神经网络的张量处理单元（Tensor Processing Units）的设计。AlphaChip 使用强化学习（reinforcement learning）来学习如何在硅片（silicon）上布局芯片组件，例如 SRAM 和逻辑门。

Why it matters: Designing circuits usually requires rules of thumb, templates, and hundreds of hours of simulations and experiments to determine the best design. AI can cut the required expertise and time and possibly find effective designs that wouldn't occur to human designers.

重要性：电路设计通常依赖于经验方法、既定模式，以及耗费数百小时的仿真和实验才能最终确定最佳方案。而人工智能的介入，则有望减少对专业知识和时间的依赖，甚至可能发现人类设计师难以企及的巧妙设计。

We're thinking: AI-generated circuit designs could help circuit designers to break out of set ways of thinking and discover new design principles.

我们正在考虑：AI 生成的电路设计可以帮助电路设计师打破固有的思维模式，并发现新的设计原则。

## 原文


DeepSeek’s Open Reasoning Model, Affordable Humanoid Robots, Texas’ Restrictive AI Law, GenAI for Electronics


The Batch @ DeepLearning.AI <thebatch@deeplearning.ai> 退订
12:02 (4小时前)
发送至 我

View in browser
The Batch top banner - January 22, 2025
Subscribe   Submit a tip
 

 

Dear friends,

 

Greetings from Davos, Switzerland! Many business and government leaders are gathered here again for the annual World Economic Forum to discuss tech, climate, geopolitics, and economic growth. While the vast majority of my conversations have been on AI business implementations and governance, I have also been speaking about our latest AI climate simulator and about geoengineering. After speaking about geoengineering onstage at multiple events to a total of several hundred people, I’ve been pleasantly surprised by almost uniformly positive reactions. You can play with our simulator here.

 

Here’s why I think we should seriously consider geoengineering: The world urgently needs to reduce carbon emissions, but it hasn’t happened fast enough. Given recent emission trends, without geoengineering, there’s no longer any plausible path to keeping global warming to the 1.5 degrees Celsius goal set by the Paris agreement. Under reasonable assumptions, we are on a path to 2.5 degrees of warming or worse. We might be in for additional abrupt changes if we hit certain tipping points.

 

If you tilt a four-legged chair by a few degrees, it will fall back onto its four legs. But if you tip it far enough — beyond its “tipping point” — it will fall over with a crash. Climate tipping points are like that, where parts of our planet, warmed sufficiently, might reach a point where the planet reorganizes abruptly in a way that is impossible to reverse. Examples include a possible melting of the Arctic permafrost, which would release additional methane (a potent greenhouse gas), or a collapse of ocean currents that move warm water northward from the tropics (the Atlantic Meridional Overturning Circulation).

 

Keeping warming low will significantly lower the risk of hitting a tipping point. This is why the OECD’s report states, “the existence of climate system tipping points means it is vital to limit the global temperature increase to 1.5 degrees C, with no or very limited overshoot.”

Global temperature change map and graph comparing scenarios with and without SAI intervention.
The good news is that geoengineering keeps the 1.5 degree goal alive. Spraying reflective particles into the atmosphere — an idea called Stratospheric Aerosol Injection (SAI) — to reflect 1% of sunlight back into space would get us around 1 degree Celsius of cooling.

 

Now, there are risks to doing this. For example, just as global warming has had uneven regional effects, the global cooling impact will also be uneven. But on average, a planet with 1.5 degrees of warming would be much more livable than one with 2.5 degrees (or more). Further, after collaborating extensively with climate scientists on AI climate models and examining the output of multiple such models, I believe the risks associated with cooling down our planet will be much lower than the risks of runaway climate change.

 

I hope we can build a global governance structure to decide collectively whether, and if so to what extent and how, to implement geoengineering. For example, we might start with small scale experiments (aiming for <<0.1 degrees of cooling) that are easy to stop/reverse at any time. Further, there is much work to be done to solve difficult engineering challenges, such as how to build and operate a fleet of aircraft to efficiently lift and spray reflective particles at the small particle sizes needed.

 

Even as I have numerous conversations about AI business and governance here at the World Economic Forum, I am glad that AI climate modeling is helpful for addressing global warming. If you are interested in learning more about geoengineering, I encourage you to play with our simulator at planetparasol.ai.

 

I am grateful to my collaborators on the simulator work: Jeremy Irvin, Jake Dexheimer, Dakota Gruener, Charlotte DeWald, Daniele Visioni, Duncan Watson-Parris, Douglas MacMartin, Joshua Elliott, Juerg Luterbacher, and Kion Yaghoobzadeh.

 

Keep learning!

Andrew 

 

 

A MESSAGE FROM DEEPLEARNING.AI
Promo banner for "Building Towards Computer Use with Anthropic"
Explore Computer Use, which enables AI assistants to navigate, use, and accomplish tasks on computers. Taught by Colt Steele, this free course covers Anthropic’s model family, its approach to AI research, and  capabilities like multimodal prompts and prompt caching. Sign up for free

 

News
Bar chart comparing accuracy and percentile scores of DeepSeek models and OpenAI models across benchmarks.
DeepSeek Sharpens Its Reasoning
A new open model rivals OpenAI’s o1, and it’s free to use or modify.

What’s new: DeepSeek released DeepSeek-R1, a large language model that executes long lines of reasoning before producing output. The code and weights are licensed freely for commercial and personal use, including training new models on R1 outputs. The paper provides an up-close look at the training of a high-performance model that implements a chain of thought without explicit prompting. (DeepSeek-R1-lite-preview came out in November with fewer parameters and a different base model.)

How it works: DeepSeek-R1 is a version of DeepSeek-V3-Base that was fine-tuned over four stages to enhance its ability to process a chain of thought (CoT). It’s a mixture-of-experts transformer with 671 billion total parameters, 37 billion of which are active at any given time, and it processes 128,000 tokens of input context. Access to the model via DeepSeek’s API costs $0.55 per million input tokens ($0.14 for cached inputs) and $2.19 per million output tokens. (In comparison, o1 costs $15 per million input tokens, $7.50 for cached inputs, and $60 per million output tokens.)

The team members fine-tuned DeepSeek-V3-Base on a synthetic dataset of thousands of long-form CoT examples that were generated using multiple techniques. For instance, they prompted DeepSeek-V3-Base few-shot style with long CoTs as examples, prompted that model to generate detailed answers while evaluating and double-checking its own CoT steps,  and hired human annotators to refine and process the results.
They used group relative policy optimization, a reinforcement learning algorithm, to improve the model’s ability to solve challenging problems. For example, for math problems, they created rule-based systems that rewarded the model for returning the final answer in a particular format (an accuracy reward) and for showing its internal CoT steps within <think> tags (a format reward). 
For further fine-tuning, they used the in-progress versions of R1 to generate around 600,000 responses to reasoning prompts, retaining only correct responses. They mixed in another 200,000 non-reasoning examples (such as language translation pairs) either generated by DeepSeek-V3-base or from its training dataset. 
They fine-tuned the model using a final round of reinforcement learning. This step encouraged the model to further boost its accuracy on reasoning problems while generally improving its helpfulness and harmlessness.
Other models: DeepSeek researchers also released seven related models. 

DeepSeek-R1-Zero is similar to DeepSeek-R1, but fine-tuned entirely using reinforcement learning. The researchers note that DeepSeek-R1-Zero was able to develop problem-solving strategies simply by being given incentives to do so. However, it was more likely to mix languages and produce unreadable outputs.
DeepSeek also released six dense models (with parameter counts of 1.5 billion, 7 billion, 8 billion, 14 billion, 32 billion, and 70 billion), four of them based on versions of Qwen, and two based on versions of Llama. 
Results: In DeepSeek’s tests, DeepSeek-R1 went toe-to-toe with o1, outperforming that model on 5 of 11 of the benchmarks tested. Some of the other new models showed competitive performance, too.

DeepSeek-R1 topped o1 on AIME 2024, MATH-500, and SWE-Bench Verified, while turning in competitive performance on Codeforces, GPQA Diamond, and MMLU. For instance, on LiveCodeBench, which includes coding problems that are frequently updated, it solved 65.9 percent of problems correctly, while o1 solved 63.4 percent correctly. 
It also outperformed two top models that don’t implement chains of thought without explicit prompting. It bested Anthropic Claude 3.5 Sonnet on 19 of 21 benchmarks and OpenAI GPT-4o on 20 of 21 benchmarks.
In DeepSeek’s tests, DeepSeek-R1-Distill-Qwen-32B outperforms OpenAI-o1-mini across all benchmarks tested including AIME 2024 and GPQA Diamond, while DeepSeek-R1-Distill-Llama-70B beats o1-mini on all benchmarks tested except Codeforces.
Why it matters: Late last year, OpenAI’s o1 kicked off a trend toward so-called reasoning models that implement a CoT without explicit prompting. But o1 and o3, its not-yet-widely-available successor, hide their reasoning steps. In contrast, DeepSeek-R1 bares all, allowing users to see the steps the model took to arrive at a particular answer. DeepSeek’s own experiments with distillation show how powerful such models can be as teachers to train smaller student models. Moreover, they appear to pass along some of the benefits of their reasoning skills, making their students more accurate.

We’re thinking: DeepSeek is rapidly emerging as a strong builder of open models. Not only are these models great performers, but their license permits use of their outputs for distillation, potentially pushing forward the state of the art for language models (and multimodal models) of all sizes.

 

GIF of two humanoid robots walking, one on grass and the other on a paved surface.
Humanoid Robot Price Break
Chinese robot makers Unitree and EngineAI showed off relatively low-priced humanoid robots that could bring advanced robotics closer to everyday applications.

What’s new: At the annual Consumer Electronics Show (CES) in Las Vegas, Unitree showed its G1 ($16,000 with three-finger hands, $21,000 with five-finger, articulated hands), which climbed stairs and navigated around obstacles. Elsewhere on the show floor, EngineAI’s PM01 ($13,700 through March 2025 including articulated hands) and SE01 (price not yet disclosed) marched among attendees with notably naturalistic gaits.

How it works: Relatively small and lightweight, these units are designed for household and small-business uses. They’re designed for general-purpose tasks and to maintain stability and balance while walking on varied terrain.

Unitree: A downsized version of Unitree’s 6-foot H1, which debuted in 2023, the G1 stands at 4 feet, 3 inches and weighs 77 pounds. It walks at speeds up to 4.4 miles per hour and carries up to 5 pounds, and demo videos show it performing tasks that require manual dexterity such as cracking eggs. It was trained via reinforcement learning to avoid obstacles, climb stairs, and jump. A rechargeable, swappable battery ($750) lasts two hours. Unitree offers four models that are programmable (in Python, C++, or ROS) and outfitted with Nvidia Jetson Orin AI accelerators ($40,000 to $68,000). All models can be directed with a radio controller.
EngineAI: The PM01 is slightly larger and heavier than the G1 at 4 feet, 5 inches and 88 pounds. The SE01 is 5 feet, 7 inches and 121 pounds. Both units travel at 4.4 miles per hour and include an Nvidia Jetson Orin AI accelerator. They were trained via reinforcement learning to navigate dynamic environments and adjust to specific requirements. Pretrained AI models enhance their ability to recognize gestures and interact through voice commands. They include built-in obstacle avoidance and path-planning capabilities to operate in cluttered or unpredictable spaces. The robot can be controlled using voice commands or a touchscreen embedded in its chest. Rechargeable, swappable batteries provide two hours of performance per charge.
Behind the news: In contrast to the more-affordable humanoid robots coming out of China, U.S. companies like Boston Dynamics, Figure AI, and Tesla tend to cater to industrial customers. Tesla plans to produce several thousand of its Optimus ($20,000 to $30,000) humanoids in 2025, ramping to as many as 100,000 in 2026. Figure AI has demonstrated its Figure 02 ($59,000) in BMW manufacturing plants, showing a 400 percent speed improvement in some tasks. At CES, Nvidia unveiled its GR00T Blueprint, which includes vision-language models and synthetic data for training humanoid robots, and said its Jetson Thor computer for humanoids would be available early 2025. 
Why it matters: China’s push into humanoid robotics reflects its broader national ambitions. Its strength in hardware has allowed it to establish a dominant position in drones, and humanoid robots represent a new front for competition. China’s government aims to achieve mass production of humanoid robots by 2025 and establish global leadership by 2027, partly to address projected labor shortages of 30 million workers in manufacturing alone. Lower price points for robots that can perform arbitrary tasks independently could be valuable in elder care and logistics, offering tools for repetitive or physically demanding tasks. .

We’re thinking: Although humanoid robots generate a lot of excitement, they’re still in an early stage of development, and businesses are still working to identify and prove concrete use cases. For many industrial applications, wheeled robots — which are less expensive, more stable, and better able to carry heavy loads — will remain a sensible choice. But the prospect of machines that look like us and fit easily into environments built for us is compelling. 

 

A group of researchers working in a modern but not overly futuristic library, collaborating on their computers.
Learn More About AI With Data Points!
AI is moving faster than ever. Data Points helps you make sense of it just as fast. Data Points arrives in your inbox twice a week with six brief news stories. This week, we covered Berkeley students developing a high-performing AI model for under $450. Subscribe today!

 

A bull in a grassy field with a neural network diagram integrated into its horns.
Texas Moves to Regulate AI
Lawmakers in the U.S. state of Texas are considering stringent AI regulation.

What’s new: The Texas legislature is considering the proposed Texas Responsible AI Governance Act (TRAIGA). The bill would prohibit a short list of harmful or invasive uses of AI, such as output intended to manipulate users. It would impose strict oversight on AI systems that contribute to decisions in key areas like health care.

How it works: Republican House Representative Giovanni Capriglione introduced TRAIGA, also known as HB 1709, to the state legislature at the end of 2024. If it’s passed and signed, the law would go into effect in September 2025.

The proposed law would apply to any company that develops, distributes, or deploys an AI system while doing business in Texas, regardless of where the company is headquartered. It makes no distinction between large and small models or research and commercial uses. However, it includes a modest carve-out for independent small businesses that are based in the state.
The law controls “high-risk” AI systems that bear on consequential decisions in areas that include education, employment, financial services, transportation, housing, health care, and voting. The following uses of AI would be banned: manipulating, deceiving, or coercing users; inferring race or gender from biometric data; computing a “social score or similar categorical estimation or valuation of a person or group;” and generating sexually explicit deepfakes. The law is especially broad with respect to deepfakes: It outlaws any system that is “capable of producing unlawful visual material.” 
Companies would have to notify users whenever AI is used. They would also have to safeguard against algorithmic discrimination, maintain and share detailed records of training data and accuracy metrics, assess impacts, and withdraw any system that violates the law until it can achieve compliance.
The Texas attorney general would investigate companies that build or use AI, file civil lawsuits, and impose penalties up to $200,000 per violation, with additional fines for ongoing noncompliance of $40,000 per day.
The bill would establish a Texas AI Council that reports to the governor, whose members would be appointed by the governor, lieutenant governor, and state legislative leaders. The council would monitor AI companies, develop non-binding ethical guidelines for them, and recommend new laws and regulations.
Sandbox: A “sandbox” provision would allow registered AI developers to test and refine AI systems temporarily with fewer restrictions. Developers who registered AI projects with the Texas AI Council would gain temporary immunity, even if their systems did not fully comply with the law. However, this exemption would come with conditions: Developers must submit detailed reports on their projects’ purposes, risks, and mitigation plans. The sandbox status would be in effect for 36 months (with possible extensions), and organizations would have to bring their systems into compliance or decommission them once the period ends. The Texas AI Council could revoke sandbox protections if it determined that a project posed a risk of public harm or failed to meet reporting obligations.
Behind the news: Other U.S. states, too, are considering or have already passed laws that regulate AI:

California SB 1047, aimed to regulate both open and closed models above a specific size. The state’s governor vetoed the proposed bill due to concerns about regulatory gaps and overreach.
Colorado signed its AI Act into law in 2024. Like the Texas proposal, it mandates civil penalties for algorithmic discrimination in “consequential use of AI.” However, it doesn’t create a government body to regulate AI or outlaw specific uses.
New York state is considering a bill similar to California SB 1047 but narrower in scope. New York’s proposed bill would focus on catastrophic harms potentially caused by AI models that require more than 1026 FLOPs or cost $100 million or more to train). It would mandate third-party audits and protection for whistleblowers.
Why it matters: AI is not specifically regulated at the national level in the United States. This leaves individual states free to formulate their own laws. However, state-by-state regulation risks a patchwork of laws in which a system — or a particular feature — may be legal in some states but not others. Moreover, given the distributed nature of AI development and deployment, a law that governs AI in an individual state could affect developers and users worldwide. 
We’re thinking: The proposed bill has its positive aspects, particularly insofar as it seeks to restrict harmful applications rather than the underlying technology. However, it imposes burdensome requirements for compliance, suffers from overly broad language, fails to adequately protect open source, and doesn’t distinguish between research and commercial use. Beyond that, state-by-state regulation of AI is not workable. On the contrary, AI demands international conventions and standards.

 

Workflow for inverse design using deep learning to predict S-parameters and radiation in structures.
Generated Chip Designs Work in Mysterious Ways
Designing integrated circuits typically requires years of human expertise. Recent work set AI to the task with surprising results.

What’s new: Emir Ali Karahan, Zheng Liu, Aggraj Gupta, and colleagues at Princeton and Indian Institute of Technology Madras used deep learning and an evolutionary algorithm, which generates variations and tests their fitness, to generate designs for antennas, filters, power splitters, resonators, and other chips with applications in wireless communications and other applications. They fabricated a handful of the generated designs and found they worked — but in mysterious ways. 

How it works: The authors trained convolutional neural networks (CNNs), given a binary image of a circuit design (in which each pixel represents whether the corresponding portion of a semiconductor surface is raised or lowered), to predict its electromagnetic scattering properties and radiative properties. Based on this simulation, they generated new binary circuit images using evolution. 

The authors produced a training set of images and associated properties using Matlab EM Toolbox. The images depicted designs for chip sizes between 200x200 micrometers (which they represented as 10x10 pixels) and 500x500 micrometers (represented as 25x25 pixels). 
They trained a separate CNN on designs of each size.
They generated 4,000 designs at random and predicted their properties using the appropriate CNN.
Given the properties, the authors used a tournament method to select the designs whose properties were closest to the desired values. They randomly modified the selected designs to produce a new pool of 4,000 designs, predicted their properties, and repeated the tournament. The number of iterations isn’t specified.
Results: The authors fabricated some of the designs to test their real-world properties. The chips showed similar performance than the CNNs had predicted. The authors found the designs themselves baffling; they “delivered stunning high-performances devices that ran counter to the usual rules of thumb and human intuition,” co-author Uday Khankhoje told the tech news site Tech Xplore. Moreover, the design process was faster than previous approaches. The authors’ method designed a 300x300 micrometer chip in approximately 6 minutes. Using traditional methods it would have taken 21 days.

Behind the news: Rather than wireless chips, Google has used AI to accelerate design of the Tensor Processing Units that process neural networks in its data centers. AlphaChip used reinforcement learning to learn how to position chip components such as SRAM and logic gates on silicon.

Why it matters: Designing circuits usually requires rules of thumb, templates, and hundreds of hours of simulations and experiments to determine the best design. AI can cut the required expertise and time and possibly find effective designs that wouldn’t occur to human designers.

We’re thinking: AI-generated circuit designs could help circuit designers to break out of set ways of thinking and discover new design principles.