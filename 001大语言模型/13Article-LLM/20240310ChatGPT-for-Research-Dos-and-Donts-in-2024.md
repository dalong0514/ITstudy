## 20240310ChatGPT-for-Research-Dos-and-Donts-in-2024

[ChatGPT for Research: Do's and Don'ts in 2024](https://litmaps.substack.com/p/chatgpt-for-research-in-2024-dos)

ChatGPT, and AI tools in general, have evolved dramatically over the last year, as have their uses for scientific work. Here's what researchers should know about using these tools in 2024.

MARINA KISLEY

2024 年 3 月 8 日

Just a year ago, we wrote our first Do's and Don'ts for ChatGPT. Since then, a lot has changed. Many researchers have experiment with ChatGPT, and 30% of scientists have already used generative AI to write papers, according to a 2023 Nature survey. These tools are already transforming how science gets done, but what we've seen so far may be just the tip of the iceberg.

We recently interviewed Ilya Shabanov, creator of The Effortless Academic, to examine how AI tools like ChatGPT have evolved over the last year, and what role these tools do and should play in academia. Shabanov has been investigating academic tools over the last year, building a community of like-minded researchers through Twitter. He started by sharing his expertise in productive note-taking techniques and tool usage, but has since evolved to consider the wide range of technologies available to academics. Today, his platform, The Effortless Academic, gives considerable attention to using AI in research.

Here, we dive into what researchers need to know about using AI tools and ChatGPT in research today.

[ChatGPT for Research, The Do’s and Don’ts - by Digl](https://litmaps.substack.com/p/chatgpt-for-research-the-dos-and)

[AI and science: what 1,600 researchers think](https://www.nature.com/articles/d41586-023-02980-0)

[Ilya Shabanov (@Artifexx) / X](https://twitter.com/Artifexx)

[Home - The Effortless Academic](https://effortlessacademic.com/)

仅仅一年前，我们发布了第一篇关于如何正确使用 ChatGPT 的建议指南。从那时起，情况发生了巨大变化。众多研究者开始探索 ChatGPT 的潜力，根据《自然》杂志 2023 年的调查，已有 30% 的科学家利用生成式人工智能（Generative AI）来撰写论文。这些工具正在逐步改变科学研究的方式，但目前所观察到的或许只是更广泛应用潜力的一小部分。

我们最近对 The Effortless Academic 的创始人 Ilya Shabanov 进行了采访，他是一位深入研究过去一年间 AI 工具，特别是 ChatGPT 在学术界演变及其应有角色的学者。Shabanov 一年来一直在探索学术工具，并通过 Twitter 聚集了一群有共同研究兴趣的人。他最初分享的是关于高效笔记技巧和工具的使用经验，但随后他的研究领域扩展到了学术界可用的各种技术。现在，他的平台 The Effortless Academic 重点介绍如何在研究中应用 AI 技术。

接下来，我们将深入探讨研究人员在当下的研究工作中如何以及为什么需要使用 AI 工具和 ChatGPT。

### 01. A new way to view AI tools

Since its inception at the end of 2022, ChatGPT has taken the world by storm, and scientific research along with it. The original problems that surfaced have mostly settled, only to be replaced by a new wave of concerns. The regulations across publishers and its banned use in peer review reflect this caution. However, many researchers are also optimistic. The majority of academics agree that generative AI will help researchers with repetitive tasks and reduce language barriers, which can radically improve research collaborations and opportunities worldwide.

If the scientific community's reaction is mixed between extreme caution and hopeful, futuristic thinking, then Ilya Shabanov is somewhere in the middle: optimistic about the novel applications of AI in research, and distinctly aware of the key drawbacks and issues. He explores the world of AI-powered research, where new applications surface almost daily. According to him, there is no shortage of tools to explore, but only a fraction appear to provide genuine value: "Most tools are not very useful, but they're easy to build, and since with AI you can build tools in a few days, we've seen many come and go. There's a cambric explosion of tools (so to speak) but only a few tool families will evolve to see the light of day."

The majority of tools and uses of generative AI (i.e. ChatGPT) focus on improving writing and reading. But Shabanov feels this is just the tip of the iceberg, and the most impactful uses of generative AI are still being overlooked.

自 2022 年末 ChatGPT 面世以来，它迅速成为全球焦点，并且显著影响了科学研究领域。最初遇到的问题大部分已经得到解决，但随之而来的是一系列新的担忧。出版界的规范以及禁止在同行评审中使用它，反映了这种谨慎的态度。然而，许多研究者对此持乐观看法。大部分学术界人士认同，生成式人工智能（Generative AI）将协助研究人员完成重复性工作，并降低语言障碍，这将从根本上促进全球范围内的研究合作和机遇。

如果说科学界对此持有从极端谨慎到满怀希望的未来主义思考的混合态度，那么 Ilya Shabanov 的立场则介于两者之间：他对 AI 在研究中的新兴应用持乐观态度，同时也清醒地看到了关键的挑战和问题。他深入探讨了由 AI 驱动的研究世界，这是一个几乎每天都有新应用涌现的领域。他指出，尽管可探索的工具众多，但真正具有价值的只是一小部分：「大多数工具实际上并不那么有用，但它们很容易开发。得益于 AI 技术，你可以在几天之内创建出新工具，因此我们看到了许多工具的快速出现与消失。这是一场类似寒武纪生物大爆发的工具革命，但只有少数工具家族能够发展并最终大放光彩。」

大部分工具和生成式 AI 的应用（例如 ChatGPT）主要致力于改进写作和阅读体验。然而，Shabanov 认为，这只是探索的起点，许多生成式 AI 的最具影响力的应用还未被充分发掘。

### 02. The best use cases for researchers

Improving writing and evaluating written work are two of the most common uses of AI tools today, and are often central to the most heated debates, like if AI should be banned in peer review or how AI can reduce the trustworthiness and quality of scientific work.

Although improving writing and reading are no doubt useful, Shabanov feels these applications are limited in scope. The majority of the scientific community appears to be unaware of the fundamentally transformational applications available, which we dive into below.

今天，AI 工具最常见的两项用途是提高写作质量和评估书面作品，这经常成为激烈讨论的焦点，比如是否应该在同行评审中禁止使用 AI，或 AI 如何可能降低科学工作的信任度和品质。

尽管提升写作和阅读能力无疑是有益的，Shabanov 认为这些应用的范围相对有限。科学界的大多数人似乎还未意识到那些能够根本性转变研究方式的应用，我们接下来将深入探讨。

### 03. Learn a new topic, as an expert

One of the most exciting uses of generative AI is the ability to quickly jump into a new field. This is equally salient for novice student researchers entering a field for the first time as it is for mature researchers learning a new domain. For Shabanov, the ability to jump into a new topic quickly and solve cross-domain questions is remarkable.

How to do this in practice varies based on use case. The most basic methods involve researchers interacting directly with ChatGPT and asking it questions. On the other end of the spectrum is custom GPTs, where users can train a personalized bot to answer any question on a topic, given a specific set of data. These AI bots can be given specific texts, books, papers, etc. to help them solve specific tasks better. For example, a bot can be trained to recommend the best statistical tests for your data. The key limiting factors when it comes to developing these assistants are the user's creativity and "prompt literacy".

"AI enables you to wedge into these cross-domain questions much faster… Before that, you'd have to read a couple books. No PhD student or let alone a professor has time for that." - Ilya Shabanov

GPTs are customizable AI assistants that users can program for specific tasks. Academics can use these to create personalized research assistants (image from here).

利用生成式人工智能（Generative AI）快速跨入新领域是其中最令人兴奋的应用之一。无论是初次进入某个领域的新手研究生，还是正在学习新领域的资深研究者，这一点都同样重要。对 Shabanov 而言，快速深入一个新主题并解决跨领域问题的能力极为出色。

具体实践方式会根据具体案例有所不同。最基础的做法包括研究者直接与 ChatGPT 互动，向它提问。另一种方式是定制 GPT，用户可以根据特定数据集训练一个个性化机器人，针对某一主题回答任何问题。这些 AI 机器人可以通过特定的文本、书籍、论文等资料来提高解决特定任务的能力。比如，可以训练一个机器人为你的数据推荐最佳的统计测试方法。开发这些辅助工具的关键限制因素在于用户的创造力和如何高效利用 AI 的「提示技能」。

Ilya Shabanov 表示：「AI 使得我们能够更快地深入探讨跨领域的问题…… 在此之前，你可能需要阅读几本书。没有任何博士生或教授有时间去做这件事。」

GPT 是可以定制的 AI 助理，用户可以针对特定的任务进行编程。学术工作者可以利用它们来打造个性化的研究助理（图片来自此处）。

### 04. Fill knowledge gaps and find supporting evidence

AI tools are highly effective at helping researchers find resources and examples. This is particularly useful when trying to find supporting evidence or alternative approaches to a given method. For example, Shabanov recommends the prompt "find evidence for/against" for any document or text in order to critically analyze it from multiple perspectives (using Consensus). Note, this isn't equally effective across all AI tools/bots. For example, Consensus, SciSpace and ScholarAI are expressly trained on millions of scientific papers, whereas the default ChatGPT is not.

By leveraging AI's ability to study large corpuses of information and learn facts, researchers can close gaps in knowledge more easily than manually searching. Shabanov cites an example in his field of ecology, to determine what models exist for predicting population growth. Although dozens of possible algorithms may exist, identifying all of these in the literature manually is an arduous process. Plus, a more novice researcher may not even know what to search for. Instead, he queries ChatGPT (see image below).

Here, ChatGPT provides the top algorithms, and serves as a starting point from which to dive deeper into each recommendation.

AI can be used to fill in knowledge gaps, as in this example of finding relevant models.(image from here).

Prompt:

Give me a list of models common in ecology to predict population growth. (Bullet points and very short explanations only)

利用 AI 填补知识缺口和寻找支撑证据

AI 工具在协助研究人员寻找资源和案例方面极其有效。特别是当需要找到支持某种方法的证据或探索替代方案时，这一点显得尤为重要。比如，Shabanov 推荐使用「寻找支持/反对... 的证据」这样的命令来从多个角度批判性分析任何文档或文本（使用 Consensus）。需要注意的是，并不是所有 AI 工具/机器人都能同样有效地执行这一任务。例如，Consensus、SciSpace 和 ScholarAI 都是专门针对数百万篇科学论文进行训练的，而标准的 ChatGPT 则没有。

利用 AI 研究大量信息库和学习事实的能力，研究者可以比手动检索更容易地弥补知识的不足。Shabanov 在他的生态学研究领域给出了一个例子，他想确定预测人口增长的模型有哪些。尽管可能有数十种算法存在，但手动从文献中识别这些算法是一项艰巨的任务。而且，初学者研究人员可能连搜索的方向都不清楚。相反，他选择询问 ChatGPT（如下图所示）。

在这里，ChatGPT 提供了一系列顶级算法，并作为深入探究每个推荐算法的起点。

AI 被用来填补知识空白，正如这个例子中寻找相关模型所展示的那样。（图片来源于此）。

### 05. Writing

The majority of AI-assisted tools today focus primarily on helping researchers write better and faster. Scientific writing has clear, specific rules. AI can easily identify how text is written and adapt it to this style. Shabanov shares his techniques for using AI to help improve how one writes. For example, he may input a text and ask AI, based on certain rules of writing, where he could improve. In fact, AI could be treated like an initial peer reviewer, asked to review articles before they are even submitted.

However, it's worth noting that the time-saving capabilities of these tools are often offset by paying additional penalties regarding the quality and reliability of the results. As Shabanov shares, "Since the technology isn't highly reliable, I pay for that time through accuracy, which, in science, is often unacceptable."

当前，许多 AI 辅助的写作工具着重于协助研究人员提高写作效率和质量。科学写作遵循一套明确而具体的规则，而 AI 能够轻松识别并调整其写作风格以符合这些规则。Shabanov 介绍了他如何利用 AI 改善写作技巧的方法。举例来说，他可能会提交一段文本，并请求 AI 基于特定的写作规则提出改进意见。事实上，AI 可以被看作是一名初步审稿人，在文章提交前进行评审。

不过，需要指出的是，尽管这些工具能够节省时间，但它们在结果的质量和可靠性方面可能要求用户付出更多。正如 Shabanov 所言：「由于这项技术并不高度可靠，我是通过牺牲准确性来节省时间的，在科学研究中，这通常是难以接受的。」

### 06. What to watch out for in ChatGPT, in 2024

Many researchers were initially skeptical about ChatGPT's responses because of its hallucinations. Although the issue persists, it has improved significantly with ChatGPT-4, which has a significantly lower rate of hallucinations compared to 3.5 or Bard (according to some studies). This is particularly true when models are expressly trained on specific corpuses of knowledge. The community also appears to discuss this problem less often. As Shabanov shares, "In 2024, barely anyone talks about it [hallucinations], and there are ways around it. You have connections to the Internet, to scientific databases. The biggest thing is not hallucinations, the biggest thing is that it's incomplete. That it misses certain things."

Shabanov stresses that AI tools can serve as an effective starting point to dive into a new topic, but that the information cannot be assumed to be fully complete.

Most users today are already aware of the other key issues in AI models, like how they exhibit and exacerbate various biases. A 2023 study identified political biases in ChatGPT, and just a couple weeks ago Google's Gemini AI came under fire for some generated images. This issue is particularly hard to solve, as we attempt to create perfect models using data from an imperfect world.

Poor results are one problem, but when these inaccuracies start to permeate the academic system, they become an even bigger issue. The community was in uproar after the image below was circulated: an inaccurate AI-generated image which wasn't caught in peer-review and ended up in a published article. Researchers who specialize in assessing the reliability of scientific papers, like Elizabeth Bik, are especially cautious of these new technologies, fearing that "Generative AI will do serious harm to the quality, trustworthiness, and value of scientific papers."

This AI-generated image, published (now retracted) in a Frontiers paper, was widely ridiculed by the scientific community. It demonstrates the need to educate researchers in when and when not to use AI in science.

It's essential to note that the limitations and disadvantages of AI tools vary greatly. Students, in particular, should be aware of AI tool limitations, since they are more likely to use free or limited versions, compared to their supervisors and colleagues who have access to better resources. For example, ChatGPT4 provides significantly better results than 3.5, but with its $20/month price-tag, many students can't afford it.

Ideally, advisors and senior researchers take responsibility to ensure their students are educated in how to appropriately use these tools. But, they may also not know the answers themselves. This is where the variety of webinars and workshops available on these topics should be given consideration, as they provide a reliable way to stay up-to-date on the ever-evolving landscape of AI tools.

许多研究者最初对 ChatGPT 的回答持怀疑态度，原因是其生成的虚假信息。虽然这个问题仍然存在，但在 ChatGPT-4 的版本中得到了显著的改善，与 3.5 版或 Google 的 Bard 相比，生成错误的频率有了大幅下降（根据一些研究报告）。特别是当模型针对特定知识库进行训练时，这一点尤其明显。社区对这个问题的讨论频率似乎也有所下降。正如 Shabanov 所说，「到 2024 年，几乎没有人讨论生成错误的问题了，而且我们找到了解决方法。你可以连接到互联网、科学数据库。真正的问题不是生成错误，而是信息的不完整性。它遗漏了一些东西。」

Shabanov 强调，AI 工具可以作为深入了解新话题的一个有效起点，但我们不能假设所获取的信息是完全全面的。

现在，大多数用户已经意识到 AI 模型中存在的其他关键问题，例如它们展示和放大的偏见问题。2023 年的一项研究揭示了 ChatGPT 中的政治偏见，而就在几周前，Google 的 Gemini AI 因生成的某些图像而受到批评。这个问题特别难以解决，因为我们试图使用一个不完美的世界中的数据来创建完美的模型。

不精确的结果本身就是一个问题，但当这些错误开始影响学术系统时，问题变得更加严重。一张 AI 生成的、不准确的图像未能在同行评审中被识别出来，并被发表在一篇学术文章中，这引起了学术界的广泛关注。像 Elizabeth Bik 这样专门评估科学论文可靠性的研究者对这些新技术持谨慎态度，担心「生成式 AI 将严重损害科学论文的质量、信任度和价值。」

这张在 Frontiers 杂志上发表（现已撤回）的 AI 生成图像，遭到了科学界的广泛嘲笑。这说明有必要教育研究人员在何时应该以及不应该在科研中使用 AI。

需要注意的是，AI 工具的局限性和缺点差异很大。特别是学生，应该明白 AI 工具的局限性，因为相比于有更好资源的导师和同事，他们更可能使用免费或限制版。例如，ChatGPT4 相比 3.5 版提供了更好的结果，但是其每月 20 美元的价格对许多学生来说可能是一个负担。

理想情况下，导师和资深研究者应当确保他们的学生知道如何恰当地使用这些工具。但是，他们自己可能也不完全清楚如何做。这时，应当考虑参加关于这些主题的各种网络研讨会和工作坊，这是保持对 AI 工具不断演进的领域保持最新认知的可靠方式。

---

Although regulations about AI's use in peer review and publication have been formed, the dust is still far from settling when it comes to the impact of AI in research. The scientific community is abuzz, with both avid supporters and cautious skeptics contributing to discussions. Some researchers, like Ilya Shabanov, are trying to shift the community's perspective from one focused exclusively on the biases and inaccuracies of AI towards a more optimistic and inclusive view of how AI can support and accelerate research.

Shabanov believes these tools can radically transform how science gets done. He encourages researchers to start experimenting, explore the best use cases, and be creative. Although it's tempting to ask ChatGPT to simply summarize a paper, there are far bigger fish to fry.

"Use it to leverage the knowledge it has and close the knowledge gaps that you have, finding these jigsaw puzzles pieces that fit into one another." - Ilya Shabanov

Do you use AI in your research? Are you worried about the future of scientific research? Or excited? Share your thoughts with us below.

The Scoop would like to warmly thank Ilya Shabanov for his unique perspectives and valuable contributions to this edition of The Scoop. Learn more about his work on this topic at The Effortless Academic.

Subscribe to stay up-to-date on the latest academic news and research trends.

虽然关于 AI 在同行评审和学术出版中应用的规则已经确立，但 AI 对研究影响的全貌仍旧模糊不清。科学界对此议论纷纷，既有对 AI 充满热情的支持者，也不乏持谨慎态度的怀疑者。像 Ilya Shabanov 这样的研究者，正尝试将社区的焦点从单纯关注 AI 的偏差和不准确性，转向更为乐观和包容的方向 —— 探讨 AI 如何助力并加速科学研究的进程。

Shabanov 认为，这些工具能够从根本上改变科研的方式。他鼓励研究人员开始进行实验，探索最适合的应用场景，并激发创新思维。虽然让 ChatGPT 来简化论文总结看似一个不错的选择，但我们有更重要的任务需要完成。

「利用 AI 拥有的知识来填补你的知识空白，寻找那些能够相互契合的知识碎片。」—— Ilya Shabanov

你在科研工作中使用 AI 技术了吗？对科学研究的未来，你是感到忧虑还是兴奋？欢迎在下方留言分享你的看法。

《The Scoop》在此特别感谢 Ilya Shabanov，因他提供了独到的见解和对本期内容的贡献。想了解他在这一议题上的更多工作，敬请访问 The Effortless Academic。

订阅我们，随时获取学术界最新的新闻和研究动态。

### Resources

[Is ChatGPT making scientists hyper-productive? The highs and lows of using AI](https://www.nature.com/articles/d41586-024-00592-w)

[A ridiculous AI-generated rat penis made it into a peer-reviewed journal | Popular Science](https://www.popsci.com/technology/ai-rat-journal/)

[AI hallucinations: The 3% problem no one can fix slows the AI juggernaut - SiliconANGLE](https://siliconangle.com/2024/02/07/ai-hallucinations-3-problem-no-one-can-fix-slows-ai-juggernaut/#:~:text=%E2%80%9CThe%20rate%20of%20hallucinations%20will,can%20give%20out%20false%20information.%E2%80%9D)

[AI and science: what 1,600 researchers think](https://www.nature.com/articles/d41586-023-02980-0)

