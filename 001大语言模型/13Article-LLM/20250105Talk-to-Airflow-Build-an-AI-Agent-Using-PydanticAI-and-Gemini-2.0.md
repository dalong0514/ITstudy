## 20250105Talk-to-Airflow-Build-an-AI-Agent-Using-PydanticAI-and-Gemini-2.0

[Talk to Airflow â€” Build an AI Agent Using PydanticAI and Gemini 2.0 | by Volker Janz | Dec, 2024 | Data Engineer Things](https://blog.det.life/talk-to-airflow-build-an-ai-agent-using-pydanticai-and-gemini-2-0-fd645cf99fcb)

Create an AI agent with PydanticAI to interact with Airflow DAGs

Volker Janz

Published in Data Engineer Things

Dec 24, 2024

### A Journey from Chaos to Control

ä»æ··æ²Œåˆ°æŒæ§çš„æ—…ç¨‹

In the pioneering days of aviation, pilots flew through clouds with little more than basic instruments and raw instinct. Each flight was a dance between human judgment and mechanical power, relying heavily on experience and intuition for success. A slight miscalculation or unexpected weather change could spell disaster. They used amazing technology with little control over it.

åœ¨èˆªç©ºä¸šçš„æ—©æœŸï¼Œé£è¡Œå‘˜ä»¬ç©¿æ¢­äºäº‘å±‚ä¹‹é—´ï¼Œä»–ä»¬æ‰€ä¾èµ–çš„ä»…ä»…æ˜¯ç®€é™‹çš„ä»ªè¡¨å’Œä¸ç”Ÿä¿±æ¥çš„æœ¬èƒ½ã€‚æ¯ä¸€æ¬¡é£è¡Œï¼Œéƒ½æ˜¯äººç±»çš„åˆ¤æ–­åŠ›ä¸æœºæ¢°åŠ¨åŠ›ä¹‹é—´çš„ä¸€åœºåšå¼ˆï¼ŒæˆåŠŸä¸å¦å¾ˆå¤§ç¨‹åº¦ä¸Šå–å†³äºç»éªŒå’Œç›´è§‰ã€‚å“ªæ€•æ˜¯ç»†å¾®çš„è®¡ç®—å¤±è¯¯æˆ–æ˜¯çªå¦‚å…¶æ¥çš„å¤©æ°”å˜åŒ–ï¼Œéƒ½å¯èƒ½å¯¼è‡´ç¾éš¾æ€§çš„åæœã€‚é‚£æ—¶å€™ï¼Œé£è¡Œå‘˜ä»¬è™½ç„¶æ‹¥æœ‰ä»¤äººæƒŠå¹çš„æŠ€æœ¯ï¼Œä½†å¯¹å®ƒä»¬çš„æŒæ§èƒ½åŠ›å´ååˆ†æœ‰é™ã€‚

When I first started integrating LLMs into production systems, I felt like one of those early pilots â€” commanding immense power with minimal instrumentation. Every deployment felt like a leap of faith.

å½“æˆ‘åˆæ¬¡å°è¯•å°†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLM/Large Language Modelï¼‰åº”ç”¨äºå®é™…ç”Ÿäº§ç³»ç»Ÿæ—¶ï¼Œæ„Ÿè§‰è‡ªå·±å°±åƒæ—©æœŸçš„é£è¡Œå‘˜ä¸€æ ·ï¼Œè™½ç„¶æŒæ¡ç€å¼ºå¤§çš„èƒ½åŠ›ï¼Œä½†å¯ç”¨çš„ç›‘æ§æ‰‹æ®µå´éå¸¸æœ‰é™ã€‚æ¯ä¸€æ¬¡éƒ¨ç½²éƒ½åƒæ˜¯ä¸€æ¬¡å¤§èƒ†çš„å°è¯•ã€‚

The landscape of AI development today mirrors those early aviation challenges. We have incredibly powerful models like Gemini 2.0 at our disposal â€” capable of understanding context, generating human-like responses, and processing complex instructions. Yet, utilizing this power for production-grade applications often feels like flying through a storm without proper navigation tools.

å¦‚ä»Šçš„ AI å¼€å‘ï¼Œå…¶å±€é¢ä¸æ—©æœŸèˆªç©ºé¢ä¸´çš„æŒ‘æˆ˜é¢‡ä¸ºç›¸ä¼¼ã€‚æˆ‘ä»¬æ‹¥æœ‰åƒ Gemini 2.0 è¿™æ ·å¼ºå¤§çš„æ¨¡å‹ â€”â€” å®ƒä»¬èƒ½å¤Ÿç†è§£ä¸Šä¸‹æ–‡ï¼Œç”Ÿæˆç±»ä¼¼äººç±»çš„å›å¤ï¼Œå¹¶å¤„ç†å¤æ‚çš„æŒ‡ä»¤ã€‚ç„¶è€Œï¼Œå°†è¿™äº›èƒ½åŠ›åº”ç”¨åˆ°ç”Ÿäº§çº§åº”ç”¨ä¸­ï¼Œå¸¸å¸¸è®©äººæ„Ÿè§‰åƒæ˜¯åœ¨æ²¡æœ‰å¯¼èˆªå·¥å…·çš„æƒ…å†µä¸‹ï¼Œäºæš´é£é›¨ä¸­é£è¡Œã€‚

But just as modern aviation evolved from risky adventures to reliable transportation through proper instrumentation and control systems, AI development is undergoing its own transformation toward agents. Unlike traditional AI, which simply responds to queries, agents actively engage with their environment. They make decisions, use tools, and execute tasks on your behalf. Modern AI agents, powered by LLMs like Gemini, understand natural language instructions, break down complex tasks into smaller steps, and provide structured output and monitoring.

ä½†æ˜¯ï¼Œæ­£å¦‚ç°ä»£èˆªç©ºé€šè¿‡å®Œå–„çš„ä»ªè¡¨å’Œæ§åˆ¶ç³»ç»Ÿï¼Œä»é«˜é£é™©çš„æ¢ç´¢å‘å±•ä¸ºå¯é çš„äº¤é€šè¿è¾“ä¸€æ ·ï¼Œäººå·¥æ™ºèƒ½ï¼ˆAIï¼‰çš„å¼€å‘ä¹Ÿæ­£æœç€ AI æ™ºèƒ½ä½“çš„æ–¹å‘æ¼”è¿›ã€‚ä¸ä¼ ç»Ÿ AI ä»…ä»…å“åº”æŸ¥è¯¢ä¸åŒï¼ŒAI æ™ºèƒ½ä½“ä¼šç§¯æåœ°ä¸å…¶ç¯å¢ƒäº’åŠ¨ã€‚å®ƒä»¬ä¼šåšå‡ºå†³ç­–ï¼Œä½¿ç”¨å·¥å…·ï¼Œå¹¶ä»£è¡¨æ‚¨æ‰§è¡Œä»»åŠ¡ã€‚ç°ä»£ AI æ™ºèƒ½ä½“ï¼Œç”±è¯¸å¦‚ Gemini ç­‰å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨ï¼Œèƒ½å¤Ÿç†è§£è‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼Œå°†å¤æ‚çš„ä»»åŠ¡åˆ†è§£ä¸ºæ›´å°çš„æ­¥éª¤ï¼Œå¹¶ç»™å‡ºç»“æ„åŒ–çš„ç»“æœå¹¶è¿›è¡Œç›‘æ§ã€‚

This is where PydanticAI appears at the sky. Built by the team behind Pydantic â€” the same foundation that powers numerous famous projects â€” it's a framework designed for modern AI development that brings control and reliability to agent systems.

PydanticAI æ­£æ˜¯æ¨ªç©ºå‡ºä¸–äºæ­¤æ—¶ã€‚å®ƒç”± Pydantic èƒŒåçš„å›¢é˜Ÿæ‰“é€ ï¼Œè€Œ Pydantic æ­£æ˜¯ä¼—å¤šçŸ¥åé¡¹ç›®çš„åŸºçŸ³ã€‚PydanticAI æ˜¯ä¸€æ¬¾ä¸“ä¸ºç°ä»£ AI å¼€å‘è®¾è®¡çš„æ¡†æ¶ï¼Œæ—¨åœ¨ä¸º AI æ™ºèƒ½ä½“ç³»ç»Ÿå¸¦æ¥æ›´å¼ºçš„æ§åˆ¶åŠ›å’Œå¯é æ€§ã€‚

Think of PydanticAI as your aircraft's modern cockpit â€” combining assistant systems, engine controls, and instrumentation panels into one coherent interface. It provides clear readings, predictable controls, and most importantly, the confidence to navigate through complex scenarios. It brings structure to chaos.

ä¸å¦¨æŠŠ PydanticAI çœ‹ä½œæ˜¯æ‚¨é£æœºçš„ç°ä»£åŒ–é©¾é©¶èˆ± â€”â€” å®ƒå°†è¾…åŠ©ç³»ç»Ÿã€å¼•æ“æ§åˆ¶å’Œä»ªè¡¨ç›˜æ•´åˆä¸ºä¸€ä¸ªç»Ÿä¸€çš„ç•Œé¢ã€‚å®ƒä¸ä»…æä¾›æ¸…æ™°çš„æ•°æ®è¯»å–å’Œå¯é¢„æµ‹çš„æ“ä½œæ§åˆ¶ï¼Œæ›´é‡è¦çš„æ˜¯ï¼Œå®ƒèƒ½è®©æ‚¨åœ¨å¤æ‚çš„æƒ…å½¢ä¸­å……æ»¡ä¿¡å¿ƒåœ°é©¾é©¶ã€‚PydanticAI ä¸ºæ··ä¹±èµ‹äºˆäº†ç§©åºã€‚

In this article, we'll put PydanticAI to the test by building an AI agent that interacts with Apache Airflow. We'll create a system that can understand natural language queries about your workflows, fetch real-time status updates, and respond with structured, reliable data. No more flying blind through your DAG operations.

[Apache Airflow](https://airflow.apache.org/)

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†é€šè¿‡æ„å»ºä¸€ä¸ªä¸ Apache Airflow äº¤äº’çš„ AI æ™ºèƒ½ä½“æ¥æ£€éªŒ PydanticAI çš„èƒ½åŠ›ã€‚æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªç³»ç»Ÿï¼Œå®ƒèƒ½å¤Ÿç†è§£å…³äºä½ çš„å·¥ä½œæµçš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼Œè·å–å®æ—¶çš„çŠ¶æ€æ›´æ–°ï¼Œå¹¶ä»¥ç»“æ„åŒ–çš„ã€å¯é çš„æ•°æ®è¿›è¡Œå“åº”ã€‚æœ‰äº†å®ƒï¼Œä½ å°†ä¸å†å¯¹ DAG çš„è¿è¡Œæƒ…å†µä¸€æ— æ‰€çŸ¥ã€‚

Want to jump straight into the code? Check out the project on GitHub:

[vojay-dev/pydantic-airflow-agent](https://github.com/vojay-dev/pydantic-airflow-agent)

### Why PydanticAI? The FastAPI Feeling for AI Development

ä¸ºä»€ä¹ˆé€‰æ‹© PydanticAIï¼Ÿ

Building production-grade AI applications shouldn't feel like solving a puzzle. Yet, when I first explored the landscape of AI frameworks, that's exactly what it felt like. Let me share why PydanticAI is becoming my go-to choice for modern AI development.

åƒ FastAPI ä¸€æ ·æµç•…çš„ AI å¼€å‘ä½“éªŒæ„å»ºå¯ç”¨äºç”Ÿäº§ç¯å¢ƒçš„ AI åº”ç”¨ç¨‹åºä¸åº”è¯¥åƒè§£è°œä¸€æ ·å›°éš¾ã€‚ç„¶è€Œï¼Œå½“æˆ‘æœ€åˆæ¥è§¦å„ç§ AI æ¡†æ¶æ—¶ï¼Œå®é™…ä½“éªŒå´å¹¶éå¦‚æ­¤ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘å°†åˆ†äº«ä¸ºä»€ä¹ˆ PydanticAI é€æ¸æˆä¸ºæˆ‘è¿›è¡Œç°ä»£ AI å¼€å‘çš„é¦–é€‰å·¥å…·ã€‚

The Current Landscape

å½“å‰å½¢åŠ¿

The AI framework ecosystem is rich with options:

AI æ¡†æ¶ç”Ÿæ€ç§ç±»ç¹å¤šï¼š

LangChain: Comprehensive but complex, offering numerous integrations and features.

LangChainï¼šåŠŸèƒ½å…¨é¢ä½†ç»“æ„å¤æ‚ï¼Œé›†æˆäº†å¤šç§å·¥å…·å’Œç‰¹æ€§ã€‚

crewAI: Specialized in multi-agent orchestration, great for complex agent interactions.

crewAIï¼šä¸“æ³¨äºå¤š AI æ™ºèƒ½ä½“ååŒï¼Œå°¤å…¶æ“…é•¿å¤„ç†å¤æ‚çš„ AI æ™ºèƒ½ä½“ä¹‹é—´çš„äº’åŠ¨ã€‚

Instructor: Focused on structured outputs and instruction following.

æ¨¡å‹ï¼šä¸“æ³¨äºç»“æ„åŒ–è¾“å‡ºå’ŒæŒ‡ä»¤éµå¾ªã€‚

Each has its strengths, but they often come with significant complexity and steep learning curves.

æ¯ç§æ¨¡å‹éƒ½æœ‰å…¶ä¼˜ç‚¹ï¼Œä½†å®ƒä»¬é€šå¸¸ä¹Ÿä¼´éšç€æ˜¾è‘—çš„å¤æ‚æ€§å’Œè¾ƒé«˜çš„å­¦ä¹ é—¨æ§›ã€‚

PydanticAI Simplicity

```py
from pydantic_ai import Agent

agent = Agent('gemini-1.5-flash', system_prompt='Be concise.')
result = agent.run_sync('Why choose PydanticAI?')
```

When I first saw the PydanticAI examples, it reminded me of my first FastAPI experience â€” clean, intuitive, and just right.

PydanticAIï¼šç®€å•æ˜“ç”¨æˆ‘ç¬¬ä¸€æ¬¡çœ‹åˆ° PydanticAI çš„ç¤ºä¾‹æ—¶ï¼Œå°±æƒ³èµ·äº†æˆ‘åˆæ¬¡æ¥è§¦ FastAPI çš„æ„Ÿè§‰ â€”â€” ä»£ç ç®€æ´ã€ä½¿ç”¨ç›´è§‚ï¼Œä¸€åˆ‡éƒ½æ°åˆ°å¥½å¤„ã€‚

What sets PydanticAI apart:

PydanticAI çš„ç‹¬ç‰¹ä¹‹å¤„ï¼š

Built by the Pydantic Team

å®ƒæ˜¯ç”± Pydantic å›¢é˜Ÿå¼€å‘çš„ã€‚

1 Deep integration with Pydantic's ecosystem

ä¸ Pydantic ç”Ÿæ€ç³»ç»Ÿçš„æ·±åº¦æ•´åˆ

2 Type safety that actually helps development

åˆ‡å®æå‡å¼€å‘æ•ˆç‡çš„ç±»å‹å®‰å…¨

3 Familiar patterns for FastAPI developers

FastAPI å¼€å‘äººå‘˜çš„å¸¸ç”¨æ¨¡å¼

Production-Ready Design

é¢å‘ç”Ÿäº§ç¯å¢ƒçš„è®¾è®¡

1 Model-agnostic (OpenAI, Anthropic, Gemini, Ollama)

ä¸ä¾èµ–ç‰¹å®šæ¨¡å‹ï¼ˆOpenAIï¼ŒAnthropicï¼ŒGeminiï¼ŒOllama)

2 Built-in dependency injection for testing

å†…ç½®ä¾èµ–æ³¨å…¥ï¼Œæ–¹ä¾¿è¿›è¡Œæµ‹è¯•

3 Seamless Logfire integration for real-time monitoring

æ— ç¼é›†æˆ Logfire å®ç°å®æ—¶ç›‘æ§

Clean, Maintainable Code

ä»£ç æ•´æ´ï¼Œæ˜“äºç»´æŠ¤

1 Minimal boilerplate

æç®€çš„é¢„è®¾ä»£ç 

2 Strong type checking

ä¸¥æ ¼çš„ç±»å‹æ£€æŸ¥

3 Intuitive error messages

Note: The integration with Logfire is simple yet elegant, allowing for a detailed understanding of the flow of agents. There are impressive examples on the official PydanticAI page, but I haven't tried them yet. I highly recommend checking it out if you want to explore the framework beyond this article. If you do, feel free to let me know how it goes.

æ³¨æ„ï¼šä¸ Logfire çš„é›†æˆæ—¢ç®€å•åˆä¼˜é›…ï¼Œèƒ½å¤Ÿå¸®åŠ©æˆ‘ä»¬è¯¦ç»†äº†è§£ AI æ™ºèƒ½ä½“ï¼ˆAI Agentï¼‰çš„è¿è¡Œæµç¨‹ã€‚PydanticAI çš„å®˜æ–¹é¡µé¢ä¸Šæœ‰ä¸€äº›éå¸¸æ£’çš„ç¤ºä¾‹ï¼Œä½†æˆ‘è¿˜æ²¡æœ‰äº²è‡ªå°è¯•ã€‚å¦‚æœä½ æƒ³æ·±å…¥äº†è§£æœ¬æ–‡ä¹‹å¤–çš„æ›´å¤šæ¡†æ¶å†…å®¹ï¼Œæˆ‘å¼ºçƒˆå»ºè®®ä½ å»çœ‹çœ‹ã€‚å¦‚æœä½ å°è¯•äº†ï¼Œæ¬¢è¿éšæ—¶å‘Šè¯‰æˆ‘ä½ çš„ä½“éªŒã€‚

The Future of PydanticAI

PydanticAI çš„æœªæ¥å±•æœ›

The real power of PydanticAI lies in its alignment with modern Python development practices. As Pydantic continues to be the backbone of major Python frameworks and AI libraries, PydanticAI's tight integration becomes increasingly valuable.

PydanticAI çš„çœŸæ­£ä¼˜åŠ¿åœ¨äºå®ƒä¸ç°ä»£ Python å¼€å‘å®è·µçš„ç´§å¯†ç»“åˆã€‚éšç€ Pydantic é€æ¸æˆä¸ºä¸»æµ Python æ¡†æ¶å’Œ AI åº“çš„æ ¸å¿ƒç»„ä»¶ï¼ŒPydanticAI çš„æ·±åº¦é›†æˆä¹Ÿå˜å¾—æ„ˆå‘é‡è¦ã€‚

Its future looks promising because:

å®ƒå‰æ™¯å…‰æ˜ï¼ŒåŸå› åœ¨äºï¼š

1 Growing Pydantic ecosystem integration

Pydantic ç”Ÿæ€ç³»ç»Ÿçš„æ•´åˆæ­£åœ¨ä¸æ–­åŠ å¼ºï¼ˆPydantic ecosystem integration)

2 Active development by the core Pydantic team

3 Focus on developer experience and production readiness

Pydantic æ ¸å¿ƒå›¢é˜Ÿæ­£åœ¨ç§¯æå¼€å‘ä¸“æ³¨äºæå‡å¼€å‘è€…ä½“éªŒå’Œäº§å“åœ¨ç”Ÿäº§ç¯å¢ƒä¸­çš„å¯ç”¨æ€§

When to consider alternatives? If you need LangChain's vast integrations, crewAI's multi-agent capabilities, or Instructor's specialized instruction handling. But for most AI applications, PydanticAI provides everything you need with less complexity.

ä»€ä¹ˆæƒ…å†µä¸‹åº”è¯¥è€ƒè™‘å…¶ä»–é€‰æ‹©ï¼Ÿå¦‚æœä½ çš„åº”ç”¨éœ€è¦ LangChain å¼ºå¤§çš„é›†æˆèƒ½åŠ›ã€crewAI çš„å¤š AI æ™ºèƒ½ä½“åŠŸèƒ½ï¼Œæˆ–æ˜¯ Instructor ä¸“é—¨çš„æŒ‡ä»¤å¤„ç†èƒ½åŠ›ã€‚ä½†å¯¹äºå¤§å¤šæ•° AI åº”ç”¨æ¥è¯´ï¼ŒPydanticAI å·²ç»è¶³å¤Ÿæ»¡è¶³éœ€æ±‚ï¼Œå¹¶ä¸”æ›´åŠ ç®€æ´ã€‚

PydanticAI brings the "FastAPI feeling" to AI development â€” and that's exactly what this space needs. It's not just about writing less code; it's about writing better, more maintainable AI applications.

PydanticAI å°†ã€ŒFastAPI å¼çš„ä½“éªŒã€å¸¦åˆ°äº† AI å¼€å‘é¢†åŸŸ â€”â€” è€Œè¿™æ­£æ˜¯è¯¥é¢†åŸŸæ‰€äºŸéœ€çš„ã€‚å®ƒä¸ä»…ä»…æ˜¯ä¸ºäº†å‡å°‘ä»£ç é‡ï¼Œæ›´æ˜¯ä¸ºäº†æ„å»ºæ›´ä¼˜è´¨ã€æ›´æ˜“äºç»´æŠ¤çš„ AI åº”ç”¨ç¨‹åºã€‚

Note: PydanticAI is still in early development, but given the Pydantic team's track record, I'm confident in betting on its future. The framework is already showing what the future of AI development tools should look like.

æ³¨æ„ï¼šPydanticAI ä»å¤„äºæ—©æœŸå¼€å‘é˜¶æ®µï¼Œä½†è€ƒè™‘åˆ° Pydantic å›¢é˜Ÿçš„æ—¢å¾€æˆå°±ï¼Œæˆ‘å¯¹å®ƒçš„æœªæ¥å……æ»¡ä¿¡å¿ƒã€‚è¯¥æ¡†æ¶å·²åˆæ­¥å±•ç°äº†æœªæ¥ AI å¼€å‘å·¥å…·çš„å‘å±•æ–¹å‘ã€‚

### PydanticAI Basics: A Quick Start Guide

PydanticAI åŸºç¡€ï¼šå¿«é€Ÿå…¥é—¨æŒ‡å—

PydanticAI makes building AI agents feel as natural as writing regular Python code. Let's look at three core patterns that make it powerful yet simple to use.

PydanticAI è®©æ„å»º AI æ™ºèƒ½ä½“å°±åƒç¼–å†™æ™®é€šçš„ Python ä»£ç ä¸€æ ·è‡ªç„¶ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ¥çœ‹çœ‹ PydanticAI å¼ºå¤§ä¸”æ˜“ç”¨çš„ä¸‰ä¸ªæ ¸å¿ƒæ¨¡å¼ã€‚

I will keep this brief because, honestly, the PydanticAI documentation is among the best I have ever read. Generally, Pydantic projects feature excellent documentation with an engaging, informative, and enjoyable writing style. Therefore, the best way to gain more information is to consult the documentation directly. This article aims to go beyond the documentation and explore a creative real-world application of the framework.

æˆ‘å°†å°½é‡ç®€çŸ­ï¼Œå› ä¸ºå¦ç‡åœ°è¯´ï¼ŒPydanticAI çš„æ–‡æ¡£æ˜¯æˆ‘è¯»è¿‡çš„æœ€ä½³æ–‡æ¡£ä¹‹ä¸€ã€‚é€šå¸¸ï¼ŒPydantic é¡¹ç›®çš„æ–‡æ¡£éƒ½éå¸¸å‡ºè‰²ï¼Œå†™ä½œé£æ ¼ä¸ä»…å¼•äººå…¥èƒœï¼Œè€Œä¸”ä¿¡æ¯ä¸°å¯Œï¼Œè¯»èµ·æ¥ä¹Ÿèµå¿ƒæ‚¦ç›®ã€‚å› æ­¤ï¼Œè¦äº†è§£æ›´å¤šä¿¡æ¯ï¼Œæœ€å¥½çš„æ–¹æ³•æ˜¯ç›´æ¥æŸ¥é˜…å®˜æ–¹æ–‡æ¡£ã€‚æœ¬æ–‡çš„ç›®çš„åœ¨äºï¼Œåœ¨å®˜æ–¹æ–‡æ¡£çš„åŸºç¡€ä¸Šï¼Œè¿›ä¸€æ­¥æ¢è®¨è¯¥æ¡†æ¶åœ¨ç°å®ä¸–ç•Œä¸­çš„åˆ›æ–°åº”ç”¨ã€‚

Basic Agents

åŸºç¡€æ™ºèƒ½ä½“

```py
agent = Agent('gemini-1.5-flash', system_prompt='Be concise.')
result = agent.run_sync('What is PydanticAI?')
```

At its simplest, an agent is just a wrapper around an LLM that handles the conversation flow. You choose your model, set a system prompt, and start chatting.

æœ€ç®€å•çš„å½¢å¼ï¼Œä¸€ä¸ªæ™ºèƒ½ä½“åªæ˜¯å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä¸€ä¸ªå¤–å£³ï¼Œå®ƒè´Ÿè´£å¤„ç†å¯¹è¯è¿‡ç¨‹ã€‚ä½ é€‰æ‹©ä½ çš„æ¨¡å‹ï¼Œè®¾å®šç³»ç»ŸæŒ‡ä»¤ï¼Œç„¶åå°±å¯ä»¥å¼€å§‹èŠå¤©äº†ã€‚

Structured Outputs

ç»“æ„åŒ–è¾“å‡º

```py
class WeatherInfo(BaseModel):
    temperature: float
    condition: str

weather_agent = Agent('gemini-1.5-flash', result_type=WeatherInfo)
```

Instead of parsing free text, PydanticAI guides the LLM to return structured data. Your IDE gets type hints, and you get guaranteed data structure.

PydanticAI ä¸è§£æè‡ªç”±æ–‡æœ¬ï¼Œè€Œæ˜¯å¼•å¯¼ LLMï¼ˆLarge Language Modelï¼‰è¿”å›ç»“æ„åŒ–æ•°æ®ã€‚ä½ çš„ IDE ä¼šè·å¾—ç±»å‹æç¤ºï¼Œå¹¶ä¸”ä½ å¯ä»¥è·å¾—æœ‰ä¿è¯çš„æ•°æ®ç»“æ„ã€‚

Tools

å·¥å…·

```py
@agent.tool
async def get_temperature(city: str) -> float:
    """Fetch current temperature for a city."""
    return await weather_api.get(city)
```

Tools are functions your agent can call. They extend your agent's capabilities beyond conversation to real actions like API calls or data fetching.

å·¥å…·æ˜¯ä½ çš„ AI æ™ºèƒ½ä½“å¯ä»¥è°ƒç”¨çš„å‡½æ•°ã€‚å®ƒä»¬å°†æ™ºèƒ½ä½“çš„èƒ½åŠ›ä»å¯¹è¯æ‰©å±•åˆ°ä¾‹å¦‚ API è°ƒç”¨æˆ–è·å–æ•°æ®ç­‰å®é™…æ“ä½œã€‚

What's particularly clever about PydanticAI's tool system is how it handles function signatures. The framework automatically extracts parameters (except RunContext) to build the tool's schema, and even pulls parameter descriptions from your docstrings using griffe.

PydanticAI çš„å·¥å…·ç³»ç»Ÿæœ€å·§å¦™ä¹‹å¤„åœ¨äºå®ƒå¯¹å‡½æ•°ç­¾åçš„å¤„ç†æ–¹å¼ã€‚è¿™ä¸ªç³»ç»Ÿä¼šè‡ªåŠ¨æå–å‡½æ•°å‚æ•°ï¼ˆé™¤äº† RunContextï¼‰ï¼Œä»¥æ­¤æ„å»ºå·¥å…·çš„ç»“æ„ï¼Œå®ƒç”šè‡³èƒ½åˆ©ç”¨ griffe ä»ä»£ç çš„æ–‡æ¡£æ³¨é‡Šï¼ˆdocstringï¼‰ä¸­æå–å‚æ•°çš„æè¿°ä¿¡æ¯ã€‚

This intelligent parsing means your tools are not just functional â€” they're self-documenting. The LLM understands exactly how to use them because the documentation is built right into the schema. No more manually maintaining separate descriptions of your tools!

è¿™ç§æ™ºèƒ½åŒ–çš„è§£ææ–¹å¼æ„å‘³ç€ä½ çš„å·¥å…·ä¸ä»…å…·å¤‡åŠŸèƒ½ï¼Œè¿˜èƒ½è‡ªæˆ‘ç”Ÿæˆæ–‡æ¡£ã€‚å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¹‹æ‰€ä»¥èƒ½å‡†ç¡®ç†è§£å¦‚ä½•ä½¿ç”¨è¿™äº›å·¥å…·ï¼Œæ˜¯å› ä¸ºå®ƒä»¬çš„æ–‡æ¡£ç›´æ¥åµŒå…¥åœ¨ç»“æ„å®šä¹‰ä¸­ã€‚è¿™æ ·ä¸€æ¥ï¼Œä½ å°±ä¸å†éœ€è¦æ‰‹åŠ¨ç»´æŠ¤å·¥å…·çš„é¢å¤–è¯´æ˜äº†ã€‚

What I love about PydanticAI is how these patterns compose naturally. Start with a basic agent, add structure when you need clean data, and sprinkle in tools when you need real-world interactions. It grows with your needs! 

æˆ‘å–œæ¬¢ PydanticAI çš„ä¸€ç‚¹æ˜¯ï¼Œè¿™äº›æ¨¡å¼èƒ½å¤Ÿå¦‚æ­¤è‡ªç„¶åœ°ç»„åˆåœ¨ä¸€èµ·ã€‚ä½ å¯ä»¥ä»ä¸€ä¸ªåŸºç¡€çš„ AI æ™ºèƒ½ä½“å¼€å§‹ï¼Œå½“éœ€è¦æ¸…æ™°çš„æ•°æ®æ—¶ï¼Œå†æ·»åŠ ç»“æ„åŒ–çš„å¤„ç†æ–¹å¼ï¼Œè€Œå½“éœ€è¦ä¸ç°å®ä¸–ç•Œäº’åŠ¨æ—¶ï¼Œåˆ™å¯ä»¥åŠ å…¥å„ç§å·¥å…·ã€‚å®ƒä¼šéšç€ä½ çš„éœ€æ±‚è€Œä¸æ–­æˆé•¿ï¼

This foundation is all you need to start building powerful AI agents. In our Airflow example coming up, we'll see how these patterns work together in a real application.

æœ‰äº†è¿™ä¸ªåŸºç¡€ï¼Œä½ å°±å¯ä»¥å¼€å§‹æ„å»ºå¼ºå¤§çš„ AI æ™ºèƒ½ä½“äº†ã€‚åœ¨æ¥ä¸‹æ¥çš„ Airflow ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°è¿™äº›æ¨¡å¼å¦‚ä½•åœ¨å®é™…åº”ç”¨ä¸­ååŒå·¥ä½œã€‚

### Mirror, Mirror on the Wall, What's the DAG Status After All?

é­”é•œé­”é•œï¼Œå¢™ä¸Šçš„é•œå­ï¼Œæœ‰å‘æ— ç¯å›¾ï¼ˆDAGï¼‰çš„çŠ¶æ€ç©¶ç«Ÿå¦‚ä½•ï¼Ÿ

The complete code for this tutorial is available on GitHub. While we'll walk through the key components here, feel free to clone the repository to follow along:

æœ¬æ•™ç¨‹çš„å®Œæ•´ä»£ç å·²ä¸Šä¼ è‡³ GitHubã€‚è™½ç„¶æˆ‘ä»¬ä¼šåœ¨æœ¬æ–‡ä¸­è®²è§£å…³é”®éƒ¨åˆ†ï¼Œæ‚¨ä¹Ÿå¯ä»¥å…‹éš†å­˜å‚¨åº“ä»¥ä¾¿è¿›ä¸€æ­¥å­¦ä¹ ï¼š

git clone git@github.com:vojay-dev/pydantic-airflow-agent.git

Bear in mind that PydanticAI is under heavy development, which is great, but it also means that details of this demo project might change in the future. However, it will definitely help you gain a good understanding of the basic principles and inspire your own PydanticAI project.

è¯·æ³¨æ„ï¼ŒPydanticAI ç›®å‰æ­£å¤„äºå¿«é€Ÿå¼€å‘é˜¶æ®µï¼Œè¿™å½“ç„¶æ˜¯å¥½äº‹ï¼Œä½†ä¹Ÿæ„å‘³ç€è¿™ä¸ªæ¼”ç¤ºé¡¹ç›®çš„å…·ä½“ç»†èŠ‚æœªæ¥å¯èƒ½ä¼šæœ‰æ‰€å˜åŠ¨ã€‚ä¸è¿‡ï¼Œè¿™ä¸ªé¡¹ç›®è‚¯å®šèƒ½å¸®åŠ©ä½ æ·±å…¥ç†è§£å…¶åŸºæœ¬åŸç†ï¼Œå¹¶ä¸ºä½ çš„ PydanticAI é¡¹ç›®æä¾›çµæ„Ÿã€‚

With this project, we aim to go beyond the documentation and basic examples. Let's create an AI agent that can interact with Airflow via the Airflow REST API. You will be able to ask it about the status of a DAG without needing to specify an exact DAG ID. Simply describe the DAG, and the agent will identify the most relevant one by retrieving all DAGs from the API. It will then fetch the status of the selected DAG and return the information in a structured format.

[Airflow REST API](https://airflow.apache.org/docs/apache-airflow/stable/stable-rest-api-ref.html)

åœ¨è¿™ä¸ªé¡¹ç›®ä¸­ï¼Œæˆ‘ä»¬çš„ç›®æ ‡ä¸ä»…ä»…æ˜¯é˜…è¯»æ–‡æ¡£å’Œè¿è¡Œç®€å•çš„ç¤ºä¾‹ã€‚æˆ‘ä»¬æ¥åˆ›å»ºä¸€ä¸ª AI æ™ºèƒ½ä½“ï¼ˆAI Agentï¼‰ï¼Œå®ƒå¯ä»¥é€šè¿‡ Airflow REST API ä¸ Airflow äº¤äº’ã€‚ä½ æ— éœ€æä¾›ç¡®åˆ‡çš„ DAG IDï¼Œåªéœ€æè¿°ä¸€ä¸‹ä½ å…³å¿ƒçš„ DAGï¼Œè¿™ä¸ª AI æ™ºèƒ½ä½“å°±èƒ½é€šè¿‡ API è·å–æ‰€æœ‰ DAG ä¿¡æ¯ï¼Œå¹¶ä»ä¸­æ‰¾åˆ°æœ€åŒ¹é…çš„é‚£ä¸ªã€‚æ¥ç€ï¼Œå®ƒä¼šæŠ“å–è¿™ä¸ª DAG çš„çŠ¶æ€ï¼Œå¹¶ä»¥ç»“æ„åŒ–çš„å½¢å¼è¿”å›ç»™ä½ ã€‚

For simplicity, we are using a local Airflow environment with Docker and Astro CLI (install via brew install astro), which is an effective way to start Airflow projects. We will integrate our PydanticAI agent and Airflow setup within the same project for ease of use. Typically, these would be two separate components.

ç®€å•æ¥è¯´ï¼Œæˆ‘ä»¬ä½¿ç”¨æœ¬åœ° Airflow ç¯å¢ƒï¼Œå®ƒé€šè¿‡ Docker å’Œ Astro CLIï¼ˆé€šè¿‡ `brew install astro` å®‰è£…ï¼‰è¿›è¡Œé…ç½®ï¼Œè¿™æ˜¯ä¸€ç§å¯åŠ¨ Airflow é¡¹ç›®çš„æœ‰æ•ˆæ–¹å¼ã€‚ä¸ºäº†æ–¹ä¾¿èµ·è§ï¼Œæˆ‘ä»¬å°† PydanticAI æ™ºèƒ½ä½“å’Œ Airflow çš„é…ç½®æ•´åˆåˆ°åŒä¸€ä¸ªé¡¹ç›®ä¸­ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œè¿™ä¸¤ä¸ªç»„ä»¶æ˜¯ç‹¬ç«‹å­˜åœ¨çš„ã€‚

We are using the latest version of Airflow, 2.10.4, as of the time of writing this article. If you are reading this after the release of Airflow 3, that's amazing! I can't wait for the new UI and other great features. However, this also means that things may have changed significantly. Still, you should be able to get an idea of how to adapt to it.

åœ¨æ’°å†™æœ¬æ–‡æ—¶ï¼Œæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯ Airflow çš„æœ€æ–°ç‰ˆæœ¬ 2.10.4ã€‚å¦‚æœæ‚¨åœ¨ Airflow 3 å‘å¸ƒä¹‹åé˜…è¯»æœ¬æ–‡ï¼Œé‚£çœŸæ˜¯å¤ªå¥½äº†ï¼æˆ‘éå¸¸æœŸå¾…æ–°çš„ç”¨æˆ·ç•Œé¢å’Œå…¶ä»–ä¼˜ç§€çš„åŠŸèƒ½ã€‚ä¸è¿‡ï¼Œè¿™ä¹Ÿæ„å‘³ç€æƒ…å†µå¯èƒ½å·²ç»å‘ç”Ÿäº†æ˜¾è‘—å˜åŒ–ã€‚å°½ç®¡å¦‚æ­¤ï¼Œæ‚¨åº”è¯¥ä»ç„¶èƒ½å¤Ÿä»ä¸­äº†è§£å¦‚ä½•è¿›è¡Œè°ƒæ•´ã€‚

First, let's set up the project using Poetry and install the required dependencies, starting with PydanticAI and then creating an Airflow environment via Astro CLI.

é¦–å…ˆï¼Œæˆ‘ä»¬ä½¿ç”¨ Poetry æ¥æ­å»ºé¡¹ç›®ï¼Œå¹¶å®‰è£…å¿…è¦çš„ä¾èµ–ï¼Œé¦–å…ˆå®‰è£… PydanticAIï¼Œæ¥ç€ä½¿ç”¨ Astro CLI åˆ›å»º Airflow ç¯å¢ƒã€‚

poetry new pydantic-airflow-agent
cd pydantic-airflow-agent
poetry add pydantic-ai
poetry add colorlog

Before adding the Airflow dependency, change the Python requirement in pyproject.toml:

åœ¨æ·»åŠ  Airflow ä¾èµ–ä¹‹å‰ï¼Œè¯·å…ˆä¿®æ”¹ pyproject.toml æ–‡ä»¶ä¸­çš„ Python ç‰ˆæœ¬è¦æ±‚ï¼š

python = ">=3.12,<3.13"

Now, add the Airflow dependency:

æ¥ä¸‹æ¥ï¼Œæ·»åŠ  Airflow ä¾èµ–ï¼š

poetry add apache-airflow

Finally, spin up the local Airflow environment:

æœ€åï¼Œæ­å»ºæœ¬åœ° Airflow ç¯å¢ƒï¼š

astro dev init # confirm to create the project in a non-empty directory
astro dev start

Implement some sample DAGs

åˆ›å»ºä¸€äº›ç¤ºä¾‹ DAGã€‚

The focus is the PydanticAI driven AI agent, however, without some DAGs we have nothing to interact with. We go as minimal as possible and simply add to DAGs doing nothing essentially.

æ ¸å¿ƒæ˜¯åŸºäº PydanticAI çš„ AI æ™ºèƒ½ä½“ï¼Œä½†æ˜¯ï¼Œå¦‚æœæ²¡æœ‰æœ‰å‘æ— ç¯å›¾ï¼ˆDAGï¼‰ï¼Œæˆ‘ä»¬å°±æ— æ³•è¿›è¡Œä»»ä½•äº¤äº’ã€‚æˆ‘ä»¬å°½é‡ä¿æŒæœ€ç®€è®¾è®¡ï¼Œåªæ˜¯ç®€å•åœ°å°†å…ƒç´ æ·»åŠ åˆ°ä¸€äº›åŸºæœ¬ä¸Šä¸æ‰§è¡Œä»»ä½•æ“ä½œçš„æœ‰å‘æ— ç¯å›¾ä¸­ã€‚

```py
import pendulum  
from airflow.decorators import dag, task  
from airflow.operators.smooth import SmoothOperator  
  
start_date = pendulum.datetime(2024, 12, 1, tz="UTC")  
  
@dag(schedule='@daily', start_date=start_date)  
def payment_report():  
    SmoothOperator(task_id='some_task')  
  
@dag(schedule='@daily', start_date=start_date)  
def customer_profile():  
    SmoothOperator(task_id='some_task')  
  
payment_report()  
customer_profile()
```

If you don't know about SmoothOperator yet, check the logs for it in Airflow. It's a delightful little Easter egg that brings a smile to the faces of us Data Engineers.

å¦‚æœä½ è¿˜ä¸äº†è§£ SmoothOperatorï¼Œè¯·åœ¨ Airflow æ—¥å¿—ä¸­æŸ¥æ‰¾å®ƒã€‚è¿™æ˜¯ä¸€ä¸ªä»¤äººæƒŠå–œçš„å°å½©è›‹ï¼Œèƒ½è®©æˆ‘ä»¬çš„æ•°æ®å·¥ç¨‹å¸ˆä»¬ä¼šå¿ƒä¸€ç¬‘ã€‚

Local Airflow setup with two example DAGs, source: by author

æœ¬åœ° Airflow ç¯å¢ƒæ­å»ºï¼ŒåŒ…å«ä¸¤ä¸ªç¤ºä¾‹ DAGï¼Œä½œè€…æä¾›

Implement an Airflow AI agent with PydanticAI

åˆ©ç”¨ PydanticAI æ„å»º Airflow AI æ™ºèƒ½ä½“

Since we want to interact with Airflow through the Airflow REST API, we can derive some of the agent's dependencies from it. We need the base URI of our Airflow service, the port on which the API is running, and a username and password.

ç”±äºæˆ‘ä»¬å¸Œæœ›é€šè¿‡ Airflow REST API ä¸ Airflow äº¤äº’ï¼Œæˆ‘ä»¬å¯ä»¥ä» Airflow REST API è·å–ä¸€äº› AI æ™ºèƒ½ä½“çš„ä¾èµ–é¡¹ã€‚æˆ‘ä»¬éœ€è¦ Airflow æœåŠ¡çš„æ ¹ URIã€API ç›‘å¬çš„ç«¯å£ä»¥åŠç”¨æˆ·åå’Œå¯†ç ã€‚

We also expect our AI agent to respond with a structured object that represents the state of a DAG, including several interesting attributes. Let's define both the dependencies and the output model.

æˆ‘ä»¬è¿˜æœŸæœ›æˆ‘ä»¬çš„ AI æ™ºèƒ½ä½“ä»¥ç»“æ„åŒ–çš„å¯¹è±¡å½¢å¼è¿”å›ç»“æœï¼Œè¿™ä¸ªå¯¹è±¡ç”¨äºè¡¨ç¤ºæœ‰å‘æ— ç¯å›¾ï¼ˆDAGï¼‰çš„çŠ¶æ€ï¼Œå…¶ä¸­åŒ…å«ä¸€äº›å€¼å¾—å…³æ³¨çš„å±æ€§ã€‚ä¸‹é¢æˆ‘ä»¬æ¥å®šä¹‰ä¾èµ–å…³ç³»å’Œè¾“å‡ºæ¨¡å‹ã€‚

```py
@dataclass  
class Deps:  
    airflow_api_base_uri: str  
    airflow_api_port: int  
    airflow_api_user: str  
    airflow_api_pass: str  
  
class DAGStatus(BaseModel):  
    dag_id: str = Field(description='ID of the DAG')  
    dag_display_name: str = Field(description='Display name of the DAG')  
    is_paused: bool = Field(description='Whether the DAG is paused')  
    next_dag_run_data_interval_start: str = Field(description='Next DAG run data interval start')  
    next_dag_run_data_interval_end: str = Field(description='Next DAG run data interval end')  
    last_dag_run_id: str = Field(default='No DAG run', description='Last DAG run ID')  
    last_dag_run_state: str = Field(default='No DAG run', description='Last DAG run state')  
    total_dag_runs: int = Field(description='Total number of DAG runs')
```

With that, we can define our model and Agent. For this example, we use the latest Gemini 2.0 Flash model.

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰æ¨¡å‹å’Œ AI æ™ºèƒ½ä½“ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬é€‰ç”¨æœ€æ–°çš„ Gemini 2.0 Flash æ¨¡å‹ã€‚

Note: I experimented extensively with various models. Many models struggled to interact with tool functions in the correct order or to use the results for constructing the final structured output. Gemini 2.0 Flash provided the best results, but I also recommend trying other supported models. You can use models via Ollama, such as Mistral or Llama 3.3, both of which also support tool functions and structured output. However, for this demo, we will use the model that gave the best results. Ultimately, we want to have an agent we can trust. Would you fly on an airplane that only sometimes works?

æ³¨æ„ï¼šæˆ‘æ›¾å¹¿æ³›æµ‹è¯•è¿‡å„ç§æ¨¡å‹ã€‚è®¸å¤šæ¨¡å‹åœ¨æŒ‰æ­£ç¡®é¡ºåºä¸å·¥å…·å‡½æ•°äº¤äº’æ—¶é‡åˆ°å›°éš¾ï¼Œæˆ–è€…éš¾ä»¥åˆ©ç”¨ç»“æœæ„å»ºæœ€ç»ˆçš„ç»“æ„åŒ–è¾“å‡ºã€‚Gemini 2.0 Flash è¡¨ç°æœ€ä½³ï¼Œä½†æˆ‘ä¹Ÿå»ºè®®å°è¯•å…¶ä»–æ”¯æŒçš„æ¨¡å‹ã€‚æ‚¨å¯ä»¥é€šè¿‡ Ollama ä½¿ç”¨ Mistral æˆ– Llama 3.3 ç­‰æ¨¡å‹ï¼Œå®ƒä»¬ä¹Ÿéƒ½æ”¯æŒå·¥å…·å‡½æ•°å’Œç»“æ„åŒ–è¾“å‡ºã€‚ä¸è¿‡ï¼Œä¸ºäº†æœ¬æ¬¡æ¼”ç¤ºï¼Œæˆ‘ä»¬å°†é‡‡ç”¨æ•ˆæœæœ€å¥½çš„æ¨¡å‹ã€‚æœ€ç»ˆï¼Œæˆ‘ä»¬å¸Œæœ›æ‹¥æœ‰ä¸€ä¸ªå€¼å¾—ä¿¡èµ–çš„ AI æ™ºèƒ½ä½“ã€‚ä½ ä¼šä¹˜åä¸€æ¶å¶å°”æ‰æ­£å¸¸å·¥ä½œçš„é£æœºå—ï¼Ÿ

```py
model = VertexAIModel(  
    model_name='gemini-2.0-flash-exp',  
    service_account_file='gcp-credentials.json'  
)  
  
airflow_agent = Agent(  
    model=model,  
    system_prompt=(  
        'You are an Airflow monitoring assistant. For each request:\n'  
        '1. Use `list_dags` first to get available DAGs\n'  
        '2. Match the user request to the most relevant DAG ID\n'  
        '3. Use `get_dag_status` to fetch the DAG status details'    ),  
    result_type=DAGStatus,  
    deps_type=Deps,  
    retries=2  
)
```

As you can see, I am quite strict and clear about how the agent should handle requests and interact with tool functions. This largely depends on the model you use. Depending on the use case, it can sometimes work well not to specify any tool functions explicitly in the system prompt.

å¯ä»¥çœ‹åˆ°ï¼Œæˆ‘å¯¹ AI æ™ºèƒ½ä½“å¦‚ä½•å¤„ç†è¯·æ±‚ä»¥åŠå¦‚ä½•ä¸å·¥å…·å‡½æ•°äº¤äº’æœ‰ç€éå¸¸ä¸¥æ ¼å’Œæ¸…æ™°çš„è¦æ±‚ã€‚è¿™åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå–å†³äºä½ æ‰€ä½¿ç”¨çš„æ¨¡å‹ã€‚æ ¹æ®ä¸åŒçš„åº”ç”¨åœºæ™¯ï¼Œæœ‰æ—¶åœ¨ç³»ç»Ÿæç¤ºä¸­ä¸æ˜ç¡®æŒ‡å®šä»»ä½•å·¥å…·å‡½æ•°ä¹Ÿèƒ½è¾¾åˆ°å¾ˆå¥½çš„æ•ˆæœã€‚

Next, let us add a tool function so that our AI agent can retrieve a list of DAGs. We will return the DAG IDs and display names, allowing the model to select the DAG that best fits the user's question.

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ·»åŠ ä¸€ä¸ªå·¥å…·å‡½æ•°ï¼Œè®©æˆ‘ä»¬çš„ AI æ™ºèƒ½ä½“èƒ½å¤Ÿè·å– DAG åˆ—è¡¨ã€‚æˆ‘ä»¬å°†è¿”å› DAG çš„ ID å’Œæ˜¾ç¤ºåç§°ï¼Œä»¥ä¾¿æ¨¡å‹é€‰æ‹©æœ€ç¬¦åˆç”¨æˆ·é—®é¢˜çš„ DAGã€‚

```py
@airflow_agent.tool
async def list_dags(ctx: RunContext[Deps]) -> str:
    """
    Get a list of all DAGs from the Airflow instance. Returns DAGs with their IDs and display names.
    """
    logger.info('Getting available DAGs...')
    uri = f'{ctx.deps.airflow_api_base_uri}:{ctx.deps.airflow_api_port}/api/v1/dags'
    auth = (ctx.deps.airflow_api_user, ctx.deps.airflow_api_pass)

    async with AsyncClient() as client:
        response = await client.get(uri, auth=auth)
        response.raise_for_status()

        dags_data = response.json()['dags']
        result = json.dumps([
            {'dag_id': dag['dag_id'], 'dag_display_name': dag['dag_display_name']} for dag in dags_data
        ])
        logger.debug(f'Available DAGs: {result}')
        return result
```

Each tool function receives the RunContext, which contains the previously defined dependencies. This allows us to easily connect to the Airflow API and fetch the necessary data.

æ¯ä¸ªå·¥å…·å‡½æ•°éƒ½ä¼šæ¥æ”¶ä¸€ä¸ª RunContext å¯¹è±¡ï¼Œå®ƒåŒ…å«äº†é¢„å…ˆè®¾å®šçš„ä¾èµ–å…³ç³»ã€‚è¿™ä½¿å¾—æˆ‘ä»¬å¯ä»¥æ–¹ä¾¿åœ°ä¸ Airflow API äº¤äº’ï¼Œä»è€Œè·å–æ‰€éœ€çš„æ•°æ®ã€‚

Once the agent determines which DAG ID best fits the user's requests, it must retrieve the details about the DAG and its runs to compute the structured output, also known as the model class we defined earlier.

å½“ AI æ™ºèƒ½ä½“ï¼ˆAI Agentï¼‰ç¡®å®šå“ªä¸ª DAG ID æœ€ç¬¦åˆç”¨æˆ·çš„è¯·æ±‚æ—¶ï¼Œå®ƒéœ€è¦è·å– DAG åŠå…¶è¿è¡Œçš„è¯¦ç»†ä¿¡æ¯ï¼Œä»¥ä¾¿è®¡ç®—ç»“æ„åŒ–è¾“å‡ºï¼Œä¹Ÿå°±æ˜¯æˆ‘ä»¬ä¹‹å‰å®šä¹‰çš„æ¨¡å‹ç±»ã€‚

Therefore, let's add another tool function to obtain the details.

å› æ­¤ï¼Œæˆ‘ä»¬è¿˜éœ€è¦æ·»åŠ ä¸€ä¸ªå·¥å…·å‡½æ•°ï¼Œä»¥ä¾¿è·å–æ›´è¯¦å°½çš„ä¿¡æ¯ã€‚

```py
@airflow_agent.tool
async def get_dag_status(ctx: RunContext[Deps], dag_id: str) -> str:
    """
    Get detailed status information for a specific DAG by DAG ID.
    """
    logger.info(f'Getting status for DAG with ID: {dag_id}')
    base_url = f'{ctx.deps.airflow_api_base_uri}:{ctx.deps.airflow_api_port}/api/v1'
    auth = (ctx.deps.airflow_api_user, ctx.deps.airflow_api_pass)

    try:
        async with AsyncClient() as client:
            dag_response = await client.get(f'{base_url}/dags/{dag_id}', auth=auth)
            dag_response.raise_for_status()

            runs_response = await client.get(
                f'{base_url}/dags/{dag_id}/dagRuns',
                auth=auth,
                params={'order_by': '-execution_date', 'limit': 1}
            )
            runs_response.raise_for_status()

            result = {
                'dag_data': dag_response.json(),
                'runs_data': runs_response.json()
            }

            logger.debug(f'DAG status: {json.dumps(result)}')
            return json.dumps(result)

    except httpx.HTTPStatusError as e:
        if e.response.status_code == 404:
            return f'DAG with ID {dag_id} not found'
        raise
```

With that, we have all tools we need and can run the agent as follows.

è‡³æ­¤ï¼Œæˆ‘ä»¬å·²ç»å…·å¤‡äº†æ‰€æœ‰å¿…éœ€çš„å·¥å…·ï¼Œå¯ä»¥å¼€å§‹è¿è¡Œ AI æ™ºèƒ½ä½“äº†ï¼Œå…·ä½“æ­¥éª¤å¦‚ä¸‹ã€‚

```py
async def main():
    deps = Deps(
        airflow_api_base_uri='http://localhost',
        airflow_api_port=8080,
        airflow_api_user='admin',
        airflow_api_pass='admin'
    )

    user_request = 'What is the status of the DAG for our daily payment report?'
    result = await airflow_agent.run(user_request, deps=deps)
    pprint(result.data)

if __name__ == "__main__":
    asyncio.run(main())
```

You might notice that many operations in PydanticAI use async and await. This isn't just a random choice - it's a powerful feature that makes our applications more efficient, especially when dealing with I/O operations like API calls or model interactions.

ä½ å¯èƒ½å·²ç»æ³¨æ„åˆ°ï¼ŒPydanticAI ä¸­çš„è®¸å¤šæ“ä½œéƒ½ä½¿ç”¨äº† async å’Œ awaitã€‚è¿™å¹¶ééšæ„ä¹‹ä¸¾ï¼Œè€Œæ˜¯ä¸€é¡¹å¼ºå¤§çš„åŠŸèƒ½ï¼Œèƒ½å¤Ÿæé«˜åº”ç”¨ç¨‹åºçš„æ•ˆç‡ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†è¯¸å¦‚ API è°ƒç”¨æˆ–æ¨¡å‹äº¤äº’ç­‰ I/O æ“ä½œæ—¶ã€‚

Think of async like being an expert multitasker. When you're cooking, you don't wait idly by the stove for water to boil â€” you prep other ingredients while waiting. That's what async does for our code. When our agent makes an API call or waits for an LLM response, instead of blocking everything else, it can handle other tasks â€” like processing another request or updating logs. This is particularly valuable in production environments where efficiency matters.

å¯ä»¥å°†å¼‚æ­¥ï¼ˆasyncï¼‰æƒ³è±¡æˆä¸€ä½é«˜æ•ˆçš„ã€Œå¤šé¢æ‰‹ã€ã€‚å°±åƒåšé¥­æ—¶ï¼Œä½ ä¸ä¼šå‚»ç­‰æ°´å¼€ï¼Œè€Œæ˜¯ä¼šåˆ©ç”¨ç­‰å¾…çš„æ—¶é—´å‡†å¤‡å…¶ä»–é£Ÿæã€‚å¼‚æ­¥åœ¨ä»£ç ä¸­çš„ä½œç”¨ä¹Ÿæ˜¯å¦‚æ­¤ã€‚å½“æˆ‘ä»¬çš„ AI æ™ºèƒ½ä½“ï¼ˆAI Agentï¼‰å‘èµ· API è°ƒç”¨æˆ–ç­‰å¾…å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å›å¤æ—¶ï¼Œå®ƒä¸ä¼šåœæ»ä¸å‰ï¼Œè€Œæ˜¯å¯ä»¥åŒæ—¶å¤„ç†å…¶ä»–ä»»åŠ¡ï¼Œä¾‹å¦‚å“åº”æ–°çš„è¯·æ±‚æˆ–æ›´æ–°æ—¥å¿—ã€‚è¿™åœ¨è¿½æ±‚æ•ˆç‡çš„ç”Ÿäº§ç¯å¢ƒä¸­æ˜¾å¾—å°¤ä¸ºé‡è¦ã€‚

Let's combine everything before we dive into the demo. Here is the complete Airflow AI agent code with PydanticAI.

åœ¨å¼€å§‹æ¼”ç¤ºä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆå°†æ‰€æœ‰å†…å®¹æ•´åˆä¸€ä¸‹ã€‚è¿™é‡Œæ˜¯ä½¿ç”¨ PydanticAI å®ç°çš„å®Œæ•´ Airflow AI æ™ºèƒ½ä½“ä»£ç ã€‚

```py
import asyncio
import json
import logging
from dataclasses import dataclass
from devtools import pprint

import colorlog
import httpx
from httpx import AsyncClient
from pydantic import BaseModel, Field
from pydantic_ai import Agent, RunContext
from pydantic_ai.models.vertexai import VertexAIModel

log_format = '%(log_color)s%(asctime)s [%(levelname)s] %(reset)s%(purple)s[%(name)s] %(reset)s%(blue)s%(message)s'
handler = colorlog.StreamHandler()
handler.setFormatter(colorlog.ColoredFormatter(log_format))
logging.basicConfig(level=logging.INFO, handlers=[handler])

logger = logging.getLogger(__name__)

@dataclass
class Deps:
    airflow_api_base_uri: str
    airflow_api_port: int
    airflow_api_user: str
    airflow_api_pass: str

class DAGStatus(BaseModel):
    dag_id: str = Field(description='ID of the DAG')
    dag_display_name: str = Field(description='Display name of the DAG')
    is_paused: bool = Field(description='Whether the DAG is paused')
    next_dag_run_data_interval_start: str = Field(description='Next DAG run data interval start')
    next_dag_run_data_interval_end: str = Field(description='Next DAG run data interval end')
    last_dag_run_id: str = Field(default='No DAG run', description='Last DAG run ID')
    last_dag_run_state: str = Field(default='No DAG run', description='Last DAG run state')
    total_dag_runs: int = Field(description='Total number of DAG runs')

model = VertexAIModel(
    model_name='gemini-2.0-flash-exp',
    service_account_file='gcp-credentials.json'
)

airflow_agent = Agent(
    model=model,
    system_prompt=(
        'You are an Airflow monitoring assistant. For each request:\n'
        '1. Use `list_dags` first to get available DAGs\n'
        '2. Match the user request to the most relevant DAG ID\n'
        '3. Use `get_dag_status` to fetch the DAG status details'
    ),
    result_type=DAGStatus,
    deps_type=Deps,
    retries=2
)

@airflow_agent.tool
async def list_dags(ctx: RunContext[Deps]) -> str:
    """
    Get a list of all DAGs from the Airflow instance. Returns DAGs with their IDs and display names.
    """
    logger.info('Getting available DAGs...')
    uri = f'{ctx.deps.airflow_api_base_uri}:{ctx.deps.airflow_api_port}/api/v1/dags'
    auth = (ctx.deps.airflow_api_user, ctx.deps.airflow_api_pass)

    async with AsyncClient() as client:
        response = await client.get(uri, auth=auth)
        response.raise_for_status()

        dags_data = response.json()['dags']
        result = json.dumps([
            {'dag_id': dag['dag_id'], 'dag_display_name': dag['dag_display_name']} for dag in dags_data
        ])
        logger.debug(f'Available DAGs: {result}')
        return result

@airflow_agent.tool
async def get_dag_status(ctx: RunContext[Deps], dag_id: str) -> str:
    """
    Get detailed status information for a specific DAG by DAG ID.
    """
    logger.info(f'Getting status for DAG with ID: {dag_id}')
    base_url = f'{ctx.deps.airflow_api_base_uri}:{ctx.deps.airflow_api_port}/api/v1'
    auth = (ctx.deps.airflow_api_user, ctx.deps.airflow_api_pass)

    try:
        async with AsyncClient() as client:
            dag_response = await client.get(f'{base_url}/dags/{dag_id}', auth=auth)
            dag_response.raise_for_status()

            runs_response = await client.get(
                f'{base_url}/dags/{dag_id}/dagRuns',
                auth=auth,
                params={'order_by': '-execution_date', 'limit': 1}
            )
            runs_response.raise_for_status()

            result = {
                'dag_data': dag_response.json(),
                'runs_data': runs_response.json()
            }

            logger.debug(f'DAG status: {json.dumps(result)}')
            return json.dumps(result)

    except httpx.HTTPStatusError as e:
        if e.response.status_code == 404:
            return f'DAG with ID {dag_id} not found'
        raise

async def main():
    deps = Deps(
        airflow_api_base_uri='http://localhost',
        airflow_api_port=8080,
        airflow_api_user='admin',
        airflow_api_pass='admin'
    )

    user_request = 'What is the status of the DAG for our daily payment report?'
    result = await airflow_agent.run(user_request, deps=deps)
    pprint(result.data)

if __name__ == "__main__":
    asyncio.run(main())
```

What I found essential is having high transparency regarding how the agent makes tool and LLM calls during development. In the example above, we use logging. However, I highly recommend checking out the Logfire integration.

åœ¨å¼€å‘è¿‡ç¨‹ä¸­ï¼Œæˆ‘å‘ç°è‡³å…³é‡è¦çš„æ˜¯ï¼Œè¦é«˜åº¦é€æ˜åœ°äº†è§£æ™ºèƒ½ä½“å¦‚ä½•è°ƒç”¨å·¥å…·å’Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ã€‚åœ¨å‰é¢çš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†æ—¥å¿—è®°å½•ã€‚ä¸è¿‡ï¼Œæˆ‘å¼ºçƒˆå»ºè®®ä½ äº†è§£ä¸€ä¸‹ Logfire çš„æ•´åˆæ–¹æ¡ˆã€‚

Demo

Time to let the magic happen. Let's run our agent with the following user question:

ç°åœ¨ï¼Œæ˜¯æ—¶å€™è§è¯å¥‡è¿¹äº†ã€‚è®©æˆ‘ä»¬ç”¨ä»¥ä¸‹ç”¨æˆ·é—®é¢˜è¿è¡Œæˆ‘ä»¬çš„ AI æ™ºèƒ½ä½“ï¼ˆAI Agent)ï¼š

What is the status of the DAG for our daily payment report?

æˆ‘ä»¬çš„æ¯æ—¥ä»˜æ¬¾æŠ¥å‘Šçš„ DAG çŠ¶æ€æ˜¯ä»€ä¹ˆï¼Ÿ

Remember, we have two DAGs defined: payment_report and customer_profile. In the question above, we do not use the exact DAG IDs; the agent has to determine them on its own. Let's see how it handles our request by examining the output.

éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸¤ä¸ª DAGï¼Œåˆ†åˆ«æ˜¯ payment_report å’Œ customer_profile ã€‚åœ¨ä¸Šé¢çš„é—®é¢˜ä¸­ï¼Œæˆ‘ä»¬æ²¡æœ‰ç›´æ¥ä½¿ç”¨ DAG çš„ IDï¼Œè€Œæ˜¯éœ€è¦ AI æ™ºèƒ½ä½“è‡ªè¡Œåˆ¤æ–­ã€‚æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬é€šè¿‡æ£€æŸ¥è¾“å‡ºæ¥çœ‹çœ‹å®ƒæ˜¯å¦‚ä½•å¤„ç†è¿™ä¸ªè¯·æ±‚çš„ã€‚

(.venv) ~/projects/pydantic-airflow-agent
poetry run python pydantic_airflow_agent/agent.py
2024-12-23 14:49:05,127 [INFO] [httpx] HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1/projects/vojay-329716/locations/us-central1/publishers/google/models/gemini-2.0-flash-exp:generateContent "HTTP/1.1 200 OK"
2024-12-23 14:49:05,132 [INFO] [__main__] Getting available DAGs...
2024-12-23 14:49:05,241 [INFO] [httpx] HTTP Request: GET http://localhost:8080/api/v1/dags "HTTP/1.1 200 OK"
2024-12-23 14:49:06,640 [INFO] [httpx] HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1/projects/vojay-329716/locations/us-central1/publishers/google/models/gemini-2.0-flash-exp:generateContent "HTTP/1.1 200 OK"
2024-12-23 14:49:06,643 [INFO] [__main__] Getting status for DAG with ID: payment_report
2024-12-23 14:49:06,721 [INFO] [httpx] HTTP Request: GET http://localhost:8080/api/v1/dags/payment_report "HTTP/1.1 200 OK"
2024-12-23 14:49:06,798 [INFO] [httpx] HTTP Request: GET http://localhost:8080/api/v1/dags/payment_report/dagRuns?order_by=-execution_date&limit=1 "HTTP/1.1 200 OK"
2024-12-23 14:49:09,915 [INFO] [httpx] HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1/projects/vojay-329716/locations/us-central1/publishers/google/models/gemini-2.0-flash-exp:generateContent "HTTP/1.1 200 OK"

DAGStatus(
    dag_id='payment_report',
    dag_display_name='payment_report',
    is_paused=False,
    next_dag_run_data_interval_start='2024-12-23T00:00:00+00:00',
    next_dag_run_data_interval_end='2024-12-24T00:00:00+00:00',
    last_dag_run_id='scheduled__2024-12-22T00:00:00+00:00',
    last_dag_run_state='success',
    total_dag_runs=22,
)

As you can see, it started by fetching the available DAGs:

å¯ä»¥çœ‹åˆ°ï¼Œå®ƒé¦–å…ˆè¯»å–å¯ç”¨çš„ DAGï¼ˆDirected Acyclic Graphï¼Œæœ‰å‘æ— ç¯å›¾ï¼‰ï¼š

2024-12-23 14:49:05,132 [INFO] [__main__] Getting available DAGs...\

It then selected the DAG which fits best to the user input, and used the other tool function to get the details:

2024-12-23 14:49:06,643 [INFO] [__main__] Getting status for DAG with ID: payment_report

And finally used structured output to return a DAGStatus instance.

æœ€åä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºè¿”å›ä¸€ä¸ª DAGStatus å®ä¾‹ã€‚

Fig: The Airflow AI agent powered by PydanticAI in action, source: by author

Honestly, the first time I ran this successfully, it blew me away. This powerful prototype combines simplicity with type-safe integration, and I was immediately hooked. I began to think about how to generate value with such an agent. For example, imagine someone asks in the data team's Slack channel why a specific report did not update. Such an agent could autonomously find the related DAG and engage in a conversation with the user while the Data Engineering team enjoys their coffee in peace. 

è¯´å®è¯ï¼Œå½“æˆ‘ç¬¬ä¸€æ¬¡æˆåŠŸè¿è¡Œè¿™ä¸ªç¨‹åºæ—¶ï¼Œå®ƒç»™æˆ‘ç•™ä¸‹äº†æ·±åˆ»çš„å°è±¡ã€‚è¿™ä¸ªå¼ºå¤§çš„åŸå‹å…¼å…·ç®€æ´æ€§å’Œç±»å‹å®‰å…¨çš„é›†æˆç‰¹æ€§ï¼Œæˆ‘ç«‹åˆ»å°±è¢«å®ƒå¸å¼•äº†ã€‚æˆ‘å¼€å§‹æ€è€ƒå¦‚ä½•åˆ©ç”¨è¿™æ ·çš„æ™ºèƒ½ä½“æ¥åˆ›é€ ä»·å€¼ã€‚ä¾‹å¦‚ï¼Œè®¾æƒ³ä¸€ä¸‹ï¼Œå¦‚æœæœ‰äººåœ¨æ•°æ®å›¢é˜Ÿçš„ Slack é¢‘é“é‡Œè¯¢é—®ä¸ºä»€ä¹ˆæŸä¸ªç‰¹å®šçš„æŠ¥å‘Šæ²¡æœ‰æ›´æ–°ã€‚è¿™æ ·çš„æ™ºèƒ½ä½“å°±å¯ä»¥è‡ªåŠ¨æŸ¥æ‰¾ç›¸å…³çš„ DAGï¼Œå¹¶ä¸ç”¨æˆ·å±•å¼€å¯¹è¯ï¼Œä¸æ­¤åŒæ—¶ï¼Œæ•°æ®å·¥ç¨‹å›¢é˜Ÿåˆ™å¯ä»¥å®‰å¿ƒåœ°äº«å—ä»–ä»¬çš„å’–å•¡æ—¶å…‰ã€‚

### From Blind Flight to Clear Skies

ä»ç›²é£åˆ°æ™´ç©º

This article has shown that building production-grade AI applications doesn't have to feel like navigating through a storm. With the right tools and frameworks, it can be as straightforward as modern air travel â€” powerful, yet controlled and reliable.

æœ¬æ–‡é˜è¿°äº†ï¼Œæ„å»ºç”Ÿäº§çº§ AI åº”ç”¨ç¨‹åºä¸å¿…åƒåœ¨æš´é£é›¨ä¸­æ‘¸ç´¢ã€‚æœ‰äº†åˆé€‚çš„å·¥å…·å’Œæ¡†æ¶ï¼Œå®ƒå°±å¯ä»¥åƒç°ä»£èˆªç©ºæ—…è¡Œä¸€æ ·é¡ºç•… â€”â€” å¼ºå¤§ã€å¯æ§ä¸”å¯é ã€‚

The landscape of AI development is evolving rapidly, but frameworks like PydanticAI give us a steady foundation to build upon. Like modern aviation continues to advance while maintaining its core principles of safety and reliability, PydanticAI sets the stage for future innovations without sacrificing stability.

äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰çš„å‘å±•æ—¥æ–°æœˆå¼‚ï¼Œä½†åƒ PydanticAI è¿™æ ·çš„æ¡†æ¶ä¸ºæˆ‘ä»¬æä¾›äº†åšå®çš„åŸºç¡€ã€‚æ­£å¦‚ç°ä»£èˆªç©ºåœ¨åšå®ˆå®‰å…¨å’Œå¯é æ ¸å¿ƒåŸåˆ™çš„åŒæ—¶ä¸æ–­è¿›æ­¥ï¼ŒPydanticAI ä¹Ÿä¸ºæœªæ¥çš„åˆ›æ–°å¥ å®šäº†åŸºç¡€ï¼ŒåŒæ—¶ä¿è¯äº†ç¨³å®šæ€§ã€‚

Keep an eye on the PydanticAI project. With the amazing team behind it and the framework's elegant design, I believe we are only seeing the beginning of its potential.

è¯·å¯†åˆ‡å…³æ³¨ PydanticAI é¡¹ç›®ã€‚å®ƒèƒŒåæœ‰ä¸€ä¸ªå‡ºè‰²çš„å›¢é˜Ÿï¼Œè€Œä¸”æ¡†æ¶è®¾è®¡ç²¾å·§ï¼Œæˆ‘ç›¸ä¿¡æˆ‘ä»¬ç°åœ¨çœ‹åˆ°çš„ä»…ä»…æ˜¯å®ƒæ½œåŠ›çš„å†°å±±ä¸€è§’ã€‚

Whether you're building AI agents for Airflow monitoring, customer support, or any other use case, remember: you don't have to fly blind anymore. The instruments are here, the controls are intuitive, and the skies are clear for takeoff.

æ— è®ºä½ æ˜¯ä¸º Airflow ç›‘æ§ã€å®¢æˆ·æ”¯æŒæˆ–ä»»ä½•å…¶ä»–ç”¨ä¾‹æ„å»º AI æ™ºèƒ½ä½“ï¼Œè¯·è®°ä½ï¼šä½ ä¸å†éœ€è¦æ‘¸é»‘æ¢ç´¢ã€‚å„ç§å·¥å…·å·²ç»å°±ç»ªï¼Œæ“ä½œç®€å•ç›´è§‚ï¼Œä¸€åˆ‡å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥å¼€å§‹è¡ŒåŠ¨äº†ã€‚

Now, if you'll excuse me, I have some DAGs to chat with!

ç°åœ¨ï¼Œå¦‚æœä½ ä¸ä»‹æ„çš„è¯ï¼Œæˆ‘å¾—å»å’Œä¸€äº› DAGï¼ˆDirected Acyclic Graphï¼Œæœ‰å‘æ— ç¯å›¾ï¼‰èŠèŠäº†ï¼

## åŸæ–‡

Talk to Airflow â€” Build an AI Agent Using PydanticAI and Gemini 2.0
Create an AI agent with PydanticAI to interact with Airflow DAGs
Volker Janz

Published in Data Engineer Things

Dec 24, 2024


A Journey from Chaos to Control
In the pioneering days of aviation, pilots flew through clouds with little more than basic instruments and raw instinct. Each flight was a dance between human judgment and mechanical power, relying heavily on experience and intuition for success. A slight miscalculation or unexpected weather change could spell disaster. They used amazing technology with little control over it.

When I first started integrating LLMs into production systems, I felt like one of those early pilots â€” commanding immense power with minimal instrumentation. Every deployment felt like a leap of faith.


AI agents getting ready for Airflow, source: generated with Adobe Firefly
The landscape of AI development today mirrors those early aviation challenges. We have incredibly powerful models like Gemini 2.0 at our disposal â€” capable of understanding context, generating human-like responses, and processing complex instructions. Yet, utilizing this power for production-grade applications often feels like flying through a storm without proper navigation tools.

But just as modern aviation evolved from risky adventures to reliable transportation through proper instrumentation and control systems, AI development is undergoing its own transformation toward agents. Unlike traditional AI, which simply responds to queries, agents actively engage with their environment. They make decisions, use tools, and execute tasks on your behalf. Modern AI agents, powered by LLMs like Gemini, understand natural language instructions, break down complex tasks into smaller steps, and provide structured output and monitoring.

This is where PydanticAI appears at the sky. Built by the team behind Pydantic â€” the same foundation that powers numerous famous projects â€” itâ€™s a framework designed for modern AI development that brings control and reliability to agent systems.

Think of PydanticAI as your aircraftâ€™s modern cockpit â€” combining assistant systems, engine controls, and instrumentation panels into one coherent interface. It provides clear readings, predictable controls, and most importantly, the confidence to navigate through complex scenarios. It brings structure to chaos.

In this article, weâ€™ll put PydanticAI to the test by building an AI agent that interacts with Apache Airflow. Weâ€™ll create a system that can understand natural language queries about your workflows, fetch real-time status updates, and respond with structured, reliable data. No more flying blind through your DAG operations.

ğŸš€ Want to jump straight into the code? Check out the project on GitHub:
https://github.com/vojay-dev/pydantic-airflow-agent

â€“ A Journey from Chaos to Control
â€“ Why PydanticAI? The FastAPI Feeling for AI Development
âˆ’âˆ’ The Current Landscape
âˆ’âˆ’ PydanticAI Simplicity
âˆ’âˆ’ The Future of PydanticAI
â€“ PydanticAI Basics: A Quick Start Guide
â€“ Mirror, Mirror on the Wall, Whatâ€™s the DAG Status After All?
âˆ’âˆ’ Implement some sample DAGs
âˆ’âˆ’ Implement an Airflow AI agent with PydanticAI
âˆ’âˆ’ Demo
â€“ From Blind Flight to Clear Skies

Why PydanticAI? The FastAPI Feeling for AI Development
Building production-grade AI applications shouldnâ€™t feel like solving a puzzle. Yet, when I first explored the landscape of AI frameworks, thatâ€™s exactly what it felt like. Let me share why PydanticAI is becoming my go-to choice for modern AI development.

The Current Landscape
The AI framework ecosystem is rich with options:

LangChain: Comprehensive but complex, offering numerous integrations and features.
crewAI: Specialized in multi-agent orchestration, great for complex agent interactions.
Instructor: Focused on structured outputs and instruction following.
Each has its strengths, but they often come with significant complexity and steep learning curves.

PydanticAI Simplicity
from pydantic_ai import Agent

agent = Agent('gemini-1.5-flash', system_prompt='Be concise.')
result = agent.run_sync('Why choose PydanticAI?')
When I first saw the PydanticAI examples, it reminded me of my first FastAPI experience â€” clean, intuitive, and just right.

What sets PydanticAI apart:

Built by the Pydantic Team

Deep integration with Pydanticâ€™s ecosystem
Type safety that actually helps development
Familiar patterns for FastAPI developers
Production-Ready Design

Model-agnostic (OpenAI, Anthropic, Gemini, Ollama)
Built-in dependency injection for testing
Seamless Logfire integration for real-time monitoring
Clean, Maintainable Code

Minimal boilerplate
Strong type checking
Intuitive error messages
Note: The integration with Logfire is simple yet elegant, allowing for a detailed understanding of the flow of agents. There are impressive examples on the official PydanticAI page, but I havenâ€™t tried them yet. I highly recommend checking it out if you want to explore the framework beyond this article. If you do, feel free to let me know how it goes. ğŸ˜‰

The Future of PydanticAI
The real power of PydanticAI lies in its alignment with modern Python development practices. As Pydantic continues to be the backbone of major Python frameworks and AI libraries, PydanticAIâ€™s tight integration becomes increasingly valuable.

Its future looks promising because:

Growing Pydantic ecosystem integration
Active development by the core Pydantic team
Focus on developer experience and production readiness
When to consider alternatives? If you need LangChainâ€™s vast integrations, crewAIâ€™s multi-agent capabilities, or Instructorâ€™s specialized instruction handling. But for most AI applications, PydanticAI provides everything you need with less complexity.

PydanticAI brings the â€œFastAPI feelingâ€ to AI development â€” and thatâ€™s exactly what this space needs. Itâ€™s not just about writing less code; itâ€™s about writing better, more maintainable AI applications.

Note: PydanticAI is still in early development, but given the Pydantic teamâ€™s track record, Iâ€™m confident in betting on its future. The framework is already showing what the future of AI development tools should look like.

PydanticAI Basics: A Quick Start Guide
PydanticAI makes building AI agents feel as natural as writing regular Python code. Letâ€™s look at three core patterns that make it powerful yet simple to use.

I will keep this brief because, honestly, the PydanticAI documentation is among the best I have ever read. Generally, Pydantic projects feature excellent documentation with an engaging, informative, and enjoyable writing style. Therefore, the best way to gain more information is to consult the documentation directly. This article aims to go beyond the documentation and explore a creative real-world application of the framework.

Basic Agents

agent = Agent('gemini-1.5-flash', system_prompt='Be concise.')
result = agent.run_sync('What is PydanticAI?')
At its simplest, an agent is just a wrapper around an LLM that handles the conversation flow. You choose your model, set a system prompt, and start chatting.

Structured Outputs

class WeatherInfo(BaseModel):
    temperature: float
    condition: str

weather_agent = Agent('gemini-1.5-flash', result_type=WeatherInfo)
Instead of parsing free text, PydanticAI guides the LLM to return structured data. Your IDE gets type hints, and you get guaranteed data structure.

Tools

@agent.tool
async def get_temperature(city: str) -> float:
    """Fetch current temperature for a city."""
    return await weather_api.get(city)
Tools are functions your agent can call. They extend your agentâ€™s capabilities beyond conversation to real actions like API calls or data fetching.

Whatâ€™s particularly clever about PydanticAIâ€™s tool system is how it handles function signatures. The framework automatically extracts parameters (except RunContext) to build the tool's schema, and even pulls parameter descriptions from your docstrings using griffe.

This intelligent parsing means your tools are not just functional â€” theyâ€™re self-documenting. The LLM understands exactly how to use them because the documentation is built right into the schema. No more manually maintaining separate descriptions of your tools!

What I love about PydanticAI is how these patterns compose naturally. Start with a basic agent, add structure when you need clean data, and sprinkle in tools when you need real-world interactions. It grows with your needs! ğŸ› ï¸

This foundation is all you need to start building powerful AI agents. In our Airflow example coming up, weâ€™ll see how these patterns work together in a real application.

Mirror, Mirror on the Wall, Whatâ€™s the DAG Status After All?
The complete code for this tutorial is available on GitHub. While weâ€™ll walk through the key components here, feel free to clone the repository to follow along:

git clone git@github.com:vojay-dev/pydantic-airflow-agent.git
Bear in mind that PydanticAI is under heavy development, which is great, but it also means that details of this demo project might change in the future. However, it will definitely help you gain a good understanding of the basic principles and inspire your own PydanticAI project.

With this project, we aim to go beyond the documentation and basic examples. Letâ€™s create an AI agent that can interact with Airflow via the Airflow REST API. You will be able to ask it about the status of a DAG without needing to specify an exact DAG ID. Simply describe the DAG, and the agent will identify the most relevant one by retrieving all DAGs from the API. It will then fetch the status of the selected DAG and return the information in a structured format.

For simplicity, we are using a local Airflow environment with Docker and Astro CLI (install via brew install astro), which is an effective way to start Airflow projects. We will integrate our PydanticAI agent and Airflow setup within the same project for ease of use. Typically, these would be two separate components.

We are using the latest version of Airflow, 2.10.4, as of the time of writing this article. If you are reading this after the release of Airflow 3, thatâ€™s amazing! I canâ€™t wait for the new UI and other great features. However, this also means that things may have changed significantly. Still, you should be able to get an idea of how to adapt to it.

First, letâ€™s set up the project using Poetry and install the required dependencies, starting with PydanticAI and then creating an Airflow environment via Astro CLI.

poetry new pydantic-airflow-agent
cd pydantic-airflow-agent
poetry add pydantic-ai
poetry add colorlog
Before adding the Airflow dependency, change the Python requirement in pyproject.toml:

python = ">=3.12,<3.13"
Now, add the Airflow dependency:

poetry add apache-airflow
Finally, spin up the local Airflow environment:

astro dev init # confirm to create the project in a non-empty directory
astro dev start
Implement some sample DAGs
The focus is the PydanticAI driven AI agent, however, without some DAGs we have nothing to interact with. We go as minimal as possible and simply add to DAGs doing nothing essentially.

import pendulum  
from airflow.decorators import dag, task  
from airflow.operators.smooth import SmoothOperator  
  
start_date = pendulum.datetime(2024, 12, 1, tz="UTC")  
  
@dag(schedule='@daily', start_date=start_date)  
def payment_report():  
    SmoothOperator(task_id='some_task')  
  
@dag(schedule='@daily', start_date=start_date)  
def customer_profile():  
    SmoothOperator(task_id='some_task')  
  
payment_report()  
customer_profile()
If you donâ€™t know about SmoothOperator yet, check the logs for it in Airflow. It's a delightful little Easter egg that brings a smile to the faces of us Data Engineers.


Local Airflow setup with two example DAGs, source: by author
Implement an Airflow AI agent with PydanticAI
Since we want to interact with Airflow through the Airflow REST API, we can derive some of the agentâ€™s dependencies from it. We need the base URI of our Airflow service, the port on which the API is running, and a username and password.

We also expect our AI agent to respond with a structured object that represents the state of a DAG, including several interesting attributes. Letâ€™s define both the dependencies and the output model.

@dataclass  
class Deps:  
    airflow_api_base_uri: str  
    airflow_api_port: int  
    airflow_api_user: str  
    airflow_api_pass: str  
  
class DAGStatus(BaseModel):  
    dag_id: str = Field(description='ID of the DAG')  
    dag_display_name: str = Field(description='Display name of the DAG')  
    is_paused: bool = Field(description='Whether the DAG is paused')  
    next_dag_run_data_interval_start: str = Field(description='Next DAG run data interval start')  
    next_dag_run_data_interval_end: str = Field(description='Next DAG run data interval end')  
    last_dag_run_id: str = Field(default='No DAG run', description='Last DAG run ID')  
    last_dag_run_state: str = Field(default='No DAG run', description='Last DAG run state')  
    total_dag_runs: int = Field(description='Total number of DAG runs')
With that, we can define our model and Agent. For this example, we use the latest Gemini 2.0 Flash model.

Note: I experimented extensively with various models. Many models struggled to interact with tool functions in the correct order or to use the results for constructing the final structured output. Gemini 2.0 Flash provided the best results, but I also recommend trying other supported models. You can use models via Ollama, such as Mistral or Llama 3.3, both of which also support tool functions and structured output. However, for this demo, we will use the model that gave the best results. Ultimately, we want to have an agent we can trust. Would you fly on an airplane that only sometimes works?

model = VertexAIModel(  
    model_name='gemini-2.0-flash-exp',  
    service_account_file='gcp-credentials.json'  
)  
  
airflow_agent = Agent(  
    model=model,  
    system_prompt=(  
        'You are an Airflow monitoring assistant. For each request:\n'  
        '1. Use `list_dags` first to get available DAGs\n'  
        '2. Match the user request to the most relevant DAG ID\n'  
        '3. Use `get_dag_status` to fetch the DAG status details'    ),  
    result_type=DAGStatus,  
    deps_type=Deps,  
    retries=2  
)
As you can see, I am quite strict and clear about how the agent should handle requests and interact with tool functions. This largely depends on the model you use. Depending on the use case, it can sometimes work well not to specify any tool functions explicitly in the system prompt.

Next, let us add a tool function so that our AI agent can retrieve a list of DAGs. We will return the DAG IDs and display names, allowing the model to select the DAG that best fits the userâ€™s question.

@airflow_agent.tool
async def list_dags(ctx: RunContext[Deps]) -> str:
    """
    Get a list of all DAGs from the Airflow instance. Returns DAGs with their IDs and display names.
    """
    logger.info('Getting available DAGs...')
    uri = f'{ctx.deps.airflow_api_base_uri}:{ctx.deps.airflow_api_port}/api/v1/dags'
    auth = (ctx.deps.airflow_api_user, ctx.deps.airflow_api_pass)

    async with AsyncClient() as client:
        response = await client.get(uri, auth=auth)
        response.raise_for_status()

        dags_data = response.json()['dags']
        result = json.dumps([
            {'dag_id': dag['dag_id'], 'dag_display_name': dag['dag_display_name']} for dag in dags_data
        ])
        logger.debug(f'Available DAGs: {result}')
        return result
Each tool function receives the RunContext, which contains the previously defined dependencies. This allows us to easily connect to the Airflow API and fetch the necessary data.

Once the agent determines which DAG ID best fits the userâ€™s requests, it must retrieve the details about the DAG and its runs to compute the structured output, also known as the model class we defined earlier.

Therefore, letâ€™s add another tool function to obtain the details.

@airflow_agent.tool
async def get_dag_status(ctx: RunContext[Deps], dag_id: str) -> str:
    """
    Get detailed status information for a specific DAG by DAG ID.
    """
    logger.info(f'Getting status for DAG with ID: {dag_id}')
    base_url = f'{ctx.deps.airflow_api_base_uri}:{ctx.deps.airflow_api_port}/api/v1'
    auth = (ctx.deps.airflow_api_user, ctx.deps.airflow_api_pass)

    try:
        async with AsyncClient() as client:
            dag_response = await client.get(f'{base_url}/dags/{dag_id}', auth=auth)
            dag_response.raise_for_status()

            runs_response = await client.get(
                f'{base_url}/dags/{dag_id}/dagRuns',
                auth=auth,
                params={'order_by': '-execution_date', 'limit': 1}
            )
            runs_response.raise_for_status()

            result = {
                'dag_data': dag_response.json(),
                'runs_data': runs_response.json()
            }

            logger.debug(f'DAG status: {json.dumps(result)}')
            return json.dumps(result)

    except httpx.HTTPStatusError as e:
        if e.response.status_code == 404:
            return f'DAG with ID {dag_id} not found'
        raise
With that, we have all tools we need and can run the agent as follows.

async def main():
    deps = Deps(
        airflow_api_base_uri='http://localhost',
        airflow_api_port=8080,
        airflow_api_user='admin',
        airflow_api_pass='admin'
    )

    user_request = 'What is the status of the DAG for our daily payment report?'
    result = await airflow_agent.run(user_request, deps=deps)
    pprint(result.data)

if __name__ == "__main__":
    asyncio.run(main())
You might notice that many operations in PydanticAI use async and await. This isn't just a random choice - it's a powerful feature that makes our applications more efficient, especially when dealing with I/O operations like API calls or model interactions.

Think of async like being an expert multitasker. When youâ€™re cooking, you donâ€™t wait idly by the stove for water to boil â€” you prep other ingredients while waiting. Thatâ€™s what async does for our code. When our agent makes an API call or waits for an LLM response, instead of blocking everything else, it can handle other tasks â€” like processing another request or updating logs. This is particularly valuable in production environments where efficiency matters.

Letâ€™s combine everything before we dive into the demo. Here is the complete Airflow AI agent code with PydanticAI.

import asyncio
import json
import logging
from dataclasses import dataclass
from devtools import pprint

import colorlog
import httpx
from httpx import AsyncClient
from pydantic import BaseModel, Field
from pydantic_ai import Agent, RunContext
from pydantic_ai.models.vertexai import VertexAIModel

log_format = '%(log_color)s%(asctime)s [%(levelname)s] %(reset)s%(purple)s[%(name)s] %(reset)s%(blue)s%(message)s'
handler = colorlog.StreamHandler()
handler.setFormatter(colorlog.ColoredFormatter(log_format))
logging.basicConfig(level=logging.INFO, handlers=[handler])

logger = logging.getLogger(__name__)

@dataclass
class Deps:
    airflow_api_base_uri: str
    airflow_api_port: int
    airflow_api_user: str
    airflow_api_pass: str

class DAGStatus(BaseModel):
    dag_id: str = Field(description='ID of the DAG')
    dag_display_name: str = Field(description='Display name of the DAG')
    is_paused: bool = Field(description='Whether the DAG is paused')
    next_dag_run_data_interval_start: str = Field(description='Next DAG run data interval start')
    next_dag_run_data_interval_end: str = Field(description='Next DAG run data interval end')
    last_dag_run_id: str = Field(default='No DAG run', description='Last DAG run ID')
    last_dag_run_state: str = Field(default='No DAG run', description='Last DAG run state')
    total_dag_runs: int = Field(description='Total number of DAG runs')

model = VertexAIModel(
    model_name='gemini-2.0-flash-exp',
    service_account_file='gcp-credentials.json'
)

airflow_agent = Agent(
    model=model,
    system_prompt=(
        'You are an Airflow monitoring assistant. For each request:\n'
        '1. Use `list_dags` first to get available DAGs\n'
        '2. Match the user request to the most relevant DAG ID\n'
        '3. Use `get_dag_status` to fetch the DAG status details'
    ),
    result_type=DAGStatus,
    deps_type=Deps,
    retries=2
)

@airflow_agent.tool
async def list_dags(ctx: RunContext[Deps]) -> str:
    """
    Get a list of all DAGs from the Airflow instance. Returns DAGs with their IDs and display names.
    """
    logger.info('Getting available DAGs...')
    uri = f'{ctx.deps.airflow_api_base_uri}:{ctx.deps.airflow_api_port}/api/v1/dags'
    auth = (ctx.deps.airflow_api_user, ctx.deps.airflow_api_pass)

    async with AsyncClient() as client:
        response = await client.get(uri, auth=auth)
        response.raise_for_status()

        dags_data = response.json()['dags']
        result = json.dumps([
            {'dag_id': dag['dag_id'], 'dag_display_name': dag['dag_display_name']} for dag in dags_data
        ])
        logger.debug(f'Available DAGs: {result}')
        return result

@airflow_agent.tool
async def get_dag_status(ctx: RunContext[Deps], dag_id: str) -> str:
    """
    Get detailed status information for a specific DAG by DAG ID.
    """
    logger.info(f'Getting status for DAG with ID: {dag_id}')
    base_url = f'{ctx.deps.airflow_api_base_uri}:{ctx.deps.airflow_api_port}/api/v1'
    auth = (ctx.deps.airflow_api_user, ctx.deps.airflow_api_pass)

    try:
        async with AsyncClient() as client:
            dag_response = await client.get(f'{base_url}/dags/{dag_id}', auth=auth)
            dag_response.raise_for_status()

            runs_response = await client.get(
                f'{base_url}/dags/{dag_id}/dagRuns',
                auth=auth,
                params={'order_by': '-execution_date', 'limit': 1}
            )
            runs_response.raise_for_status()

            result = {
                'dag_data': dag_response.json(),
                'runs_data': runs_response.json()
            }

            logger.debug(f'DAG status: {json.dumps(result)}')
            return json.dumps(result)

    except httpx.HTTPStatusError as e:
        if e.response.status_code == 404:
            return f'DAG with ID {dag_id} not found'
        raise

async def main():
    deps = Deps(
        airflow_api_base_uri='http://localhost',
        airflow_api_port=8080,
        airflow_api_user='admin',
        airflow_api_pass='admin'
    )

    user_request = 'What is the status of the DAG for our daily payment report?'
    result = await airflow_agent.run(user_request, deps=deps)
    pprint(result.data)

if __name__ == "__main__":
    asyncio.run(main())
What I found essential is having high transparency regarding how the agent makes tool and LLM calls during development. In the example above, we use logging. However, I highly recommend checking out the Logfire integration.

Demo
Time to let the magic happen. Letâ€™s run our agent with the following user question:

What is the status of the DAG for our daily payment report?

Remember, we have two DAGs defined: payment_report and customer_profile. In the question above, we do not use the exact DAG IDs; the agent has to determine them on its own. Let's see how it handles our request by examining the output.

(.venv) ~/projects/pydantic-airflow-agent
poetry run python pydantic_airflow_agent/agent.py
2024-12-23 14:49:05,127 [INFO] [httpx] HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1/projects/vojay-329716/locations/us-central1/publishers/google/models/gemini-2.0-flash-exp:generateContent "HTTP/1.1 200 OK"
2024-12-23 14:49:05,132 [INFO] [__main__] Getting available DAGs...
2024-12-23 14:49:05,241 [INFO] [httpx] HTTP Request: GET http://localhost:8080/api/v1/dags "HTTP/1.1 200 OK"
2024-12-23 14:49:06,640 [INFO] [httpx] HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1/projects/vojay-329716/locations/us-central1/publishers/google/models/gemini-2.0-flash-exp:generateContent "HTTP/1.1 200 OK"
2024-12-23 14:49:06,643 [INFO] [__main__] Getting status for DAG with ID: payment_report
2024-12-23 14:49:06,721 [INFO] [httpx] HTTP Request: GET http://localhost:8080/api/v1/dags/payment_report "HTTP/1.1 200 OK"
2024-12-23 14:49:06,798 [INFO] [httpx] HTTP Request: GET http://localhost:8080/api/v1/dags/payment_report/dagRuns?order_by=-execution_date&limit=1 "HTTP/1.1 200 OK"
2024-12-23 14:49:09,915 [INFO] [httpx] HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1/projects/vojay-329716/locations/us-central1/publishers/google/models/gemini-2.0-flash-exp:generateContent "HTTP/1.1 200 OK"

DAGStatus(
    dag_id='payment_report',
    dag_display_name='payment_report',
    is_paused=False,
    next_dag_run_data_interval_start='2024-12-23T00:00:00+00:00',
    next_dag_run_data_interval_end='2024-12-24T00:00:00+00:00',
    last_dag_run_id='scheduled__2024-12-22T00:00:00+00:00',
    last_dag_run_state='success',
    total_dag_runs=22,
)
As you can see, it started by fetching the available DAGs:

2024-12-23 14:49:05,132 [INFO] [__main__] Getting available DAGs...\
It then selected the DAG which fits best to the user input, and used the other tool function to get the details:

2024-12-23 14:49:06,643 [INFO] [__main__] Getting status for DAG with ID: payment_report
And finally used structured output to return a DAGStatus instance.


The Airflow AI agent powered by PydanticAI in action, source: by author
Honestly, the first time I ran this successfully, it blew me away. This powerful prototype combines simplicity with type-safe integration, and I was immediately hooked. I began to think about how to generate value with such an agent. For example, imagine someone asks in the data teamâ€™s Slack channel why a specific report did not update. Such an agent could autonomously find the related DAG and engage in a conversation with the user while the Data Engineering team enjoys their coffee in peace. â˜•

From Blind Flight to Clear Skies
This article has shown that building production-grade AI applications doesnâ€™t have to feel like navigating through a storm. With the right tools and frameworks, it can be as straightforward as modern air travel â€” powerful, yet controlled and reliable.

The landscape of AI development is evolving rapidly, but frameworks like PydanticAI give us a steady foundation to build upon. Like modern aviation continues to advance while maintaining its core principles of safety and reliability, PydanticAI sets the stage for future innovations without sacrificing stability.

Keep an eye on the PydanticAI project. With the amazing team behind it and the frameworkâ€™s elegant design, I believe we are only seeing the beginning of its potential. ğŸš€

Whether youâ€™re building AI agents for Airflow monitoring, customer support, or any other use case, remember: you donâ€™t have to fly blind anymore. The instruments are here, the controls are intuitive, and the skies are clear for takeoff.

Now, if youâ€™ll excuse me, I have some DAGs to chat with! ğŸ˜‰

Enjoyed this article? ğŸ«¶
ğŸ‘ If you found value in this post, give it some claps (you can clap up to 50 times!)
ğŸ’­ Share your thoughts in the comments below â€” Iâ€™d love to hear your perspective
âœ¨ Highlight your favorite insights to bookmark them for later
ğŸ™ Your engagement means the world to me and helps this content reach more readers.