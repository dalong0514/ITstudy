## 20231229清华讲席教授周伯文内部分享

大语言模型为何会表现出接近 AGI 的能力

[清华讲席教授周伯文内部分享：大语言模型为何会表现出接近 AGI 的能力](https://new.qq.com/rain/a/20231227A06LWM00)

2023-12-28 07:00:00 发布于北京腾讯科技 AI 未来指北官方账号

「尝试找到如何让机器使用语言，形成抽象的概念，解决现在人类还不能解决的问题并提升自己等。对于当下的人工智能来说，首要问题是让机器像人类一样表现出智能。」这是 1956 年，达特茅斯会议上对人工智能的定义。从那时算起，人工智能的历史已经接近 70 年。

在今天，随着大语言模型的突破，让人类觉得似乎我们离 AGI 更近了一步。维特根斯坦有一句名言是：「语言的边界就是思想的边界」。AI 现在已经体现出掌握人类语言的能力，未来 AI 是不是真的能够去触摸人类思想的边界，并复现人类智能？

未来究竟是 AI for Tools (人类仍然是未来世界的主导）还是 Tools for AI (AI 会在未来占据主导地位)？

这是一个令人深思的哲学问题，现在还没有确切答案。但是 AI 的迅速发展已经在重塑技术发展路径和人类社会，除了大语言模型，我们也应该去思考更深层次的问题：当下 AI 智能的突破从哪里来？未来的 AI 向哪里发展？人工智能的发展对未来科学创新、人机协同有哪些影响？

清华大学讲席教授、电子工程系长聘教授、IEEE &CAAI Fellow、衔远科技创始人周伯文教授，近日在【2023 年腾讯技术周】AIGC 大咖面对面活动中，围绕以上问题，做了深度的内部分享。腾讯科技联合腾讯学堂，将周教授的分享整理成精华文章，收录在《AI 未来指北》系列内容中，希望能让更多持续关注 AI 发展的读者，获得一些灵感与收获。文章较长，值得收藏阅读。

划重点：

1、是不是全世界只需要一个巨大的语言模型就能够解决所有问题？从商业落地的角度看，可以总结为在「高价值」（high-value）和「高通量」（high-volume）之间寻求平衡。

2、ChatGPT 的诞生让 AI 从「与人竞争」变成「与人协同交互」。

3、从 GPT 到 Agent，核心问题在于 AI 作为人类创造的工具，是否能够自己学会创造和使用工具？这将是智能的下一个阶段。

以下为分享精华内容：

### 01. 一个大模型能解决所有问题？

第一个方向是大模型需要承担更多复杂场景的任务。

一些段子在网络上流传，戏谑大模型似乎只擅长诗歌和绘画，而人们依然在辛苦的从事各种工作。这其实源于大模型尚未具备处理众多复杂任务的能力。尽管它在推理、对话和总结方面取得了显著进展，但如何让它在复杂的现实世界中解决更多实际问题，这是大模型发展的一个重要方向。

第二个方向是大模型的专业化能力。

虽然这两个问题有相关性，但并不完全相同。复杂问题不一定需要高度专业化的能力，复杂问题可能是由一系列简单问题的组合构成。因此，如何将复杂问题分解成更简单的问题是一个方向，而专业化则是另一个方向。一开始很多人都忽视了专业化的重要性。例如，2023 年初，在 ChatGPT 横空出世后，很多人预期一个大模型可以解决所有问题，因此并未考虑专业化的问题。拉长时间维度到无限来看，这仍然是一个开放性问题，即如果 GPT4 无法胜任，是否可以依赖 GPT5、GPT6......？但从可见未来的一段时间来看，答案应该是明确否定的。

我想引用谷歌前董事长埃里克·施密特和斯坦福大学教授合作在今年 4 月份发布的一篇论文，题为「是不是全世界只需要一个巨大的语言模型能够解决所有问题」。

这篇论文得出的结论也是否定的。尽管这篇文章很长，但从我的角度看，可以总结为在「高价值」（high-value）和「高通量」（high-volume）之间寻求平衡。他们在论文中呈现了一张图表，横轴表示工作流，纵轴表示价值，以展示不同大模型在不同场景下的表现。如下所示，这张图表符合许多 AI 技术落地与价值创造的规律。

[Maithra Raghu | Does One Large Model Rule Them All?](https://maithraraghu.com/blog/2023/does-one-model-rule-them-all/)

在高频使用情境中，通用 AI 模型可以创造一定的价值，然而，这种价值潜力有限。ChatGPT 的月活跌幅也在某种程度上印证了这一观点。通用 AI 模型看似适用于各种任务，但各任务的实际价值有限，同时也会对模型提出需求，即推理成本必须低于带来的价值，这使得推理方面的要求更为迫切。

相应地，Workflow（工作流）中的头部呈现出极高的价值潜力，因此，模型需要具备高度专业化。在有限的应用情境中，这将带来高价值。

我们希望回答以下三个核心问题：

1、当前 AI 智能的突破点在哪里？

2、未来 AI 的发展方向是什么？

3、人工智能的发展对未来科学创新和人机协同将产生何种影响？

首先我认为目前 ChatGPT 带来的核心变化在两个维度。

第一个维度，ChatGPT 的诞生让「与人竞争的 AI」变成「与人协同交互的 AI」。

在 ChatGPT 之前，从 AIphaGo 到深蓝再到 Watson。每一次 AI 成为头条事件，它的背后都是 AI 与地表最强人类竞争获胜来获取大众注意力。但这次 ChatGPT 为什么引起的热潮更大？

最大的原因是 ChatGPT 不再是跟人竞争，而是它能够与千千万万个你我一样的普通人一起更好地从协同、交互的角度解决现实问题。这样的 AI 毫无疑问比与人竞争的 AI 带来的市场价值和规模更大。

这是我长期以来的观点，即 AI 的最大价值在于与人协同和互动，在交互中学习。这种学习不仅包括技能的学习，还包括价值观的对齐，从而协同解决问题。在考虑 AI 应该处理什么问题、解决什么难题时，目前 ChatGPT 在这方面更符合期望。

第二个维度，我想分享我于 2016 年在纽约的一些思考。当时，我们和一些来自全球的人工智能研究者在一个会议上一起探讨未来人工智能的发展趋势。

我当时提到一个概念，关于人工智能的发展，我认为在 2016 年之后将划分为三个阶段，如下图所示。

Stage 1: Artificial Narrow Intelligence (largely done by 2016)

- Mostly supervised learning with a large amount of manually labeled data

- Task scope is narrow and new models need to be trained for new tasks

- We know exactly what AI can or cannot do

Stage 2: Artificial Broad Intelligence (onboard!)

- Self supervision: No need for excessive explicit teaching

- End-to-end: Al can decompose & complete multiple tasks on its own

- Discrimination/Classification => Generative Assistant

- Unexpected: Emergence, zero-shot learning

Stage 3: AGI (yet to come)

- Smarter than humans and always learning to become smarter

- Independent and self-developed

- Govemance & regulation is a MUST

当时，我们都假设人工智能最终目标是实现 AGI，即比人类更具智慧且可以持续学习，所以治理和监管要做好准备，但 2016 年时并没有大家能看到的实现路径。与此对应，我将 2016 年时的人工智能称之为狭义人工智能（ANI，Artificial Narrow Intelligence），即第一阶段。它的定义是此时人工智能大部分的训练和学习来自于人工标注和监督的数据；任务范围窄；如果执行新任务，需要重新训练；我们完全知道「那个 AI」能做什么、不能做什么。后者虽然不一定让人满意，但让我们晚上可以安心睡觉。

我当时提出在通向 AGI 的方向上会有一个必经之路的第二个阶段，叫做 ABI（Artificial Broad Intelligence，广义人工智能）。它的定义：

第一，一定是大量的自监督学习，不需要额外的标注。

第二，一定要端到端，AI 能自己执行并完成复杂的任务，具备自发的子任务分解与多任务学习能力。以语音翻译举例，在 2016 年绝大部分语音翻译是先识别，后翻译，再合成。任务的分割是人工给予并分阶段标注的。所谓的 ABI 应该是端到端的，何时识别何时翻译，不用人再发出指示，而是 AI 自己决定，子任务之间可能没有明确的界限。

第三，当时提出了要从分类任务、决策任务变成生成式的助手。

著名物理学家 Feynman

如上这张图是美国著名的物理学家 Feynman，他说过「凡是我不能创造的，我都没有真正理解」。Feynman 代表的毫无疑问是人类的最高水平，AI 也一样，如果 AI 不能创造，AI 就没有真正理解。

所谓的自然语言理解，所谓的 benchmark 都不是真正理解，只有逼着它做生成，才能倒过来做理解。

曾经我们认为 ABI 将是过渡到 AGI 的必由之路，但现在 ChatGPT 在 2022 年、2023 年都实现了。

基于当时 ABI 的判断，我当时已专注于多头 self-attention 的工作，因为按照端到端的思考，如何让模型学好与下游任务无关的任务，这其中自然语言的上下文表征很重要，我们基于此工作发表相关论文于 2017 初的 ICLR 上。

2017 年谷歌发表的论文 Attention is All you need，这也成为 Transformer 核心思想之一，Transformer 也采用多头自注意力，Open AI 首先意识到 Transformer 的价值，坚持用预测下一个词的方式来高效率、大规模来评估和训练智能体，使得 GPT 应运而生。

Open AI 为什么会这种认识？它在报告中提到，基于多头自注意力架构来预测下一个词训练出来的大语言模型，是目前最好的世界知识压缩器。（To predict the next word with multi-head self-attention architecture is currently the SOTA world knowledge compressor）

换一句话讲，你预测下一个词，可以把世界知识都压缩进一个大模型里。你去问模型丹麦的首都是哥本哈根还是伦敦，逼着它去学会地理知识。这种对下一个词的预训练会逼着模型学到很多知识，而且这种知识进化到一定程度会展现出非常惊艳的效果。

当然还有 BERT，BERT 也是一种 Transformer，最核心的差别在于 BERT 不是基于上文预测下一个词，而是把中间的一个词抠掉，用上文和下文一起预测出中间词。

BERT 和 GPT 之间的差异体现在哪里？这微小的差异实际上反映了哲学上的不同思考方式。BERT 鼓励模型使用未来的信息来预测，而 GPT 则要求只使用历史信息，不能使用未来信息来预测下一个词。

正是基于所有这些工作，现在我们可以看到这种压缩技术能够产生许多令人惊讶的智能表现。

举一个例子，衔远打造的 ProductGPT 大模型执行的问答任务。ProductGPT 是通过压缩消费者与商品或服务之间的各种互动与世界知识，来更专业地学习理解商品和消费者。我认为这个答案能够很好地展示底层大模型具备的能力。

背景是瑞幸和茅台联名推出了酱香拿铁，我们询问模型，它如何看待这一事件，茅台和咖啡的联名产品是否可能成为爆款，以及有哪些优势和风险。

这个模型的训练早在瑞幸推出该产品之前就已经完成，因此模型对瑞幸的这次创新一无所知，问题和答案中都没有提及瑞幸，而是讨论咖啡和茅台的假设性的联合产品。能看出来它的所有分析都是基于大模型的内生能力，而不是使用搜索增强来总结执行助手任务，这体现了大模型已经扩展到完成战略预测和深度思考的任务。

从表达的架构和逻辑来看，许多大模型在很多方面相似，但最关键的差别是专业性和由此带来的思考深度问题。

ProductGPT 的回答涉及以下几个方面：

首先它指出茅台和咖啡的消费者群体重叠很低，事实上这是推出联名款的主要动机，以此扩大潜在消费者群体。同时大模型提到了潜在的联名产品面临的需要克服的挑战，比如首先是产品创新，关于咖啡和茅台如何融合来解决味道、口感、风格的问题。

其次，价格定位。模型理解茅台是高端产品，而咖啡不是，需要确定如何定价。

第三，供应链和渠道。咖啡主要通过线下门店销售，而茅台的销售不是那么依赖于门店，两者如何融合？特别是茅台在供应链流通中还存在防伪、朔源等问题。

许多普通消费者在购买酱香拿铁前可能会有类似的设想，是否是在瑞幸咖啡店里放了几瓶茅台，在购买咖啡时添加一些茅台？如果是这样的话，ProductGPT 提出的以上这些挑战都不能很好地解决。

瑞幸和解决这些挑战的办法就是将酱香加入到奶精中。这也是为什么这个产品被称为「酱香拿铁」而不是「酱香咖啡」的原因。

实际上通过这一做法解决了三个问题。首先，将茅台加入奶精中简化了产品创新问题，咖啡豆的选择、烘焙和制作咖啡的过程保持不变。

其次，酱香奶精降低了加入茅台的成本，因此解决了价格问题。

第三，它解决了供应链和渠道问题，将酱香密封在奶精中，可以更方便线下门店运输和存储，而不是运输茅台本身。避免了涉及到茅台物流需要考虑的防伪防盗等因素和额外的成本支出。

换句话说，我们能看到 ProductGPT 大模型基于内在的认知和推理，在短短 10 秒内提出的关键优势与潜在问题，是茅台和瑞幸这样的顶级商业机构和优秀团队在合作中真正去考虑与解决的关键点。这反映出了专业性和人与商品之间的复杂性。大模型通过生成式人工智能以及对下一个词的预测来学会解决这类问题。

### 02. LLM 为什么会表现出接近 AGI 的能力？

我们需要思考为什么基于语言的大模型具有一定程度的 AGI 能力。很多人都认为 ChatGPT 是离 AGI 最近的 AI 系统。

我认为出现这种想法的原因有两点：第一点，解释了为什么它具备 AGI 的智能。

维特根斯坦有一句名言是：「语言的边界就是思想的边界」。类似的表达还有「凡是不能用语言表达的都不值得讨论，也无法讨论」。换句话说，整个世界的知识在很大程度上会被压缩成语言，并且能够在下一个词中重新构建。

第二点是「Sequentialization」（序列化）。与正常语言一样，将信息排列成从左到右的序列是一种高度的抽象过程。这种抽象和还原过程非常重要，因为 Sequentialization 学会的不仅仅是世界知识，还包括人的状态和人机互动，这些都在其中进行了压缩。

我认为下一步的发展，从 GPT 到 Agent，核心问题在于 AI 作为人类创造的工具，它是否能够自己学会创造和使用工具？这将是智能的下一个阶段。

我认为是肯定的。从语言模型的角度来看，从 Edward 的专家系统到语言分层理论再到 IBM 模型或 Yoshua Bengio 的神经网络等，现在基本上已经解决了语言问题。但 AI 如何理解和使用工具，这是一个非常重要的问题，可以从语言的角度进行思考，并且有很多相似性。

在很多工作中，已经有使用基座模来调用这些工具。但我们需要思考一个框架性的问题，即当谈论工具时，实际上指的是哪些工具。

我将工具定义成三类：

第一类，能够跟物理世界进行互动的工具，比如机器人、机械臂。

第二类，GUI 工具，在移动互联网时代，整个世界可以抽象成一系列 GUI 的工具组合。

第三类，所有可编程的接口、API 都是工具。这是所谓的软件正在吞噬世界后面的逻辑。

在把所有的工具定位成这三类，再来思考一个具备语言智能和工具智能的 Agent 应该是什么？和自然语言一样，三类工具经过处理后，都可以把它理解成是一系列的 Token。

这里面有两个含义，Tokenization everything。即世界上所有的工具都可以被表征，可以被比较，可以被组合，可以去思考它们相互的关系。

同时，能够把它序列化。所有一切任务的组合都取决于序列，什么时间，什么地点，用什么工具。如果跳出自己去观察一个人，站在另外一个角度看某人，他做的所有工作都是唤起一系列工具来完成的，从早上被闹钟叫醒起床，到刷牙、上班、写代码等等，每一个过程都在唤醒某一个工具，而且需要理解工具输出的结果以及下一步的处理。

如果人这样理解，那所有的智能体做的工作就是学习怎么标记和使用这些工具，理解这些工具的输出。这样带来的好处是这种工具的使用和语言的输出和 GPT 模型一样。原来训练中的算法在工具化的使用中是完全可以复用的。

未来还有亟待深度思考的问题，我们如何实现工具智能？下一代的操作系统将会如何？我们也在进行相关的研究，研究成果也会在未来系统性地发布。如果大家有任何问题或建议，也欢迎留言或联系编辑 grace_guoxj，感谢大家的耐心阅读。