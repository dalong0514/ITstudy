## 20240501七个帮助最小化RAG模型风险的指标

原文：

[7 measurements that help minimize model risk for RAG - YouTube](https://www.youtube.com/watch?v=DRZMjP5Pg5A)

今天我们要学习如何使用关键指标评估 RAG。

想象一下你早上准备开车时的情景。你会看车辆的仪表盘，上面有许多信息。从速度表显示的你的行驶速度，到可能因为超速而被罚款，再到汽油表告诉你油箱是空的还是满的，以确保你在路上不会因为没有油而抛锚或者因为加油而迟到，接着你还会看到像发动机指示灯这样的警告灯。知道车内是否有人没系安全带，或者你是否需要换机油，或者你的发动机是否有问题。我们想要了解这些信息，只有通过车辆提供的各种监测器和指标来确保安全。

对于你的生成式 AI 模型也同样如此。我们需要确保我们正在监控这些模型，以尽可能减少你在使用它们过程中可能遇到的风险。

下面我们进一步了解一下检索增强生成，也就是 RAG。检索增强生成是一种非常流行的生成式 AI 方法，它从向量数据库中提取信息，这些信息数量庞大并且会定期更新，以确保你获取的信息是最新和最准确的。你可以在一个地方用自然语言提出问题并获取这些信息的答案，这一点非常关键。所以这不仅是获取信息的来源，而是从多个来源汇集信息到一个地方。

好的，现在我们来讨论评估你的 RAG 模型的七个关键指标。

1、Rouge 分数。它也用来衡量召回率和完整性。当我们得到模型生成的回答后，我们会把它和一组人类生成的期望回答进行对比。接下来，我们要对比计算机生成的文字中的具体词语，我们不只对比一个词，而是会看一系列的词，看我们生成的回答与期望回答的完整性如何。这个分数会在 0 和 1 之间变化。

2、BLEU 分数。不知道有没有人注意到这些都是法语单词。如果你知道这些评估方法的起源，我们非常欢迎你留言评论。BLEU 分数主要衡量的是精确度。因此，我们再次审视计算机生成的回应与我们期望的标准相比的情况。我们关注的是整个文本中各个词汇的精确度。在这种情况下，长回应可能会由于受到惩罚而影响其精确性和准确性，因为长回应相对于原文可能会被过分惩罚。因此，这是在使用 Bleu 评分方法时您可能需要考虑的一个因素。

3、Metor 分数。它能给我们提供精确度和召回率的平均值，这是从第一点和第二点得出的。这是一种比较全面的评估模型性能的方式。

4、PII（个人身份信息）。这就是所有能够识别你身份的信息，像电话号码、电子邮件、名字这样的信息。这些都是你可能不希望模型生成的，它们可能会让你从个人和消费者的角度承担巨大的责任。因此，了解模型的输出和输入都非常重要。

5、HAP 分数（仇恨、滥用和粗言秽语）。如果模型输出有关仇恨、滥用或者粗言秽语的内容，那就不妙了。所以，你需要随时监控模型，确保这种信息不会出现。我们肯定不希望这种情况发生。

6、上下文相关性。这个指标非常重要。比如说，我们提出一个关于纽约州的问题。这就是我对纽约州的描述。我们想要明确知道纽约州在哪里，它的首府是什么。所以，我们向检索增强型生成模型提出了两个问题，并希望得到一句话包含两个答案。如果我们的上下文相关性较差，我们可能会给出一个正确但和问题完全无关的答案。比如，纽约是一个帝国州，或者被称为帝国州。虽然这是一个事实，但并没有回答我们原来的问题，纽约在哪儿，首府是什么？这就是一个衡量上下文相关性的例子。

7、错觉。我们要确保模型不给出错误的答案，然后让我们误以为是正确的。回到我们的纽约例子，为了得到低的错觉分数和高的相关性分数。我们需要回答这两个问题。纽约位于美国东海岸，它北邻新泽西州，西邻康涅狄格州。首府是奥尔巴尼。所以，答案没有错觉，而且和上下文非常相关。

现在我们已经介绍了七个 RAG 评估指标。当然，还有许多其他的指标，我很希望在评论中听到你们用来监控 RAG 的一些最喜欢的指标。一定要使用这些指标来降低模型在实际应用中的风险。

